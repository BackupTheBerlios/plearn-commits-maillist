<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r10084 - trunk/plearn/ker
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2009-April/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10084%20-%20trunk/plearn/ker&In-Reply-To=%3C200904042034.n34KY3vm017752%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003523.html">
   <LINK REL="Next"  HREF="003525.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r10084 - trunk/plearn/ker</H1>
    <B>chapados at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10084%20-%20trunk/plearn/ker&In-Reply-To=%3C200904042034.n34KY3vm017752%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r10084 - trunk/plearn/ker">chapados at mail.berlios.de
       </A><BR>
    <I>Sat Apr  4 22:34:03 CEST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="003523.html">[Plearn-commits] r10083 - trunk/plearn/ker
</A></li>
        <LI>Next message: <A HREF="003525.html">[Plearn-commits] r10085 - trunk/plearn_learners/regressors
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3524">[ date ]</a>
              <a href="thread.html#3524">[ thread ]</a>
              <a href="subject.html#3524">[ subject ]</a>
              <a href="author.html#3524">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: chapados
Date: 2009-04-04 22:34:02 +0200 (Sat, 04 Apr 2009)
New Revision: 10084

Added:
   trunk/plearn/ker/Matern1ARDKernel.cc
   trunk/plearn/ker/Matern1ARDKernel.h
Log:
New Matern kernel with nu=1/2 corresponding to Ornstein-Uhlenbeck process

Added: trunk/plearn/ker/Matern1ARDKernel.cc
===================================================================
--- trunk/plearn/ker/Matern1ARDKernel.cc	2009-04-04 20:33:18 UTC (rev 10083)
+++ trunk/plearn/ker/Matern1ARDKernel.cc	2009-04-04 20:34:02 UTC (rev 10084)
@@ -0,0 +1,403 @@
+// -*- C++ -*-
+
+// Matern1ARDKernel.cc
+//
+// Copyright (C) 2009 Nicolas Chapados
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Nicolas Chapados
+
+/*! \file Matern1ARDKernel.cc */
+
+
+#include &quot;Matern1ARDKernel.h&quot;
+#include &lt;plearn/math/pl_math.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    Matern1ARDKernel,
+    &quot;Matern kernel with nu=1/2 that can be used for Automatic Relevance Determination.&quot;,
+    &quot;With nu=1/2, the Matern kernel corresponds to the Ornstein-Uhlenbeck\n&quot;
+    &quot;process.  This function is specified as:\n&quot;
+    &quot;\n&quot;
+    &quot;  k(x,y) = (sf / (2*a)) * exp(-a sum_i |x_i - y_i|/w_i) * k_kron(x,y)\n&quot;
+    &quot;\n&quot;
+    &quot;where sf = softplus(isp_signal_sigma), a = softplus(isp_persistence), w_i =\n&quot;
+    &quot;softplus(isp_global_sigma + isp_input_sigma[i]), and k_kron(x,y) is the\n&quot;
+    &quot;result of the KroneckerBaseKernel evaluation, or 1.0 if there are no\n&quot;
+    &quot;Kronecker terms.  Note that since the Kronecker terms are incorporated\n&quot;
+    &quot;multiplicatively, the very presence of the term associated to this kernel\n&quot;
+    &quot;can be gated by the value of some input variable(s) (that are incorporated\n&quot;
+    &quot;within one or more Kronecker terms).\n&quot;
+    &quot;\n&quot;
+    &quot;Note that to make its operations more robust when used with unconstrained\n&quot;
+    &quot;optimization of hyperparameters, all hyperparameters of this kernel are\n&quot;
+    &quot;specified in the inverse softplus domain.  See IIDNoiseKernel for more\n&quot;
+    &quot;explanations.\n&quot;
+    );
+
+
+Matern1ARDKernel::Matern1ARDKernel()
+    : m_isp_persistence(pl_log(exp(1.0) - 1.)) // inverse-softplus(1.0)
+{ }
+
+
+//#####  declareOptions  ######################################################
+
+void Matern1ARDKernel::declareOptions(OptionList&amp; ol)
+{
+    declareOption(
+        ol, &quot;isp_persistence&quot;,
+        &amp;Matern1ARDKernel::m_isp_persistence,
+        OptionBase::buildoption,
+        &quot;Inverse softplus of the O-U persistence parameter.  Default value =\n&quot;
+        &quot;isp(1.0).&quot;);
+    
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+
+//#####  build  ###############################################################
+
+void Matern1ARDKernel::build()
+{
+    // ### Nothing to add here, simply calls build_
+    inherited::build();
+    build_();
+}
+
+
+//#####  build_  ##############################################################
+
+void Matern1ARDKernel::build_()
+{
+    // Ensure that we multiply in Kronecker terms
+    inherited::m_default_value = 1.0;
+}
+
+
+//#####  evaluate  ############################################################
+
+real Matern1ARDKernel::evaluate(const Vec&amp; x1, const Vec&amp; x2) const
+{
+    PLASSERT( x1.size() == x2.size() );
+    PLASSERT( !m_isp_input_sigma.size() || x1.size() == m_isp_input_sigma.size() );
+
+    real gating_term = inherited::evaluate(x1,x2);
+    if (fast_is_equal(gating_term, 0.0))
+        return 0.0;
+    
+    if (x1.size() == 0)
+        return softplus(m_isp_signal_sigma) /
+            (2*softplus(m_isp_persistence)) * gating_term;
+    
+    const real* px1 = x1.data();
+    const real* px2 = x2.data();
+    real sf         = softplus(m_isp_signal_sigma);
+    real persistence= softplus(m_isp_persistence);
+    real expval     = 0.0;
+
+    // Case where we have real ARD
+    if (m_isp_input_sigma.size() &gt; 0) {
+        const real* pinpsig = m_isp_input_sigma.data();
+        for (int i=0, n=x1.size() ; i&lt;n ; ++i) {
+            real diff    = *px1++ - *px2++;
+            real absdiff = fabs(diff);
+            expval      += absdiff / softplus(m_isp_global_sigma + *pinpsig++);
+        }
+    }
+    // No ARD
+    else {
+        real global_sigma = softplus(m_isp_global_sigma);
+        for (int i=0, n=x1.size() ; i&lt;n ; ++i) {
+            real diff    = *px1++ - *px2++;
+            real absdiff = fabs(diff);
+            expval      += absdiff / global_sigma;
+        }
+    }
+
+    // Gate by Kronecker term
+    return sf / (2. * persistence) * exp(-persistence * expval) * gating_term;
+}
+
+
+//#####  computeGramMatrix  ###################################################
+
+void Matern1ARDKernel::computeGramMatrix(Mat K) const
+{
+    PLASSERT( !m_isp_input_sigma.size() || dataInputsize() == m_isp_input_sigma.size() );
+    PLASSERT( K.size() == 0 || m_data_cache.size() &gt; 0 );  // Ensure data cached OK
+
+    // Compute Kronecker gram matrix
+    inherited::computeGramMatrix(K);
+
+    // Precompute some terms. Make sure that the input sigmas don't get too
+    // small
+    real sf          = softplus(m_isp_signal_sigma);
+    real persistence = softplus(m_isp_persistence);
+    m_input_sigma.resize(dataInputsize());
+    softplusFloor(m_isp_global_sigma, 1e-6);
+    m_input_sigma.fill(m_isp_global_sigma);  // Still in ISP domain
+    for (int i=0, n=m_input_sigma.size() ; i&lt;n ; ++i) {
+        if (m_isp_input_sigma.size() &gt; 0) {
+            softplusFloor(m_isp_input_sigma[i], 1e-6);
+            m_input_sigma[i] += m_isp_input_sigma[i];
+        }
+        m_input_sigma[i] = softplus(m_input_sigma[i]);
+    }
+
+    // Compute Gram Matrix
+    int  l = data-&gt;length();
+    int  m = K.mod();
+    int  n = dataInputsize();
+    int  cache_mod = m_data_cache.mod();
+
+    real *data_start = &amp;m_data_cache(0,0);
+    real *Ki = K[0];                         // Start of current row
+    real *Kij;                               // Current element along row
+    real *input_sigma_data = m_input_sigma.data();
+    real *xi = data_start;
+    
+    for (int i=0 ; i&lt;l ; ++i, xi += cache_mod, Ki+=m)
+    {
+        Kij = Ki;
+        real *xj = data_start;
+
+        for (int j=0; j&lt;=i; ++j, xj += cache_mod) {
+            // Kernel evaluation per se
+            real *x1 = xi;
+            real *x2 = xj;
+            real *p_inpsigma = input_sigma_data;
+            real sum_wt = 0.0;
+            int  k = n;
+
+            // Use Duff's device to unroll the following loop:
+            //     while (k--) {
+            //         real diff = *x1++ - *x2++;
+            //         sum_wt += fabs(diff) / *p_inpsigma++;
+            //     }
+            real diff;
+            switch (k % 8) {
+            case 0: do { diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+            case 7:      diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+            case 6:      diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+            case 5:      diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+            case 4:      diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+            case 3:      diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+            case 2:      diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+            case 1:      diff = *x1++ - *x2++; sum_wt += fabs(diff) / *p_inpsigma++;
+                       } while((k -= 8) &gt; 0);
+            }
+
+            // Multiplicatively update kernel matrix (already pre-filled with
+            // Kronecker terms, or 1.0 if no Kronecker terms, as per build_).
+            real Kij_cur = *Kij * sf / (2.*persistence) * exp(-persistence * sum_wt);
+            *Kij++ = Kij_cur;
+        }
+    }
+    if (cache_gram_matrix) {
+        gram_matrix.resize(l,l);
+        gram_matrix &lt;&lt; K;
+        gram_matrix_is_cached = true;
+    }
+}
+
+
+//#####  computeGramMatrixDerivative  #########################################
+
+void Matern1ARDKernel::computeGramMatrixDerivative(
+    Mat&amp; KD, const string&amp; kernel_param, real epsilon) const
+{
+    static const string ISS(&quot;isp_signal_sigma&quot;);
+    static const string IGS(&quot;isp_global_sigma&quot;);
+    static const string IIS(&quot;isp_input_sigma[&quot;);
+    static const string IPe(&quot;isp_persistence&quot;);
+
+    if (kernel_param == ISS) {
+        computeGramMatrixDerivIspSignalSigma(KD);
+        
+        // computeGramMatrixDerivNV&lt;
+        //     Matern1ARDKernel,
+        //     &amp;Matern1ARDKernel::derivIspSignalSigma&gt;(KD, this, -1);
+    }
+    /*
+    else if (kernel_param == IGS) {
+        computeGramMatrixDerivNV&lt;
+            Matern1ARDKernel,
+            &amp;Matern1ARDKernel::derivIspGlobalSigma&gt;(KD, this, -1);
+    }
+    else if (string_begins_with(kernel_param, IIS) &amp;&amp;
+             kernel_param[kernel_param.size()-1] == ']')
+    {
+        int arg = tolong(kernel_param.substr(
+                             IIS.size(), kernel_param.size() - IIS.size() - 1));
+        PLASSERT( arg &lt; m_isp_input_sigma.size() );
+
+        computeGramMatrixDerivIspInputSigma(KD, arg);
+
+    }
+    */
+    else
+        inherited::computeGramMatrixDerivative(KD, kernel_param, epsilon);
+}
+
+
+//#####  evaluate_all_i_x  ####################################################
+
+void Matern1ARDKernel::evaluate_all_i_x(const Vec&amp; x, const Vec&amp; k_xi_x,
+                                        real squared_norm_of_x, int istart) const
+{
+    evaluateAllIXNV&lt;Matern1ARDKernel&gt;(x, k_xi_x, istart);
+}
+
+
+//#####  derivIspSignalSigma  #################################################
+
+real Matern1ARDKernel::derivIspSignalSigma(int i, int j, int arg, real K) const
+{
+    // (No longer used; see computeGramMatrixDerivIspInputSigma below)
+    return K*sigmoid(m_isp_signal_sigma)/softplus(m_isp_signal_sigma);
+}
+
+
+//#####  derivIspGlobalSigma  #################################################
+
+real Matern1ARDKernel::derivIspGlobalSigma(int i, int j, int arg, real K) const
+{
+    if (fast_is_equal(K,0.))
+        return 0.;
+
+    // The norm term inside the exponential may be accessed as Log(K/sf)
+    real inner = pl_log(K / softplus(m_isp_signal_sigma));
+    return - K * inner * sigmoid(m_isp_global_sigma) / softplus(m_isp_global_sigma);
+
+    // Note: in the above expression for 'inner' there is the implicit
+    // assumption that the input_sigma[i] are zero, which allows the
+    // sigmoid/softplus term to be factored out of the norm summation.
+}
+
+
+//#####  computeGramMatrixDerivIspSignalSigma  ################################
+
+void Matern1ARDKernel::computeGramMatrixDerivIspSignalSigma(Mat&amp; KD) const
+{
+    int l = data-&gt;length();
+    KD.resize(l,l);
+    PLASSERT_MSG(
+        gram_matrix.width() == l &amp;&amp; gram_matrix.length() == l,
+        &quot;To compute the derivative with respect to 'isp_signal_sigma', the\n&quot;
+        &quot;Gram matrix must be precomputed and cached in Matern1ARDKernel.&quot;);
+    
+    KD &lt;&lt; gram_matrix;
+    KD *= sigmoid(m_isp_signal_sigma)/softplus(m_isp_signal_sigma);
+}
+
+
+//#####  computeGramMatrixDerivIspInputSigma  #################################
+
+void Matern1ARDKernel::computeGramMatrixDerivIspInputSigma(Mat&amp; KD,
+                                                           int arg) const
+{
+    // Precompute some terms
+    real input_sigma_arg = m_input_sigma[arg];
+    real input_sigma_sq  = input_sigma_arg * input_sigma_arg;
+    real input_sigmoid   = sigmoid(m_isp_global_sigma + m_isp_input_sigma[arg]);
+    
+    // Compute Gram Matrix derivative w.r.t. isp_input_sigma[arg]
+    int  l = data-&gt;length();
+    PLASSERT_MSG(
+        gram_matrix.width() == l &amp;&amp; gram_matrix.length() == l,
+        &quot;To compute the derivative with respect to 'isp_input_sigma[i]', the\n&quot;
+        &quot;Gram matrix must be precomputed and cached in Matern1ARDKernel.&quot;);
+
+    // Variables that walk over the data matrix
+    int  cache_mod = m_data_cache.mod();
+    real *data_start = &amp;m_data_cache(0,0);
+    real *xi = data_start+arg;               // Iterator on data rows
+
+    // Variables that walk over the gram cache
+    int   gram_cache_mod = gram_matrix.mod();
+    real *gram_cache_row = gram_matrix.data();
+    real *gram_cache_cur;
+    
+    // Variables that walk over the kernel derivative matrix (KD)
+    KD.resize(l,l);
+    real* KDi = KD.data();                   // Start of row i
+    real* KDij;                              // Current element on row i
+    int   KD_mod = KD.mod();
+
+    // Iterate on rows of derivative matrix
+    for (int i=0 ; i&lt;l ; ++i, xi += cache_mod, KDi += KD_mod,
+             gram_cache_row += gram_cache_mod)
+    {
+        KDij = KDi;
+        real *xj  = data_start+arg;           // Inner iterator on data rows
+        gram_cache_cur = gram_cache_row;
+
+        // Iterate on columns of derivative matrix
+        for (int j=0 ; j &lt;= i
+                 ; ++j, xj += cache_mod, ++gram_cache_cur)
+        {
+            real diff    = *xi - *xj;
+            real sq_diff = diff * diff;
+            real KD_cur  = 0.5 * *gram_cache_cur *
+                           input_sigmoid * sq_diff / input_sigma_sq;
+
+            // Set into derivative matrix
+            *KDij++ = KD_cur;
+        }
+    }
+}
+
+
+//#####  makeDeepCopyFromShallowCopy  #########################################
+
+void Matern1ARDKernel::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/ker/Matern1ARDKernel.h
===================================================================
--- trunk/plearn/ker/Matern1ARDKernel.h	2009-04-04 20:33:18 UTC (rev 10083)
+++ trunk/plearn/ker/Matern1ARDKernel.h	2009-04-04 20:34:02 UTC (rev 10084)
@@ -0,0 +1,158 @@
+// -*- C++ -*-
+
+// Matern1ARDKernel.h
+//
+// Copyright (C) 2009 Nicolas Chapados
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Nicolas Chapados
+
+/*! \file Matern1ARDKernel.h */
+
+
+#ifndef MATERN1ARDKERNEL_INC
+#define MATERN1ARDKERNEL_INC
+
+#include &lt;plearn/ker/ARDBaseKernel.h&gt;
+
+namespace PLearn {
+
+/**
+ *  Matern kernel with nu=1/2 that can be used for Automatic Relevance
+ *  Determination.
+ *
+ *  With nu=1/2, the Matern kernel corresponds to the Ornstein-Uhlenbeck
+ *  process.  This function is specified as:
+ *
+ *    k(x,y) = (sf / (2*a)) * exp(-a sum_i |x_i - y_i|/w_i) * k_kron(x,y)
+ *
+ *  where sf = softplus(isp_signal_sigma), a = softplus(isp_persistence), w_i =
+ *  softplus(isp_global_sigma + isp_input_sigma[i]), and k_kron(x,y) is the
+ *  result of the KroneckerBaseKernel evaluation, or 1.0 if there are no
+ *  Kronecker terms.  Note that since the Kronecker terms are incorporated
+ *  multiplicatively, the very presence of the term associated to this kernel
+ *  can be gated by the value of some input variable(s) (that are incorporated
+ *  within one or more Kronecker terms).
+ *
+ *  Note that to make its operations more robust when used with unconstrained
+ *  optimization of hyperparameters, all hyperparameters of this kernel are
+ *  specified in the inverse softplus domain.  See IIDNoiseKernel for more
+ *  explanations.
+ */
+class Matern1ARDKernel : public ARDBaseKernel
+{
+    typedef ARDBaseKernel inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    /// Inverse softplus of the O-U persistence parameter.  Default value =
+    /// isp(1.0).
+    mutable real m_isp_persistence;
+    
+public:
+    //#####  Public Member Functions  #########################################
+
+    /// Default constructor
+    Matern1ARDKernel();
+
+
+    //#####  Kernel Member Functions  #########################################
+
+    /// Compute K(x1,x2).
+    virtual real evaluate(const Vec&amp; x1, const Vec&amp; x2) const;
+
+    /// Compute the Gram Matrix.
+    virtual void computeGramMatrix(Mat K) const;
+    
+    /// Directly compute the derivative with respect to hyperparameters
+    /// (Faster than finite differences...)
+    virtual void computeGramMatrixDerivative(Mat&amp; KD, const string&amp; kernel_param,
+                                             real epsilon=1e-6) const;
+    
+    /// Fill k_xi_x with K(x_i, x), for all i from istart to istart + k_xi_x.length() - 1.
+    virtual void evaluate_all_i_x(const Vec&amp; x, const Vec&amp; k_xi_x,
+                                  real squared_norm_of_x=-1, int istart = 0) const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    PLEARN_DECLARE_OBJECT(Matern1ARDKernel);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    /// Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    /// Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+    /// Derivative function with respect to isp_signal_sigma
+    real derivIspSignalSigma(int i, int j, int arg, real K) const;
+
+    /// Derivative function with respect to isp_global_sigma
+    real derivIspGlobalSigma(int i, int j, int arg, real K) const;
+    
+    /// Compute derivative w.r.t. isp_persistence
+    void derivIspPersistence(int i, int j, int arg, real K) const;
+    
+    /// Compute derivative w.r.t. isp_signal_sigma for WHOLE MATRIX
+    void computeGramMatrixDerivIspSignalSigma(Mat&amp; KD) const;
+    
+    /// Compute derivative w.r.t. isp_input_sigma[arg] for WHOLE MATRIX
+    void computeGramMatrixDerivIspInputSigma(Mat&amp; KD, int arg) const;
+
+private:
+    /// This does the actual building.
+    void build_();
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(Matern1ARDKernel);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003523.html">[Plearn-commits] r10083 - trunk/plearn/ker
</A></li>
	<LI>Next message: <A HREF="003525.html">[Plearn-commits] r10085 - trunk/plearn_learners/regressors
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3524">[ date ]</a>
              <a href="thread.html#3524">[ thread ]</a>
              <a href="subject.html#3524">[ subject ]</a>
              <a href="author.html#3524">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
