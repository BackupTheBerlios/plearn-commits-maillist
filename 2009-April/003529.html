<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r10089 - trunk/plearn_learners/regressors
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2009-April/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10089%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200904061827.n36IRCAL029020%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003528.html">
   <LINK REL="Next"  HREF="003530.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r10089 - trunk/plearn_learners/regressors</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10089%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200904061827.n36IRCAL029020%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r10089 - trunk/plearn_learners/regressors">nouiz at mail.berlios.de
       </A><BR>
    <I>Mon Apr  6 20:27:12 CEST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="003528.html">[Plearn-commits] r10088 - trunk/plearn/python
</A></li>
        <LI>Next message: <A HREF="003530.html">[Plearn-commits] r10090 - trunk
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3529">[ date ]</a>
              <a href="thread.html#3529">[ thread ]</a>
              <a href="subject.html#3529">[ subject ]</a>
              <a href="author.html#3529">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2009-04-06 20:27:09 +0200 (Mon, 06 Apr 2009)
New Revision: 10089

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.h
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.h
Log:
new optimisation with their is no missing value in the trainset for the regression tree. We make only one pass on the dataset. Need to be make more general


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.h	2009-04-06 15:27:42 UTC (rev 10088)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.h	2009-04-06 18:27:09 UTC (rev 10089)
@@ -50,7 +50,8 @@
 class RegressionTreeLeave: public Object
 {
     typedef Object inherited;
- 
+    friend class RegressionTreeNode;
+    friend class RegressionTreeRegisters;
     static Vec dummy_vec;
 
 public:

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2009-04-06 15:27:42 UTC (rev 10088)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2009-04-06 18:27:09 UTC (rev 10089)
@@ -255,6 +255,7 @@
     Vec right_error(3);
     Vec missing_error(3);
     missing_error.clear();
+    bool one_pass_on_data=!RTR_HAVE_MISSING &amp;&amp; leave-&gt;classname()==&quot;RegressionTreeLeave&quot;;
     PP&lt;RegressionTreeRegisters&gt; train_set = tree-&gt;getSortedTrainingSet();
 
     int inputsize = train_set-&gt;inputsize();
@@ -267,7 +268,13 @@
     row_split_balance.clear();
 #endif
     int leave_id = leave-&gt;getId();
-   
+    
+    int l_length = 0;
+    real l_weights_sum = 0;
+    real l_targets_sum = 0;
+    real l_weighted_targets_sum = 0;
+    real l_weighted_squared_targets_sum = 0;
+
     for (int col = 0; col &lt; inputsize; col++)
     {
         missing_leave-&gt;initStats();
@@ -276,6 +283,7 @@
         
         PLASSERT(registered_row.size()==leave-&gt;length());
         PLASSERT(candidate.size()==0);
+        tuple&lt;real,real,int&gt; ret;
 #ifdef NPREFETCH
         //The ifdef is in case we don't want to use the optimized version with
         //prefetch of memory. Maybe the optimization is hurtfull for some computer.
@@ -320,24 +328,56 @@
             }
         }
 
+        missing_leave-&gt;getOutputAndError(tmp_vec, missing_error);
+        ret=bestSplitInRow(col, candidate, left_error,
+                           right_error, missing_error,
+                           right_leave, left_leave,
+                           train_set, registered_value,
+                           registered_target_weight);
+
 #else
-        train_set-&gt;getAllRegisteredRowLeave(leave_id, col, registered_row,
-                                            registered_target_weight,
-                                            registered_value,
-                                            missing_leave,
-                                            left_leave,
-                                            right_leave, candidate);
+        if(!one_pass_on_data){
+            train_set-&gt;getAllRegisteredRowLeave(leave_id, col, registered_row,
+                                                registered_target_weight,
+                                                registered_value,
+                                                missing_leave,
+                                                left_leave,
+                                                right_leave, candidate);
+            PLASSERT(candidate.size()&gt;0);
+            missing_leave-&gt;getOutputAndError(tmp_vec, missing_error);
+            ret=bestSplitInRow(col, candidate, left_error,
+                               right_error, missing_error,
+                               right_leave, left_leave,
+                               train_set, registered_value,
+                               registered_target_weight);
+        }else{
+            ret=train_set-&gt;bestSplitInRow(leave_id, col, registered_row,
+                                          missing_leave,
+                                          left_leave,
+                                          right_leave, left_error,
+                                          right_error, missing_error);
+        }
         PLASSERT(registered_row.size()==leave-&gt;length());
-        PLASSERT(candidate.size()&gt;0);
-
 #endif
 
-        missing_leave-&gt;getOutputAndError(tmp_vec, missing_error);
-        tuple&lt;real,real,int&gt; ret=bestSplitInRow(col, candidate, left_error,
-                                                right_error, missing_error,
-                                                right_leave, left_leave,
-                                                train_set, registered_value,
-                                                registered_target_weight);
+        if(col==0){
+            l_length=left_leave-&gt;length()+right_leave-&gt;length();
+            l_weights_sum=left_leave-&gt;weights_sum+right_leave-&gt;weights_sum;
+            l_targets_sum=left_leave-&gt;targets_sum+right_leave-&gt;targets_sum;
+            l_weighted_targets_sum=left_leave-&gt;weighted_targets_sum+right_leave-&gt;weighted_targets_sum;
+            l_weighted_squared_targets_sum=left_leave-&gt;weighted_squared_targets_sum+right_leave-&gt;weighted_squared_targets_sum;
+        }else if(!one_pass_on_data){
+            PLCHECK(l_length==left_leave-&gt;length()+right_leave-&gt;length());
+            PLCHECK(fast_is_equal(l_weights_sum,
+                                  left_leave-&gt;weights_sum+right_leave-&gt;weights_sum));
+            PLCHECK(fast_is_equal(l_targets_sum,
+                                  left_leave-&gt;targets_sum+right_leave-&gt;targets_sum));
+            PLCHECK(fast_is_equal(l_weighted_targets_sum,
+                                  left_leave-&gt;weighted_targets_sum+right_leave-&gt;weighted_targets_sum));
+            PLCHECK(fast_is_equal(l_weighted_squared_targets_sum,
+                                  left_leave-&gt;weighted_squared_targets_sum+right_leave-&gt;weighted_squared_targets_sum));
+        }
+
 #ifdef RCMP
         row_split_err[col] = get&lt;0&gt;(ret);
         row_split_value[col] = get&lt;1&gt;(ret);

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2009-04-06 15:27:42 UTC (rev 10088)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2009-04-06 18:27:09 UTC (rev 10089)
@@ -415,6 +415,165 @@
 
 }
 
+tuple&lt;real,real,int&gt; RegressionTreeRegisters::bestSplitInRow(
+    RTR_type_id leave_id, int col, TVec&lt;RTR_type&gt; &amp;reg,
+    PP&lt;RegressionTreeLeave&gt; missing_leave,
+    PP&lt;RegressionTreeLeave&gt; left_leave,
+    PP&lt;RegressionTreeLeave&gt; right_leave,
+    Vec left_error, Vec right_error,
+    Vec missing_error) const
+{
+//    fill reg, t_w et value and candidate
+    PLCHECK(missing_leave-&gt;classname()==&quot;RegressionTreeLeave&quot;);
+    PLCHECK(RTR_HAVE_MISSING==false);//need to modif the code to make it work with missing value.
+
+    PLASSERT(tsource_mat.length()==tsource.length());
+    getAllRegisteredRow(leave_id,col,reg);
+    real * p = tsource_mat[col];
+    pair&lt;RTR_target_t,RTR_weight_t&gt;* ptw = target_weight.data();
+    RTR_type * preg = reg.data();
+
+    int row_idx_end = reg.size() - 1;
+    int prev_row=preg[row_idx_end];
+    real prev_val=p[prev_row];
+    PLASSERT(reg.size()&gt;row_idx_end &amp;&amp; row_idx_end&gt;=0);
+    PLASSERT(p[prev_row]==tsource(col,prev_row));
+    //fill right_leave
+    for( ;row_idx_end&gt;0;row_idx_end--)
+    {
+        int futur_row = preg[row_idx_end-8];
+        __builtin_prefetch(&amp;ptw[futur_row],1,2);
+        __builtin_prefetch(&amp;p[futur_row],1,2);
+
+        int row=prev_row;
+        real val=prev_val;
+        prev_row = preg[row_idx_end-1];
+        prev_val = p[prev_row];
+
+        PLASSERT(reg.size()&gt;row_idx_end &amp;&amp; row_idx_end&gt;0);
+        PLASSERT(target_weight.size()&gt;row &amp;&amp; row&gt;=0);
+        PLASSERT(p[row]==tsource(col,row));
+        RTR_target_t target = ptw[row].first;
+        RTR_weight_t weight = ptw[row].second;
+
+        if (RTR_HAVE_MISSING &amp;&amp; is_missing(val))
+            missing_leave-&gt;addRow(row, target, weight);
+        else if(val==prev_val)
+            right_leave-&gt;addRow(row, target, weight);
+        else
+            break;
+    }
+
+    if(col==0){//do 2 pass finding of the best split.
+        //fill left_leave
+        for(int row_idx = 0;row_idx&lt;=row_idx_end;row_idx++)
+        {
+            int futur_row = preg[row_idx+8];
+            __builtin_prefetch(&amp;ptw[futur_row],1,2);
+            __builtin_prefetch(&amp;p[futur_row],1,2);
+            
+            PLASSERT(reg.size()&gt;row_idx &amp;&amp; row_idx&gt;=0);
+            int row=int(preg[row_idx]);
+            real val=p[row];
+            PLASSERT(target_weight.size()&gt;row &amp;&amp; row&gt;=0);
+            PLASSERT(p[row]==tsource(col,row));
+            
+            RTR_target_t target = ptw[row].first;
+            RTR_weight_t weight = ptw[row].second;
+            if (RTR_HAVE_MISSING &amp;&amp; is_missing(val)){
+                missing_leave-&gt;addRow(row, target, weight);
+            }else {
+                left_leave-&gt;addRow(row, target, weight);
+            }
+        }
+
+        l_length=left_leave-&gt;length()+right_leave-&gt;length();
+        l_weights_sum=left_leave-&gt;weights_sum+right_leave-&gt;weights_sum;
+        l_targets_sum=left_leave-&gt;targets_sum+right_leave-&gt;targets_sum;
+        l_weighted_targets_sum=left_leave-&gt;weighted_targets_sum+right_leave-&gt;weighted_targets_sum;
+        l_weighted_squared_targets_sum=left_leave-&gt;weighted_squared_targets_sum+right_leave-&gt;weighted_squared_targets_sum;
+    }else{//do 1 pass finding of the best split.
+
+        //fill left_leave
+        left_leave-&gt;length_=l_length-right_leave-&gt;length();
+        left_leave-&gt;weights_sum=l_weights_sum-right_leave-&gt;weights_sum;
+        left_leave-&gt;targets_sum=l_targets_sum-right_leave-&gt;targets_sum;
+        left_leave-&gt;weighted_targets_sum=l_weighted_targets_sum-right_leave-&gt;weighted_targets_sum;
+        left_leave-&gt;weighted_squared_targets_sum=l_weighted_squared_targets_sum-right_leave-&gt;weighted_squared_targets_sum;
+        PLCHECK(l_length==left_leave-&gt;length()+right_leave-&gt;length());
+        PLCHECK(fast_is_equal(l_weights_sum,left_leave-&gt;weights_sum+right_leave-&gt;weights_sum));
+        PLCHECK(fast_is_equal(l_targets_sum,left_leave-&gt;targets_sum+right_leave-&gt;targets_sum));
+        PLCHECK(fast_is_equal(l_weighted_targets_sum,left_leave-&gt;weighted_targets_sum+right_leave-&gt;weighted_targets_sum));
+        PLCHECK(fast_is_equal(l_weighted_squared_targets_sum,left_leave-&gt;weighted_squared_targets_sum+right_leave-&gt;weighted_squared_targets_sum));
+    }
+
+    //find best_split
+    int best_balance=INT_MAX;
+    real best_feature_value = REAL_MAX;
+    real best_split_error = REAL_MAX;
+    //in case of only missing value
+    if(left_leave-&gt;length()==0)
+        return make_tuple(best_feature_value, best_split_error, best_balance);
+
+
+    real missing_errors = missing_error[0] + missing_error[1];
+
+    Vec tmp(3);
+    int iter=reg.size()-right_leave-&gt;length()-1;
+    RTR_type row=reg[iter];
+//    RTR_type next_row = reg[reg.size()-2-right_leave-&gt;length()];
+    real first_value=p[preg[0]];
+    real next_feature=p[row];
+
+
+    //next_feature!=first_value is to check if their is more split point
+    // in case of binary variable or variable with few different value,
+    // this give a great speed up.
+    for(int i=iter-1;i&gt;=0&amp;&amp;next_feature!=first_value;i--)
+    {
+        RTR_type next_row = preg[i];
+        real row_feature=next_feature;
+        next_feature=p[next_row];
+        
+        PLASSERT(next_row!=row);
+
+        PLASSERT((i+1)&lt;reg.size() || row==reg[i+1]);
+        PLASSERT(next_row==reg[i]);
+        PLASSERT(get(next_row, col)==next_feature);
+        PLASSERT(get(row, col)==row_feature);
+        PLASSERT(next_feature&lt;=row_feature);
+
+        int futur_row = preg[i+9];
+        __builtin_prefetch(&amp;ptw[futur_row],1,2);
+        __builtin_prefetch(&amp;p[futur_row],1,2);
+
+
+        real target=ptw[row].first;
+        real weight=ptw[row].second;
+
+        left_leave-&gt;removeRow(row, target, weight);
+        right_leave-&gt;addRow(row, target, weight);
+
+        row = next_row;
+        if (next_feature &lt; row_feature){
+            left_leave-&gt;getOutputAndError(tmp, left_error);
+            right_leave-&gt;getOutputAndError(tmp, right_error);
+        }else
+            continue;
+        real work_error = missing_errors + left_error[0]
+            + left_error[1] + right_error[0] + right_error[1];
+        int work_balance = abs(left_leave-&gt;length() -
+                               right_leave-&gt;length());
+        if (fast_is_more(work_error,best_split_error)) continue;
+        else if (fast_is_equal(work_error,best_split_error) &amp;&amp;
+                 fast_is_more(work_balance,best_balance)) continue;
+
+        best_feature_value = 0.5 * (row_feature + next_feature);
+        best_split_error = work_error;
+        best_balance = work_balance;
+    }
+    return make_tuple(best_split_error, best_feature_value, best_balance);
+}
 void RegressionTreeRegisters::sortRows()
 {
     next_id = 0;

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2009-04-06 15:27:42 UTC (rev 10088)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2009-04-06 18:27:09 UTC (rev 10089)
@@ -109,6 +109,12 @@
     mutable vector&lt;bool&gt; compact_reg;
     mutable int compact_reg_leave;
 
+    mutable int l_length;
+    mutable real l_weights_sum;
+    mutable real l_targets_sum;
+    mutable real l_weighted_targets_sum;
+    mutable real l_weighted_squared_targets_sum;
+
 public:
 
     RegressionTreeRegisters();
@@ -149,13 +155,20 @@
     void         getAllRegisteredRow(RTR_type_id leave_id, int col, TVec&lt;RTR_type&gt; &amp;reg)const;
     void         getAllRegisteredRow(RTR_type_id leave_id, int col, TVec&lt;RTR_type&gt; &amp;reg,
                                      TVec&lt;pair&lt;RTR_target_t,RTR_weight_t&gt; &gt; &amp;t_w, Vec &amp;value)const;
-    void         getAllRegisteredRowLeave(
+   void          getAllRegisteredRowLeave(
         RTR_type_id leave_id, int col, TVec&lt;RTR_type&gt; &amp;reg,
         TVec&lt;pair&lt;RTR_target_t,RTR_weight_t&gt; &gt; &amp;t_w, Vec &amp;value,
         PP&lt;RegressionTreeLeave&gt; missing_leave,
         PP&lt;RegressionTreeLeave&gt; left_leave,
         PP&lt;RegressionTreeLeave&gt; right_leave,
         TVec&lt;RTR_type&gt; &amp;candidate)const;
+    tuple&lt;real,real,int&gt; bestSplitInRow(
+        RTR_type_id leave_id, int col, TVec&lt;RTR_type&gt; &amp;reg,
+        PP&lt;RegressionTreeLeave&gt; missing_leave,
+        PP&lt;RegressionTreeLeave&gt; left_leave,
+        PP&lt;RegressionTreeLeave&gt; right_leave,
+        Vec left_error, Vec right_error,
+        Vec missing_error)const;
     void         printRegisters();
     void         getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight);
     inline virtual void put(int i, int j, real value)


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003528.html">[Plearn-commits] r10088 - trunk/plearn/python
</A></li>
	<LI>Next message: <A HREF="003530.html">[Plearn-commits] r10090 - trunk
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3529">[ date ]</a>
              <a href="thread.html#3529">[ thread ]</a>
              <a href="subject.html#3529">[ subject ]</a>
              <a href="author.html#3529">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
