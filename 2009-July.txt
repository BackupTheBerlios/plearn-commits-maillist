From nouiz at mail.berlios.de  Mon Jul  6 19:05:24 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 6 Jul 2009 19:05:24 +0200
Subject: [Plearn-commits] r10258 - trunk/scripts
Message-ID: <200907061705.n66H5Obt012803@sheep.berlios.de>

Author: nouiz
Date: 2009-07-06 19:05:16 +0200 (Mon, 06 Jul 2009)
New Revision: 10258

Modified:
   trunk/scripts/dbidispatch
Log:
added the --fast option for condor.


Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2009-06-29 13:33:10 UTC (rev 10257)
+++ trunk/scripts/dbidispatch	2009-07-06 17:05:16 UTC (rev 10258)
@@ -36,6 +36,7 @@
                               [--[*no_]keep_failed_jobs_in_queue]
                               [--max_file_size=N][--[no_]debug]
                               [--[no_]local_log_file][--next_job_start_delay=N]
+                              [--fast]
 
 An * after '[', '{' or ',' signals the default value.
 An + tell that we can put one or more separeted by a comma
@@ -212,6 +213,9 @@
       local disk. This help to solv a bug with condor and lock on NFS directory.
   The '--next_job_start_delay=N' option allow to tell condor to wait N second
       between each job we start. Default 0.
+  The '--fast' option tell condor to send the jobs only on fast computer. This 
+      add some hardcoded(maggie, brams and zappa) computers to the list 
+      generated by --machine=...
 
 where <command-template> is interpreted as follows: the first argument
 is the <command> above, and the rest are interpreted as <arguments>.
@@ -254,9 +258,14 @@
 
 """%{'ShortHelp':ShortHelp,'ScriptName':ScriptName}
 
+#the computer to use with the --fast option.
+fast_computer=["maggie"+str(x) for x in [11,12,13,14,15,16,21,22,23,24,25,26,31,32,33,34,35,36,41,42,43,44,45,46]]
+fast_computer+=["brams0"+str(x) for x in [0,1,2,3,4,5,6,7,'a','b','c','d','e','f']]
+fast_computer+=["zappa"+str(x) for x in range(1,9)]
+MAX_FILE_NAME_SIZE=255
+
 dbi_param={}
 testmode=False
-MAX_FILE_NAME_SIZE=255
 PATH=os.getenv('PATH')
 if search_file('condor_submit',PATH):
     launch_cmd = 'Condor'
@@ -305,13 +314,14 @@
                    "--getenv", "--cwait", "--clean_up" ,"--nice",
                    "--set_special_env", "--abs_path", "--pkdilly", "--to_all",
                    "--m32G", "--keep_failed_jobs_in_queue", "--restart",
-                   "--debug", "--local_log_file", "--exec_in_exp_dir"]:
+                   "--debug", "--local_log_file", "--exec_in_exp_dir", "--fast"]:
         dbi_param[argv[2:]]=True
     elif argv in ["--no_force", "--no_interruptible", "--no_long",
                   "--no_getenv", "--no_cwait", "--no_clean_up" , "--no_nice",
                   "--no_set_special_env", "--no_abs_path", "--no_pkdilly",
                   "--no_m32G", "--no_keep_failed_jobs_in_queue", "--no_restart",
-                  "--no_debug", "--no_local_log_file", "--no_exec_in_exp_dir"]:
+                  "--no_debug", "--no_local_log_file", "--no_exec_in_exp_dir",
+                  "--no_fast"]:
         dbi_param[argv[5:]]=False
     elif argv=="--testdbi":
         dbi_param["test"]=True
@@ -500,6 +510,8 @@
 elif dbi_param.get("restart",False):
     assert launch_cmd=="Condor"
     cmds=[]
+#    p1_=Popen('condor_q -l -const "JobStatus!=4" '+args(command_argv, shell=True, stdout=PIPE)
+#TODO put condor_history outside the loop as this take much time the we have a not too small history.
     for arg in command_argv:
         #We accept to start jobs in the queue if they are completed
         p1=Popen('condor_q -l -const "JobStatus!=4" '+arg, shell=True, stdout=PIPE)
@@ -542,6 +554,12 @@
     dbi_param["next_job_start_delay"]=1
     
 
+if dbi_param.get("fast",False):
+    dbi_param.setdefault("machine",[])
+    for m in fast_computer:
+        dbi_param["machine"]+=[m+".iro.umontreal.ca"]
+    del dbi_param["fast"]
+
 #we duplicate the command so that everything else work correctly.
 if dbi_param.has_key("to_all"):
     assert(len(commands)==1)



From nouiz at mail.berlios.de  Tue Jul  7 17:19:55 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 7 Jul 2009 17:19:55 +0200
Subject: [Plearn-commits] r10259 - trunk/speedtest
Message-ID: <200907071519.n67FJt43022436@sheep.berlios.de>

Author: nouiz
Date: 2009-07-07 17:19:53 +0200 (Tue, 07 Jul 2009)
New Revision: 10259

Modified:
   trunk/speedtest/Makefile
   trunk/speedtest/xgemm.c
Log:
don't use cblas anymore, but the same blas interface as plearn.


Modified: trunk/speedtest/Makefile
===================================================================
--- trunk/speedtest/Makefile	2009-07-06 17:05:16 UTC (rev 10258)
+++ trunk/speedtest/Makefile	2009-07-07 15:19:53 UTC (rev 10259)
@@ -3,7 +3,8 @@
 LIBCBLAS=~bastienf/.NOBACKUP/CBLAS/lib/${OSARCH}/libcblas.a
 
 LIBBLAS=-lblas ${LIBCBLAS}
-LIBGOTO=-lgoto -lgfortran ${LIBCBLAS}
+#LIBGOTO=-lgoto -lgfortran ${LIBCBLAS}
+LIBGOTO=-lgoto -lgfortran -I~/PLearn
 LIBATLAS=-lcblas -lf77blas -latlas -lg2c
 LIBMKL=-lmkl -lvml ${LIBCBLAS}
 LIBMKLPT=-lmkl -lvml -lguide -lpthread ${LIBCBLAS}
@@ -12,7 +13,8 @@
 ACMLBASE=/u/lisa/local/acml-3-6-0/gfortran32
 LIBACML= ${LIBCBLAS} ${ACMLBASE}/lib/libacml.a -lgfortran
 LIBACMLPT= ${LIBCBLAS} ${ACMLBASE}_mp/lib/libacml_mp.a -lg2c -lgfortran
-LIBNVIDIA=-L/u/bastienf/NVIDIA_CUDA_SDK/cuda/lib -L/u/bastienf/NVIDIA_CUDA_SDK/lib/ -I/u/bastienf/NVIDIA_CUDA_SDK/cuda/include/ -lcuda -lcudart -lGL -lGLU -lcublas -l cutil
+LIBNVIDIA=-L/u/bastienf/NVIDIA_CUDA_SDK/cuda/lib -L/u/bastienf/NVIDIA_CUDA_SDK/lib/ -I/u/bastienf/NVIDIA_CUDA_SDK/cuda/include/ -lcuda -lcudart -lGL -lGLU -lcublas 
+#-l cutil
 
 all: xgemm
 
@@ -85,6 +87,12 @@
 xgemm-sgemm-nvidia-compare: xgemm.c
 	${CC} ${CFLAGS} -m32 -o $@ -DUSEFLOAT $< ${LIBNVIDIA} -DNVIDIA -DCOMPARE
 
+xgemm-sgemm-nvidia-64: xgemm.c
+	${CC} ${CFLAGS} -m64 -o $@ -DUSEFLOAT $<  ${LIBNVIDIA} -DNVIDIA
+
+xgemm-sgemm-nvidia-compare-64: xgemm.c
+	${CC} ${CFLAGS} -m64 -o $@ -DUSEFLOAT $< ${LIBNVIDIA} -DNVIDIA -DCOMPARE
+
 xgemv: xgemv-blas xgemv-blas-compare xgemv-cxgemm xgemv-goto xgemv-goto-compare xgemv-nvidia xgemv-nvidia-compare xgemv-sgemv-goto xgemv-dgemv-goto xgemv-sgemv-blas xgemv-dgemv-blas
 	true
 

Modified: trunk/speedtest/xgemm.c
===================================================================
--- trunk/speedtest/xgemm.c	2009-07-06 17:05:16 UTC (rev 10258)
+++ trunk/speedtest/xgemm.c	2009-07-07 15:19:53 UTC (rev 10259)
@@ -9,15 +9,16 @@
   /* Includes, cuda */
   #include <cublas.h>
 #else
-  /* Includes, cblas */
-  #include <gsl/gsl_cblas.h>
+#include <plearn/math/blas_proto.h>
 #endif
 #ifdef USEDOUBLE
-  typedef double real;
-  #define cblas_xgemm cblas_dgemm
+//  typedef double real;
+#define real double
+  #define xgemm_ dgemm_
 #elif USEFLOAT
-  typedef float real;
-  #define cblas_xgemm cblas_sgemm
+//  typedef float real;
+#define real float
+  #define xgemm_ sgemm_
 #else
   #error "USEDOUBLE or USEFLOAT must be defined"
 #endif
@@ -34,7 +35,7 @@
   int k;
   for (i = 0; i < M; ++i) {
     for (j = 0; j < N; ++j) {
-      float prod = 0;
+      real prod = 0;
       for (k = 0; k < K; ++k) {
 	prod += A[i * K + k] * B[k * N + j];
       }
@@ -146,7 +147,7 @@
       c_xgemm(M,N,K, alpha, h_A, h_B, beta, h_C);
     h_C_ref = h_C;
     /* Allocate host memory for reading back the result from device memory */
-    h_C = (float*)malloc(NC * sizeof(h_C[0]));
+    h_C = (real*)malloc(NC * sizeof(h_C[0]));
     if (h_C == 0) {
         fprintf (stderr, "!!!! host memory allocation error (C)\n");
         return EXIT_FAILURE;
@@ -174,8 +175,10 @@
     for (int i=0;i<NBITER;i++)
       c_xgemm(M,N,K, alpha, h_A, h_B, beta, h_C);
 #else
+    char transa='N', transb='N';
     for (int i=0;i<NBITER;i++)
-      cblas_xgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, M,N,K, alpha, h_A, K, h_B, N, beta, h_C, N);
+      sgemm_(&transb, &transa, &N, &M, &K, &alpha, h_B, &N, h_A, &K, &beta, h_C, &N);
+
 #endif
 #ifdef COMPARE
     /* Check result against reference */



From nouiz at mail.berlios.de  Wed Jul  8 20:40:07 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 8 Jul 2009 20:40:07 +0200
Subject: [Plearn-commits] r10260 - in trunk: commands/PLearnCommands
	plearn/misc plearn/vmat
Message-ID: <200907081840.n68Ie7Yp006763@sheep.berlios.de>

Author: nouiz
Date: 2009-07-08 20:40:05 +0200 (Wed, 08 Jul 2009)
New Revision: 10260

Modified:
   trunk/commands/PLearnCommands/VMatCommand.cc
   trunk/plearn/misc/vmatmain.cc
   trunk/plearn/vmat/FileVMatrix.cc
   trunk/plearn/vmat/FileVMatrix.h
   trunk/plearn/vmat/VMatrix.cc
   trunk/plearn/vmat/VMatrix.h
Log:
added pl vmat src dst.pmat --force_float option to force the destination file to be in float format. This allow to save disk space but could loose precission depending of the src dataset.


Modified: trunk/commands/PLearnCommands/VMatCommand.cc
===================================================================
--- trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-07 15:19:53 UTC (rev 10259)
+++ trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-08 18:40:05 UTC (rev 10260)
@@ -71,7 +71,7 @@
         "       ( will work only if your executable includes commands/PLearnCommands/VMatViewCommand.h )\n"
         "   or: vmat stats <dataset> \n"
         "       Will display basic statistics for each field \n"
-        "   or: vmat convert <source> <destination> [--cols=col1,col2,col3,...] [--mat_to_mem] [--save_vmat]\n"
+        "   or: vmat convert <source> <destination> [--cols=col1,col2,col3,...] [--mat_to_mem] [--save_vmat] [--force_float]\n"
         "       To convert any dataset into a .amat, .pmat, .dmat, .vmat, .csv or .arff format. \n"
         "       The extension of the destination is used to determine the format you want. \n"
         "       If the option --cols is specified, it requests to keep only the given columns\n"
@@ -82,6 +82,7 @@
         "       If the option --save_vmat is specified, we save the source vmat in the destination metadatadir\n"
         "       If the option --update is specified, we generate the <destination> only when the <source> file is newer\n"
         "         then the destination file or when the destination file is missing\n"
+        "       If .pmat is specified as the destination file, the option --force_float will save the data in float format\n"
         "       If .csv (Comma-Separated Value) is specified as the destination file, the \n"
         "       following additional options are also supported:\n"
         "         --skip-missings: if a row (after selecting the appropriate columns) contains\n"

Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2009-07-07 15:19:53 UTC (rev 10259)
+++ trunk/plearn/misc/vmatmain.cc	2009-07-08 18:40:05 UTC (rev 10260)
@@ -657,7 +657,7 @@
     {
         if(argc<4)
             PLERROR("Usage: vmat convert <source> <destination> "
-                    "[--mat_to_mem] [--cols=col1,col2,col3,...] [--save_vmat] [--skip-missings] [--precision=N] [--delimiter=CHAR]");
+                    "[--mat_to_mem] [--cols=col1,col2,col3,...] [--save_vmat] [--skip-missings] [--precision=N] [--delimiter=CHAR] [--force_float]");
 
         string source = argv[2];
         string destination = argv[3];
@@ -689,6 +689,8 @@
          *     --update
          *           :: we generate the <destination> only when the <source> file is newer than
          *           :: the destination  file or when the destination file is missing
+         *     --force_float
+         *           :: if the destination is a pmat, we force the pmat file to be in float format
          */
         TVec<string> columns;
         TVec<string> date_columns;
@@ -698,6 +700,10 @@
         bool convert_date = false;
         bool save_vmat = false;
         bool update = false;
+        bool force_float = false;
+
+        string ext = extract_extension(destination);
+
         for (int i=4 ; i < argc && argv[i] ; ++i) {
             string curopt = removeblanks(argv[i]);
             if (curopt == "")
@@ -716,6 +722,7 @@
                 precision = toint(curopt.substr(12));
             }
             else if (curopt.substr(0,12) == "--delimiter=") {
+                PLCHECK(ext==".cvs");
                 delimiter = curopt.substr(12);
             }
             else if (curopt == "--convert-date")
@@ -726,7 +733,10 @@
                 save_vmat = true;
             else if (curopt == "--update")
                 update = true;
-            else
+            else if (curopt == "--force_float"){
+                PLCHECK(ext==".pmat");
+                force_float = true;
+            }else
                 PLWARNING("VMat convert: unrecognized option '%s'; ignoring it...",
                           curopt.c_str());
         }
@@ -738,7 +748,6 @@
         if (columns.size() > 0)
             vm = new SelectColumnsVMatrix(vm, columns);
 
-        string ext = extract_extension(destination);
         if (ext != ".csv" && skip_missings)
             PLWARNING("Option '--skip-missings' not supported for extension '%s'; ignoring it...",
                       ext.c_str());
@@ -750,7 +759,7 @@
             // Save strings as strings so they are not lost.
             vm->saveAMAT(destination, true, false, true);
         else if(ext==".pmat")
-            vm->savePMAT(destination);
+            vm->savePMAT(destination, force_float);
         else if(ext==".dmat")
             vm->saveDMAT(destination);
         else if(ext == ".csv")

Modified: trunk/plearn/vmat/FileVMatrix.cc
===================================================================
--- trunk/plearn/vmat/FileVMatrix.cc	2009-07-07 15:19:53 UTC (rev 10259)
+++ trunk/plearn/vmat/FileVMatrix.cc	2009-07-08 18:40:05 UTC (rev 10260)
@@ -77,10 +77,12 @@
     build_();
 }
 
-FileVMatrix::FileVMatrix(const PPath& filename, int the_length, int the_width):
+FileVMatrix::FileVMatrix(const PPath& filename, int the_length, int the_width,
+                         bool force_float):
     inherited       (the_length, the_width, true),
     filename_       (filename.absolute()),
     f               (0),
+    force_float     (force_float),
     build_new_file  (true)
 {
     remove_when_done = track_ref = -1;
@@ -175,6 +177,8 @@
 #ifdef BIGENDIAN
         file_is_bigendian = true;
 #endif
+        if(force_float)
+            file_is_float = true;
 
         updateHeader();
 
@@ -490,22 +494,18 @@
 //////////////////
 void FileVMatrix::updateHeader() {
     char header[DATAFILE_HEADERLENGTH];
-#ifdef USEFLOAT
+    string real = "DOUBLE";
+    if(file_is_float)
+        real = "FLOAT";
+
 #ifdef LITTLEENDIAN
-    sprintf(header,"MATRIX %d %d FLOAT LITTLE_ENDIAN", length_, width_);
+    sprintf(header,"MATRIX %d %d %s LITTLE_ENDIAN", length_, width_, real.c_str());
 #endif
 #ifdef BIGENDIAN
-    sprintf(header,"MATRIX %d %d FLOAT BIG_ENDIAN", length_, width_);
+    sprintf(header,"MATRIX %d %d %s BIG_ENDIAN", length_, width_, real.c_str());
 #endif
-#endif
-#ifdef USEDOUBLE
-#ifdef LITTLEENDIAN
-    sprintf(header,"MATRIX %d %d DOUBLE LITTLE_ENDIAN", length_, width_);
-#endif
-#ifdef BIGENDIAN
-    sprintf(header,"MATRIX %d %d DOUBLE BIG_ENDIAN", length_, width_);
-#endif
-#endif
+
+
     int pos = strlen(header);
     for(; pos<DATAFILE_HEADERLENGTH; pos++)
     {

Modified: trunk/plearn/vmat/FileVMatrix.h
===================================================================
--- trunk/plearn/vmat/FileVMatrix.h	2009-07-07 15:19:53 UTC (rev 10259)
+++ trunk/plearn/vmat/FileVMatrix.h	2009-07-08 18:40:05 UTC (rev 10260)
@@ -74,6 +74,7 @@
 #endif
     bool file_is_bigendian;
     bool file_is_float;
+    bool force_float;
 
 private:
 
@@ -85,7 +86,8 @@
 
     FileVMatrix();
     FileVMatrix(const PPath& filename, bool writable_=false); //!<  opens an existing file
-    FileVMatrix(const PPath& filename, int the_length, int the_width); //!<  create a new matrix file
+    FileVMatrix(const PPath& filename, int the_length, int the_width,
+                bool force_float=false); //!<  create a new matrix file
     FileVMatrix(const PPath& filename, int the_length, const TVec<string>& fieldnames); //!<  create a new matrix file
 
 protected:

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2009-07-07 15:19:53 UTC (rev 10259)
+++ trunk/plearn/vmat/VMatrix.cc	2009-07-08 18:40:05 UTC (rev 10260)
@@ -2019,7 +2019,7 @@
 //////////////
 // savePMAT //
 //////////////
-void VMatrix::savePMAT(const PPath& pmatfile) const
+void VMatrix::savePMAT(const PPath& pmatfile, const bool force_float) const
 {
     if (width() == -1)
         PLERROR("In VMat::save - Saving in a pmat file is only possible for constant width VMats (where width()!=-1)");
@@ -2028,7 +2028,7 @@
     PPath pmatfiletmp=pmatfile+".tmp";
 
     {        
-    FileVMatrix m(pmatfiletmp,nsamples,width());
+    FileVMatrix m(pmatfiletmp,nsamples,width(),force_float);
     m.setMetaInfoFrom(this);
     // m.setFieldInfos(getFieldInfos());
     // m.copySizesFrom(this);

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2009-07-07 15:19:53 UTC (rev 10259)
+++ trunk/plearn/vmat/VMatrix.h	2009-07-08 18:40:05 UTC (rev 10260)
@@ -323,7 +323,8 @@
     virtual void save(const PPath& filename) const;
 
     /// Save the VMatrix in PMat format
-    virtual void savePMAT(const PPath& pmatfile) const;
+    virtual void savePMAT(const PPath& pmatfile,
+                          const bool force_float=false) const;
 
     /// Save the VMatrix in DMat format
     virtual void saveDMAT(const PPath& dmatdir) const;



From nouiz at mail.berlios.de  Wed Jul  8 21:39:18 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 8 Jul 2009 21:39:18 +0200
Subject: [Plearn-commits] r10261 - trunk/plearn/vmat
Message-ID: <200907081939.n68JdIOE015665@sheep.berlios.de>

Author: nouiz
Date: 2009-07-08 21:39:17 +0200 (Wed, 08 Jul 2009)
New Revision: 10261

Modified:
   trunk/plearn/vmat/VMatrix.cc
   trunk/plearn/vmat/VMatrix.h
Log:
fix the last commit for the python interface.


Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2009-07-08 18:40:05 UTC (rev 10260)
+++ trunk/plearn/vmat/VMatrix.cc	2009-07-08 19:39:17 UTC (rev 10261)
@@ -298,11 +298,16 @@
          ArgDoc ("save_strings", "save string instead of real values")));
 
     declareMethod(
-        rmm, "savePMAT", &VMatrix::savePMAT,
+        rmm, "savePMAT", &VMatrix::remote_savePMAT,
         (BodyDoc("Saves this matrix as a .pmat file."),
          ArgDoc ("pmatfile", "Path of the file to create.")));
 
     declareMethod(
+        rmm, "savePMAT_float", &VMatrix::remote_savePMAT_float,
+        (BodyDoc("Saves this matrix as a .pmat file in float format."),
+         ArgDoc ("pmatfile", "Path of the file to create.")));
+
+    declareMethod(
         rmm, "saveDMAT", &VMatrix::saveDMAT,
         (BodyDoc("Saves this matrix as a .dmat directory."),
          ArgDoc ("dmatdir", "Path of the dir to create.")));

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2009-07-08 18:40:05 UTC (rev 10260)
+++ trunk/plearn/vmat/VMatrix.h	2009-07-08 19:39:17 UTC (rev 10261)
@@ -325,6 +325,8 @@
     /// Save the VMatrix in PMat format
     virtual void savePMAT(const PPath& pmatfile,
                           const bool force_float=false) const;
+    virtual void remote_savePMAT(const PPath& pmatfile) const{savePMAT(pmatfile,false);}
+    virtual void remote_savePMAT_float(const PPath& pmatfile) const{savePMAT(pmatfile,true);}
 
     /// Save the VMatrix in DMat format
     virtual void saveDMAT(const PPath& dmatdir) const;



From nouiz at mail.berlios.de  Thu Jul  9 16:38:14 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 9 Jul 2009 16:38:14 +0200
Subject: [Plearn-commits] r10262 - trunk/plearn/vmat
Message-ID: <200907091438.n69EcEoE000948@sheep.berlios.de>

Author: nouiz
Date: 2009-07-09 16:38:14 +0200 (Thu, 09 Jul 2009)
New Revision: 10262

Modified:
   trunk/plearn/vmat/FileVMatrix.cc
   trunk/plearn/vmat/FileVMatrix.h
   trunk/plearn/vmat/VMatrix.h
Log:
implemented default VMatrix::getSizeOnDisk() that return -1
implemented FileVMatrix::getSizeOnDisk()
new para call_build_ to constructor FileVMatrix(filename,length,width,force_float, call_build)


Modified: trunk/plearn/vmat/FileVMatrix.cc
===================================================================
--- trunk/plearn/vmat/FileVMatrix.cc	2009-07-08 19:39:17 UTC (rev 10261)
+++ trunk/plearn/vmat/FileVMatrix.cc	2009-07-09 14:38:14 UTC (rev 10262)
@@ -78,7 +78,7 @@
 }
 
 FileVMatrix::FileVMatrix(const PPath& filename, int the_length, int the_width,
-                         bool force_float):
+                         bool force_float, bool call_build_):
     inherited       (the_length, the_width, true),
     filename_       (filename.absolute()),
     f               (0),
@@ -87,7 +87,8 @@
 {
     remove_when_done = track_ref = -1;
     writable = true;
-    build_();
+    if(call_build_)
+        build_();
 }
 
 FileVMatrix::FileVMatrix(const PPath& filename, int the_length,
@@ -534,6 +535,11 @@
 #endif
 
 }
+
+
+int64_t FileVMatrix::getSizeOnDisk(){
+    return DATAFILE_HEADERLENGTH + width_*length_*(file_is_float ? 4 : 8);
+}
 } // end of namespace PLearn
 
 

Modified: trunk/plearn/vmat/FileVMatrix.h
===================================================================
--- trunk/plearn/vmat/FileVMatrix.h	2009-07-08 19:39:17 UTC (rev 10261)
+++ trunk/plearn/vmat/FileVMatrix.h	2009-07-09 14:38:14 UTC (rev 10262)
@@ -87,7 +87,7 @@
     FileVMatrix();
     FileVMatrix(const PPath& filename, bool writable_=false); //!<  opens an existing file
     FileVMatrix(const PPath& filename, int the_length, int the_width,
-                bool force_float=false); //!<  create a new matrix file
+                bool force_float=false, bool call_build_ = true); //!<  create a new matrix file
     FileVMatrix(const PPath& filename, int the_length, const TVec<string>& fieldnames); //!<  create a new matrix file
 
 protected:
@@ -122,6 +122,7 @@
     //! Destructor.
     virtual ~FileVMatrix();
 
+    virtual int64_t getSizeOnDisk();
 private:
 
     void build_();

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2009-07-08 19:39:17 UTC (rev 10261)
+++ trunk/plearn/vmat/VMatrix.h	2009-07-09 14:38:14 UTC (rev 10262)
@@ -890,6 +890,9 @@
     /// dataset)
     bool isSFIFDirect(int col, string ext);
     bool isSFIFDirect(string fieldname, string ext);
+
+    // return the size on the disk. If the sub class don't implement it return -1. 
+    virtual int64_t getSizeOnDisk(){return -1;}
 };
 
 DECLARE_OBJECT_PTR(VMatrix);



From nouiz at mail.berlios.de  Thu Jul  9 16:51:32 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 9 Jul 2009 16:51:32 +0200
Subject: [Plearn-commits] r10263 - in trunk: commands/PLearnCommands
	plearn/vmat
Message-ID: <200907091451.n69EpW1F002658@sheep.berlios.de>

Author: nouiz
Date: 2009-07-09 16:51:31 +0200 (Thu, 09 Jul 2009)
New Revision: 10263

Modified:
   trunk/commands/PLearnCommands/VMatCommand.cc
   trunk/plearn/vmat/FileVMatrix.cc
Log:
added plearn vmat pmat_float_save that return the size saved if we save the file in float format and the error generated.


Modified: trunk/commands/PLearnCommands/VMatCommand.cc
===================================================================
--- trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-09 14:38:14 UTC (rev 10262)
+++ trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-09 14:51:31 UTC (rev 10263)
@@ -42,6 +42,8 @@
 #include "VMatCommand.h"
 #include <plearn/db/getDataSet.h>
 #include <plearn/base/lexical_cast.h>
+#include <plearn/vmat/FileVMatrix.h>
+#include <plearn/base/plerror.h>
 
 namespace PLearn {
 using namespace std;
@@ -133,6 +135,8 @@
         "       Kolmogorov-Smirnov 2 samples statistic\n\n"
         "   or: vmat mtime <dataset>\n"
         "       Print the mtime of a dataset\n"
+        "   or: vmat pmat_float_save <dataset>...\n"
+        "       Print the number of byte saved if we transform the mat to pmat in float format and the maximum diff?rence and maximum relative diff?rence in value."
         "<dataset> is a parameter understandable by getDataSet: \n"
 
         + getDataSetHelp()
@@ -166,6 +170,40 @@
             new_args[i - 1] = args[i];
         PLearnCommandRegistry::run("vmat_view", new_args);
     }
+    else if (command == "pmat_float_save")
+    {
+#ifdef USEFLOAT
+        PLERROR("vmat pmat_float_save don't work correctly when compiled in float.");
+#endif
+        PLCHECK(args.size()>1);
+        for(int f=1;f<args.size();f++){
+            string dataspec = args[f];
+            VMat vm = getDataSet(dataspec);
+            int64_t orig_size = vm->getSizeOnDisk();
+
+            if(orig_size==-1)
+                cout<<"-1 -1 -1"<<endl;
+            else{
+                FileVMatrix n = FileVMatrix(dataspec+"dummy",vm.length(),vm.width(),true,false);
+                int64_t new_size = n.getSizeOnDisk();
+                Vec v(vm->width());
+                double max_diff=0;
+                double max_rel_diff=0;
+                for(int i=0;i<vm->length();i++){
+                    vm->getRow(i,v);
+                    for(int j=0;j<vm->width();j++){
+                        double diff = v[j]-float(v[j]);
+                        if(max_diff<diff)
+                            max_diff=diff;
+                        double rel_diff = diff/v[j];
+                        if(max_rel_diff<rel_diff)
+                            max_rel_diff=rel_diff;
+                    }
+                }
+                cout << orig_size-new_size <<" "<< max_diff <<" "<<max_rel_diff<<endl;
+            }
+        }
+    }
     else
     {
         // Dirty hack to plug into old vmatmain code

Modified: trunk/plearn/vmat/FileVMatrix.cc
===================================================================
--- trunk/plearn/vmat/FileVMatrix.cc	2009-07-09 14:38:14 UTC (rev 10262)
+++ trunk/plearn/vmat/FileVMatrix.cc	2009-07-09 14:51:31 UTC (rev 10263)
@@ -82,6 +82,7 @@
     inherited       (the_length, the_width, true),
     filename_       (filename.absolute()),
     f               (0),
+    file_is_float   (force_float),
     force_float     (force_float),
     build_new_file  (true)
 {



From nouiz at mail.berlios.de  Thu Jul  9 20:54:27 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 9 Jul 2009 20:54:27 +0200
Subject: [Plearn-commits] r10264 - trunk/python_modules/plearn/pymake
Message-ID: <200907091854.n69IsROP020942@sheep.berlios.de>

Author: nouiz
Date: 2009-07-09 20:54:26 +0200 (Thu, 09 Jul 2009)
New Revision: 10264

Modified:
   trunk/python_modules/plearn/pymake/pymake.py
Log:
fix a syntax error in python 2.4.3 on redhat enterprise 5.


Modified: trunk/python_modules/plearn/pymake/pymake.py
===================================================================
--- trunk/python_modules/plearn/pymake/pymake.py	2009-07-09 14:51:31 UTC (rev 10263)
+++ trunk/python_modules/plearn/pymake/pymake.py	2009-07-09 18:54:26 UTC (rev 10264)
@@ -3015,7 +3015,10 @@
         if verbose>2:
             print '*** Running pymake on '+os.path.basename(target)+' using configuration file: ' + configpath
         if verbose>1:
-            print '*** Running pymake on '+os.path.basename(target)+' using options: ' + string.join(map(lambda o: '-'+o if o else '', options))
+            def f(o):
+                if o: return '-'+o
+                else: return ''
+            print '*** Running pymake on '+os.path.basename(target)+' using options: ' + string.join(map(f, options))
             print '++++ Computing dependencies of '+target
         get_ccfiles_to_compile_and_link(target, ccfiles_to_compile, ccfiles_to_link, executables_to_link, linkname)
         if verbose>1:



From nouiz at mail.berlios.de  Mon Jul 13 16:05:08 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 13 Jul 2009 16:05:08 +0200
Subject: [Plearn-commits] r10265 - trunk/plearn_learners/meta
Message-ID: <200907131405.n6DE58jc024466@sheep.berlios.de>

Author: nouiz
Date: 2009-07-13 16:05:08 +0200 (Mon, 13 Jul 2009)
New Revision: 10265

Modified:
   trunk/plearn_learners/meta/AdaBoost.cc
Log:
fix AdaBoost complicated test when we have found a weak learner with 0 error train error.


Modified: trunk/plearn_learners/meta/AdaBoost.cc
===================================================================
--- trunk/plearn_learners/meta/AdaBoost.cc	2009-07-09 18:54:26 UTC (rev 10264)
+++ trunk/plearn_learners/meta/AdaBoost.cc	2009-07-13 14:05:08 UTC (rev 10265)
@@ -717,6 +717,7 @@
             voting_weights.push_back(1);
             sum_voting_weights = 1;
             found_zero_error_weak_learner = true;
+            stage++;
             break;
         }
 
@@ -758,9 +759,27 @@
         inherited::test(testset, test_stats, testoutputs, testcosts);
         saved_testset.append(testset);
         saved_testoutputs.append(PLearn::deepCopy(testoutputs));
-        PLCHECK(weak_learners.length()==stage);
+        PLCHECK(weak_learners.length()==stage || found_zero_error_weak_learner);
+        cout << weak_learners.length()<<" "<<stage<<endl;;
         saved_last_test_stages.append(stage);
         Profiler::pl_profile_end("AdaBoost::test() first" );
+    }else if(found_zero_error_weak_learner && saved_last_test_stages.last()==stage){
+        Vec input;
+        Vec output(outputsize());
+        Vec target;
+        Vec costs(nTestCosts());
+        real weight;
+        VMat old_outputs=saved_testoutputs[index];
+        PLCHECK(old_outputs->width()==testoutputs->width());
+        PLCHECK(old_outputs->length()==testset->length());
+        for(int row=0;row<testset.length();row++){
+            output=old_outputs(row);
+            testset.getExample(row, input, target, weight);
+            computeCostsFromOutputs(input,output,target,costs);
+            if(testoutputs)testoutputs->putOrAppendRow(row,output);
+            if(testcosts)testcosts->putOrAppendRow(row,costs);
+            if(test_stats)test_stats->update(costs,weight);
+        }
     }else{
         Profiler::pl_profile_start("AdaBoost::test() seconds" );
         PLCHECK(weak_learners.size()>1);



From nouiz at mail.berlios.de  Mon Jul 13 17:06:38 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 13 Jul 2009 17:06:38 +0200
Subject: [Plearn-commits] r10266 - trunk/scripts
Message-ID: <200907131506.n6DF6c44031215@sheep.berlios.de>

Author: nouiz
Date: 2009-07-13 17:06:38 +0200 (Mon, 13 Jul 2009)
New Revision: 10266

Modified:
   trunk/scripts/dbidispatch
Log:
remove condor_q from the loop of the --restart options and added some verification.


Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2009-07-13 14:05:08 UTC (rev 10265)
+++ trunk/scripts/dbidispatch	2009-07-13 15:06:38 UTC (rev 10266)
@@ -510,30 +510,45 @@
 elif dbi_param.get("restart",False):
     assert launch_cmd=="Condor"
     cmds=[]
-#    p1_=Popen('condor_q -l -const "JobStatus!=4" '+args(command_argv, shell=True, stdout=PIPE)
-#TODO put condor_history outside the loop as this take much time the we have a not too small history.
+    #We accept to start jobs in the queue only if they are completed
+    p=Popen('condor_q -l -const "JobStatus!=4" '+" ".join(command_argv),
+             shell=True, stdout=PIPE)
+    p.wait();
+    lines=p.stdout.readlines()
+    for l in lines:
+        if l.startswith("Arguments = "):
+            print "We don't accept to restart jobs in the queue that are not completed:", arg
+            sys.exit(1)
+
+    #get all jobs in the queue that are completed.
+    p=Popen('condor_q -l -const "JobStatus==4" '+" ".join(command_argv),
+             shell=True, stdout=PIPE)
+    p.wait()
+    for l in p.stdout.readlines():
+        if l.startswith("Arguments = "):
+            cmd=l[13:-2]
+            cmds.append(cmd.replace("'",""))
+
     for arg in command_argv:
-        #We accept to start jobs in the queue if they are completed
-        p1=Popen('condor_q -l -const "JobStatus!=4" '+arg, shell=True, stdout=PIPE)
-        p2=Popen("condor_history -l "+arg, shell=True, stdout=PIPE)
-        p3=Popen('condor_q -l -const "JobStatus==4" '+arg, shell=True, stdout=PIPE)
-        p1.wait();p2.wait();p3.wait()
-        lines=p1.stdout.readlines()
+        #condor_history don't accept multiple argument! This is the bottleneck.
+        #We need to modif condor_history to let it accept multiple parameter!
+        p=Popen("condor_history -l "+arg, shell=True, stdout=PIPE)
+        p.wait()
+        lines=p.stdout.readlines()
         for l in lines:
             if l.startswith("Arguments = "):
-                print "We don't accept to restart jobs in the queue that are not completed:", arg
-                sys.exit(1)
-        print
-        lines=p2.stdout.readlines()
-        lines+=p3.stdout.readlines()
-        for l in lines:
-            if l.startswith("Arguments = "):
                 cmd=l[13:-2]
                 cmds.append(cmd.replace("'",""))
     commands=cmds
     if len(commands)<1:
-         raise Exception("Their is no commands selected to be restarted!")
+        raise Exception("Their is no commands selected to be restarted!")
+    if len(commands)<len(command_argv):
+        raise Exception("Their is a bad command number in '%s'!"%command_argv)
+    if all([x.find(".")>=0 for x in command_argv]) and len(commands)!=len(command_argv):
+        raise Exception("Their is a bad command number in '%s'!"%command_argv)
+        
     choise_args=[]
+    del p, lines, cmds
 else:
     (commands,choise_args)=generate_commands(command_argv)
 



From nouiz at mail.berlios.de  Mon Jul 13 21:46:28 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 13 Jul 2009 21:46:28 +0200
Subject: [Plearn-commits] r10267 - trunk/commands/PLearnCommands
Message-ID: <200907131946.n6DJkSEu013542@sheep.berlios.de>

Author: nouiz
Date: 2009-07-13 21:46:27 +0200 (Mon, 13 Jul 2009)
New Revision: 10267

Modified:
   trunk/commands/PLearnCommands/VMatCommand.cc
Log:
added a WARNING in the documentation of plearn vmat convert that when we convert to a dmat, it convert to float ALL double by default!
Added check that the file exists too.


Modified: trunk/commands/PLearnCommands/VMatCommand.cc
===================================================================
--- trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-13 15:06:38 UTC (rev 10266)
+++ trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-13 19:46:27 UTC (rev 10267)
@@ -44,6 +44,7 @@
 #include <plearn/base/lexical_cast.h>
 #include <plearn/vmat/FileVMatrix.h>
 #include <plearn/base/plerror.h>
+#include <plearn/io/fileutils.h>
 
 namespace PLearn {
 using namespace std;
@@ -76,6 +77,7 @@
         "   or: vmat convert <source> <destination> [--cols=col1,col2,col3,...] [--mat_to_mem] [--save_vmat] [--force_float]\n"
         "       To convert any dataset into a .amat, .pmat, .dmat, .vmat, .csv or .arff format. \n"
         "       The extension of the destination is used to determine the format you want. \n"
+        "       WARNING: In dmat format, all double are currently casted to float!\n"
         "       If the option --cols is specified, it requests to keep only the given columns\n"
         "       (no space between the commas and the columns); columns can be given either as a\n"
         "       number (zero-based) or a column name (string).  You can also specify a range,\n"
@@ -176,8 +178,13 @@
         PLERROR("vmat pmat_float_save don't work correctly when compiled in float.");
 #endif
         PLCHECK(args.size()>1);
-        for(int f=1;f<args.size();f++){
-            string dataspec = args[f];
+        for(uint f=1;f<args.size();f++){
+            PPath dataspec = args[f];
+            if(!isfile(dataspec)){
+                PLWARNING("%s is not a file!",dataspec.c_str());
+                continue;
+            }
+                
             VMat vm = getDataSet(dataspec);
             int64_t orig_size = vm->getSizeOnDisk();
 



From plearner at mail.berlios.de  Mon Jul 13 22:33:00 2009
From: plearner at mail.berlios.de (plearner at BerliOS)
Date: Mon, 13 Jul 2009 22:33:00 +0200
Subject: [Plearn-commits] r10268 - in trunk: commands/EXPERIMENTAL
	plearn/var/EXPERIMENTAL
Message-ID: <200907132033.n6DKX0Vc018366@sheep.berlios.de>

Author: plearner
Date: 2009-07-13 22:33:00 +0200 (Mon, 13 Jul 2009)
New Revision: 10268

Added:
   trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.cc
   trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.h
   trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc
   trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.h
Modified:
   trunk/commands/EXPERIMENTAL/plearn_exp.cc
Log:
Experimental variables


Modified: trunk/commands/EXPERIMENTAL/plearn_exp.cc
===================================================================
--- trunk/commands/EXPERIMENTAL/plearn_exp.cc	2009-07-13 19:46:27 UTC (rev 10267)
+++ trunk/commands/EXPERIMENTAL/plearn_exp.cc	2009-07-13 20:33:00 UTC (rev 10268)
@@ -356,7 +356,9 @@
 // ***   New EXPERIMENTAL stuff
 
 #include <plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedBernoullis.h>
+#include <plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.h>
 #include <plearn/var/EXPERIMENTAL/SumEntropyOfBernoullis.h>
+#include <plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.h>
 #include <plearn/var/EXPERIMENTAL/LinearCombinationOfScalarVariables.h>
 #include <plearn/var/EXPERIMENTAL/SaltPepperNoiseVariable.h>
 

Added: trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.cc	2009-07-13 19:46:27 UTC (rev 10267)
+++ trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.cc	2009-07-13 20:33:00 UTC (rev 10268)
@@ -0,0 +1,196 @@
+// -*- C++ -*-
+
+// SumEntropyOfCategoricals.cc
+//
+// Copyright (C) 2009 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file SumEntropyOfCategoricals.cc */
+
+
+#include "SumEntropyOfCategoricals.h"
+
+namespace PLearn {
+using namespace std;
+
+/** SumEntropyOfCategoricals **/
+
+PLEARN_IMPLEMENT_OBJECT(
+    SumEntropyOfCategoricals,
+    "Computes the sum of the entropies of independent categorical variables (multinomials with number-of-trials n=1) whose probability parameters are given as input.",
+    "i.e. if input is a matrix P, computes sum_ij - [P_ij log(P_ij)].\n"
+    "Note that this formula does not depend on whether the parameters in P are those of a single categorical variable \n"
+    "or represent the parameters of several independent categorical variables."
+    );
+
+SumEntropyOfCategoricals::SumEntropyOfCategoricals()
+    : inherited(0, 1, 1)
+{
+}
+
+// constructor from input variable.
+SumEntropyOfCategoricals::SumEntropyOfCategoricals(Variable* input)
+    : inherited(input, 1, 1)
+{
+    build_();
+}
+
+// constructor from input variable and parameters
+// SumEntropyOfCategoricals::SumEntropyOfCategoricals(Variable* input, param_type the_parameter,...)
+// ### replace with actual parameters
+//  : inherited(input, this_variable_length, this_variable_width),
+//    parameter(the_parameter),
+//    ...
+//{
+//    // ### You may (or not) want to call build_() to finish building the
+//    // ### object
+//}
+
+void SumEntropyOfCategoricals::recomputeSize(int& l, int& w) const
+{
+    l = w = 1;
+}
+
+// ### computes value from input's value
+void SumEntropyOfCategoricals::fprop()
+{
+    double res = 0;
+    Mat P = input->matValue;
+    int l = P.length();
+    int w = P.width();
+
+    for(int i=0; i<l; i++)
+    {
+        const real* P_i = P[i];
+        for(int j=0; j<w; j++)
+        {
+            real P_ij = P_i[j];
+            if( P_ij>1e-25 )
+                res += P_ij*pl_log(P_ij);
+        }
+    }
+    valuedata[0] = -(real)res;
+}
+
+// ### computes input's gradient from gradient
+void SumEntropyOfCategoricals::bprop()
+{
+    /*
+      [-p log(p)]' = -[log(p) + 1]
+    */
+    real gr = gradientdata[0];
+    Mat P = input->matValue;
+    Mat Pgr = input->matGradient;
+
+    int l = P.length();
+    int w = P.width();
+
+    for(int i=0; i<l; i++)
+    {
+        const real* P_i = P[i];
+        real* Pgr_i = Pgr[i];
+        for(int j=0; j<w; j++)
+        {
+            real P_ij = P_i[j];
+            real logPij = P_ij>1e-25 ?pl_log(P_ij): -57.5;
+            Pgr_i[j] -= gr*(logPij + 1);
+        }
+    }
+}
+
+// ### You can implement these methods:
+// void SumEntropyOfCategoricals::bbprop() {}
+// void SumEntropyOfCategoricals::symbolicBprop() {}
+// void SumEntropyOfCategoricals::rfprop() {}
+
+
+// ### Nothing to add here, simply calls build_
+void SumEntropyOfCategoricals::build()
+{
+    inherited::build();
+    build_();
+}
+
+void SumEntropyOfCategoricals::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+void SumEntropyOfCategoricals::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    // ### ex:
+    // declareOption(ol, "myoption", &SumEntropyOfCategoricals::myoption,
+    //               OptionBase::buildoption,
+    //               "Help text describing this option");
+    // ...
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void SumEntropyOfCategoricals::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.h	2009-07-13 19:46:27 UTC (rev 10267)
+++ trunk/plearn/var/EXPERIMENTAL/SumEntropyOfCategoricals.h	2009-07-13 20:33:00 UTC (rev 10268)
@@ -0,0 +1,162 @@
+// -*- C++ -*-
+
+// SumEntropyOfCategoricals.h
+//
+// Copyright (C) 2009 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file SumEntropyOfCategoricals.h */
+
+
+#ifndef SumEntropyOfCategoricals_INC
+#define SumEntropyOfCategoricals_INC
+
+#include <plearn/var/UnaryVariable.h>
+
+namespace PLearn {
+using namespace std;
+
+/*! * SumEntropyOfCategoricals * */
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class SumEntropyOfCategoricals : public UnaryVariable
+{
+    typedef UnaryVariable inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor, usually does nothing
+    SumEntropyOfCategoricals();
+
+    //! Constructor initializing from input variable
+    // ### Make sure the implementation in the .cc calls inherited constructor
+    // ### and initializes all fields with reasonable default values.
+    SumEntropyOfCategoricals(Variable* input);
+
+    // ### If your class has parameters, you probably want a constructor that
+    // ### initializes them
+    // SumEntropyOfCategoricals(Variable* input, param_type the_parameter, ...);
+
+    // Your other public member functions go here
+
+    //#####  PLearn::Variable methods #########################################
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void recomputeSize(int& l, int& w) const;
+    virtual void fprop();
+    virtual void bprop();
+
+    // ### These ones are not always implemented
+    // virtual void bbprop();
+    // virtual void symbolicBprop();
+    // virtual void rfprop();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(SumEntropyOfCategoricals);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(SumEntropyOfCategoricals);
+
+// ### Put here a convenient method for building your variable.
+// ### e.g., if your class is TotoVariable, with two parameters foo_type foo
+// ### and bar_type bar, you could write:
+// inline Var toto(Var v, foo_type foo=default_foo, bar_type bar=default_bar)
+// { return new TotoVariable(v, foo, bar); }
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc	2009-07-13 19:46:27 UTC (rev 10267)
+++ trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc	2009-07-13 20:33:00 UTC (rev 10268)
@@ -0,0 +1,272 @@
+// -*- C++ -*-
+
+// SumVarianceOfLinearTransformedCategoricals.cc
+//
+// Copyright (C) 2009 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file SumVarianceOfLinearTransformedCategoricals.cc */
+
+
+#include "SumVarianceOfLinearTransformedCategoricals.h"
+
+namespace PLearn {
+using namespace std;
+
+/** SumVarianceOfLinearTransformedCategoricals **/
+
+PLEARN_IMPLEMENT_OBJECT(
+    SumVarianceOfLinearTransformedCategoricals,
+    "Computes the sum of the variances of the elements of a linear transformation of a concatenation of independent random variables following a categorical distribution.",
+    "By categorical distribution we mean multinomials with the number-of-trials parameter set to n=1.\n"
+    "Let P=inpu1 a (l,d') matrix. Each row contains the parameters of groupsize.length() categoricals.\n"
+    "  ( the sum of the groupsize elements equals d').\n"
+    "Let H ~ MultipleCategorical(P) a (l,d') corresponding random variable, \n"
+    "  this correponds to drawings from independent categorical variables whose probablity parameters are those in P \n"
+    "Let W=input2 a (d,d') linear transformation matrix. \n"
+    "Let X=H W^t a (l,d) random variable matrix corresponding to applying the transformation. \n"
+    "  i.e. X_i = \sum_j H_ij W^t_j \n" 
+    "SumVarianceOfLinearTransformedCategoricals computes the sum of the variances of the elements of X.\n"
+    "i.e. \sum_ij Var[X_ij] \n"
+    );
+
+SumVarianceOfLinearTransformedCategoricals::SumVarianceOfLinearTransformedCategoricals()
+    : inherited(0,0,1,1)
+{}
+
+SumVarianceOfLinearTransformedCategoricals::SumVarianceOfLinearTransformedCategoricals(Variable* input1, Variable* input2,
+                           bool call_build_)
+    : inherited(input1, input2, 1, 1, call_build_)
+{
+    if (call_build_)
+        build_();
+}
+
+// constructor from input variable and parameters
+// SumVarianceOfLinearTransformedCategoricals::SumVarianceOfLinearTransformedCategoricals(Variable* input1, Variable* input2,
+//                            param_type the_parameter, ...,
+//                            bool call_build_)
+// ### replace with actual parameters
+//  : inherited(input1, input2, this_variable_length, this_variable_width,
+//              call_build_),
+//    parameter(the_parameter),
+//    ...
+//{
+//    if (call_build_)
+//        build_();
+//}
+
+void SumVarianceOfLinearTransformedCategoricals::recomputeSize(int& l, int& w) const
+{
+    l = 1;
+    w = 1;
+}
+
+// ### computes value from input1 and input2 values
+void SumVarianceOfLinearTransformedCategoricals::fprop()
+{
+    if(input1.width()!=input2.width())
+        PLERROR("Incompatible sizes: width of P (input1) must equal width of W (input2)"); 
+
+    Mat P = input1->matValue;
+    Mat W = input2->matValue;
+    int d = W.length();
+    int l = P.length();
+    // int m = W.width(); // should equal sum of groupsizes
+
+    double simplesum = 0;
+    double sqsum = 0;
+
+    int ngroups = groupsizes.length();
+    const int* pgroupsize = groupsizes.data();
+
+    for(int t=0; t<l; t++)
+    {
+        const real* p = P[t];
+        for(int i=0; i<d; i++)
+        {
+            const real* Wi = W[i];
+            int k = 0;
+            for(int groupnum=0; groupnum<ngroups; groupnum++)
+            {
+                double tmpsqsum = 0;
+                int gs = pgroupsize[groupnum];
+                while(gs--)
+                {
+                    real Wik = Wi[k];
+                    real pk = p[k];
+                    real Wik_pk = Wik*pk;
+                    simplesum += Wik*Wik_pk;
+                    tmpsqsum += Wik_pk;
+                    k++;
+                }
+                sqsum += tmpsqsum*tmpsqsum;
+            }
+        }
+    }
+    value[0] = simplesum-sqsum;
+}
+
+// ### computes input1 and input2 gradients from gradient
+void SumVarianceOfLinearTransformedCategoricals::bprop()
+{
+    Mat P = input1->matValue;
+    Mat Pgrad = input1->matGradient;
+    Mat W = input2->matValue;
+    Mat Wgrad = input2->matGradient;
+    int d = W.length();
+    int l = P.length();
+    // int m = W.width(); // should equal sum of groupsizes
+
+    real gr = gradient[0];
+
+    int ngroups = groupsizes.length();
+    const int* pgroupsize = groupsizes.data();    
+
+    group_sum_wik_pk.resize(ngroups);
+    real* p_group_sum_wik_pk = group_sum_wik_pk.data();
+
+    for(int t=0; t<l; t++)
+    {
+        const real* p = P[t];
+        real* gp = Pgrad[t];
+        for(int i=0; i<d; i++)
+        {
+            const real* Wi = W[i];
+            int k = 0;
+            for(int groupnum=0; groupnum<ngroups; groupnum++)
+            {
+                int gs = pgroupsize[groupnum];
+                double sum_wik_pk = 0;
+                while(gs--)
+                {
+                    sum_wik_pk += Wi[k]*p[k];
+                    k++;
+                }
+                p_group_sum_wik_pk[groupnum] = sum_wik_pk;
+            }
+                    
+            real* gWi = Wgrad[i];
+            k = 0;
+            for(int groupnum=0; groupnum<ngroups; groupnum++)
+            {
+                int gs = pgroupsize[groupnum];
+                real grsum = p_group_sum_wik_pk[groupnum];
+                while(gs--)
+                {
+                    real Wik = Wi[k];
+                    gWi[k] += gr*2*p[k]*(Wik-grsum);
+                    gp[k] += gr*Wik*(Wik-2*grsum);
+                    k++;
+                }
+            }
+        }
+    }
+
+}
+
+// ### You can implement these methods:
+// void SumVarianceOfLinearTransformedCategoricals::bbprop() {}
+// void SumVarianceOfLinearTransformedCategoricals::symbolicBprop() {}
+// void SumVarianceOfLinearTransformedCategoricals::rfprop() {}
+
+
+// ### Nothing to add here, simply calls build_
+void SumVarianceOfLinearTransformedCategoricals::build()
+{
+    inherited::build();
+    build_();
+}
+
+void SumVarianceOfLinearTransformedCategoricals::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all "pointer-like" fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+    deepCopyField(groupsizes, copies);
+    deepCopyField(group_sum_wik_pk, copies);
+
+    // ### If you want to deepCopy a Var field:
+    // varDeepCopyField(somevariable, copies);
+}
+
+void SumVarianceOfLinearTransformedCategoricals::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    declareOption(ol, "groupsizes", &SumVarianceOfLinearTransformedCategoricals::groupsizes,
+                  OptionBase::buildoption,
+                  "defines the dimensions of the categorical variables.");
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void SumVarianceOfLinearTransformedCategoricals::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.h	2009-07-13 19:46:27 UTC (rev 10267)
+++ trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.h	2009-07-13 20:33:00 UTC (rev 10268)
@@ -0,0 +1,167 @@
+// -*- C++ -*-
+
+// SumVarianceOfLinearTransformedCategoricals.h
+//
+// Copyright (C) 2009 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file SumVarianceOfLinearTransformedCategoricals.h */
+
+
+#ifndef SumVarianceOfLinearTransformedCategoricals_INC
+#define SumVarianceOfLinearTransformedCategoricals_INC
+
+#include <plearn/var/BinaryVariable.h>
+
+namespace PLearn {
+using namespace std;
+
+/*! * SumVarianceOfLinearTransformedCategoricals * */
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class SumVarianceOfLinearTransformedCategoricals : public BinaryVariable
+{
+    typedef BinaryVariable inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    TVec<int> groupsizes;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor.
+    SumVarianceOfLinearTransformedCategoricals();
+
+    //! Constructor initializing from two input variables.
+    // ### Make sure the implementation in the .cc calls inherited constructor
+    // ### and initializes all fields with reasonable default values.
+    SumVarianceOfLinearTransformedCategoricals(Variable* input1, Variable* input2, bool call_build_ = true);
+
+    // ### If your class has parameters, you probably want a constructor that
+    // ### initializes them
+    // SumVarianceOfLinearTransformedCategoricals(Variable* input1, Variable* input2,
+    //              param_type the_parameter, ..., bool call_build_ = true);
+
+    // Your other public member functions go here
+
+    //#####  PLearn::Variable methods #########################################
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void recomputeSize(int& l, int& w) const;
+    virtual void fprop();
+    virtual void bprop();
+
+    // ### These ones are not always implemented
+    // virtual void bbprop();
+    // virtual void symbolicBprop();
+    // virtual void rfprop();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(SumVarianceOfLinearTransformedCategoricals);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // temporary variables used in fprop and bprop
+    Vec group_sum_wik_pk;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(SumVarianceOfLinearTransformedCategoricals);
+
+// ### Put here a convenient method for building your variable from two
+// ### existing ones.
+// ### e.g., if your class is TotoVariable, with two parameters foo_type foo
+// ### and bar_type bar, you could write:
+// inline Var toto(Var v1, Var v2,
+//                 foo_type foo=default_foo, bar_type bar=default_bar)
+// { return new TotoVariable(v1, v2, foo, bar); }
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From nouiz at mail.berlios.de  Tue Jul 14 15:31:52 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 14 Jul 2009 15:31:52 +0200
Subject: [Plearn-commits] r10269 - trunk/plearn/vmat
Message-ID: <200907141331.n6EDVqo5014245@sheep.berlios.de>

Author: nouiz
Date: 2009-07-14 15:31:52 +0200 (Tue, 14 Jul 2009)
New Revision: 10269

Modified:
   trunk/plearn/vmat/LIBSVMSparseVMatrix.cc
   trunk/plearn/vmat/LIBSVMSparseVMatrix.h
Log:
-Registered LIBSSVMSparseVMatrix as a regular VMatrix. This make it recognised by getDataSet. This allow to use plearn vmat ... command with libsvm file.
-If class_string is not gived, we check that the target is an int and if true, we use this value as the target.


Modified: trunk/plearn/vmat/LIBSVMSparseVMatrix.cc
===================================================================
--- trunk/plearn/vmat/LIBSVMSparseVMatrix.cc	2009-07-13 20:33:00 UTC (rev 10268)
+++ trunk/plearn/vmat/LIBSVMSparseVMatrix.cc	2009-07-14 13:31:52 UTC (rev 10269)
@@ -66,6 +66,13 @@
 {
 }
 
+LIBSVMSparseVMatrix::LIBSVMSparseVMatrix(PPath filename, bool use_coarse_representation):
+    libsvm_file(filename),
+    use_coarse_representation(use_coarse_representation)
+{
+    build();
+}
+
 void LIBSVMSparseVMatrix::getNewRow(int i, const Vec& v) const
 {
     if( !use_coarse_representation )
@@ -83,7 +90,7 @@
 {
     declareOption(ol, "class_strings", &LIBSVMSparseVMatrix::class_strings,
                   OptionBase::buildoption,
-                  "Strings associated to the different classes.\n");
+                  "Strings associated to the different classes. If not present we suppose classes are int.\n");
 
     declareOption(ol, "libsvm_file", &LIBSVMSparseVMatrix::libsvm_file,
                   OptionBase::buildoption,
@@ -116,6 +123,9 @@
 void LIBSVMSparseVMatrix::build_()
 {
 
+    if(libsvm_file.isEmpty())
+        return;
+
     // Read data
     PStream libsvm_stream = openFile(libsvm_file, PStream::raw_ascii);
     updateMtime(libsvm_file);
@@ -140,10 +150,14 @@
         
         // Get target
         target_index = class_strings.find(tokens[0]);
-        if( target_index < 0)
-            PLERROR("In LIBSVMSparseVMatrix::build_(): target %s unknown",
-                    tokens[0].c_str());
-        
+        if( target_index < 0){
+            double d;
+            if(pl_isnumber(tokens[0],&d) && ((double)((int)d))==d)
+                target_index=(int)d;
+            else
+                PLERROR("In LIBSVMSparseVMatrix::build_(): target %s unknown and not an int",
+                        tokens[0].c_str());
+        }
         if( (tokens.size()-1)%2 != 0 )
             PLERROR("In LIBSVMSparseVMatrix::build_(): line %s has incompatible "
                     "format", line.c_str()); 
@@ -234,6 +248,12 @@
     }
 }
 
+VMatrixExtensionRegistrar* LIBSVMSparseVMatrix::extension_registrar =
+    new VMatrixExtensionRegistrar(
+        "libsvm",
+        &LIBSVMSparseVMatrix::instantiateFromPPath,
+        "libsvm format(good for sparce input).");
+
 } // end of namespace PLearn
 
 

Modified: trunk/plearn/vmat/LIBSVMSparseVMatrix.h
===================================================================
--- trunk/plearn/vmat/LIBSVMSparseVMatrix.h	2009-07-13 20:33:00 UTC (rev 10268)
+++ trunk/plearn/vmat/LIBSVMSparseVMatrix.h	2009-07-14 13:31:52 UTC (rev 10269)
@@ -41,6 +41,8 @@
 #define LIBSVMSparseVMatrix_INC
 
 #include <plearn/vmat/RowBufferedVMatrix.h>
+#include <plearn/db/getDataSet.h>
+#include <plearn/vmat/VMat.h>
 
 namespace PLearn {
 
@@ -50,6 +52,7 @@
 class LIBSVMSparseVMatrix : public RowBufferedVMatrix
 {
     typedef RowBufferedVMatrix inherited;
+    static VMatrixExtensionRegistrar* extension_registrar;
 
 public:
     //#####  Public Build Options  ############################################
@@ -78,6 +81,7 @@
 
     //! Default constructor
     LIBSVMSparseVMatrix();
+    LIBSVMSparseVMatrix(PPath filename, bool use_coarse_representation);
 
     //#####  PLearn::Object Protocol  #########################################
 
@@ -87,8 +91,13 @@
     // Simply calls inherited::build() then build_()
     virtual void build();
 
+    static VMat instantiateFromPPath(const PPath& filename)
+    {
+        //By default use normal representation
+        return VMat(new LIBSVMSparseVMatrix(filename, true));
+    }
+
     //! Transforms a shallow copy into a deep copy
-    // (PLEASE IMPLEMENT IN .cc)
     virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
 
     virtual void getExample(int i, Vec& input, Vec& target, real& weight);
@@ -106,19 +115,16 @@
     //#####  Protected Member Functions  ######################################
 
     //! Declares the class options.
-    // (PLEASE IMPLEMENT IN .cc)
     static void declareOptions(OptionList& ol);
 
     //! Fill the vector 'v' with the content of the i-th row.
     //! 'v' is assumed to be the right size.
-    // (PLEASE IMPLEMENT IN .cc)
     virtual void getNewRow(int i, const Vec& v) const;
 
 private:
     //#####  Private Member Functions  ########################################
 
     //! This does the actual building.
-    // (PLEASE IMPLEMENT IN .cc)
     void build_();
 
 private:



From nouiz at mail.berlios.de  Tue Jul 14 18:27:03 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 14 Jul 2009 18:27:03 +0200
Subject: [Plearn-commits] r10270 - in trunk/plearn: misc vmat
Message-ID: <200907141627.n6EGR3UX001921@sheep.berlios.de>

Author: nouiz
Date: 2009-07-14 18:27:03 +0200 (Tue, 14 Jul 2009)
New Revision: 10270

Modified:
   trunk/plearn/misc/vmatmain.cc
   trunk/plearn/vmat/VMatrix.cc
   trunk/plearn/vmat/VMatrix.h
Log:
added option --auto_float to plearn vmat convert <dataset1> <dataset2>.pmat --auto_float.
It will save in float format if this don't loose any precission compared to double format(tolerence 0)


Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2009-07-14 13:31:52 UTC (rev 10269)
+++ trunk/plearn/misc/vmatmain.cc	2009-07-14 16:27:03 UTC (rev 10270)
@@ -657,7 +657,7 @@
     {
         if(argc<4)
             PLERROR("Usage: vmat convert <source> <destination> "
-                    "[--mat_to_mem] [--cols=col1,col2,col3,...] [--save_vmat] [--skip-missings] [--precision=N] [--delimiter=CHAR] [--force_float]");
+                    "[--mat_to_mem] [--cols=col1,col2,col3,...] [--save_vmat] [--skip-missings] [--precision=N] [--delimiter=CHAR] [--force_float] [--auto_float]");
 
         string source = argv[2];
         string destination = argv[3];
@@ -691,6 +691,8 @@
          *           :: the destination  file or when the destination file is missing
          *     --force_float
          *           :: if the destination is a pmat, we force the pmat file to be in float format
+         *     --auto_float
+         *           :: if the destination is a pmat, we will store the data in float format if this don't loose any precision compared to double format.
          */
         TVec<string> columns;
         TVec<string> date_columns;
@@ -701,6 +703,7 @@
         bool save_vmat = false;
         bool update = false;
         bool force_float = false;
+        bool auto_float = false;
 
         string ext = extract_extension(destination);
 
@@ -736,11 +739,13 @@
             else if (curopt == "--force_float"){
                 PLCHECK(ext==".pmat");
                 force_float = true;
+            }else if (curopt == "--auto_float"){
+                PLCHECK(ext==".pmat");
+                auto_float = true;
             }else
                 PLWARNING("VMat convert: unrecognized option '%s'; ignoring it...",
                           curopt.c_str());
         }
-
         VMat vm = getVMat(source, indexf);
 
         // If columns specified, select them.  Note: SelectColumnsVMatrix is very
@@ -759,7 +764,7 @@
             // Save strings as strings so they are not lost.
             vm->saveAMAT(destination, true, false, true);
         else if(ext==".pmat")
-            vm->savePMAT(destination, force_float);
+            vm->savePMAT(destination, force_float, auto_float);
         else if(ext==".dmat")
             vm->saveDMAT(destination);
         else if(ext == ".csv")

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2009-07-14 13:31:52 UTC (rev 10269)
+++ trunk/plearn/vmat/VMatrix.cc	2009-07-14 16:27:03 UTC (rev 10270)
@@ -2024,15 +2024,39 @@
 //////////////
 // savePMAT //
 //////////////
-void VMatrix::savePMAT(const PPath& pmatfile, const bool force_float) const
+void VMatrix::savePMAT(const PPath& pmatfile, bool force_float, 
+                       bool auto_float) const
 {
     if (width() == -1)
         PLERROR("In VMat::save - Saving in a pmat file is only possible for constant width VMats (where width()!=-1)");
 
+    if(force_float && auto_float)
+        PLERROR("force_float an auto_float are incompatible option");
+
     int nsamples = length();
     PPath pmatfiletmp=pmatfile+".tmp";
-
-    {        
+    if(auto_float){
+#ifdef USEFLOAT
+        PLERROR("VMatrix::savePMAT auto_float can't reliably select  float or double when compiled in float. Compile it in double.");
+#endif
+        Vec v(width());
+        bool found_not_equal=false;
+        for(int i=0;i<length();i++){
+            getRow(i,v);
+            for(int j=0;j<width();j++){
+                if( ((double)((float)(v[j])))!=v[j] ){
+                    found_not_equal=true;break;
+                }
+            }
+        }
+        if(!found_not_equal){
+            force_float=true;
+            pout<<"We will store the result matrix in FLOAT format."<<endl;
+        }
+        else
+            pout<<"We will store the result matrix in DOUBLE format."<<endl;
+    }
+    {
     FileVMatrix m(pmatfiletmp,nsamples,width(),force_float);
     m.setMetaInfoFrom(this);
     // m.setFieldInfos(getFieldInfos());

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2009-07-14 13:31:52 UTC (rev 10269)
+++ trunk/plearn/vmat/VMatrix.h	2009-07-14 16:27:03 UTC (rev 10270)
@@ -324,7 +324,8 @@
 
     /// Save the VMatrix in PMat format
     virtual void savePMAT(const PPath& pmatfile,
-                          const bool force_float=false) const;
+                          bool force_float=false,
+                          bool auto_float=false) const;
     virtual void remote_savePMAT(const PPath& pmatfile) const{savePMAT(pmatfile,false);}
     virtual void remote_savePMAT_float(const PPath& pmatfile) const{savePMAT(pmatfile,true);}
 



From nouiz at mail.berlios.de  Tue Jul 14 21:55:06 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 14 Jul 2009 21:55:06 +0200
Subject: [Plearn-commits] r10271 - trunk/plearn/vmat
Message-ID: <200907141955.n6EJt6wx011333@sheep.berlios.de>

Author: nouiz
Date: 2009-07-14 21:55:05 +0200 (Tue, 14 Jul 2009)
New Revision: 10271

Modified:
   trunk/plearn/vmat/VMatrix.cc
Log:
better error message.


Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2009-07-14 16:27:03 UTC (rev 10270)
+++ trunk/plearn/vmat/VMatrix.cc	2009-07-14 19:55:05 UTC (rev 10271)
@@ -2031,13 +2031,13 @@
         PLERROR("In VMat::save - Saving in a pmat file is only possible for constant width VMats (where width()!=-1)");
 
     if(force_float && auto_float)
-        PLERROR("force_float an auto_float are incompatible option");
+        PLERROR("VMatrix::savePMAT() - force_float an auto_float are incompatible option");
 
     int nsamples = length();
     PPath pmatfiletmp=pmatfile+".tmp";
     if(auto_float){
 #ifdef USEFLOAT
-        PLERROR("VMatrix::savePMAT auto_float can't reliably select  float or double when compiled in float. Compile it in double.");
+        PLERROR("VMatrix::savePMAT() - auto_float can't reliably select  float or double when compiled in float. Compile it in double.");
 #endif
         Vec v(width());
         bool found_not_equal=false;



From nouiz at mail.berlios.de  Wed Jul 15 20:38:21 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 15 Jul 2009 20:38:21 +0200
Subject: [Plearn-commits] r10272 - in trunk: commands/PLearnCommands
	plearn/misc
Message-ID: <200907151838.n6FIcLOq008663@sheep.berlios.de>

Author: nouiz
Date: 2009-07-15 20:38:19 +0200 (Wed, 15 Jul 2009)
New Revision: 10272

Modified:
   trunk/commands/PLearnCommands/VMatCommand.cc
   trunk/plearn/misc/vmatmain.cc
Log:
plearn vmat info now accept multiple args.


Modified: trunk/commands/PLearnCommands/VMatCommand.cc
===================================================================
--- trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-14 19:55:05 UTC (rev 10271)
+++ trunk/commands/PLearnCommands/VMatCommand.cc	2009-07-15 18:38:19 UTC (rev 10272)
@@ -56,7 +56,7 @@
     PLearnCommand(
         "vmat",
         "Examination and manipulation of vmat datasets",
-        "Usage: vmat info <dataset> \n"
+        "Usage: vmat info <dataset>... \n"
         "       Will info about dataset (size, etc..)\n"
         "   or: vmat fields <dataset> [name_only] [transpose] \n"
         "       To list the fields with their names (if 'name_only' is specified, the indexes won't be displayed,\n"

Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2009-07-14 19:55:05 UTC (rev 10271)
+++ trunk/plearn/misc/vmatmain.cc	2009-07-15 18:38:19 UTC (rev 10272)
@@ -796,28 +796,32 @@
     }
     else if(command=="info")
     {
-        string dbname = argv[2];
-        VMat vm = getVMat(dbname, indexf);
-        pout<<vm.length()<<" x "<<vm.width()<<endl;
-        pout << "inputsize: " << vm->inputsize() << endl;
-        pout << "targetsize: " << vm->targetsize() << endl;
-        pout << "weightsize: " << vm->weightsize() << endl;
-        pout << "extrasize: " << vm->extrasize() << endl;
-        VVMatrix * vvm = dynamic_cast<VVMatrix*>((VMatrix*)vm);
-        if(vvm!=NULL)
-        {
-            pout<< "Last modification (including dependencies of .vmat): "
-                << int32_t(vvm->getMtime()) << endl;
-            bool ispre=vvm->isPrecomputedAndUpToDate();
-            pout<<"precomputed && uptodate : ";
-            if(ispre)
+        for(int i=2;i<argc;i++){
+            string dbname = argv[i];
+            VMat vm = getVMat(dbname, indexf);
+            if(argc>3)
+                pout<<dbname<<endl;
+            pout<<vm.length()<<" x "<<vm.width()<<endl;
+            pout << "inputsize: " << vm->inputsize() << endl;
+            pout << "targetsize: " << vm->targetsize() << endl;
+            pout << "weightsize: " << vm->weightsize() << endl;
+            pout << "extrasize: " << vm->extrasize() << endl;
+            VVMatrix * vvm = dynamic_cast<VVMatrix*>((VMatrix*)vm);
+            if(vvm!=NULL)
             {
-                pout <<"yes : " << vvm->getPrecomputedDataName()<<endl;
-                pout<< "timestamp of precom. data : "
-                    << int32_t(getDataSetDate(vvm->getPrecomputedDataName()))
-                    << endl;
+                pout<< "Last modification (including dependencies of .vmat): "
+                    << int32_t(vvm->getMtime()) << endl;
+                bool ispre=vvm->isPrecomputedAndUpToDate();
+                pout<<"precomputed && uptodate : ";
+                if(ispre)
+                {
+                    pout <<"yes : " << vvm->getPrecomputedDataName()<<endl;
+                    pout<< "timestamp of precom. data : "
+                        <<int32_t(getDataSetDate(vvm->getPrecomputedDataName()))
+                        << endl;
+                }
+                else pout <<"no"<<endl;
             }
-            else pout <<"no"<<endl;
         }
     }
     else if(command=="fields")



From nouiz at mail.berlios.de  Wed Jul 15 21:21:52 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 15 Jul 2009 21:21:52 +0200
Subject: [Plearn-commits] r10273 - trunk
Message-ID: <200907151921.n6FJLqQA012715@sheep.berlios.de>

Author: nouiz
Date: 2009-07-15 21:21:52 +0200 (Wed, 15 Jul 2009)
New Revision: 10273

Modified:
   trunk/pymake.config.model
Log:
remoged the lib gfortran when we compile with goto as this is not needed anymore on all lisa computer.


Modified: trunk/pymake.config.model
===================================================================
--- trunk/pymake.config.model	2009-07-15 18:38:19 UTC (rev 10272)
+++ trunk/pymake.config.model	2009-07-15 19:21:52 UTC (rev 10273)
@@ -893,7 +893,7 @@
 
 pymakeLinkOption( name = 'goto',
               description = 'linking using GOTO lib for BLAS',
-              linkeroptions = '-L' + libdir +'goto -lgoto -lgfortran'
+              linkeroptions = '-L' + libdir +'goto -lgoto'
               )
 
 tmp = getOptions(options_choices, optionargs[:])



From nouiz at mail.berlios.de  Fri Jul 17 17:07:28 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 17 Jul 2009 17:07:28 +0200
Subject: [Plearn-commits] r10274 - trunk/plearn_learners/online
Message-ID: <200907171507.n6HF7SYe002850@sheep.berlios.de>

Author: nouiz
Date: 2009-07-17 17:07:27 +0200 (Fri, 17 Jul 2009)
New Revision: 10274

Modified:
   trunk/plearn_learners/online/StackedAutoassociatorsNet.cc
Log:
put as default StackedAutoassociatorsNet::test_minibatch_size=128 as this don't change the result and make the test faster.


Modified: trunk/plearn_learners/online/StackedAutoassociatorsNet.cc
===================================================================
--- trunk/plearn_learners/online/StackedAutoassociatorsNet.cc	2009-07-15 19:21:52 UTC (rev 10273)
+++ trunk/plearn_learners/online/StackedAutoassociatorsNet.cc	2009-07-17 15:07:27 UTC (rev 10274)
@@ -93,6 +93,8 @@
     // random_gen will be initialized in PLearner::build_()
     random_gen = new PRandom();
     nstages = 0;
+    //To have faster test time by default. That don't change the result.
+    test_minibatch_size = 128;
 }
 
 void StackedAutoassociatorsNet::declareOptions(OptionList& ol)



From nouiz at mail.berlios.de  Fri Jul 17 17:09:15 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 17 Jul 2009 17:09:15 +0200
Subject: [Plearn-commits] r10275 - trunk/plearn_learners/online
Message-ID: <200907171509.n6HF9F9B003037@sheep.berlios.de>

Author: nouiz
Date: 2009-07-17 17:09:15 +0200 (Fri, 17 Jul 2009)
New Revision: 10275

Modified:
   trunk/plearn_learners/online/StackedAutoassociatorsNet.cc
Log:
don't override explicit value of the test_minibatch_size. We can't explicitly set a value of 1...


Modified: trunk/plearn_learners/online/StackedAutoassociatorsNet.cc
===================================================================
--- trunk/plearn_learners/online/StackedAutoassociatorsNet.cc	2009-07-17 15:07:27 UTC (rev 10274)
+++ trunk/plearn_learners/online/StackedAutoassociatorsNet.cc	2009-07-17 15:09:15 UTC (rev 10275)
@@ -94,7 +94,8 @@
     random_gen = new PRandom();
     nstages = 0;
     //To have faster test time by default. That don't change the result.
-    test_minibatch_size = 128;
+    if(test_minibatch_size==1)
+        test_minibatch_size = 128;
 }
 
 void StackedAutoassociatorsNet::declareOptions(OptionList& ol)



From plearner at mail.berlios.de  Fri Jul 17 19:04:27 2009
From: plearner at mail.berlios.de (plearner at BerliOS)
Date: Fri, 17 Jul 2009 19:04:27 +0200
Subject: [Plearn-commits] r10276 - in trunk:
	plearn_learners/generic/EXPERIMENTAL scripts/EXPERIMENTAL
Message-ID: <200907171704.n6HH4R3V012858@sheep.berlios.de>

Author: plearner
Date: 2009-07-17 19:04:18 +0200 (Fri, 17 Jul 2009)
New Revision: 10276

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h
   trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py
Log:
Added stuff to collect simple unit activation stats


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2009-07-17 15:09:15 UTC (rev 10275)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2009-07-17 17:04:18 UTC (rev 10276)
@@ -233,6 +233,15 @@
                    (BodyDoc(""),
                     ArgDoc("layer", "no of the layer"),
                     RetDoc("")));
+
+    declareMethod(rmm,
+                   "computeAndSaveLayerActivationStats",
+                   &DeepReconstructorNet::computeAndSaveLayerActivationStats,
+                   (BodyDoc(""),
+                    ArgDoc("dataset", "the data vmatrix to compute activaitons on"),
+                    ArgDoc("which_layer", "the layer (1 for first hidden layer)"),
+                    ArgDoc("pmatfilepath", ".pmat file where to save computed stats")));
+
 }
 
 void DeepReconstructorNet::build_()
@@ -825,6 +834,44 @@
 }
 
 
+void DeepReconstructorNet::computeAndSaveLayerActivationStats(VMat dataset, int which_layer, const string& pmatfilepath)
+{
+    int len = dataset.length();
+    Var layer = layers[which_layer];
+    int layersize = layer->size();
+    Mat actstats(1+layersize,5);
+    actstats.fill(0.);
+
+    Vec input;
+    Vec target;
+    real weight;
+    Vec output;
+
+    for(int i=0; i<len; i++)
+    {
+        dataset.getExample(i, input, target, weight);
+        computeOutput(input, output);
+        Vec activations = layer->value;
+        for(int k=0; k<layersize; k++)
+        {
+            real act = activations[k];
+            actstats(k+1,0) += act;
+            if(act<0.25)
+                actstats(k+1,1)++;
+            else if(act<0.50)
+                actstats(k+1,2)++;
+            else if(act<0.75)
+                actstats(k+1,3)++;                
+            else
+                actstats(k+1,4)++;
+        }        
+    }
+    actstats *= 1./len;
+    Vec meanvec = actstats(0);
+    columnMean(actstats.subMat(1,0,layersize,5), meanvec);
+    savePMat(pmatfilepath, actstats);
+}
+
 void DeepReconstructorNet::computeOutput(const Vec& input, Vec& output) const
 {
     output.resize(nout);

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h	2009-07-17 15:09:15 UTC (rev 10275)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h	2009-07-17 17:04:18 UTC (rev 10276)
@@ -206,9 +206,8 @@
     Mat fpropOneLayer(int layer);
     Mat reconstructOneLayer(int layer);
        
+    void computeAndSaveLayerActivationStats(VMat dataset, int which_layer, const string& pmatfilepath);
 
-    
-
     // *** SUBCLASS WRITING: ***
     // While in general not necessary, in case of particular needs
     // (efficiency concerns for ex) you may also want to overload

Modified: trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py
===================================================================
--- trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py	2009-07-17 15:09:15 UTC (rev 10275)
+++ trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py	2009-07-17 17:04:18 UTC (rev 10276)
@@ -17,8 +17,9 @@
 ################
 
 def print_usage_and_exit():
-    print "Usage : deepnet_collect_filters.py dirname"
-    print "  will collect ad save .png files of filters found in any *learner*.psave in specified directory and subdirectories"
+    print "Usage : deepnet_collect_filters.py dirname [dataset.vmat]"
+    print "  will collect and save .png files of filters found in any *learner*.psave in specified directory and subdirectories"
+    print "  if a dataset is specfied, the first layer activation statistics for that set will be saved in a ..._layer1_actstats.pmat"
     sys.exit()
 
 #print "Press Enter to continue"
@@ -32,7 +33,13 @@
     return imgwidth,imgheight
 
 
-def collectFilters(basedir):
+def collectFilters(basedir, datasetspec):
+
+    if datasetspec is None:
+        dataset = None
+    else:
+        dataset = serv.new('AutoVMatrix(specification ="'+datasetspec+'");')
+
     for dirpath, dirs, files in os.walk(basedir):
         for filename in files:
             if filename.endswith(".psave") and "learner" in filename:
@@ -50,6 +57,10 @@
                         print "   --> "+imgfilename
                         saveRowsAsImage(os.path.join(dirpath,imgfilename), matrix,
                                         imgwidth, imgheight, 10, 20)
+                if dataset is not None:
+                    print "   Now computing first layer activation statistics"
+                    actpath = os.path.join(dirpath,filename[:-6]+"_layer1_actstats.pmat")
+                    learner.computeAndSaveLayerActivationStats(dataset,1,actpath)
                 learner.delete()
 
 ############
@@ -63,5 +74,9 @@
 serv = launch_plearn_server(command = server_command)
 
 basedir = sys.argv[1]
-collectFilters(basedir)
+if len(sys.argv)<3:
+    datasetspec = None
+else:
+    datasetspec = sys.argv[2]
+collectFilters(basedir, datasetspec)
     



From plearner at mail.berlios.de  Fri Jul 17 20:22:50 2009
From: plearner at mail.berlios.de (plearner at BerliOS)
Date: Fri, 17 Jul 2009 20:22:50 +0200
Subject: [Plearn-commits] r10277 - in trunk: plearn/var/EXPERIMENTAL
	plearn_learners/generic/EXPERIMENTAL
	python_modules/plearn/table scripts/EXPERIMENTAL
Message-ID: <200907171822.n6HIMovU007517@sheep.berlios.de>

Author: plearner
Date: 2009-07-17 20:22:50 +0200 (Fri, 17 Jul 2009)
New Revision: 10277

Modified:
   trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
   trunk/python_modules/plearn/table/viewtable.py
   trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py
Log:
A few minor fixes


Modified: trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc	2009-07-17 17:04:18 UTC (rev 10276)
+++ trunk/plearn/var/EXPERIMENTAL/SumVarianceOfLinearTransformedCategoricals.cc	2009-07-17 18:22:50 UTC (rev 10277)
@@ -54,9 +54,9 @@
     "  this correponds to drawings from independent categorical variables whose probablity parameters are those in P \n"
     "Let W=input2 a (d,d') linear transformation matrix. \n"
     "Let X=H W^t a (l,d) random variable matrix corresponding to applying the transformation. \n"
-    "  i.e. X_i = \sum_j H_ij W^t_j \n" 
+    "  i.e. X_i = sum_j H_ij W^t_j \n" 
     "SumVarianceOfLinearTransformedCategoricals computes the sum of the variances of the elements of X.\n"
-    "i.e. \sum_ij Var[X_ij] \n"
+    "i.e. sum_ij Var[X_ij] \n"
     );
 
 SumVarianceOfLinearTransformedCategoricals::SumVarianceOfLinearTransformedCategoricals()

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2009-07-17 17:04:18 UTC (rev 10276)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2009-07-17 18:22:50 UTC (rev 10277)
@@ -839,7 +839,7 @@
     int len = dataset.length();
     Var layer = layers[which_layer];
     int layersize = layer->size();
-    Mat actstats(1+layersize,5);
+    Mat actstats(1+layersize,6);
     actstats.fill(0.);
 
     Vec input;
@@ -856,19 +856,20 @@
         {
             real act = activations[k];
             actstats(k+1,0) += act;
+            actstats(k+1,1) += act*act;
             if(act<0.25)
-                actstats(k+1,1)++;
+                actstats(k+1,2)++;
             else if(act<0.50)
-                actstats(k+1,2)++;
+                actstats(k+1,3)++;
             else if(act<0.75)
-                actstats(k+1,3)++;                
+                actstats(k+1,4)++;                
             else
-                actstats(k+1,4)++;
+                actstats(k+1,5)++;
         }        
     }
     actstats *= 1./len;
     Vec meanvec = actstats(0);
-    columnMean(actstats.subMat(1,0,layersize,5), meanvec);
+    columnMean(actstats.subMat(1,0,layersize,6), meanvec);
     savePMat(pmatfilepath, actstats);
 }
 

Modified: trunk/python_modules/plearn/table/viewtable.py
===================================================================
--- trunk/python_modules/plearn/table/viewtable.py	2009-07-17 17:04:18 UTC (rev 10276)
+++ trunk/python_modules/plearn/table/viewtable.py	2009-07-17 18:22:50 UTC (rev 10277)
@@ -932,6 +932,10 @@
              """xterm -e sh -c 'cd "_DIRPATH_"; pwd;"""+
              set_filepath("learner.psave","Split0/LearnerExpdir/Strat0/Trials0/Split0/LearnerExpdir")+
              """deepnetplot.py plotRepAndRec $filepath ~/data/mnist/mnist_small/mnist_basic2_valid.pmat; sh' """),
+            ('a',"view learner layer1 activation stats", 
+             """xterm -e sh -c 'cd "_DIRPATH_"; pwd; """+
+             set_filepath("learner_layer1_actstats.pmat","Split0/LearnerExpdir/Strat0/Trials0/Split0/LearnerExpdir")+
+             """myplearn vmat view $filepath' """),        
             ('v',"deepnetplot.py plotEachRow learner.psave", 
              """xterm -e sh -c 'cd "_DIRPATH_"; pwd; """+
              set_filepath("learner.psave","Split0/LearnerExpdir/Strat0/Trials0/Split0/LearnerExpdir")+
@@ -944,6 +948,10 @@
              """xterm -e sh -c 'cd "_DIRPATH_"; pwd; """+
              set_filepath("learner_Layer1_Wr.png","Split0/LearnerExpdir/Strat0/Trials0/Split0/LearnerExpdir")+
              """xv $filepath' """),
+            ('a',"view final_learner layer1 activation stats", 
+             """xterm -e sh -c 'cd "_DIRPATH_"; pwd; """+
+             set_filepath("final_learner_layer1_actstats.pmat","Split0/LearnerExpdir")+
+             """myplearn vmat view $filepath' """),        
             ('I',"deepnetplot.py plotRepAndRec final_learner.psave", 
              """xterm -e sh -c 'cd "_DIRPATH_"; pwd; """+
              set_filepath("final_learner.psave","Split0/LearnerExpdir")+

Modified: trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py
===================================================================
--- trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py	2009-07-17 17:04:18 UTC (rev 10276)
+++ trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py	2009-07-17 18:22:50 UTC (rev 10277)
@@ -59,8 +59,9 @@
                                         imgwidth, imgheight, 10, 20)
                 if dataset is not None:
                     print "   Now computing first layer activation statistics"
-                    actpath = os.path.join(dirpath,filename[:-6]+"_layer1_actstats.pmat")
-                    learner.computeAndSaveLayerActivationStats(dataset,1,actpath)
+                    pmatfname = filename[:-6]+"_layer1_actstats.pmat"
+                    learner.computeAndSaveLayerActivationStats(dataset,1,os.path.join(dirpath,pmatfname))
+                    print "   --> "+pmatfname
                 learner.delete()
 
 ############
@@ -70,7 +71,7 @@
 if len(sys.argv)<2:
     print_usage_and_exit()
 
-server_command = "myplearn server"
+server_command = "plearn_exp server"
 serv = launch_plearn_server(command = server_command)
 
 basedir = sys.argv[1]



From nouiz at mail.berlios.de  Mon Jul 20 16:56:17 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 20 Jul 2009 16:56:17 +0200
Subject: [Plearn-commits] r10278 - trunk/python_modules/plearn/parallel
Message-ID: <200907201456.n6KEuHVT018304@sheep.berlios.de>

Author: nouiz
Date: 2009-07-20 16:56:17 +0200 (Mon, 20 Jul 2009)
New Revision: 10278

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
don't make the tmp_dir twice.


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2009-07-17 18:22:50 UTC (rev 10277)
+++ trunk/python_modules/plearn/parallel/dbi.py	2009-07-20 14:56:17 UTC (rev 10278)
@@ -623,7 +623,6 @@
             os.mkdir(self.tmp_dir)
         self.tmp_dir = os.path.join(self.tmp_dir,os.path.split(self.log_dir)[1])
         print "[DBI] All bqtools file will be in ",self.tmp_dir
-        os.mkdir(self.tmp_dir)
         os.chdir(self.tmp_dir)
 
         if self.long:



From nouiz at mail.berlios.de  Mon Jul 20 16:58:59 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 20 Jul 2009 16:58:59 +0200
Subject: [Plearn-commits] r10279 - trunk/plearn/misc
Message-ID: <200907201458.n6KEwxOl018412@sheep.berlios.de>

Author: nouiz
Date: 2009-07-20 16:58:58 +0200 (Mon, 20 Jul 2009)
New Revision: 10279

Modified:
   trunk/plearn/misc/vmatmain.cc
Log:
added check so we don't owerride the src matrix. This can cause trouble in some case as we don't always preload it.


Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2009-07-20 14:56:17 UTC (rev 10278)
+++ trunk/plearn/misc/vmatmain.cc	2009-07-20 14:58:58 UTC (rev 10279)
@@ -659,10 +659,11 @@
             PLERROR("Usage: vmat convert <source> <destination> "
                     "[--mat_to_mem] [--cols=col1,col2,col3,...] [--save_vmat] [--skip-missings] [--precision=N] [--delimiter=CHAR] [--force_float] [--auto_float]");
 
-        string source = argv[2];
-        string destination = argv[3];
+        PPath source = argv[2];
+        PPath destination = argv[3];
         bool mat_to_mem = false;
-
+        if(source==destination)
+            PLERROR("You are overwriting the source. This is not allowed!");
         /**
          * Interpret the following options:
          *



From nouiz at mail.berlios.de  Mon Jul 20 17:01:54 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 20 Jul 2009 17:01:54 +0200
Subject: [Plearn-commits] r10280 - in trunk/plearn: misc vmat
Message-ID: <200907201501.n6KF1sHf018725@sheep.berlios.de>

Author: nouiz
Date: 2009-07-20 17:01:53 +0200 (Mon, 20 Jul 2009)
New Revision: 10280

Modified:
   trunk/plearn/misc/vmatmain.cc
   trunk/plearn/vmat/VMatrix.cc
   trunk/plearn/vmat/VMatrix.h
Log:
implemented pl vmat convert src dst.cmat for some type of matrix. This is not optimal and not for all type of matrix.


Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2009-07-20 14:58:58 UTC (rev 10279)
+++ trunk/plearn/misc/vmatmain.cc	2009-07-20 15:01:53 UTC (rev 10280)
@@ -764,6 +764,8 @@
         else if(ext==".amat")
             // Save strings as strings so they are not lost.
             vm->saveAMAT(destination, true, false, true);
+        else if(ext==".cmat")
+            vm->saveCMAT(destination);
         else if(ext==".pmat")
             vm->savePMAT(destination, force_float, auto_float);
         else if(ext==".dmat")

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2009-07-20 14:58:58 UTC (rev 10279)
+++ trunk/plearn/vmat/VMatrix.cc	2009-07-20 15:01:53 UTC (rev 10280)
@@ -39,6 +39,7 @@
  ******************************************************* */
 
 #include "VMatrix.h"
+#include "CompactFileVMatrix.h"
 #include "DiskVMatrix.h"
 #include "FileVMatrix.h"
 #include "SubVMatrix.h"
@@ -53,6 +54,7 @@
 #include <nspr/prenv.h>
 #include <plearn/math/TMat_maths.h> //!< for dot, powdistance externalProductAcc
 #include <plearn/sys/procinfo.h> //!< for getPid, getUser
+#include <limits>
 
 namespace PLearn {
 using namespace std;
@@ -2154,6 +2156,86 @@
     }
 }
 
+void VMatrix::saveCMAT(const PPath& filename) const
+{
+    PLWARNING("VMatrix::saveCMAT() - NOT FULLY IMPLEMENTED");
+
+    //calculate the datatype needed
+    TVec<StatsCollector> stats = getStats(true);
+    CompactFileVMatrix n = CompactFileVMatrix();
+    int max_bits=0;
+    for(int i=0;i<stats.size();i++){
+        StatsCollector stat = stats[i];
+        if(! stat.isinteger())
+            PLERROR("VMatrix::saveCMAT() currently the source need to contain only integer.");
+        if(stat.min()>=0){
+            int bits=ceil(sqrt(stat.max()));
+            if(max_bits<bits)max_bits=bits;
+        }else{
+            PLERROR("not implemented to store negatif number.");
+        }
+        
+    }
+    //example 12000000 u:784:1:8 u:1:1:8
+    //write the header
+     if(max_bits>8) PLERROR("VMatrix::saveCMAT() currently we convert to cmat with a maximum of 8 bits by fields!");
+    if(max_bits > 1 && max_bits<8){
+        max_bits=8;
+        PLWARNING("VMatrix::saveCMAT() currently when we need less then 8 bits(except for 1), we upgrade to 8 bits.");
+    }
+    if(max_bits==0){
+        PLERROR("VMatrix::saveCMAT() - their was only 0 in the matrix! This is not supported as we don't think this can happen in real case!");
+    }
+    //write the data
+    if(max_bits==8){
+        PStream out = openFile(filename, PStream::raw_ascii, "w");
+        out<<length()<<" u:"<<width()<<":1:"<<max_bits<<endl;
+        Vec v(width());
+        for(int i=0;i<length();i++){
+            getRow(i,v);
+            for(int j=0;j<width();j++){
+                out.put((char)v[j]);
+            }
+        }
+    }else if(max_bits==1){
+        PStream out = openFile(filename, PStream::raw_ascii, "w");
+        int w2=width()%8;
+        int w1=width()-w2;
+        PLCHECK(w2+w1==width());
+        PLCHECK(w1%8==0);
+        PLCHECK(w1>0 && w2>=0);
+        out<<length()<<" u:"<<w1<<":1:"<<max_bits;
+        if(w2!=0)
+            out<<" u:"<<w2<<":1:8";
+        out<<endl;
+        Vec v(width());
+
+        for(int i=0;i<length();i++){
+            getRow(i,v);
+            int j;
+            for(j=0;j<w1;){
+                char c=0;
+                for(int k=0;k<8;j++,k++){
+                    c=c<<1;
+                    c|=((bool)v[j]);
+                }
+                //revert the bits
+                char value=c;
+                value = (value & 0x0f) << 4 | (value & 0xf0) >> 4;
+                value = (value & 0x33) << 2 | (value & 0xcc) >> 2;
+                value = (value & 0x55) << 1 | (value & 0xaa) >> 1;
+                out.put(value);
+            }
+            PLCHECK(width()-j==w2);
+            for(;j<width();j++){
+                out.put((char)v[j]);
+            }
+        }
+    }
+    else
+        PLERROR("VMatrix::saveCMAT() - %d bits are not supported!",max_bits);
+    pout<<"generated the file " <<filename <<endl;
+}
 ///////////////////
 // accumulateXtY //
 ///////////////////

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2009-07-20 14:58:58 UTC (rev 10279)
+++ trunk/plearn/vmat/VMatrix.h	2009-07-20 15:01:53 UTC (rev 10280)
@@ -343,6 +343,8 @@
     virtual void saveAMAT(const PPath& amatfile, bool verbose = true,
                           bool no_header = false, bool save_strings = false) const;
 
+    virtual void saveCMAT(const PPath& filename) const;
+
     /// Return true if the matrix is writable, i.e. if put()-like member
     /// functions can succeed.
     inline bool isWritable() const { return writable; }



From nouiz at mail.berlios.de  Mon Jul 20 17:26:20 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 20 Jul 2009 17:26:20 +0200
Subject: [Plearn-commits] r10281 - trunk/python_modules/plearn/parallel
Message-ID: <200907201526.n6KFQKqP021314@sheep.berlios.de>

Author: nouiz
Date: 2009-07-20 17:26:20 +0200 (Mon, 20 Jul 2009)
New Revision: 10281

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
fix the order of creation of the tmp_dir.


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2009-07-20 15:01:53 UTC (rev 10280)
+++ trunk/python_modules/plearn/parallel/dbi.py	2009-07-20 15:26:20 UTC (rev 10281)
@@ -619,9 +619,9 @@
             raise DBIError("[DBI] ERROR: The log file(%s) and the log dir(%s) should not have the symbol ','"%(self.log_file,self.log_dir))
 
         # create directory in which all the temp files will be created
+        self.tmp_dir = os.path.join(self.tmp_dir,os.path.split(self.log_dir)[1])
         if not os.path.exists(self.tmp_dir):
             os.mkdir(self.tmp_dir)
-        self.tmp_dir = os.path.join(self.tmp_dir,os.path.split(self.log_dir)[1])
         print "[DBI] All bqtools file will be in ",self.tmp_dir
         os.chdir(self.tmp_dir)
 



From plearner at mail.berlios.de  Tue Jul 21 23:22:48 2009
From: plearner at mail.berlios.de (plearner at BerliOS)
Date: Tue, 21 Jul 2009 23:22:48 +0200
Subject: [Plearn-commits] r10282 - in trunk: plearn/math
	plearn_learners/generic/EXPERIMENTAL scripts/EXPERIMENTAL
Message-ID: <200907212122.n6LLMmpf022073@sheep.berlios.de>

Author: plearner
Date: 2009-07-21 23:22:48 +0200 (Tue, 21 Jul 2009)
New Revision: 10282

Added:
   trunk/scripts/EXPERIMENTAL/displaybihist.py
   trunk/scripts/EXPERIMENTAL/displaystatscol.py
Modified:
   trunk/plearn/math/VecStatsCollector.cc
   trunk/plearn/math/VecStatsCollector.h
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h
   trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py
Log:
Exported a number of methods in VecStatscollector for python extension / remote call.
Also added a few experimental display scripts.


Modified: trunk/plearn/math/VecStatsCollector.cc
===================================================================
--- trunk/plearn/math/VecStatsCollector.cc	2009-07-20 15:26:20 UTC (rev 10281)
+++ trunk/plearn/math/VecStatsCollector.cc	2009-07-21 21:22:48 UTC (rev 10282)
@@ -216,6 +216,36 @@
          RetDoc ("The vector of means for each field.")));
 
     declareMethod(
+        rmm, "getVariance", &VecStatsCollector::getVariance,
+        (BodyDoc("Return the vector of variances of all field..\n"),
+         RetDoc ("The vector of variance for each field.")));
+
+    declareMethod(
+        rmm, "getStdDev", &VecStatsCollector::getStdDev,
+        (BodyDoc("Return the vector of standard deviations of all field..\n"),
+         RetDoc ("The vector of standard deviation for each field.")));
+
+    declareMethod(
+        rmm, "getStdError", &VecStatsCollector::getStdError,
+        (BodyDoc("Return the vector of standard error of all field..\n"),
+         RetDoc ("The vector of standard error for each field.")));
+
+    declareMethod(
+        rmm, "getXtX", &VecStatsCollector::getXtX,
+        (BodyDoc(""),
+         RetDoc ("Return the matrix XtX ")));
+
+    declareMethod(
+        rmm, "getCovariance", &VecStatsCollector::remote_getCovariance,
+        (BodyDoc(""),
+         RetDoc ("Returns the (centered) covariance matrix")));
+    
+    declareMethod(
+        rmm, "getCorrelation", &VecStatsCollector::getCorrelation,
+        (BodyDoc(""),
+         RetDoc ("Returns the correlation matrix")));
+
+    declareMethod(
         rmm, "setFieldNames", &VecStatsCollector::setFieldNames,
         (BodyDoc("Set field names.\n"),
          ArgDoc ("fieldnames", 

Modified: trunk/plearn/math/VecStatsCollector.h
===================================================================
--- trunk/plearn/math/VecStatsCollector.h	2009-07-20 15:26:20 UTC (rev 10281)
+++ trunk/plearn/math/VecStatsCollector.h	2009-07-21 21:22:48 UTC (rev 10282)
@@ -226,9 +226,8 @@
     }
 
     //! Remote version of getMean.
-    Vec remote_getMean() {
-        return getMean();
-    }
+    Vec remote_getMean() 
+    { return getMean(); }
   
     //! Store the empirical mean in the given vec (which is resized)
     void getMean(Vec& mean) const;
@@ -253,6 +252,10 @@
     //! coefficient is not exactly the sum of weights.
     void getCovariance(Mat& covar) const;
     Mat getCovariance() const;
+
+    //! Remote version of getCovariance.
+    Mat remote_getCovariance() 
+    { return getCovariance(); }
   
     //! returns correlation matrix
     Mat getCorrelation() const;

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2009-07-20 15:26:20 UTC (rev 10281)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2009-07-21 21:22:48 UTC (rev 10282)
@@ -43,6 +43,9 @@
 #include <plearn/vmat/ConcatColumnsVMatrix.h>
 #include <plearn/var/ConcatColumnsVariable.h>
 #include <plearn/io/load_and_save.h>
+#include <plearn/io/MatIO.h>
+#include <plearn/math/PRandom.h>
+#include <plearn/math/VecStatsCollector.h>
 
 namespace PLearn {
 using namespace std;
@@ -237,10 +240,28 @@
     declareMethod(rmm,
                    "computeAndSaveLayerActivationStats",
                    &DeepReconstructorNet::computeAndSaveLayerActivationStats,
-                   (BodyDoc(""),
+                   (BodyDoc("computeAndSaveLayerActivationStats will compute statistics (univariate and bivariate)\n"
+                            "of the post-nonlinearity activations of a hidden layer on a given dataset:\n"
+                            "\n"
+                            "  - It will compute a matrix of simple statistics for all units of that layer and \n"
+                            "    save it in filebasename_all_simplestats.pmat \n"
+                            "  - It will also select a subset of the units made of the first nfirstunits units \n"
+                            "    and of notherunits randomly selected units among the others.\n"
+                            "    For this selected subset more extensive statistics are computed and saved:\n"
+                            "      + a VecStatsCollector collecting univariate histograms and bivariate\n"
+                            "        covariance will be saved in filebasename_selected_statscol.psave\n"
+                            "      + a matrix of bivariate histograms will be saved as \n"
+                            "        filebasename_selected_bihist.pmat \n"
+                            "        Row i*nselectedunits+j of that matrix will contain the 5*5 bivariate\n"
+                            "        histogram for the activations of selected_unit_i vs selected_unit_j.\n"
+                            "\n"
+                            "which_layer: 1 means first hidden layer, 2, second hidden layer, etc... \n"),
                     ArgDoc("dataset", "the data vmatrix to compute activaitons on"),
                     ArgDoc("which_layer", "the layer (1 for first hidden layer)"),
-                    ArgDoc("pmatfilepath", ".pmat file where to save computed stats")));
+                    ArgDoc("filebasename", "basename for generated files"),
+                    ArgDoc("nfirstunits", "number of first units to select for extensive stats."),
+                    ArgDoc("notherunits", "number of other units to select for extensive stats.")
+                    ));
 
 }
 
@@ -833,25 +854,84 @@
     }
 }
 
+/**
+computeAndSaveLayerActivationStats will compute statistics (univariate and bivariate) 
+of the post-nonlinearity activations of a hidden layer on a given dataset:
 
-void DeepReconstructorNet::computeAndSaveLayerActivationStats(VMat dataset, int which_layer, const string& pmatfilepath)
+- It will compute a matrix of simple statistics for all units of that layer and 
+  save it in filebasename_all_simplestats.pmat
+- It will also select a subset of the units made of the first nfirstunits units 
+  and of notherunits randomly selected units among the others.
+  For this selected subset more extensive statistics are computed and saved:
+    + a VecStatsCollector collecting univariate histograms and bivariate covariance 
+      will be saved in filebasename_selected_statscol.psave
+    + a matrix of bivariate histograms will be saved as 
+      filebasename_selected_bihist.pmat
+      Row i*nselectedunits+j of that matrix will contain the 5*5 bivariate
+      histogram for the activations of selected_unit_i vs selected_unit_j.
+
+which_layer: 1 means first hidden layer, 2, second hidden layer, etc... 
+**/
+
+void DeepReconstructorNet::computeAndSaveLayerActivationStats(VMat dataset, int which_layer, const string& filebasename, int nfirstunits, int notherunits)
 {
     int len = dataset.length();
     Var layer = layers[which_layer];
     int layersize = layer->size();
     Mat actstats(1+layersize,6);
     actstats.fill(0.);
+    TVec<string> actstatsfields(6);
+    actstatsfields[0] = "E[act]";
+    actstatsfields[1] = "E[act^2]";
+    actstatsfields[2] = "[0,.25)";
+    actstatsfields[3] = "[.25,.50)";
+    actstatsfields[4] = "[.50,.75)";
+    actstatsfields[5] = "[.75,1.00]";
 
+    // build the list of indexes of the units for which we want to keep bivariate statistics
+    // we will take the nfirstunits first units, and notherunits at random from the rest.
+    // resulting list of indices will be put in unitindexes.
+    TVec<int> unitindexes(0,nfirstunits-1,1);
+    if(notherunits>0)
+    {
+        TVec<int> randomindexes(notherunits, layersize, 1);
+        PRandom rnd;
+        rnd.shuffleElements(randomindexes);
+        randomindexes = randomindexes.subVec(0,notherunits);
+        unitindexes = concat(unitindexes, randomindexes);
+    }
+    int nselectunits = unitindexes.length();
+    Vec selectedactivations(nselectunits); // will hold the activations of the selected units
+
+    TVec<string> fieldnames(nselectunits);
+    for(int k=0; k<nselectunits; k++)
+        fieldnames[k] = tostring(unitindexes[k]);
+    VecStatsCollector stcol;
+    stcol.maxnvalues = 20;
+    stcol.compute_covariance = true;
+    stcol.setFieldNames(fieldnames);
+    stcol.build();
+
+    const int nbins = 5;
+    // bivariate nbins*nbins histograms will be computed for each of the nselectunits*nselectunits pairs of units
+    Mat bihist(nselectunits*nselectunits, nbins*nbins);
+    bihist.fill(0.);
+    TVec<string> bihistfields(nbins*nbins);
+    for(int k=0; k<nbins*nbins; k++)
+        bihistfields[k] = tostring(1+k/nbins)+","+tostring(1+k%nbins);
+        
     Vec input;
     Vec target;
     real weight;
     Vec output;
 
-    for(int i=0; i<len; i++)
+    for(int t=0; t<len; t++)
     {
-        dataset.getExample(i, input, target, weight);
+        dataset.getExample(t, input, target, weight);
         computeOutput(input, output);
         Vec activations = layer->value;
+        
+        // collect simple univariate stats for all units
         for(int k=0; k<layersize; k++)
         {
             real act = activations[k];
@@ -862,15 +942,56 @@
             else if(act<0.50)
                 actstats(k+1,3)++;
             else if(act<0.75)
-                actstats(k+1,4)++;                
+                actstats(k+1,4)++;   
             else
                 actstats(k+1,5)++;
-        }        
+        }
+
+        // collect more extensive stats for selected units
+        for(int k=0; k<nselectunits; k++)
+            selectedactivations[k] = activations[unitindexes[k]];
+
+        stcol.update(selectedactivations);
+
+        // collect bivariate histograms for selected units
+        for(int i=0; i<nselectunits; i++)
+        {
+            real act_i = selectedactivations[i];
+            
+            int binpos_i = int(act_i*nbins);
+            if(binpos_i<0)
+                binpos_i = 0;
+            else if(binpos_i>=nbins)
+                binpos_i = nbins-1;
+
+            for(int j=0; j<nselectunits; j++)
+            {
+                real act_j = selectedactivations[j];
+                int binpos_j = int(act_j*nbins);
+                if(binpos_j<0)
+                    binpos_j = 0;
+                else if(binpos_j>=nbins)
+                    binpos_j = nbins-1;
+                
+                bihist(i*nselectunits+j, nbins*binpos_i+binpos_j)++;
+            }
+        }
     }
+
+    stcol.finalize();
+    PLearn::save(filebasename+"_selected_statscol.psave", stcol);
+
+    bihist *= 1./len;
+    string pmatfilename = filebasename+"_selected_bihist.pmat";
+    savePMat(pmatfilename, bihist);
+    savePMatFieldnames(pmatfilename, bihistfields);
+
     actstats *= 1./len;
     Vec meanvec = actstats(0);
     columnMean(actstats.subMat(1,0,layersize,6), meanvec);
-    savePMat(pmatfilepath, actstats);
+    pmatfilename = filebasename+"_all_simplestats.pmat";
+    savePMat(pmatfilename, actstats);
+    savePMatFieldnames(pmatfilename, actstatsfields);
 }
 
 void DeepReconstructorNet::computeOutput(const Vec& input, Vec& output) const

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h	2009-07-20 15:26:20 UTC (rev 10281)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h	2009-07-21 21:22:48 UTC (rev 10282)
@@ -206,7 +206,7 @@
     Mat fpropOneLayer(int layer);
     Mat reconstructOneLayer(int layer);
        
-    void computeAndSaveLayerActivationStats(VMat dataset, int which_layer, const string& pmatfilepath);
+    void computeAndSaveLayerActivationStats(VMat dataset, int which_layer, const string& filebasename, int nfirstunits=10, int notherunits=10);
 
     // *** SUBCLASS WRITING: ***
     // While in general not necessary, in case of particular needs

Modified: trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py
===================================================================
--- trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py	2009-07-20 15:26:20 UTC (rev 10281)
+++ trunk/scripts/EXPERIMENTAL/deepnet_collect_filters.py	2009-07-21 21:22:48 UTC (rev 10282)
@@ -42,7 +42,7 @@
 
     for dirpath, dirs, files in os.walk(basedir):
         for filename in files:
-            if filename.endswith(".psave") and "learner" in filename:
+            if filename.endswith("learner.psave"):
                 filepath = os.path.join(dirpath,filename)
                 print 
                 print "*** EXTRACTING FILTERS FROM "+filepath
@@ -59,9 +59,9 @@
                                         imgwidth, imgheight, 10, 20)
                 if dataset is not None:
                     print "   Now computing first layer activation statistics"
-                    pmatfname = filename[:-6]+"_layer1_actstats.pmat"
-                    learner.computeAndSaveLayerActivationStats(dataset,1,os.path.join(dirpath,pmatfname))
-                    print "   --> "+pmatfname
+                    basename = filename[:-6]+"_layer1act"
+                    learner.computeAndSaveLayerActivationStats(dataset,1,os.path.join(dirpath,basename), 100, 0)
+                    print "   --> "+basename+"_*"
                 learner.delete()
 
 ############

Added: trunk/scripts/EXPERIMENTAL/displaybihist.py
===================================================================
--- trunk/scripts/EXPERIMENTAL/displaybihist.py	2009-07-20 15:26:20 UTC (rev 10281)
+++ trunk/scripts/EXPERIMENTAL/displaybihist.py	2009-07-21 21:22:48 UTC (rev 10282)
@@ -0,0 +1,179 @@
+#!/usr/bin/env python
+
+import sys
+import os
+import os.path
+import math
+
+import matplotlib.pylab as mpl
+
+from numpy import array, arange, diag, outer
+
+from plearn.vmat.PMat import load_pmat_as_array
+from plearn.plotting.netplot import plotRowsAsImages
+
+class showBihistRows:
+
+    def __init__(self, X, 
+                 img_height,
+                 img_width,
+                 nrows = 10, ncols = 20,
+                 startidx = 0,
+                 figtitle="",
+                 luminance_scale_mode=0,
+                 colormaps = [mpl.cm.jet, mpl.cm.gray],
+                 vmin = None, vmax = None,
+                 transpose_img=False):
+
+        self.X = X
+        self.img_height = img_height
+        self.img_width = img_width
+        self.nrows = nrows
+        self.ncols = ncols
+        self.figtitle = figtitle
+        self.startidx = startidx
+
+        # appearance control
+        self.luminance_scale_mode = luminance_scale_mode
+        self.interpolation = 'nearest'
+        self.colormaps = colormaps
+        self.cmapchoice = 0
+        self.show_colorbar = True
+        self.disable_ticks = True
+        self.vmin = vmin
+        self.vmax = vmax
+        self.transpose_img = transpose_img
+
+        # plot it
+        self.draw()      
+        mpl.connect('key_press_event', self.keyPressed)
+        # connect('button_press_event', self.__clicked)
+
+        # start interactive loop
+        mpl.show()
+
+    def draw(self):
+        # print "Start plotting..."
+        mpl.clf()
+        endidx = min(self.startidx+self.nrows*self.ncols, len(self.X))        
+        title = self.figtitle+" ("+str(self.startidx)+" ... "+str(endidx-1)+")"
+        plotRowsAsImages(self.X[self.startidx : endidx],
+                         img_height = self.img_height,
+                         img_width = self.img_width,
+                         nrows = self.nrows,
+                         ncols = self.ncols,
+                         figtitle = title,
+                         luminance_scale_mode = self.luminance_scale_mode,
+                         show_colorbar = self.show_colorbar,
+                         disable_ticks = self.disable_ticks,
+                         colormap = self.colormaps[self.cmapchoice],
+                         vmin = self.vmin,
+                         vmax = self.vmax,
+                         transpose_img = self.transpose_img
+                         )
+        # print "Plotted,"
+        mpl.draw()
+        # print "Drawn."
+        
+
+    def plotNext(self):
+        self.startidx += self.nrows*self.ncols
+        if self.startidx >= len(self.X):
+            self.startidx = 0
+        self.draw()
+
+    def plotPrev(self):
+        if self.startidx>0:
+            self.startidx -= self.nrows*self.ncols
+        else:
+            self.startidx = len(self.X)-self.nrows*self.ncols
+        if self.startidx<0:
+            self.startidx = 0            
+        self.draw()
+
+    def keyPressed(self, event):
+        char = event.key
+        print 'Pressed',char
+        if char == 'c':
+            self.changeColorMap()
+        elif char == 'right':
+            self.plotNext()
+        elif char == 'left':
+            self.plotPrev()
+        elif char == 'b':
+            self.show_colorbar = not self.show_colorbar
+            self.draw()
+        elif char == 't':
+            self.transpose_img = not self.transpose_img
+            self.draw()
+        elif char == 'i':
+            self.disable_ticks = not self.disable_ticks
+            self.draw()
+        elif char == 's':
+            self.luminance_scale_mode = (self.luminance_scale_mode+1)%3
+            self.draw()
+        elif char == '':
+            pass
+        else:
+            print """
+            *******************************************************
+            * KEYS
+            *  right : show next filters
+            *  left  : show previous filters
+            *  t     : tranpose images
+            *  c     : change colormap
+            *  s     : cycle through luminance scale mode
+            *          0 independent luminance scaling for each
+            *          1 min-max luminance scaling across display
+            *          2 +-min or +- max (largest range)
+            *  b     : toggle showing colorbar 
+            *  i     : toggle showing ticks
+            *
+            * Close window to stop.
+            *******************************************************
+            """
+
+    def changeColorMap(self):
+        self.cmapchoice = (self.cmapchoice+1)%len(self.colormaps)
+        self.draw()
+
+    
+def display_bihists(m):
+    nbins = int(math.sqrt(m.shape[1]))
+    nvars = int(math.sqrt(m.shape[0]))
+    
+    m2 = m[:,:]
+    hists = [ diag(m[i*nvars+i].reshape(nbins,nbins)) for i in xrange(nvars) ] 
+    for i in xrange(nvars):        
+        for j in xrange(nvars):
+            bihist = m2[i*nvars+j].reshape(nbins,nbins)
+            if i==j:
+                bihist.fill(1.)
+            else:
+                bihist[:,:] = bihist-outer(hists[i],hists[j])
+                
+    showBihistRows(m2, nbins, nbins,
+                     nrows = 10, ncols = 20,
+                     startidx = 0,
+                     figtitle="",
+                     luminance_scale_mode=1,
+                     vmin = -1., vmax = 1.,
+                     transpose_img=False)
+
+def print_usage_and_exit():
+    print "Usage : displaybihist.py bihists.pmat"
+    print "  will graphically display the bivariate histograms in the pmat."
+    sys.exit()
+
+
+############
+### main ###
+############
+
+if len(sys.argv)<2:
+    print_usage_and_exit()
+
+pmatfname = sys.argv[1]
+m = load_pmat_as_array(pmatfname)
+
+display_bihists(m)


Property changes on: trunk/scripts/EXPERIMENTAL/displaybihist.py
___________________________________________________________________
Name: svn:executable
   + *

Added: trunk/scripts/EXPERIMENTAL/displaystatscol.py
===================================================================
--- trunk/scripts/EXPERIMENTAL/displaystatscol.py	2009-07-20 15:26:20 UTC (rev 10281)
+++ trunk/scripts/EXPERIMENTAL/displaystatscol.py	2009-07-21 21:22:48 UTC (rev 10282)
@@ -0,0 +1,93 @@
+#!/usr/bin/env python
+
+import sys
+import os
+import os.path
+
+from numpy import array, arange, diag, outer
+import matplotlib.pylab as plt
+
+# chose a non-GUI backend
+# matplotlib.use( 'Agg' )
+
+def plot_offdiag_histogram(m, xlabel="historgram of off-diagonal values", nbins=10):
+    vals = []
+    for i in xrange(m.shape[0]):
+        for j in xrange(m.shape[1]):
+            if i!=j:
+                vals.append(m[i,j])
+    n, bins, patches = plt.hist(array(vals), nbins, normed=1, facecolor='green', alpha=0.75)
+    plt.xlabel(xlabel)
+    plt.grid(True)
+    
+def plot_diag_histogram(m, xlabel="historgram of diagonal values", nbins=10):
+    vals = diag(m)
+    n, bins, patches = plt.hist(vals, nbins, normed=1, facecolor='green', alpha=0.75)
+    plt.xlabel(xlabel)
+    plt.grid(True)
+    
+def plot_histogram(vals, xlabel="historgram", nbins=10):
+    n, bins, patches = plt.hist(array(vals), nbins, normed=1, facecolor='green', alpha=0.75)
+    plt.xlabel(xlabel)
+    plt.grid(True)
+
+    
+def display_vecstascollector_summary(stcol):
+    n = stcol.getStat("N[0]")
+    print n
+    mean = stcol.getMean()
+    stddev = stcol.getStdDev()
+    ucov = (1.0/n)*stcol.getXtX()
+    cov = stcol.getCovariance()
+    corr = stcol.getCorrelation()
+    pxy_px_py = ucov-outer(mean,mean)
+    
+    plt.subplot(4,2,1)
+    plt.errorbar(arange(len(mean)),mean,yerr=stddev)
+    plt.title("activations mean and stddev")
+    plt.subplot(4,2,2)
+    plot_histogram(mean, "activations mean")
+
+    plt.subplot(4,2,3)
+    plot_offdiag_histogram(ucov, "uncentered covariances")
+    plt.subplot(4,2,4)
+    plot_diag_histogram(ucov, "uncentered variances")
+
+    plt.subplot(4,2,5)
+    plot_offdiag_histogram(cov, "covariances")
+    plt.subplot(4,2,6)
+    plot_diag_histogram(cov, "variances")
+
+    plt.subplot(4,2,7)
+    plot_offdiag_histogram(corr, "correlations")
+    plt.subplot(4,2,8)
+    plot_histogram(stddev, "stddevs")
+
+    plt.show()
+    
+    
+
+################
+### methods ###
+################
+
+def print_usage_and_exit():
+    print "Usage : displaystatscol.py statscol.psave"
+    print "  will graphically display some of the statistics contained in a saved stats collector."
+    sys.exit()
+
+
+############
+### main ###
+############
+
+if len(sys.argv)<2:
+    print_usage_and_exit()
+
+import plearn.pyext.plext as pl
+
+stfname = sys.argv[1]
+stcol = pl.loadObject(stfname)
+
+display_vecstascollector_summary(stcol)
+



From nouiz at mail.berlios.de  Wed Jul 22 17:20:56 2009
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 22 Jul 2009 17:20:56 +0200
Subject: [Plearn-commits] r10283 - trunk/plearn/misc
Message-ID: <200907221520.n6MFKu50029399@sheep.berlios.de>

Author: nouiz
Date: 2009-07-22 17:20:55 +0200 (Wed, 22 Jul 2009)
New Revision: 10283

Modified:
   trunk/plearn/misc/vmatmain.cc
Log:
fix a PLCHECK and generate a PLERROR instead.


Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2009-07-21 21:22:48 UTC (rev 10282)
+++ trunk/plearn/misc/vmatmain.cc	2009-07-22 15:20:55 UTC (rev 10283)
@@ -726,7 +726,8 @@
                 precision = toint(curopt.substr(12));
             }
             else if (curopt.substr(0,12) == "--delimiter=") {
-                PLCHECK(ext==".cvs");
+                if(ext!=".csv")
+                    PLERROR("Vmat convert: the --delimiter option is supported only with .csv destination file. You have a '%s' extension.",ext.c_str());
                 delimiter = curopt.substr(12);
             }
             else if (curopt == "--convert-date")



From tihocan at mail.berlios.de  Tue Jul 28 17:23:37 2009
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Tue, 28 Jul 2009 17:23:37 +0200
Subject: [Plearn-commits] r10284 - trunk/python_modules/plearn/parallel
Message-ID: <200907281523.n6SFNbCv011679@sheep.berlios.de>

Author: tihocan
Date: 2009-07-28 17:23:36 +0200 (Tue, 28 Jul 2009)
New Revision: 10284

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
Fixed bug on mammouth: the TMP_DBI directory was not created

Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2009-07-22 15:20:55 UTC (rev 10283)
+++ trunk/python_modules/plearn/parallel/dbi.py	2009-07-28 15:23:36 UTC (rev 10284)
@@ -621,7 +621,7 @@
         # create directory in which all the temp files will be created
         self.tmp_dir = os.path.join(self.tmp_dir,os.path.split(self.log_dir)[1])
         if not os.path.exists(self.tmp_dir):
-            os.mkdir(self.tmp_dir)
+            os.makedirs(self.tmp_dir)
         print "[DBI] All bqtools file will be in ",self.tmp_dir
         os.chdir(self.tmp_dir)
 



From tihocan at mail.berlios.de  Fri Jul 31 17:37:32 2009
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 31 Jul 2009 17:37:32 +0200
Subject: [Plearn-commits] r10285 - trunk/python_modules/plearn/parallel
Message-ID: <200907311537.n6VFbWO2010680@sheep.berlios.de>

Author: tihocan
Date: 2009-07-31 17:37:26 +0200 (Fri, 31 Jul 2009)
New Revision: 10285

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
Couple fixes for dbidispatch --cluster, still not working though

Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2009-07-28 15:23:36 UTC (rev 10284)
+++ trunk/python_modules/plearn/parallel/dbi.py	2009-07-31 15:37:26 UTC (rev 10285)
@@ -217,7 +217,7 @@
         """
         n=task_id-1
         base=self.tasks[n].log_file
-        if self.base_tasks_log_file:
+        if self.base_tasks_log_file and self.base_tasks_log_file[n]:
             base = self.base_tasks_log_file[n]
             base=os.path.join(self.log_dir,base)
             self.check_path(base)
@@ -512,7 +512,7 @@
         if self.interruptible:
             command += " --interruptible"
         if self.cpu>0:
-            command += " --cpu "+self.cpu
+            command += " --cpu " + str(self.cpu)
         if self.os:
             command += " --os "+self.os
         command += " --execute '"+ filename + "'"
@@ -686,7 +686,7 @@
         logfiles_file = open( 'logfiles', 'w' )
         assert len(self.stdouts)==len(self.stderrs)==0
         for task in self.tasks:
-            #-4 as we will happend .err or .out
+            #-4 as we will append .err or .out.
             base=self.get_file_redirection(task.id)[0][:-4]
             self.check_path(base)
             tasks_file.write( ';'.join(task.commands) + '\n' )



