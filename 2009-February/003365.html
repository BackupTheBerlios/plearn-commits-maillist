<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9925 - in trunk: python_modules/plearn/parallel	scripts
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2009-February/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9925%20-%20in%20trunk%3A%20python_modules/plearn/parallel%0A%09scripts&In-Reply-To=%3C200902102134.n1ALYrCS010513%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003364.html">
   <LINK REL="Next"  HREF="003366.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9925 - in trunk: python_modules/plearn/parallel	scripts</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9925%20-%20in%20trunk%3A%20python_modules/plearn/parallel%0A%09scripts&In-Reply-To=%3C200902102134.n1ALYrCS010513%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9925 - in trunk: python_modules/plearn/parallel	scripts">nouiz at mail.berlios.de
       </A><BR>
    <I>Tue Feb 10 22:34:53 CET 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="003364.html">[Plearn-commits] r9924 - trunk/plearn_learners_experimental
</A></li>
        <LI>Next message: <A HREF="003366.html">[Plearn-commits] r9926 - trunk/plearn_learners_experimental
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3365">[ date ]</a>
              <a href="thread.html#3365">[ thread ]</a>
              <a href="subject.html#3365">[ subject ]</a>
              <a href="author.html#3365">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2009-02-10 22:34:53 +0100 (Tue, 10 Feb 2009)
New Revision: 9925

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
   trunk/scripts/dbidispatch
Log:
-added the dbidispatch option --keep_failed_jobs_in_queue for condor backend
-restructured to remove duplicate code.


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2009-02-10 18:13:13 UTC (rev 9924)
+++ trunk/python_modules/plearn/parallel/dbi.py	2009-02-10 21:34:53 UTC (rev 9925)
@@ -797,6 +797,7 @@
         self.machine = []
         self.machines = []
         self.to_all = False
+        self.keep_failed_jobs_in_queue = False
 
         DBIBase.__init__(self, commands, **args)
 
@@ -1132,47 +1133,54 @@
 
             os.chmod(launch_tmp_file, 0755)
             os.rename(launch_tmp_file, self.launch_file)
-
-    def run_dag(self):
-        if self.to_all:
-            raise DBIError(&quot;[DBI] ERROR: condor backend don't support the option --to_all and a maximum number of process&quot;)
-        condor_submit_fd = open( self.condor_submit_file, 'w' )
-
-        self.log_file = os.path.join(&quot;/tmp/bastienf/dbidispatch&quot;,self.log_dir)
-        os.system('mkdir -p ' + self.log_file)
-        self.log_file = os.path.join(self.log_file,&quot;condor.log&quot;)
-
-        condor_submit_fd.write( dedent('''\
+    def print_common_condor_submit(self, fd, output, error, arguments=None):
+        fd.write( dedent('''\
                 executable     = %s
                 universe       = %s
                 requirements   = %s
-                output         = $(stdout)
-                error          = $(stderr)
+                output         = %s
+                error          = %s
                 log            = %s
                 getenv         = %s
                 nice_user      = %s
-                arguments      = $(args)
                 ''' % (self.launch_file, self.universe, self.req,
+                       output,
+                       error,
                        self.log_file,str(self.getenv),str(self.nice))))
+        if arguments:
+            fd.write('arguments      = '+arguments+'\n')
+        if self.keep_failed_jobs_in_queue:
+            fd.write('leave_in_queue = (ExitCode!=0)\n')
         if self.mem&gt;0:
             #condor need value in Kb
-            condor_submit_fd.write('ImageSize      = %d\n'%(self.mem))
+            fd.write('ImageSize      = %d\n'%(self.mem))
 
         if self.files: #ON_EXIT_OR_EVICT
-            condor_submit_fd.write( dedent('''\
+            fd.write( dedent('''\
                 when_to_transfer_output = ON_EXIT
                 should_transfer_files   = Yes
                 transfer_input_files    = %s
                 '''%(self.files+','+self.launch_file+','+self.tasks[0].commands[0].split()[0]))) # no directory
         if self.env:
-            condor_submit_fd.write('environment    = '+self.env+'\n')
+            fd.write('environment    = '+self.env+'\n')
         if self.raw:
-            condor_submit_fd.write( self.raw+'\n')
+            fd.write( self.raw+'\n')
         if self.rank:
-            condor_submit_fd.write( dedent('''\
+            fd.write( dedent('''\
                 rank = %s
                 ''' %(self.rank)))
 
+        
+    def run_dag(self):
+        if self.to_all:
+            raise DBIError(&quot;[DBI] ERROR: condor backend don't support the option --to_all and a maximum number of process&quot;)
+        condor_submit_fd = open( self.condor_submit_file, 'w' )
+
+        self.log_file = os.path.join(&quot;/tmp/bastienf/dbidispatch&quot;,self.log_dir)
+        os.system('mkdir -p ' + self.log_file)
+        self.log_file = os.path.join(self.log_file,&quot;condor.log&quot;)
+        self.print_common_condor_submit(condor_submit_fd, &quot;$(stdout)&quot;, &quot;$(stderr)&quot;,&quot;$(args)&quot;)
+
         condor_submit_fd.write(&quot;\nqueue\n&quot;)
         condor_submit_fd.close()
 
@@ -1227,47 +1235,16 @@
 
 
         condor_submit_fd = open( self.condor_submit_file, 'w' )
-
         self.log_file= os.path.join(self.log_dir,&quot;condor.log&quot;)
+        self.print_common_condor_submit(condor_submit_fd, self.log_dir+&quot;/$(Process).out&quot;, self.log_dir+&quot;/$(Process).error&quot;)
 
-        condor_submit_fd.write( dedent('''\
-                executable     = %s
-                universe       = %s
-                requirements   = %s
-                output         = %s/$(Process).out
-                error          = %s/$(Process).error
-                log            = %s
-                getenv         = %s
-                nice_user      = %s
-                ''' % (self.launch_file, self.universe, self.req,
-                       self.log_dir,
-                       self.log_dir,
-                       self.log_file,str(self.getenv),str(self.nice))))
         if self.pkdilly:
             condor_submit_fd.write(dedent(&quot;&quot;&quot;
-            stream_error = True
-            stream_output = True
-            transfer_executable = True
+            stream_error            = True
+            stream_output           = True
+            transfer_executable     = True
             when_to_transfer_output = ON_EXIT
             &quot;&quot;&quot;))
-        if self.mem&gt;0:
-            #condor need value in Kb
-            condor_submit_fd.write('ImageSize      = %d\n'%(self.mem))
-
-        if self.files: #ON_EXIT_OR_EVICT
-            condor_submit_fd.write( dedent('''\
-                when_to_transfer_output = ON_EXIT
-                should_transfer_files   = Yes
-                transfer_input_files    = %s
-                '''%(self.files+','+self.launch_file+','+self.tasks[0].commands[0].split()[0]))) # no directory
-        if self.env:
-            condor_submit_fd.write('environment    = '+self.env+'\n')
-        if self.raw:
-            condor_submit_fd.write( self.raw+'\n')
-        if self.rank:
-            condor_submit_fd.write( dedent('''\
-                rank = %s
-                ''' %(self.rank)))
         if len(condor_datas)!=0:
             for i in condor_datas:
                 condor_submit_fd.write(&quot;arguments      = sh &quot;+i+&quot; $$(Arch) \nqueue\n&quot;)

Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2009-02-10 18:13:13 UTC (rev 9924)
+++ trunk/scripts/dbidispatch	2009-02-10 21:34:53 UTC (rev 9925)
@@ -31,6 +31,8 @@
                               [--universe={vanilla*, standard, grid, java,
                                            scheduler, local, parallel, vm}]
                               [--machine=HOSTNAME+] [--machines=regex+]
+                              [--[*no_]keep_failed_jobs_in_queue]
+
 An * after '[', '{' or ',' signals the default value.
 An + tell that we can put one or more separeted by a comma
 '''
@@ -187,6 +189,9 @@
        universe to test your script as this make the all the jobs start 
        immediately without being preempted on the local host. Take care to 
        don't send too much jobs.
+  The '--[no_]keep_failed_jobs_in_queue' option will cause the jobs to stay 
+      in the queue in completed status if it failed. You should do condor_rm 
+      after to remove it from the queue.
 
 where &lt;command-template&gt; is interpreted as follows: the first argument
 is the &lt;command&gt; above, and the rest are interpreted as &lt;arguments&gt;.
@@ -298,12 +303,12 @@
     elif argv in  [&quot;--force&quot;, &quot;--interruptible&quot;, &quot;--long&quot;, 
                    &quot;--getenv&quot;, &quot;--cwait&quot;, &quot;--clean_up&quot; ,&quot;--nice&quot;,
                    &quot;--set_special_env&quot;, &quot;--abs_path&quot;, &quot;--pkdilly&quot;, &quot;--to_all&quot;,
-                   &quot;--m32G&quot;]:
+                   &quot;--m32G&quot;, &quot;--keep_failed_jobs_in_queue&quot;]:
         dbi_param[argv[2:]]=True
     elif argv in [&quot;--no_force&quot;, &quot;--no_interruptible&quot;, &quot;--no_long&quot;,
                   &quot;--no_getenv&quot;, &quot;--no_cwait&quot;, &quot;--no_clean_up&quot; , &quot;--no_nice&quot;,
                   &quot;--no_set_special_env&quot;, &quot;--no_abs_path&quot;, &quot;--no_pkdilly&quot;,
-                  &quot;--no_m32G&quot;]:
+                  &quot;--no_m32G&quot;, &quot;--no_keep_failed_jobs_in_queue&quot;]:
         dbi_param[argv[5:]]=False
     elif argv==&quot;--testdbi&quot;:
         dbi_param[&quot;test&quot;]=True
@@ -370,7 +375,7 @@
 elif launch_cmd==&quot;Condor&quot;:
     valid_dbi_param +=[&quot;req&quot;, &quot;arch&quot;, &quot;getenv&quot;, &quot;nice&quot;, &quot;files&quot;, &quot;rank&quot;, &quot;env&quot;,
                        &quot;raw&quot;, &quot;os&quot;, &quot;set_special_env&quot;, &quot;mem&quot;, &quot;cpu&quot;, &quot;pkdilly&quot;,
-                       &quot;universe&quot;, &quot;machine&quot;, &quot;machines&quot;, &quot;to_all&quot;]
+                       &quot;universe&quot;, &quot;machine&quot;, &quot;machines&quot;, &quot;to_all&quot;, &quot;keep_failed_jobs_in_queue&quot;]
 elif launch_cmd==&quot;Bqtools&quot;:
     valid_dbi_param +=[&quot;cpu&quot;, &quot;duree&quot;, &quot;long&quot;, &quot;mem&quot;, &quot;micro&quot;,
                        &quot;nano&quot;, &quot;queue&quot;, &quot;raw&quot;, &quot;submit_options&quot;, &quot;jobs_name&quot; ]


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003364.html">[Plearn-commits] r9924 - trunk/plearn_learners_experimental
</A></li>
	<LI>Next message: <A HREF="003366.html">[Plearn-commits] r9926 - trunk/plearn_learners_experimental
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3365">[ date ]</a>
              <a href="thread.html#3365">[ thread ]</a>
              <a href="subject.html#3365">[ subject ]</a>
              <a href="author.html#3365">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
