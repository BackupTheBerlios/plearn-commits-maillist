<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6751 - trunk/plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-March/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6751%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200703180232.l2I2WxMu031533%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000199.html">
   <LINK REL="Next"  HREF="000201.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6751 - trunk/plearn_learners/generic/EXPERIMENTAL</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6751%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200703180232.l2I2WxMu031533%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6751 - trunk/plearn_learners/generic/EXPERIMENTAL">yoshua at mail.berlios.de
       </A><BR>
    <I>Sun Mar 18 03:32:59 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000199.html">[Plearn-commits] r6750 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="000201.html">[Plearn-commits] r6752 - trunk/python_modules/plearn/pytest
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#200">[ date ]</a>
              <a href="thread.html#200">[ thread ]</a>
              <a href="subject.html#200">[ subject ]</a>
              <a href="author.html#200">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-03-18 03:32:59 +0100 (Sun, 18 Mar 2007)
New Revision: 6751

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h
Log:


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc	2007-03-17 23:40:41 UTC (rev 6750)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc	2007-03-18 02:32:59 UTC (rev 6751)
@@ -224,6 +224,8 @@
     int status = lapackSolveLinearSystem(A,r_row,pivots);
     if (status!=0)
         PLWARNING(&quot;NatGradEstimator: lapackSolveLinearSystem returned %d\n:&quot;,status);
+    if (verbosity&gt;0 &amp;&amp; i%(cov_minibatch_size/3)==0)
+        cout &lt;&lt; &quot;solution r = &quot; &lt;&lt; r &lt;&lt; endl;
     // solution is in r
     transposeProduct(v, Xt, r);
     if (renormalize)

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-03-17 23:40:41 UTC (rev 6750)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-03-18 02:32:59 UTC (rev 6751)
@@ -60,6 +60,7 @@
       lrate_decay(0),
       minibatch_size(1),
       output_type(&quot;NLL&quot;),
+      verbosity(0),
       n_layers(-1)
 {
     random_gen = new PRandom();
@@ -71,6 +72,10 @@
                   OptionBase::buildoption,
                   &quot;Number of outputs of the neural network, which can be derived from  output_type and targetsize_\n&quot;);
 
+    declareOption(ol, &quot;verbosity&quot;, &amp;NatGradNNet::verbosity,
+                  OptionBase::buildoption,
+                  &quot;Verbosity level\n&quot;);
+
     declareOption(ol, &quot;n_layers&quot;, &amp;NatGradNNet::n_layers,
                   OptionBase::learntoption,
                   &quot;Number of layers of weights (ie. 2 for a neural net with one hidden layer).\n&quot;
@@ -159,6 +164,9 @@
     }
     else PLERROR(&quot;NatGradNNet: output_type should be NLL or MSE\n&quot;);
 
+    
+    while (hidden_layer_sizes[hidden_layer_sizes.length()-1]==0)
+        hidden_layer_sizes.resize(hidden_layer_sizes.length()-1);
     n_layers = hidden_layer_sizes.length()+2;
     layer_sizes.resize(n_layers);
     layer_sizes.subVec(1,n_layers-2) &lt;&lt; hidden_layer_sizes;
@@ -326,7 +334,8 @@
             pb-&gt;update( stage + 1 );
     }
     Profiler::end(&quot;training&quot;);
-    Profiler::report(cout);
+    if (verbosity&gt;0)
+        Profiler::report(cout);
     const Profiler::Stats&amp; stats = Profiler::getStats(&quot;training&quot;);
     costs.fill(MISSING_VALUE);
     costs_plus_time[train_costs.width()] = stats.user_duration+stats.system_duration;
@@ -347,8 +356,20 @@
         //      (minibatch_size x layer_size[i])
         // try to use BLAS
         if (i&gt;1) // compute gradient on previous layer
-            productScaleAcc(neuron_gradients_per_layer[i-1],neuron_gradients_per_layer[i],false,
+        {
+            Mat previous_neurons_gradient = neuron_gradients_per_layer[i-1];
+            Mat previous_neurons_output = neuron_outputs_per_layer[i-1];
+            productScaleAcc(previous_neurons_gradient,neuron_gradients_per_layer[i],false,
                             weights[i-1],false,1,0);
+            
+            for (int j=0;j&lt;previous_neurons_gradient.length();j++)
+            {
+                real* grad = previous_neurons_gradient[j];
+                real* out = previous_neurons_output[j];
+                for (int k=0;k&lt;previous_neurons_gradient.width();k++,out++)
+                    grad[k] *= (1 - *out * *out); // gradient through tanh derivative
+            }
+        }
         // compute gradient on parameters, possibly update them
         if (full_natgrad) 
         {
@@ -362,14 +383,31 @@
 
         } else // just regular stochastic gradient
             // compute gradient on weights and update them
-            productScaleAcc(layer_params[i-1],neuron_gradients_per_layer[i],true,
-                            neuron_extended_outputs_per_layer[i-1],false,-lrate/minibatch_size,1); // mean gradient
+        {
+            if (verbosity&gt;0)
+            {
+                if (verbosity&gt;1)
+                    layer_params_gradient[i-1].clear();
+                productScaleAcc(layer_params_gradient[i-1],neuron_gradients_per_layer[i],true,
+                                neuron_extended_outputs_per_layer[i-1],false,1./minibatch_size,0); // mean gradient
+            }
+            else
+                productScaleAcc(layer_params[i-1],neuron_gradients_per_layer[i],true,
+                                neuron_extended_outputs_per_layer[i-1],false,-lrate/minibatch_size,1); // mean gradient
+        }
     }
     if (full_natgrad) 
     {
         (*full_natgrad)(t/minibatch_size,all_params_gradient,all_params_delta); // compute update direction by natural gradient
         multiplyAcc(all_params,all_params_delta,-lrate); // update
     }
+    else if (verbosity&gt;0)
+    {
+        if ((t/minibatch_size)%10==0) 
+            cout &lt;&lt; &quot;gradient norm = &quot; &lt;&lt; norm(all_params_gradient) &lt;&lt; endl;
+        multiplyAcc(all_params,all_params_gradient,-lrate); // update
+    }
+        
 }
 
 void NatGradNNet::computeOutput(const Vec&amp; input, Vec&amp; output) const

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h	2007-03-17 23:40:41 UTC (rev 6750)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h	2007-03-18 02:32:59 UTC (rev 6751)
@@ -92,6 +92,8 @@
     //! type of output cost: &quot;NLL&quot; for classification problems, &quot;MSE&quot; for regression
     string output_type;
 
+    int verbosity;
+
 public:
     //#####  Public Member Functions  #########################################
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000199.html">[Plearn-commits] r6750 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="000201.html">[Plearn-commits] r6752 - trunk/python_modules/plearn/pytest
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#200">[ date ]</a>
              <a href="thread.html#200">[ thread ]</a>
              <a href="subject.html#200">[ subject ]</a>
              <a href="author.html#200">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
