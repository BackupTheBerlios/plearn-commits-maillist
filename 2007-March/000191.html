<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6742 - trunk/plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-March/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6742%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200703160219.l2G2JYDC010393%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000190.html">
   <LINK REL="Next"  HREF="000192.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6742 - trunk/plearn_learners/generic/EXPERIMENTAL</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6742%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200703160219.l2G2JYDC010393%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6742 - trunk/plearn_learners/generic/EXPERIMENTAL">yoshua at mail.berlios.de
       </A><BR>
    <I>Fri Mar 16 03:19:34 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000190.html">[Plearn-commits] r6741 - trunk/plearn/math
</A></li>
        <LI>Next message: <A HREF="000192.html">[Plearn-commits] r6743 - trunk/plearn/math
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#191">[ date ]</a>
              <a href="thread.html#191">[ thread ]</a>
              <a href="subject.html#191">[ subject ]</a>
              <a href="author.html#191">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-03-16 03:19:33 +0100 (Fri, 16 Mar 2007)
New Revision: 6742

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h
Log:


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-03-16 00:28:59 UTC (rev 6741)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-03-16 02:19:33 UTC (rev 6742)
@@ -169,7 +169,7 @@
     {
         layer_params[i].resize(layer_sizes[i+1],layer_sizes[i]+1);
         biases[i]=layer_params[i].subMatColumns(0,1);
-        weights[i]=layer_params[i].subMatColumns(1,layer_sizes[i]);
+        weights[i]=layer_params[i].subMatColumns(1,layer_sizes[i]); // weights[0] from layer 0 to layer 1
         n_neurons+=layer_sizes[i+1];
     }
     if (params_natgrad_template)
@@ -180,7 +180,7 @@
         
     }
     neuron_gradients.resize(minibatch_size,n_neurons);
-    neuron_outputs_per_layer.resize(n_layers); // layer 0 = input
+    neuron_outputs_per_layer.resize(n_layers); // layer 0 = input, layer n_layers-1 = output
     neuron_gradients_per_layer.resize(n_layers); // layer 0 not used
     neuron_outputs_per_layer[0].resize(minibatch_size,layer_sizes[0]);
     for (int i=1,k=0;i&lt;n_layers;k+=layer_sizes[i],i++)
@@ -271,10 +271,10 @@
         Vec input = neuron_outputs_per_layer[0](b);
         Vec target = targets(b);
         train_set-&gt;getExample(sample, input, target, example_weights[b]);
-        if (b+1==minibatch_size)
+        if (b+1==minibatch_size) // do also special end-case || stage+1==nstages)
         {
-            onlineStep( neuron_outputs_per_layer[0], targets, 
-                        train_costs, example_weights );
+            onlineStep(stage, neuron_outputs_per_layer[0], targets, 
+                       train_costs, example_weights );
             for (int i=0;i&lt;minibatch_size;i++)
                 train_stats-&gt;update( train_costs(b) );
         }
@@ -285,13 +285,23 @@
     train_stats-&gt;finalize(); // finalize statistics for this epoch
 }
 
-void NatGradNNet::onlineStep(const Mat&amp; input, const Mat&amp; targets,
+void NatGradNNet::onlineStep(int t, const Mat&amp; input, const Mat&amp; targets,
                              Mat&amp; train_costs, Vec example_weights)
 {
+    real lrate = init_lrate/(1 + t*lrate_decay);
     fpropNet(input);
-    fbpropLoss(neuron_outputs_per_layer[n_layers-2],targets,example_weights,train_costs);
-    for (int i=n_layers-2;i&gt;0;i--)
+    fbpropLoss(neuron_outputs_per_layer[n_layers-1],targets,example_weights,train_costs);
+    for (int i=n_layers-1;i&gt;0;i--)
     {
+        // here neuron_gradients_per_layer[i] contains the gradient on activations (weighted sums)
+        //      (minibatch_size x layer_size[i])
+        // try to use BLAS
+        if (i&gt;1) // compute gradient on previous layer
+            productScaleAcc(neuron_gradients_per_layer[i-1],neuron_gradients_per_layer[i],false,
+                            weights[i-1],false,1,0);
+        // compute gradient on weights and update them
+        productScaleAcc(weights[i-1],neuron_gradients_per_layer[i],true,
+                        neuron_outputs_per_layer[i-1],false,lrate,1);
     }
 }
 
@@ -334,7 +344,9 @@
 void NatGradNNet::fbpropLoss(const Mat&amp; output, const Mat&amp; target, const Vec&amp; example_weight, Mat&amp; costs) const
 {
     int n_examples = output.length();
-    Mat out_grad = (n_examples==minibatch_size)?neuron_gradients_per_layer[0]:neuron_gradients_per_layer[0].subMatRows(0,n_examples);
+    Mat out_grad = neuron_gradients_per_layer[n_layers-1];
+    if (n_examples!=minibatch_size)
+        out_grad = out_grad.subMatRows(0,n_examples);
     if (output_type==&quot;NLL&quot;)
     {
         for (int i=0;i&lt;n_examples;i++)

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h	2007-03-16 00:28:59 UTC (rev 6741)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h	2007-03-16 02:19:33 UTC (rev 6742)
@@ -189,7 +189,7 @@
     static void declareOptions(OptionList&amp; ol);
 
     //! one minibatch training step for the (input,target) pair
-    void onlineStep( const Mat&amp; input, const Mat&amp; target, Mat&amp; train_costs, Vec example_weights );
+    void onlineStep(int t, const Mat&amp; input, const Mat&amp; target, Mat&amp; train_costs, Vec example_weights);
 
     //! compute network top-layer output given input
     //! (note that log-probabilities are computed for classification tasks, output_type=NLL)


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000190.html">[Plearn-commits] r6741 - trunk/plearn/math
</A></li>
	<LI>Next message: <A HREF="000192.html">[Plearn-commits] r6743 - trunk/plearn/math
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#191">[ date ]</a>
              <a href="thread.html#191">[ thread ]</a>
              <a href="subject.html#191">[ subject ]</a>
              <a href="author.html#191">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
