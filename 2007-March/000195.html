<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6746 - trunk/plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-March/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6746%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200703162150.l2GLo9MV013165%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000194.html">
   <LINK REL="Next"  HREF="000196.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6746 - trunk/plearn_learners/generic/EXPERIMENTAL</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6746%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200703162150.l2GLo9MV013165%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6746 - trunk/plearn_learners/generic/EXPERIMENTAL">yoshua at mail.berlios.de
       </A><BR>
    <I>Fri Mar 16 22:50:09 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000194.html">[Plearn-commits] r6745 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="000196.html">[Plearn-commits] r6747 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#195">[ date ]</a>
              <a href="thread.html#195">[ thread ]</a>
              <a href="subject.html#195">[ subject ]</a>
              <a href="author.html#195">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-03-16 22:50:09 +0100 (Fri, 16 Mar 2007)
New Revision: 6746

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.h
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
Log:


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc	2007-03-16 17:27:06 UTC (rev 6745)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.cc	2007-03-16 21:50:09 UTC (rev 6746)
@@ -186,6 +186,10 @@
     declareOption(ol, &quot;gamma&quot;, &amp;NatGradEstimator::gamma,
                   OptionBase::buildoption,
                   &quot;Forgetting factor in moving average estimator of covariance. 0&lt;gamma&lt;1.\n&quot;);
+    declareOption(ol, &quot;amari_version&quot;, &amp;NatGradEstimator::amari_version,
+                  OptionBase::buildoption,
+                  &quot;Instead of our tricks, use the formula Ginv &lt;-- (1+eps) Ginv - eps Ginv g g' Ginv\n&quot;
+                  &quot;to estimate the inverse of the covariance matrix, and multiply it with g at each step.\n&quot;);
     declareOption(ol, &quot;verbosity&quot;, &amp;NatGradEstimator::verbosity,
                   OptionBase::buildoption,
                   &quot;Verbosity level\n&quot;);
@@ -230,15 +234,15 @@
         PLASSERT_MSG(gamma&lt;1 &amp;&amp; gamma&gt;0, &quot;NatGradEstimator::init(), gamma should be &lt; 1 and &gt;0&quot;);
         Ut.resize(n_eigen,n_dim);
         Vt.resize(n_eigen+1,n_eigen+cov_minibatch_size);
-        Vkt = Vt.subMat(0,n_eigen,0,n_eigen);
+        Vkt = Vt.subMat(0,0,n_eigen,n_eigen);
         Vbt = Vt.subMat(0,n_eigen,n_eigen,cov_minibatch_size);
         E.resize(n_eigen+1);
         D = E.subVec(0,n_eigen);
         M.resize(n_eigen + cov_minibatch_size, n_eigen + cov_minibatch_size);
-        M11=M.subMat(0,n_eigen,0,n_eigen);
+        M11=M.subMat(0,0,n_eigen,n_eigen);
         M12=M.subMat(0,n_eigen,n_eigen,cov_minibatch_size);
-        M21=M.subMat(n_eigen,cov_minibatch_size,0,n_eigen);
-        M22=M.subMat(n_eigen,cov_minibatch_size,n_eigen,cov_minibatch_size);
+        M21=M.subMat(n_eigen,0,cov_minibatch_size,n_eigen);
+        M22=M.subMat(n_eigen,n_eigen,cov_minibatch_size,cov_minibatch_size);
         Gt.resize(cov_minibatch_size, n_dim);
         initial_v.resize(cov_minibatch_size, n_dim);
         tmp_v.resize(n_dim);
@@ -293,6 +297,8 @@
     }
 
     // iterate on v to solve linear system
+    if (verbosity&gt;0)
+        cout &lt;&lt; &quot;start inversion iterations&quot; &lt;&lt; endl;
     for (int j=0;j&lt;inversion_n_iterations;j++)
     {
         multiply(v, (1 - gamma*alpha),tmp_v);
@@ -352,7 +358,7 @@
         diagonalizedFactorsProduct(newUt,Vkt,sqrtD,Ut,true);
         Ut &lt;&lt; newUt;
     }
-    
+    previous_t = t;
 }
 
 } // end of namespace PLearn

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.h	2007-03-16 17:27:06 UTC (rev 6745)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradEstimator.h	2007-03-16 21:50:09 UTC (rev 6746)
@@ -90,6 +90,10 @@
     //! verbosity level, track improvement, spectrum, etgc.
     int verbosity;
 
+    //! use the formula Ginv &lt;-- (1+eps) Ginv - eps Ginv g g' Ginv
+    //! to estimate the inverse of the covariance matrix
+    bool amari_version;
+
 public:
     //#####  Public Member Functions  #########################################
 

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-03-16 17:27:06 UTC (rev 6745)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-03-16 21:50:09 UTC (rev 6746)
@@ -337,8 +337,6 @@
         {
             productScaleAcc(layer_params_gradient[i-1],neuron_gradients_per_layer[i],true,
                             neuron_extended_outputs_per_layer[i-1],false,1,0);
-            (*full_natgrad)(t/minibatch_size,all_params_gradient,all_params_delta); // compute update direction by natural gradient
-            multiplyAcc(all_params,all_params_delta,-lrate); // update
         }
         else if (params_natgrad_template)
         {
@@ -349,6 +347,11 @@
             productScaleAcc(layer_params[i-1],neuron_gradients_per_layer[i],true,
                             neuron_extended_outputs_per_layer[i-1],false,lrate,1);
     }
+    if (full_natgrad) 
+    {
+        (*full_natgrad)(t/minibatch_size,all_params_gradient,all_params_delta); // compute update direction by natural gradient
+        multiplyAcc(all_params,all_params_delta,-lrate); // update
+    }
 }
 
 void NatGradNNet::computeOutput(const Vec&amp; input, Vec&amp; output) const
@@ -365,7 +368,7 @@
     for (int i=0;i&lt;n_layers-1;i++)
     {
         Mat prev_layer = neuron_extended_outputs_per_layer[i];
-        Mat next_layer = neuron_extended_outputs_per_layer[i+1];
+        Mat next_layer = neuron_outputs_per_layer[i+1];
         if (n_examples!=minibatch_size)
         {
             prev_layer = prev_layer.subMatRows(0,n_examples);


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000194.html">[Plearn-commits] r6745 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="000196.html">[Plearn-commits] r6747 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#195">[ date ]</a>
              <a href="thread.html#195">[ thread ]</a>
              <a href="subject.html#195">[ subject ]</a>
              <a href="author.html#195">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
