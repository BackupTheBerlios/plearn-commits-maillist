<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6794 - trunk/plearn_learners/generic
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-March/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6794%20-%20trunk/plearn_learners/generic&In-Reply-To=%3C200703271832.l2RIWdEu007772%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000242.html">
   <LINK REL="Next"  HREF="000244.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6794 - trunk/plearn_learners/generic</H1>
    <B>chrish at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6794%20-%20trunk/plearn_learners/generic&In-Reply-To=%3C200703271832.l2RIWdEu007772%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6794 - trunk/plearn_learners/generic">chrish at mail.berlios.de
       </A><BR>
    <I>Tue Mar 27 20:32:39 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000242.html">[Plearn-commits] r6793 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="000244.html">[Plearn-commits] r6795 - trunk/commands/PLearnCommands
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#243">[ date ]</a>
              <a href="thread.html#243">[ thread ]</a>
              <a href="subject.html#243">[ subject ]</a>
              <a href="author.html#243">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: chrish
Date: 2007-03-27 20:32:38 +0200 (Tue, 27 Mar 2007)
New Revision: 6794

Modified:
   trunk/plearn_learners/generic/NNet.cc
Log:
Add L1 cost to NNet.


Modified: trunk/plearn_learners/generic/NNet.cc
===================================================================
--- trunk/plearn_learners/generic/NNet.cc	2007-03-27 16:57:04 UTC (rev 6793)
+++ trunk/plearn_learners/generic/NNet.cc	2007-03-27 18:32:38 UTC (rev 6794)
@@ -276,6 +276,7 @@
         &quot;  - \&quot;conf_rated_adaboost_cost\&quot; (for confidence rated Adaboost)\n&quot;
         &quot;  - \&quot;gradient_adaboost_cost\&quot; (also for confidence rated Adaboost)\n&quot;
         &quot;  - \&quot;poisson_nll\&quot;\n&quot;
+        &quot;  - \&quot;L1\&quot;\n&quot;
         &quot;The FIRST function of the list will be used as \n&quot;
         &quot;the objective function to optimize \n&quot;
         &quot;(possibly with an added weight decay penalty) \n&quot;);
@@ -461,14 +462,14 @@
         PLERROR(&quot;In NNet::buildCosts - Empty cost_funcs : must at least specify the cost function to optimize!&quot;);
     costs.resize(ncosts);
 
-    for(int k=0; k&lt;ncosts; k++)
+    for (int k=0; k&lt;ncosts; k++)
     {
         // create costfuncs and apply individual weights if weightpart &gt; 1
-        if(cost_funcs[k]==&quot;mse&quot;)
+        if (cost_funcs[k]==&quot;mse&quot;)
             costs[k]= sumsquare(the_output-the_target);
-        else if(cost_funcs[k]==&quot;mse_onehot&quot;)
+        else if (cost_funcs[k]==&quot;mse_onehot&quot;)
             costs[k] = onehot_squared_loss(the_output, the_target);
-        else if(cost_funcs[k]==&quot;NLL&quot;) 
+        else if (cost_funcs[k]==&quot;NLL&quot;) 
         {
             if (the_output-&gt;size() == 1) {
                 // Assume sigmoid output here!
@@ -480,22 +481,19 @@
                     costs[k] = neg_log_pi(the_output, the_target);
             }
         } 
-        else if(cost_funcs[k]==&quot;class_error&quot;)
+        else if (cost_funcs[k]==&quot;class_error&quot;)
         {
             if (the_output-&gt;size()==1)
                 costs[k] = binary_classification_loss(the_output, the_target);
             else
                 costs[k] = classification_loss(the_output, the_target);
         }
-        else if(cost_funcs[k]==&quot;binary_class_error&quot;)
+        else if (cost_funcs[k]==&quot;binary_class_error&quot;)
             costs[k] = binary_classification_loss(the_output, the_target);
-        else if(cost_funcs[k]==&quot;multiclass_error&quot;)
+        else if (cost_funcs[k]==&quot;multiclass_error&quot;)
             costs[k] = multiclass_loss(the_output, the_target);
-        else if(cost_funcs[k]==&quot;cross_entropy&quot;)
+        else if (cost_funcs[k]==&quot;cross_entropy&quot;)
             costs[k] = cross_entropy(the_output, the_target);
-//        else if(cost_funcs[k]==&quot;scaled_cross_entropy&quot;) {
-//            costs[k] = cross_entropy(the_output, the_target, true);
-//        } 
         else if(cost_funcs[k]==&quot;conf_rated_adaboost_cost&quot;)
         {
             if(output_transfer_func != &quot;sigmoid&quot;)
@@ -504,7 +502,7 @@
             params.append(alpha_adaboost);
             costs[k] = conf_rated_adaboost_cost(the_output, the_target, alpha_adaboost);
         }
-        else if(cost_funcs[k]==&quot;gradient_adaboost_cost&quot;)
+        else if (cost_funcs[k]==&quot;gradient_adaboost_cost&quot;)
         {
             if(output_transfer_func != &quot;sigmoid&quot;)
                 PLWARNING(&quot;In NNet:buildCosts(): gradient_adaboost_cost expects an output in (0,1)&quot;);
@@ -529,9 +527,11 @@
             if (weightsize()&gt;0)
                 the_varray.push_back(sampleweight);
             costs[k] = neglogpoissonvariable(the_varray);
-        }        
-        else  // Assume we got a Variable name and its options
-        {
+        }
+        else if (cost_funcs[k] == &quot;L1&quot;)
+            costs[k] = sumabs(the_output - the_target);
+        else {
+            // Assume we got a Variable name and its options                
             costs[k]= dynamic_cast&lt;Variable*&gt;(newObject(cost_funcs[k]));
             if(costs[k].isNull())
                 PLERROR(&quot;In NNet::build_()  unknown cost_func option: %s&quot;,cost_funcs[k].c_str());
@@ -539,9 +539,8 @@
             costs[k]-&gt;build();
         }
 
-        // take into account the sampleweight
-        //if(sampleweight)
-        //  costs[k]= costs[k] * sampleweight; // NO, because this is taken into account (more properly) in stats-&gt;update
+        // We don't need to take into account the sampleweight, because it is
+        // taken care of in stats-&gt;update.
     }
 
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000242.html">[Plearn-commits] r6793 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="000244.html">[Plearn-commits] r6795 - trunk/commands/PLearnCommands
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#243">[ date ]</a>
              <a href="thread.html#243">[ thread ]</a>
              <a href="subject.html#243">[ subject ]</a>
              <a href="author.html#243">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
