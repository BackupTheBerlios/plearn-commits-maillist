<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8818 - trunk/python_modules/plearn/learners
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-April/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8818%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200804152223.m3FMN5id016673%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002265.html">
   <LINK REL="Next"  HREF="002267.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8818 - trunk/python_modules/plearn/learners</H1>
    <B>louradou at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8818%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200804152223.m3FMN5id016673%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8818 - trunk/python_modules/plearn/learners">louradou at mail.berlios.de
       </A><BR>
    <I>Wed Apr 16 00:23:05 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002265.html">[Plearn-commits] r8817 - trunk/python_modules/plearn/learners
</A></li>
        <LI>Next message: <A HREF="002267.html">[Plearn-commits] r8819 - trunk/plearn/var
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2266">[ date ]</a>
              <a href="thread.html#2266">[ thread ]</a>
              <a href="subject.html#2266">[ subject ]</a>
              <a href="author.html#2266">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: louradou
Date: 2008-04-16 00:23:03 +0200 (Wed, 16 Apr 2008)
New Revision: 8818

Modified:
   trunk/python_modules/plearn/learners/SVM.py
Log:


Modified: trunk/python_modules/plearn/learners/SVM.py
===================================================================
--- trunk/python_modules/plearn/learners/SVM.py	2008-04-15 18:52:59 UTC (rev 8817)
+++ trunk/python_modules/plearn/learners/SVM.py	2008-04-15 22:23:03 UTC (rev 8818)
@@ -122,7 +122,7 @@
                 print &quot;WARNING: get_data_stats() takes default value for input stats.&quot;
             return ( 2, 1. )
 
-        if self.verbosity &gt; 0:
+        if self.verbosity &gt; 1:
             print &quot;  (computing input stats)&quot;
         
         self.inputsize = len(samples[0])
@@ -131,7 +131,7 @@
             if( self.input_avgstd &lt; 0.5
             or  self.input_avgstd &gt; 10.
             or  std__std_per_component/self.input_avgstd &gt; 0.1 ):
-                print &quot;Warning in SVMHyperParamOracle__kernel::get_input_stats() &quot; + \
+                print &quot;WARNING in SVMHyperParamOracle__kernel::get_input_stats() &quot; + \
                     &quot;\n\tYour data does not seem to be normalized: &quot; + \
                     &quot;\n\t(E[std_comp] = %.2f, std[std_comp] = %.2f)&quot; % \
                     ( self.input_avgstd, std__std_per_component )
@@ -731,7 +731,8 @@
         self.validtype       = 'simple'
 
         self.n_fold   = 5
-        self.balanceC = True
+        self.balanceC = False
+        self.balance_classes = False
         self.normalize_inputs = False
 
         self.HyperParamOracle__linear  = SVMHyperParamOracle__linear()
@@ -756,6 +757,8 @@
         self.stats_are_uptodate = False
         self.inputsize = None
         self.input_avgstd = None
+        self.input_means = None
+        self.input_stds = None
         self.nclasses = None
         self.class_priors = None
         self.weight = None
@@ -786,6 +789,8 @@
         self.test_stats      = None
         self.train_stats     = None
         self.stats_are_uptodate = False
+        self.input_means = None
+        self.input_stds = None
         # Note: when we forget, we keep the value of
         #       'self.best_param'. This allow to initialize
         #       a new search (when data changed a bit) to
@@ -808,6 +813,11 @@
             return None
         return dataspec[ self.testset_key ]
 
+    def additional_preproc(self, input_vmat, isTrain=False):
+        if self.balance_classes and isTrain:
+            return ReplicateSamplesVMatrix(source = input_vmat, operate_on_bags = True)
+        return input_vmat
+
     ## specific to libsvm
     &quot;&quot;&quot; Return samples and targets in the format required
         by libsvm, i.e. lists of float.
@@ -834,9 +844,10 @@
         return samples, targets
 
     def get_svminputlist(self, input_vmat, isTrain=False):
+        input_vmat = self.additional_preproc( input_vmat, isTrain )
         samples, targets = self.get_datalist( input_vmat )
         if self.normalize_inputs:
-            if isTrain:
+            if self.input_means == None:
                 self.input_means, self.input_stds = normalize_data(samples)
             else:
                 assert self.input_means
@@ -866,7 +877,7 @@
                      self.inputsize, self.input_avgstd )
         assert vmat &lt;&gt; None
 
-        samples, targets = self.get_svminputlist( vmat, True )
+        samples, targets = self.get_svminputlist( vmat )
 
         self.all_experts[0].verbosity = self.verbosity
         self.inputsize, self.input_avgstd = self.all_experts[0].get_input_stats(samples)
@@ -928,8 +939,13 @@
         return self.get_cost( stats, maincost_name )
     def get_all_costs(self, stats):
         allcosts={}
+        allNones = True
         for cost_name in self.costnames:
             allcosts[cost_name] = self.get_cost(stats, cost_name)
+            if allNones and allcosts[cost_name] &lt;&gt; None:
+                allNones = False
+        if allNones:
+            return None
         return allcosts
 
     &quot;&quot;&quot; Return a svm_parameter in the format for libsvm.
@@ -1042,7 +1058,7 @@
                     continue
 
                 costnames_string += &quot;E[%s.E[%s]] &quot; % (dataset, cn)
-                if cn in costs:
+                if costs &lt;&gt; None and cn in costs:
                     costvalues_string += &quot;%s &quot; % costs[cn]
                 else:
                     costvalues_string += &quot;None &quot;
@@ -1380,21 +1396,21 @@
     def crossvalid( self,
                     dataspec,
                     param = None ):
+        if not param:
+            param = self.best_param
+        nclasses = self.nclasses
         n_fold = self.n_fold
         self.validtype = '%s-fold' % n_fold
-        if not param:
-            param = self.best_param
-
         if self.verbosity &gt; 0:
             print &quot;\n** %d-fold Cross Validation&quot; % n_fold
             print &quot;   with param %s&quot; % param
         
         trainset = self.train_inputspec(dataspec)
-        trainset_class = [None]*self.nclasses
-        N=[0]*self.nclasses
-        Nfold=[0]*self.nclasses
-        Nlastfold=[0]*self.nclasses
-        for c in range(self.nclasses):
+        trainset_class = [None]*nclasses
+        N=[0]*nclasses
+        Nfold=[0]*nclasses
+        Nlastfold=[0]*nclasses
+        for c in range(nclasses):
             trainset_class[c] = ClassSubsetVMatrix( source = trainset,
                                                     classes = [c],)
             N[c] = trainset_class[c].length
@@ -1405,10 +1421,10 @@
             Nlastfold[c] = N[c] - Nfold[c] * (n_fold-1)
         
         validstats = None
-        sub_trainset_class = [None]*self.nclasses
-        sub_testset_class = [None]*self.nclasses
+        sub_trainset_class = [None]*nclasses
+        sub_testset_class = [None]*nclasses
         for i in range(n_fold):
-            for c in range(self.nclasses):
+            for c in range(nclasses):
                 if i &lt; n_fold-1:
                     test_indices = range( i*Nfold[c], (i+1)*Nfold[c] )
                     train_indices = range( 0,i*Nfold[c])+range((i+1)*Nfold[c], N[c] )
@@ -1467,8 +1483,6 @@
 
             # No improvement measured
             if not self.update_trials( param, valid_stats ):
-                if self.verbosity &gt; 0:
-                    print &quot; -- valid costs: &quot;, self.get_all_costs( valid_stats )
 
                 # We reject the model (to avoid testing on it)
                 self.model = None


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002265.html">[Plearn-commits] r8817 - trunk/python_modules/plearn/learners
</A></li>
	<LI>Next message: <A HREF="002267.html">[Plearn-commits] r8819 - trunk/plearn/var
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2266">[ date ]</a>
              <a href="thread.html#2266">[ thread ]</a>
              <a href="subject.html#2266">[ subject ]</a>
              <a href="author.html#2266">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
