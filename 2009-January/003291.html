<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9851 - trunk/python_modules/plearn/parallel
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2009-January/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9851%20-%20trunk/python_modules/plearn/parallel&In-Reply-To=%3C200901201714.n0KHExwW021457%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003290.html">
   <LINK REL="Next"  HREF="003292.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9851 - trunk/python_modules/plearn/parallel</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9851%20-%20trunk/python_modules/plearn/parallel&In-Reply-To=%3C200901201714.n0KHExwW021457%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9851 - trunk/python_modules/plearn/parallel">nouiz at mail.berlios.de
       </A><BR>
    <I>Tue Jan 20 18:14:59 CET 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="003290.html">[Plearn-commits] r9850 - trunk/python_modules/plearn/parallel
</A></li>
        <LI>Next message: <A HREF="003292.html">[Plearn-commits] r9852 - trunk/plearn_learners/meta
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3291">[ date ]</a>
              <a href="thread.html#3291">[ thread ]</a>
              <a href="subject.html#3291">[ subject ]</a>
              <a href="author.html#3291">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2009-01-20 18:14:59 +0100 (Tue, 20 Jan 2009)
New Revision: 9851

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
small refactoring:
-all error use DBIError
-moved some error to be detected earlier
-local_req are not self.tasks_req in DBICondor so that both run can use it.


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2009-01-20 16:39:13 UTC (rev 9850)
+++ trunk/python_modules/plearn/parallel/dbi.py	2009-01-20 17:14:59 UTC (rev 9851)
@@ -103,8 +103,7 @@
         if maxThreads==-1:
             nb_thread=len(argsVector)
         elif maxThreads&lt;=0:
-            print &quot;[DBI] you set %d concurrent jobs. Must be higher then 0!!&quot;%(maxThreads)
-            sys.exit(1)
+            raise DBIError(&quot;[DBI] ERROR: you set %d concurrent jobs. Must be higher then 0!!&quot;%(maxThreads))
         else:
             nb_thread=maxThreads
         if nb_thread&gt;len(argsVector):
@@ -563,10 +562,7 @@
 
 ### We can't accept the symbols &quot;,&quot; as this cause trouble with bqtools
         if self.log_dir.find(',')!=-1 or self.log_file.find(',')!=-1:
-            print &quot;[DBI] ERROR: The log file and the log dir should not have the symbol ','&quot;
-            print &quot;[DBI] log file=&quot;,self.log_file
-            print &quot;[DBI] log dir=&quot;,self.log_dir
-            sys.exit(1)
+            raise DBIError(&quot;[DBI] ERROR: The log file(%s) and the log dir(%s) should not have the symbol ','&quot;%(self.log_file,self.log_dir))
 
         # create directory in which all the temp files will be created
         if not os.path.exists(self.tmp_dir):
@@ -721,8 +717,9 @@
     # escape the double quote so that dagman handle it corretly
     # DAGMAN don't handle single quote!!!
     if &quot;'&quot; in argstring:
-        print &quot;[DBI] ERROR: the condor back-end with dagman don't support using the ' symbol in the command line&quot;
-        sys.exit(1)
+        raise DBIError(&quot;[DBI] ERROR: the condor back-end with dagman don't support using the ' symbol in the command to execute&quot;)
+    if &quot;;&quot; in argstring:
+        raise DBIError(&quot;[DBI] ERROR: the condor back-end with dagman don't support the symbol ';' in the command to execute!&quot;)
     return argstring.replace('&quot;',r'\\\&quot;')
 
 class DBICondor(DBIBase):
@@ -765,13 +762,11 @@
 
         valid_universe = [&quot;standard&quot;, &quot;vanilla&quot;, &quot;grid&quot;, &quot;java&quot;, &quot;scheduler&quot;, &quot;local&quot;, &quot;parallel&quot;, &quot;vm&quot;]
         if not self.universe in valid_universe:
-            print &quot;[DBI] ERROR: the universe option have an invalid value&quot;,self.universe,&quot;. Valid values are:&quot;,valid_universe
-            sys.exit(1)
+            raise DBIError(&quot;[DBI] ERROR: the universe option have an invalid value&quot;,self.universe,&quot;. Valid values are:&quot;,valid_universe)
         if self.universe==&quot;local&quot;:
             n=subprocess.Popen(&quot;cat /proc/cpuinfo |grep processor|wc -l&quot;, shell = True, stdout=PIPE).stdout.readline()
             if len(commands)&gt;int(n):
-                print &quot;[DBI] ERROR we refuse to start more jobs on the local universe then the total number of core. Start less jobs or use another universe.&quot;
-                sys.exit(1)
+                raise DBIError(&quot;[DBI] ERROR we refuse to start more jobs on the local universe then the total number of core. Start less jobs or use another universe.&quot;)
 
         #transform from meg to kilo
         self.mem=int(self.mem)*1024
@@ -858,7 +853,7 @@
                 newcommand+='; else '
                 newcommand+=c+&quot;.32&quot;+c2+'; fi'
                 if not os.access(c+&quot;.64&quot;, os.X_OK):
-                    raise Exception(&quot;The command '&quot;+c+&quot;.64' does not have execution permission!&quot;)
+                    raise DBIError(&quot;[DBI] ERROR: The command '&quot;+c+&quot;.64' does not have execution permission!&quot;)
 #                newcommand=command
                 c+=&quot;.32&quot;
             elif self.cplat==&quot;INTEL&quot; and os.path.exists(c+&quot;.32&quot;):
@@ -877,9 +872,9 @@
                 pass
             elif not os.path.exists(c):
                 if not os.path.abspath(c):
-                    raise Exception(&quot;The command '&quot;+c+&quot;' does not exist!&quot;)
+                    raise DBIError(&quot;[DBI] ERROR: The command '&quot;+c+&quot;' does not exist!&quot;)
             elif not os.access(c, os.X_OK):
-                raise Exception(&quot;The command '&quot;+c+&quot;' does not have execution permission!&quot;)
+                raise DBIError(&quot;[DBI] ERROR: The command '&quot;+c+&quot;' does not have execution permission!&quot;)
 
             self.tasks.append(Task(newcommand, self.tmp_dir, self.log_dir,
                                    self.time_format, self.pre_tasks,
@@ -906,8 +901,7 @@
             if err.startswith('La tache a soumettre est dans: '):
                 pkdilly_file = err.split()[-1]
         if not pkdilly_file:
-            print &quot;[DBI] ERROR: pkdilly didn't returned a good string&quot;
-            sys.exit(1)
+            raise DBIError(&quot;[DBI] ERROR: pkdilly didn't returned a good string&quot;)
 
         pkdilly_fd = open( pkdilly_file, 'r' )
         lines = pkdilly_fd.readlines()
@@ -1087,6 +1081,8 @@
             os.rename(launch_tmp_file, self.launch_file)
 
     def run_dag(self):
+        if self.to_all:
+            raise DBIError(&quot;[DBI] ERROR: condor backend don't support the option --to_all and a maximum number of process&quot;)
         condor_submit_fd = open( self.condor_submit_file, 'w' )
 
         self.log_file = os.path.join(&quot;/tmp/bastienf/dbidispatch&quot;,self.log_dir)
@@ -1129,11 +1125,6 @@
 
         condor_dag_file = self.condor_submit_file+&quot;.dag&quot;
         condor_dag_fd = open( condor_dag_file, 'w' )
-        for task in self.tasks:
-            for c in task.commands:
-                if &quot;;&quot; in c:
-                    print &quot;[DBI] ERROR the option --condor=N don't support the symbol ';' in the command to execute!&quot;
-                    sys.exit(1)
 
         if self.base_tasks_log_file:
             for i in range(len(self.tasks)):
@@ -1148,19 +1139,11 @@
         elif self.stdouts and self.stderrs:
             assert len(self.stdouts)==len(self.stderrs)==len(self.tasks)
             for (task,stdout_file,stderr_file) in zip(self.tasks,self.stdouts,self.stderrs):
-                if stdout_file==stderr_file:
-                    print &quot;Condor can't redirect the stdout and stderr to the same file!&quot;
-                    sys.exit(1)
                 argstring =condor_dag_escape_argument(' ; '.join(task.commands))
                 condor_dag_fd.write(&quot;JOB %d %s\n&quot;%(i,self.condor_submit_file))
                 condor_dag_fd.write('VARS %d args=&quot;%s&quot;\n'%(i,argstring))
                 condor_dag_fd.write('VARS %d stdout=&quot;%s&quot;\n'%(i,stdout_file))
                 condor_dag_fd.write('VARS %d stderr=&quot;%s&quot;\n\n'%(i,stderr_file))
-
-
-        elif self.stdouts or self.stderrs:
-            print &quot;DBICondor should have stdouts and stderrs or none of them&quot;
-            sys.exit(1)
         else:
             #should not happen
             raise NotImplementedError()
@@ -1246,30 +1229,19 @@
                     condor_submit_fd.write(&quot;error        = %s \nqueue\n&quot; %stderr_file)
                 if req:
                     condor_submit_fd.write(&quot;requirements   = %s\n&quot;%(req))
-            local_req=[&quot;&quot;]*len(self.tasks)
-            if self.to_all:
-                local_req=[]
-                for m in self.machine:
-                    local_req.append(self.req+'&amp;&amp;(Machine==&quot;'+m+'&quot;)')
             if self.base_tasks_log_file:
                 for (task,task_log,req) in zip(self.tasks,self.base_tasks_log_file,
-                                               local_req):
+                                               self.tasks_req):
                     stdout_file=self.log_dir+&quot;/condor&quot;+task_log+&quot;.out&quot;
                     stderr_file=self.log_dir+&quot;/condor&quot;+task_log+&quot;.err&quot;
                     print_task(task,stdout_file,stderr_file,req)
             elif self.stdouts and self.stderrs:
                 assert len(self.stdouts)==len(self.stderrs)==len(self.tasks)
                 for (task,stdout_file,stderr_file,req) in zip(self.tasks,self.stdouts,
-                                                              self.stderrs,local_req):
-                    if stdout_file==stderr_file:
-                        print &quot;Condor can't redirect the stdout and stderr to the same file!&quot;
-                        sys.exit(1)
+                                                              self.stderrs,self.tasks_req):
                     print_task(task,stdout_file,stderr_file)
-            elif self.stdouts or self.stderrs:
-                print &quot;DBICondor should have stdouts and stderrs or none of them&quot;
-                sys.exit(1)
             else:
-                for (task,req) in zip(self.tasks,local_req):
+                for (task,req) in zip(self.tasks,self.tasks_req):
                     print_task(task, &quot;&quot;, &quot;&quot;, req)
         condor_submit_fd.close()
 
@@ -1288,10 +1260,16 @@
                     pass
                 pass
 
-
     def run(self):
         if (self.pkdilly and self.nb_proc &gt; 0):
-            print &quot;curently pkdilly with nb_proc &gt;0 is not supported!&quot;
+            raise DBIError(&quot;[DBI] ERROR: curently pkdilly with nb_proc &gt;0 is not supported!&quot;)
+        if (self.stdouts and not self.stderrs) or (self.stderrs and not self.stdouts)
+            raise DBIError(&quot;[DBI] ERROR: the condor back-end should have both stdouts and stderrs or none of them&quot;)
+        if self.stdouts and self.stderrs:
+            assert len(self.stdouts)==len(self.stderrs)==len(self.tasks)
+            for (stdout_file,stderr_file) in zip(self.stdouts, self.stderrs):
+                if stdout_file==stderr_file:
+                    raise DBIError(&quot;[DBI] ERROR: the condor back-end can't redirect the stdout and stderr to the same file!&quot;)
 
         print &quot;[DBI] The Log file are under %s&quot;%self.log_dir
         if self.source_file and self.source_file.endswith(&quot;.cshrc&quot;):
@@ -1324,11 +1302,17 @@
                             self.os.split(','),
                             self.req+'&amp;&amp;(False ')+&quot;)&quot;
         machine_choice=[]
+        self.tasks_req=[&quot;&quot;]*len(self.tasks)
         if not self.to_all:
             #we don't put them in the requirement here
             #as they will be &quot;local&quot; requirement to each jobs.
             for m in self.machine:
                 machine_choice.append('(Machine==&quot;'+m+'&quot;)')
+        else:
+            assert(len(self.machines)==0)
+            for m in self.machine:
+                self.tasks_req.append(self.req+'&amp;&amp;(Machine==&quot;'+m+'&quot;)')
+
         for m in self.machines:
             machine_choice.append('(regexp(&quot;'+m+'&quot;, target.Machine))')
         if machine_choice:
@@ -1446,7 +1430,7 @@
             # same architecture as the architecture of the launch computer
 
             if not os.access(c, os.X_OK):
-                raise Exception(&quot;The command '&quot;+c+&quot;' does not exist or does not have execution permission!&quot;)
+                raise DBIError(&quot;[DBI] ERROR: The command '&quot;+c+&quot;' does not exist or does not have execution permission!&quot;)
             self.tasks.append(Task(command, tmp_dir, log_dir,
                                    time_format, pre_tasks,
                                    post_tasks,dolog,id,False,self.args))
@@ -1609,8 +1593,7 @@
 def find_all_ssh_hosts():
     hostspath_list = [os.path.join(os.getenv(&quot;HOME&quot;),&quot;.pymake&quot;,get_platform()+'.hosts')]
     if os.path.exists(hostspath_list[0])==0:
-        print &quot;[DBI] no host file %s for the ssh backend&quot;%(hostspath_list[0])
-        sys.exit(1)
+        raise DBIError(&quot;[DBI] ERROR: no host file %s for the ssh backend&quot;%(hostspath_list[0]))
     print &quot;[DBI] using file %s for the list of host&quot;%(hostspath_list[0])
 #    from plearn.pymake.pymake import process_hostspath_list
 #    (list_of_hosts, nice_values) = process_hostspath_list(hostspath_list,19,get_hostname())


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003290.html">[Plearn-commits] r9850 - trunk/python_modules/plearn/parallel
</A></li>
	<LI>Next message: <A HREF="003292.html">[Plearn-commits] r9852 - trunk/plearn_learners/meta
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3291">[ date ]</a>
              <a href="thread.html#3291">[ thread ]</a>
              <a href="subject.html#3291">[ subject ]</a>
              <a href="author.html#3291">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
