<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r10315 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2010-January/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10315%20-%20trunk/plearn_learners/online&In-Reply-To=%3C201001212231.o0LMVY7n002353%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003754.html">
   <LINK REL="Next"  HREF="003756.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r10315 - trunk/plearn_learners/online</H1>
    <B>islaja at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10315%20-%20trunk/plearn_learners/online&In-Reply-To=%3C201001212231.o0LMVY7n002353%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r10315 - trunk/plearn_learners/online">islaja at mail.berlios.de
       </A><BR>
    <I>Thu Jan 21 23:31:34 CET 2010</I>
    <P><UL>
        <LI>Previous message: <A HREF="003754.html">[Plearn-commits] r10314 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="003756.html">[Plearn-commits] r10316 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3755">[ date ]</a>
              <a href="thread.html#3755">[ thread ]</a>
              <a href="subject.html#3755">[ subject ]</a>
              <a href="author.html#3755">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: islaja
Date: 2010-01-21 23:31:33 +0100 (Thu, 21 Jan 2010)
New Revision: 10315

Modified:
   trunk/plearn_learners/online/StackedAutoassociatorsNet.h
Log:


Modified: trunk/plearn_learners/online/StackedAutoassociatorsNet.h
===================================================================
--- trunk/plearn_learners/online/StackedAutoassociatorsNet.h	2010-01-21 22:30:06 UTC (rev 10314)
+++ trunk/plearn_learners/online/StackedAutoassociatorsNet.h	2010-01-21 22:31:33 UTC (rev 10315)
@@ -103,6 +103,12 @@
     //! The layers of units in the network
     TVec&lt; PP&lt;RBMLayer&gt; &gt; layers;
 
+    //! The reconstruction layers in the network.
+    //! If not defined, will be the same layers as in the encodage phase.
+    //! Useful for example if we want binomial input components 
+    //! and real reconstruction components.
+    TVec&lt; PP&lt;RBMLayer&gt; &gt; reconstruction_layers;
+
     //! The weights of the connections between the layers
     TVec&lt; PP&lt;RBMConnection&gt; &gt; connections;
 
@@ -158,7 +164,7 @@
     string noise_type;
 
     //! Method used to fill the double_input vector when using missing_data
-    //| noise type.
+    //! noise type.
     string missing_data_method;
 
     //! Weight given to a corrupted (or missing) data when
@@ -188,6 +194,25 @@
     //! 0 or 1 according to prop_salt_noise. 
     bool mask_with_pepper_salt;
 
+    //! Indicate if the pepper salt is zero centered (&gt;0) or not (0).
+    //! If pep_salt_zero_centered equal 0
+    //!   then pepper value is 0 and salt value is 1.
+    //! If pep_salt_zero_centered is greater than 0, 
+    //!   then the pepper value is -pep_salt_zero_centered and 
+    //!   the salt value is pep_salt_zero_centered.
+    real pep_salt_zero_centered;
+
+    //! Indication that the autoassociator will try to
+    //! &quot;reconstruct&quot; another _corrupted version_ of the input
+    //! (instead of the input itself).
+    bool renoising;
+
+    //! Usage of noisy example before doing a particular training.
+    //! Could be before unsup. pre-training (=1) or 
+    //! before unsup pre-training AND before supervised fine-tuning (=2).
+    //! Original example are used for any test.
+    int noisy;   
+
     //! Probability that we mask the input by 1 instead of 0.
     real prob_salt_noise;
 
@@ -225,7 +250,17 @@
     //! -1 (default) means the number of training samples.
     int train_stats_window;
 
+    //! Experiment directory where the learner will be save
+    //! if save_learner_before_fine_tuning is true.
+    string learnerExpdir;
 
+    //! Saves the learner before the supervised fine_tuning.
+    bool save_learner_before_fine_tuning;
+    
+    //! Keep trace of the representations obtained during an 
+    //! unsupervised training phase.
+    bool keep_online_representations;
+
     //#####  Public Learnt Options  ###########################################
 
     //! Number of layers
@@ -277,9 +312,20 @@
     //! and  for which it updates the VecStatsCollector train_stats.
     virtual TVec&lt;std::string&gt; getTrainCostNames() const;
 
+    //! Returns the representations obtained during last pre-training of the current layer.
+    inline TVec&lt; Vec &gt; getTrainRepresentations() const
+    {
+        return train_representations;
+    }
 
+    inline void remote_setCurrentlyTrainedLayer(int new_currently_trained_layer)
+    {
+        currently_trained_layer = new_currently_trained_layer;
+    }
+        
+
     void greedyStep(const Vec&amp; input, const Vec&amp; target, int index,
-                    Vec train_costs);
+                    Vec train_costs, Vec&amp; representation);
     void greedyStep(const Mat&amp; inputs, const Mat&amp; targets, int index,
                     Mat&amp; train_costs);
 
@@ -435,6 +481,14 @@
     //! Layers randomly masked, for unsupervised fine-tuning.
     TVec&lt; Vec &gt; corrupted_autoassociator_expectations;
 
+    //! Corrupted version of the autoassociator input not used for denoising.
+    //! Useful when renoising or noisy is true. 
+    //! In the first case: autoassociator will try to have its decoded version
+    //! getting closer to this corrupted version during the non-supervised training.
+    //! In the second case: example will be corrupted before any non-supervised
+    //! (without denoising) and supervised training. 
+    TVec&lt; Vec &gt; second_corrupted_autoassociator_expectations;
+
     //! Stores the weight of each data used when
     //! backpropagating the gradient of reconstruction cost.
     //! The weight is either corrupted_data_weight or data_weight
@@ -443,6 +497,9 @@
     //! during the reconstruction.
     mutable Vec reconstruction_weights;
 
+    //! Representations computed for the current trained layer.
+    mutable TVec&lt; Vec &gt; train_representations;
+
     //! Layers random binary maske, for online learning.
     TVec&lt; Vec &gt; binary_masks;
 
@@ -503,7 +560,9 @@
     void divide_input(const Vec&amp; input, Vec&amp; divided_input) const ;
 
     //! Supposes the learner is already trained.
-    //! Allows a codage-decodage ktime from a source image. Returns the 'fantasize' image. 
+    //! Allows a codage-decodage ktime, each time from the same source image (alwaysFromSrcImg==True)
+    //!   or each time from the last fantasize image (alwaysFromSrcImg==False). 
+    //!   Returns the source image followed by the kTime obtained 'fantasize' images. 
     //! You can choose how many layers to use (including raws layer) by defining the size of sample. 
     //! You can corrupt layers differently during the codage phase by defining maskNoiseFractOrProb 
     //! You can apply a binary sampling (1) or not (0) differently for each layer during the decode phase
@@ -513,9 +572,13 @@
     //!                                          // and first hidden layer.
     //!     sample = [1,0,0] // sampling only before reconstruction of the
     //!                      // raws input.
-    Vec fantasizeKTime(int KTime, const Vec&amp; srcImg, const Vec&amp; sample,
-                        const Vec&amp; maskNoiseFractOrProb);
+    TVec&lt;Vec&gt; fantasizeKTime(const int KTime, const Vec&amp; srcImg, const Vec&amp; sample,
+                        const Vec&amp; maskNoiseFractOrProb, bool alwaysFromSrcImg);
 
+    //! Same as fantasizeKTime, but does it on different source images.
+    TVec&lt;Vec&gt; fantasizeKTimeOnMultiSrcImg(const int KTime, const Mat&amp; srcImg, const Vec&amp; sample,
+                        const Vec&amp; maskNoiseFractOrProb, bool alwaysFromSrcImg);
+
     void corrupt_input(const Vec&amp; input, Vec&amp; corrupted_input, int layer, Vec&amp; binary_mask);
 
     //! Global storage to save memory allocations.


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003754.html">[Plearn-commits] r10314 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="003756.html">[Plearn-commits] r10316 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3755">[ date ]</a>
              <a href="thread.html#3755">[ thread ]</a>
              <a href="subject.html#3755">[ subject ]</a>
              <a href="author.html#3755">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
