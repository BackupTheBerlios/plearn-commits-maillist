<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r10227 - in trunk/python_modules/plearn: . table
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2009-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10227%20-%20in%20trunk/python_modules/plearn%3A%20.%20table&In-Reply-To=%3C200906022259.n52Mxkxv016391%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003666.html">
   <LINK REL="Next"  HREF="003668.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r10227 - in trunk/python_modules/plearn: . table</H1>
    <B>plearner at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10227%20-%20in%20trunk/python_modules/plearn%3A%20.%20table&In-Reply-To=%3C200906022259.n52Mxkxv016391%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r10227 - in trunk/python_modules/plearn: . table">plearner at mail.berlios.de
       </A><BR>
    <I>Wed Jun  3 00:59:46 CEST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="003666.html">[Plearn-commits] r10226 - trunk/scripts/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="003668.html">[Plearn-commits] r10228 - in trunk/scripts: . DEPRECATED
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3667">[ date ]</a>
              <a href="thread.html#3667">[ thread ]</a>
              <a href="subject.html#3667">[ subject ]</a>
              <a href="author.html#3667">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: plearner
Date: 2009-06-03 00:59:44 +0200 (Wed, 03 Jun 2009)
New Revision: 10227

Added:
   trunk/python_modules/plearn/table/
   trunk/python_modules/plearn/table/__init__.py
   trunk/python_modules/plearn/table/date.py
   trunk/python_modules/plearn/table/pltable_commands.py
   trunk/python_modules/plearn/table/table.py
   trunk/python_modules/plearn/table/tablestat.py
   trunk/python_modules/plearn/table/viewtable.py
Log:
ApSTAT contribution of the table classes


Added: trunk/python_modules/plearn/table/__init__.py
===================================================================

Added: trunk/python_modules/plearn/table/date.py
===================================================================
--- trunk/python_modules/plearn/table/date.py	2009-06-02 21:55:31 UTC (rev 10226)
+++ trunk/python_modules/plearn/table/date.py	2009-06-02 22:59:44 UTC (rev 10227)
@@ -0,0 +1,208 @@
+&quot;&quot;&quot;
+Module plearn.table.date
+
+Copyright (C) 2005 ApSTAT Technologies Inc.
+
+This file was contributed by ApSTAT Technologies to the
+PLearn library under the following BSD-style license: 
+
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions are met:
+#
+#   1. Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#
+#   2. Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in the
+#      documentation and/or other materials provided with the distribution.
+#
+#   3. The name of the authors may not be used to endorse or promote
+#      products derived from this software without specific prior written
+#      permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+#  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+#  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+#  NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+#  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+#  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+#  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+#  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+#  This file is part of the PLearn library. For more information on the PLearn
+#  library, go to the PLearn Web site at www.plearn.org
+
+&quot;&quot;&quot;
+
+# Author: Pascal Vincent
+
+import datetime, string
+from re import match
+
+monthnum = {
+'JAN' : 1,
+'FEB' : 2,
+'MAR' : 3,
+'APR' : 4,
+'MAY' : 5,
+'JUN' : 6,
+'JUL' : 7,
+'AUG' : 8,
+'SEP' : 9,
+'OCT' : 10,
+'NOV' : 11,
+'DEC' : 12 }
+
+def CYYMMDD_to_YYYYMMDD(cyymmdd):
+    return 19000000+int(cyymmdd)
+
+def YYYYMMDD_to_CYYMMDD(yyyymmdd):
+    return int(yyyymmdd)-19000000
+
+def date_to_CYYMMDD(date):
+    &quot;&quot;&quot;Takes a python datetime.date and returns an int in CYYMMDD format&quot;&quot;&quot;
+    if date.year&lt;1900:
+        raise ValueError('In date_to_CYYMMDD CYYMMDD format is only valid for years 1900 and above, not'+str(date))
+    return (date.year-1900)*10000 + date.month*100 + date.day
+
+def date_to_YYYYMMDD(date):
+    &quot;&quot;&quot;Takes a python datetime.date and returns an int in YYYYMMDD format&quot;&quot;&quot;
+    return date.year*10000 + date.month*100 + date.day
+
+def CYYMMDD_to_date(cyymmdd):
+    cyymm,dd = divmod(cyymmdd,100)
+    cyy,mm = divmod(cyymm,100)
+    try: d = datetime.date(1900+cyy,mm,dd)
+    except ValueError:
+        raise ValueError('Invalid CYYMMDD date: ' + str(cyymmdd))
+    return d
+
+daysinmonth = [31,28,31,30,31,30,31,31,30,31,30,31]
+def float_sum(l):
+    s = 0
+    for x in l:
+        s += float(x or '0')
+    return s
+
+def CYYMMDD_to_ymd(cyymmdd):
+    y = int(cyymmdd/10000)
+    mmdd = cyymmdd - 10000*y
+    m = int(mmdd/100)
+    d = mmdd - 100*m
+    return (y,m,d)
+    
+def toyears(date):
+    sdate = str(date)
+#    print ':',sdate,':'
+    # Assumed format:  DDMMMYYYY
+    if match(r'\d{2}[a-zA-Z]{3}\d{4}',sdate): 
+        try:
+            d = float(sdate[0:2])
+            m = monthnum[sdate[2:5]]
+            y = float(sdate[5:])
+        except:
+            raise ValueError('1:Can\'t convert ' + str(date) + ' in toyears()')
+        
+    # Assumed format:  YYYYMMDD
+    elif match(r'\d{8}',sdate):  
+        try:
+            d = date%100
+            date = (date - d)/100
+            m = date%100
+            y = (date - m)/100
+        except:
+            raise ValueError('2:Can\'t convert ' + str(date) + ' in toyears()')
+
+    # Assumed format:  YYMMDD        
+    elif match(r'\d{6}',sdate):
+        try:
+            d = date%100
+            date = (date - d)/100
+            m = date%100
+            y = (date - m)/100 + 1900
+            if y &lt; 4:
+                y = y + 100
+        except:
+            raise ValueError('3:Can\'t convert ' + str(date) + ' in toyears()')        
+
+    # Assumed format:  YYYY        
+    elif match(r'\d{4}',sdate):
+	try:
+	    y = float(date)
+	    m = 1
+	    d = 1
+	except:
+            raise ValueError('4:Can\'t convert ' + str(date) + ' in toyears()')
+	    
+    else:
+        raise ValueError('0:Can\'t convert ' + str(date) + ' in toyears()')
+    if y%4==0:
+        if m &gt; 2:
+            return y + (float_sum(daysinmonth[:m-1])+1+d-1)/366.
+        else:
+            return y + (float_sum(daysinmonth[:m-1])+d-1)/366.
+    return y + (float_sum(daysinmonth[:m-1])+d-1)/365.
+
+def YYYYMMDD_to_date(yyyymmdd):
+    yyyymm,dd = divmod(yyyymmdd,100)
+    yyyy,mm = divmod(yyyymm,100)
+    return datetime.date(yyyy,mm,dd)
+    
+def dateint_to_date(dateint):
+    &quot;&quot;&quot;Takes a dateint in YYYYMMDD or CYYMMDD format and returns a python datetime.date&quot;&quot;&quot;
+    if dateint&gt;=10000000: # YYYYMMDD format (we suppose we won't see date before year 1000 !)
+        return YYYYMMDD_to_date(dateint)
+    else: # CYYMMDD format
+        return CYYMMDD_to_date(dateint)
+
+def datestring_to_date(datestring):
+    &quot;&quot;&quot;Takes a datestring in various formats and returns a python datetime.date
+    Currently recognized formats are:
+    YYYYMMDD
+    CYYMMDD
+    YYYY-MM-DD
+    YYYY/MM/DD
+    27JAN2003
+    &quot;&quot;&quot;
+    date = datestring.strip()
+    dateint = 0
+    try: dateint = int(datestring)
+    except: pass
+    if dateint:
+        return dateint_to_date(dateint)
+
+    # Format &quot;2003/01/27&quot; or &quot;2003-01-27&quot;
+    if len(date) == 10 and date[4] in '/-' and date[7] in '/-':
+        year = int(date[0:4])
+        month = int(date[5:7])
+        day = int(date[8:10])
+        return datetime.date(year,month,day)
+        
+    # Format &quot;27JAN2003&quot;
+    if len(date)==9 and date[2] in string.uppercase and date[3] in string.uppercase and date[4] in string.uppercase:
+        year = int(date[5:9])
+        day = int(date[0:2])
+        month = monthnum[date[2:5]]
+        return datetime.date(year,month,day)
+        
+    raise ValueError(&quot;Invalid datestring format: &quot;+datestring)
+
+def datestring_to_CYYMMDD(datestring):
+    return date_to_CYYMMDD(datestring_to_date(datestring))
+
+def datestring_to_YYYYMMDD(datestring):
+    return date_to_YYYYMMDD(datestring_to_date(datestring))
+
+def todate(date):
+    &quot;&quot;&quot;Accepts both string date formats and int date formats, and returns a python datetime.date&quot;&quot;&quot;
+    if isinstance(date,datetime.date):
+        return date
+    elif type(date)==str:
+        return datestring_to_date(date)
+    elif type(date)==int:
+        return dateint_to_date(date)
+        
+def daydiff(cyymmdd1, cyymmdd2):
+    return (CYYMMDD_to_date(cyymmdd1)-CYYMMDD_to_date(cyymmdd2)).days

Added: trunk/python_modules/plearn/table/pltable_commands.py
===================================================================
--- trunk/python_modules/plearn/table/pltable_commands.py	2009-06-02 21:55:31 UTC (rev 10226)
+++ trunk/python_modules/plearn/table/pltable_commands.py	2009-06-02 22:59:44 UTC (rev 10227)
@@ -0,0 +1,254 @@
+
+&quot;&quot;&quot;
+pltable_command.py
+
+Copyright (C) 2005 ApSTAT Technologies Inc.
+
+This file was contributed by ApSTAT Technologies to the
+PLearn library under the following BSD-style license: 
+
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions are met:
+#
+#   1. Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#
+#   2. Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in the
+#      documentation and/or other materials provided with the distribution.
+#
+#   3. The name of the authors may not be used to endorse or promote
+#      products derived from this software without specific prior written
+#      permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+#  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+#  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+#  NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+#  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+#  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+#  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+#  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+#  This file is part of the PLearn library. For more information on the PLearn
+#  library, go to the PLearn Web site at www.plearn.org
+&quot;&quot;&quot;
+
+# Author: Pascal Vincent
+
+from plearn.table.viewtable import *
+
+def print_usage_and_exit():
+    print &quot;&quot;&quot;
+    Usage: pytable [options] command [params...]
+
+    Options:
+           -i &lt;indexfile&gt;
+           --index &lt;indexfile&gt;
+             uses indexfile as an index for the first table
+
+    Commands:
+           pytable info &lt;table_file&gt;
+             prints length x width
+             
+           pytable fields &lt;table_file&gt;
+             prints all fieldnames in original order
+             
+           pytable sorted_fields &lt;table_file&gt;
+             prints all fieldnames sorted alphabetically
+             
+           pytable view &lt;table_file&gt;
+             view of table interactively (curses based)
+
+           pytable convert &lt;src_table&gt; &lt;dest_file&gt;
+             saves src_table (can be a .txt .pytable .ptab .ptabdir .pmat)
+             as dest_file which must be a .txt .ptab .ptabdir .pmat or .dmat
+             Note that if you save into a .pmat or .dmat, all values must either
+             be convertible to float, or be the empty string '' (which will
+             be output as missing values (NaN)). If you want a smarter
+             handling of strings, consider invoking 'pytable tovmat'
+             instead.
+
+           pytable tovmat &lt;src_table&gt; &lt;dest_vmat&gt; &lt;stringmap_reference_dir&gt;
+             saves src_table (can be a .txt .pytable .ptab .ptabdir .pmat)
+             as dest_vmat which must be a .pmat or .dmat
+             The stringmap_reference_dir is a directory which
+             will contain the mapping from non-numerical string
+             representations to numerical value. This mapping will be
+             automatically extended if yet unmapped representations are
+             encountered. The dest_vmat.metadata/FieldInfo will be created
+             as a symbolic link to stringmap_reference_dir/mappings.
+             Also stringmap_reference_dir/logdir/YYYY-MM-DD_HH:MM:SS/ will
+             contain stats.txt with the new type stat counts, and a .smap
+             for each field whose string mapping had to be extended
+             containing the extra mappings.
+
+           pytable scan &lt;table_file&gt;
+             will do a pass through the table, accessing every row
+
+           pytable diff &lt;table_file1&gt; &lt;table_file2&gt;
+             will report the differences between the 2 tables
+          
+           pytable countall &lt;table.pytable&gt; &lt;fieldname&gt;
+             will count all possible instances of the value of the given field
+             and print a list of all values with the associated count.
+
+           pytable sum &lt;table.pytable&gt;
+             will sum the values of each fields and print the result
+
+           pytable dump &lt;table.pytable&gt;
+             will dump the whole table as a tab-separated text table
+
+      table_file can be a tab-separated text table
+      or a python script ending in .pytable and defining a
+      result variable that is a Table.
+      &quot;&quot;&quot;
+    sys.exit()
+
+    
+def main(argv):
+    
+    if len(argv)&lt;3:
+        print_usage_and_exit()
+    
+    index_name = None
+    n= 1
+    if argv[n][:7]=='--index':
+        if len(argv[n]) &gt; 7:
+            if argv[n][7] == '=':
+                index_name = argv[n][8:]
+                n+= 1
+            else:
+                print &quot;invalid option syntax: &quot; + argv[n]
+                print_usage_and_exit()
+    
+        else:
+            index_name = argv[n+1]
+            n+= 2
+    
+    if argv[n][:2]=='-i':
+        if len(argv[n]) &gt; 2:
+            if argv[n][2] == '=':
+                index_name = argv[n][3:]
+                n+= 1
+            else:
+                print &quot;invalid option syntax: &quot; + argv[n]
+                print_usage_and_exit()
+        else:
+            index_name = argv[n+1]
+            n+= 2
+    
+    command = argv[n]
+    
+    cmd_args = argv[n+1:]
+    
+    table_name= cmd_args[0]
+    table= openTable(table_name)
+    
+    if index_name!=None:
+        index= IntVecFile(index_name)
+        table= SelectRows(table, index)
+    
+    
+    if command == 'info':
+        print str(table.length())+'x'+str(table.width())
+    elif command == 'fields':
+        for fieldname in table.fieldnames:
+            print fieldname
+    elif command == 'sorted_fields':
+        fieldnames = table.fieldnames[:]
+        fieldnames.sort()
+        for fieldname in fieldnames:
+            print fieldname
+        
+    elif command == 'view':
+        fname = table_name
+        table.set_title('FILE: '+fname)
+        viewtable(table)
+    
+    elif command == 'convert':
+        saveTable(table,cmd_args[1])
+    
+    elif command == 'tovmat':
+        saveTableAsVMAT(table,cmd_args[1],cmd_args[2])
+    
+    elif command == 'scan':
+        fname = table_name
+        i = 0
+        pbar = PBar('Scanning '+fname,len(table))
+        # try:
+        for row in table:
+            pbar.update(i)
+            i += 1
+        # except Exception, e:
+        #    print 'At row ',i
+        #    raise e
+        print 'Successfully scanned',i,'rows of',len(table)
+    
+    elif command == 'diff':
+        m1 = table
+        m2 = openTable(cmd_args[1])
+        if len(m1)!=len(m2):
+            print 'Lengths differ: ',len(m1),'!=',len(m2)
+        if m1.width() != m2.width():
+            print 'Widths differ: ',m1.width(),'!=',m2.width()
+        if m1.fieldnames != m2.fieldnames:
+            print 'Fieldnames differ: ',m1.fieldnames,'!=',m2.fieldnames
+        w = m1.width()
+        for i in xrange(min(len(m1),len(m2))):
+            r1 = m1[i]
+            r2 = m2[i]
+            for j in xrange(w):
+                if str(r1[j])!=str(r2[j]):
+                    print 'Difference at (',i,',',j,') : ', r1[j], '!=', r2[j]            
+    
+    elif command == 'countall':
+        fieldname = cmd_args[1]
+        fieldpos = table.fieldnum(fieldname)
+        counts = {}
+        pbar = PBar('Counting all possible values of field '+fieldname,len(table))
+        i = 0
+        for row in table:
+            val = row[fieldpos]
+            try:
+                counts[val] += 1
+            except KeyError:
+                counts[val] = 1
+            i += 1
+            pbar.update(i)
+        pbar.close()
+        print '## Value : Count'
+        for key,val in counts.items():
+            print ' ',key,'\t:',val
+    
+    elif command == 'sum':
+        w = table.width()
+        tot = [0.]*w
+        pbar = PBar('Computing sums',len(table))
+        i = 0
+        for row in table:
+            for j in xrange(w):
+                try:
+                    tot[j] += float(row[j])
+                except ValueError:
+                    pass
+            i += 1
+            pbar.update(i)
+        pbar.close()
+        print '## Sums:'
+        for j in xrange(w):
+            print '#',j,table.fieldnames[j],':',tot[j]
+    
+    elif command == 'dump':
+        print '\t'.join(table.fieldnames)
+        for i in xrange(len(table)):
+            print '\t'.join(map(str,table[i]))
+    
+    else:
+        print &quot;invalid command: &quot;, command
+        print_usage_and_exit()
+
+    table.close()
+    

Added: trunk/python_modules/plearn/table/table.py
===================================================================
--- trunk/python_modules/plearn/table/table.py	2009-06-02 21:55:31 UTC (rev 10226)
+++ trunk/python_modules/plearn/table/table.py	2009-06-02 22:59:44 UTC (rev 10227)
@@ -0,0 +1,2136 @@
+## Automatically adapted for numpy.numarray Jun 13, 2007 by python_numarray_to_numpy (-xsm)
+
+&quot;&quot;&quot;
+table.py
+
+Copyright (C) 2005-2009 ApSTAT Technologies Inc.
+
+This file was contributed by ApSTAT Technologies to the
+PLearn library under the following BSD-style license: 
+
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions are met:
+#
+#   1. Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#
+#   2. Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in the
+#      documentation and/or other materials provided with the distribution.
+#
+#   3. The name of the authors may not be used to endorse or promote
+#      products derived from this software without specific prior written
+#      permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+#  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+#  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+#  NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+#  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+#  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+#  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+#  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+#  This file is part of the PLearn library. For more information on the PLearn
+#  library, go to the PLearn Web site at www.plearn.org
+&quot;&quot;&quot;
+
+# Author: Pascal Vincent
+
+import os.path, string, struct, zlib, fpconst, pickle, csv, time, copy, subprocess
+
+from numpy.numarray import array, argsort, random_array
+
+from plearn.utilities.progress import PBar
+
+from random import seed, randint, uniform
+
+# Use of VMat through the Python-bridge
+try:
+    from plearn.pyext import DiskVMatrix, FileVMatrix
+except ImportError:
+    print &quot;WARNING: Import of DiskVMatrix, FileVMatrix from plearn.pyext failed. Probably no plearn python extension compiled. Skipping this import.&quot; 
+
+def float_or_str(x):
+    try: return float(x)
+    except: return str(x)
+
+def float_or_zero(x):
+    try: return float(x)
+    except: return 0.
+
+def float_or_value(x, val):
+    try: return float(x)
+    except: return val
+
+def int_or_zero(x):
+    try: return int(x)
+    except: return 0
+
+def int_or_value(x, val):
+    try: return int(x)
+    except: return val
+
+class StructFile:
+    &quot;&quot;&quot;File with fixed size packed binary records.
+    Records are packed using the struct module;
+    all records use the same format string.
+    &quot;&quot;&quot;
+
+    def __init__(self, fname, struct_format, openmode='r', data_offset=0):
+        &quot;&quot;&quot;data_offset is the pos. of beg. of data from beg. of file, in bytes&quot;&quot;&quot;
+        self.fname = fname
+        self.openmode = openmode
+        self.struct_format = struct_format
+        self.struct_size = struct.calcsize(struct_format)
+        self.closed = False
+        self.data_offset = data_offset
+        self.last_call_was_append = False
+        
+        if openmode=='r':
+            self._len = (os.path.getsize(fname)-data_offset)/self.struct_size
+            self.f = open(fname,'rb')
+        elif openmode=='r+':
+            self._len = (os.path.getsize(fname)-data_offset)/self.struct_size
+            self.f = open(fname,'rb+')
+        elif openmode=='w+':
+            self._len = 0
+            self.f = open(fname,'wb+')
+        else:
+            raise ValueError(&quot;Invalid value for openmode (&quot;+`openmode`+&quot; Must be one of 'r' 'r+' or 'w+'&quot;)
+            
+    def append(self, x):
+        if not self.last_call_was_append:
+            self.f.seek(0,2) # seek to end of index file
+            
+        if isinstance(x,list):
+            self.f.write(struct.pack(self.struct_format,*x))
+        else:
+            self.f.write(struct.pack(self.struct_format,x))
+        self._len += 1
+
+        self.last_call_was_append = True
+
+    def __getitem__(self,i):
+        self.last_call_was_append = False
+        
+        l = self.__len__()
+        if i&lt;0: i+=l
+        if i&lt;0 or i&gt;=l:
+            raise IndexError('StructFile index out of range')
+
+        self.f.seek(self.data_offset + i*self.struct_size)
+        x = struct.unpack(self.struct_format,self.f.read(self.struct_size))
+
+        if len(x)==1:
+            return x[0]
+        else:
+            return x
+
+    def __setitem__(self, i, x):
+        self.last_call_was_append = False
+
+        l = self.__len__()
+        if i&lt;0: i+=l
+        if i&lt;0 or i&gt;=l:
+            raise IndexError('StructFile index out of range')
+        self.f.seek(self.data_offset + i*self.struct_size)
+        try: # should work when x is a kind of list
+            self.f.write(struct.pack(self.struct_format,*x))
+        except TypeError: # should work when x is a single element
+            self.f.write(struct.pack(self.struct_format,x))
+        #self.flush() ##is it necessary?
+            
+
+    def flush(self):
+        self.last_call_was_append = False
+        self.f.flush()
+
+    def close(self):
+        self.last_call_was_append = False
+
+        if not self.closed:
+            self.f.close()
+            self.closed = True
+
+    # Note: it's better for your code to call close() explicitly rather than rely on this being called automatically
+    def __del__(self):
+        self.close()
+        
+    def __len__(self):
+        return int(self._len)
+
+
+class IntVecFile(StructFile): # read-only for now...
+    def __init__(self, fname, openmode='r', endianness='L'):
+        &quot;&quot;&quot;endianness is ignored when reading&quot;&quot;&quot;
+
+        #self.fname = fname
+        #self.openmode = openmode
+
+        
+        if openmode[0]=='r':
+            self.f = open(fname,'rb')
+            self.readFileSignature()
+            self.f.close()
+        else:
+            self.endianness= endianness
+#         if openmode=='r':
+#             self.f = open(fname,'rb')
+#             self.readFileSignature()
+#         elif openmode=='r+':
+#             self.f = open(fname,'rb+')
+#             self.readFileSignature()
+#         elif openmode=='w+':
+#             self._len = 0
+#             self.f = open(fname,'wb+')
+#             self.endianness= endianness
+#             self.writeFileSignature()
+#         else:
+#             raise ValueError(&quot;Invalid value for openmode (&quot;+`openmode`+&quot; Must be one of 'r' 'r+' or 'w+'&quot;)
+
+        endcode = '&lt;'
+        if self.endianness=='L': endcode = '&lt;'
+        elif self.endianness=='B': endcode = '&gt;'
+        else: raise ValueError(&quot;Invalid value endianness (&quot; + self.endianness + &quot;) must be 'L' or 'B'&quot;)
+        #self.struct_format = endcode+'l'
+        struct_format = endcode+'l'
+        #self.struct_size = struct.calcsize(self.struct_format)
+
+        #if openmode[0]=='r':
+        #    self._len = os.path.getsize(fname)/self.struct_size -2
+
+        StructFile.__init__(self, fname, struct_format, openmode, 8)
+        if openmode[0]=='w':
+            self.writeFileSignature()
+
+
+    def readFileSignature(self):
+        self.f.seek(0)
+        s = self.f.read(4)
+        if s != '\xde\xad\xbe\xef':
+            raise RuntimeError(&quot;Is this an IntVecFile?? (&quot;+self.fname+&quot;)&quot;)
+        self.endianness= self.f.read(1)
+        if self.endianness not in ['L','B']:
+            raise RuntimeError(&quot;Invalid endianness (&quot;+self.endianness+&quot;) for IntVecFile &quot;+self.fname\
+                               +&quot; (should be 'L' or 'B')&quot;)
+        
+    def writeFileSignature(self):
+        self.f.seek(0)
+        self.f.write('\xde\xad\xbe\xef') #dead beef
+        self.f.write(self.endianness)
+        self.f.write('\0\0')
+        self.f.write('\1') # version number
+
+#     def append(self, x):
+#         self.f.seek(0,2) # seek to end of index file
+#         if isinstance(x,list):
+#             self.f.write(struct.pack(self.struct_format,*x))
+#         else:
+#             self.f.write(struct.pack(self.struct_format,x))
+#         self._len += 1
+
+#     def __getitem__(self,i):
+#         l = self.__len__()
+#         if i&lt;0: i+=l
+#         if i&lt;0 or i&gt;=l:
+#             raise IndexError('StructFile index out of range')
+#         self.f.seek((i+2)*self.struct_size)
+#         x = struct.unpack(self.struct_format,self.f.read(self.struct_size))
+#         if len(x)==1:
+#             return x[0]
+#         else:
+#             return x
+
+#     def __setitem__(self, i, x):
+#         l = self.__len__()
+#         if i&lt;0: i+=l
+#         if i&lt;0 or i&gt;=l:
+#             raise IndexError('StructFile index out of range')
+#         self.f.seek(i*self.struct_size)
+#         try: # should work when x is a kind of list
+#             self.f.write(struct.pack(self.struct_format,*x))
+#         except TypeError: # should work when x is a single element
+#             self.f.write(struct.pack(self.struct_format,x))
+            
+
+#     def flush(self):
+#         self.f.flush()
+
+#     def close(self):
+#         self.f.close()
+        
+#     def __len__(self):
+#         return int(self._len)
+
+
+def build_row_index_file(txtfilename, idxfilename, struct_format = '&lt;Q', offset= 0):
+    &quot;&quot;&quot;Creates an index file giving the offset to each line (record) in a
+    text file.    
+    &quot;&quot;&quot;
+    f = open(txtfilename)
+    index = StructFile(idxfilename,'&lt;Q','w+')
+    while True:
+        pos = f.tell()
+        line = f.readline()
+        if len(line)==0:
+            break
+        if offset &gt; 0:
+            offset-= 1
+        else:
+            index.append(pos)
+
+class FieldValues:
+    &quot;&quot;&quot;DEPRECATED -- use ListWithFieldNames instead
+    FieldValues are objects that represent a row of data by associating
+    field names with their values as object attributes.
+    &quot;&quot;&quot;
+    def __init__(self, fieldnames, values):
+        for name,val in zip(fieldnames, values):
+            setattr(self,name,val)
+
+class FieldIndex:
+    &quot;&quot;&quot;FieldIndex objects have an attribute for each field in a table
+    indicating the index of that field.
+    &quot;&quot;&quot;
+    def __init__(self, fieldnames):
+        for i in range(len(fieldnames)):
+            setattr(self,fieldnames[i],i)
+
+
+class ListWithFieldNames:
+    &quot;&quot;&quot;This allows to have a view on a sequence
+    object with associated fieldnames, so that the elements of the sequence
+    can be accessed with either its numerical position, or its
+    fieldname.&quot;&quot;&quot;
+    
+    def __init__(self, list_items, fieldnames=None, fieldpos=None):
+        &quot;&quot;&quot;elemlist can be any sequence of elements
+
+        fieldnames should be a sequence of strings of the same length as
+        elemlist
+
+        fieldpos can optionally be passed (otherwise self.fieldpos will be
+        computed from the fieldnames): it corresponds to a dictionary,
+        mapping a fieldname to its position in the list.
+        &quot;&quot;&quot;
+        self.list = list(list_items)
+        self.fieldnames = fieldnames
+        self.fieldpos = fieldpos
+        self.rownum = -1
+
+        # if autoappend is set to True, then accessing a field with [fieldname] will
+        # append it if fieldname is not already a fieldname of the list
+        # if autoappend is set to false, an error will be raised if accessing
+        self.autoappend = False
+        
+        # we suppose we may initially have shared fieldnames and fieldpos
+        # make_private_copy_of_fields will make a private copy of those, and
+        # will be called as soon as a we append or delete an item.
+        self.shared_fieldnames = True    
+
+        assert(fieldnames is None or len(fieldnames)==len(list_items))
+        if fieldnames and not fieldpos:
+            self.fieldpos = {}
+            pos = 0
+            for name in fieldnames:
+                self.fieldpos[name] = pos
+                pos += 1
+                
+    def __len__(self):
+        return len(self.list)
+
+    def __getitem__(self,key):
+        if isinstance(key,str):
+            key = self.fieldpos[key]
+        return self.list[key]
+
+    def __setitem__(self, key, value):
+        if isinstance(key,str):
+            try:
+                key = self.fieldpos[key]
+                self.list[key] = value
+            except KeyError:
+                if self.autoappend:
+                    self.append(value, key)
+                else:
+                    raise
+        else:
+            self.list[key] = value
+
+    def __delitem__(self,key):
+        if self.shared_fieldnames:
+            self.make_private_copy_of_fields()
+        if isinstance(key,str):
+            key = self.fieldpos[key]
+        del self.list[key]
+        if self.fieldnames:
+            fieldname = self.fieldnames[key]
+            del self.fieldnames[key]
+            del self.fieldpos[fieldname]
+
+    def __iter__(self):
+        return self.list.__iter__()
+
+    def __repr__(self):
+        return self.list.__repr__()
+
+    def __str__(self):
+        return self.list.__str__()
+    
+    def __add__(self, other):
+        return self.list + list(other)
+
+
+    def set_fieldnames(self,fieldnames):
+        self.fieldnames = fieldnames
+        self.fieldpos = {}
+        pos = 0
+        for name in fieldnames:
+            self.fieldpos[name] = pos
+            pos += 1
+
+    def make_private_copy_of_fields(self):
+        if self.fieldnames:
+            self.set_fieldnames(self.fieldnames[:])
+        self.shared_fieldnames = False
+
+    def append(self, val, name='?'):
+        if self.shared_fieldnames:
+            self.make_private_copy_of_fields()
+        self.list.append(val)
+        if self.fieldnames:
+            self.fieldpos[name] = len(self.fieldnames)
+            self.fieldnames.append(name)
+
+    def as_dict(self):
+        return dict(zip(self.fieldnames, self.list))
+
+
+class Table:
+    &quot;&quot;&quot;Subclasses should call self.set_fieldnames(fieldnames) with an appropriate list of fieldnames
+    And they should implement:
+      getRow(self,i) (no need to perform bound checks for i)
+      __len__(self)
+      &quot;&quot;&quot;
+
+    def set_fieldnames(self,fieldnames):
+        self.fieldnames = fieldnames
+        self.fieldpos = {}
+        pos = 0
+        for name in fieldnames:
+            self.fieldpos[name] = pos
+            pos += 1
+
+    def colname(self,i):
+        try:
+            return self.fieldnames[i]
+        except:
+            return str(i)
+
+    def get_column(self,c):
+        return [r[c] for r in self]
+
+    def set_rownames(self,rownames):
+        self.rownames = rownames
+
+    def rowname(self,i):
+        try:
+            return self.rownames[i]
+        except:
+            return str(i)
+
+    def set_title(self,title):
+        self.title_ = title
+
+    def title(self):
+        try: return self.title_
+        except: return ''            
+
+    def set_filepath(self,filepath):
+        self.filepath_ = filepath
+
+    def filepath(self):
+        try: return self.filepath_
+        except: return ''
+
+    def rename_fields(self, name_map, fieldname_must_exist = True):
+        names = self.fieldnames[:]
+        for oldname, newname in name_map.items():
+            try:
+                k = self.fieldpos[oldname]
+                names[k] = newname
+            except KeyError:
+                if fieldname_must_exist:
+                    raise ValueError('No field named '+oldname)
+        self.set_fieldnames(names)
+
+    def fieldnum(self,fieldname_or_num):
+        try:
+            return self.fieldpos[fieldname_or_num]
+        except:
+            pass
+        return int(fieldname_or_num)
+            
+    def __getitem__(self,i):
+        # print 'getitem',i
+        if isinstance(i,slice):
+            start, stop, step = i.start,i.stop,i.step
+            if step!=None:
+                raise IndexError('Extended slice with step not currently supported')
+            l = self.__len__()
+            if stop&gt;l:
+                stop = l
+            return SelectRowRange(self,start,stop)
+        else:
+            l = self.__len__()
+            if i&lt;0: i+=l
+            if i&lt;0 or i&gt;=l:
+                raise IndexError('TableFile index out of range ('+str(i)+'/'+str(l)+')')
+            row = ListWithFieldNames(self.getRow(i), self.fieldnames, self.fieldpos)
+            row.rownum = i
+            return row
+
+    def length(self):
+        return len(self)
+
+    def width(self):
+        return len(self.fieldnames)
+
+    def __concat__(self,other):
+        return VConcatTable([self,other])
+
+    def close(self):
+        pass
+
+##     def __getslice__(self,start,stop):
+##         print 'getsli
+##         l = self.__len__()
+##         if start&lt;0: start+=l
+##         if stop&lt;0: stop+=l
+##         if stop 
+##         if i&lt;0 or i&gt;=l:
+
+class StructTable(Table):
+    &quot;&quot;&quot;Table implemented as a StructFile.
+    The struct format and the field names are saved in a secondary file
+    with the same name as the data file, plus a '.format' extension.
+    This file is executed when the table is openned for read ('r' or 'r+');
+    it is created from the supplied field names and format when the table
+    is created ('w+').
+    &quot;&quot;&quot;
+    
+    def __init__(self, fname, openmode='r', fieldnames=None, struct_format=None):
+        self.set_fieldnames(fieldnames)
+        self.fname = fname
+        self.set_filepath(fname)
+        self.closed = False
+        if openmode=='r' or openmode=='r+':
+            self.load_format()
+        elif openmode=='w+':
+            self.set_format(fieldnames, struct_format)
+        else:
+            raise ValueError('Invalid openmode '+openmode)
+        
+        self.struct = StructFile(fname,self.struct_format,openmode)
+
+    def set_format(self, fieldnames, struct_format):
+            if not isinstance(fieldnames,list) or not isinstance(struct_format,str):
+                raise ValueError('You must specify the list of fieldnames and the struct_format string')
+            self.set_fieldnames(fieldnames)
+            self.struct_format = struct_format
+            self.save_format()
+            
+    def load_format(self):
+        vars = {}
+        execfile(self.fname+'.format',vars)
+        self.set_fieldnames(vars['fieldnames'])
+        self.struct_format = vars['struct_format']
+
+    def save_format(self):
+        f = open(self.fname+'.format','wb')
+        f.write('fieldnames = '+repr(self.fieldnames)+'\n\n')
+        f.write('struct_format = '+repr(self.struct_format)+'\n\n')
+        
+    def getRow(self,i):
+        return self.struct[i]
+
+    def __len__(self):
+        return len(self.struct)
+
+    def append(self, x):
+        self.struct.append(x)
+
+    def close(self):
+        if not self.closed:
+            self.struct.close()        
+            self.closed = True
+
+    # Note: it's better for your code to call close() explicitly rather than rely on this being called automatically
+    def __del__(self):
+        self.close()
+
+def compr_factor(m):
+    s = '\n'.join([ '\t'.join(r) for r in m ])
+    cs = zlib.compress(s)
+    return float(len(s))/len(cs)
+
+def compr_factor2(m):
+    w = m.width()
+    m = [ r for r in m ]
+    uncompr_len = 0
+    compr_len = 0
+    for c in range(w):
+        s = '\n'.join([r[c] for r in m])
+        uncompr_len += len(s)
+        compr_len += len(zlib.compress(s))
+    return float(uncompr_len)/compr_len
+
+def cf(m):
+    return compr_factor(m), compr_factor2(m)
+
+
+class CSVTable(Table):
+    &quot;&quot;&quot;Read-only for now&quot;&quot;&quot;
+    
+    def __init__(self, datafname, openmode=&quot;r&quot;):
+        if openmode!=&quot;r&quot;:
+            raise ValueError(&quot;Currently only openmode=='r' is supported&quot;)
+        
+        self.datafname = datafname
+        self.len = -1
+        self.f = open(datafname,'rb')
+        self.reader = csv.reader(self.f)
+        self.i = -1
+        self.row_i = self.reader.next()
+        self.set_fieldnames(self.row_i)
+        
+    def getRow(self,i):
+        if i&lt;self.i:
+            self.f.close()
+            self.f = open(self.datafname,'rb')
+            self.reader = csv.reader(self.f)
+            self.i = -1
+            self.row_i = self.reader.next()
+        
+        while self.i&lt;i:
+            self.i += 1
+            self.row_i = self.reader.next()
+
+        return self.row_i
+
+    def __len__(self):
+        if self.len&lt;0:
+            f = open(self.datafname,'rb')
+            tmpreader = csv.reader(f)
+            self.len = -1
+            for line in tmpreader:                
+                self.len += 1
+            f.close()
+        return self.len
+
+
+class CompressedTableFile(Table):
+    &quot;&quot;&quot;
+    Main file format:
+    header: PLTABLE &lt;version&gt; &lt;nrows_per_chunk&gt; \n
+    fieldnames_row
+    chunks of data
+    
+    Each chunk of data contains the zlib compressed representation of at most nrows_per_chunk \n separated rows.
+    
+    There is also an associated index file containing 8-byte integers.
+    Integer #i gives the byteindex of chunk #i.
+    The last integer gives the number of rows in the last chunk.
+    &quot;&quot;&quot;
+    
+    def __init__(self, datafname, openmode='r', fieldnames=None, nrows_per_chunk=100):
+        self.openmode = openmode
+        indexfname = datafname+'.idx'
+        self.set_filepath(datafname)
+        self.closed = False
+        self.final_chunk_rows = []
+        
+        if openmode=='r':
+            self.dataf = open(datafname,'rb')
+            self.index = StructFile(indexfname,'!Q','r')
+            self.read_header_and_fieldnames()
+            self.cached_chunk_rows = []
+            self.cached_chunknum = -1
+        elif openmode=='a' or openmode=='r+':
+            self.dataf = open(datafname,'r+b')
+            self.index = StructFile(indexfname,'!Q','r+')
+            self.read_header_and_fieldnames()
+            if self.nrows_in_last_chunk==self.nrows_per_chunk or self.nrows_in_last_chunk==0:
+                self.final_chunk_rows = []
+            else:
+                self.final_chunk_rows = self.read_chunk_rows(self.last_chunknum())
+        elif openmode=='w' or openmode=='w+': 
+            self.nrows_per_chunk = nrows_per_chunk
+            self.set_fieldnames(fieldnames)
+            self.dataf = open(datafname,'w+b')
+            self.index = StructFile(indexfname,'!Q','w+')
+            self.write_header_and_fieldnames()
+            self.final_chunk_rows = []
+            self.nrows_in_last_chunk = self.nrows_per_chunk
+        else:
+            raise ValueError('Invalid openmode: '+openmode)
+
+    def read_header_and_fieldnames(self):
+        self.dataf.seek(0)
+        headerline = self.dataf.readline()
+        headcode, version, nrows = headerline.split()
+        if headcode!='PLTABLE' or version!='01':
+            raise TypeError('Invalid header or version'+headcode+' '+version)
+        self.nrows_per_chunk = int(nrows)
+        fieldnamesline = self.dataf.readline()
+        self.set_fieldnames(fieldnamesline.split())
+        self.nrows_in_last_chunk = int(self.index[-1])
+        self._len = self.last_chunknum()*self.nrows_per_chunk + self.nrows_in_last_chunk
+        self.dataf.seek(0,2)   # seek to end of file
+
+    def last_chunknum(self):
+        return len(self.index)-3
+
+    def write_header_and_fieldnames(self):
+        self.dataf.seek(0)
+        self.dataf.write('PLTABLE 01\t'+str(self.nrows_per_chunk)+'\n')
+        self.dataf.write('\t'.join(self.fieldnames)+'\n')
+        self.dataf.flush()
+        self._len = 0
+        self.index.append(self.dataf.tell())
+        self.index.append(0)
+        self.index.flush()
+
+    def compress(self, rows):
+        return zlib.compress('\n'.join(rows))
+        # return '\n'.join(rows)
+
+    def decompress(self, encodedstring):
+        chunk = zlib.decompress(encodedstring)
+        # chunk = encodedstring
+        rows = chunk.split('\n')
+        return rows
+    
+    def read_chunk_rows(self, chunknum):
+        if chunknum&gt;self.last_chunknum():
+            raise IndexError('chunk out of range: '+str(chunknum))
+        startpos = self.index[chunknum]
+        endpos = self.index[chunknum+1]
+        self.dataf.seek(startpos)
+        encodedchunk = self.dataf.read(endpos-startpos)
+        rows = self.decompress(encodedchunk)
+        return rows
+
+    def get_chunk_rows(self, chunknum):
+        if chunknum!=self.cached_chunknum:
+            self.cached_chunk_rows = self.read_chunk_rows(chunknum)
+            self.cached_chunknum = chunknum
+        return self.cached_chunk_rows
+        
+    def getRow(self,i):
+        if self.openmode!='r':
+            raise IOError(&quot;Can only getRow if in 'r' openmode, not in &quot;+repr(self.openmode)+&quot; mode.&quot;)
+        chunknum,ii = divmod(i,self.nrows_per_chunk)
+        line = self.get_chunk_rows(chunknum)[int(ii)]
+        elements = line.split('\t')
+        return elements
+
+    def flush(self):
+        if self.openmode!='r' and self.final_chunk_rows:
+            encodedchunk = self.compress(self.final_chunk_rows)
+            # print 'Flushing with nrows_in_last_chunk = ',self.nrows_in_last_chunk,' and self.final_chunk_rows=',repr(self.final_chunk_rows)
+            if self.nrows_in_last_chunk&lt;self.nrows_per_chunk: # some more room in last chunk
+                # print 'Rewriting last chunk'
+                self.dataf.seek(self.index[self.last_chunknum()]) # seek to beginning of existing last chunk
+                self.dataf.write(encodedchunk)
+                self.index[-2] = self.dataf.tell()
+                self.nrows_in_last_chunk = len(self.final_chunk_rows)
+                self.index[-1] = self.nrows_in_last_chunk
+            else: # append new chunk
+                # print 'Appending new chunk'
+                self.dataf.seek(0,2) # seek to end of file
+                self.dataf.write(encodedchunk)
+                self.index[-1] = self.dataf.tell()
+                self.nrows_in_last_chunk = len(self.final_chunk_rows)
+                self.index.append(self.nrows_in_last_chunk)
+            if len(self.final_chunk_rows)==self.nrows_per_chunk:
+                self.final_chunk_rows = []
+            self.dataf.flush()
+            self.index.flush()    
+
+    def close(self):
+        if not self.closed:
+            self.flush()
+            self.dataf.close()
+            self.index.close()
+            self.closed = True
+
+    def append(self, row):
+        if self.openmode not in ['w','a','w+','r+']:
+            raise IOError(&quot;Can only append if in 'w','w+','r+' or 'a' openmode, not in &quot;+repr(self.openmode)+&quot; mode.&quot;)
+        if len(row)!=self.width():
+            raise ValueError('length of row does not match table width')
+        self.final_chunk_rows.append('\t'.join([ str(elem).strip() for elem in row]))
+
+        if len(self.final_chunk_rows)==self.nrows_per_chunk:
+            self.flush()
+        self._len += 1
+
+    # Note: it's better for your code to call close() explicitly rather than rely on this being called automatically
+    def __del__(self):
+        self.close()
+
+    def __len__(self):
+        return int(self._len)
+
+
+        
+
+class MemoryTable(Table):
+    &quot;&quot;&quot;Table saved in RAM.
+    This is a simple list of lists of fields; field names must be supplied to
+    the constructor.
+    &quot;&quot;&quot;
+
+    def __init__(self, fieldnames, data=None):
+        self.set_fieldnames(fieldnames)
+        if data==None:
+            self.data = []
+        else:
+            self.data = data
+        
+    def append(self,elements):
+        if len(elements)!=len(self.fieldnames):
+            raise ValueError(&quot;elements (len=&quot;+str(len(elements))+&quot;) must be a vector of same length as fieldnames (len=&quot;+str(len(self.fieldnames))+&quot;)&quot;)
+        self.data.append(elements)
+    
+    def getRow(self,i):
+        return self.data[i][:]
+
+    def __len__(self):
+        return len(self.data)
+
+def memorize(table):
+    &quot;&quot;&quot;Loads a table in memory: fetches all rows from table into a
+    MemoryTable and returns that object.
+    &quot;&quot;&quot;
+    mtable = MemoryTable(table.fieldnames)
+    for row in table:
+        mtable.append(row)
+    return mtable
+
+
+class PMatTable(Table):
+    &quot;&quot;&quot;Matrix of reals saved on disk in binary format.
+    The data file starts with a 64 bytes header that indicates:
+    - the number of rows in the table
+    - the number of fields in a row
+    - the data type (float or double)
+    - the endianness of the data
+    The rest is the data itself, in a fixed width format.
+    Other data is saved in a subdirectory with the same name as the
+    data file, plus a '.metadata' extension.  For example, field names
+    are saved in '&lt;table_name&gt;.metadata/fieldnames', one name per line.
+    &quot;&quot;&quot;
+    def __init__(self, fname, openmode='r', fieldnames=None):
+        self.fname = fname
+        self.set_filepath(fname)
+        if openmode=='r':
+            self.f = open(fname,'rb')
+            self.read_and_parse_header()
+            self.set_fieldnames(self.determine_fieldnames())
+        else:
+            raise ValueError(&quot;Currently only supported openmode is 'r'.&quot;+repr(openmode)+&quot; is not supported&quot;)
+
+    def read_and_parse_header(self):        
+            header = self.f.read(64)
+            mat_type, l, w, data_type, endianness = header.split()
+            if mat_type!='MATRIX':
+                raise ValueError('Invalid file header (should start with MATRIX)')
+            self.len = int(l)
+            self.w = int(w)
+            if endianness=='LITTLE_ENDIAN':              
+                struct_format = '&lt;'
+            elif endianness=='BIG_ENDIAN':
+                struct_format = '&gt;'
+            else:
+                raise ValueError('Invalid endianness in file header: '+endianness)
+
+            if data_type=='DOUBLE':
+                struct_format += 'd'*self.w
+            elif data_type=='FLOAT':
+                struct_format += 'f'*self.w
+                
+            self.struct_format = struct_format
+            self.struct_size = struct.calcsize(struct_format)
+
+    def determine_fieldnames(self):
+        fieldnames = []
+        fieldnamefile = os.path.join(self.fname+'.metadata','fieldnames')
+        if os.path.isfile(fieldnamefile):
+            for row in open(fieldnamefile):
+                row = row.split()
+                if len(row)&gt;0:
+                    fieldnames.append(row[0])
+        else:
+            fieldnames = map(str,range(self.w))
+        return fieldnames
+
+    def getRow(self,i):
+        self.f.seek(64+i*self.struct_size)
+        x = struct.unpack(self.struct_format,self.f.read(self.struct_size))
+        return list(x)
+
+    def __len__(self):
+        return int(self.len)
+
+
+
+class TableFile(Table):
+    &quot;&quot;&quot;Table saved as a tab separated text file (variable width records.)
+    An index giving the offset to each record is saved in a file with the same
+    name as the data file, plus a '.idx' extension; this index is a simple list
+    of 64 bit offsets in binary format.
+    The first line of the data file contains the field names, separated by
+    tabs; these must be supplied when the file is created ('w+').
+    &quot;&quot;&quot;
+
+    def __init__(self, fname, openmode='r', fieldnames=None,
+                 tolerate_different_field_count=True, separator='\t'):
+        self.separator= separator
+        self.struct_format = '&lt;Q'
+        self.fname = fname
+        self.set_filepath(fname)
+        self.closed = False
+        self.openmode = openmode
+        self.tolerate_different_field_count = tolerate_different_field_count
+        self.last_call_was_append = False
+       
+        indexfname = self.fname+'.idx'
+        if openmode=='r':
+            self.f = open(fname,'r')
+            fieldnames = self.f.readline().strip('\r\n').split(self.separator)
+            self.set_fieldnames(fieldnames)
+            if not os.path.isfile(indexfname):
+                build_row_index_file(fname,indexfname,self.struct_format)
+            self.index = StructFile(indexfname,self.struct_format,'r')
+        elif openmode=='r+':
+            self.f = open(fname,'r+')
+            fieldnames = self.f.readline().strip('\r\n').split(self.separator)
+            self.set_fieldnames(fieldnames)
+            if not os.path.isfile(indexfname):
+                build_row_index_file(fname,indexfname)
+            self.index = StructFile(indexfname,self.struct_format,'r+')
+        elif openmode=='w+':
+            self.f = open(fname,'w+')
+            fieldnames = fieldnames[:]
+            self.set_fieldnames(fieldnames)
+            self.index = StructFile(indexfname,self.struct_format,'w+')
+            self.append(fieldnames)
+        else:
+            raise ValueError(&quot;Invalid value for openmode (&quot;+`openmode`+&quot; Must be one of 'r' 'r+' or 'w+'&quot;)
+
+            
+    def append(self,elements):
+        if len(elements)!=len(self.fieldnames):
+            raise ValueError(&quot;elements must be a vector of same length as fieldnames&quot;)
+
+        self.index.append(self.f.tell())
+        
+        if not self.last_call_was_append:
+            self.f.seek(0,2) # seek to end of file
+
+        self.f.write(self.separator.join(map(str,elements))+'\r\n')
+        
+        self.last_call_was_append = True
+
+    def flush(self):
+        if self.openmode!='r':
+            self.f.flush()
+            self.index.flush()
+
+    def close(self):
+        if not self.closed:
+            self.flush()
+            self.f.close()
+            self.index.close()
+            self.closed = True
+
+    # Note: it's better for your code to call close() explicitly rather than rely on this being called automatically
+    def __del__(self):
+        self.close()
+
+    def getRow(self,i):
+        self.last_call_was_append = False
+        
+        self.f.seek(self.index[i+1])
+        line = self.f.readline().strip('\r\n')
+        elements = line.split(self.separator)
+        if len(elements)!=len(self.fieldnames):
+            if self.tolerate_different_field_count:
+                if len(elements)&lt;len(self.fieldnames):
+                    elements += ['']*(len(self.fieldnames)-len(elements))
+                else: # len(elements)&gt;len(self.fieldnames)
+                    elements = elements[0:len(self.fieldnames)]
+            else:
+                raise ValueError(&quot;At row &quot;+str(i)+
+                                 &quot;, read only &quot;+str(len(elements))+
+                                 &quot; while there are &quot;+str(len(self.fieldnames))+
+                                 &quot; fieldnames&quot;)
+        return map(string.strip, elements)
+
+    def __len__(self):
+        return len(self.index)-1
+
+
+class SortWithinGroup(Table):
+    &quot;&quot;&quot;Creates a view from an existing table by grouping
+    records and then sorting records within a group.  Grouping is made
+    according to the supplied grouping fields: all consecutive records with
+    the same values for all those fields will be part of the same group.  The
+    group is then sorted according to the supplied sorting fields (ascending,
+    in the same order the fields are given.)
+    &quot;&quot;&quot;
+    def __init__(self, table, grouping_fields, sorting_fields):
+        self.table = table
+        self.set_fieldnames(table.fieldnames)
+        self.grouping_fields = [self.fieldnum(f) for f in grouping_fields]
+        self.sorting_fields = [self.fieldnum(f) for f in sorting_fields]
+        self.cached_group_start = None
+        self.cached_group_end = None
+        self.cached_group = None
+    
+    def getRow(self,i):
+
+        if self.cached_group and i&gt;=self.cached_group_start and i&lt;self.cached_group_end:
+            return self.cached_group[i-self.cached_group_start]
+
+        row_i = self.table[i]
+        groupkeys = [ row_i[k] for k in self.grouping_fields ]
+
+        group = []
+        pos = i-1
+        while pos&gt;=0:
+            row = self.table[pos]
+            if [ row[k] for k in self.grouping_fields ] != groupkeys:
+                break
+            group.append(row)
+            pos -= 1
+        
+##         if pos&gt;=0:
+##             row = self.table[pos]
+##         while(pos&gt;=0 and [ row[k] for k in self.grouping_fields ] == groupkeys):
+##             group.append(row)
+##             pos -= 1
+##             if pos&gt;=0:
+##                 row = self.table[pos]
+
+        self.cached_group_start = pos+1
+        group.reverse()
+        group.append(row_i)
+
+        l = len(self.table)
+        pos = i+1
+        while pos&lt;l:
+            row = self.table[pos]
+            if [ row[k] for k in self.grouping_fields ] != groupkeys:
+                break
+            group.append(row)
+            pos += 1
+            
+        
+##         row = self.table[pos]
+##         while(pos&lt;l and [ row[k] for k in self.grouping_fields ] == groupkeys):
+##             group.append(row)
+##             pos += 1
+##             print 'getting ',pos,l
+##             if pos&lt;l:
+##                 row = self.table[pos]
+
+        self.cached_group_end = pos
+
+        def cmpfunc(x,y):
+            xkeys = [ x[k] for k in self.sorting_fields ]
+            ykeys = [ y[k] for k in self.sorting_fields ]
+            return cmp(xkeys, ykeys)
+        
+        group.sort(cmpfunc)
+        self.cached_group = group
+
+        return list(self.cached_group[i-self.cached_group_start])
+
+    def __len__(self):
+        return len(self.table)
+
+
+class SelectRowRange(Table):
+    &quot;&quot;&quot;Creates view of a table by extracting a range of rows from an
+    existing table.
+    &quot;&quot;&quot;
+    def __init__(self, table, start, stop):
+        self.table = table
+        self.start = start
+        self.stop = stop
+        try: self.set_fieldnames(table.fieldnames)
+        except: pass
+
+    def getRow(self,i):
+        #return self.table[self.start+i]
+        return self.table.getRow(self.start+i)
+
+    def __len__(self):
+        return int(self.stop-self.start)
+
+
+class VConcatTable(Table):
+    &quot;&quot;&quot;Creates a view by concatenating the rows of several
+    existing tables.  All tables must have the same fields.
+    &quot;&quot;&quot;
+    def __init__(self, tables):
+        self.tables = tables
+        self.set_fieldnames(tables[0].fieldnames)
+        for t in tables:
+            if t.fieldnames != self.fieldnames:
+                print &quot;got: &quot;, t.fieldnames
+                print &quot;s/b: &quot;, self.fieldnames
+                raise RuntimeError('In VConcatTable fieldnames of the individual tables differ')
+
+    def getRow(self,i):
+        start = 0
+        stop = 0
+        for t in self.tables:
+            stop += len(t)
+            if i&lt;stop:
+                #return t[i-start]
+                return t.getRow(i-start)
+            start = stop
+        raise IndexError('In VConcatTable: index out of range')
+
+    def __len__(self):
+        l = 0
+        for t in self.tables:
+            l += len(t)
+        return l
+
+class HConcatTable(Table):
+    &quot;&quot;&quot;Creates a view by concatenating the fields of several
+    existing tables.  All tables must have the same number of rows.
+    &quot;&quot;&quot;
+    def __init__(self, tables):
+        self.tables = [] 
+        fieldnames = []
+        l = len(tables[0])
+        for table in tables:
+            if len(table)!=l:
+                raise RuntimeError('In HConcatTable length of the individual tables differ')
+            self.tables.append(table)
+            fieldnames.extend(table.fieldnames)
+        self.set_fieldnames(fieldnames)
+
+    def getRow(self,i):
+        row = []
+        for table in self.tables:
+            #row.extend(table[i])
+            row.extend(table.getRow(i))
+        return row
+
+    def __len__(self):
+        return len(self.tables[0])
+        
+class SelectRows(Table):
+    &quot;&quot;&quot;Creates a view by selecting specific rows from an
+    existing table, in the given order.
+    &quot;&quot;&quot;
+    def __init__(self, table, indexes):
+        self.table = table
+        self.indexes = indexes
+        #///***///***///***
+        # ARGHHH!!! FIXME:
+        try: self.set_fieldnames(table.fieldnames)
+        except: pass
+
+    def getRow(self,i):
+        #return self.table[self.indexes[i]]
+        #///***///***///***
+        # TODO: make sure this is OK (not that ^)
+        return self.table.getRow(self.indexes[i])
+
+    def __len__(self):
+        return len(self.indexes)
+
+class UpsideDownTable(Table):
+    &quot;&quot;&quot;Creates a view of a table with rows in reverse order&quot;&quot;&quot;
+    def __init__(self, table):
+        self.table = table
+        try: self.set_fieldnames(table.fieldnames)
+        except: pass
+
+    def getRow(self,i):
+        #return self.table[len(self.table)-1-i]
+        return self.table.getRow(len(self.table)-1-i)
+
+    def __len__(self):
+        return len(self.table)
+
+class AddFieldsTable(Table):
+    def __init__(self, table, extra_fields):
+        self.table= table
+        self.extra_fields= extra_fields
+        self.set_fieldnames(table.fieldnames + extra_fields)
+
+        
+    def getRow(self,i):
+        return self.table.getRow(i) + ['' for f in self.extra_fields]
+        
+    def __len__(self):
+        return len(self.table)
+    
+
+class SelectFields(Table):
+    &quot;&quot;&quot;Returns a view of a table by selecting only some of the fields.
+    &quot;&quot;&quot;
+
+    def __init__(self, table, selected_fields, newnames=[], must_exist=True):
+        &quot;&quot;&quot;Returns a view of table with only the selected_fields (in that order).
+        selected_fields is a list of fieldnames or fieldpositions in the original table.
+        The fields can optionally be renamed by giving a non-empty list of newnames
+        (which must be the same length as the selected_fields list)&quot;&quot;&quot;
+        
+        if len(newnames)==0:
+            newnames = selected_fields
+        elif len(newnames)!= len(selected_fields):
+            raise ValueError('In SelectFields invalid specification of newnames len(newnames) is not 0 and is different from len(selected_fields)')
+
+        self.table = table
+        self.fieldnums = []
+        fieldnames = []
+        for field,newname in zip(selected_fields,newnames):
+            if isinstance(field,int):
+                self.fieldnums.append(field)
+                fieldnames.append(table.fieldnames[field])
+            else:
+                try: pos = table.fieldnames.index(field)
+                except ValueError: pos = -1
+                if pos&gt;=0:
+                    self.fieldnums.append(pos)
+                    fieldnames.append(newname)
+                elif must_exist:
+                    raise ValueError('In SelectFields invalid field specification: '+repr(field)+'\n Fields are:'+repr(table.fieldnames))
+        self.set_fieldnames(fieldnames)
+
+    def getRow(self,i):
+        row = self.table[i]
+        return [ row[field] for field in self.fieldnums ]
+
+    def __len__(self):
+        return len(self.table)
+
+def DeleteFields(table, deleted_fields):
+    &quot;&quot;&quot;Creates a SelectFields table by selecting all table fields _not_ listed
+    in deleted_fields.
+    &quot;&quot;&quot;
+    selected_fields = [ field for field in table.fieldnames if field not in deleted_fields ]
+    return SelectFields(table,selected_fields)
+
+def GeneratedTable(tablefname, generating_func, list_of_dependencies=[]):
+    &quot;&quot;&quot;Opens a table with dependencies, regenerating the table when necessary.
+    The last modification time of the table is compared against the last
+    modification time of each file listed in list_of_dependencies.  If some
+    dependency was modified after the table, generating_func is called
+    prior to openning the file.
+    &quot;&quot;&quot;
+    try:
+        target_mtime = os.path.getmtime(tablefname)
+    except OSError:
+        target_mtime = 0
+
+    dep_mtime = 0
+    for fname in list_of_dependencies:
+        try:
+            mtime = os.path.getmtime(fname)
+        except OSError:
+            mtime = 0
+        if mtime&gt;dep_mtime:
+            dep_mtime = mtime
+
+    if target_mtime==0 or dep_mtime&gt;target_mtime:
+        generating_func()
+
+    return openTable(tablefname)
+
+#     def getRow(self,i):
+#         row = self.table.getRow
+#         t = FieldValues(self.table.fieldnames, self.table[i])
+#         t._rownum_ = i
+#         self.processingfunc(t)
+#         return [ getattr(t,fieldname) for fieldname in self.fieldnames ]
+    
+#     def __len__(self):
+#         return len(self.table)
+
+
+class ProcessFields(Table):
+    &quot;&quot;&quot;DEPRECATED -- use ProcessFields2 instead
+    Creates a view by mapping a function on each row of an existing table.
+    processingfunc must take a FieldValues object and modify it in place.
+    newfieldnames is a list of names of fields to be added to the already
+    existing fields; these should be created by processingfunc.
+    &quot;&quot;&quot;
+    def __init__(self, table, processingfunc, newfieldnames=[]):
+        self.table = table
+        self.processingfunc = processingfunc
+        fieldnames = table.fieldnames+newfieldnames
+        self.set_fieldnames(fieldnames)
+
+    def getRow(self,i):
+        t = FieldValues(self.table.fieldnames, self.table[i])
+        t._rownum_ = i
+        self.processingfunc(t)
+        return [ getattr(t,fieldname) for fieldname in self.fieldnames ]
+    
+    def __len__(self):
+        return len(self.table)
+
+class ProcessFields2(Table):
+    &quot;&quot;&quot;Creates a view by applying a function to each row of an existing table.
+    processingfunc must work in place on a ListWithFieldNames object, to
+    which it can add fields if autoappend is True.
+    &quot;&quot;&quot;
+    def __init__(self, table, processingfunc, autoappend=False):
+        self.table = table
+        self.processingfunc = processingfunc
+        self.autoappend = autoappend
+        row = table[0]
+        row.autoappend = self.autoappend
+        processingfunc(row)
+        self.set_fieldnames(row.fieldnames)
+
+    def getRow(self,i):
+        row = self.table[i]
+        row.autoappend = self.autoappend
+        self.processingfunc(row)
+        return list(row)
+    
+    def __len__(self):
+        return len(self.table)
+
+class AppendRownum(Table):
+    &quot;&quot;&quot;Creates a view from an existing table by adding a field that contains
+    the row number.
+    &quot;&quot;&quot;
+    def __init__(self, table, rownum_fieldname='rownum'):
+        self.table = table
+        fieldnames = table.fieldnames+[rownum_fieldname]
+        self.set_fieldnames(fieldnames)
+
+    def getRow(self,i):
+        #return self.table[i]+[i]
+        return list(self.table.getRow(i))+[i]
+    
+    def __len__(self):
+        return len(self.table)
+
+class AppendConstantFields(Table):
+    &quot;&quot;&quot;Creates a view from an existing table by appending a list of fields with 
+    constant values.
+    &quot;&quot;&quot;
+    def __init__(self, table, extra_fieldnames, extra_fieldvals):
+        self.table = table
+        self.set_fieldnames(table.fieldnames+extra_fieldnames)
+        self.extra_fieldvals = extra_fieldvals
+
+    def getRow(self,i):
+        #return self.table[i]+self.extra_fieldvals
+        return self.table.getRow(i)+self.extra_fieldvals
+    
+    def __len__(self):
+        return len(self.table)
+
+class StrippedFieldsTable(Table):
+    &quot;&quot;&quot;Creates a view from an existing table by stripping all leading
+    and trailing whitespace from text fields.  If stripquotes is true, double
+    quotes and leading and trailing whitespace within those quotes will also
+    be stripped.
+    &quot;&quot;&quot;
+    def __init__(self, table, stripquotes=True):
+        self.stripquotes = stripquotes
+        self.table = table
+        self.set_fieldnames(table.fieldnames)
+
+    def mystrip(self,val):
+        if isinstance(val,str):
+            val = val.strip()
+            if self.stripquotes and len(val)&gt;=2 and val[0]=='&quot;' and val[-1]=='&quot;':
+                val = val[1:-1].strip()
+        return val
+            
+
+    def getRow(self,i):
+        #return map(self.mystrip, self.table[i])
+        return map(self.mystrip, self.table.getRow(i))
+    
+    def __len__(self):
+        return len(self.table)
+
+
+class CacheTable(Table):
+    &quot;&quot;&quot;Creates a direct view of an existing table and caches the last
+    max_nrows_in_cache rows fetched in RAM.
+    &quot;&quot;&quot;
+    def __init__(self, table, max_nrows_in_cache=200):
+        self.table = table
+        self.max_nrows_in_cache = 200
+        self.set_fieldnames(table.fieldnames)
+        self.cached_rownum = []
+        self.cached_rows = []
+
+    def getRow(self,i):
+
+        try:
+            k = self.cached_rownum.index(i)
+            return self.cached_rows[k]
+        except ValueError:
+            row = self.table.getRow(i)
+            if len(self.cached_rows)&gt;=self.max_nrows_in_cache:
+                del self.cached_rows[0]
+                del self.cached_rownum[0]
+            self.cached_rows.append(row)
+            self.cached_rownum.append(i)
+            return row
+            
+    def clearCache(self):
+        self.cached_rownum = []
+        self.cached_rows = []
+    
+    def __len__(self):
+        return len(self.table)
+
+class ShuffleTable(SelectRows):
+    &quot;&quot;&quot;Creates a view of an existing table with rows randomly permuted.
+    If no seed is given, this will always generate the same permutation.
+    &quot;&quot;&quot;
+    def __init__(self, table, seed_x=123, seed_y=456):
+        random_array.seed(seed_x,seed_y)
+        indexes = random_array.permutation(len(table))
+        SelectRows.__init__(self, table, indexes)
+        
+
+class FilterTable(SelectRows):
+    &quot;&quot;&quot;DEPRECATED -- use FilterTable2 instead
+    Creates a view of an existing table by selecting some of the rows
+    according to boolfunc.  An indexfile can also be supplied to save/restore
+    the indexes of rows selected by boolfunc.
+    boolfunc must be a predicate that takes a FieldValues parameter.
+    &quot;&quot;&quot;
+    def __init__(self, table, boolfunc, indexfile=&quot;&quot;):
+            
+        if os.path.isfile(indexfile):
+            indexes = StructFile(indexfile, '&lt;L', 'r')
+            
+        else: # create indexes
+            if indexfile=='':
+                indexes = []
+            else:
+                indexes = StructFile(indexfile+'.tmp', '&lt;L', 'w+')
+            l = len(table)
+            pbar = PBar('Filtering',l)
+            for i in xrange(l):
+                t = FieldValues(table.fieldnames, table[i])
+                if boolfunc(t):
+                    indexes.append(i)
+                pbar.update(i)
+            pbar.close()
+            if indexfile!='':
+                os.rename(indexfile+'.tmp',indexfile)
+
+        SelectRows.__init__(self, table, indexes)
+
+
+class FilterTable2(SelectRows):
+    &quot;&quot;&quot;Creates a view of an existing table by selecting some of the rows
+    according to boolfunc.  An indexfile can also be supplied to save/restore
+    the indexes of rows selected by boolfunc.
+    boolfunc must be a predicate that takes a ListWithFieldNames parameter.
+    &quot;&quot;&quot;
+    def __init__(self, table, boolfunc, indexfile=&quot;&quot;):
+
+        struct_fmt= '&lt;L'
+            
+        if os.path.isfile(indexfile):
+            indexes = StructFile(indexfile, struct_fmt, 'r')
+            
+        else: # create indexes
+            if indexfile=='':
+                indexes = []
+            else:
+                indexes = StructFile(indexfile+'.tmp', struct_fmt, 'w+')
+            l = len(table)
+            pbar = PBar('Filtering',l)
+            for i in xrange(l):
+                if boolfunc(table[i]):
+                    indexes.append(i)
+                pbar.update(i)
+            pbar.close()
+            if indexfile!='':
+                indexes.close()
+                os.rename(indexfile+'.tmp',indexfile)
+                indexes= StructFile(indexfile,struct_fmt)
+
+        SelectRows.__init__(self, table, indexes)
+
+class BootstrapTable(SelectRows):
+    &quot;&quot;&quot;Creates a table by sampling (with replacement) 
+       the rows of an original table.
+       Unweighted version: tables (original and sample) are of same length.
+       Weighted version: total weight of sample table is made close to the original's
+    &quot;&quot;&quot;
+    def __init__(self, table, manualseed=&quot;&quot;, weightfield=&quot;&quot;, indexfile=&quot;&quot;, verbose=1):
+
+        def binsearch(x,vec):
+            vec = [0] + vec
+            n = len(vec)
+            il = 0
+            ih = n-1
+            while ih - il &gt; 1: 
+                im = int((ih+il)/2)
+                if x &gt; vec[im]:
+                    il = im
+                else:
+                    ih = im
+            return il
+            
+        struct_fmt= '&lt;L'
+            
+        if os.path.isfile(indexfile):
+            indexes = StructFile(indexfile, struct_fmt, 'r')
+            
+        else: # create indexes
+            if indexfile=='':
+                indexes = []
+            else:
+                indexes = StructFile(indexfile+'.tmp', struct_fmt, 'w+')
+            l = len(table)
+            if manualseed: seed(manualseed)
+            if not weightfield:
+                if verbose:
+                    pb = PBar('Sampling table',l) 
+                for i in range(l):
+                    if verbose:
+                        pb.update(i)
+                    indexes.append(randint(0,l-1))
+                if verbose:
+                    pb.close()
+            else:
+                cumw = l*[0]
+                totw = 0
+                for i in range(l):
+                    totw += table[i][weightfield]
+                    cumw[i] = totw
+                totw_sam = 0
+                if verbose:
+                    pb = PBar('Sampling table', int(totw))
+                while totw_sam &lt; totw:
+                    if verbose:
+                        pb.update(int(totw_sam))
+                    cw = totw * uniform(0,1)
+                    i = binsearch(cw,cumw)
+                    indexes.append(i)
+                    wi = table[i][weightfield]
+                    totw_sam += wi
+                if wi &lt; 2*(totw_sam - totw):
+                    indexes.pop()
+                if verbose:
+                    pb.close()
+            if indexfile!='':
+                indexes.close()
+                os.rename(indexfile+'.tmp',indexfile)
+                indexes= StructFile(indexfile,struct_fmt)
+
+        SelectRows.__init__(self, table, indexes)
+
+class SortTable(SelectRows):
+    &quot;&quot;&quot;Creates a view of an existing table by sorting the rows in
+    ascending order of sortfields.  An index file name can be supplied
+    to save/restore the index so that it does not need to be recalculated.
+    &quot;&quot;&quot;
+    def __init__(self, table, sortfields, indexfile=&quot;&quot;, reverse=False, verbose=1):
+            
+        if os.path.isfile(indexfile):
+            indexes = StructFile(indexfile, '&lt;L', 'r')
+            
+        else: # create indexes
+            sortfields = [ isinstance(field,int) and field or table.fieldnames.index(field) for field in sortfields ]
+            keylist = []
+            l = len(table)
+            if verbose:
+                pbar = PBar('Reading fields to be sorted',l)
+            for i in xrange(l):
+                row = table[i]
+                keylist.append( [ row[field] for field in sortfields ]+[i] )
+                if verbose:
+                    pbar.update(i)
+            keylist.sort(reverse=reverse)
+            if indexfile==&quot;&quot;:
+                indexes = [ row[-1] for row in keylist ]
+            else:
+                indexes = StructFile(indexfile+'.tmp', '&lt;L', 'w+')
+                if verbose:
+                    pbar = PBar('Writing sorted index',l)
+                for row,i in zip(keylist,xrange(l)):
+                    indexes.append(row[-1])
+                    if verbose:
+                        pbar.update(i)
+                os.rename(indexfile+'.tmp',indexfile)
+
+        SelectRows.__init__(self, table, indexes)
+
+
+class EfficientSortTable(SelectRows):
+    &quot;&quot;&quot;Creates a view of an existing table by sorting rows in ascending order
+    of a single numeric field.  Can be more memory efficient than SortTable.
+    &quot;&quot;&quot;
+    def __init__(self, table, sortfield, sortfieldtype='d', indexfile=&quot;&quot;):
+            
+        if os.path.isfile(indexfile):
+            indexes = StructFile(indexfile, '&lt;L', 'r')
+            
+        else: # create indexes
+            if not isinstance(sortfield,int):
+                sortfield = table.fieldnames.index(sortfield)
+
+            l = len(table)
+            keys = array(type=sortfieldtype, shape=(l,) )
+            pbar = PBar('Reading fields to be sorted',l)
+            for i in xrange(l):
+                key = table[i][sortfield]
+                keys[i] = float(key)
+                pbar.update(i)
+
+            indexarray = argsort(keys)
+            if indexfile==&quot;&quot;:
+                indexes = indexarray
+            else:
+                indexes = StructFile(indexfile+'.tmp', '&lt;L', 'w+')
+                pbar = PBar('Writing sorted index',l)
+                for pos in indexarray:
+                    indexes.append(pos)
+                    pbar.update(i)
+                os.rename(indexfile+'.tmp',indexfile)
+
+        SelectRows.__init__(self, table, indexes)
+
+
+        
+
+def group_by(table, selected_fields):
+    &quot;&quot;&quot;Creates a generator that acts like a list of sub tables, where the rows
+    are grouped by field values of selected_fields to make each sub table.
+    &quot;&quot;&quot;
+    fieldnums = []
+    for field in selected_fields:
+        try:
+            if isinstance(field,int):
+                fieldnums.append(field)
+            else:
+                fieldnums.append(table.fieldnames.index(field))
+        except ValueError:
+            raise ValueError('In table.group_by invalid field specification: '+repr(field)+'\n Fields are:'+repr(table.fieldnames))
+
+    row = table[0]
+    current_values = [ row[field] for field in fieldnums ]
+    start = 0
+    # print len(table)
+    for stop in xrange(len(table)):
+        # print stop
+        row = table[stop]
+        values = [ row[field] for field in fieldnums ]
+        if values!=current_values:
+            yield table[start:stop]
+            current_values = values
+            start = stop
+    yield table[start:len(table)]
+
+
+def float_or_NaN_if_empty(x):
+    &quot;&quot;&quot;Returns a float from another value, or NaN if the parameter is
+    the empty string.
+    &quot;&quot;&quot;
+    if x=='':
+        return fpconst.NaN
+    else:
+        return float(x)
+
+
+class FieldTypeStats:
+
+    def __init__(self):
+        self.n = 0
+        self.n_missing_value = 0
+        self.n_numerical_value = 0
+        self.n_other_value = 0
+        self.n_numerical_type = 0
+        self.min_value = None
+        self.max_value = None
+                
+    def __repr__(self):
+        return 'FieldTypeStats(' + \
+        'n ='+ repr(self.n) + \
+        ', n_missing_value ='+ repr(self.n_missing_value) + \
+        ', n_numerical_value ='+ repr(self.n_numerical_value) + \
+        ', n_other_value ='+ repr(self.n_other_value) + \
+        ', n_numerical_type ='+ repr(self.n_numerical_type) + \
+        ', min_value ='+ repr(self.min_value) + \
+        ', max_value ='+ repr(self.max_value) + ')'       
+
+    def update(self, val):
+        self.n += 1
+        if isinstance(val, (int, long, float, bool)):
+            self.n_numerical_type += 1
+            
+        if val is None or val==&quot;&quot;:
+            self.n_missing_value += 1
+        else:
+            try:
+                numval = float(val)
+                self.n_numerical_value +=1
+                if self.min_value is None:
+                    self.min_value = numval
+                    self.max_value = numval
+                else:
+                    self.min_value = min(numval, self.min_value)
+                    self.max_value = max(numval, self.max_value)
+            except ValueError:
+                self.n_other_value += 1
+
+    def smap_start_id(self):
+        if self.max_value is None:
+            return 1
+        else:
+            return int(self.max_value+1)
+        
+
+class StringMapFile:
+
+    def __init__(self, filepath, openmode='a', startid=1):
+        if openmode not in &quot;rwa&quot;:
+            raise ValueError(&quot;openmode must be one of 'r','w','a'&quot;)
+        self.startid = startid
+        self.maxid = None
+        self.filepath = filepath
+        self.openmode = openmode
+        self.map = {}
+        if openmode=='r':
+            self.load_map()
+        elif openmode=='w':
+            self.f = open(filepath,'w')
+        elif openmode=='a':
+            if os.path.exists(filepath):
+                self.load_map()
+            self.f = open(filepath,'a')
+
+    def load_map(self):
+        f = open(self.filepath,'r')
+        for row in f:
+            pos = row.rfind(' ')
+            strval = row[1:pos-1]
+            numid = float(row[pos+1:])
+            self.map[strval] = numid
+            if self.maxid is None:
+                self.maxid = numid
+            else:
+                self.maxid = max(numid, self.maxid)
+        f.close()
+
+    def __getitem__(self,strval):
+        return self.map[str(strval)]
+
+    def __len__(self):
+        return len(self.map)
+
+    def append(self, strval, numid=None):
+        strval = str(strval) # make sure it's a string
+        if numid is None:
+            if self.maxid is None:
+                self.maxid = self.startid
+            else:
+                self.maxid += 1
+            numid = self.maxid
+        # self.f.seek(0,2)
+        print &gt;&gt; self.f, '&quot;'+strval.replace('&quot;','\\&quot;')+'&quot;', numid
+        self.map[strval] = numid
+        self.flush()
+        return numid
+            
+    def close(self):
+        self.f.close()
+        
+    def flush(self):
+        self.f.flush()
+
+def computeFieldTypeStats(table, show_progress=True):
+    w = table.width()
+    stats = []
+    for j in xrange(w):
+        stats.append(FieldTypeStats())
+    if show_progress:
+        pbar = PBar('Computing stats',len(table))
+    i = 0
+    for row in table:
+        for j in xrange(w):
+            stats[j].update(row[j])
+        if show_progress:
+            pbar.update(i)
+        i += 1
+    if show_progress:
+        pbar.close()
+
+    return stats
+
+def saveFieldTypeStats(stats, fieldnames, statsfname):
+    f = open(statsfname,'w')
+    for fieldname,stat in zip(fieldnames,stats):
+        print &gt;&gt; f, fieldname, ': ', stat
+    f.close()
+
+def saveTableAsVMAT(table, vmat_name, stringmap_reference_dir=&quot;&quot;, show_progress=True, overwrite=True):
+    ext = os.path.splitext(vmat_name)[1]
+    assert ext in ['.dmat', '.pmat']
+
+    ## What should we do if the VMat aleardy exists?
+    if os.path.exists(vmat_name):
+        ## Erase VMat
+        if overwrite:
+            vmat_metadata = vmat_name + '.metadata'
+            rm_cmd = 'rm -fr %s %s' %(vmat_name, vmat_metadata)
+            subprocess.Popen(rm_cmd, shell=True, bufsize=0, stdout=subprocess.PIPE).stdout.read()
+        else:
+            raise RuntimeError, 'File or directory path &quot;%s&quot; already exists.' %vmat_name
+
+    if isinstance(table, str):
+        table = openTable(table)
+    width = table.width()
+
+    if ext == '.pmat':
+        vmat = FileVMatrix(filename=vmat_name, width=width, length=0)
+    elif ext == '.dmat':
+        vmat = DiskVMatrix(dirname=vmat_name, writable=True, width=width, length=0)
+    print 'len(table) = ', len(table)
+    print 'table.fieldnames = ', table.fieldnames
+    print 'vmat_name = ', vmat_name
+    print 'vmat = ', vmat
+    vmat.declareFieldNames(table.fieldnames)
+    vmat.saveFieldInfos()
+
+    if stringmap_reference_dir==&quot;&quot;:
+        if show_progress:
+            i = 0
+            pbar = PBar('Saving '+vmat_name, len(table))
+        for row in table:
+            vmat.appendRow( [ float_or_NaN_if_empty(e) for e in row ] )
+            if show_progress:
+                pbar.update(i)
+                i += 1
+        if show_progress:
+            pbar.close()
+
+    else: # we have a reference directory from which to retrieve/store stringmaps
+        refdir = os.path.join(stringmap_reference_dir,&quot;mappings&quot;)
+        if not os.path.isdir(refdir):
+            os.makedirs(refdir)
+
+        logdir = os.path.join(stringmap_reference_dir,&quot;logdir&quot;)
+        logdir = os.path.join(logdir, time.strftime('%Y-%m-%d_%H:%M:%S'))
+        if not os.path.isdir(logdir):
+            os.makedirs(logdir)
+        statsfname = os.path.join(logdir,'stats.txt')
+
+        # get and save field type stats
+        stats = computeFieldTypeStats(table, show_progress)
+        saveFieldTypeStats(stats, table.fieldnames, statsfname)
+        
+        stringmaps = {}
+        extramappings = {}
+
+        # now loop over the rows and save as pmat, completing the mapping if needed
+        if show_progress:
+            i = 0
+            pbar = PBar('Saving '+vmat_name, len(table))
+        for row in table:
+            numrow = []
+            for j in xrange(width):
+                val = row[j]
+                if val is None or val==&quot;&quot;:
+                    numrow.append(fpconst.NaN)
+                else:
+                    try:
+                        numrow.append(float(val))
+                    except ValueError:
+                        strval = str(val)
+                        fieldname = table.fieldnames[j]
+                        try:
+                            smap = stringmaps[fieldname]
+                        except KeyError:                            
+                            smap = StringMapFile(os.path.join(refdir,fieldname+&quot;.smap&quot;),&quot;a&quot;,stats[j].smap_start_id())
+                            stringmaps[fieldname] = smap
+                        try:
+                            numval = smap[strval]
+                        except KeyError:
+                            numval = smap.append(strval)
+                            try:
+                                extramap = extramappings[fieldname]
+                            except KeyError:
+                                extramap = StringMapFile(os.path.join(logdir,fieldname+&quot;.smap&quot;),&quot;w&quot;)
+                                extramappings[fieldname] = extramap
+                            extramap.append(strval,numval)
+                        numrow.append(numval)
+                        
+            vmat.appendRow(numrow)
+            if show_progress:
+                pbar.update(i)
+                i += 1
+        if show_progress:
+            pbar.close()
+
+        # now close the maps
+        for map in stringmaps.values():
+            map.close()
+        for map in extramappings.values():
+            map.close()
+
+        # Create a symbolic link from vmat_name.metadata/FieldInfo -&gt; refdir
+        if show_progress:
+            inmetadata = os.path.join(vmat_name+'.metadata', 'FieldInfo')
+            absrefdir = os.path.abspath(refdir)
+            print &quot;&gt;&gt;&gt; Creating symbolic link: &quot;,inmetadata,'-&gt;',absrefdir
+        os.symlink(absrefdir, inmetadata)
+
+        if show_progress:
+            print &quot;&gt;&gt;&gt; If any, extra added mappings have been written in&quot;, logdir
+            print &quot;    You should consult this directory to check if there's anything suspect.&quot;
+            print &quot;    (Did you expect any new previously unseen strings?)&quot;
+            print
+
+    ## Close vmat file
+    vmat.flush()
+    del(vmat)
+            
+def saveTable(table, fname, show_progress=True, stringmap_reference_dir=&quot;&quot;):
+    &quot;&quot;&quot;Saves a table to disk in the format specified by the extension of fname.
+    Can be one of:
+    - .pmat : PLearn matrix: table of reals in binary format
+    - .ptab : table compressed in chunks using zlib
+    - .ptabdir : TBD! do not use!
+    - .txt : tab separated text file
+    table can be a Table object or the name of the file containing the table.
+    When the extension is .pmat, stringmap_reference_dir could be used for string mapping.
+    &quot;&quot;&quot;
+    if isinstance(table,str):
+        table = openTable(table)
+    if fname.endswith('.pmat') or fname.endswith('.dmat'):
+        saveTableAsVMAT(table, fname, stringmap_reference_dir, show_progress)
+    else:
+        if fname.endswith('.ptab'):
+            m = CompressedTableFile(fname, 'w', table.fieldnames)
+        elif fname.endswith('.ptabdir'):
+            m = TableDir(fname, 'w+', table.fieldnames)
+        elif fname.endswith('.txt'):
+            m = TableFile(fname, 'w+', table.fieldnames)
+        else:
+            raise ValueError('Invalid extension for destination file '+fname)
+
+        if show_progress:
+            pbar = PBar('Saving '+fname,len(table))
+        i = 0
+        for row in table:
+            m.append( [ str(e) for e in row ] )
+            if show_progress:
+                pbar.update(i)
+            i += 1
+        m.close()
+        if show_progress:
+            pbar.close()
+
+
+class VMatTable(Table):
+    &quot;&quot;&quot;
+    Table that wraps a PLearn VMatrix
+    &quot;&quot;&quot;
+    __buflen= 256
+    
+    def __init__(self, vmat, get_strings=False):
+        self.vmat= vmat
+        self.set_fieldnames(vmat.fieldNames())
+        self.buf= None
+        self.bufstart= -self.__buflen
+        self.get_strings= get_strings
+
+    def getRow(self, i):
+        if self.get_strings:
+            r= []
+            for j in range(self.width()):
+                r+= [self.vmat.getString(i,j)]
+            return r
+        if i &lt; self.bufstart or i &gt;= self.bufstart+self.__buflen:
+            buflen= min(self.__buflen, len(self)-i)
+            self.buf= self.vmat.subMat(i, 0, buflen, self.width()).getMat()
+            self.bufstart= i
+        return self.buf[i-self.bufstart]
+
+    def __len__(self):
+        return int(self.vmat.length)
+
+
+class H5Table(Table):
+    &quot;&quot;&quot;
+    Table from an HDF5 array
+    &quot;&quot;&quot;
+    def __init__(self, filename, arrayname, fieldnames=None, mode='r'):
+        import tables
+        if mode!='r': raise NotImplementedError
+        self.file= tables.openFile(filename)
+        self.array= self.file.getNode(arrayname)
+        if fieldnames:
+            self.set_fieldnames(fieldnames)
+        else:
+            self.set_fieldnames(['f'+str(i) for i in range(len(self.array[0]))])
+        
+    def getRow(self, i):
+        return self.array[i]
+
+    def __len__(self):
+        return len(self.array)
+
+class AMATTable(TableFile):
+    &quot;&quot;&quot;
+    read-only for now
+    &quot;&quot;&quot;
+    def __init__(self, fname, openmode):
+        self.struct_format = '&lt;Q'
+        self.fname = fname
+        self.set_filepath(fname)
+        self.closed = False
+        self.openmode = openmode
+        self.tolerate_different_field_count = True
+        self.separator= None
+        indexfname = self.fname+'.idx'
+        if openmode=='r':
+            self.f = open(fname,'r')
+            l= self.f.readline().strip('\r\n').split(self.separator)
+            n= 0
+            while l[0] != '#:':
+                l= self.f.readline().strip('\r\n').split(self.separator)
+                n+= 1
+            fieldnames = l[1:]
+            fieldnames = [f for f in fieldnames if f != '']
+            self.set_fieldnames(fieldnames)
+
+            if not os.path.isfile(indexfname):
+                build_row_index_file(fname,indexfname,self.struct_format, n)
+            self.index = StructFile(indexfname,self.struct_format,'r')
+        else:
+            raise ValueError(&quot;Invalid value for openmode (&quot;+`openmode`+&quot; Must be 'r'&quot;)
+
+
+class JoinTable(Table):
+    def __init__(self, tables, key_fields, indexfname= None):
+        ntables= len(tables)
+        assert(ntables &gt;= 2)
+        self.tables= tables #should already be sorted by key_fields!
+        self.key_fields= key_fields
+
+        # take all fieldnames from all files
+        fieldnames= []
+        nextid= 1 # to differentiate dup. field names
+        for t in tables:
+            for f in t.fieldnames:
+                while f in fieldnames: # add suffix if already there
+                    f+= '-'+str(nextid)
+                    nextid+= 1
+                fieldnames.append(f)
+        self.set_fieldnames(fieldnames)
+
+        idxstructformat= '!'+'Q'*ntables
+        if indexfname and os.path.isfile(indexfname):
+            self.index= StructFile(indexfname, idxstructformat, 'r')
+        else: # build index
+            rowidx= [0]*ntables
+            index= []
+            pbar= PBar('Building Join Index', len(tables[0]))
+            while rowidx[0] &lt; len(tables[0]):
+                match= True
+                key= [tables[0][rowidx[0]][f] for f in key_fields]
+                for i in range(1,ntables):
+                    while rowidx[i] &lt; len(tables[i]) and key &gt; [tables[i][rowidx[i]][f] for f in key_fields]:
+                        rowidx[i]+= 1 #try to find a match
+                    if rowidx[i] == len(tables[i]) or key != [tables[i][rowidx[i]][f] for f in key_fields]:
+                        match= False
+                        break
+                if match: index.append(copy.copy(rowidx))
+                rowidx[0]+= 1
+                pbar.update(rowidx[0])
+            del pbar
+            self.index= index
+            if indexfname and not os.path.isfile(indexfname):
+                indexfile= StructFile(indexfname, idxstructformat, 'w+')
+                for i in index: indexfile.append(i)
+
+    def getRow(self, i):
+        rowidx= self.index[i]
+        row= []
+        for i,t in zip(rowidx, self.tables):
+            row+= t[i]
+        return row
+
+    def __len__(self):
+        return len(self.index)
+
+
+def openTable(tablespec,openmode='r'):
+    &quot;&quot;&quot;Opens a file containing a representation of a Table object.
+    The format of the file is determined by its extension like for saveTable,
+    but the '.pytable' type is also supported; this is a file containing
+    Python code to create the table.
+    openmode is used only for CompressedTableFile,PMatTable,TableDir and
+    TableFile
+    &quot;&quot;&quot;
+    
+    if isinstance(tablespec,str):
+        if tablespec.endswith('.pytable'):
+            olddir = os.getcwd()
+            try:
+                dirname, filename = os.path.split(os.path.abspath(tablespec))
+                os.chdir(dirname)
+                vars = {}
+                execfile(filename, vars)
+            finally:
+                os.chdir(olddir)
+            table = vars['result']
+            table.set_filepath(tablespec)
+            return table
+        elif tablespec.endswith('.ptab'):
+            return CompressedTableFile(tablespec,openmode)
+        elif tablespec.endswith('.csv'):
+            return CSVTable(tablespec, openmode)
+        elif tablespec.endswith('.pmat'):
+            return PMatTable(tablespec,openmode)
+        elif tablespec.endswith('.ptabdir'):
+            return TableDir(tablespec,openmode)
+        elif tablespec.endswith('.amat'):
+            return AMATTable(tablespec,openmode)
+        elif tablespec.endswith('.dmat') or tablespec.endswith('.vmat'):
+            from plearn import pyext
+            vm= pyext.AutoVMatrix(filename= tablespec)
+            return VMatTable(vm)
+        elif tablespec.endswith('.psave'):
+            from plearn import pyext
+            vm= pyext.loadObject(tablespec)
+            return VMatTable(vm)
+        else:
+            return TableFile(tablespec,openmode)
+    # otherwise, assume tablespec is already a Table
+    return tablespec
+
+# vim: filetype=python:expandtab:shiftwidth=4:tabstop=8:softtabstop=4 :

Added: trunk/python_modules/plearn/table/tablestat.py
===================================================================
--- trunk/python_modules/plearn/table/tablestat.py	2009-06-02 21:55:31 UTC (rev 10226)
+++ trunk/python_modules/plearn/table/tablestat.py	2009-06-02 22:59:44 UTC (rev 10227)
@@ -0,0 +1,720 @@
+## Automatically adapted for numpy.numarray Jun 13, 2007 by python_numarray_to_numpy (-xsm)
+
+&quot;&quot;&quot;
+tablestat.py
+
+Copyright (C) 2005 ApSTAT Technologies Inc.
+
+This file was contributed by ApSTAT Technologies to the
+PLearn library under the following BSD-style license: 
+
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions are met:
+#
+#   1. Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#
+#   2. Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in the
+#      documentation and/or other materials provided with the distribution.
+#
+#   3. The name of the authors may not be used to endorse or promote
+#      products derived from this software without specific prior written
+#      permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+#  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+#  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+#  NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+#  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+#  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+#  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+#  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+#  This file is part of the PLearn library. For more information on the PLearn
+#  library, go to the PLearn Web site at www.plearn.org
+
+&quot;&quot;&quot;
+
+# Author: Pascal Vincent
+
+import numpy.numarray as numarray
+import numpy
+import bisect
+import math
+from numpy.numarray import *
+from plearn.table.table import *
+
+def smartdiv(a,b):
+    try: return a/b
+    except: return 'Error'
+
+def smartpercent(a,b):
+    try: return str(a*100./b)+' %'
+    except: return 'Error'
+
+def num2str(num):
+    try:
+        if isinstance(num,float) and math.floor(num)==num:
+            return str(int(num))
+        else:
+            return str(num)
+    except OverflowError:
+        #raise OverflowError('in num2str for num '+repr(num))
+        return repr(num)
+
+## def interval_to_string(interval):
+##     if isinstance(interval,str):
+##         return interval
+##     elif isinstance(interval,tuple):
+##         include_low, low, high, include_high = interval
+##         if include_low: repr = '[ '
+##         else: repr = '] '
+##         repr += num2str(low)+', '+num2str(high)
+##         if include_high: repr += ' ]'
+##         else: repr += ' ['
+##         return repr
+##     return num2str(interval)
+
+
+class Interval:
+    &quot;&quot;&quot;Defines an interval between values low and high where include_low and include_high
+    are booleans that indicate where the interval is closed or open.
+    If low==high this is to be understood as a point value&quot;&quot;&quot;    
+
+    def __init__(self, include_low, low, high, include_high):
+        if low&gt;high:
+            raise ValueError('Interval must have low&lt;=high')
+        self.include_low = include_low
+        self.low = low
+        self.high = high
+        self.include_high = include_high
+
+    def __str__(self):
+        if self.low==self.high:
+            return num2str(self.low)
+        else:
+            return repr(self)
+
+    def __repr__(self):
+        if self.include_low: res = '[ '
+        else: res = '] '
+        res += num2str(self.low)+', '+num2str(self.high)
+        if self.include_high: res += ' ]'
+        else: res += ' ['
+        return res
+
+    def __contains__(self, item):
+        if not isinstance(item,Interval): # assume item is a number 
+            if self.include_low:
+                res = item&gt;=self.low
+            else:
+                res = item&gt;self.low
+            if self.include_high:
+                res = res and (item&lt;=self.high)
+            else:                
+                res = res and (item&lt;self.high)
+        else: # item is an Interval
+            if self.include_low:
+                res = item.low&gt;=self.low
+            else:
+                res = (item.low&gt;self.low) or (item.low==self.low and not item.include_low)
+            if self.include_high:
+                res = res and (item.high&lt;=self.high)
+            else:
+                res = res and (item.high&lt;self.high or (item.high==self.high and not item.include_high))
+        return res
+
+    def __add__(self, other):
+        &quot;&quot;&quot;union of self and other (result must be an interval, or exception is raised&quot;&quot;&quot;
+        if self.low&lt;=other.low:
+            low = self.low
+            if self.low==other.low:
+                include_low = self.include_low or other.include_low
+            else:
+                include_low = self.include_low
+
+            if self.high&lt;other.low or (self.high==other.low and not (self.include_high or other.include_low)):
+                raise ValueError('Union of these 2 intervals is not an interval')
+
+            if self.high&gt;other.high:
+                high = self.high
+                include_high = self.include_high
+            elif other.high&gt;self.high:
+                high = other.high
+                include_high = other.include_high
+            else: # self.high==other.high
+                high = self.high
+                include_high = self.include_high or other.include_high
+            return Interval(include_low, low, high, include_high)
+        else:
+            return other+self
+
+
+class AutoDomain:
+
+    def __init__(self, maxnstrings=25, maxnnumbers=25):
+
+        # maximum number of strings recorded in strings_index
+        # (actually strings_index might end up containing one or two extra
+        # special strings: the empty string '' and the '/OTHER/' string.)
+        self.maxnstrings = maxnstrings
+        self.maxnnumbers = maxnnumbers
+        
+        # number of allocated indexes (the index method will return indexes witihn 0..nindexes_-1
+        self.nindexes_ = 0
+
+        # maps non float convertible strings to their index
+        # It will include the empty string '' if it was encountered
+        # It will include the '/OTHER/' string if we exceed maxnstrings registered strings
+        self.strings_index = {}
+
+        # sorted list of registered numbers 
+        self.numbers = []
+        # numbers_index[k] is the integer index of float value numbers[k]
+        self.numbers_index = []
+        # less_than_index[k] is the integer index of float values &lt;numbers[k] and &gt;number[k-1]
+        # Note 1: less_than_index is one element longer than numbers (and numbers_index),
+        # so that its last element is the index for values greater than the last of numbers.
+        # (its first element is the index for values smaller than the first of numbers).
+        # Note 1: less_than_index is empty as long as numbers has not been filled (len &lt; maxnnumbers)
+        # Then it is filled with -1, before recruiting indexes in it.
+        self.less_than_index = []
+
+        # min and max number values encountered (stays None if no numerical value is encountered).
+        self.min_val = None
+        self.max_val = None
+
+    def nindexes(self):
+        &quot;&quot;&quot;Returns the total number of recorded indexes.&quot;&quot;&quot;
+        return self.nindexes_
+
+    def index(self, x):
+        &quot;&quot;&quot;Will return the integer index associated with value x. If x does
+        not map to an index already in the domain then the domain will
+        be extended to include x and a corresponding new index will be
+        associated to that extension and returned. &quot;&quot;&quot; 
+
+        v = None
+        
+        try: v = float(x)
+        except ValueError: pass
+
+        if v is None or (isinstance(x,str) 
+                         and len(x)&gt;=2
+                         and x[0]=='0' and x[1]!='.'): # handle it as a string
+            s = str(x).strip()
+            id = self.strings_index.get(s)
+            #if not id: # unknown string
+            if id == None: # unknown string
+                
+                if len(self.strings_index)&lt;self.maxnstrings:
+                    # we haven't reached maxnstrings so let's add this new one
+                    id = self.nindexes_
+                    self.strings_index[s] = id
+                    self.nindexes_ += 1
+                else: # we have reached maxnstrings
+                    if s=='': # it's the empty string, add it all the same
+                        id = self.nindexes_
+                        self.strings_index[s] = id
+                        self.nindexes_ += 1
+                    else: # look for '/OTHER/' 
+                        id = self.strings_index.get('/OTHER/')
+                        if not id: # no /OTHER/ : add it
+                            id = self.nindexes_
+                            self.strings_index['/OTHER/'] = id
+                            self.nindexes_ += 1                            
+
+        else: # handle it as a float v
+            pos = bisect.bisect_left(self.numbers, v)
+            if pos &lt; len(self.numbers) and self.numbers[pos]==v:
+                # we have already registered that value
+                id = self.numbers_index[pos]
+            else: # this is not a registered value
+
+                if self.min_val is None:
+                    self.min_val = v
+                    self.max_val = v
+                else:
+                    self.min_val = min(self.min_val, v)
+                    self.max_val = max(self.max_val, v)
+
+                if len(self.numbers)&lt;self.maxnnumbers: # self.numbers not full: insert the new value
+                    self.numbers.insert(pos,v)
+                    id = self.nindexes_
+                    self.numbers_index.insert(pos,id)
+                    self.nindexes_ += 1
+                    if len(self.numbers)==self.maxnnumbers: # we've filled self.numbers
+                        if self.min_val&lt;0. and self.max_val&gt;0.:
+                            # insert 0. if not already there
+                            pos = bisect.bisect_left(self.numbers, 0.)
+                            if self.numbers[pos]!=0.:
+                                self.numbers.insert(pos,0)
+                                self.numbers_index.insert(pos,self.nindexes_)
+                                self.nindexes_ += 1
+                        # fill the less_than_index with -1
+                        self.less_than_index = [-1]*(len(self.numbers)+1)                        
+                else: # self.numbers is full 
+                    id = self.less_than_index[pos]
+                    if id&lt;0:
+                        id = self.nindexes_
+                        self.less_than_index[pos] = id
+                        self.nindexes_ += 1
+
+        return id
+
+    def string_domain(self):
+        &quot;&quot;&quot;This will return an ordered list of (xstring, index) for the string part of the domain&quot;&quot;&quot;
+        keys = self.strings_index.keys()
+        keys.sort()
+        dom = [ (key,self.strings_index[key]) for key in keys ]
+        return dom
+        
+    def number_domain(self):
+        &quot;&quot;&quot;This will return an ordered list of (interval, index) for the numerical part of the domain
+        interval is an instance of Interval 
+        &quot;&quot;&quot;
+        dom = []
+        if self.min_val and self.less_than_index and self.less_than_index[0]&gt;=0:
+            interval = Interval(True, self.min_val, self.numbers[0], False)
+            dom.append( (interval, self.less_than_index[0]) )
+        for k in xrange(len(self.numbers)):
+            interval = Interval(True, self.numbers[k], self.numbers[k], True)
+            dom.append((interval, self.numbers_index[k]))
+            if self.less_than_index and self.less_than_index[k+1]&gt;=0:
+                if k&lt;len(self.numbers)-1:
+                    interval = Interval(False, self.numbers[k], self.numbers[k+1], False)
+                    dom.append( (interval, self.less_than_index[k+1]) )
+                elif self.max_val:
+                    interval = Interval(False, self.numbers[k], self.max_val, True)
+                    dom.append( (interval, self.less_than_index[k+1]) )
+        return dom
+
+    def domain(self):
+        return self.string_domain()+self.number_domain()
+
+    def domain_descr_id(self):
+        do = self.domain()
+        descriptions = []
+        ids = []
+        for range,id in do:            
+            descriptions.append(str(range))
+            ids.append(id)
+        return descriptions,ids
+
+
+class AutoCube:
+
+    def __init__(self, nkeys, nvalues=1, typecode='f8'):
+        self.nvalues = nvalues
+        shape = [1]*nkeys
+        if nvalues&gt;0:
+            shape.append(nvalues)
+        self.data = zeros(shape, typecode)
+
+    def enlarge(self,idx):
+        if isinstance(idx,int):
+            idx = [idx] # make it a list
+        oldshape = self.data.shape
+        newshape = list(oldshape)
+        for k in xrange(len(idx)):
+            newshape[k] = max(newshape[k], idx[k]+1)
+        newdata = zeros(newshape, numarray.typefrom(self.data))
+        slicespec = [ slice(0,dim) for dim in oldshape ]
+        newdata[slicespec] = self.data
+        self.data = newdata
+
+    def __getitem__(self,idx):
+        try:
+            return self.data[idx]
+        except IndexError:
+            self.enlarge(idx)
+        return self.data[idx]
+            
+    def __setitem__(self,idx,val):
+        try:
+            self.data[idx] = val
+        except IndexError:
+            self.enlarge(idx)
+        self.data[idx] = val
+        
+
+def combinations(lists):    
+    if not lists:
+        yield []
+    else:
+        for i in lists[0]:
+            for c in combinations(lists[1:]):
+                yield [i]+c
+
+def all_combinations(lists):
+    return [ comb for comb in combinations(lists) ]
+    
+
+def domain_union( range_ids_a, range_ids_b ):
+    ra,idsa = range_ids_a
+    rb,idsb = range_ids_b
+    
+
+
+
+class BaseTableStats:
+
+    def __init__(self, var_combinations, var_domains, valuenames=[], weightvar='', full_shuffle_stats=True):
+        &quot;&quot;&quot;
+        var_combinations is a list of tuples of variable names
+        var domains maps variable names to AutoDomain
+        valuef is a function that takes a row and returns a tuple of values
+        valuenames is a list of variable names for the tuples returned by valuef
+        &quot;&quot;&quot;
+        self.var_combinations = var_combinations
+        self.var_domains = var_domains
+        self.valuenames = valuenames
+        self.weightvar = weightvar
+        # self.valuef = valuef
+        self.cubes = {}
+        self.nsamples = 0
+        self.full_shuffle_stats = full_shuffle_stats
+        
+        for vars in var_combinations:
+            self.cubes[tuple(vars)] = AutoCube(len(vars), 1+len(self.valuenames))
+
+    def extended_value_names(self):
+        if self.weightvar:
+            return [self.weightvar]+[ self.weightvar+'*'+varname for varname in self.valuenames ]
+        else:
+            return ['_count_']+self.valuenames
+
+##         countvar = self.weightvar
+##         if not countvar:
+##             countvar = '_count_'
+##         valuenames = [countvar]+self.valuenames
+##        return valuenames        
+
+    def update(self, row):
+        # values = self.valuef(row)
+        values = array([1.]+[ float_or_zero(row[valuename]) for valuename in self.valuenames ])
+        if self.weightvar:
+            w = float_or_zero(row[self.weightvar])
+            values *= w
+        for vars,cube in self.cubes.items():
+            indexes = tuple([ self.var_domains[varname].index(row[varname]) for varname in vars ])
+            cube[indexes] += values
+        self.nsamples += 1
+        return self.nsamples
+
+
+    def stringDomain(self, varname):
+        s_domain = self.var_domains[varname].string_domain()
+        return [ (s, [id] ) for s,id in s_domain ]
+
+    def numberDomain(self, varname, condvar, summarize_min_prob = -1.):
+        &quot;&quot;&quot;Will return an ordered list of (interval, indexes) for the numerical part of the domain
+        interval is an instance of Interval
+        indexes is a list of corresponding cube-indexes for variable varname in a cube
+        corresponding to varname, such that the union of the individual intervals associated with
+        those indexes gives interval (thus the slices corresponding to those indexes must be summed
+        to get the values corresponding to interval).
+        Consecutive intervals will be merged until the largest conditional probability within them
+        reaches summarize_min_prob
+        &quot;&quot;&quot;
+        
+        num_domain = self.var_domains[varname].number_domain()
+        if not num_domain: # empty list
+            return num_domain
+
+        if summarize_min_prob&lt;=0.:
+            return [ (interval, [id] ) for interval,id in num_domain ]
+        
+        try:
+            cube = self.cubes[(varname, condvar)]
+        except KeyError:
+            cube = self.cubes[(condvar, varname)]
+            cube = transpose(cube,(1,0,2))
+
+        num_ids = [ id for interval,id in num_domain ]
+        # we consider only the &quot;counts&quot; (value index 0)
+        counts = cube[:,:,0]
+        # sum the counts 
+        count_sums = abs(sum(counts, 0))+1e-6  # we add 1e-6 just to make sure we don't have zeros and divisions by zero
+        condprobs = counts/count_sums
+        # we keep only the numerical domain
+        condprobs = take(condprobs,num_ids)
+        l,w = condprobs.shape
+
+        summarized_domain = []
+        newinterval = None
+        newrow = zeros(w, numarray.typefrom(condprobs))
+        ids = []
+        for i in xrange(l):
+            row = condprobs[i]
+            interval, id = num_domain[i]
+            if not newinterval:
+                newinterval = interval
+            else:
+                newinterval = Interval(newinterval.include_low, newinterval.low, interval.high, interval.include_high)
+            ids.append(id)
+            newrow += row
+            if max(newrow)&gt;=summarize_min_prob or i==l-1:
+                summarized_domain.append( (newinterval, ids) )
+                newinterval = None
+                newrow[:] = 0.
+                ids = []
+        
+        return summarized_domain
+
+    def trimmedNumberDomain(self, varname, condvar, summarize_remove_n, summarize_min_prob):
+        &quot;&quot;&quot;Will return an ordered list of (interval, indexes) for the numerical part of the domain
+        interval is an instance of Interval
+        indexes is a list of corresponding cube-indexes for variable varname in a cube
+        corresponding to varname, such that the union of the individual intervals associated with
+        those indexes gives interval (thus the slices corresponding to those indexes must be summed
+        to get the values corresponding to interval).
+        summarize_remove_n is the number of small intervals to 'remove'
+        In addition, all intervals whose prob is less than summarize_min_prob will also be 'removed'
+        &quot;&quot;&quot;
+
+        num_domain = self.var_domains[varname].number_domain()
+        summarized_domain = [ (interval, (id,) ) for interval,id in num_domain ]
+
+        if (summarize_remove_n&lt;=0 and summarize_min_prob&gt;=1.) or len(summarized_domain)==0:
+            return summarized_domain
+
+        try:
+            cube = self.cubes[(varname, condvar)]
+        except KeyError:
+            cube = self.cubes[(condvar, varname)]
+            cube = transpose(cube,(1,0,2))
+
+        num_ids = [ id for xrange,id in num_domain ] 
+        # we consider only the &quot;counts&quot; (value index 0)
+        counts = cube[:,:,0]
+        # sum the counts 
+        count_sums = abs(sum(counts, 0))+1e-6  # we add 1e-6 just to make sure we don't have zeros and divisions by zero
+        condprobs = counts/count_sums
+        # we keep only the numerical domain
+        condprobs = take(condprobs,num_ids)
+
+        l,w = condprobs.shape
+        nremoved = 0
+
+        while l&gt;0:
+            maxprobs = array([ max(p) for p in condprobs ])
+            k = argmin(maxprobs)
+            minprob = maxprobs[k]
+            #print &gt;&gt;f, 'maxprobs: ',maxprobs
+            #print &gt;&gt;f, 'k: ',k
+            #print &gt;&gt;f, 'minprob: ',minprob
+            if nremoved&gt;=summarize_remove_n or minprob&gt;=summarize_min_prob:
+                break # exit while loop
+            if k==0:
+                k_a = 0
+                k_b = 1
+            elif k==l-1:
+                k_a = l-2
+                k_b = l-1
+            elif maxprobs[k-1]&lt;=maxprobs[k+1]:
+                k_a = k-1
+                k_b = k
+            else:
+                k_a = k
+                k_b = k+1
+            interval_a, ids_a = summarized_domain[k_a]
+            interval_b, ids_b = summarized_domain[k_b]
+            try:
+                union_interval = interval_a + interval_b
+            except ValueError: # union of the 2 intervals is not an interval!
+                break
+            summarized_domain[k_a] = (union_interval, ids_a+ids_b)
+            del summarized_domain[k_b]
+            #newcondprobs = numarray.typefrom(zeros((l-1,w),condprobs))
+            newcondprobs = zeros((l-1,w),numarray.typefrom(condprobs))
+            newcondprobs[0:k_b] += condprobs[0:k_b]
+            newcondprobs[k_a:] += condprobs[k_b:]
+            condprobs = newcondprobs
+            l = l-1
+            nremoved += 1
+
+        return summarized_domain
+
+
+    def getSumsMatrixAndNames(self, condvari, condvarj, summarize_min_prob=1e10):
+        &quot;&quot;&quot; Returns the tuple (mat, rownames, colnames)&quot;&quot;&quot;
+        try:
+            cube = self.cubes[(condvari, condvarj)]
+        except KeyError:
+            cube = self.cubes[(condvarj, condvari)]
+            cube = transpose(cube,(1,0,2))
+
+        condi_domain = self.stringDomain(condvari)+self.numberDomain(condvari, condvarj, summarize_min_prob)
+        condi_descr = [ str(interval) for interval,ids in condi_domain ]
+
+        condj_descr, condj_id = self.var_domains[condvarj].domain_descr_id()
+
+        values = cube[:,:,:]
+        values = take(values,condj_id,axis=1)
+        l, w, d = values.shape
+        n = len(condi_domain)
+        #mat = numarray.typefrom(zeros((1+n,1+w,d),values))
+        mat = zeros((1+n,1+w,d),numarray.typefrom(values))
+        firstrow = sum(values, 0)
+        mat[0, 1:1+w, :] = firstrow
+
+        mat[0, 0, :]   = sum(firstrow)
+        for i in xrange(n):
+            interval,ids = condi_domain[i]
+            s = mat[1+i,0,:]
+            for id in ids:
+                row = values[id]                
+                mat[1+i, 1:, :] += row
+                s += sum(row)
+
+        condi_descr.insert(0,'/*/')
+        condj_descr.insert(0,'/*/')
+        return mat, condi_descr, condj_descr
+
+    def getCondTable(self, condvari, condvarj, sumvar='', divvar='', marginalize=0, summarize_min_prob=0., combinvarsmode=0):
+        mat, rownames, colnames = self.getSumsMatrixAndNames(condvari, condvarj, summarize_min_prob)
+        l,w,d = mat.shape
+        valuenames = self.extended_value_names()
+        #numarray.ufunc.Error.pushMode(dividebyzero=&quot;ignore&quot;, invalid=&quot;ignore&quot;)
+        if sumvar and not divvar:
+            m = mat[:,:,valuenames.index(sumvar)]
+            title = 'SUM['+sumvar+'] | ' + condvari +', '+condvarj
+        elif sumvar and divvar:
+            if combinvarsmode==0:
+                title = 'SUM['+sumvar+']/SUM['+divvar+'] | ' + condvari +', '+condvarj
+                m = mat[:,:,valuenames.index(sumvar)]/mat[:,:,valuenames.index(divvar)]
+            elif combinvarsmode==1:
+                title = 'SUM['+sumvar+']-0.7*SUM['+divvar+'] | ' + condvari +', '+condvarj
+                m = mat[:,:,valuenames.index(sumvar)]-0.7*mat[:,:,valuenames.index(divvar)]
+        elif divvar and not sumvar:
+            m = 1./mat[:,:,valuenames.index(divvar)]
+            title = '1/SUM['+divvar+'] | ' + condvari +', '+condvarj
+        else:
+            raise ValueError('Must specify at least one of sumvar or divvar')
+
+        if marginalize:
+            if marginalize==1:
+                m = m/m[0:1,:]
+            elif marginalize==2:
+                m = m/m[:,0:1]
+            elif marginalize==3:
+                m = m/m[0,0]
+            m *= 100.0
+            title = title + ' -&gt; percents '+str(marginalize)
+
+        if summarize_min_prob&gt;0.:
+            title = title + '   [prob&gt;='+str(int(summarize_min_prob*10000)/100.0)+'%]'
+
+        #numarray.ufunc.Error.popMode()
+        table = MemoryTable(colnames, m)
+        table.set_rownames(rownames)
+        table.set_title(title)
+        return table
+
+
+##     def getCondProbTable(self, targetvar, condvar):
+##         try:
+##             cube = self.cubes[(targetvar, condvar)]
+##         except KeyError:
+##             cube = self.cubes[(condvar, targetvar)]
+##             cube = transpose(cube,(1,0,2))
+            
+##         cond_descr, cond_id = self.var_domains[condvar].domain_descr_id()
+##         targ_descr, targ_id = self.var_domains[targetvar].domain_descr_id()
+
+##         prob = cube[:,:,0]
+##         prob = take(take(prob,targ_id,axis=0),cond_id,axis=1)
+##         prob_sum = sum(prob,0)
+##         # prob = prob*100./sum(prob)
+
+##         table = MemoryTable(cond_descr)
+##         for pr in prob:
+##             row = [ smartpercent(p,ps) for p,ps in zip(pr,prob_sum) ]
+##             table.append(row)
+##         table.set_rownames(targ_descr)
+##         return table
+        
+##     def getCondValuesTable(self, condvar1, condvar2, strvaluef):
+##         try:
+##             cube = self.cubes[(condvar1, condvar2)]
+##         except KeyError:
+##             cube = self.cubes[(condvar2, condvar1)]
+##             cube = transpose(cube,(1,0,2))
+            
+##         cond1_descr, cond1_id = self.var_domains[condvar1].domain_descr_id()
+##         cond2_descr, cond2_id = self.var_domains[condvar2].domain_descr_id()
+
+##         sumt = take(take(cube,cond1_id,axis=0),cond2_id,axis=1)
+
+##         table = MemoryTable(cond2_descr)
+##         table.set_rownames(cond1_descr)
+##         for i in xrange(len(cond1_descr)):
+##             row = []
+##             for j in xrange(len(cond2_descr)):
+##                 row.append(strvaluef(sumt[i,j]))
+##             table.append(row)
+##         return table
+            
+##     def getCondSumsTable(self, condvari, condvarj):
+##         try:
+##             cube = self.cubes[(condvari, condvarj)]
+##         except KeyError:
+##             cube = self.cubes[(condvarj, condvari)]
+##             cube = transpose(cube,(1,0,2))
+            
+##         condi_descr, condi_id = self.var_domains[condvari].domain_descr_id()
+##         condj_descr, condj_id = self.var_domains[condvarj].domain_descr_id()
+
+##         sumt = cube[:,:,:]
+##         sumt = take(take(sumt,condi_id,axis=0),condj_id,axis=1)
+
+##         table = MemoryTable(['sum_var']+condj_descr)
+##         rownames = []
+##         valuenames = self.extended_value_names()
+##         for i in xrange(len(condi_descr)):
+##             condi_str = condi_descr[i]
+##             for k in xrange(len(valuenames)):
+##                 row = [ valuenames[k] ]
+##                 for j in xrange(len(condj_descr)):
+##                     row.append(sumt[i,j,k])
+##                 table.append(row)
+##                 rownames.append(condi_str)
+##                 condi_str = ''
+##         table.set_rownames(rownames)
+##         return table
+            
+##     def getCondRatioTable(self, condvari, condvarj, divide_by):
+##         &quot;&quot;&quot;divide_by must be the valuename by which to divide&quot;&quot;&quot;        
+##         try:
+##             cube = self.cubes[(condvari, condvarj)]
+##         except KeyError:
+##             cube = self.cubes[(condvarj, condvari)]
+##             cube = transpose(cube,(1,0,2))
+            
+##         condi_descr, condi_id = self.var_domains[condvari].domain_descr_id()
+##         condj_descr, condj_id = self.var_domains[condvarj].domain_descr_id()
+
+##         sumt = cube[:,:,:]
+##         sumt = take(take(sumt,condi_id,axis=0),condj_id,axis=1)
+
+##         valuenames = self.extended_value_names()
+##         divideidx = valuenames.index(divide_by)
+##         table = MemoryTable(['sum_var']+condj_descr)
+##         rownames = []
+##         for i in xrange(len(condi_descr)):
+##             condi_str = condi_descr[i]
+##             for k in xrange(len(valuenames)):
+##                 row = [ valuenames[k] ]
+##                 for j in xrange(len(condj_descr)):
+##                     row.append(smartdiv(sumt[i,j,k],sumt[i,j,divideidx]))
+##                 table.append(row)
+##                 rownames.append(condi_str)
+##                 condi_str = ''
+##         table.set_rownames(rownames)
+##         return table
+            
+

Added: trunk/python_modules/plearn/table/viewtable.py
===================================================================
--- trunk/python_modules/plearn/table/viewtable.py	2009-06-02 21:55:31 UTC (rev 10226)
+++ trunk/python_modules/plearn/table/viewtable.py	2009-06-02 22:59:44 UTC (rev 10227)
@@ -0,0 +1,1625 @@
+&quot;&quot;&quot;
+viewtable.py
+
+Copyright (C) 2005-2009 ApSTAT Technologies Inc.
+
+This file was contributed by ApSTAT Technologies to the
+PLearn library under the following BSD-style license: 
+
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions are met:
+#
+#   1. Redistributions of source code must retain the above copyright
+#      notice, this list of conditions and the following disclaimer.
+#
+#   2. Redistributions in binary form must reproduce the above copyright
+#      notice, this list of conditions and the following disclaimer in the
+#      documentation and/or other materials provided with the distribution.
+#
+#   3. The name of the authors may not be used to endorse or promote
+#      products derived from this software without specific prior written
+#      permission.
+#
+#  THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+#  IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+#  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+#  NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+#  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+#  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+#  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+#  NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+#  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+#
+#  This file is part of the PLearn library. For more information on the PLearn
+#  library, go to the PLearn Web site at www.plearn.org
+&quot;&quot;&quot;
+
+# Author: Pascal Vincent
+
+import sys
+import curses
+import threading
+import cPickle as pickle
+import bisect
+import os
+import os.path
+import subprocess
+import traceback
+import locale
+from plearn.table.table import *
+from plearn.table.tablestat import *
+from plearn.table.date import *
+from plearn.plotting.numpy_utils import to_numpy_float_array, mapping_of_values_to_pos
+import matplotlib.colors
+
+def format_string_to_width(s, width):
+    if len(s)&lt;width:
+        s += ' '*(width-len(s))
+    else:
+        s = s[0:width-1]+' '
+    return s
+
+def daydiff(cyymmdd1, cyymmdd2):
+    return (CYYMMDD_to_date(cyymmdd1)-CYYMMDD_to_date(cyymmdd2)).days
+
+def select_item(scr, items, title='',
+               instructions='Select one of the following by pressing the appropriate key'):
+
+    &quot;&quot;&quot;scr is the curses screen or window,
+    items is a list of strings to be selected from.  This displays a selection
+    screen allowing the user to select one of the items.
+    The index of the selected item is returned&quot;&quot;&quot;
+
+    scr.erase()
+    scr.addstr(0,0,title,curses.A_REVERSE)
+    scr.addstr(2,1,instructions,curses.A_BOLD)
+
+    n = len(items)
+    keys = &quot;123456789abcdefghijklmnop&quot;
+    keys = keys[0:n]
+    keycodes = map(ord,keys)
+    for i in xrange(n):
+        scr.addstr(4+i,3,'['+keys[i]+'] '+items[i])
+    scr.move(4+n,3)
+    scr.refresh();
+    while True:
+        k = scr.getch();
+        try:
+            id = keycodes.index(k)
+            break
+        except ValueError:
+            pass
+    scr.erase()
+    return id
+
+class TableView:
+
+    def __init__(self, table, stdscr):
+        
+        self.stdscr = stdscr
+        self.transposed = False
+        self.dot_mode = False
+        self.margin_top = 2
+        self.margin_left = 0
+        self.margin_right = 0
+        self.margin_bottom = 2
+        self.rowname_width = 20
+        self.set_field_dim(20, 1)
+
+        self.monetary_format= False
+        self.orig_locale= locale.getlocale(locale.LC_NUMERIC)
+        self.full_shuffle_stats= False
+
+        self.reinit(table)
+        
+
+    def reinit(self, table):
+        self.i0 = 0
+        self.j0 = 0
+        self.current_i = 0
+        self.current_j = 0
+        self.setTable(table)
+
+        self.conditioning_field = ''
+        self.weight_field = ''
+        self.target_fields = []
+
+        self.search_field = 0
+        self.search_value = table[0][0]
+        self.search_expression = ''
+
+        self.stats = None
+        self.statsthread = None
+        self.stop_thread = False
+        self.statslock = threading.Lock()
+        self.shuffled_rowidx = None
+        self.statsview = None
+
+        self.sumvar = ''
+        self.divvar = ''
+        self.marginalize = 0
+        # combinvarsmode 0: numerator_sum_var/denominator_sum_var   1: numerator_sum_var-0.7*denominator_sum_var
+        self.combinvarsmode = 0
+        # a map containing for each variable name the summarize_remove_n setting
+        self.summarize_remove_n = {}
+        self.minprob = 0.
+
+        # used by sort and filter operations
+        self.selected_rows = None
+        self.selected_fields = []
+        
+        self.graph_fields = {}
+        
+        self.redraw()        
+
+
+    def writecolname(self,sj,text,attr=curses.A_NORMAL):
+        text = format_string_to_width(text, self.fieldwidth)
+        si = self.margin_top
+        sj = self.margin_left+self.rowname_width+sj*self.fieldwidth
+        self.stdscr.addstr(si,sj,text,attr)        
+        
+    def writerowname(self,si,text,attr=curses.A_NORMAL):
+        text = format_string_to_width(text, self.rowname_width)
+        si = self.margin_top+1+si*self.fieldheight
+        sj = self.margin_left
+        self.stdscr.addstr(si,sj,text,attr)                
+
+    def writetop(self,text,attr=curses.A_NORMAL):
+        text = format_string_to_width(text,curses.COLS-1)
+        self.stdscr.addstr(0,0,text,attr)
+
+    def writebottom(self,text,attr=curses.A_NORMAL):
+        self.stdscr.addstr(curses.LINES-2,0,'_'*curses.COLS)
+        text = format_string_to_width(text,curses.COLS-1)
+        self.stdscr.addstr(curses.LINES-1,0,text,attr)
+
+    def writefield(self,si,sj,text,attr=curses.A_NORMAL):
+        text = format_string_to_width(text, self.fieldwidth)
+        si = self.margin_top+1+si*self.fieldheight
+        sj = self.margin_left+self.rowname_width+sj*self.fieldwidth
+        self.stdscr.addstr(si,sj,text,attr)
+
+    def setTable(self,table):
+        self.table = table
+        self.selected_columns = range(self.table.width())
+        self.cache = {}
+        self.cache_capacity = 100
+        self.cache_min_i = 0
+        self.cache_max_i = 0
+        if self.current_i&gt;=self.table.length():
+            self.current_i = 0
+            self.i0 = 0
+        if self.current_j&gt;=self.table.width():
+            self.current_j = 0
+            self.j0 = 0
+        l,w = table.length(), table.width()
+        self.set_toprightinfo(str(l)+'x'+str(w))
+
+    def getFullRow(self,i):
+        if self.selected_rows is not None:
+            i = self.selected_rows[i]
+        # row = self.table.getRow(i)
+        row = self.table[i]
+        return row
+
+    def getRow(self,i):
+        if self.selected_rows is not None:
+            i = self.selected_rows[i]
+        try:
+            row = self.cache[i]
+        except KeyError:
+            self.statslock.acquire()
+            row = self.table.getRow(i)
+            self.statslock.release()
+            if len(self.cache)&gt;=self.cache_capacity: # delete one row from the cache
+                if i==self.cache_max_i+1:
+                    del self.cache[self.cache_min_i]
+                    self.cache_min_i = min(self.cache)
+                elif i==self.cache_min_i-1:
+                    del self.cache[self.cache_max_i]
+                    self.cache_max_i = max(self.cache)
+                else:
+                    self.cache = {}
+                    self.cache_min_i = i
+                    self.cache_max_i = i
+                    
+            self.cache[i] = row
+            self.cache_min_i = min(i,self.cache_min_i)
+            self.cache_max_i = max(i, self.cache_max_i)
+
+        return [ row[col] for col in self.selected_columns ]
+
+    def getVal(self,i,j):
+        return self.getRow(i)[j]
+    
+##         if i&gt;=self.row_cache_mini and i&lt;=self.row_cache_maxi:
+##         try:
+##             return self.row_cache[i-]
+    
+
+    def set_field_dim(self, fieldwidth, fieldheight):
+        self.fieldwidth = max(2, min(fieldwidth, 100))
+        self.fieldheight = max(1, min(fieldheight, 50))
+        self.compute_ni_nj()
+
+    def compute_ni_nj(self):
+        if self.transposed:            
+            self.ni = (curses.COLS-(self.rowname_width+self.margin_left+self.margin_right))/self.fieldwidth
+            self.nj = (curses.LINES-(self.margin_top+self.margin_bottom+1))/self.fieldheight
+        else:            
+            self.ni = (curses.LINES-(self.margin_top+self.margin_bottom+1))/self.fieldheight
+            self.nj = (curses.COLS-(self.rowname_width+self.margin_left+self.margin_right))/self.fieldwidth
+
+    def display_help(self,c=0):
+#        self.stdscr.erase()
+        helptext = &quot;&quot;&quot;
+*************************
+**  KEYS IN DATA VIEW  **
+*************************
+ arrow keys   : move in corresponding direction
+ page up/down : move up/down one screen
+ home/end     : move to first / last screen
+ t            : transpose view
+ &gt; &lt;          : increase or decrease width of display field
+ ) (          : sort rows in increasing or decreasing order of values of current field 
+ a            : sort fieldnames alphabetically
+ SPACE        : select/deselect field 
+ c            : select constant fields (fields having constant value in all rows)
+ ENTER        : keep only selected fields in display
+ k            : hide selected fields from display (or if none selected, hide current field)
+ l            : prompt for a line number and go to that line
+ .            : toggle displaying of ... for values that do not change
+ =            : search for a value of the current field
+ /            : search for row satisfying python expression (ex: float(AGE1)&lt;float(AGE2) )
+ N            : search next
+ P            : search previous
+ !            : filter rows satisfying python expression (or current selected fields values)
+ o            : revert to the original table (all fields and rows in orignal order)
+ h            : display this help screen
+ *            : mark main conditioning field (Also used for subplot rows)
+ +            : mark conditional summing fields (Also used for subplot columns)
+ ~            : mark (optional) weight field. (Also used for figure number).
+ s            : choose among saved stats
+ x            : execute a shell command
+ TAB          : switch to stats view
+ F            : toggle full shuffle of records for stats [currently: %s]
+ f            : find a field by name
+ m            : toggle display of numeric fields in monetary format [currently: %s]
+ X            : select x field
+ Y            : select y field
+ M            : select marker field (discrete variable)
+ C            : select color field (discrete variable)
+ S            : select marker-size field
+ U            : select arrow x component field
+ V            : select arrow y component field
+ G            : graphical plot of selected fields
+ w            : write (save) current view as a pytable file (NEEDS TO BE FIXED)
+ q            : quit program
+
+*******************************
+** EXTRA KEYS IN STATS VIEW: **
+*******************************
+ 1/2       : cycle through numerator or denominator sum variable 
+ 3         : cycle through percentage views
+ 4         : toggle between numerator/denominator and numerator-0.7*denominator
+ - =       : decrease/increase number of numerical intervals by increasing min cond prob
+ n/p       : move to next/previous field for first conditioning var
+ SPACE     : update view 
+ TAB or q  : go back to data view
+
+(press any key to continue)
+&quot;&quot;&quot; % (self.full_shuffle_stats, self.monetary_format)
+        # if c:
+        #    helptext = 'Pressed '+str(c)+'\n'+helptext
+
+        self.display_fullscreen(helptext)
+            
+#         helpi = 1
+#         for line in helptext.split('\n'):
+#             self.safeaddstr(helpi,2,line)
+#             helpi += 1
+#         self.stdscr.refresh();
+#         self.stdscr.getch();
+#         self.redraw()
+        
+    def safeaddstr(self,i,j,line,attr=curses.A_NORMAL):
+        if i&lt;curses.LINES-1 and j&lt;curses.COLS:
+            self.stdscr.addstr(i,j,line,attr)
+        
+    def fieldname(self, j):
+        return self.table.fieldnames[self.selected_columns[j]]
+
+    def fieldnames(self):
+        return [ self.table.fieldnames[self.selected_columns[j]] for j in xrange(self.width()) ]
+
+    def length(self):
+        if self.selected_rows is not None:
+            return len(self.selected_rows)
+        else:
+            return self.table.length()
+
+    def width(self):
+        return len(self.selected_columns)
+
+    def set_graph_field(self, fieldchar):
+        fieldname = self.fieldname(self.current_j)
+        if fieldchar in self.graph_fields and self.graph_fields[fieldchar]==fieldname:
+            del self.graph_fields[fieldchar]
+        else:
+            self.graph_fields[fieldchar]=fieldname
+        self.redraw()
+        
+    def fieldname_repr_and_style(self, j):
+        fieldname = self.fieldname(j)
+        fnamerepr = fieldname
+        style = curses.A_BOLD
+        if fieldname in self.target_fields:
+            fnamerepr = ' + '+fnamerepr
+            style = curses.A_BOLD | curses.A_UNDERLINE
+        if self.conditioning_field and fieldname==self.conditioning_field:
+            fnamerepr = ' * '+fnamerepr
+            style = curses.A_BOLD | curses.A_UNDERLINE
+        if self.weight_field and fieldname==self.weight_field:
+            fnamerepr = ' ~ '+fnamerepr
+            style = curses.A_BOLD | curses.A_UNDERLINE
+
+        for fieldchar,gfieldname in self.graph_fields.items():
+            if fieldname==gfieldname:
+                fnamerepr = fieldchar+' '+fnamerepr            
+
+        pos = None
+        try:
+            pos = self.selected_fields.index(fieldname)
+        except ValueError:
+            pass
+
+        if pos != None:
+            fnamerepr = str(pos)+'. '+fnamerepr 
+            style = style | curses.A_REVERSE
+           
+        return fnamerepr, style
+
+    def redraw(self):
+        self.stdscr.erase()
+        l, w = self.length(),self.width()
+        table = self.table
+        if self.current_j&gt;=self.width():
+            self.current_j = self.width()-1
+        if self.transposed:
+            self.draw_transposed()
+        else:
+            self.draw_normal()
+
+        # Write title
+        # self.stdscr.hline(0,0,curses.COLS-1,ord(' '))
+        title = self.table.title()
+        self.stdscr.addstr(0,0,title,curses.A_BOLD)
+        # Write dimensions
+        dimstr = self.get_toprightinfo()
+        self.stdscr.addstr(0,curses.COLS-len(dimstr)-1,dimstr,curses.A_BOLD)
+        
+        # write info line
+        self.stdscr.hline(curses.LINES-2,0,curses.COLS,ord('_'))
+        # self.stdscr.addstr(curses.LINES-2,0,'_'*curses.COLS)
+        current_val = self.getVal(self.current_i,self.current_j)
+        infoline = self.rowname(self.current_i)+' | '+self.fieldname(self.current_j)+' | '+str(current_val) + ' | ' + str(type(current_val))
+        self.writebottom(infoline)
+        self.stdscr.refresh();
+
+    def get_toprightinfo(self):
+        return self.toprightinfo
+
+    def set_toprightinfo(self, text):
+        self.toprightinfo = text
+
+    def rowname(self,i):
+        return self.table.rowname(i)
+
+    def format(self,x):
+        v = None
+        try: v = float(x)
+        except ValueError: pass
+        except TypeError: pass
+        if v == None or not self.monetary_format:
+            return str(x)
+        return locale.format('%.2f', v, True)
+
+
+    def draw_normal(self):
+        istart, jstart = self.i0, self.j0
+        istop = istart+self.ni
+        if istop&gt;self.length():
+            istop = self.length()
+        jstop = jstart+self.nj
+        if jstop&gt;self.width():
+            jstop = self.width()
+
+        # write fieldnames
+        for j in xrange(jstart,jstop):
+            fieldname, style = self.fieldname_repr_and_style(j)
+            self.writecolname(j-jstart,fieldname,style)
+
+        # write rowname and values of table row i
+        prev_row = None
+        for i in xrange(istart,istop):
+            # write name of row i            
+            rowname = self.rowname(i)
+            self.writerowname(i-istart,rowname,curses.A_BOLD)
+            row = self.getRow(i)
+            # write values of row i
+            for j in xrange(jstart,jstop):
+                val = row[j]
+                #strval = str(val)
+                strval = self.format(val)
+                if self.dot_mode and prev_row!=None and prev_row[j]==val:
+                    strval = '...'
+                style = curses.A_NORMAL
+                if j==self.current_j or i==self.current_i:
+                    style = curses.A_REVERSE
+                self.writefield(i-istart,j-jstart,strval,style)
+            prev_row = row
+
+    def draw_transposed(self):
+        istart, jstart = self.i0, self.j0
+        istop = istart+self.ni
+        if istop&gt;self.length():
+            istop = self.length()
+        jstop = jstart+self.nj
+        if jstop&gt;self.width():
+            jstop = self.width()
+
+        # write fieldnames
+        for j in xrange(jstart,jstop):
+            fieldname, style = self.fieldname_repr_and_style(j)
+            self.writerowname(j-jstart,fieldname,style)
+
+        # write rowname and values of table row i
+        prev_row = None
+        for i in xrange(istart,istop):
+            # write name of row i            
+            rowname = self.rowname(i)
+            self.writecolname(i-istart,rowname,curses.A_BOLD)
+            row = self.getRow(i)
+            # write values of row i
+            for j in xrange(jstart,jstop):
+                val = row[j]
+                #strval = str(val)
+                strval = self.format(val)
+                if self.dot_mode and prev_row!=None and prev_row[j]==val:
+                    strval = '...'
+                style = curses.A_NORMAL
+                if j==self.current_j or i==self.current_i:
+                    style = curses.A_REVERSE
+                self.writefield(j-jstart,i-istart,strval,style)
+            prev_row = row
+
+    def saveStats(self):
+        self.statslock.acquire()
+        fpath = self.statsFilePathFromSelectedVars()
+        dirpath = os.path.dirname(fpath)
+        if not os.path.isdir(dirpath):
+            os.makedirs(dirpath)
+        f = open(fpath+'.new','wb')
+        pickle.dump(self.stats, f, 0) # using protocol 0, because 1 and 2 have bug not allowing pickling of inf
+        f.close()
+        try: os.remove(fpath)
+        except OSError: pass
+        os.rename(fpath+'.new',fpath)
+        self.statslock.release()
+
+    def statsFilePathFromSelectedVars(self):
+        dirpath = self.table.filepath()+'.stats'
+        fname = 'CONDSTAT_'+self.conditioning_field+'___'+self.weight_field+'___'+'___'.join(self.target_fields)+'.pickle'
+        fpath = os.path.join(dirpath,fname)
+        return fpath
+
+    def loadStats(self, statsfpath):
+        self.clearStats()
+        self.selectVarsFromStatsFilePath(statsfpath)
+        f = open(statsfpath)
+        self.stats = pickle.load(f)
+        f.close()
+        self.sumvar = ''
+        self.divvar = ''
+        self.marginalize = 0
+        self.combinvarsmode = 0
+        
+    def loadMostRecentStats(self):
+        dirpath = self.table.filepath()+'.stats'
+        try:
+            fpathlist = [ os.path.join(dirpath,fname) for fname in os.listdir(dirpath) if fname.startswith('CONDSTAT_') and fname.endswith('.pickle') ]
+        except OSError:
+            fpathlist = []
+        if not fpathlist:
+            scr = self.stdscr
+            scr.erase()
+            self.safeaddstr(5,3,&quot;You must choose at least the conditioning field with * before getting statistics&quot;,curses.A_BOLD)
+            scr.refresh();
+            scr.getch();
+            self.redraw()
+            return                
+        fpathtimes = [ os.stat(fpath).st_mtime for fpath in fpathlist ]
+        fpath = fpathlist[argmax(fpathtimes)]
+        self.loadStats(fpath)        
+
+    def chooseStats(self):
+        self.stopThread()
+        dirpath = self.table.filepath()+'.stats'
+        try:
+            fnamelist = [ fname for fname in os.listdir(dirpath) if fname.startswith('CONDSTAT_') and fname.endswith('.pickle') ]
+        except OSError:
+            fnamelist = []
+        if not fnamelist:
+            return
+        else:
+            headlen = len('CONDSTAT_')
+            taillen = len('.pickle')
+            def myrepr(fname):
+                tokens = fname[headlen:-taillen].split('___')
+                condfield = tokens[0]
+                wfield = tokens[1]
+                rest = tokens[2:]
+                if wfield:
+                    return '*'+condfield+'  ~'+wfield+'  +'+' +'.join(rest)
+                else:
+                    return '*'+condfield+'  +'+' +'.join(rest)
+            itemlist = map(myrepr, fnamelist)
+            itemnum = select_item(self.stdscr, itemlist, 'Choose a stats file to load')
+        statsfpath = os.path.join(dirpath,fnamelist[itemnum])
+        self.loadStats(statsfpath)        
+
+    def selectVarsFromStatsFilePath(self, fpath):
+        fname = os.path.basename(fpath)
+        basename,ext   = os.path.splitext(fname)
+
+        if ext!='.pickle':
+            raise ValueError('statfilepath should end with .pickle')
+        if not basename.startswith('CONDSTAT_'):
+            raise ValueError('statfilepath should start with CONDSTAT_')
+        fieldnames = basename[len('CONDSTAT_'):].split('___')
+        self.conditioning_field = fieldnames[0]
+        self.weight_field = fieldnames[1]
+        if fieldnames[2]:
+            self.target_fields = fieldnames[2:]
+        else:
+            self.target_fields = []
+            
+        # f = open('toto.log','w')
+        # print &gt;&gt;f, 'fpath: ',fpath 
+        # print &gt;&gt;f, 'fieldnames: ',fieldnames 
+        # print &gt;&gt;f, 'self.target_fields: ',self.target_fields
+        # f.close()
+
+    def initStats(self):
+        &quot;&quot;&quot;Initializes the stats member according to selected variables
+        trying to load a start version from file if available&quot;&quot;&quot;
+
+        try:
+            self.loadStats(self.statsFilePathFromSelectedVars())
+        except IOError:
+            var_combinations = all_combinations([self.table.fieldnames, [self.conditioning_field]])
+            var_domains = {}
+            for varname in self.table.fieldnames:
+                var_domains[varname] = AutoDomain()
+            self.stats = BaseTableStats(var_combinations, var_domains, self.target_fields, self.weight_field,
+                                        self.full_shuffle_stats)
+            self.initShuffledIndex()
+            # update with row 0 so that stats are not empty
+            row = self.table[self.shuffled_rowidx[0]]
+            self.stats.update(row) 
+            self.startThread()
+            self.sumvar = ''
+            self.divvar = ''
+            self.marginalize = 0
+            self.combinvarsmode = 0
+
+    def clearStats(self):
+        self.stopThread()
+        self.stats = None
+
+    def initShuffledIndex(self):
+        min_len_for_partial_shuffle= 5000
+        if self.shuffled_rowidx is None:
+            self.stdscr.erase()
+            self.safeaddstr(5,3,&quot;Building shuffled index. Please be patient...&quot;,curses.A_BOLD)
+            self.stdscr.refresh()
+            numpy.numarray.random_array.seed(58273,26739)
+            self.shuffled_rowidx = numpy.numarray.random_array.permutation(self.table.length()).astype(int)
+            if hasattr(self.stats, 'full_shuffle_stats'):
+                self.full_shuffle_stats= self.stats.full_shuffle_stats
+            else:
+                self.full_shuffle_stats= True
+            if not self.full_shuffle_stats and self.table.length() &gt;= min_len_for_partial_shuffle:
+                x= self.shuffled_rowidx
+                #x.resize(min_len_for_partial_shuffle)
+                resize(x,[min_len_for_partial_shuffle])
+                xd = {}
+                for z in x:
+                    xd[z]=z
+                y = numpy.numarray.arange(self.table.length())
+                y= numpy.numarray.array([z for z in y if xd.get(z) == None])
+                self.shuffled_rowidx= numpy.numarray.concatenate((x,y)).astype(int)
+    
+    def startThread(self):
+        if not self.statsthread and self.stats.nsamples&lt;self.table.length():
+            self.initShuffledIndex()
+            self.statsthread = threading.Thread(target=self.statsThreadRun)
+            self.statsthread.start()
+
+    def statsThreadRun(self):
+        l = self.table.length()
+        idx = self.shuffled_rowidx
+        self.statslock.acquire()
+        nsamples = self.stats.nsamples
+        self.statslock.release()
+
+        #f=open('xxxxx.nfg.tmp','w')
+        
+
+        while nsamples&lt;l:            
+            self.statslock.acquire()
+            row = self.table[idx[nsamples]]
+            
+            #f.write(str([nsamples, idx[nsamples]]))
+
+            nsamples = self.stats.update(row)
+            stop_thread = self.stop_thread
+            self.statslock.release()
+
+            
+            if stop_thread:
+                break
+            if nsamples % 2000 == 0:
+                self.saveStats()
+        self.saveStats()
+
+        #f.close()
+            
+    def stopThread(self):
+        if self.statsthread:
+            self.statslock.acquire()
+            self.stop_thread = True
+            self.statslock.release()
+            self.statsthread.join()
+            self.statsthread = None
+            self.stop_thread = False
+
+    def transpose(self):
+        self.transposed = not self.transposed
+        self.compute_ni_nj()
+        self.i0 = max(0,self.current_i-self.ni//2)
+        self.j0 = max(0,self.current_j-self.nj//2)
+        self.redraw()
+
+    def sort_rows(self, j, reverse=False):
+        &quot;&quot;&quot;sort in incresing order of field j&quot;&quot;&quot;
+        if self.selected_rows is None:
+            self.selected_rows = range(self.length())
+        if reverse: # hack to make sure we keep the partial order of previous sorts on other columns
+            self.selected_rows.reverse()
+        biglist = [ (float_or_str(self.getVal(pos,j)), pos) for pos in xrange(self.length()) ]
+        biglist.sort(reverse=reverse)
+        self.selected_rows = [ self.selected_rows[pos] for val,pos in biglist ]
+        self.redraw()
+
+    def previous_row(self):
+        if self.current_i&gt;0:
+            self.current_i -= 1
+            if self.current_i&lt;self.i0:
+                self.i0 -= 1
+
+    def next_row(self):
+        if self.current_i&lt;self.length()-1:
+            self.current_i += 1
+            if self.current_i&gt;=self.i0+self.ni:
+                self.i0 += 1
+
+    def previous_field(self):
+        if self.current_j&gt;0:
+            self.current_j -= 1
+            if self.current_j&lt;self.j0:
+                self.j0 -= 1
+
+    def next_field(self):
+        if self.current_j&lt;self.width()-1:
+            self.current_j += 1
+            if self.current_j&gt;=self.j0+self.nj:
+                self.j0 += 1
+
+    def left(self):
+        if self.transposed:
+            self.previous_row()
+        else:
+            self.previous_field()
+        self.redraw()
+
+    def right(self):
+        if self.transposed:
+            self.next_row()
+        else:
+            self.next_field()
+        self.redraw()
+
+    def up(self):
+        if self.transposed:
+            self.previous_field()
+        else:
+            self.previous_row()
+        self.redraw()
+
+    def down(self):
+        if self.transposed:
+            self.next_field()
+        else:
+            self.next_row()
+        self.redraw()
+
+    def pgdown(self):
+        if self.transposed:
+            self.j0 = min(self.j0+self.nj, max(0,self.width()-self.nj))
+            self.current_j = min(self.current_j+self.nj, self.width()-1)
+        else:
+            self.i0 = min(self.i0+self.ni, max(0,self.length()-self.ni))
+            self.current_i = min(self.current_i+self.ni, self.length()-1)
+        self.redraw()
+
+    def pgup(self):
+        if self.transposed:
+            self.j0 = max(self.j0-self.nj, 0)
+            self.current_j = max(self.current_j-self.nj, 0)
+        else:
+            self.i0 = max(self.i0-self.ni, 0)
+            self.current_i = max(self.current_i-self.ni, 0)
+        self.redraw()
+
+    def home(self):
+        if self.transposed:
+            self.j0 = 0
+            self.current_j = 0
+        else:
+            self.i0 = 0
+            self.current_i = 0
+        self.redraw()
+
+    def end(self):
+        if self.transposed:
+            self.current_j = self.width()-1
+            self.j0 = max(0, self.width()-self.nj)
+        else:
+            self.current_i = self.length()-1
+            self.i0 = max(0, self.length()-self.ni)
+        self.redraw()
+
+    def input(self,prompt):
+        si = curses.LINES-1
+        self.stdscr.addstr(si,0,' '*(curses.COLS-1))
+        self.stdscr.addstr(si,0,prompt, curses.A_BOLD)
+        curses.echo()
+        entry = self.stdscr.getstr(si,len(prompt))
+        curses.noecho()
+        return entry
+
+    def goto_line(self,i):
+        i = max(0, min(i, self.length()-1))
+        self.current_i = i
+        self.i0 = max(0,i-self.ni//2)
+        self.redraw()
+
+    def goto_col(self,j):
+        j = max(0, min(j, self.width()-1))
+        self.current_j = j
+        self.j0 = max(0,j-self.nj//2)
+        self.redraw()
+
+    def search_next(self):
+        orig_i = self.current_i
+        for i in xrange(self.current_i+1, self.length()):
+            if i%10000 == 0: #prorgess...
+                self.goto_line(i)
+            if self.search_expression=='':
+                val = self.getVal(i,self.search_field)
+                if str(val) == self.search_value:
+                    self.goto_line(i)
+                    return #break
+            else:
+                v = dict(zip(self.table.fieldnames, self.getFullRow(i)))
+                try:
+                    res = eval(self.search_expression, globals(), v)
+                except:
+                    self.goto_line(i)
+                    self.display_exception(sys.exc_info())
+                    return #break
+                else:
+                    if res:
+                        self.goto_line(i)
+                        return #break
+        self.goto_line(orig_i) # not found, reset cursor (was moved to show progress)
+
+    def select_constant_cols(self):
+        &quot;&quot;&quot;Will select all columns for which the values do not change&quot;&quot;&quot;
+
+        constant_cols = self.selected_columns[:]
+
+        first_row = None
+        for i in xrange(self.length()):
+            if self.selected_rows is None:
+                orig_i = i
+            else:
+                orig_i = self.selected_rows[i]
+            row = self.table.getRow(orig_i)
+            if first_row is None:
+                first_row = row[:]
+            constant_cols = [ j for j in constant_cols if row[j]==first_row[j] ]
+        self.selected_fields = [ self.table.fieldnames[j] for j in constant_cols ]
+        self.redraw()
+
+    def filter(self):
+        if self.selected_fields == []:
+            filter_expression = self.input('Filter expression ex: float(AGE)&gt;3 : ').strip()
+        else:
+            row = self.getFullRow(self.current_i)
+            filter_expression = ' and '.join([ 'locals()[&quot;'+fname+'&quot;]=='+repr(row[fname]) for fname in self.selected_fields ])
+            #self.selected_columns = [ self.table.fieldnames.index(fname) for fname in self.selected_fields]
+
+        if filter_expression!='':
+            selection = []
+            for i in xrange(self.length()):
+                if self.selected_rows is None:
+                    orig_i = i
+                else:
+                    orig_i = self.selected_rows[i]
+                v = dict(zip(self.table.fieldnames, self.table.getRow(orig_i)))
+                try:
+                    keepit = eval(filter_expression, globals(), v)
+                except:
+                    self.goto_line(i)
+                    self.display_exception(sys.exc_info(), filter_expression)
+                    self.redraw()
+                    return
+                else:
+                    if keepit:
+                        selection.append(orig_i)
+                if i==self.current_i:
+                    self.current_i = len(selection)-1
+            self.selected_rows = selection
+            self.selected_fields = []
+        self.i0 = 0
+        #self.j0 = 0
+        self.current_i = 0
+        #self.current_j = 0
+        self.redraw()
+
+    def executeShellCommand(self, command):
+
+        filepathdir = &quot;&quot;
+        # First figure out filepathdir (if possible)
+        try:
+            filepath = self.getFullRow(self.current_i)[&quot;_filepath_&quot;]
+            filepathdir = os.path.dirname(filepath)
+        except KeyError:
+            pass
+
+        # replace _DIRPATH_ in command by filepathdir
+        command = command.replace('_DIRPATH_',filepathdir)
+        
+        # os.system(command)
+        subprocess.Popen(command, shell=True)
+        
+    def chooseAndExecuteShellCommand(self):
+        
+        commands = [
+            ('s',&quot;Launch terminal and shell in this matrix's directory&quot;,
+             &quot;&quot;&quot;xterm -e sh -c &quot;cd '_DIRPATH_'; pwd; ls; sh&quot; &quot;&quot;&quot;),
+            ('1',&quot;View layer 1 unsup training costs&quot;,
+             &quot;&quot;&quot;xterm -e sh -c &quot;cd '_DIRPATH_'; myplearn vmat view training_costs_layer_1.pmat&quot; &quot;&quot;&quot;),
+            ('i',&quot;deepnetplot.py plotRepAndRec learner.psave&quot;, 
+             &quot;&quot;&quot;xterm -e sh -c &quot;cd '_DIRPATH_'; pwd; deepnetplot.py plotRepAndRec learner.psave ~/data/mnist/mnist_small/mnist_basic2_valid.pmat; sh&quot; &quot;&quot;&quot;),
+            ('w',&quot;deepnetplot.py plotEachRow learner.psave&quot;, 
+             &quot;&quot;&quot;xterm -e sh -c &quot;cd '_DIRPATH_'; pwd; deepnetplot.py plotEachRow learner.psave ~/data/mnist/mnist_small/mnist_basic2_valid.pmat; sh&quot; &quot;&quot;&quot;),
+            ('I',&quot;deepnetplot.py plotRepAndRec final_learner.psave&quot;, 
+             &quot;&quot;&quot;xterm -e sh -c &quot;cd '_DIRPATH_'; pwd; deepnetplot.py plotRepAndRec final_learner.psave ~/data/mnist/mnist_small/mnist_basic2_valid.pmat; sh&quot; &quot;&quot;&quot;),
+            ('W',&quot;deepnetplot.py plotEachRow final_learner.psave&quot;, 
+             &quot;&quot;&quot;xterm -e sh -c &quot;cd '_DIRPATH_'; pwd; deepnetplot.py plotEachRow final_learner.psave ~/data/mnist/mnist_small/mnist_basic2_valid.pmat; sh&quot; &quot;&quot;&quot;),
+            ]
+
+        menutxt = '\n'.join([ '['+commands[i][0]+'] '+commands[i][1] for i in range(len(commands)) ])+'\n'
+        k = self.display_fullscreen(menutxt)
+        for com in commands:
+            key, descr, command = com
+            if k==ord(key):
+                self.executeShellCommand(command)
+                break
+            
+        if( k==ord('\n') ):
+            return
+
+    def collect_fieldvecs(self, fieldnames):
+        &quot;&quot;&quot;Returns a dictionary indexed by the names of fields,
+        containing vectors of values of those fields.&quot;&quot;&quot;
+        orig_fieldnames = self.table.fieldnames
+        orig_pos = [ orig_fieldnames.index(fname) for fname in fieldnames ]
+        l = self.length()
+        n = len(fieldnames)
+        fieldvecs = [ [] for i in xrange(n) ]
+        for i in xrange(l):
+            row = self.getFullRow(i)
+            for j in xrange(n):
+                fieldvecs[j].append( row[orig_pos[j]] )
+        fieldvecdict = {}
+        for j in xrange(n):
+            fieldvecdict[fieldnames[j]] = numpy.array(fieldvecs[j])
+        return fieldvecdict
+
+    def take_part_of_fieldvecs(self, positions, fieldvecs):
+        result = {}
+        for name,fieldvec in fieldvecs.items():
+            result[name] = numpy.take(fieldvec, positions)
+        return result
+    
+    def graphical_scatter_plot(self):
+        &quot;&quot;&quot;
+        (STILL UNDER DEVELOPMENT, SOME DEBUGGING LEFT TO DO)
+        This docstring is probably not fully accurate.
+        The function can potentially create several figures, one for each value of the 'weight field' (if specified).
+        For each figure, it can create several subplots, based on the values of the 'conditioning field' and selected target fields.
+        For each such subplot, it will use the following tagged fields:
+        X: coordinate
+        Y: coordinate
+        C: color
+        M: marker
+        S: size of marker
+
+        A color field can be specified for a categorical variable.
+        A marker field can be specified for a categorical variable (points will use different markers).
+        
+        If U and/or V are specified, an arrow plot is superposed (pylab.quiver) of given U,V relative tip coordinates
+        &quot;&quot;&quot;
+
+        # First find out what fields are of interest
+        fieldnames = self.graph_fields.values()
+        if self.conditioning_field!='':
+            fieldnames.append(self.conditioning_field)
+        if self.weight_field!='':
+            fieldnames.append(self.weight_field)
+        fieldnames += self.target_fields
+
+        # collect the values of those fields in a dictionary indexed by fieldname
+        fieldvecs = self.collect_fieldvecs(fieldnames)
+
+        if self.weight_field!='':
+            val2pos = mapping_of_values_to_pos(fieldvecs[self.weight_field])
+            fignum = 0
+            for val, positions in val2pos.items():
+                fieldvecs_part = self.take_part_of_fieldvecs(positions, fieldvecs)
+                fignum += 1
+                pylab.figure(fignum)
+                self.scatter_plot_all_subplots(fieldvecs_part, title=self.weight_field+'='+str(val))
+        else:
+            pylab.figure(1)
+            self.scatter_plot_all_subplots(fieldvecs, title=&quot;&quot;)            
+
+        pylab.show()
+
+    def display_colors_legend(self, colorlabel, colorlist):
+        &quot;&quot;&quot;colorlist is a list of pairs (value, coilrspec) for the legend&quot;&quot;&quot;
+        x = 0.92
+        y = 0.9
+        pylab.figtext(x,y,'['+colorlabel+']',color='k',weight='bold')
+        y -= 0.025
+        for val,color in colorlist:
+            pylab.figtext(x,y,str(val),color=color)
+            y -= 0.025
+
+    def display_markers_legend(self, markerlabel, markerdict):
+        legend_lines = []
+        legend_labels = markerdict.keys()
+        legend_labels.sort()
+        for label in legend_labels:
+            legend_lines.append(pylab.Line2D(range(2), range(2), linestyle=' ',
+                                             marker=markerdict[label], color='k'))
+        label_line = pylab.Line2D(range(2), range(2), linestyle=' ', marker=' ', color='k')
+        pylab.figlegend([label_line]+legend_lines,
+                        [markerlabel]+legend_labels,
+                        'lower right')        
+                
+    def scatter_plot_all_subplots(self, fieldvecs, title=''):
+        # TODO: fix this: pylab.suptitle(title)
+        rows_field = self.conditioning_field
+        if rows_field=='':
+            nrows = 1
+        else:
+            rows_val2pos = mapping_of_values_to_pos(fieldvecs[rows_field])
+            rows_vals = rows_val2pos.keys()
+            nrows = len(rows_vals)
+        
+        if len(self.target_fields)==0:
+            cols_field = ''
+            ncols = 1
+        else:
+            cols_field = self.target_fields[0]
+            cols_val2pos = mapping_of_values_to_pos(fieldvecs[cols_field])
+            cols_vals = cols_val2pos.keys()
+            ncols = len(cols_vals)
+
+        # For convenience, make a new dictionary indexes by keys ('X', 'Y','C') rather than by actual fieldnames
+        kvecs = {}
+        for key,fieldname in self.graph_fields.items():
+            kvecs[key] = fieldvecs[fieldname]
+
+        mymarkers= ['o','s','&gt;','&lt;','^','v','d','p','h','g','+','x']
+        mymarkerdict = {} # will map values of the 'M' field to marker symbols
+        self.colors = ['b','g','r','c','y','k','m']
+        self.C2idx = {} # will map values of the 'C' field to color index
+        self.cmap = matplotlib.colors.ListedColormap(self.colors)
+
+        # Numerize a number of fields
+        if 'X' in kvecs:
+            kvecs['X'] = to_numpy_float_array(kvecs['X'], missing_value = 0.)
+        if 'Y' in kvecs:
+            kvecs['Y'] = to_numpy_float_array(kvecs['Y'], missing_value = 0.)
+        if 'S' in kvecs:
+            kvecs['S'] = to_numpy_float_array(kvecs['S'], missing_value = 0.)
+        if 'U' in kvecs:
+            kvecs['U'] = to_numpy_float_array(kvecs['U'], missing_value = 0.)
+        if 'V' in kvecs:
+            kvecs['V'] = to_numpy_float_array(kvecs['V'], missing_value = 0.)
+        if 'C' in kvecs: # transform it to real values indexed in self.cmap
+            n = len(self.colors)
+            for val in kvecs['C']:
+                self.C2idx.setdefault(val, len(self.C2idx)%n)
+            # print &gt;&gt;sys.stderr, self.C2idx
+            kvecs['Cfloat'] = [ float(self.C2idx[val])/n for val in kvecs['C'] ]
+        if 'M' in kvecs: # transform it to marker strings
+            for val in kvecs['M']:
+                mymarkerdict.setdefault(val, mymarkers[len(mymarkerdict)%len(mymarkers)])
+            kvecs['M'] = [ mymarkerdict[val] for val in kvecs['M'] ]
+            
+        # make sure we have both X and Y
+        if 'X' not in kvecs or 'Y' not in kvecs:
+            if 'X' in kvecs:
+                kvecs['Y'] = zeros(len(kvecs['X']))
+            elif 'Y' in kvecs:
+                kvecs['X'] = zeros(len(kvecs['Y']))
+            else:
+                raise ValueError(&quot;Scatter plot requires you to specify at least one of X or Y fields&quot;)
+            
+        for i in range(nrows):             
+            newtitle = ''
+            if rows_field=='':
+                r_kvecs_part = kvecs
+            else:
+                newtitle += rows_field+'='+str(rows_vals[i])
+                r_kvecs_part = self.take_part_of_fieldvecs(rows_val2pos[rows_vals[i]], kvecs)        
+            
+            if cols_field=='':
+                pylab.subplot(nrows, ncols, 1+i)
+                pylab.title(newtitle)
+                self.scatter_plot_in_axes(r_kvecs_part)
+            else:
+                cols_val2pos = mapping_of_values_to_pos(r_kvecs_part[cols_field])                
+                for cval,j in zip(cols_vals, range(ncols)):
+                    if cval in cols_val2pos:
+                        newtitle += cols_field+'='+str(cols_vals[j])
+                        c_kvecs_part = self.take_part_of_fieldvecs(cols_val2pos[cval], r_kvecs_part)
+                        pylab.subplot(nrows, ncols, 1+i*ncols+j)
+                        pylab.title(newtitle)
+                        self.scatter_plot_in_axes(c_kvecs_part)
+
+
+        C2spec = [ (val, self.colors[self.C2idx[val]]) for val in self.C2idx ]
+        C2spec.sort()
+        self.display_colors_legend(self.graph_fields.get('C',''), C2spec)
+        self.display_markers_legend(self.graph_fields.get('M',''), mymarkerdict)
+
+        
+    def scatter_plot_in_axes(self, kvecs, default_color='b', default_marker='o'):
+
+        # make a useful all-zeros vector
+        n = len(kvecs['X'])
+        zer = zeros(n)
+
+        X = kvecs.get('X',None)
+        Y = kvecs.get('Y',None)
+        U = kvecs.get('U',None)
+        V = kvecs.get('V',None)
+
+        # plot arrows
+        if U is not None or V is not None:
+            if V is None:
+                V = zer
+            elif U is None:
+                U = zer
+            pylab.quiver(X,Y,U,V,width=0.002, color='gray')
+                
+
+#         if 'M' in kvecs and 'C' in kvecs:
+#             markers_v2pos = mapping_of_values_to_pos(kvecs['M'])
+#             i = 0
+#             for mval, mpositions in markers_v2pos.items():
+#                 kvecs_m = self.take_part_of_fieldvecs(mpositions, kvecs)
+#                 marker = markers[i%len(markers)]
+                
+#                 colors_v2pos = mapping_of_values_to_pos(kvecs_m['C'])
+#                 j = 0
+#                 for cval, cpositions in colors_v2pos.items():
+#                     kvecs_mc = self.take_part_of_fieldvecs(cpositions, kvecs_m)
+#                     color = colors[j%len(colors)]
+#                     line = pylab.plot(kvecs_mc['X'],
+#                                       kvecs_mc['Y'],
+#                                       # s = kvecsp.get('S',20),
+#                                       marker = marker,
+#                                       color = color,
+#                                       linestyle = 'None'
+#                                       )
+#                     if i==0:
+#                         colors_legend_lines.append(line)
+#                         colors_legend_labels.append(str(cval))
+#                     if j==0:
+#                         markers_legend_lines.append(line)
+#                         markers_legend_labels.append(str(mval))
+#                     j = j+1
+#                 i = i+1
+
+            
+        # split on marker?        
+        if 'M' in kvecs:
+            val2pos = mapping_of_values_to_pos(kvecs['M'])
+            for marker, positions in val2pos.items():
+                kvecsp = self.take_part_of_fieldvecs(positions, kvecs)
+                #print &gt;&gt;sys.stderr, &quot;Len: &quot;,len(kvecsp['X']),len(kvecsp['Cfloat'])
+                #print &gt;&gt;sys.stderr, marker, &quot;: &quot;,kvecsp.get('C',default_color)
+                line = pylab.scatter(kvecsp['X'],
+                                     kvecsp['Y'],
+                                     s = kvecsp.get('S',40),
+                                     marker = marker,
+                                     c = kvecsp.get('Cfloat',default_color),
+                                     cmap = self.cmap,
+                                     #norm = matplotlib.colors.NoNorm(vmin=0, vmax=1)
+                                     vmin = 0.,
+                                     vmax = 1.)
+                
+        else: # no markers, make a single scatter plot
+#             msg = &quot; x=&quot;+repr(kvecs['X'])\
+#                   +&quot;\r\n y=&quot;+repr(kvecs['Y'])\
+#                   +&quot;\r\n s=&quot;+repr(kvecs.get('S',20))\
+#                   +&quot;\r\n marker=&quot;+repr(default_marker)\
+#                   +&quot;\r\n c=&quot;+repr(kvecs.get('Cfloat',default_color))\
+#                   +&quot;\r\n&quot;;            
+#             sys.stderr.write(msg)                  
+            pylab.scatter(kvecs['X'],
+                          kvecs['Y'],
+                          s = kvecs.get('S',40),
+                          marker = default_marker,
+                          c = kvecs.get('Cfloat',default_color),
+                          cmap = self.cmap,
+                          #norm = matplotlib.colors.NoNorm(vmin=0, vmax=1)
+                          vmin = 0.,
+                          vmax = 1.)
+                
+        pylab.xlabel(self.graph_fields.get('X','no X'))
+        pylab.ylabel(self.graph_fields.get('Y','no Y'))
+
+
+        #if len(colors_legend_lines)!=0:
+        #    pylab.legend(colors_legend_lines, colors_legend_labels, loc=1)
+
+#         if len(markers_legend_lines)!=0:
+#             pylab.legend(markers_legend_lines, markers_legend_labels, loc=4)
+
+#         legend_lines = []
+#         legend_lines.append(pylab.Line2D(range(10), range(10), linestyle='-', marker='o', color='b'))
+#         legend_labels.append('aaaa')
+#         legend_lines.append(pylab.Line2D(range(10), range(10), linestyle='-', marker='x', color='g'))
+#         legend_labels.append('bbbb')
+#         pylab.legend(legend_lines, legend_labels)
+
+    def graphical_plot(self):
+        menutxt = &quot;&quot;&quot;
+        ************************************************
+        ** Choose the kind of graphical plot you want **
+        ************************************************
+          NOTE: THIS FEATURE IS STILL UNDER DEVELOPMENT
+                AND NOT QUITE READY TO USE YET (Pascal)
+                
+          [1]: scatter plot (with optional horizontal and vertical arrows).
+               Can use X, Y, C (color), M (marker), S (size), U, V.
+               If present uses U,V for a horizontal and vertical arrow of different scales.
+          [2]: scatter plot (with optional single arrow).
+               Same as [1] but U,V are considered the relative coordinates
+               of the tip of a single arrow and will have the same scale. 
+        
+          Or press ENTER to cancel
+        &quot;&quot;&quot;
+
+        if &quot;pylab&quot; not in globals():
+            global pylab
+            import matplotlib.pylab as pylab
+
+        self.graphical_scatter_plot()
+
+#         k = self.display_fullscreen(menutxt,&quot;12\n&quot;)
+#         if( k==ord('\n') ):
+#             return
+    
+#         if( k==ord('1') ):           
+#         elif( k==ord('2') ):           
+#             self.graphical_scatter_plot()
+
+
+            
+    def display_exception(self,exc, expression=''):
+        ls= ([&quot;Error in search expression:\n&quot;] +
+             [ expression +'\n'] +
+             traceback.format_exception(*exc) +
+             [&quot;\n(press any key to continue.)&quot;])
+        txt= &quot;&quot;
+        for l in ls:
+            txt= txt + l
+        self.display_fullscreen(txt)
+
+
+    def display_fullscreen(self,txt, check_key=&quot;&quot;):
+        &quot;&quot;&quot;Displays the given text, and waits for a valid key press.
+        The code of the pressed key is returned.
+        Any key is considered valid if check_key is the empty string
+        If check_key is a character string, then one of the
+        specified keys must be pressed.&quot;&quot;&quot;
+        self.stdscr.erase()
+        i = 1
+        for line in txt.split('\n'):
+            self.safeaddstr(i,2,line)
+            i += 1
+        self.stdscr.refresh();
+        k = self.stdscr.getch();
+        if check_key!=&quot;&quot;:
+            allowed_codes = [ ord(c) for c in check_key ]
+            while k not in allowed_codes:
+                k = self.stdscr.getch();                            
+        self.redraw()
+        return k
+        
+    def search_previous(self):
+        for i in xrange(self.current_i-1, -1, -1):
+            if self.search_expression=='':
+                val = self.getVal(i,self.search_field)
+                if str(val) == self.search_value:
+                    self.goto_line(i)
+                    break
+            else:
+                v = dict(zip(self.table.fieldnames, self.getFullRow(i)))
+                if eval(self.search_expression, globals(), v):
+                    self.goto_line(i)
+                    break
+
+    def alphabetical_order(self):        
+        selected_fieldnames = [ self.table.fieldnames[col] for col in self.selected_columns ]
+        selected_fieldnames.sort()
+        self.selected_columns = [ self.table.fieldnames.index(fname) for fname in selected_fieldnames ]
+        self.redraw()
+
+    def revert_to_original(self):
+        self.selected_columns = range(self.table.width())
+        self.selected_rows = None
+        self.redraw()        
+
+    def hideSelectedFields(self):
+        if self.selected_fields != []:
+            self.selected_columns = [ k for k in self.selected_columns if self.table.fieldnames[k] not in self.selected_fields ]
+        else: # no selected fields: simply hide the current field           
+            del self.selected_columns[self.current_j]
+        self.selected_fields = []
+        self.redraw()
+
+    def find_field(self):
+        fldname= self.input('Field name to find: ')
+        good = False
+        for j in xrange(self.table.width()):
+            if fldname.lower() == self.fieldname(j).lower():
+                self.goto_col(j)
+                self.redraw()
+                good = True
+                break
+        if not good:
+            self.writebottom(&quot;Field '&quot; + fldname + &quot;' not found.&quot;)
+
+    def event_loop(self):
+        ret = None
+        while not ret:
+            k = self.stdscr.getch() 
+            ret = self.handle_key_press(k)
+        if self.statsthread:
+            self.stopThread()
+        return ret
+
+    def handle_key_press(self, c):
+        if c == ord('q') or c==27:
+            return c
+        elif c == ord('\t'):
+            self.viewStatsTable()
+        elif c == ord('.'):
+            self.dot_mode = not self.dot_mode
+            self.redraw()
+        elif c == ord('t'):
+            self.transpose()
+        elif c == curses.KEY_UP:
+            self.up()
+        elif c == curses.KEY_DOWN:
+            self.down()
+        elif c == curses.KEY_LEFT:
+            self.left()
+        elif c == curses.KEY_RIGHT:
+            self.right()      
+        elif c == curses.KEY_NPAGE:
+            self.pgdown()            
+        elif c == curses.KEY_PPAGE:
+            self.pgup()
+        elif c == curses.KEY_HOME:
+            self.home()
+        elif c == curses.KEY_END:
+            self.end()
+        elif c == ord('s'):
+            self.chooseStats()
+            self.redraw()
+        elif c == ord('l'):
+            try: self.goto_line(int(self.input('Goto line #')))
+            except: pass
+        elif c == ord('='):
+            self.search_field = self.current_j
+            self.search_value = self.input('Search '+self.fieldname(self.current_j)+ ' = ')
+            self.search_expression = ''
+            self.search_next()
+        elif c == ord('/'):
+            self.search_field = self.current_j
+            self.search_expression = self.input('Search expression ex: float(AGE)&gt;3 : ').strip()
+            if self.search_expression!='':
+                self.search_next()
+        elif c == ord('!'):
+            self.filter()
+        elif c == ord('N'):
+            self.search_next()
+        elif c == ord('P'):
+            self.search_previous()
+        elif c == ord('n'):
+            self.next_field()
+            self.redraw()
+        elif c == ord('p'):
+            self.previous_field()
+            self.redraw()
+        elif c == ord('a'):
+            self.alphabetical_order()
+        elif c == ord('o'):
+            self.revert_to_original()
+        elif c == ord('c'):
+            self.select_constant_cols()
+        elif c == ord('k'):
+            self.hideSelectedFields()
+        elif c == ord('\n'):
+            self.hideFieldsNotSelected()
+        elif c == ord('h'):
+            self.display_help()
+        elif c == ord('&gt;'):
+            self.set_field_dim(self.fieldwidth+1,self.fieldheight)
+            self.redraw()
+        elif c == ord('&lt;'):
+            self.set_field_dim(self.fieldwidth-1,self.fieldheight)
+            self.redraw()
+        elif c == ord(')'):
+            self.sort_rows(self.current_j)
+        elif c == ord('('):
+            self.sort_rows(self.current_j, reverse=True)
+        elif c == ord('x'):
+            self.chooseAndExecuteShellCommand()
+        elif c == ord('*'):
+            self.clearStats()
+            fieldname = self.fieldname(self.current_j)
+            if self.conditioning_field == fieldname:
+                self.conditioning_field = ''
+            else:
+                self.conditioning_field = fieldname
+            self.redraw()
+        elif c == ord('~'):
+            self.clearStats()
+            fieldname = self.fieldname(self.current_j)
+            if self.weight_field == fieldname:
+                self.weight_field = ''
+            else:
+                self.weight_field = fieldname
+            self.redraw()
+        elif c == ord('+'):
+            self.clearStats()
+            fieldname = self.fieldname(self.current_j)
+            pos = bisect.bisect_left(self.target_fields, fieldname)
+            if pos&lt;len(self.target_fields) and self.target_fields[pos]==fieldname:
+                del self.target_fields[pos]
+            else:
+                self.target_fields.insert(pos,fieldname)
+            self.redraw()
+        elif c == ord('f'):
+            self.find_field()
+        elif c == ord('m'):
+            self.monetary_format= not self.monetary_format
+            if self.monetary_format:
+                locale.setlocale(locale.LC_NUMERIC, ('en_US','utf-8'))
+            else:
+                locale.setlocale(locale.LC_NUMERIC, self.orig_locale)
+            self.redraw()
+        elif c == ord('F'):
+            self.full_shuffle_stats= not self.full_shuffle_stats
+
+        elif c == ord(' '):
+            self.selectField()
+            self.redraw()
+
+        elif chr(c) in 'XYCMSUVW':
+            self.set_graph_field(chr(c))
+
+        elif c == ord('G'):
+            self.graphical_plot()
+
+        elif c == ord('w'):
+            self.saveSubTable()        
+
+        else:
+            curses.flash()
+            self.display_help(c)
+
+    def selectField(self):
+        field = self.fieldname(self.current_j)
+        if field in self.selected_fields:
+            self.selected_fields.remove(field)
+        else:
+            self.selected_fields.append(field)
+
+    def hideFieldsNotSelected(self):
+        if self.selected_fields != []:
+            self.j0 = 0
+            self.current_j = 0
+            self.selected_columns = [ self.table.fieldnames.index(fname) for fname in self.selected_fields]
+            self.selected_fields= []
+        self.redraw()
+
+    def saveSubTable(self):
+        orig_table= self.table.filepath()
+        pytablecode= &quot;&quot;&quot;
+from plearn.table.table import *
+result = SelectFields(openTable('%s'),%s)
+        &quot;&quot;&quot; % (orig_table, [ self.table.fieldnames[col] for col in self.selected_columns ])
+
+        new_tablename= self.input('File name for sub-table (.pytable): ').strip()
+        if new_tablename != '':
+            (base,ext)= os.path.splitext(new_tablename)
+            if ext != '.pytable':
+                new_tablename+= '.pytable'
+            if os.path.exists(new_tablename):
+                self.writebottom(&quot;File '&quot; + new_tablename + &quot;' already exists.&quot;)
+                return
+            self.stopThread()
+            f= open(new_tablename, 'w')
+            f.write(pytablecode)
+            f.close()
+            newtable = openTable(new_tablename)
+            newtable.set_title('FILE: '+new_tablename)
+            self.reinit(newtable)
+
+    def viewStatsTable(self):
+        if not self.stats:
+            if self.conditioning_field: # we have a conditioning field
+                self.initStats()
+            else: # no conditioning field, try to load the most recently updated stats
+                self.loadMostRecentStats()
+            if not self.stats:
+                return
+
+        while 1:
+            self.statslock.acquire()
+            ns = self.stats.nsamples
+            self.statslock.release()
+            if ns&lt;1:
+                break
+            currentvar = self.fieldname(self.current_j)
+            condvar = self.conditioning_field
+            valuenames = self.stats.extended_value_names()
+            if not self.sumvar:
+                self.sumvar = valuenames[0]
+##             try:
+##                 rmn = self.summarize_remove_n[currentvar]
+##             except KeyError:
+##                 rmn = -1
+##                 self.summarize_remove_n[currentvar] = rmn
+                
+            self.statslock.acquire()
+            stattab = self.stats.getCondTable(currentvar, condvar,
+                                              self.sumvar, self.divvar,
+                                              self.marginalize, self.minprob, self.combinvarsmode)
+            self.statslock.release()
+
+            if not self.statsview:
+                self.statsview = StatsTableView(stattab, self.stdscr)
+            else:
+                self.statsview.setTable(stattab)
+            l = self.table.length()
+            progress = str(ns)+'/'+str(l)+'  [ '+str((ns*1000/l)*0.1)+'% ]'
+            self.statsview.set_toprightinfo(progress)
+            self.statsview.redraw()
+            k = self.statsview.event_loop()
+
+            if k==ord(' '):
+                self.startThread()
+            if k==ord('1'):
+                if not self.sumvar:
+                    self.sumvar = valuenames[0]
+                else:
+                    idx = valuenames.index(self.sumvar)+1
+                    if idx&gt;=len(valuenames):
+                        idx = 0
+                    self.sumvar = valuenames[idx]
+            elif k==ord('2'):
+                if not self.divvar:
+                    self.divvar = valuenames[0]
+                else:
+                    idx = valuenames.index(self.divvar)+1
+                    if idx&gt;=len(valuenames):
+                        self.divvar = ''
+                    else:
+                        self.divvar = valuenames[idx]
+            elif k==ord('3'):
+                self.marginalize = (self.marginalize+1)%4
+            elif k==ord('4'):
+                self.combinvarsmode = (self.combinvarsmode+1)%2
+            elif k==ord('-'):
+                # self.summarize_remove_n[currentvar] += 1
+                if self.minprob&lt;=0.:
+                    self.minprob = 0.001
+                else:
+                    self.minprob *= 1.1
+            elif k==ord('='):
+                # rmn = self.summarize_remove_n[currentvar]                
+                # self.summarize_remove_n[currentvar] = max(rmn-1,0)
+                self.minprob /= 1.1               
+                if self.minprob&lt;0.001:
+                    self.minprob = 0.
+            elif k==ord('p'):
+                self.previous_field()
+            elif k==ord('n'):
+                self.next_field()
+            elif k==ord('s'):
+                self.chooseStats()
+            elif k==ord('q') or k==ord('\t'):
+                break
+        self.redraw()
+        
+
+class StatsTableView(TableView):
+
+    #def __init__(self, table, stdscr):
+    #    TableView.__init__(self, table, stdscr)
+
+    def handle_key_press(self, k):
+        if k in map(ord,&quot;\tpns 1234-=&quot;):
+            return k
+        elif k in map(ord,&quot;~+*&quot;):
+            pass # ignore this key
+        else:
+            return TableView.handle_key_press(self, k)
+
+    
+def curses_viewtable(stdscr, table):
+    view = TableView(table, stdscr)
+    view.redraw()
+    view.event_loop()
+
+def curses_showtable(stdscr, table):
+    view = TableView(table, stdscr)
+    view.redraw()
+
+def viewtable(table):
+    # table = CacheTable(table,100)
+    curses.wrapper(curses_viewtable,table)
+
+    
+
+if __name__ == &quot;__main__&quot;:
+    viewtable(openTable(sys.argv[1]))
+    


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003666.html">[Plearn-commits] r10226 - trunk/scripts/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="003668.html">[Plearn-commits] r10228 - in trunk/scripts: . DEPRECATED
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3667">[ date ]</a>
              <a href="thread.html#3667">[ thread ]</a>
              <a href="subject.html#3667">[ subject ]</a>
              <a href="author.html#3667">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
