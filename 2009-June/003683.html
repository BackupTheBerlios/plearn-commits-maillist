<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r10243 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2009-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10243%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200906042252.n54Mq1mR011227%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003682.html">
   <LINK REL="Next"  HREF="003684.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r10243 - trunk/plearn_learners_experimental</H1>
    <B>laulysta at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10243%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200906042252.n54Mq1mR011227%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r10243 - trunk/plearn_learners_experimental">laulysta at mail.berlios.de
       </A><BR>
    <I>Fri Jun  5 00:52:01 CEST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="003682.html">[Plearn-commits] r10242 - trunk/scripts/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="003684.html">[Plearn-commits] r10244 - in trunk/scripts: . EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3683">[ date ]</a>
              <a href="thread.html#3683">[ thread ]</a>
              <a href="subject.html#3683">[ subject ]</a>
              <a href="author.html#3683">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: laulysta
Date: 2009-06-05 00:51:55 +0200 (Fri, 05 Jun 2009)
New Revision: 10243

Modified:
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
Log:


Modified: trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2009-06-04 16:36:43 UTC (rev 10242)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2009-06-04 22:51:55 UTC (rev 10243)
@@ -758,7 +758,7 @@
                       //  inject_zero_forcing_noise(encoded_seq, input_noise_prob);
 
                 // recurrent no noise phase
-                if(stage&gt;=nb_stage_reconstruction){
+                if(stage &gt;= nb_stage_reconstruction){
                     if(recurrent_lr!=0)
                     {
                         
@@ -769,24 +769,27 @@
                     }
                 }
 
-                if(stage&lt;nb_stage_reconstruction || nb_stage_reconstruction == 0 ){
+                if(stage &lt; nb_stage_reconstruction || nb_stage_reconstruction == 0 ){
+                
 
                     // greedy phase hidden
                     if(hidden_reconstruction_lr!=0){
+                        
                         setLearningRate( hidden_reconstruction_lr);
+                        
                         recurrentFprop(train_costs, train_n_items, true);
                         //recurrentUpdate(0, hidden_reconstruction_cost_weight, 1, 0,1, train_costs, train_n_items );
                         recurrentUpdate(0, hidden_reconstruction_cost_weight, 1, 0,1, train_costs, train_n_items );
                     }
-
+                
                     /*if(recurrent_lr!=0)
-                    {                 
-                        setLearningRate( recurrent_lr );                    
-                        recurrentFprop(train_costs, train_n_items);
-                        //recurrentUpdate(0,0,1, prediction_cost_weight,0, train_costs, train_n_items );
-                        recurrentUpdate(0,0,0, prediction_cost_weight,0, train_costs, train_n_items );
-                        
-                        }*/
+                      {                 
+                      setLearningRate( recurrent_lr );                    
+                      recurrentFprop(train_costs, train_n_items);
+                      //recurrentUpdate(0,0,1, prediction_cost_weight,0, train_costs, train_n_items );
+                      recurrentUpdate(0,0,0, prediction_cost_weight,0, train_costs, train_n_items );
+                      
+                      }*/
                     
                     // greedy phase input
                     if(input_reconstruction_lr!=0){
@@ -839,6 +842,12 @@
             //double totalCosts = 0;
             for(int i=0; i&lt;train_costs.length(); i++)
             {
+                
+                if (train_costs[i] &lt;= 0 || train_n_items[i] &lt;= 0 ){
+                    train_costs[i] = 1;
+                    train_n_items[i] = 1; 
+                }
+                
                 if (i &lt; target_layers_weights.length()){
                     if( !fast_exact_is_equal(target_layers_weights[i],0) ){
                         train_costs[i] /= train_n_items[i];
@@ -882,11 +891,50 @@
         splitRawMaskedSupervisedSequence(seq, doNoise);
     else if(encoding==&quot;generic&quot;)
         encode_artificialData(seq);
-    else
+    else if(encoding==&quot;note_octav_duration&quot;)
         encodeAndCreateSupervisedSequence(seq);
+    else if(encoding==&quot;diffNote_duration&quot;)
+        encodeAndCreateSupervisedSequence2(seq);
 }
 
 // encodes sequ, then populates: input_list, targets_list, masks_list
+void DenoisingRecurrentNet::encodeAndCreateSupervisedSequence2(Mat seq) const
+{
+     if(use_target_layers_masks)
+        PLERROR(&quot;Bug: use_target_layers_masks is expected to be false (no masks) when in encodeAndCreateSupervisedSequence&quot;);
+
+    encodeSequence(seq, encoded_seq);
+    // now work with encoded_seq
+    Vec tempoTar;
+    int l = encoded_seq.length();
+    resize_lists(l-input_window_size);
+
+
+    int ntargets = target_layers.length();
+    targets_list.resize(ntargets);
+   
+    for(int tar=0; tar&lt;ntargets; tar++)
+    {
+        int targsize = target_layers[tar]-&gt;size;
+    
+        targets_list[tar].resize(l-input_window_size, targsize);   
+    }  
+    int startTar;
+    for(int t=input_window_size; t&lt;l; t++)
+    {
+
+        input_list[t-input_window_size] = encoded_seq.subMatRows(t-input_window_size,input_window_size).toVec();
+        startTar = 43;
+        for(int tar=0; tar&lt;ntargets; tar++)
+        {
+            int targsize = target_layers[tar]-&gt;size;
+            targets_list[tar](t-input_window_size) &lt;&lt; encoded_seq(t).subVec(startTar,targsize);
+            startTar += targsize;
+        }
+    }
+}
+
+// encodes sequ, then populates: input_list, targets_list, masks_list
 void DenoisingRecurrentNet::encodeAndCreateSupervisedSequence(Mat seq) const
 {
     if(use_target_layers_masks)
@@ -1421,7 +1469,106 @@
     productAcc(hidden_gradient, reconstruction_weights, input_reconstruction_activation_grad);
 }
 
+double DenoisingRecurrentNet::fpropHiddenReconstructionFromLastHidden2(Vec theInput, 
+                                                                      Vec hidden, 
+                                                                      Mat reconstruction_weights, 
+                                                                      Mat&amp; acc_weights_gr, 
+                                                                      Vec&amp; reconstruction_bias, 
+                                                                      Vec&amp; reconstruction_bias2, 
+                                                                      Vec hidden_reconstruction_activation_grad, 
+                                                                      Vec&amp; reconstruction_prob, 
+                                                                      Vec hidden_target, 
+                                                                      Vec hidden_gradient, 
+                                                                      double hidden_reconstruction_cost_weight, 
+                                                                      double lr)
+{
+    // set appropriate sizes
+    int fullhiddenlength = hidden_target.length();
+    Vec reconstruction_activation;
+    Vec reconstruction_activation2;
+    Vec reconstruction_prob2;
+    Vec hidden_act_no_bias;
+    Vec hidden_exp;
+    Vec dynamic_act_no_bias_contribution;
+    if(reconstruction_bias.length()==0)
+    {
+        reconstruction_bias.resize(fullhiddenlength);
+        reconstruction_bias.clear();
+    }
+    if(reconstruction_bias2.length()==0)
+    {
+        reconstruction_bias2.resize(fullhiddenlength);
+        reconstruction_bias2.clear();
+    }
+    reconstruction_prob2.resize(fullhiddenlength);
+    reconstruction_activation.resize(fullhiddenlength);
+    reconstruction_activation2.resize(fullhiddenlength);
+    reconstruction_prob.resize(fullhiddenlength);
 
+   
+    hidden_act_no_bias.resize(fullhiddenlength);
+    hidden_exp.resize(fullhiddenlength);
+    dynamic_act_no_bias_contribution.resize(fullhiddenlength);
+
+    
+
+    // predict (denoised) input_reconstruction 
+    transposeProduct(reconstruction_activation, reconstruction_weights, hidden); //dynamic matrice tied
+    //product(reconstruction_activation, reconstruction_weights, hidden); //dynamic matrice not tied
+    reconstruction_activation += reconstruction_bias;
+
+    for( int j=0 ; j&lt;fullhiddenlength ; j++ )
+        reconstruction_prob[j] = fastsigmoid( reconstruction_activation[j] );
+
+
+
+     // predict (denoised) input_reconstruction 
+    transposeProduct(reconstruction_activation2, reconstruction_weights, reconstruction_prob); //dynamic matrice tied
+    reconstruction_activation2 += reconstruction_bias2;
+
+    for( int j=0 ; j&lt;fullhiddenlength ; j++ )
+        reconstruction_prob2[j] = fastsigmoid( reconstruction_activation2[j] );
+
+
+    //hidden_layer-&gt;fprop(reconstruction_activation, reconstruction_prob);
+
+    /********************************************************************************/
+    hidden_reconstruction_activation_grad.resize(reconstruction_prob.size());
+    hidden_reconstruction_activation_grad &lt;&lt; reconstruction_prob;
+    hidden_reconstruction_activation_grad -= hidden_target;
+    hidden_reconstruction_activation_grad *= hidden_reconstruction_cost_weight;
+    
+
+    productAcc(hidden_gradient, reconstruction_weights, hidden_reconstruction_activation_grad); //dynamic matrice tied
+    //transposeProductAcc(hidden_gradient, reconstruction_weights, hidden_reconstruction_activation_grad); //dynamic matrice not tied
+    
+    //update bias
+    multiplyAcc(reconstruction_bias, hidden_reconstruction_activation_grad, -lr);
+    // update weight
+    externalProductScaleAcc(acc_weights_gr, hidden, hidden_reconstruction_activation_grad, -lr); //dynamic matrice tied
+    //externalProductScaleAcc(acc_weights_gr, hidden_reconstruction_activation_grad, hidden, -lr); //dynamic matrice not tied
+                
+    //update bias2
+    //multiplyAcc(reconstruction_bias2, hidden_gradient, -lr);
+    /********************************************************************************/
+    // Vec hidden_reconstruction_activation_grad;
+    /*hidden_reconstruction_activation_grad.clear();
+    for(int k=0; k&lt;reconstruction_prob.length(); k++){
+        //    hidden_reconstruction_activation_grad[k] = safelog(1-reconstruction_prob[k]) - safelog(reconstruction_prob[k]);
+        hidden_reconstruction_activation_grad[k] = - reconstruction_activation[k];
+        }*/
+
+    double result_cost = 0;
+    double neg_log_cost = 0; // neg log softmax
+    for(int k=0; k&lt;reconstruction_prob.length(); k++){
+        //if(hidden_target[k]!=0)
+        neg_log_cost -= hidden_target[k]*safelog(reconstruction_prob[k]) + (1-hidden_target[k])*safelog(1-reconstruction_prob[k]);
+    }
+    result_cost = neg_log_cost;
+    
+    return result_cost;
+}
+
 double DenoisingRecurrentNet::fpropHiddenReconstructionFromLastHidden(Vec theInput, 
                                                                       Vec hidden, 
                                                                       Mat reconstruction_weights, 
@@ -1935,17 +2082,52 @@
             }
         }
     }
+    
+    
     //update matrice's connections
     for( int tar=0; tar&lt;target_layers.length(); tar++)
     {
         multiplyAcc(targetWeights[tar], acc_target_connections_gr[tar], 1);
     }
     multiplyAcc(inputWeights, acc_input_connections_gr, 1);
+    
     if(dynamic_connections )
     {
         multiplyAcc(dynamicWeights, acc_dynamic_connections_gr, 1);
         //multiplyAcc(reconsWeights, acc_reconstruction_dynamic_connections_gr, 1);
     }
+    
+    
+
+
+     /* int r;
+    int modulo;
+    if(input_reconstruction_weight!=0)
+        modulo = 2;
+    else
+        modulo=3;
+    
+    r = rand() % modulo +1;
+   
+   
+    if(r==1)
+    {
+        multiplyAcc(inputWeights, acc_input_connections_gr, 1);
+    }
+    else if (r==2){
+        if(dynamic_connections )
+        {
+            multiplyAcc(dynamicWeights, acc_dynamic_connections_gr, 1);
+            //multiplyAcc(reconsWeights, acc_reconstruction_dynamic_connections_gr, 1);
+        }
+    }
+    else {
+        //update matrice's connections
+        for( int tar=0; tar&lt;target_layers.length(); tar++)
+        {
+            multiplyAcc(targetWeights[tar], acc_target_connections_gr[tar], 1);
+        }
+        }*/
 }
 
 
@@ -2035,6 +2217,8 @@
         encode_onehot_note_octav_duration(sequence, encoded_seq, prepend_zero_rows, false, 0);
     else if(encoding==&quot;note_octav_duration&quot;)
         encode_onehot_note_octav_duration(sequence, encoded_seq, prepend_zero_rows, false, 4);    
+    else if(encoding==&quot;diffNote_duration&quot;)
+        encode_onehot_diffNote_duration(sequence, encoded_seq, false);
     else if(encoding==&quot;raw_masked_supervised&quot;)
         PLERROR(&quot;raw_masked_supervised means already encoded! You shouldnt have landed here!!!&quot;);
     else if(encoding==&quot;generic&quot;)
@@ -2101,6 +2285,39 @@
   bit at position note_nbits+octav_nbits+duration is on
  */
 
+void DenoisingRecurrentNet::encode_onehot_diffNote_duration(Mat sequence, Mat&amp; encoded_sequence,
+                                                              bool use_silence,  int duration_nbits)
+{
+    int l = sequence.length();
+    //diff paussible -21 ... -1 0 1 ... 21
+    // index          0     20 21 22    43
+    int note_nbits = 43; //de -21 a 21
+
+    encoded_sequence.resize(l,note_nbits+duration_nbits);
+    encoded_sequence.clear();
+    
+    
+    for(int i=0; i&lt;l; i++)
+    {
+        //int midi_number = int(sequence(i,0));
+
+        if(i==0) // silence
+        {
+            encoded_sequence(i,21) = 1;
+        }
+        else{
+            int diffNote = int(sequence(i,0))-int(sequence(i-1,0))+21;
+            encoded_sequence(i,diffNote) = 1;
+        }
+
+       
+        int duration_bit = getDurationBit(int(sequence(i,1)));
+        if(duration_bit&lt;0 || duration_bit&gt;=duration_nbits)
+            PLERROR(&quot;duration_bit out of valid range&quot;);
+        encoded_sequence(i,note_nbits+duration_bit) = 1;
+    }
+}
+
 void DenoisingRecurrentNet::encode_onehot_note_octav_duration(Mat sequence, Mat&amp; encoded_sequence, int prepend_zero_rows,
                                                               bool use_silence, int octav_nbits, int duration_nbits)
 {

Modified: trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2009-06-04 16:36:43 UTC (rev 10242)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2009-06-04 22:51:55 UTC (rev 10243)
@@ -186,6 +186,9 @@
     //! (declared const because it needs to be called in test)
     void encodeSequence(Mat sequence, Mat&amp; encoded_seq) const;
 
+    static void encode_onehot_diffNote_duration(Mat sequence, Mat&amp; encoded_sequence,
+                                                  bool use_silence, int duration_nbits=20);
+
     static void encode_onehot_note_octav_duration(Mat sequence, Mat&amp; encoded_sequence, int prepend_zero_rows,
                                                   bool use_silence, int octav_nbits, int duration_nbits=20);
     
@@ -438,6 +441,8 @@
     //! encodes seq, then populates: inputslist, targets_list, masks_list
     void encodeAndCreateSupervisedSequence(Mat seq) const;
 
+    void encodeAndCreateSupervisedSequence2(Mat seq) const;
+
     //! For the (backward testing) raw_masked_supervised case. Populates: input_list, targets_list, masks_list
     void splitRawMaskedSupervisedSequence(Mat seq, bool doNoise) const;
 
@@ -501,6 +506,9 @@
     void updateInputReconstructionFromHidden(Vec hidden, Mat&amp; reconstruction_weights, Mat&amp; acc_weights_gr, Vec&amp; input_reconstruction_bias, Vec input_reconstruction_prob, 
                                              Vec clean_input, Vec hidden_gradient, double input_reconstruction_cost_weight, double lr);
 
+    double fpropHiddenReconstructionFromLastHidden2(Vec theInput, Vec hidden, Mat reconstruction_weights, Mat&amp; acc_weights_gr, Vec&amp; reconstruction_bias, Vec&amp; reconstruction_bias2, Vec hidden_reconstruction_activation_grad, Vec&amp; reconstruction_prob, 
+                                                                          Vec clean_input, Vec hidden_gradient, double hidden_reconstruction_cost_weight, double lr);
+
     double fpropHiddenReconstructionFromLastHidden(Vec theInput, Vec hidden, Mat reconstruction_weights, Mat&amp; acc_weights_gr, Vec&amp; reconstruction_bias, Vec&amp; reconstruction_bias2, Vec hidden_reconstruction_activation_grad, Vec&amp; reconstruction_prob, 
                                                                           Vec clean_input, Vec hidden_gradient, double hidden_reconstruction_cost_weight, double lr);
     


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003682.html">[Plearn-commits] r10242 - trunk/scripts/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="003684.html">[Plearn-commits] r10244 - in trunk/scripts: . EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3683">[ date ]</a>
              <a href="thread.html#3683">[ thread ]</a>
              <a href="subject.html#3683">[ subject ]</a>
              <a href="author.html#3683">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
