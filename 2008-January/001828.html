<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8380 - trunk/python_modules/plearn/learners
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-January/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8380%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200801111953.m0BJrCA3019549%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001827.html">
   <LINK REL="Next"  HREF="001829.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8380 - trunk/python_modules/plearn/learners</H1>
    <B>louradou at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8380%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200801111953.m0BJrCA3019549%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8380 - trunk/python_modules/plearn/learners">louradou at mail.berlios.de
       </A><BR>
    <I>Fri Jan 11 20:53:12 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="001827.html">[Plearn-commits] r8379 - trunk/plearn_learners_experimental
</A></li>
        <LI>Next message: <A HREF="001829.html">[Plearn-commits] r8381 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1828">[ date ]</a>
              <a href="thread.html#1828">[ thread ]</a>
              <a href="subject.html#1828">[ subject ]</a>
              <a href="author.html#1828">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: louradou
Date: 2008-01-11 20:53:12 +0100 (Fri, 11 Jan 2008)
New Revision: 8380

Modified:
   trunk/python_modules/plearn/learners/SVM.py
Log:


Modified: trunk/python_modules/plearn/learners/SVM.py
===================================================================
--- trunk/python_modules/plearn/learners/SVM.py	2008-01-10 22:56:44 UTC (rev 8379)
+++ trunk/python_modules/plearn/learners/SVM.py	2008-01-11 19:53:12 UTC (rev 8380)
@@ -239,6 +239,14 @@
 
       def test(self, samples_target_list):
           check_samples_target_list([samples_target_list])
+          if self.save_filename != None:
+                        try:
+                           FID=open(self.save_filename,'a')
+                           #FID.write('------------\nTry with '+kernel_type+' kernel :( parameters : '+str(parameters)+' )\n')
+                           FID.write('\n'+'='*10+'\n ==&gt; Test Error rate = '+str(test_error_rate)+'\n'+'='*10+'\n')
+                           FID.close()
+                        except:
+                           print &quot;COULD not write in save_filename&quot;
           return test_model(self.best_model, [[x_i for x_i in x] for x in samples_target_list[0]], [float(l) for l in samples_target_list[1]])['error_rate']
 
 
@@ -246,10 +254,18 @@
           check_samples_target_list(samples_target_list)
           if len(samples_target_list) == 1:
              print &quot;\nCross-validation...\n&quot;
+             train_error_name=str(self.nr_fold)+&quot;-fold Cross-Valid Error Rate&quot;
+             test_error_name=train_error_name
           elif len(samples_target_list) == 2:
              print &quot;\nSimple validation...\n&quot;
+             train_error_name=&quot;Valid Error Rate&quot;
+             test_error_name=train_error_name
           elif len(samples_target_list) == 3:
              print &quot;\nValidation + test...\n&quot;
+             train_error_name=&quot;Valid Error Rate&quot;
+             test_error_name=&quot;Test Error Rate&quot;
+          else:
+             raise TypeError, &quot;last argument of train_and_tune() should be a list, with length between 1 and 3&quot;
            
           expert = eval( 'self.'+kernel_type+'_expert' )
           
@@ -280,22 +296,25 @@
                      model = svm_model(train_problem, param)
                      error_rate = test_model(model, samples_target_list[1][0], samples_target_list[1][1])['error_rate']
                      
-                     if self.save_filename != None:
-                        try:
-                           FID=open(self.save_filename,'a')
-                           FID.write('------------\nTry with '+kernel_type+' kernel :( parameters : '+str(parameters)+' )\n')
-                           FID.write(' --&gt; Error rate = '+str(error_rate)+'\n')
-                           FID.close()
-                        except:
-                           print &quot;COULD not write in save_filename&quot;
-
-                  self.add_result_to_result_list(kernel_type, parameters, error_rate)
+                  self.add_result_to_result_list(kernel_type, parameters, self.error_rate)
                   if error_rate &lt; best_error_rate:
                      best_parameters = parameters
                      best_error_rate = error_rate
 		     if len(samples_target_list) &lt;&gt; 1: # in case of cross-validation, we will compute the model later
                         best_model   = model
 
+                  if self.save_filename != None:
+                     try:
+                        FID=open(self.save_filename,'a')
+                        FID.write('------------\nTry with '+kernel_type+' kernel :( parameters : '+str(parameters)+' )\n')
+                        FID.write(' --&gt; Error rate = '+str(error_rate)+'\n')
+                        FID.close()
+                     except:
+                        print &quot;COULD not write in save_filename&quot;
+                  print '------------\nTry with '+kernel_type+' kernel :( parameters : '+str(parameters)
+                  print ' --&gt; '+train_error_name+' = '+str(error_rate)+'\n'
+                  print '...'
+
           if best_error_rate &lt; expert.error_rate:
              expert.best_parameters = best_parameters
              expert.error_rate = best_error_rate
@@ -317,6 +336,23 @@
 	     if expert.should_be_tuned_again():
 	        self.train_and_tune(kernel_type, samples_target_list)
 	  
+          if self.save_filename != None:
+             try:
+                  FID=open(self.save_filename,'a')
+                  FID.write('==============================================\n')
+                  if len(samples_target_list) == 3: # train-valid-test
+                     FID.write(' --&gt; Best '+train_error_name+' = '+str(self.valid_error_rate)+'\n')
+                  FID.write(' --&gt; '+test_error_name+' = '+str(self.error_rate)+'\n')
+                  FID.write('     for prms: '+str(self.best_parameters)+'\n')
+                  FID.close()
+             except:
+                  print &quot;COULD not write in save_filename&quot;
+
+          print '=============================================='
+          print ' --&gt; Best error rate = '+str(self.error_rate)
+          print '     for prms: '+str(self.best_parameters)
+
+
 	  return self.error_rate
           
 
@@ -386,6 +422,7 @@
     diffs = {}
     for i in range(N):
           diff = abs(model.predict([float(x_i) for x_i in samples[i]]) - float(targets[i]))
+          #print &quot;prediction: &quot;,model.predict([float(x_i) for x_i in samples[i]]),&quot;  -  real: &quot;,float(targets[i]),&quot;  ( &quot;,diff,&quot; )&quot;
           if diffs.has_key(diff):
                 diffs[diff] += 1
           else:
@@ -394,7 +431,7 @@
     linear_class_error = 0
     square_class_error = 0
     for diff, nbdiff in diffs.iteritems():
-          if not diff == 0:
+          if abs(diff) &gt; 0.001:
                 error_rate += 1*nbdiff
           linear_class_error += diff*nbdiff
           square_class_error += (diff*diff)*nbdiff
@@ -452,13 +489,13 @@
     stds=[get_std_cmp(data,i) for i in range(len(data[0]))]
     return sum(stds)/len(stds)
 def get_std_cmp(data,i):
-    values=[vec[i] for vec in data]
+    values=[float(vec[i]) for vec in data]
     tot = sum(values)
     avg = tot*1.0/len(values)
     sdsq = sum([(i-avg)**2 for i in values])
     return (sdsq*1.0/(len(values)-1 or 1))**.5
 def get_mean_cmp(data,i):
-    values=[vec[i] for vec in data]
+    values=[float(vec[i]) for vec in data]
     return  sum(values)/len(values)
 
 def arithm_mean(data):
@@ -569,7 +606,7 @@
     my_svm.train_and_tune( 'POLY' ,    DATA )
     #[..]
 
-    valid_error_rate =  my_svm.error_rate
+    valid_error_rate =  my_svm.valid_error_rate
     print valid_error_rate
     print my_svm.best_parameters
     print my_svm.tried_parameters
@@ -598,7 +635,7 @@
     # (retrain the model on new train data, but no search for better parameters)
     my_svm.train_and_test( NEW_DATA )
     
-    valid_error_rate = my_svm.error_rate
+    valid_error_rate = my_svm.valid_error_rate
 
 #&lt;&lt;&lt;#
 #&gt;&gt;&gt;# To try the best trained model with new data (and obtain &quot;fair&quot; error rates)
@@ -608,3 +645,14 @@
     test_error_rate = my_svm.test( TEST_DATA )
     
     print test_error_rate
+
+#&lt;&lt;&lt;#
+#&gt;&gt;&gt;# Doing all this amounts to the same as the following
+
+    ALL_DATA = [ [train_samples , train_targets], [valid_samples , valid_targets], [test_samples , test_targets]  ]
+    my_svm.train_and_tune( 'RBF' , ALL_DATA )
+    # [...]
+    
+    valid_error_rate = my_svm.valid_error_rate
+    test_error_rate  = my_svm.error_rate
+    


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001827.html">[Plearn-commits] r8379 - trunk/plearn_learners_experimental
</A></li>
	<LI>Next message: <A HREF="001829.html">[Plearn-commits] r8381 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1828">[ date ]</a>
              <a href="thread.html#1828">[ thread ]</a>
              <a href="subject.html#1828">[ subject ]</a>
              <a href="author.html#1828">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
