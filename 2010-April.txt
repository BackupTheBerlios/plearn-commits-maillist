From lamblin at mail.berlios.de  Wed Apr 14 01:05:11 2010
From: lamblin at mail.berlios.de (lamblin at BerliOS)
Date: Wed, 14 Apr 2010 01:05:11 +0200
Subject: [Plearn-commits] r10330 - trunk/python_modules/plearn/parallel
Message-ID: <201004132305.o3DN5Bwm015966@sheep.berlios.de>

Author: lamblin
Date: 2010-04-14 01:05:08 +0200 (Wed, 14 Apr 2010)
New Revision: 10330

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
Trap SIGUSR1 and SIGUSR2 in the generated files of SGE backend,
so that the "main" job can see them without being killed first.


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2010-03-24 22:42:20 UTC (rev 10329)
+++ trunk/python_modules/plearn/parallel/dbi.py	2010-04-13 23:05:08 UTC (rev 10330)
@@ -844,11 +844,16 @@
                 # but SGE_TASK_ID starts at 1...
                 ID=$(($SGE_TASK_ID - 1))
 
+                ## Trap SIGUSR1 and SIGUSR2, so the job has time to react
+                # These signals are emitted by SGE before (respectively)
+                # SIGSTOP and SIGKILL (typically 60 s before on colosse)
+                trap "echo signal trapped by $0 >&2" SIGUSR1 SIGUSR2
+
                 # Execute the task
                 ${tasks[$ID]}
                 '''))
 
-        submit_sh_template = '''
+        submit_sh_template = '''\
                 #!/bin/bash
 
                 ## Reasonable default values
@@ -870,6 +875,11 @@
                 #$ -o %(log_dir)s/$JOB_NAME.$JOB_ID.$TASK_ID.log.out
                 #$ -e %(log_dir)s/$JOB_NAME.$JOB_ID.$TASK_ID.log.err
 
+                ## Trap SIGUSR1 and SIGUSR2, so the job has time to react
+                # These signals are emitted by SGE before (respectively)
+                # SIGSTOP and SIGKILL (typically 60 s before on colosse)
+                trap "echo signal trapped by $0 >&2" SIGUSR1 SIGUSR2
+
                 ## Execute as many jobs as needed
                 #$ -t 1-%(n_tasks)i:1
                 '''



From ducharme at mail.berlios.de  Mon Apr 19 16:01:00 2010
From: ducharme at mail.berlios.de (ducharme at BerliOS)
Date: Mon, 19 Apr 2010 16:01:00 +0200
Subject: [Plearn-commits] r10331 - trunk/python_modules/plearn/utilities
Message-ID: <201004191401.o3JE10wf001770@sheep.berlios.de>

Author: ducharme
Date: 2010-04-19 16:01:00 +0200 (Mon, 19 Apr 2010)
New Revision: 10331

Modified:
   trunk/python_modules/plearn/utilities/pldatetime.py
Log:
Add new function "date_to_yyyymmdd".


Modified: trunk/python_modules/plearn/utilities/pldatetime.py
===================================================================
--- trunk/python_modules/plearn/utilities/pldatetime.py	2010-04-13 23:05:08 UTC (rev 10330)
+++ trunk/python_modules/plearn/utilities/pldatetime.py	2010-04-19 14:01:00 UTC (rev 10331)
@@ -28,6 +28,9 @@
 def date_to_cyymmdd(d):
     return (d.year-1900)*10000 + d.month*100 +d.day
 
+def date_to_yyyymmdd(d):
+    return d.year*10000 + d.month*100 +d.day
+
 def cyymmdd_to_ordinal(x):
     if isNaN(x):
       return x



From nouiz at mail.berlios.de  Tue Apr 27 16:06:54 2010
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Apr 2010 16:06:54 +0200
Subject: [Plearn-commits] r10332 - trunk/scripts
Message-ID: <201004271406.o3RE6siL016275@sheep.berlios.de>

Author: nouiz
Date: 2010-04-27 16:06:54 +0200 (Tue, 27 Apr 2010)
New Revision: 10332

Modified:
   trunk/scripts/dbidispatch
Log:
backport to python2.4


Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2010-04-19 14:01:00 UTC (rev 10331)
+++ trunk/scripts/dbidispatch	2010-04-27 14:06:54 UTC (rev 10332)
@@ -3,6 +3,12 @@
 from plearn.utilities.toolkit import search_file
 from socket import gethostname
 from subprocess import Popen,PIPE
+if sys.version_info[:2] < (2,5):
+    def any(iterable):
+        for element in iterable:
+            if element:
+                return True
+        return False
 
 ScriptName="launchdbi.py"
 ShortHelp='''Usage: dbidispatch <common options> <back-end parameters> {--file=FILEPATH | <command-template>|--[*no_]restart condor_jobs_number... }



From nouiz at mail.berlios.de  Tue Apr 27 17:47:22 2010
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Apr 2010 17:47:22 +0200
Subject: [Plearn-commits] r10333 - trunk/scripts
Message-ID: <201004271547.o3RFlM60025578@sheep.berlios.de>

Author: nouiz
Date: 2010-04-27 17:47:22 +0200 (Tue, 27 Apr 2010)
New Revision: 10333

Modified:
   trunk/scripts/dbidispatch
Log:
added condor option to dbidispatch --gpu,--gpu_enabled, --whitespace


Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2010-04-27 14:06:54 UTC (rev 10332)
+++ trunk/scripts/dbidispatch	2010-04-27 15:47:22 UTC (rev 10333)
@@ -55,7 +55,7 @@
                               [--[*no_]keep_failed_jobs_in_queue]
                               [--max_file_size=N][--[no_]debug]
                               [--[no_]local_log_file][--next_job_start_delay=N]
-                              [--fast]
+                              [--fast] [--[no_]gpu] [--[no_]gpu_enabled]
     sge options              :[--project=STRING]
         (Note: SGE support is experimental)
 
@@ -125,6 +125,7 @@
       - processid: (condor only)put the process id of the jobs. Idem as nb0
       - none    : remove all preceding pattern
   The '*--[no_]exec_in_exp_dir' option remove the executable from the log dir.
+  The '--[no_*]whitespace' option allow to put white space inside {{}}. I put this as an option as I don't remember the reason why their was this restriction.
 
 bqtools, cluster, condor and sge option:
   The '--cpu=nb_cpu_per_node' option determine the number of cpu(cores) that 
@@ -245,6 +246,9 @@
   The '--fast' option tell condor to send the jobs only on fast computer. This 
       add some hardcoded(maggie, brams and zappa) computers to the list 
       generated by --machine=...
+  The '--gpu' option tell to launch only on host with gpu card.
+  The '--gpu_enabled' option tell that we can take adventage of gpu card.
+      We try to launch on gpu host first.
 
 sge only option:
   The '--project' specifies the project to which this  job  is  assigned.
@@ -296,7 +300,9 @@
 fast_computer+=["zappa"+str(x) for x in range(1,9)]
 MAX_FILE_NAME_SIZE=255
 
-dbi_param={}
+dbi_param={"req":"True", "files":"", "rank":"True", "raw":"", "env":"",
+           "machine":[], "machines":[], "no_machine":[], "tasks_filename":[]}
+dbi_param_orig = dbi_param.copy()
 testmode=False
 PATH=os.getenv('PATH')
 if search_file('condor_submit',PATH):
@@ -346,14 +352,18 @@
                    "--getenv", "--cwait", "--clean_up" ,"--nice",
                    "--set_special_env", "--abs_path", "--pkdilly", "--to_all",
                    "--m32G", "--keep_failed_jobs_in_queue", "--restart",
-                   "--debug", "--local_log_file", "--exec_in_exp_dir", "--fast"]:
+                   "--debug", "--local_log_file", "--exec_in_exp_dir", "--fast", "--whitespace",
+                   "--gpu", "--gpu_enabled",
+                   ]:
         dbi_param[argv[2:]]=True
     elif argv in ["--no_force", "--no_interruptible", "--no_long",
                   "--no_getenv", "--no_cwait", "--no_clean_up" , "--no_nice",
                   "--no_set_special_env", "--no_abs_path", "--no_pkdilly",
                   "--no_m32G", "--no_keep_failed_jobs_in_queue", "--no_restart",
                   "--no_debug", "--no_local_log_file", "--no_exec_in_exp_dir",
-                  "--no_fast"]:
+                  "--no_fast", "--no_whitespace",
+                  "--no_gpu", "--no_gpu_enabled",
+                  ]:
         dbi_param[argv[5:]]=False
     elif argv=="--testdbi":
         dbi_param["test"]=True
@@ -378,16 +388,12 @@
         val = sp[1]
         if param in ["req", "files", "rank"]:
             #param that we happend to if defined more then one time
-            dbi_param.setdefault(param,'True')
             dbi_param[param]+='&&('+val+')'
         elif param == "raw":
-            dbi_param.setdefault(param,'')
             dbi_param[param]+='\n'+val
         elif param=="env":
-            dbi_param.setdefault(param,"")
             dbi_param[param]+='"'+val+'"'
         elif param in ["machine", "machines", "no_machine", "tasks_filename"]:
-            dbi_param.setdefault(param,[])
             dbi_param[param]+=val.split(",")
         else:
             #otherwise we erase the old value
@@ -398,7 +404,6 @@
             param='rank'
         else:
             param='req'
-        dbi_param.setdefault(param,'True')
         if argv.find('no_')==-1:
             dbi_param[param]+='&&(SERVER=?=True)'
         else:
@@ -411,7 +416,8 @@
         break
     command_argv.remove(argv)
 
-dbi_param.setdefault("tasks_filename", ["nb0","compact"])
+if len(dbi_param["tasks_filename"])==0:
+    dbi_param["tasks_filename"] = ["nb0","compact"]
 
 if len(command_argv) == 0 and not dbi_param.has_key("file"):
     print "No command or file with command to execute!"
@@ -428,7 +434,8 @@
     os.mkdir(LOGDIR)
 
 valid_dbi_param=["clean_up", "test", "dolog", "nb_proc", "exp_dir", "file",
-                 "tasks_filename", "exec_in_exp_dir", "repeat_jobs"
+                 "tasks_filename", "exec_in_exp_dir", "repeat_jobs",
+                 "whitespace",
                  ]
 if launch_cmd=="Cluster":
     valid_dbi_param +=["cwait","force","arch","interruptible",
@@ -439,7 +446,7 @@
                        "universe", "machine", "machines", "no_machine","to_all",
                        "keep_failed_jobs_in_queue", "restart",
                        "max_file_size", "debug", "local_log_file",
-                       "next_job_start_delay"
+                       "next_job_start_delay", "gpu", "gpu_enabled"
                        ]
 elif launch_cmd=="Bqtools":
     valid_dbi_param +=["cpu", "duree", "long", "mem", "micro",
@@ -448,6 +455,13 @@
 elif launch_cmd=="Sge":
     valid_dbi_param += ["duree", "jobs_name", "queue"]
 
+if dbi_param.get('gpu',False):
+    dbi_param['req']+="&&(Target.GPU=?=True)"
+    dbi_param['raw']+='\n+GPU=True'
+elif dbi_param.get('gpu_enabled',False):
+    dbi_param['rank']+="&&(Target.GPU=?=True)"
+    dbi_param['raw']+='\n+GPU=True'
+
 if  launch_cmd == 'Condor' and gethostname().endswith(".iro.umontreal.ca"):
     #default value for pkdilly is true.
     if dbi_param.get("pkdilly")==None:
@@ -472,7 +486,8 @@
 
 
 print "\n\nThe jobs will be launched on the system:", launch_cmd
-print "With options: ",dbi_param
+import pdb;pdb.set_trace()
+print "With options: ",[str(param)+":"+str(value) for param,value in dbi_param.items() if value!=dbi_param_orig.get(param,None)]
 for i in dbi_param:
     if i not in valid_dbi_param:
         print "WARNING: The parameter",i,"is not valid for the",launch_cmd,"back-end. It will be ignored."
@@ -498,7 +513,10 @@
 def generate_commands(sp):
 ### Find replacement lists in the arguments
     repl = []
-    p = re.compile('\{\{\S*?\}\}')
+    if dbi_param.get('whitespace',False):
+        p = re.compile('\{\{.*\}\}')
+    else:
+        p = re.compile('\{\{\S*?\}\}')
     for arg in sp:
         reg = p.findall(arg)
         if len(reg)==1:
@@ -604,7 +622,6 @@
     
 
 if dbi_param.get("fast",False):
-    dbi_param.setdefault("machine",[])
     for m in fast_computer:
         dbi_param["machine"]+=[m+".iro.umontreal.ca"]
     del dbi_param["fast"]



From nouiz at mail.berlios.de  Tue Apr 27 17:54:12 2010
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Apr 2010 17:54:12 +0200
Subject: [Plearn-commits] r10334 - trunk/scripts
Message-ID: <201004271554.o3RFsCfg025826@sheep.berlios.de>

Author: nouiz
Date: 2010-04-27 17:54:11 +0200 (Tue, 27 Apr 2010)
New Revision: 10334

Modified:
   trunk/scripts/dbidispatch
Log:
some clean up of how parameter are handled.


Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2010-04-27 15:47:22 UTC (rev 10333)
+++ trunk/scripts/dbidispatch	2010-04-27 15:54:11 UTC (rev 10334)
@@ -301,7 +301,9 @@
 MAX_FILE_NAME_SIZE=255
 
 dbi_param={"req":"True", "files":"", "rank":"True", "raw":"", "env":"",
-           "machine":[], "machines":[], "no_machine":[], "tasks_filename":[]}
+           "machine":[], "machines":[], "no_machine":[], "tasks_filename":[],
+           "restart":False,'whitespace':False,"fast":False,
+           "gpu":False,"gpu_enabled":False}
 dbi_param_orig = dbi_param.copy()
 testmode=False
 PATH=os.getenv('PATH')
@@ -424,7 +426,7 @@
     print
     print ShortHelp
     sys.exit(1)
-if dbi_param.has_key("file") and dbi_param.has_key("restart"):
+if dbi_param.has_key("file") and dbi_param["restart"]:
     print "the --file= and --restart option are incompatible!"
     print
     print ShortHelp
@@ -455,10 +457,10 @@
 elif launch_cmd=="Sge":
     valid_dbi_param += ["duree", "jobs_name", "queue"]
 
-if dbi_param.get('gpu',False):
+if dbi_param['gpu']:
     dbi_param['req']+="&&(Target.GPU=?=True)"
     dbi_param['raw']+='\n+GPU=True'
-elif dbi_param.get('gpu_enabled',False):
+elif dbi_param['gpu_enabled']:
     dbi_param['rank']+="&&(Target.GPU=?=True)"
     dbi_param['raw']+='\n+GPU=True'
 
@@ -471,7 +473,7 @@
     nokerb_path=["/home/fringant1/","/home/fringant2/","/cluster/", "/data/"]
     pkdilly=False
     dir_with_kerb=not any([p.startswith(x) for x in nokerb_path])
-    if not dir_with_kerb or dbi_param.get('files'):
+    if not dir_with_kerb or dbi_param['files']:
         pass
     elif dbi_param.get("pkdilly")==True:
         pkdilly = True
@@ -486,12 +488,11 @@
 
 
 print "\n\nThe jobs will be launched on the system:", launch_cmd
-import pdb;pdb.set_trace()
 print "With options: ",[str(param)+":"+str(value) for param,value in dbi_param.items() if value!=dbi_param_orig.get(param,None)]
 for i in dbi_param:
     if i not in valid_dbi_param:
         print "WARNING: The parameter",i,"is not valid for the",launch_cmd,"back-end. It will be ignored."
-if dbi_param.get("restart",False):
+if dbi_param["restart"]:
     print "With the command to be restarted:"," ".join(command_argv),"\n\n"
 else:
     print "With the command to be expanded:"," ".join(command_argv),"\n\n"
@@ -513,7 +514,7 @@
 def generate_commands(sp):
 ### Find replacement lists in the arguments
     repl = []
-    if dbi_param.get('whitespace',False):
+    if dbi_param['whitespace']:
         p = re.compile('\{\{.*\}\}')
     else:
         p = re.compile('\{\{\S*?\}\}')
@@ -547,7 +548,7 @@
 
 #generate the command
 if dbi_param.has_key("file"):
-    fd = open(dbi_param.get("file"),'r')
+    fd = open(dbi_param["file"],'r')
     commands=[]
     choise_args = []
     for line in fd.readlines():
@@ -559,7 +560,7 @@
         commands+=t1
         choise_args+=t2
     fd.close
-elif dbi_param.get("restart",False):
+elif dbi_param["restart"]:
     assert launch_cmd=="Condor"
     cmds=[]
     #We accept to start jobs in the queue only if they are completed
@@ -621,7 +622,7 @@
     dbi_param["next_job_start_delay"]=1
     
 
-if dbi_param.get("fast",False):
+if dbi_param["fast"]:
     for m in fast_computer:
         dbi_param["machine"]+=[m+".iro.umontreal.ca"]
     del dbi_param["fast"]
@@ -629,7 +630,7 @@
 #we duplicate the command so that everything else work correctly.
 if dbi_param.has_key("to_all"):
     assert(len(commands)==1)
-    assert(dbi_param.has_key("machine"))
+    assert(len(dbi_param["machine"]>0))
     commands=commands*len(dbi_param["machine"])
 
 if dbi_param.has_key("exp_dir"):
@@ -646,7 +647,7 @@
     ### We need to remove the symbols "," as this cause trouble with bqtools
     tmp=re.sub( ',', '-', tmp )
     date_str=str(datetime.datetime.now())
-    if dbi_param.has_key("restart"):
+    if dbi_param["restart"]:
         tmp="jobs_restarted_"+tmp
     
     if launch_cmd == "Bqtools":
@@ -677,7 +678,7 @@
         else:
             l.append(x)
     return l
-for pattern in dbi_param.get("tasks_filename"):
+for pattern in dbi_param["tasks_filename"]:
     if pattern == "explicit":
         dbi_param[n]=merge_pattern([re.sub( '[^a-zA-Z=0-9-]', '_', x ) for x in commands])
     elif pattern == "compact":



From tihocan at mail.berlios.de  Wed Apr 28 03:00:47 2010
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Wed, 28 Apr 2010 03:00:47 +0200
Subject: [Plearn-commits] r10335 - trunk/python_modules/plearn/parallel
Message-ID: <201004280100.o3S10lSa016238@sheep.berlios.de>

Author: tihocan
Date: 2010-04-28 03:00:45 +0200 (Wed, 28 Apr 2010)
New Revision: 10335

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
dbidispatch: Do not use qlong at ms with --long option since this queue does not exist anymore on Mammouth

Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2010-04-27 15:54:11 UTC (rev 10334)
+++ trunk/python_modules/plearn/parallel/dbi.py	2010-04-28 01:00:45 UTC (rev 10335)
@@ -628,7 +628,6 @@
         os.chdir(self.tmp_dir)
 
         if self.long:
-            self.queue = "qlong at ms"
             # Get max job duration from environment variable if it is set.
             max = os.getenv("BQ_MAX_JOB_DURATION")
             if max:



From nouiz at mail.berlios.de  Thu Apr 29 19:44:59 2010
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 29 Apr 2010 19:44:59 +0200
Subject: [Plearn-commits] r10336 - in trunk: python_modules/plearn/parallel
	scripts
Message-ID: <201004291744.o3THixoY012511@sheep.berlios.de>

Author: nouiz
Date: 2010-04-29 19:44:58 +0200 (Thu, 29 Apr 2010)
New Revision: 10336

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
   trunk/scripts/dbidispatch
Log:
make the dbidispatch --env work correctly with newer version of condor.


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2010-04-28 01:00:45 UTC (rev 10335)
+++ trunk/python_modules/plearn/parallel/dbi.py	2010-04-29 17:44:58 UTC (rev 10336)
@@ -1592,9 +1592,15 @@
             return #no task to run
 
         if self.set_special_env:
-            self.env+='" OMP_NUM_THREADS=$$(CPUS) GOTO_NUM_THREADS=$$(CPUS) MKL_NUM_THREADS=$$(CPUS) CONDOR_JOB_LOGDIR=%s"'%self.log_dir
+            if self.env:
+                self.env=self.env[:-1]+' OMP_NUM_THREADS=$$(CPUS) GOTO_NUM_THREADS=$$(CPUS) MKL_NUM_THREADS=$$(CPUS) CONDOR_JOB_LOGDIR=%s"'%self.log_dir
+            else:
+                self.env='" OMP_NUM_THREADS=$$(CPUS) GOTO_NUM_THREADS=$$(CPUS) MKL_NUM_THREADS=$$(CPUS) CONDOR_JOB_LOGDIR=%s"'%self.log_dir
         else:
-            self.env+='" CONDOR_JOB_LOGDIR=%s"'%self.log_dir
+            if self.env:
+                self.env=self.env[:-1]+' CONDOR_JOB_LOGDIR=%s"'%self.log_dir
+            else:
+                self.env='" CONDOR_JOB_LOGDIR=%s"'%self.log_dir
 
         if not self.req:
             self.req = "True"

Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2010-04-28 01:00:45 UTC (rev 10335)
+++ trunk/scripts/dbidispatch	2010-04-29 17:44:58 UTC (rev 10336)
@@ -394,7 +394,10 @@
         elif param == "raw":
             dbi_param[param]+='\n'+val
         elif param=="env":
-            dbi_param[param]+='"'+val+'"'
+            if dbi_param[param]:
+                dbi_param[param]=dbi_param[param][:-1]+' '+val+'"'
+            else:
+                dbi_param[param]+='"'+val+'"'
         elif param in ["machine", "machines", "no_machine", "tasks_filename"]:
             dbi_param[param]+=val.split(",")
         else:



