<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8173 - trunk/plearn_learners/distributions
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-October/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8173%20-%20trunk/plearn_learners/distributions&In-Reply-To=%3C200710102243.l9AMhD0I027303%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001620.html">
   <LINK REL="Next"  HREF="001622.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8173 - trunk/plearn_learners/distributions</H1>
    <B>larocheh at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8173%20-%20trunk/plearn_learners/distributions&In-Reply-To=%3C200710102243.l9AMhD0I027303%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8173 - trunk/plearn_learners/distributions">larocheh at mail.berlios.de
       </A><BR>
    <I>Thu Oct 11 00:43:13 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001620.html">[Plearn-commits] r8172 - trunk/plearn_learners/distributions
</A></li>
        <LI>Next message: <A HREF="001622.html">[Plearn-commits] r8174 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1621">[ date ]</a>
              <a href="thread.html#1621">[ thread ]</a>
              <a href="subject.html#1621">[ subject ]</a>
              <a href="author.html#1621">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: larocheh
Date: 2007-10-11 00:43:12 +0200 (Thu, 11 Oct 2007)
New Revision: 8173

Modified:
   trunk/plearn_learners/distributions/NGramDistribution.cc
   trunk/plearn_learners/distributions/NGramDistribution.h
Log:


Modified: trunk/plearn_learners/distributions/NGramDistribution.cc
===================================================================
--- trunk/plearn_learners/distributions/NGramDistribution.cc	2007-10-10 22:41:33 UTC (rev 8172)
+++ trunk/plearn_learners/distributions/NGramDistribution.cc	2007-10-10 22:43:12 UTC (rev 8173)
@@ -52,7 +52,12 @@
 // NGramDistribution //
 ///////////////////////
 NGramDistribution::NGramDistribution() :
-    nan_replace(false),n(2),additive_constant(0),discount_constant(0.01), validation_proportion(0.10), smoothing(&quot;no_smoothing&quot;),lambda_estimation(&quot;manual&quot;)
+    nan_replace(false),
+    n(2),
+    additive_constant(0),
+    discount_constant(0.01), 
+    smoothing(&quot;no_smoothing&quot;),
+    lambda_estimation(&quot;manual&quot;)
 {
     forget();
     // In a N-Gram, the predicted size is always one.
@@ -78,7 +83,8 @@
     // ### OptionBase::tuningoption. Another possible flag to be combined with
     // ### is OptionBase::nosave
 
-    declareOption(ol, &quot;nan_replace&quot;, &amp;NGramDistribution::nan_replace, OptionBase::buildoption,
+    declareOption(ol, &quot;nan_replace&quot;, &amp;NGramDistribution::nan_replace, 
+                  OptionBase::buildoption,
                   &quot;Indication that the missing values in context (nan) should be\n&quot;
                   &quot;replaced by a default value (-1). nan fields should correspond\n&quot;
                   &quot;to context not accessible (like in the beginning of a sentence).\n&quot;
@@ -91,13 +97,16 @@
         &quot;'predictor_size' and 'predicted_size', i.e. predictor_size = n-1\n&quot;
         &quot;and predicted_size = 1.&quot;);
 
-    declareOption(ol, &quot;additive_constant&quot;, &amp;NGramDistribution::additive_constant, OptionBase::buildoption,
+    declareOption(ol, &quot;additive_constant&quot;, &amp;NGramDistribution::additive_constant, 
+                  OptionBase::buildoption,
                   &quot;Additive constant for add-delta smoothing&quot;);
-    declareOption(ol, &quot;discount_constant&quot;, &amp;NGramDistribution::discount_constant, OptionBase::buildoption,
+
+    declareOption(ol, &quot;discount_constant&quot;, &amp;NGramDistribution::discount_constant, 
+                  OptionBase::buildoption,
                   &quot;Discount constant for absolut discounting smoothing&quot;);
-    declareOption(ol, &quot;validation_proportion&quot;, &amp;NGramDistribution::validation_proportion, OptionBase::buildoption,
-                  &quot;Proportion of the training set used for validation (EM)&quot;);
-    declareOption(ol, &quot;smoothing&quot;, &amp;NGramDistribution::smoothing, OptionBase::buildoption,
+
+    declareOption(ol, &quot;smoothing&quot;, &amp;NGramDistribution::smoothing, 
+                  OptionBase::buildoption,
                   &quot;Smoothing method. Choose among:\n&quot;
                   &quot;- \&quot;no_smoothing\&quot;\n&quot;
                   &quot;- \&quot;add-delta\&quot;\n&quot;
@@ -105,17 +114,26 @@
                   &quot;- \&quot;witten-bell\&quot;\n&quot;
                   &quot;- \&quot;absolute-discounting\&quot;\n&quot;
         );
-    declareOption(ol, &quot;lambda_estimation&quot;, &amp;NGramDistribution::lambda_estimation, OptionBase::buildoption,
+    declareOption(ol, &quot;lambda_estimation&quot;, &amp;NGramDistribution::lambda_estimation, 
+                  OptionBase::buildoption,
                   &quot;Lambdas estimation method. Choose among:\n&quot;
                   &quot;- \&quot;manual\&quot; (lambdas field should be specified)\n&quot;
                   &quot;- \&quot;EM\&quot;\n&quot;
         );
-    declareOption(ol, &quot;lambdas&quot;, &amp;NGramDistribution::lambdas, OptionBase::buildoption,
+    declareOption(ol, &quot;lambdas&quot;, &amp;NGramDistribution::lambdas, 
+                  OptionBase::buildoption,
                   &quot;Lambdas of the interpolated ngram&quot;);
-    declareOption(ol, &quot;tree&quot;, &amp;NGramDistribution::tree, OptionBase::buildoption,
+
+    declareOption(ol, &quot;validation_set&quot;, &amp;NGramDistribution::validation_set, 
+                  OptionBase::buildoption,
+                  &quot;Validation set used to estimate the lambdas with the\n&quot;
+                  &quot;EM algorithm.&quot;);
+
+    declareOption(ol, &quot;tree&quot;, &amp;NGramDistribution::tree, OptionBase::learntoption,
                   &quot;NGramTree of the frequencies&quot;);
 
-    declareOption(ol, &quot;voc_size&quot;, &amp;NGramDistribution::voc_size, OptionBase::learntoption,
+    declareOption(ol, &quot;voc_size&quot;, &amp;NGramDistribution::voc_size, 
+                  OptionBase::learntoption,
                   &quot;Vocabulary size&quot;);
 
     // Now call the parent class' declareOptions().
@@ -136,7 +154,7 @@
 void NGramDistribution::build()
 {
     // now set in the constructor to -1
-    //predictor_size = n - 1;
+    predictor_size = n - 1;
     inherited::build();
     build_();
 }
@@ -350,51 +368,53 @@
 
 void NGramDistribution::train()
 {
-    VMat contexts_train;
-    VMat contexts_validation;
 
+//    if(smoothing == &quot;jelinek-mercer&quot; &amp;&amp; lambda_estimation == &quot;EM&quot;)
+//    {
+//        if(validation_proportion &lt;= 0 || validation_proportion &gt;= 1)
+//            PLERROR(&quot;In NGramDistribution:build_() : validation_proportion should be in (0,1)&quot;);
+//        // Making FractionSplitter
+//        PP&lt;FractionSplitter&gt; fsplit = new FractionSplitter();
+//        TMat&lt;pair&lt;real,real&gt; &gt; splits(1,2);
+//        splits(0,0).first = 0; splits(0,0).second = 1-validation_proportion;
+//        splits(0,1).first = 1-validation_proportion; splits(0,1).second = 1;
+//        fsplit-&gt;splits = splits;
+//        fsplit-&gt;build();
+//
+//        // Making RepeatSplitter
+//        PP&lt;RepeatSplitter&gt; rsplit = new RepeatSplitter();
+//        rsplit-&gt;n = 1;
+//        rsplit-&gt;shuffle = true;
+//        rsplit-&gt;seed = 123456;
+//        rsplit-&gt;to_repeat = fsplit;
+//        rsplit-&gt;setDataSet(train_set);
+//        rsplit-&gt;build();
+//
+//        TVec&lt;VMat&gt; vmat_splits = rsplit-&gt;getSplit();
+//        contexts_train = vmat_splits[0];
+//        contexts_validation = vmat_splits[1];
+//    }
+//    else
 
-    if(smoothing == &quot;jelinek-mercer&quot; &amp;&amp; lambda_estimation == &quot;EM&quot;)
-    {
-        if(validation_proportion &lt;= 0 || validation_proportion &gt;= 1)
-            PLERROR(&quot;In NGramDistribution:build_() : validation_proportion should be in (0,1)&quot;);
-        // Making FractionSplitter
-        PP&lt;FractionSplitter&gt; fsplit = new FractionSplitter();
-        TMat&lt;pair&lt;real,real&gt; &gt; splits(1,2);
-        splits(0,0).first = 0; splits(0,0).second = 1-validation_proportion;
-        splits(0,1).first = 1-validation_proportion; splits(0,1).second = 1;
-        fsplit-&gt;splits = splits;
-        fsplit-&gt;build();
 
-        // Making RepeatSplitter
-        PP&lt;RepeatSplitter&gt; rsplit = new RepeatSplitter();
-        rsplit-&gt;n = 1;
-        rsplit-&gt;shuffle = true;
-        rsplit-&gt;seed = 123456;
-        rsplit-&gt;to_repeat = fsplit;
-        rsplit-&gt;setDataSet(train_set);
-        rsplit-&gt;build();
-
-        TVec&lt;VMat&gt; vmat_splits = rsplit-&gt;getSplit();
-        contexts_train = vmat_splits[0];
-        contexts_validation = vmat_splits[1];
-    }
-    else
-        contexts_train = train_set;
-
     //Putting ngrams in the tree
     Vec row(n);
     TVec&lt;int&gt; int_row(n);
 
-
-    PP&lt;ProgressBar&gt; pb =  new ProgressBar(&quot;Inserting ngrams in NGramTree&quot;, contexts_train-&gt;length());
-    for(int i=0; i&lt;contexts_train-&gt;length(); i++)
+    if(stage == 0 &amp;&amp; nstages&gt;0)
     {
-        contexts_train-&gt;getRow(i,row);
-        getNGrams(row,int_row);
-        tree-&gt;add(int_row);
-
-        pb-&gt;update(i+1);
+        PP&lt;ProgressBar&gt; pb =  new ProgressBar(&quot;Inserting ngrams in NGramTree&quot;, train_set-&gt;length());
+        for(int i=0; i&lt;train_set-&gt;length(); i++)
+        {
+            train_set-&gt;getRow(i,row);
+            getNGrams(row,int_row);
+            tree-&gt;add(int_row);
+            
+            pb-&gt;update(i+1);
+        }
+        stage++;
+        if(smoothing == &quot;jelinek-mercer&quot; &amp;&amp; lambda_estimation == &quot;EM&quot;)
+            stage--; //Will be incremented in EM estimation
     }
 
     // Smoothing techniques parameter estimation
@@ -403,7 +423,12 @@
         //Jelinek-Mercer: EM estimation of lambdas
         if(lambda_estimation == &quot;EM&quot;)
         {
-            lambdas.resize(n+1); lambdas.fill(1.0/(n+1));
+            if(stage == 0) 
+            {
+                lambdas.resize(n+1); lambdas.fill(1.0/(n+1));
+            }
+            if(!validation_set) PLERROR(&quot;In NGramDistribution:build_() : &quot;
+                                        &quot;validation_set needs to be provided&quot;);
             real diff = EM_PRECISION+1;
             real l_old = 0, l_new = -REAL_MAX;
             Vec e(n+1);
@@ -411,7 +436,8 @@
             TVec&lt;int&gt; ngram(n);
             real p_sum = 0;
             int n_ngram = 0;
-            while(diff &gt; EM_PRECISION)
+            //while(diff &gt; EM_PRECISION)
+            while(stage &lt; nstages)
             {
                 if(verbosity &gt; 2)
                     cout &lt;&lt; &quot;EM diff: &quot; &lt;&lt; diff &lt;&lt; endl;
@@ -421,13 +447,15 @@
                 // E step
 
                 e.fill(0);
-                for(int t=0; t&lt;contexts_validation-&gt;length(); t++)
+                //for(int t=0; t&lt;contexts_validation-&gt;length(); t++)
+                for(int t=0; t&lt;validation_set-&gt;length(); t++)
                 {
                     p_sum = 0;
 
                     // get w_{t-n+1}^t
 
-                    contexts_validation-&gt;getRow(t,row);
+                    //contexts_validation-&gt;getRow(t,row);
+                    validation_set-&gt;getRow(t,row);
                     getNGrams(row,ngram);
 
                     TVec&lt;int&gt; freq = tree-&gt;freq(ngram);
@@ -455,6 +483,7 @@
                     lambdas[j] = e[j]/n_ngram;
 
                 diff = l_new-l_old;
+                stage++;
             }
 
             //Test

Modified: trunk/plearn_learners/distributions/NGramDistribution.h
===================================================================
--- trunk/plearn_learners/distributions/NGramDistribution.h	2007-10-10 22:41:33 UTC (rev 8172)
+++ trunk/plearn_learners/distributions/NGramDistribution.h	2007-10-10 22:43:12 UTC (rev 8173)
@@ -88,9 +88,6 @@
     //! Discount constant for absolute discounting smoothing
     real discount_constant;
 
-    //! Proportion of the training set used for validation
-    real validation_proportion;
-
     //! Smoothing parameter
     string smoothing;
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001620.html">[Plearn-commits] r8172 - trunk/plearn_learners/distributions
</A></li>
	<LI>Next message: <A HREF="001622.html">[Plearn-commits] r8174 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1621">[ date ]</a>
              <a href="thread.html#1621">[ thread ]</a>
              <a href="subject.html#1621">[ subject ]</a>
              <a href="author.html#1621">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
