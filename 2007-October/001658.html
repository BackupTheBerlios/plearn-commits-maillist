<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8210 - trunk/plearn/math
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-October/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8210%20-%20trunk/plearn/math&In-Reply-To=%3C200710241912.l9OJCWxA018076%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001657.html">
   <LINK REL="Next"  HREF="001659.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8210 - trunk/plearn/math</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8210%20-%20trunk/plearn/math&In-Reply-To=%3C200710241912.l9OJCWxA018076%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8210 - trunk/plearn/math">nouiz at mail.berlios.de
       </A><BR>
    <I>Wed Oct 24 21:12:32 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001657.html">[Plearn-commits] r8209 - trunk/plearn/python
</A></li>
        <LI>Next message: <A HREF="001659.html">[Plearn-commits] r8211 - in trunk/plearn: base python
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1658">[ date ]</a>
              <a href="thread.html#1658">[ thread ]</a>
              <a href="subject.html#1658">[ subject ]</a>
              <a href="author.html#1658">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2007-10-24 21:12:31 +0200 (Wed, 24 Oct 2007)
New Revision: 8210

Modified:
   trunk/plearn/math/convolutions.cc
   trunk/plearn/math/plapack.cc
   trunk/plearn/math/random.cc
   trunk/plearn/math/random.h
Log:
Removed duplicate documentation. Doxygen generate warning when their is multiple file that comment the same function.


Modified: trunk/plearn/math/convolutions.cc
===================================================================
--- trunk/plearn/math/convolutions.cc	2007-10-24 15:52:33 UTC (rev 8209)
+++ trunk/plearn/math/convolutions.cc	2007-10-24 19:12:31 UTC (rev 8210)
@@ -49,11 +49,6 @@
 namespace PLearn {
 using namespace std;
 
-//! Convolve a source signal of length NS with a kernel of length NK
-//! with steps S, and put result in a destination signal which should
-//! be of length NS-NK+1.
-//! The destination signal is
-//!    dest_signal[i] = sum_{j=0}^{NK-1} source_signal[i*step+j]*kernel[j]
 void convolve1D(const Vec&amp; source_signal, const Vec&amp; kernel,
                 const Vec&amp; dest_signal, int step, bool accumulate)
 {
@@ -83,17 +78,6 @@
     }
 }
 
-//! Back-convolve INTO a &quot;source&quot; signal of length NS with a kernel of length
-//! NK and FROM a &quot;destination&quot; signal which should be of length NS-NK+1
-//! This is EXACTLY the TRANSPOSE operation of a convolve1D with the same
-//! arguments, with computations flowing in the other direction.
-//! for i=0 to nd-1:
-//!   for j=0 to nk-1:
-//!    source_signal[i*step+j] += dest_signal[i]*kernel[j]
-//! If the accumulate flag is not set, then source_signal is first cleared.
-//! N.B. THIS IS THE SAME AS COMPUTING dC/dsource_signal (into the
-//! source_signal argument), GIVEN dC/ddest_signal, i.e. this function
-//! does part of the work done by convolve1Dbackprop.
 void backConvolve1D(const Vec&amp; source_signal, const Vec&amp; kernel,
                     const Vec&amp; dest_signal, int step, bool accumulate)
 {
@@ -127,11 +111,6 @@
 }
 
 
-//! Increment dC/dsource_signal and dC/dkernel, given dC/ddest_signal, with
-//! dest_signal computed as per convolve1D(source_signal, kernel, dest_signal):
-//!    dC/dsource_signal[k] += sum_{j=0}^{NK-1} 1_{k&gt;=j &amp;&amp; k-j&lt;ND} dC_ddest_signal[k-j]*kernel[j]
-//!    dC/dkernel[j] += sum_{k=0}^{ND-1} 1_{k&gt;=j &amp;&amp; k-j&lt;ND} dC_ddest_signal[k-j]*source_signal[k]
-//! (consider the equivalence: k = i+j)
 void convolve1Dbackprop(const Vec&amp; source_signal, const Vec&amp; kernel,
                         const Vec&amp; dC_ddest_signal,
                         const Vec&amp; dC_dsource_signal, const Vec&amp; dC_dkernel,
@@ -186,9 +165,6 @@
     }
 }
 
-//! Same as above, but increments only dC/dkernel, not dC/dsource_signal
-//!    dC/dkernel[j] += sum_{k=0}^{ND-1} 1_{k&gt;=j &amp;&amp; k-j&lt;ND} dC_ddest_signal[k-j]*source_signal[k]
-//! (consider the equivalence: k = i+j)
 void convolve1Dbackprop(const Vec&amp; source_signal,
                         const Vec&amp; dC_ddest_signal,
                         const Vec&amp; dC_dkernel,
@@ -227,11 +203,6 @@
 }
 
 
-//! Increment dC/ddest_signal and dC/dkernel, given dC/ddest_signal, with
-//! source_signal computed as per
-//! backConvolve1D(source_signal, kernel, dest_signal):
-//!    dC/ddest_signal[i] += sum_{j=0}^{NK-1} dC_dsource_signal[i+j]*kernel[j]
-//!    dC/dkernel[j] += sum_{i=0}^{ND-1} dC_dsource_signal[i+j]*dest_signal[i]
 void backConvolve1Dbackprop(const Vec&amp; kernel, const Vec&amp; dest_signal,
                             const Vec&amp; dC_ddest_signal,
                             const Vec&amp; dC_dsource_signal,
@@ -291,8 +262,6 @@
 }
 
 
-//! Same as above, but increments only dC/dkernel, not  dC/ddest_signal
-//!    dC/dkernel[j] += sum_{i=0}^{ND-1} dC_dsource_signal[i+j]*dest_signal[i]
 void backConvolve1Dbackprop(const Vec&amp; dest_signal,
                             const Vec&amp; dC_dsource_signal,
                             const Vec&amp; dC_dkernel,
@@ -332,12 +301,6 @@
 }
 
 
-//! Convolve a (N1S x N2S) source image with a (N1K x N2K) kernel matrix,
-//! and put result in a destination matrix of dimensions (N1D x N2D), stepping
-//! by (step1,step2) in each direction, with NiS = NiD*stepi + NiK - 1.
-//! The destination image is
-//!    dest_image[i,j] = 
-//!      sum_{k1=0}^{N1K-1} sum_{k2=0}^{N2K-1} source_image[i*step1+k1,j*step2+k2]*kernel[k1,k2]
 void convolve2D(const Mat&amp; source_image, const Mat&amp; kernel,
                 const Mat&amp; dest_image,
                 int step1, int step2, bool accumulate)
@@ -390,24 +353,6 @@
     }
 }
 
-//! Back-convolve INTO a (N1S x N2S) &quot;source&quot; image with a (N1K x N2K)
-//! kernel matrix, and FROM a &quot;destination&quot; image of dimensions (N1D x
-//! N2D), with NiS = NiD + NiK - 1.
-//! This is EXACTLY the TRANSPOSE of convolve2D(source_image, kernel,
-//! dest_image, 1, 1) with the same arguments, computations flowing in
-//! the other direction.
-//! The kernel window is stepped by one in both directions. The
-//! destination image is
-//! for i1=0 to N1D-1:
-//!  for i2=0 to N2D-1:
-//!   for j1=0 to N1K-1:
-//!    for j2=0 to N2K-1:
-//!     source_image[i1+j1,i2+j2] += dest_image[i1,i2]*kernel[j1,j2]
-//! If the accumulate flag is not set, then source_image is first cleared.
-//! N.B. When dest_image has been computed from kernel and source_image
-//! using convolve2D, THIS IS THE SAME AS COMPUTING dC/dsource_image
-//! (into the source_image argument), GIVEN dC/ddest_image, i.e.
-//! this function does part of the work done by convolve2Dbackprop.
 void backConvolve2D(const Mat&amp; source_image, const Mat&amp; kernel,
                     const Mat&amp; dest_image,
                     int step1, int step2, bool accumulate)
@@ -461,14 +406,6 @@
     }
 }
 
-//! Increment dC/dsource_image and dC/dkernel, given dC/ddest_image, with
-//! dest_image computed as per convolve2D(source_image, kernel, dest_image):
-//! for i1=0 to N1D-1:
-//!  for i2=0 to N2D-1:
-//!   for j1=0 to N1K-1:
-//!    for j2=0 to N2K-1:
-//!     dC/dsource_image[i1+j1,i2+j2] += dC/dest_image[i1,i2]*kernel[j1,j2]
-//!     dC/dkernel[j1,j2] += dC/dest_image[i1,i2]*source_image[i1+j1,i2+j2]
 void convolve2Dbackprop(const Mat&amp; source_image, const Mat&amp; kernel,
                         const Mat&amp; dC_ddest_image,
                         const Mat&amp; dC_dsource_image, const Mat&amp; dC_dkernel,
@@ -558,12 +495,6 @@
 }
 
 
-//! As above, but increments only dC/dkernel, not dC/dsource_image
-//! for i1=0 to N1D-1:
-//!  for i2=0 to N2D-1:
-//!   for j1=0 to N1K-1:
-//!    for j2=0 to N2K-1:
-//!     dC/dkernel[j1,j2] += dC/dest_image[i1,i2]*source_image[i1+j1,i2+j2]
 void convolve2Dbackprop(const Mat&amp; source_image,
                         const Mat&amp; dC_ddest_image,
                         const Mat&amp; dC_dkernel,
@@ -622,15 +553,6 @@
 }
 
 
-//! Increment dC/ddest_image and dC/dkernel, given dC/dsource_image, with
-//! source_image computed as per
-//! backConvolve2D(source_image, kernel, dest_image):
-//! for i1=0 to N1D-1:
-//!  for i2=0 to N2D-1:
-//!   for j1=0 to N1K-1:
-//!    for j2=0 to N2K-1:
-//!     dC/ddest_image[i1,i2] += dC/dsource_image[i1+j1,i2+j2]*kernel[j1,j2]
-//!     dC/dkernel[j1,j2] += dC/dsource_image[i1+j1,i2+j2]*dest_image[i1,i2]
 void backConvolve2Dbackprop(const Mat&amp; kernel, const Mat&amp; dest_image,
                             const Mat&amp; dC_ddest_image,
                             const Mat&amp; dC_dsource_image, const Mat&amp; dC_dkernel,
@@ -721,12 +643,6 @@
     }
 }
 
-//! As above, but increments only dC/dkernel, not dC/ddest_image
-//! for i1=0 to N1D-1:
-//!  for i2=0 to N2D-1:
-//!   for j1=0 to N1K-1:
-//!    for j2=0 to N2K-1:
-//!     dC/dkernel[j1,j2] += dC/dsource_image[i1+j1,i2+j2]*dest_image[i1,i2]
 void backConvolve2Dbackprop(const Mat&amp; dest_image,
                             const Mat&amp; dC_dsource_image,
                             const Mat&amp; dC_dkernel,

Modified: trunk/plearn/math/plapack.cc
===================================================================
--- trunk/plearn/math/plapack.cc	2007-10-24 15:52:33 UTC (rev 8209)
+++ trunk/plearn/math/plapack.cc	2007-10-24 19:12:31 UTC (rev 8210)
@@ -873,14 +873,6 @@
     return sum_GCV;
 }
 
-//! Estimator of generalization error estimator called Generalized Cross-Validation (Craven &amp; Wahba 1979),
-//! computed from the SVD of the input matrix X in the ridge regression. See the comments
-//! for GCV. This function implements the formula:
-//!          n ( ||Y||^2 - ||Z||^2 + sum_{j=1}^p z_j^2 (weight_decay / (d_j^2 + weight_decay))^2 )
-//!    GCV = ------------------------------------------------------------------------------------
-//!                   ( n - p + sum_{j=1}^p (weight_decay  / (d_j^2 + weight_decay)) )^2
-//! where Z = U' Y, z_j is the j-th element of Z and d_j is the j-th singular value of X, with X = U D V' the SVD.
-//! The vector s with s_i = (weight_decay  / (d_j^2 + weight_decay)) must also be pre-computed.
 real GCVfromSVD(real n, real Y2minusZ2, Vec Z, Vec s)
 {
     int p = s.length();
@@ -895,27 +887,6 @@
     return GCV;
 }
 
-//! Perform ridge regression WITH model selection (i.e. choosing the weight decay).
-//! The selection of weight decay is done in order to minimize the Generalized Cross Validation
-//! (GCV) criterion(Craven &amp; Wahba 1979). The ridge regression weights minimize
-//!    min ||Y - X*W'||^2 + weight_decay ||W||^2.
-//! where Y is nxm, X is nxp, W is mxp, and this procedure ALSO selects a weight_decay value.
-//! The GCV is obtained by performing and SVD of X = U D V' and using the formula from
-//! (Bates, Lindstrom, Wahba, Yandell 1986) [tech report at <A HREF="http://www.stat.wisc.edu/~wahba/ftp1/oldie/775r.pdf">http://www.stat.wisc.edu/~wahba/ftp1/oldie/775r.pdf</A>]
-//! (here for m=1):
-//!          n ( ||Y||^2 - ||Z||^2 + sum_{j=1}^p z_j^2 (weight_decay / (d_j^2 + weight_decay))^2 )
-//!    GCV = ------------------------------------------------------------------------------------
-//!                   ( n - p + sum_{j=1}^p (weight_decay  / (d_j^2 + weight_decay)) )^2
-//! where Z = U' Y, z_j is the j-th element of Z and d_j is the j-th singular value of X.
-//! This formula can be efficiently re-computed for different values of weight decay.
-//! For this purpose, pre-compute the SVD can call GCVfromSVD. Once a weight decay
-//! has been selected, the SVD can also be used (optionally) to obtain the minimizing weights:
-//!    W = V inv(D^2 + weight_decay I) D Z
-//! If a positve initial_weight_decay_guess is provided, then instead of trying all the eigenvalues
-//! the algorithm searches from this initial guess, never going more than explore_threshold steps
-//! from the best weight decay found up to now. The weight decays tried are intermediate values
-//! (geometric average) between consecutive eigenvalues.
-//! Set best_GCV to the GCV of the selected weight decay and return that selected weight decay.
 real ridgeRegressionByGCV(Mat X, Mat Y, Mat W, real&amp; best_gcv, bool X_is_transposed, 
                           real initial_weight_decay_guess, int explore_threshold, real min_weight_decay)
 {
@@ -1248,11 +1219,6 @@
 }
 
 #if 0
-//! Auxiliary function used by generalizedCFRidgeRegression in order to compute the estimated generalization error
-//! associated with a given choice of weight decay. The eigenvalues and eigenvectors are those of the squared design matrix.
-//! The eigenvectors are in the ROWS of the matrix.
-//! The RHS_matrix is eigenvectors*inputs'*targets, pre-computed.
-//! The computational cost of this call is O((rank+n_examples)*n_outputs*n_inputs)
 real LOOMSEofRidgeRegression(Mat inputs, Mat targets, Mat weights, real weight_decay, Vec eigenvalues, Mat eigenvectors, Mat predictions, 
                              Mat RHS_matrix, bool inputs_are_transposed)
 {

Modified: trunk/plearn/math/random.cc
===================================================================
--- trunk/plearn/math/random.cc	2007-10-24 15:52:33 UTC (rev 8209)
+++ trunk/plearn/math/random.cc	2007-10-24 19:12:31 UTC (rev 8210)
@@ -61,10 +61,6 @@
     =================
 */
 
-/*  
-    log_gamma(): 
-    returns the natural logarithm of the gamma function
-*/
 
 real  log_gamma(real xx)
 {
@@ -85,7 +81,6 @@
     return -tmp+pl_log(2.5066282746310005*ser/x);
 }
 
-/*! returns the natural logarithm of the beta function */
 real log_beta(real x, real y)
 {
     return log_gamma(x) + log_gamma(y) - log_gamma(x+y);
@@ -141,8 +136,6 @@
     return frac;
 }
 
-/*! returns the incomplete beta function B_z(x,y)  */
-/*! Note that z must be in [0,1] */
 real incomplete_beta(real z, real x, real y)
 {
     if (z&gt;1 || z&lt;0) PLERROR(&quot;incomplete_beta(z,x,y): z =%f must be in [0,1]&quot;,z);
@@ -154,7 +147,6 @@
     return 1-coeff*incomplete_beta_continued_fraction(1-z,y,x)/y;
 }
 
-/*! Student-t cumulative distribution function */
 real student_t_cdf(real t, int nb_degrees_of_freedom)
 {
     real p_t = 0.5*incomplete_beta(nb_degrees_of_freedom/(nb_degrees_of_freedom+t*t),0.5*nb_degrees_of_freedom,0.5);
@@ -188,10 +180,6 @@
     iset     = 0;
 }
 
-/*  
-    seed(): generates a seed for random number generators, using the cpu time.
-*/
-
 void  seed()
 {
     time_t  ltime;
@@ -204,10 +192,6 @@
                 60*60*24*today-&gt;tm_mday);
 }
 
-/*  
-    get_seed(): returns the current value of the 'seed'.
-*/
-
 int32_t get_seed()
 {
     int32_t seed = the_seed;
@@ -218,33 +202,21 @@
     Constants used by the 'numerical recipes' random number generators.
 */
 
-#define NTAB 32                 /*   needs for ran1 &amp; ran2   */
-#define EPS 1.2e-7              /*   needs for ran1 &amp; ran2   */
-#define RNMX (1.0-EPS)          /*   needs for ran1 &amp; ran2   */
-#define IM1 2147483563          /*   needs for ran2          */
-#define IM2 2147483399          /*   needs for ran2          */
-#define AM1 (1.0/IM1)           /*   needs for ran2          */
-#define IMM1 (IM1-1)            /*   needs for ran2          */
-#define IA1 40014               /*   needs for ran2          */
-#define IA2 40692               /*   needs for ran2          */
-#define IQ1 53668               /*   needs for ran2          */
-#define IQ2 52774               /*   needs for ran2          */
-#define IR1 12211               /*   needs for ran2          */
-#define IR2 3791                /*   needs for ran2          */
-#define NDIV1 (1+IMM1/NTAB)     /*   needs for ran2          */
+#define NTAB 32                 /*   needs for ran1 &amp; uniform_sample()   */
+#define EPS 1.2e-7              /*   needs for ran1 &amp; uniform_sample()   */
+#define RNMX (1.0-EPS)          /*   needs for ran1 &amp; uniform_sample()   */
+#define IM1 2147483563          /*   needs for uniform_sample()          */
+#define IM2 2147483399          /*   needs for uniform_sample()          */
+#define AM1 (1.0/IM1)           /*   needs for uniform_sample()          */
+#define IMM1 (IM1-1)            /*   needs for uniform_sample()          */
+#define IA1 40014               /*   needs for uniform_sample()          */
+#define IA2 40692               /*   needs for uniform_sample()          */
+#define IQ1 53668               /*   needs for uniform_sample()          */
+#define IQ2 52774               /*   needs for uniform_sample()          */
+#define IR1 12211               /*   needs for uniform_sample()          */
+#define IR2 3791                /*   needs for uniform_sample()          */
+#define NDIV1 (1+IMM1/NTAB)     /*   needs for uniform_sample()          */
 
-/*  
-    ran2(): long period ramdom number generator from the 'numerical recipes'.
-
-    Rem: - It is a long period (&gt; 2 x 10^18) random number generator of L'Ecuyer
-    with Bays-Durham shuffle and added safeguards.
-
-    - Returns a uniform random deviate between 0.0 and 1.0
-    (exclusive of the endpoint values).
-
-    - Initialized with a negative seed.
-*/
-
 real uniform_sample()  
 {
     int j;
@@ -386,10 +358,6 @@
     ----------------
 */
 
-/*  
-    gamdev(): returns a deviate distributed as a gamma distribution from the 'numerical recipes'.
-*/
-
 real  gamdev(int ia)
 {
     int j;
@@ -418,11 +386,6 @@
     return x;
 }
 
-/*  
-    poidev(): returns a deviate distributed as a poisson distribution of mean (lambda) 'xm'
-    from the 'numerical recipes'.
-*/
-
 real  poidev(real xm)
 {
     static real sq,alxm,g,oldm=(-1.0);
@@ -556,7 +519,6 @@
     return int(N*uniform_sample());
 }
 
-//!  sample each element from uniform distribution U[minval,maxval]
 void fill_random_uniform(const Vec&amp; dest, real minval, real maxval)
 {
     Vec::iterator it = dest.begin();
@@ -566,7 +528,6 @@
         *it = real(uniform_sample()*scale+minval);
 }
 
-//!  sample each element from the given set
 void fill_random_discrete(const Vec&amp; dest, const Vec&amp; set)
 {
     Vec::iterator it = dest.begin();
@@ -576,7 +537,6 @@
         *it = set[uniform_multinomial_sample(n)];
 }
 
-//!  sample each element from Normal(mean,sdev^2) distribution
 void fill_random_normal(const Vec&amp; dest, real mean, real stdev)
 {
     Vec::iterator it = dest.begin();
@@ -585,7 +545,6 @@
         *it = real(gaussian_mu_sigma(mean,stdev));
 }
 
-//!  sample each element from multivariate Normal(mean,diag(sdev^2)) distribution
 void fill_random_normal(const Vec&amp; dest, const Vec&amp; mean, const Vec&amp; stdev)
 {
 #ifdef BOUNDCHECK

Modified: trunk/plearn/math/random.h
===================================================================
--- trunk/plearn/math/random.h	2007-10-24 15:52:33 UTC (rev 8209)
+++ trunk/plearn/math/random.h	2007-10-24 19:12:31 UTC (rev 8210)
@@ -58,6 +58,7 @@
 real log_beta(real x, real y);
 
 /*! returns the incomplete beta function B_z(x,y)  (BUGGED?)*/
+/*! Note that z must be in [0,1] */
 real incomplete_beta(real z, real x, real y);
 /*! returns the incomplete beta function B_z(x,y)  */
 //double incbet(double x, double y, double z);
@@ -77,7 +78,15 @@
 /*!   returns the current seed used by the random number generator   */
 int32_t  get_seed();
 
-/*!   returns a random number uniformly distributed between 0 and 1   */
+/*! Long period ramdom number generator from the 'numerical recipes'.
+
+    Rem: - It is a long period (&gt; 2 x 10^18) random number generator of L'Ecuyer
+    with Bays-Durham shuffle and added safeguards.
+
+    - Initialized with a negative seed.
+   @returns a random number uniformly distributed between 0 and 1 \
+   (exclusive of the endpoint values).
+*/
 real  uniform_sample();
 /*!   returns a random number uniformly distributed between a and b   */
 real  bounded_uniform(real a,real b);
@@ -96,9 +105,10 @@
   of means and standard deviations for each gaussian   */
 real  gaussian_mixture_mu_sigma(Vec&amp; w, const Vec&amp; mu, const Vec&amp; sigma);
 
-/*!   returns a gamma distributed random number   */
+/*!   @returns a deviate distributed as a gamma distribution from the 'numerical recipes'. */
 real  gamdev(int ia);
-/*!   returns a poisson random number with lambda = &quot;xm&quot;   */
+/*!   @returns returns a deviate distributed as a poisson distribution of mean (lambda) 'xm'\
+    from the 'numerical recipes'.  */
 real  poidev(real xm);
 /*!   returns a binomial random number with probability = 'pp' and trials number = 'n'   */
 real  bnldev(real pp, int n=1);


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001657.html">[Plearn-commits] r8209 - trunk/plearn/python
</A></li>
	<LI>Next message: <A HREF="001659.html">[Plearn-commits] r8211 - in trunk/plearn: base python
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1658">[ date ]</a>
              <a href="thread.html#1658">[ thread ]</a>
              <a href="subject.html#1658">[ subject ]</a>
              <a href="author.html#1658">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
