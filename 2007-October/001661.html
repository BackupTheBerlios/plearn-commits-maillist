<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8213 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-October/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8213%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200710251950.l9PJo67s024914%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001660.html">
   <LINK REL="Next"  HREF="001662.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8213 - trunk/plearn_learners_experimental</H1>
    <B>larocheh at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8213%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200710251950.l9PJo67s024914%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8213 - trunk/plearn_learners_experimental">larocheh at mail.berlios.de
       </A><BR>
    <I>Thu Oct 25 21:50:06 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001660.html">[Plearn-commits] r8212 - trunk/scripts
</A></li>
        <LI>Next message: <A HREF="001662.html">[Plearn-commits] r8214 - trunk/plearn_learners_experimental
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1661">[ date ]</a>
              <a href="thread.html#1661">[ thread ]</a>
              <a href="subject.html#1661">[ subject ]</a>
              <a href="author.html#1661">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: larocheh
Date: 2007-10-25 21:50:05 +0200 (Thu, 25 Oct 2007)
New Revision: 8213

Modified:
   trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc
   trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.h
Log:
Debugging...


Modified: trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc
===================================================================
--- trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc	2007-10-24 20:54:58 UTC (rev 8212)
+++ trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc	2007-10-25 19:50:05 UTC (rev 8213)
@@ -67,6 +67,9 @@
     fine_tuning_decrease_ct( 0. ),
     k_neighbors( 1 ),
     n_classes( -1 ),
+    do_not_use_knn_classifier(false),
+    output_weights_l1_penalty_factor(0),
+    output_weights_l2_penalty_factor(0),
     n_layers( 0 ),
     train_set_representations_up_to_date(false),
     currently_trained_layer( 0 )
@@ -174,6 +177,12 @@
                   OptionBase::buildoption,
                   &quot;Number of classes.&quot;);
 
+    declareOption(ol, &quot;do_not_use_knn_classifier&quot;, 
+                  &amp;StackedFocusedAutoassociatorsNet::do_not_use_knn_classifier,
+                  OptionBase::buildoption,
+                  &quot;Use standard neural net architecture, not the nearest &quot;
+                  &quot;neighbor model.&quot;);
+
     declareOption(ol, &quot;greedy_stages&quot;, 
                   &amp;StackedFocusedAutoassociatorsNet::greedy_stages,
                   OptionBase::learntoption,
@@ -186,6 +195,18 @@
                   &quot;Number of layers&quot;
         );
 
+    declareOption(ol, &quot;final_module&quot;, 
+                  &amp;StackedFocusedAutoassociatorsNet::final_module,
+                  OptionBase::learntoption,
+                  &quot;Output layer of neural net&quot;
+        );
+
+    declareOption(ol, &quot;final_cost&quot;, 
+                  &amp;StackedFocusedAutoassociatorsNet::final_cost,
+                  OptionBase::learntoption,
+                  &quot;Cost on output layer of neural net&quot;
+        );
+
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
 }
@@ -249,9 +270,59 @@
         }
 
         build_layers_and_connections();
+
+        if( do_not_use_knn_classifier &amp; (!final_module || !final_cost) )
+            build_output_layer_and_cost();
     }
 }
 
+void StackedFocusedAutoassociatorsNet::build_output_layer_and_cost()
+{
+    GradNNetLayerModule* gnl = new GradNNetLayerModule();
+    gnl-&gt;input_size = layers[n_layers-1]-&gt;size;
+    gnl-&gt;output_size = n_classes;
+    gnl-&gt;L1_penalty_factor = output_weights_l1_penalty_factor;
+    gnl-&gt;L2_penalty_factor = output_weights_l2_penalty_factor;
+    gnl-&gt;random_gen = random_gen;
+    gnl-&gt;build();
+
+    SoftmaxModule* sm = new SoftmaxModule();
+    sm-&gt;input_size = n_classes;
+    sm-&gt;random_gen = random_gen;
+    sm-&gt;build();
+
+    ModuleStackModule* msm = new ModuleStackModule();
+    msm-&gt;modules.resize(2);
+    msm-&gt;modules[0] = gnl;
+    msm-&gt;modules[1] = sm;
+    msm-&gt;random_gen = random_gen;
+    msm-&gt;build();
+    final_module = msm;
+
+    final_module-&gt;forget();
+
+    NLLCostModule* nll = new NLLCostModule();
+    nll-&gt;input_size = n_classes;
+    nll-&gt;random_gen = random_gen;
+    nll-&gt;build();
+    
+    ClassErrorCostModule* class_error = new ClassErrorCostModule();
+    class_error-&gt;input_size = n_classes;
+    class_error-&gt;random_gen = random_gen;
+    class_error-&gt;build();
+
+    CombiningCostsModule* comb_costs = new CombiningCostsModule();
+    comb_costs-&gt;cost_weights.resize(2);
+    comb_costs-&gt;cost_weights[0] = 1;
+    comb_costs-&gt;cost_weights[1] = 0;
+    comb_costs-&gt;sub_costs.resize(2);
+    comb_costs-&gt;sub_costs[0] = nll;
+    comb_costs-&gt;sub_costs[1] = class_error;
+
+    final_cost = comb_costs;
+    final_cost-&gt;forget();
+}
+
 void StackedFocusedAutoassociatorsNet::build_layers_and_connections()
 {
     MODULE_LOG &lt;&lt; &quot;build_layers_and_connections() called&quot; &lt;&lt; endl;
@@ -487,6 +558,9 @@
     deepCopyField(pos_up_val, copies);
     deepCopyField(neg_down_val, copies);
     deepCopyField(neg_up_val, copies);
+    deepCopyField(final_cost_input, copies);
+    deepCopyField(final_cost_value, copies);
+    deepCopyField(final_cost_gradient, copies);
     deepCopyField(class_datasets, copies);
     deepCopyField(other_classes_proportions, copies);
     deepCopyField(nearest_neighbors_indices, copies);
@@ -496,6 +570,8 @@
     deepCopyField(train_set_representations_vmat, copies);
     deepCopyField(train_set_targets, copies);
     deepCopyField(greedy_stages, copies);
+    deepCopyField(final_module, copies);
+    deepCopyField(final_cost, copies);
 }
 
 
@@ -523,12 +599,26 @@
 
     train_set_representations_up_to_date = false;
 
+    for( int i=0 ; i&lt;n_layers ; i++ )
+        layers[i]-&gt;forget();
+    
     for( int i=0 ; i&lt;n_layers-1 ; i++ )
         connections[i]-&gt;forget();
     
+    if(unsupervised_layers.length() != 0)
+        for( int i=0 ; i&lt;n_layers-1 ; i++ )
+            unsupervised_layers[i]-&gt;forget();
+    
+    if(unsupervised_connections.length() != 0)
+        for( int i=0 ; i&lt;n_layers-1 ; i++ )
+            unsupervised_connections[i]-&gt;forget();
+    
     for( int i=0; i&lt;reconstruction_connections.length(); i++)
         reconstruction_connections[i]-&gt;forget();
 
+    if( do_not_use_knn_classifier )
+        build_output_layer_and_cost();
+
     stage = 0;
     greedy_stages.clear();
 }
@@ -669,6 +759,10 @@
         similar_example.resize(inputsize());
         dissimilar_example.resize(inputsize());
 
+        final_cost_input.resize(n_classes);
+        final_cost_value.resize(2); // Should be resized anyways
+        final_cost_gradient.resize(n_classes);
+
         for( ; stage&lt;nstages ; stage++ )
         {
             sample = stage % nsamples;
@@ -790,7 +884,7 @@
     // Similar example contribution
     substract(input_representation,similar_example_representation,
               expectation_gradients[index+1]);
-    expectation_gradients[index+1] *= 4/layers[index+1]-&gt;size;
+    expectation_gradients[index+1] *= 4/sqrt(layers[index+1]-&gt;size);
     
     // Dissimilar example contribution
     real dist = sqrt(powdistance(input_representation,
@@ -808,7 +902,7 @@
                   dissimilar_gradient_contribution);
         
         dissimilar_gradient_contribution *= -5.54*
-            safeexp(-2.77*dist/layers[index+1]-&gt;size)/dist;
+            safeexp(-2.77*dist/sqrt(layers[index+1]-&gt;size));
 
         expectation_gradients[index+1] += dissimilar_gradient_contribution;
     }
@@ -917,16 +1011,19 @@
 {
     train_set_representations_up_to_date = false;
 
-    // Get similar example representation
-    
-    computeRepresentation(similar_example, similar_example_representation, 
-                          n_layers-1);
+    if( !do_not_use_knn_classifier )
+    {
+        // Get similar example representation
+        
+        computeRepresentation(similar_example, similar_example_representation, 
+                              n_layers-1);
+        
+        // Get dissimilar example representation
+        
+        computeRepresentation(dissimilar_example, dissimilar_example_representation,
+                              n_layers-1);
+    }
 
-    // Get dissimilar example representation
-
-    computeRepresentation(dissimilar_example, dissimilar_example_representation, 
-                          n_layers-1);
-
     // Get example representation
 
     computeRepresentation(input, previous_input_representation, 
@@ -934,32 +1031,49 @@
 
     // Compute supervised gradient
 
-    // Similar example contribution
-    substract(input_representation,similar_example_representation,
-              expectation_gradients[n_layers-1]);
-    expectation_gradients[n_layers-1] *= 4/layers[n_layers-1]-&gt;size;
+
+    if( do_not_use_knn_classifier )
+    {
+        // Similar example contribution
+        substract(input_representation,similar_example_representation,
+                  expectation_gradients[n_layers-1]);
+        expectation_gradients[n_layers-1] *= 4/sqrt(layers[n_layers-1]-&gt;size);
     
-    // Dissimilar example contribution
-    real dist = sqrt(powdistance(input_representation,
-                                 dissimilar_example_representation,
-                                 2));
+        // Dissimilar example contribution
+        real dist = sqrt(powdistance(input_representation,
+                                     dissimilar_example_representation,
+                                     2));
     
-    if( dist == 0 )
-        PLWARNING(&quot;StackedFocusedAutoassociatorsNet::fineTuningStep(): dissimilar&quot;
-                  &quot; example representation is exactly the sample as the&quot;
-                  &quot; input example. Gradient would be infinite! Skipping this&quot;
-                  &quot; example...&quot;);
-    else
-    {
+        if( dist == 0 )
+            PLWARNING(&quot;StackedFocusedAutoassociatorsNet::fineTuningStep(): dissimilar&quot;
+                      &quot; example representation is exactly the sample as the&quot;
+                      &quot; input example. Gradient would be infinite! Skipping this&quot;
+                      &quot; example...&quot;);
+        else
+        {
 
-        substract(input_representation,dissimilar_example_representation,
-                  dissimilar_gradient_contribution);
+            substract(input_representation,dissimilar_example_representation,
+                      dissimilar_gradient_contribution);
 
-        dissimilar_gradient_contribution *= -5.54*
-            safeexp(-2.77*dist/layers[n_layers-1]-&gt;size)/dist;
+            dissimilar_gradient_contribution *= -5.54*
+                safeexp(-2.77*dist/sqrt(layers[n_layers-1]-&gt;size));
         
-        expectation_gradients[n_layers-1] += dissimilar_gradient_contribution;
+            expectation_gradients[n_layers-1] += dissimilar_gradient_contribution;
+        }
     }
+    else
+    {
+        final_module-&gt;fprop( input_representation, final_cost_input );
+        final_cost-&gt;fprop( final_cost_input, target, final_cost_value );
+        
+        final_cost-&gt;bpropUpdate( final_cost_input, target,
+                                 final_cost_value[0],
+                                 final_cost_gradient );
+        final_module-&gt;bpropUpdate( input_representation,
+                                   final_cost_input,
+                                   expectation_gradients[ n_layers-1 ],
+                                   final_cost_gradient );
+    }
 
     for( int i=n_layers-1 ; i&gt;0 ; i-- )
     {
@@ -1000,20 +1114,29 @@
 
 void StackedFocusedAutoassociatorsNet::computeOutput(const Vec&amp; input, Vec&amp; output) const
 {
-    updateTrainSetRepresentations();
-
-    computeRepresentation(input,input_representation, 
-                          min(currently_trained_layer,n_layers-1));
-
-    computeNearestNeighbors(train_set_representations_vmat,input_representation,
-                            test_nearest_neighbors_indices);
-
-    test_votes.clear();
-    for(int i=0; i&lt;test_nearest_neighbors_indices.length(); i++)
-        test_votes[train_set_targets[test_nearest_neighbors_indices[i]]]++;
-
-    output[0] = argmax(test_votes);
-
+    if( do_not_use_knn_classifier &amp; currently_trained_layer&gt;n_layers-1 )
+    {
+        computeRepresentation(input,input_representation, 
+                              min(currently_trained_layer,n_layers-1));
+        final_module-&gt;fprop( input_representation, final_cost_input );
+        output[0] = argmax(final_cost_input);
+    }
+    else
+    {
+        updateTrainSetRepresentations();
+        
+        computeRepresentation(input,input_representation, 
+                              min(currently_trained_layer,n_layers-1));
+        
+        computeNearestNeighbors(train_set_representations_vmat,input_representation,
+                                test_nearest_neighbors_indices);
+        
+        test_votes.clear();
+        for(int i=0; i&lt;test_nearest_neighbors_indices.length(); i++)
+            test_votes[train_set_targets[test_nearest_neighbors_indices[i]]]++;
+        
+        output[0] = argmax(test_votes);
+    }
 }
 
 void StackedFocusedAutoassociatorsNet::computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
@@ -1175,6 +1298,12 @@
         connections[i]-&gt;setLearningRate( the_learning_rate );
     }
     layers[n_layers-1]-&gt;setLearningRate( the_learning_rate );
+
+    if( do_not_use_knn_classifier )
+    {
+        final_module-&gt;setLearningRate( the_learning_rate );
+        final_cost-&gt;setLearningRate( the_learning_rate );
+    }
 }
 
 

Modified: trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.h
===================================================================
--- trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.h	2007-10-24 20:54:58 UTC (rev 8212)
+++ trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.h	2007-10-25 19:50:05 UTC (rev 8213)
@@ -42,13 +42,18 @@
 
 #include &lt;plearn/vmat/ClassSubsetVMatrix.h&gt;
 #include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/online/GradNNetLayerModule.h&gt;
 #include &lt;plearn_learners/online/OnlineLearningModule.h&gt;
 #include &lt;plearn_learners/online/CostModule.h&gt;
+#include &lt;plearn_learners/online/ModuleStackModule.h&gt;
 #include &lt;plearn_learners/online/NLLCostModule.h&gt;
+#include &lt;plearn_learners/online/ClassErrorCostModule.h&gt;
+#include &lt;plearn_learners/online/CombiningCostsModule.h&gt;
 #include &lt;plearn_learners/online/RBMClassificationModule.h&gt;
 #include &lt;plearn_learners/online/RBMLayer.h&gt;
 #include &lt;plearn_learners/online/RBMMixedLayer.h&gt;
 #include &lt;plearn_learners/online/RBMConnection.h&gt;
+#include &lt;plearn_learners/online/SoftmaxModule.h&gt;
 #include &lt;plearn/misc/PTimer.h&gt;
 
 namespace PLearn {
@@ -119,6 +124,16 @@
     //! Number of classes
     int n_classes;
 
+    //! Use standard neural net architecture, not 
+    //! the nearest neighbor model.
+    bool do_not_use_knn_classifier;
+
+    //! Output weights l1_penalty_factor
+    real output_weights_l1_penalty_factor;
+
+    //! Output weights l2_penalty_factor
+    real output_weights_l2_penalty_factor;
+
     //#####  Public Learnt Options  ###########################################
 
     //! Number of layers
@@ -275,6 +290,13 @@
     //! Negative up statistic
     Vec neg_up_val;
 
+    //! Input of cost function
+    mutable Vec final_cost_input;
+    //! Cost value
+    mutable Vec final_cost_value;
+    //! Cost gradient on output layer
+    mutable Vec final_cost_gradient;
+
     //! Datasets for each class
     TVec&lt; PP&lt;ClassSubsetVMatrix&gt; &gt; class_datasets;
 
@@ -306,6 +328,12 @@
     //! n_layers means the output layer)
     int currently_trained_layer;
 
+    //! Output layer of neural net
+    PP&lt;OnlineLearningModule&gt; final_module;
+
+    //! Cost on output layer of neural net
+    PP&lt;CostModule&gt; final_cost;
+
 protected:
     //#####  Protected Member Functions  ######################################
 
@@ -320,7 +348,7 @@
 
     void build_layers_and_connections();
 
-    void build_classification_cost();
+    void build_output_layer_and_cost();
 
     void setLearningRate( real the_learning_rate );
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001660.html">[Plearn-commits] r8212 - trunk/scripts
</A></li>
	<LI>Next message: <A HREF="001662.html">[Plearn-commits] r8214 - trunk/plearn_learners_experimental
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1661">[ date ]</a>
              <a href="thread.html#1661">[ thread ]</a>
              <a href="subject.html#1661">[ subject ]</a>
              <a href="author.html#1661">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
