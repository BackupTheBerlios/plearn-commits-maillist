<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8151 - trunk/plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-October/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8151%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200710041903.l94J3J5a003150%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001598.html">
   <LINK REL="Next"  HREF="001600.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8151 - trunk/plearn_learners/generic/EXPERIMENTAL</H1>
    <B>manzagop at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8151%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200710041903.l94J3J5a003150%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8151 - trunk/plearn_learners/generic/EXPERIMENTAL">manzagop at mail.berlios.de
       </A><BR>
    <I>Thu Oct  4 21:03:19 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001598.html">[Plearn-commits] r8150 - trunk/plearn/ker
</A></li>
        <LI>Next message: <A HREF="001600.html">[Plearn-commits] r8152 - trunk/plearn_learners/testers
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1599">[ date ]</a>
              <a href="thread.html#1599">[ thread ]</a>
              <a href="subject.html#1599">[ subject ]</a>
              <a href="author.html#1599">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: manzagop
Date: 2007-10-04 21:03:19 +0200 (Thu, 04 Oct 2007)
New Revision: 8151

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h
Log:
- Coded the DiscountGrad() strategy which implements a soft invalidation
of weight statistics. Added 2 discount options. Sample stats are now real 
instead of int.


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc	2007-10-04 18:03:22 UTC (rev 8150)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc	2007-10-04 19:03:19 UTC (rev 8151)
@@ -58,8 +58,10 @@
       pv_min_samples(2),
       pv_required_confidence(0.80),
       pv_strategy(1),
-      pv_random_sample_step(false)
-
+      pv_random_sample_step(false),
+      pv_self_discount(0.5),
+      pv_other_discount(0.95),
+      n_updates(0)
 {
     random_gen = new PRandom();
 }
@@ -114,6 +116,18 @@
                   &quot;for each parameter based on the estimated probability of it being\n&quot;
                   &quot;positive or negative.&quot;);
 
+    declareOption(ol, &quot;pv_self_discount&quot;,
+                  &amp;PvGradNNet::pv_self_discount,
+                  OptionBase::buildoption,
+                  &quot;Discount used to perform soft invalidation of a weight's statistics\n&quot;
+                  &quot;after its update.&quot;);
+
+    declareOption(ol, &quot;pv_other_discount&quot;,
+                  &amp;PvGradNNet::pv_other_discount,
+                  OptionBase::buildoption,
+                  &quot;Discount used to perform soft invalidation of other weights'\n&quot; 
+                  &quot;statistics after a weight update.&quot;);
+
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
 }
@@ -188,6 +202,9 @@
     pv_all_stepsigns.fill(0);
     pv_all_stepsizes.fill(pv_initial_stepsize);
 
+    // used in the discountGrad() strategy
+    n_updates = 0; 
+    
 //    pv_gradstats-&gt;forget();
 }
 
@@ -304,8 +321,85 @@
 
 }
 
+//! This gradient strategy is much like the one from PvGrad, however:
+//!     - there is no hard statistic invalidation, it's soft with discounts.
+//!     - a weight update will also affect other weights' statistics.
+//! Note that discounting is applied after the update, never during.
+//! With pv_self_discount=0.0 and pv_other_discount=1.0, should be same as
+//! PvGrad().
 void PvGradNNet::discountGrad()
 {
+    int np = all_params.length();
+    real m, e, prob_pos, prob_neg;
+    int stepsign;
+
+    // 
+    real discount = pow(pv_other_discount,n_updates);
+    n_updates = 0;
+    if( discount &lt; 0.001 )
+        PLWARNING(&quot;PvGradNNet::discountGrad() - discount &lt; 0.001 - that seems small...&quot;);
+    real sd = pv_self_discount / pv_other_discount; // trick: apply this self discount
+                                                    // and then discount
+                                                    // everyone the same
+    for(int k=0; k&lt;np; k++) {
+        // Perform soft invalidation
+        pv_all_nsamples[k] *= discount;
+        pv_all_sum[k] *= discount;
+        pv_all_sumsquare[k] *= discount;
+
+        // update stats
+        pv_all_nsamples[k]++;
+        pv_all_sum[k] += all_params_gradient[k];
+        pv_all_sumsquare[k] += all_params_gradient[k] * all_params_gradient[k];
+
+        if(pv_all_nsamples[k]&gt;pv_min_samples)   {
+            m = pv_all_sum[k] / pv_all_nsamples[k];
+            e = real((pv_all_sumsquare[k] - square(pv_all_sum[k])/pv_all_nsamples[k])/(pv_all_nsamples[k]-1));
+            e = sqrt(e/pv_all_nsamples[k]);
+
+            // test to see if numerical problems
+            if( fabs(m) &lt; 1e-15 || e &lt; 1e-15 )  {
+                cout &lt;&lt; &quot;PvGradNNet::bpropUpdateNet() - small mean-error ratio.&quot; &lt;&lt; endl;
+                continue;
+            }
+
+            // TODO - for current treatment, not necessary to compute actual
+            // prob. Comparing the ratio would be sufficient.
+            prob_pos = gauss_01_cum(m/e);
+            prob_neg = 1.-prob_pos;
+
+            if(prob_pos&gt;=pv_required_confidence)
+                stepsign = 1;
+            else if(prob_neg&gt;=pv_required_confidence)
+                stepsign = -1;
+            else
+                continue;
+
+            // consecutive steps of same sign, accelerate
+            if( stepsign*pv_all_stepsigns[k]&gt;0 )  {
+                pv_all_stepsizes[k]*=pv_acceleration;
+                if( pv_all_stepsizes[k] &gt; pv_max_stepsize )
+                    pv_all_stepsizes[k] = pv_max_stepsize;            
+            // else if different signs decelerate
+            }   else if( stepsign*pv_all_stepsigns[k]&lt;0 )   {
+                pv_all_stepsizes[k]*=pv_deceleration;
+                if( pv_all_stepsizes[k] &lt; pv_min_stepsize )
+                    pv_all_stepsizes[k] = pv_min_stepsize;
+            // else (previous sign was undetermined
+            }//   else    {
+            //}
+            // step
+            if( stepsign &gt; 0 )
+                all_params[k] -= pv_all_stepsizes[k];
+            else
+                all_params[k] += pv_all_stepsizes[k];
+            pv_all_stepsigns[k] = stepsign;
+            // soft invalidation of self
+            pv_all_nsamples[k]*=sd;
+            pv_all_sum[k]*=sd;
+            pv_all_sumsquare[k]*=sd;
+        }
+    }
 }
 
 void PvGradNNet::globalSyncGrad()

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h	2007-10-04 18:03:22 UTC (rev 8150)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h	2007-10-04 19:03:19 UTC (rev 8151)
@@ -76,6 +76,10 @@
     // or negative.
     bool pv_random_sample_step;
 
+    //! For the discounting strategy. Used to discount stats when there are
+    //! updates
+    real pv_self_discount, pv_other_discount;
+
 public:
     //#####  Public Not Build Options  ########################################
 
@@ -131,8 +135,8 @@
     //#####  Private Data Members  ############################################
 
     //! Holds the number of samples gathered for each weight
-    TVec&lt;int&gt; pv_all_nsamples;
-    TVec&lt; TMat&lt;int&gt; &gt; pv_layer_nsamples;
+    Vec pv_all_nsamples;
+    TVec&lt; Mat &gt; pv_layer_nsamples;
     //! Sum of collected gradients 
     Vec pv_all_sum;
     TVec&lt;Mat&gt; pv_layer_sum;
@@ -148,6 +152,10 @@
     Vec pv_all_stepsizes;
     TVec&lt;Mat&gt; pv_layer_stepsizes;
 
+    //! Number of weight updates performed during a call to bpropUpdateNet
+    // int is enough?
+    int n_updates;
+
     //! accumulated statistics of gradients on each parameter.
     //PP&lt;VecStatsCollector&gt; pv_gradstats;
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001598.html">[Plearn-commits] r8150 - trunk/plearn/ker
</A></li>
	<LI>Next message: <A HREF="001600.html">[Plearn-commits] r8152 - trunk/plearn_learners/testers
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1599">[ date ]</a>
              <a href="thread.html#1599">[ thread ]</a>
              <a href="subject.html#1599">[ subject ]</a>
              <a href="author.html#1599">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
