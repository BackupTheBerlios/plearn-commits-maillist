<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9780 - trunk/plearn_learners/regressors
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-December/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9780%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200812151931.mBFJVT9L023273%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003219.html">
   <LINK REL="Next"  HREF="003221.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9780 - trunk/plearn_learners/regressors</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9780%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200812151931.mBFJVT9L023273%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9780 - trunk/plearn_learners/regressors">nouiz at mail.berlios.de
       </A><BR>
    <I>Mon Dec 15 20:31:29 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="003219.html">[Plearn-commits] r9779 - trunk/plearn_learners/regressors
</A></li>
        <LI>Next message: <A HREF="003221.html">[Plearn-commits] r9781 - trunk/plearn_learners/regressors
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3220">[ date ]</a>
              <a href="thread.html#3220">[ thread ]</a>
              <a href="subject.html#3220">[ subject ]</a>
              <a href="author.html#3220">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2008-12-15 20:31:29 +0100 (Mon, 15 Dec 2008)
New Revision: 9780

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeLeave.h
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
Log:
removed RegressionTreeLeave::getLength() to the more standard RegressionTreeLeave::length()


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2008-12-15 19:04:10 UTC (rev 9779)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2008-12-15 19:31:29 UTC (rev 9780)
@@ -57,7 +57,7 @@
     missing_leave(false),
     loss_function_weight(0),
     id(-1),
-    length(0),
+    length_(0),
     weights_sum(0),
     targets_sum(0),
     weighted_targets_sum(0),
@@ -84,7 +84,7 @@
     declareOption(ol, &quot;train_set&quot;, &amp;RegressionTreeLeave::train_set, 
                   OptionBase::buildoption | OptionBase::nosave,
                   &quot;The train set with the sorted row index matrix and the leave id vector\n&quot;);
-    declareOption(ol, &quot;length&quot;, &amp;RegressionTreeLeave::length, OptionBase::learntoption,
+    declareOption(ol, &quot;length&quot;, &amp;RegressionTreeLeave::length_, OptionBase::learntoption,
                   &quot;The number of rows in this leave\n&quot;);
     declareOption(ol, &quot;weights_sum&quot;, &amp;RegressionTreeLeave::weights_sum, OptionBase::learntoption,
                   &quot;The sum of weights for the samples in this leave\n&quot;);
@@ -131,7 +131,7 @@
 
 void RegressionTreeLeave::initStats()
 {
-    length = 0;
+    length_ = 0;
     weights_sum= 0.0;
     targets_sum = 0.0;
     weighted_targets_sum = 0.0;
@@ -143,7 +143,7 @@
 
 void RegressionTreeLeave::addRow(int row, real target, real weight)
 {
-    length += 1;
+    length_ += 1;
     weights_sum += weight;
     targets_sum += target;
     real squared_target = pow(target, 2);
@@ -178,7 +178,7 @@
 }
 void RegressionTreeLeave::removeRow(int row, real target, real weight)
 {
-    length -= 1;
+    length_ -= 1;
     weights_sum -= weight;
     targets_sum -= target;
     real squared_target = pow(target, 2);
@@ -194,7 +194,7 @@
 
 void RegressionTreeLeave::getOutputAndError(Vec&amp; output, Vec&amp; error)const
 {
-    if(length&gt;0){
+    if(length_&gt;0){
         output[0] = weighted_targets_sum / weights_sum;
         if (missing_leave != true)
         {
@@ -226,7 +226,7 @@
 
 void RegressionTreeLeave::printStats()
 {
-    cout &lt;&lt; &quot; l &quot; &lt;&lt; length;
+    cout &lt;&lt; &quot; l &quot; &lt;&lt; length_;
     Vec output(2);
     Vec error(3);
     getOutputAndError(output,error);

Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.h	2008-12-15 19:04:10 UTC (rev 9779)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.h	2008-12-15 19:31:29 UTC (rev 9780)
@@ -71,7 +71,7 @@
   Learnt options: they are sized and initialized if need be, in initLeave(...)
 */
 
-    int  length;
+    int  length_;
     real weights_sum;
     real targets_sum;
     real weighted_targets_sum;
@@ -98,7 +98,7 @@
     inline void          registerRow(int row)
     {train_set-&gt;registerLeave(id, row);}
     inline int           getId()const{return id;}
-    inline int           getLength()const{return length;}
+    inline int           length()const{return length_;}
     virtual void         getOutputAndError(Vec&amp; output, Vec&amp; error)const;
     virtual void         printStats();
   

Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2008-12-15 19:04:10 UTC (rev 9779)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2008-12-15 19:31:29 UTC (rev 9780)
@@ -112,7 +112,7 @@
 
 void RegressionTreeMulticlassLeave::initStats()
 {
-    length = 0;
+    length_ = 0;
     weights_sum = 0.0;
     if (loss_function_weight != 0.0)
     {
@@ -144,7 +144,7 @@
 
 void RegressionTreeMulticlassLeave::addRow(int row, real target, real weight)
 {
-    length += 1;
+    length_ += 1;
     weights_sum += weight;
     int multiclass_found = 0;
     //if target are 0,1,2,... it can be optimized by multiclass_weights_sum[target]
@@ -184,11 +184,11 @@
 
 void RegressionTreeMulticlassLeave::removeRow(int row, real target, real weight)
 {
-    length -= 1;
+    length_ -= 1;
     weights_sum -= weight;
-    PLASSERT(length&gt;=0);
+    PLASSERT(length_&gt;=0);
     PLASSERT(weights_sum&gt;=0);
-    PLASSERT(length&gt;0 || weights_sum==0);
+    PLASSERT(length_&gt;0 || weights_sum==0);
     bool found=false;
     //can be optimized: see addRow
     for (int mc_ind = 0; mc_ind &lt; multiclass_outputs.length(); mc_ind++)
@@ -210,7 +210,7 @@
         PLERROR(&quot;In RegressionTreeMulticlassLeave::getOutputAndError() -&quot;
                 &quot; multiclass_outputs must not be empty&quot;);
 #endif
-    if(length==0){        
+    if(length_==0){        
         output.clear();
         output[0]=MISSING_VALUE;
         error.clear();
@@ -242,7 +242,7 @@
                 error[0] += abs(output[0] - multiclass_outputs[mc_ind]) 
                     * multiclass_weights_sum[mc_ind];
             }
-            error[0] *= l1_loss_function_factor * length / weights_sum;
+            error[0] *= l1_loss_function_factor * length_ / weights_sum;
             if (error[0] &lt; 1E-10) error[0] = 0.0;
             if (error[0] &gt; weights_sum * l1_loss_function_factor)
                 error[2] = weights_sum * l1_loss_function_factor;
@@ -255,19 +255,19 @@
                 error[0] += pow(output[0] - multiclass_outputs[mc_ind], 2) 
                     * multiclass_weights_sum[mc_ind];
             }
-            error[0] *= l2_loss_function_factor * length / weights_sum;
+            error[0] *= l2_loss_function_factor * length_ / weights_sum;
             if (error[0] &lt; 1E-10) error[0] = 0.0;
             if (error[0] &gt; weights_sum * l2_loss_function_factor) 
                 error[2] = weights_sum * l2_loss_function_factor; 
             else error[2] = error[0];
         }
-        error[1] = (1.0 - output[1]) * length;
+        error[1] = (1.0 - output[1]) * length_;
     }
 }
 
 void RegressionTreeMulticlassLeave::printStats()
 {
-    cout &lt;&lt; &quot; l &quot; &lt;&lt; length;
+    cout &lt;&lt; &quot; l &quot; &lt;&lt; length_;
     Vec output(2);
     Vec error(3);
     getOutputAndError(output,error);

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2008-12-15 19:04:10 UTC (rev 9779)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2008-12-15 19:31:29 UTC (rev 9780)
@@ -242,13 +242,13 @@
 //#define RCMP
 void RegressionTreeNode::lookForBestSplit()
 {
-    if(leave-&gt;getLength()&lt;=1)
+    if(leave-&gt;length()&lt;=1)
         return;
-    TVec&lt;RTR_type&gt; candidate(0, leave-&gt;getLength());//list of candidate row to split
-    TVec&lt;RTR_type&gt; registered_row(0, leave-&gt;getLength());
-    Vec registered_target(0, leave-&gt;getLength()); 
-    Vec registered_weight(0, leave-&gt;getLength());
-    Vec registered_value(0, leave-&gt;getLength());
+    TVec&lt;RTR_type&gt; candidate(0, leave-&gt;length());//list of candidate row to split
+    TVec&lt;RTR_type&gt; registered_row(0, leave-&gt;length());
+    Vec registered_target(0, leave-&gt;length()); 
+    Vec registered_weight(0, leave-&gt;length());
+    Vec registered_value(0, leave-&gt;length());
    tmp_vec.resize(2);
     Vec left_error(3);
     Vec right_error(3);
@@ -318,7 +318,7 @@
 #ifndef BY_ROW
         //in case of missing value
         if(candidate.size()==0){
-            PLASSERT(missing_leave-&gt;getLength()&gt;0);
+            PLASSERT(missing_leave-&gt;length()&gt;0);
             continue;
         }
         int row = candidate.pop();
@@ -408,8 +408,8 @@
             continue;
         real work_error = missing_errors + left_error[0]
             + left_error[1] + right_error[0] + right_error[1];
-        int work_balance = abs(left_leave-&gt;getLength() -
-                               right_leave-&gt;getLength());
+        int work_balance = abs(left_leave-&gt;length() -
+                               right_leave-&gt;length());
         if (fast_is_more(work_error,best_split_error)) continue;
         else if (fast_is_equal(work_error,best_split_error) &amp;&amp;
                  fast_is_more(work_balance,best_balance)) continue;
@@ -429,7 +429,7 @@
     PLASSERT(left_leave_last_feature&lt;=right_leave_first_feature);
     if (left_leave_last_feature &gt;= right_leave_first_feature) return;
     real work_error = missing_error[0] + missing_error[1] + left_error[0] + left_error[1] + right_error[0] + right_error[1];
-    int work_balance = abs(left_leave-&gt;getLength() - right_leave-&gt;getLength());
+    int work_balance = abs(left_leave-&gt;length() - right_leave-&gt;length());
     if (fast_is_more(work_error,after_split_error)) return;
     else if (fast_is_equal(work_error,after_split_error) &amp;&amp;
              fast_is_more(work_balance,split_balance)) return;


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003219.html">[Plearn-commits] r9779 - trunk/plearn_learners/regressors
</A></li>
	<LI>Next message: <A HREF="003221.html">[Plearn-commits] r9781 - trunk/plearn_learners/regressors
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3220">[ date ]</a>
              <a href="thread.html#3220">[ thread ]</a>
              <a href="subject.html#3220">[ subject ]</a>
              <a href="author.html#3220">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
