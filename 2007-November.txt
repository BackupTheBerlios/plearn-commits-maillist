From tihocan at mail.berlios.de  Fri Nov  2 15:54:19 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 2 Nov 2007 15:54:19 +0100
Subject: [Plearn-commits] r8223 - trunk/plearn_learners/generic/EXPERIMENTAL
Message-ID: <200711021454.lA2EsJmL021366@sheep.berlios.de>

Author: tihocan
Date: 2007-11-02 15:54:18 +0100 (Fri, 02 Nov 2007)
New Revision: 8223

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
Log:
Fixed bug with 'synchronize_update' set to true, where the program may stall due to unlucky race effects

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-10-30 20:30:02 UTC (rev 8222)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-11-02 14:54:18 UTC (rev 8223)
@@ -917,7 +917,7 @@
             while (true) {
             int sem_value = semctl(semaphore_id, 0, GETVAL);
             if (sem_value == iam) {
-                int n_ready = 2 * ncpus;
+                int n_ready = 0;
                 if (synchronize_update && !performed_update) {
                     // We first indicate that this CPU is ready to perform his
                     // update.
@@ -929,6 +929,8 @@
                     PLCHECK( success == 0 );
                 }
                 if (delayed_update && n_ready > ncpus && !performed_update) {
+                    // Once all CPUs are ready we can actually perform the
+                    // updates.
                     //printf("CPU %d updating (nsteps = %d)\n", iam, nsteps);
                     all_params += params_update;
                     params_update.clear();
@@ -942,6 +944,14 @@
                     params_int_ptr[stage_idx] = new_stage;
                     nsteps = 0;
                 }
+                if (n_ready == 2 * ncpus) {
+                    // The last CPU has updated the parameters. All CPUs can
+                    // now break out of this loop.
+                    n_ready = semun_v.val = 0;
+                    int success = semctl(semaphore_id, ncpus + 1, SETVAL,
+                                         semun_v);
+                    PLCHECK( success == 0 );
+                }
                 // Give update token to next CPU.
                 sem_value = (sem_value + 1) % ncpus;
                 semun_v.val = sem_value;
@@ -951,20 +961,18 @@
                             "semaphore with next CPU (errno = %d, returned "
                             "value = %d, set value = %d)", errno, success,
                             semun_v.val);
-                if (!delayed_update || n_ready >= 2 * ncpus)
+                if (!delayed_update || n_ready == 0)
                     // If 'synchronize_update' is false this is always true.
                     // If 'synchronize_update' is true this means all CPUs have
                     // updated the parameters.
                     break;
+            } else if (performed_update) {
+                // TODO We could break here by checking the 'n_ready'
+                // semaphore: once it is reset to zero everyone can exit at
+                // once without necessarily doing it in turn.
             }
             }
         }
-        if (synchronize_update && iam == 0) {
-            // Reset the 'ready' semaphore.
-            semun_v.val = 0;
-            int success = semctl(semaphore_id, ncpus + 1, SETVAL, semun_v);
-            PLCHECK( success == 0 );
-        }
         /*
         if (params_averaging_coeff!=1.0 && 
             b==minibatch_size-1 && 



From tihocan at mail.berlios.de  Fri Nov  2 18:22:10 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 2 Nov 2007 18:22:10 +0100
Subject: [Plearn-commits] r8224 - trunk/plearn_learners/generic/EXPERIMENTAL
Message-ID: <200711021722.lA2HMAlX030735@sheep.berlios.de>

Author: tihocan
Date: 2007-11-02 18:22:08 +0100 (Fri, 02 Nov 2007)
New Revision: 8224

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
Log:
Fixed bug introduced in previous commit that led to optimization not working when 'synchronize_update' was set to false

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-11-02 14:54:18 UTC (rev 8223)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-11-02 17:22:08 UTC (rev 8224)
@@ -928,7 +928,9 @@
                                          semun_v);
                     PLCHECK( success == 0 );
                 }
-                if (delayed_update && n_ready > ncpus && !performed_update) {
+                if (delayed_update && (!synchronize_update ||
+                                       (!performed_update && n_ready > ncpus)))
+                {
                     // Once all CPUs are ready we can actually perform the
                     // updates.
                     //printf("CPU %d updating (nsteps = %d)\n", iam, nsteps);



From nouiz at mail.berlios.de  Mon Nov  5 15:50:28 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 5 Nov 2007 15:50:28 +0100
Subject: [Plearn-commits] r8225 - trunk/plearn/vmat
Message-ID: <200711051450.lA5EoSFJ021027@sheep.berlios.de>

Author: nouiz
Date: 2007-11-05 15:50:28 +0100 (Mon, 05 Nov 2007)
New Revision: 8225

Modified:
   trunk/plearn/vmat/TextFilesVMatrix.cc
   trunk/plearn/vmat/TextFilesVMatrix.h
Log:
-Added a format num-comma, that are numeric value with a comma that separete the thousands
-Added an option that will will reorder the field spec in the same order as in the header of the source file.


Modified: trunk/plearn/vmat/TextFilesVMatrix.cc
===================================================================
--- trunk/plearn/vmat/TextFilesVMatrix.cc	2007-11-02 17:22:08 UTC (rev 8224)
+++ trunk/plearn/vmat/TextFilesVMatrix.cc	2007-11-05 14:50:28 UTC (rev 8225)
@@ -184,13 +184,85 @@
     return (ftype=="auto" || ftype=="num" || ftype=="date" || ftype=="jdate" ||
             ftype=="postal" || ftype=="dollar" || ftype=="dollar-comma" ||
             ftype=="YYYYMM" || ftype=="sas_date" || ftype == "bell_range" ||
-            ftype == "char" );
+            ftype == "char" || ftype=="num-comma" );
 }
 
 void TextFilesVMatrix::setColumnNamesAndWidth()
 {
     width_ = 0;
     TVec<string> fnames;
+    if(reorder_fieldspec_from_headers)
+    {
+        //the fieldnames read from the files.
+        TVec<string> fn;
+        for(int i=0; i<txtfiles.size(); i++)
+        {
+            FILE* f = txtfiles[i];
+            fseek(f,0,SEEK_SET);
+            if(!fgets(buf, sizeof(buf), f))
+                PLERROR("In TextFilesVMatrix::setColumnNamesAndWidth() - "
+                        "Couldn't read the fiedls names from file '%s'",
+                        txtfilenames[i].c_str());
+            fseek(f,0,SEEK_SET);
+
+            TVec<string> fields = splitIntoFields(buf);
+            fields.append(removeblanks(fields.pop()));
+
+            fn.append(fields);
+        }
+        if(fn.size()!=fieldspec.size())
+        {
+            PLWARNING("In TextFilesVMatrix::setColumnNamesAndWidth() - "
+                    "We read %d field names from the header but have %d"
+                    "fieldspec",fn.size(),fieldspec.size());
+        }
+
+        //check that all field names from the header have a spec
+        TVec<string> not_used_fn;
+        for(int i=0;i<fn.size();i++)
+        {
+            string name=fn[i];
+            int j=0;
+            for(;j<fieldspec.size();j++)
+                if(fieldspec[j].first==name)
+                    break;
+            if(j>=fieldspec.size())
+                not_used_fn.append(name);
+        }
+        //check that all fieldspec names are also in the header
+        TVec<string> not_used_fs;
+        for(int i=0;i<fieldspec.size();i++)
+        {
+            string name=fieldspec[i].first;
+            int j=0;
+            for(;j<fn.size();j++)
+                if(fn[j]==name)
+                    break;
+            if(j>=fn.size())
+                not_used_fs.append(name);
+        }
+        if(not_used_fs.size()!=0 || not_used_fn.size()!=0)
+            PLERROR("UNUSUED field names from header: %s\n"
+                    "UNUSUED fieldspec %s",tostring(not_used_fn).c_str(),
+                    tostring(not_used_fs).c_str());
+
+        //the new order for fieldspecs
+        TVec< pair<string, string> > fs(fn.size());
+        for(int i=0;i<fn.size();i++)
+        {
+            string name=fn[i];
+            int j=0;
+            for(;j<fieldspec.size();j++)
+                if(fieldspec[j].first==name)
+                    break;
+            if(j>=fieldspec.size())
+                PLERROR("In TextFilesVMatrix::setColumnNamesAndWidth() - "
+                        "fieldspec do not contain spec for field '%s'",
+                        name.c_str());
+            fs[i]=fieldspec[j];
+        }
+        fieldspec=fs;
+    }
     for(int k=0; k<fieldspec.length(); k++)
     {
         string fname = fieldspec[k].first;
@@ -215,12 +287,6 @@
 
 void TextFilesVMatrix::build_()
 {
-    // Initialize some sizespp
-    int n = fieldspec.size();
-    mapping.resize(n);
-    mapfiles.resize(n);
-    mapfiles.fill(0);
-
     if (metadatapath != "") {
         PLWARNING("In TextFilesVMatrix::build_: metadatapath option is deprecated. "
                   "You should use metadatadir instead.\n");
@@ -236,8 +302,6 @@
     PPath metadir = getMetaDataDir();
     PPath idxfname = metadir/"txtmat.idx";
 
-    setColumnNamesAndWidth();
-
     // Now open txtfiles
     int nf = txtfilenames.length();
     txtfiles.resize(nf);
@@ -251,6 +315,8 @@
         }
     }
 
+    setColumnNamesAndWidth();
+
     // open the index file
     if(!isfile(idxfname))
         buildIdx(); // (re)build it first!
@@ -259,6 +325,12 @@
         PLERROR("Wrong endianness. Remove the index file for it to be automatically rebuilt");
     fread(&length_, 4, 1, idxfile);
 
+    // Initialize some sizes
+    int n = fieldspec.size();
+    mapping.resize(n);
+    mapfiles.resize(n);
+    mapfiles.fill(0);
+
     // Handle string mapping
     loadMappings();
 
@@ -656,6 +728,22 @@
             dest[0] = (number_1 + number_2) / (real) 2;
         }
     }
+    else if(fieldtype=="num-comma")
+    {
+        string s="";
+        for(uint i=0;i<strval.length();i++)
+        {
+            if(strval[i]!=',')
+                s=s+strval[i];
+        }
+        if(s=="")  // missing
+            dest[0] = MISSING_VALUE;
+        else if(pl_isnumber(s,&val))
+            dest[0] = real(val);
+        else
+            PLERROR("In TextFilesVMatrix::transformStringToValue - expedted a number as the value for field %d(%s). Got %s",k,fieldname.c_str(),strval.c_str());
+                
+    }
 
     else
     {
@@ -714,6 +802,7 @@
                   "- skip       : Ignore the content of the field, won't be inserted in the resulting VMat\n"
                   "- auto       : If a numeric value, keep it as is, if not, look it up in the mapping (possibly inserting a new mapping if it's not there) \n"
                   "- num        : numeric value, keep as is\n"
+                  "- num-comma  : numeric value where thousands are separeted by comma\n"
                   "- char       : look it up in the mapping (possibly inserting a new mapping if it's not there)\n"
                   "- date       : date of the form 25DEC2003 or 25-dec-2003 or 2003/12/25 or 20031225, will be mapped to float date format 1031225\n"
                   "- jdate      : date of the form 25DEC2003 or 25-dec-2003 or 2003/12/25 or 20031225, will be mapped to *julian* date format\n"
@@ -737,7 +826,11 @@
                   OptionBase::buildoption,
                   "If true, standard vmatrix stringmap will be built from the txtmat specific stringmap");
 
-
+    declareOption(ol, "reorder_fieldspec_from_headers", 
+                  &TextFilesVMatrix::reorder_fieldspec_from_headers,
+                  OptionBase::buildoption,
+                  "If true, will reorder the fieldspec in the order gived "
+                  "by the field names taken from txtfilenames");
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
 }

Modified: trunk/plearn/vmat/TextFilesVMatrix.h
===================================================================
--- trunk/plearn/vmat/TextFilesVMatrix.h	2007-11-02 17:22:08 UTC (rev 8224)
+++ trunk/plearn/vmat/TextFilesVMatrix.h	2007-11-05 14:50:28 UTC (rev 8225)
@@ -126,6 +126,10 @@
     //! specific stringmap
     bool build_vmatrix_stringmap;
 
+    //! If true, will reorder the fieldspec in the order gived
+    //! by the field names taken from txtfilenames
+    bool reorder_fieldspec_from_headers;
+
     // ****************
     // * Constructors *
     // ****************



From nouiz at mail.berlios.de  Mon Nov  5 15:53:09 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 5 Nov 2007 15:53:09 +0100
Subject: [Plearn-commits] r8226 - in trunk: commands plearn/vmat
Message-ID: <200711051453.lA5Er9PP021183@sheep.berlios.de>

Author: nouiz
Date: 2007-11-05 15:53:09 +0100 (Mon, 05 Nov 2007)
New Revision: 8226

Added:
   trunk/plearn/vmat/MissingInstructionVMatrix.cc
   trunk/plearn/vmat/MissingInstructionVMatrix.h
Modified:
   trunk/commands/plearn_noblas_inc.h
Log:
Added a vmatrix sub class that allow to transform some value to missing depending of the instructions it receive


Modified: trunk/commands/plearn_noblas_inc.h
===================================================================
--- trunk/commands/plearn_noblas_inc.h	2007-11-05 14:50:28 UTC (rev 8225)
+++ trunk/commands/plearn_noblas_inc.h	2007-11-05 14:53:09 UTC (rev 8226)
@@ -309,6 +309,8 @@
 #include <plearn/vmat/LocalNeighborsDifferencesVMatrix.h>
 #include <plearn/vmat/LocallyPrecomputedVMatrix.h>
 #include <plearn/vmat/MeanImputationVMatrix.h>
+#include <plearn/vmat/MemoryVMatrixNoSave.h>
+#include <plearn/vmat/MissingInstructionVMatrix.h>
 //#include <plearn/vmat/MixUnlabeledNeighbourVMatrix.h>
 #include <plearn/vmat/MultiInstanceVMatrix.h>
 #include <plearn/vmat/MultiTargetOneHotVMatrix.h>

Added: trunk/plearn/vmat/MissingInstructionVMatrix.cc
===================================================================
--- trunk/plearn/vmat/MissingInstructionVMatrix.cc	2007-11-05 14:50:28 UTC (rev 8225)
+++ trunk/plearn/vmat/MissingInstructionVMatrix.cc	2007-11-05 14:53:09 UTC (rev 8226)
@@ -0,0 +1,242 @@
+// -*- C++ -*-
+
+// MissingInstructionVMatrix.cc
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file MissingInstructionVMatrix.cc */
+
+
+#include "MissingInstructionVMatrix.h"
+
+namespace PLearn {
+using namespace std;
+
+
+PLEARN_IMPLEMENT_OBJECT(
+    MissingInstructionVMatrix,
+    "Transform some value as missing following received instruction",
+    "NO HELP"
+    );
+
+MissingInstructionVMatrix::MissingInstructionVMatrix():
+    default_instruction("")
+/* ### Initialize all fields to their default value */
+{
+    // ...
+
+    // ### You may (or not) want to call build_() to finish building the object
+    // ### (doing so assumes the parent classes' build_() have been called too
+    // ### in the parent classes' constructors, something that you must ensure)
+}
+
+void MissingInstructionVMatrix::getNewRow(int i, const Vec& v) const
+{
+    // ...
+    source->getRow(i,tmp2);
+    for (int col = 0,merge_col = 0; col < source->width(); col++)
+    {
+        if (ins[col] == "skip") continue;
+        else if (ins[col] == "as_is")
+        {
+            v[merge_col] = tmp2[col];
+        }
+        else if (ins[col] == "zero_is_missing")
+        {
+            if (tmp2[col] == 0.0) v[merge_col] = MISSING_VALUE;
+            else v[merge_col] = tmp2[col];
+        }
+        else if (ins[col] == "2436935_is_missing")
+        {
+            if (tmp2[col] == 2436935.0) v[merge_col] = MISSING_VALUE;
+            else v[merge_col] = tmp2[col];
+        }
+        else if (ins[col] == "present")
+        {
+            if (is_missing(tmp2[col])) v[merge_col] = 0.0;
+            else v[merge_col] = 1.0;
+        }
+        merge_col +=1;
+    }
+}
+
+void MissingInstructionVMatrix::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    // ### ex:
+    // declareOption(ol, "myoption", &MissingInstructionVMatrix::myoption,
+    //               OptionBase::buildoption,
+    //               "Help text describing this option");
+    // ...
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+    declareOption(ol, "missing_instructions", &MissingInstructionVMatrix::missing_instructions,
+                  OptionBase::buildoption,
+                  "The variable missing regeneration instructions in the form of pairs field : instruction.\n"
+                  "Supported instructions are skip, as_is, zero_is_missing, 2436935_is_missing(01JAN1960 in julian day), present.");
+    declareOption(ol, "default_instruction",
+                  &MissingInstructionVMatrix::default_instruction,
+                  OptionBase::buildoption,
+                  "If some field in the source matrix have no instruction," 
+                  " we will use this instruction. We will warn about field"
+                  " with empty instruction then will stop.");
+}
+
+void MissingInstructionVMatrix::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+    length_ = source->length();
+    ins.resize(source->width());
+    tmp2.resize(source->width());
+    TVec<string> source_names = source->fieldNames();
+
+    //set default instruction
+    for (int col = 0; col < source->width(); col++)
+    {
+        ins[col] = default_instruction;
+    }
+    if(default_instruction!="skip")
+        width_=source->width();
+    else
+        width_=missing_instructions.size();
+    int missing_field = 0;
+    for (int ins_col = 0; ins_col < missing_instructions.size(); ins_col++)
+    {
+        int source_col = 0;
+        for (source_col = 0; source_col < source->width(); source_col++)
+        {
+            if (missing_instructions[ins_col].first == source_names[source_col]) break;
+        }
+        if (source_col >= source->width()) 
+        {
+            PLWARNING("In MissingInstructionVMatrix::build_() - missing_instructions '%d': no field with this name: '%s'" 
+                    ,ins_col,(missing_instructions[ins_col].first).c_str());
+            missing_field++;
+            continue;
+        }
+        if (missing_instructions[ins_col].second == "skip")
+            ins[source_col] = "skip";
+        else if (missing_instructions[ins_col].second == "as_is")
+            ins[source_col] = "as_is";
+        else if (missing_instructions[ins_col].second == "zero_is_missing")
+            ins[source_col] = "zero_is_missing";
+        else if (missing_instructions[ins_col].second == "2436935_is_missing")
+            ins[source_col] = "2436935_is_missing";
+        else if (missing_instructions[ins_col].second == "present")
+            ins[source_col] = "present";
+        else if (missing_instructions[ins_col].second.empty())
+            PLWARNING("In MergeDond2Files::build_() - merge instruction empty for field '%s', we keep the previous instruction who could be the default_instruction",(missing_instructions[source_col].first).c_str());
+        else PLERROR("In MergeDond2Files::build_() - unsupported merge instruction: '%s'", 
+                     (missing_instructions[ins_col].second).c_str());
+        if (ins[source_col] == "skip") width_--;
+    }
+    int missing_instruction = 0;
+    for (int col = 0; col < source->width(); col++)
+    {
+        if(ins[col] == "")
+        {
+            PLWARNING("In MissingInstructionVMatrix::build_ - their is no instruction for the field '%s'",
+                    source_names[col].c_str());
+            missing_instruction++;
+        }   
+    }
+    if(missing_instruction)
+        PLERROR("In MissingInstructionVMatrix::build_ - Their have been %d field in the source matrix that have no instruction",missing_instruction);
+    if(missing_field)
+        PLERROR("In MissingInstructionVMatrix::build_ - Their have been %d instruction that have no correcponding field in the source matrix",missing_field);
+
+    // Copy the appropriate VMFields
+    fieldinfos.resize(width());
+    if (source->getFieldInfos().size() > 0) {
+        for (int source_col=0,merge_col=0; source_col<source->width(); ++source_col) {
+            if(ins[source_col]!="skip"){
+                fieldinfos[merge_col] = source->getFieldInfos(source_col);
+                merge_col++;
+            }
+        }
+    }
+
+}
+
+// ### Nothing to add here, simply calls build_
+void MissingInstructionVMatrix::build()
+{
+    inherited::build();
+    build_();
+}
+
+void MissingInstructionVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all "pointer-like" fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+
+    // ### Remove this line when you have fully implemented this method.
+    PLERROR("MissingInstructionVMatrix::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!");
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/vmat/MissingInstructionVMatrix.h
===================================================================
--- trunk/plearn/vmat/MissingInstructionVMatrix.h	2007-11-05 14:50:28 UTC (rev 8225)
+++ trunk/plearn/vmat/MissingInstructionVMatrix.h	2007-11-05 14:53:09 UTC (rev 8226)
@@ -0,0 +1,148 @@
+// -*- C++ -*-
+
+// MissingInstructionVMatrix.h
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file MissingInstructionVMatrix.h */
+
+
+#ifndef MissingInstructionVMatrix_INC
+#define MissingInstructionVMatrix_INC
+
+#include <plearn/vmat/SourceVMatrix.h>
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class MissingInstructionVMatrix : public SourceVMatrix
+{
+    typedef SourceVMatrix inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! The variable missing regeneration instructions in the form of pairs field : instruction.
+    //! Supported instructions are skip, as_is, zero_is_missing, 2436935_is_missing.
+    TVec< pair<string, string> >  missing_instructions;
+
+    //! If some field in the source matrix have no instruction, we will use 
+    //! this instruction. Will warn about field with empty instruction then stop.
+    string default_instruction;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    MissingInstructionVMatrix();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(MissingInstructionVMatrix);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+    //! Fill the vector 'v' with the content of the i-th row.
+    //! 'v' is assumed to be the right size.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void getNewRow(int i, const Vec& v) const;
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    TVec<string> ins;
+    mutable Vec tmp2;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(MissingInstructionVMatrix);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From nouiz at mail.berlios.de  Mon Nov  5 16:01:47 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 5 Nov 2007 16:01:47 +0100
Subject: [Plearn-commits] r8227 - trunk/commands
Message-ID: <200711051501.lA5F1lNr024921@sheep.berlios.de>

Author: nouiz
Date: 2007-11-05 16:01:46 +0100 (Mon, 05 Nov 2007)
New Revision: 8227

Modified:
   trunk/commands/plearn_noblas_inc.h
Log:
corrected last commit


Modified: trunk/commands/plearn_noblas_inc.h
===================================================================
--- trunk/commands/plearn_noblas_inc.h	2007-11-05 14:53:09 UTC (rev 8226)
+++ trunk/commands/plearn_noblas_inc.h	2007-11-05 15:01:46 UTC (rev 8227)
@@ -309,7 +309,6 @@
 #include <plearn/vmat/LocalNeighborsDifferencesVMatrix.h>
 #include <plearn/vmat/LocallyPrecomputedVMatrix.h>
 #include <plearn/vmat/MeanImputationVMatrix.h>
-#include <plearn/vmat/MemoryVMatrixNoSave.h>
 #include <plearn/vmat/MissingInstructionVMatrix.h>
 //#include <plearn/vmat/MixUnlabeledNeighbourVMatrix.h>
 #include <plearn/vmat/MultiInstanceVMatrix.h>



From nouiz at mail.berlios.de  Mon Nov  5 20:05:51 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 5 Nov 2007 20:05:51 +0100
Subject: [Plearn-commits] r8228 - trunk/plearn/base
Message-ID: <200711051905.lA5J5prT024659@sheep.berlios.de>

Author: nouiz
Date: 2007-11-05 20:05:50 +0100 (Mon, 05 Nov 2007)
New Revision: 8228

Modified:
   trunk/plearn/base/stringutils.cc
Log:
remove duplicate doxygen comment


Modified: trunk/plearn/base/stringutils.cc
===================================================================
--- trunk/plearn/base/stringutils.cc	2007-11-05 15:01:46 UTC (rev 8227)
+++ trunk/plearn/base/stringutils.cc	2007-11-05 19:05:50 UTC (rev 8228)
@@ -185,7 +185,6 @@
     return s.substr(0,pos);
 }
 
-//! Utility function to strip a string of leading and trailing quotes
 string removequotes(const string& s)
 {
     const int n = int(s.size());
@@ -197,7 +196,6 @@
     return s;
 }
 
-//! Quote the provided string 's'
 string quote_string(const string& s)
 {
     string quoted(s);



From nouiz at mail.berlios.de  Wed Nov  7 20:02:11 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 7 Nov 2007 20:02:11 +0100
Subject: [Plearn-commits] r8229 - in trunk: commands plearn/vmat
Message-ID: <200711071902.lA7J2B57031456@sheep.berlios.de>

Author: nouiz
Date: 2007-11-07 20:02:11 +0100 (Wed, 07 Nov 2007)
New Revision: 8229

Added:
   trunk/plearn/vmat/MemoryVMatrixNoSave.cc
   trunk/plearn/vmat/MemoryVMatrixNoSave.h
Modified:
   trunk/commands/plearn_noblas_inc.h
Log:
New VMatrix that is stored in memory, but that do not serialize the data. The data is supposed to can reconstructed at deserialization from the source


Modified: trunk/commands/plearn_noblas_inc.h
===================================================================
--- trunk/commands/plearn_noblas_inc.h	2007-11-05 19:05:50 UTC (rev 8228)
+++ trunk/commands/plearn_noblas_inc.h	2007-11-07 19:02:11 UTC (rev 8229)
@@ -309,6 +309,7 @@
 #include <plearn/vmat/LocalNeighborsDifferencesVMatrix.h>
 #include <plearn/vmat/LocallyPrecomputedVMatrix.h>
 #include <plearn/vmat/MeanImputationVMatrix.h>
+#include <plearn/vmat/MemoryVMatrixNoSave.h>
 #include <plearn/vmat/MissingInstructionVMatrix.h>
 //#include <plearn/vmat/MixUnlabeledNeighbourVMatrix.h>
 #include <plearn/vmat/MultiInstanceVMatrix.h>

Added: trunk/plearn/vmat/MemoryVMatrixNoSave.cc
===================================================================
--- trunk/plearn/vmat/MemoryVMatrixNoSave.cc	2007-11-05 19:05:50 UTC (rev 8228)
+++ trunk/plearn/vmat/MemoryVMatrixNoSave.cc	2007-11-07 19:02:11 UTC (rev 8229)
@@ -0,0 +1,132 @@
+// -*- C++ -*-
+
+// MemoryVMatrixNoSave.cc
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file MemoryVMatrixNoSave.cc */
+
+
+#include "MemoryVMatrixNoSave.h"
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    MemoryVMatrixNoSave,
+    "A MemoryVMatrix that will not save the data in memory with the object.",
+    "It is supposed you can reconstruct the data from the source."
+    );
+
+//////////////////
+// MemoryVMatrixNoSave //
+//////////////////
+MemoryVMatrixNoSave::MemoryVMatrixNoSave()
+/* ### Initialize all fields to their default value here */
+{
+    // ...
+
+    // ### You may (or not) want to call build_() to finish building the object
+    // ### (doing so assumes the parent classes' build_() have been called too
+    // ### in the parent classes' constructors, something that you must ensure)
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void MemoryVMatrixNoSave::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    // ### ex:
+    // declareOption(ol, "myoption", &MemoryVMatrixNoSave::myoption,
+    //               OptionBase::buildoption,
+    //               "Help text describing this option");
+    // ...
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+    redeclareOption(ol, "data", &MemoryVMatrix::data,
+                    OptionBase::buildoption|OptionBase::nosave,
+                    "The external Mat source. Not saved");
+
+}
+
+///////////
+// build //
+///////////
+void MemoryVMatrixNoSave::build()
+{
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void MemoryVMatrixNoSave::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+}
+
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/vmat/MemoryVMatrixNoSave.h
===================================================================
--- trunk/plearn/vmat/MemoryVMatrixNoSave.h	2007-11-05 19:05:50 UTC (rev 8228)
+++ trunk/plearn/vmat/MemoryVMatrixNoSave.h	2007-11-07 19:02:11 UTC (rev 8229)
@@ -0,0 +1,133 @@
+// -*- C++ -*-
+
+// MemoryVMatrixNoSave.h
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file MemoryVMatrixNoSave.h */
+
+
+#ifndef MemoryVMatrixNoSave_INC
+#define MemoryVMatrixNoSave_INC
+
+#include <plearn/vmat/MemoryVMatrix.h>
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class MemoryVMatrixNoSave : public MemoryVMatrix
+{
+    typedef MemoryVMatrix inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    MemoryVMatrixNoSave();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(MemoryVMatrixNoSave);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+//    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(MemoryVMatrixNoSave);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From nouiz at mail.berlios.de  Wed Nov  7 21:48:13 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 7 Nov 2007 21:48:13 +0100
Subject: [Plearn-commits] r8230 - trunk/plearn/display
Message-ID: <200711072048.lA7KmDSK004859@sheep.berlios.de>

Author: nouiz
Date: 2007-11-07 21:48:13 +0100 (Wed, 07 Nov 2007)
New Revision: 8230

Modified:
   trunk/plearn/display/DisplayUtils.h
   trunk/plearn/display/GhostScript.h
   trunk/plearn/display/Gnuplot.h
   trunk/plearn/display/MatlabInterface.h
   trunk/plearn/display/RGBImage.h
Log:
corrected path for doxygen


Modified: trunk/plearn/display/DisplayUtils.h
===================================================================
--- trunk/plearn/display/DisplayUtils.h	2007-11-07 19:02:11 UTC (rev 8229)
+++ trunk/plearn/display/DisplayUtils.h	2007-11-07 20:48:13 UTC (rev 8230)
@@ -44,7 +44,7 @@
    ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnUtil/DisplayUtils.h */
+/*! \file PLearn/plearn/display/DisplayUtils.h */
 
 #ifndef DISPLAYUTILS_INC
 #define DISPLAYUTILS_INC

Modified: trunk/plearn/display/GhostScript.h
===================================================================
--- trunk/plearn/display/GhostScript.h	2007-11-07 19:02:11 UTC (rev 8229)
+++ trunk/plearn/display/GhostScript.h	2007-11-07 20:48:13 UTC (rev 8230)
@@ -43,7 +43,7 @@
    ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnUtil/GhostScript.h */
+/*! \file PLearn/plearn/display/GhostScript.h */
 
 #ifndef GHOSTSCRIPT_INC
 #define GHOSTSCRIPT_INC

Modified: trunk/plearn/display/Gnuplot.h
===================================================================
--- trunk/plearn/display/Gnuplot.h	2007-11-07 19:02:11 UTC (rev 8229)
+++ trunk/plearn/display/Gnuplot.h	2007-11-07 20:48:13 UTC (rev 8230)
@@ -43,7 +43,7 @@
    ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnUtil/Gnuplot.h */
+/*! \file PLearn/plearn/display/Gnuplot.h */
 
 #ifndef GNUPLOT_INC
 #define GNUPLOT_INC

Modified: trunk/plearn/display/MatlabInterface.h
===================================================================
--- trunk/plearn/display/MatlabInterface.h	2007-11-07 19:02:11 UTC (rev 8229)
+++ trunk/plearn/display/MatlabInterface.h	2007-11-07 20:48:13 UTC (rev 8230)
@@ -41,7 +41,7 @@
    ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnUtil/MatlabInterface.h */
+/*! \file PLearn/plearn/display/MatlabInterface.h */
 
 #ifndef MATLAB_INTERFACE_INC
 #define MATLAB_INTERFACE_INC

Modified: trunk/plearn/display/RGBImage.h
===================================================================
--- trunk/plearn/display/RGBImage.h	2007-11-07 19:02:11 UTC (rev 8229)
+++ trunk/plearn/display/RGBImage.h	2007-11-07 20:48:13 UTC (rev 8230)
@@ -43,7 +43,7 @@
    ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnUtil/RGBImage.h */
+/*! \file PLearn/plearn/display/RGBImage.h */
 
 #ifndef RGBIMAGE_INC
 #define RGBIMAGE_INC



From nouiz at mail.berlios.de  Wed Nov  7 21:50:01 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 7 Nov 2007 21:50:01 +0100
Subject: [Plearn-commits] r8231 - trunk/plearn/db
Message-ID: <200711072050.lA7Ko1dv004934@sheep.berlios.de>

Author: nouiz
Date: 2007-11-07 21:50:01 +0100 (Wed, 07 Nov 2007)
New Revision: 8231

Modified:
   trunk/plearn/db/AutoSDBVMatrix.h
   trunk/plearn/db/NistDB.h
   trunk/plearn/db/SDBVMat.h
   trunk/plearn/db/SDBWithStats.h
   trunk/plearn/db/SimpleDB.h
   trunk/plearn/db/databases.h
Log:
corrected path for doxygen


Modified: trunk/plearn/db/AutoSDBVMatrix.h
===================================================================
--- trunk/plearn/db/AutoSDBVMatrix.h	2007-11-07 20:48:13 UTC (rev 8230)
+++ trunk/plearn/db/AutoSDBVMatrix.h	2007-11-07 20:50:01 UTC (rev 8231)
@@ -42,7 +42,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file PLearn/plearn/db/AutoSDBVMatrix.h */
 
 #ifndef AutoSDBVMatrix_INC
 #define AutoSDBVMatrix_INC

Modified: trunk/plearn/db/NistDB.h
===================================================================
--- trunk/plearn/db/NistDB.h	2007-11-07 20:48:13 UTC (rev 8230)
+++ trunk/plearn/db/NistDB.h	2007-11-07 20:50:01 UTC (rev 8231)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file Databases/NistDB.h */
+/*! \file PLearn/plearn/db/NistDB.h */
 
 #ifndef NistDB_INC
 #define NistDB_INC

Modified: trunk/plearn/db/SDBVMat.h
===================================================================
--- trunk/plearn/db/SDBVMat.h	2007-11-07 20:48:13 UTC (rev 8230)
+++ trunk/plearn/db/SDBVMat.h	2007-11-07 20:50:01 UTC (rev 8231)
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnUtil/SDBVMat.h */
+/*! \file PLearn/plearn/db/SDBVMat.h */
 
 #ifndef NGSDBVMAT_H
 #define NGSDBVMAT_H

Modified: trunk/plearn/db/SDBWithStats.h
===================================================================
--- trunk/plearn/db/SDBWithStats.h	2007-11-07 20:48:13 UTC (rev 8230)
+++ trunk/plearn/db/SDBWithStats.h	2007-11-07 20:50:01 UTC (rev 8231)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnUtil/SDBWithStats.h */
+/*! \file PLearn/plearn/db/SDBWithStats.h */
 
 #ifndef SDBWithStats_INC
 #define SDBWithStats_INC

Modified: trunk/plearn/db/SimpleDB.h
===================================================================
--- trunk/plearn/db/SimpleDB.h	2007-11-07 20:48:13 UTC (rev 8230)
+++ trunk/plearn/db/SimpleDB.h	2007-11-07 20:50:01 UTC (rev 8231)
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnUtil/SimpleDB.h */
+/*! \file PLearn/plearn/db/SimpleDB.h */
 
 #ifndef SIMPLEDB_H
 #define SIMPLEDB_H

Modified: trunk/plearn/db/databases.h
===================================================================
--- trunk/plearn/db/databases.h	2007-11-07 20:48:13 UTC (rev 8230)
+++ trunk/plearn/db/databases.h	2007-11-07 20:50:01 UTC (rev 8231)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file Databases/databases.h */
+/*! \file PLearn/plearn/db/databases.h */
 
 #ifndef DATABASES_INC
 #define DATABASES_INC



From nouiz at mail.berlios.de  Wed Nov  7 21:52:18 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 7 Nov 2007 21:52:18 +0100
Subject: [Plearn-commits] r8232 - trunk/plearn/io
Message-ID: <200711072052.lA7KqI4a005052@sheep.berlios.de>

Author: nouiz
Date: 2007-11-07 21:52:17 +0100 (Wed, 07 Nov 2007)
New Revision: 8232

Modified:
   trunk/plearn/io/IntStream.h
   trunk/plearn/io/IntVecFile.h
   trunk/plearn/io/MPIStream.h
   trunk/plearn/io/TmpFilenames.h
   trunk/plearn/io/TypesNumeriques.h
   trunk/plearn/io/fileutils.h
   trunk/plearn/io/pl_NSPR_io.cc
   trunk/plearn/io/pl_NSPR_io.h
   trunk/plearn/io/pl_io.cc
   trunk/plearn/io/pl_io.h
   trunk/plearn/io/pl_io_deprecated.cc
   trunk/plearn/io/pl_io_deprecated.h
   trunk/plearn/io/plstreams.h
Log:
corrected path for doxygen


Modified: trunk/plearn/io/IntStream.h
===================================================================
--- trunk/plearn/io/IntStream.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/IntStream.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -43,7 +43,7 @@
 */
 
 
-/*! \file PLearnLibrary/PLearnCore/IntStream.h */
+/*! \file PLearn/plearn/io/IntStream.h */
 
 #ifndef MODULE_INTSTREAM
 #define MODULE_INTSTREAM

Modified: trunk/plearn/io/IntVecFile.h
===================================================================
--- trunk/plearn/io/IntVecFile.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/IntVecFile.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/IntVecFile.h */
+/*! \file PLearn/plearn/io/IntVecFile.h */
 
 #ifndef IntVecFile_INC
 #define IntVecFile_INC

Modified: trunk/plearn/io/MPIStream.h
===================================================================
--- trunk/plearn/io/MPIStream.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/MPIStream.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/MPIStream.h */
+/*! \file PLearn/plearn/io/MPIStream.h */
 
 #ifndef MPIStream_INC
 #define MPIStream_INC

Modified: trunk/plearn/io/TmpFilenames.h
===================================================================
--- trunk/plearn/io/TmpFilenames.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/TmpFilenames.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnUtil/TmpFilenames.h */
+/*! \file PLearn/plearn/io/TmpFilenames.h */
 
 #ifndef TmpFilenames_INC
 #define TmpFilenames_INC

Modified: trunk/plearn/io/TypesNumeriques.h
===================================================================
--- trunk/plearn/io/TypesNumeriques.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/TypesNumeriques.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -45,7 +45,7 @@
 // special codes (see "rules" below).
 
 
-/*! \file PLearnLibrary/PLearnUtil/TypesNumeriques.h */
+/*! \file PLearn/plearn/io/TypesNumeriques.h */
 
 #ifndef MODULE_TYPES_NUMERIQUES
 #define MODULE_TYPES_NUMERIQUES

Modified: trunk/plearn/io/fileutils.h
===================================================================
--- trunk/plearn/io/fileutils.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/fileutils.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -45,7 +45,7 @@
 // that are used in the PLearn Library
 
 
-/*! \file PLearnLibrary/PLearnCore/fileutils.h */
+/*! \file PLearn/plearn/io/fileutils.h */
 
 #ifndef fileutils_INC
 #define fileutils_INC

Modified: trunk/plearn/io/pl_NSPR_io.cc
===================================================================
--- trunk/plearn/io/pl_NSPR_io.cc	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/pl_NSPR_io.cc	2007-11-07 20:52:17 UTC (rev 8232)
@@ -40,7 +40,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/pl_NSPR_io.cc */
+/*! \file PLearn/plearn/io/pl_NSPR_io.cc */
 
 #include "pl_NSPR_io.h"
 #include <plearn/base/byte_order.h>   //!< For endianswap.

Modified: trunk/plearn/io/pl_NSPR_io.h
===================================================================
--- trunk/plearn/io/pl_NSPR_io.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/pl_NSPR_io.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -41,7 +41,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/pl_NSPR_io.h */
+/*! \file PLearn/plearn/io/pl_NSPR_io.h */
 
 #ifndef pl_NSPR_io_INC
 #define pl_NSPR_io_INC

Modified: trunk/plearn/io/pl_io.cc
===================================================================
--- trunk/plearn/io/pl_io.cc	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/pl_io.cc	2007-11-07 20:52:17 UTC (rev 8232)
@@ -44,7 +44,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/pl_io.cc */
+/*! \file PLearn/plearn/io/pl_io.cc */
 
 //#include <limits>
 #include "pl_io.h"

Modified: trunk/plearn/io/pl_io.h
===================================================================
--- trunk/plearn/io/pl_io.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/pl_io.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/pl_io.h */
+/*! \file PLearn/plearn/io/pl_io.h */
 
 #ifndef pl_io_INC
 #define pl_io_INC

Modified: trunk/plearn/io/pl_io_deprecated.cc
===================================================================
--- trunk/plearn/io/pl_io_deprecated.cc	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/pl_io_deprecated.cc	2007-11-07 20:52:17 UTC (rev 8232)
@@ -42,7 +42,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/pl_io.cc */
+/*! \file PLearn/plearn/io/pl_io_deprecated.cc */
 
 #include "pl_io_deprecated.h"
 #include <plearn/base/stringutils.h>

Modified: trunk/plearn/io/pl_io_deprecated.h
===================================================================
--- trunk/plearn/io/pl_io_deprecated.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/pl_io_deprecated.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/pl_io.h */
+/*! \file PLearn/plearn/io/pl_io_deprecated.h */
 
 #ifndef pl_io_deprecated_INC
 #define pl_io_deprecated_INC

Modified: trunk/plearn/io/plstreams.h
===================================================================
--- trunk/plearn/io/plstreams.h	2007-11-07 20:50:01 UTC (rev 8231)
+++ trunk/plearn/io/plstreams.h	2007-11-07 20:52:17 UTC (rev 8232)
@@ -46,7 +46,7 @@
 // that are used in the PLearn Library
 
 
-/*! \file PLearnLibrary/PLearnCore/plstreams.h */
+/*! \file PLearn/plearn/io/plstreams.h */
 
 #ifndef plstreams_INC
 #define plstreams_INC



From nouiz at mail.berlios.de  Wed Nov  7 21:54:28 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 7 Nov 2007 21:54:28 +0100
Subject: [Plearn-commits] r8233 - trunk/plearn/ker
Message-ID: <200711072054.lA7KsSSB005167@sheep.berlios.de>

Author: nouiz
Date: 2007-11-07 21:54:27 +0100 (Wed, 07 Nov 2007)
New Revision: 8233

Modified:
   trunk/plearn/ker/CompactVMatrixGaussianKernel.h
   trunk/plearn/ker/CompactVMatrixPolynomialKernel.h
Log:
corrected path for doxygen


Modified: trunk/plearn/ker/CompactVMatrixGaussianKernel.h
===================================================================
--- trunk/plearn/ker/CompactVMatrixGaussianKernel.h	2007-11-07 20:52:17 UTC (rev 8232)
+++ trunk/plearn/ker/CompactVMatrixGaussianKernel.h	2007-11-07 20:54:27 UTC (rev 8233)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Kernel.h */
+/*! \file PLearn/plearn/ker/CompactVMatrixGaussianKernel.h */
 
 #ifndef CompactVMatrixGaussianKernel_INC
 #define CompactVMatrixGaussianKernel_INC

Modified: trunk/plearn/ker/CompactVMatrixPolynomialKernel.h
===================================================================
--- trunk/plearn/ker/CompactVMatrixPolynomialKernel.h	2007-11-07 20:52:17 UTC (rev 8232)
+++ trunk/plearn/ker/CompactVMatrixPolynomialKernel.h	2007-11-07 20:54:27 UTC (rev 8233)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Kernel.h */
+/*! \file PLearn/plearn/ker/CompactVMatrixPolynomialKernel.h */
 
 #ifndef CompactVMatrixPolynomialKernel_INC
 #define CompactVMatrixPolynomialKernel_INC



From nouiz at mail.berlios.de  Wed Nov  7 22:24:24 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 7 Nov 2007 22:24:24 +0100
Subject: [Plearn-commits] r8234 - trunk/plearn/math
Message-ID: <200711072124.lA7LOOAk006608@sheep.berlios.de>

Author: nouiz
Date: 2007-11-07 22:24:23 +0100 (Wed, 07 Nov 2007)
New Revision: 8234

Modified:
   trunk/plearn/math/StatsCollector.cc
   trunk/plearn/math/StatsCollector.h
Log:
exported StatsCollector functions to python


Modified: trunk/plearn/math/StatsCollector.cc
===================================================================
--- trunk/plearn/math/StatsCollector.cc	2007-11-07 20:54:27 UTC (rev 8233)
+++ trunk/plearn/math/StatsCollector.cc	2007-11-07 21:24:23 UTC (rev 8234)
@@ -50,6 +50,7 @@
 #include <assert.h>
 #include <plearn/io/openString.h>
 #include <plearn/math/random.h>   //!< For shuffleRows().
+#include <plearn/base/RemoteDeclareMethod.h>
 
 
 namespace PLearn {
@@ -317,6 +318,127 @@
     inherited::declareOptions(ol);
 }
 
+void StatsCollector::declareMethods(RemoteMethodMap& rmm)
+{
+    // Insert a backpointer to remote methods; note that this
+    // different than for declareOptions()
+    rmm.inherited(inherited::_getRemoteMethodMap_());
+    declareMethod(
+        rmm, "n", &StatsCollector::n,
+        (BodyDoc("Returns the total number of value seen\n"),
+         RetDoc ("n")));
+
+    declareMethod(
+        rmm, "nmissing", &StatsCollector::nmissing,
+        (BodyDoc("Return the total number of missing value seen\n"),
+         RetDoc ("nmissing")));
+
+    declareMethod(
+        rmm, "nnonmissing", &StatsCollector::nnonmissing,
+        (BodyDoc("Return the total number of non missing value seen\n"),
+         RetDoc ("nnonmissing")));
+
+    declareMethod(
+        rmm, "sumsquarew", &StatsCollector::sumsquarew,
+        (BodyDoc("Return sumsquarew of the seen value\n"),
+         RetDoc ("sumsquarew")));
+
+    declareMethod(
+        rmm, "sum", &StatsCollector::sum,
+        (BodyDoc("Return sum of the seen value\n"),
+         RetDoc ("sum")));
+
+    declareMethod(
+        rmm, "sumsquare", &StatsCollector::sumsquare,
+        (BodyDoc("Return sumsquare of the seen value\n"),
+         RetDoc ("sumsquare")));
+
+    declareMethod(
+        rmm, "min", &StatsCollector::min,
+        (BodyDoc("Return the minimum value seeup to date\n"),
+         RetDoc ("the minimum")));
+
+    declareMethod(
+        rmm, "max", &StatsCollector::max,
+        (BodyDoc("Return the maximum value see up to date\n"),
+         RetDoc ("the maximum")));
+
+    declareMethod(
+        rmm, "agemin", &StatsCollector::agemin,
+        (BodyDoc("Return the agemin value\n"),
+         RetDoc ("agemin")));
+
+    declareMethod(
+        rmm, "agemax", &StatsCollector::agemax,
+        (BodyDoc("Return the agemax value\n"),
+         RetDoc ("agemax")));
+
+    declareMethod(
+        rmm, "range", &StatsCollector::range,
+        (BodyDoc("Return min - max\n"),
+         RetDoc ("min - max")));
+
+    declareMethod(
+        rmm, "mean", &StatsCollector::mean,
+        (BodyDoc("Return mean of the seen value\n"),
+         RetDoc ("sum/nnonmissing")));
+
+    declareMethod(
+        rmm, "variance", &StatsCollector::variance,
+        (BodyDoc("Return the variance of the seen value\n"),
+         RetDoc ("variance")));
+
+    declareMethod(
+        rmm, "stddev", &StatsCollector::stddev,
+        (BodyDoc("Return stddev of the seen value\n"),
+         RetDoc ("stddev")));
+
+    declareMethod(
+        rmm, "skewness", &StatsCollector::skewness,
+        (BodyDoc("Return skewness of the seen value\n"),
+         RetDoc ("skewness")));
+
+    declareMethod(
+        rmm, "kurtosis", &StatsCollector::kurtosis,
+        (BodyDoc("Return kurtosis of the seen value\n"),
+         RetDoc ("kurtosis")));
+
+    declareMethod(
+        rmm, "stderror", &StatsCollector::stderror,
+        (BodyDoc("Return stderror of the seen value\n"),
+         RetDoc ("stderror")));
+
+    declareMethod(
+        rmm, "first_obs", &StatsCollector::first_obs,
+        (BodyDoc("Return first_obs of the seen value\n"),
+         RetDoc ("first_obs")));
+
+    declareMethod(
+        rmm, "last_obs", &StatsCollector::last_obs,
+        (BodyDoc("Return last_obs of the seen value\n"),
+         RetDoc ("last_obs")));
+
+    declareMethod(
+        rmm, "sharperatio", &StatsCollector::sharperatio,
+        (BodyDoc("Return sharperatio of the seen value\n"),
+         RetDoc ("sharperatio")));
+
+    declareMethod(
+        rmm, "mean_over_skewness", &StatsCollector::mean_over_skewness,
+        (BodyDoc("Return mean_over_skewness of the seen value\n"),
+         RetDoc ("mean_over_skewness")));
+
+    declareMethod(
+        rmm, "mean_over_skewness_ms", &StatsCollector::mean_over_skewness_ms,
+        (BodyDoc("Return mean_over_skewness_ms of the seen value\n"),
+         RetDoc ("mean_over_skewness_ms")));
+
+    declareMethod(
+        rmm, "mean_over_kurtosis", &StatsCollector::mean_over_kurtosis,
+        (BodyDoc("Return mean_over_kurtosis of the seen value\n"),
+         RetDoc ("mean_over_kurtosis")));
+
+}
 ////////////
 // build_ //
 ////////////

Modified: trunk/plearn/math/StatsCollector.h
===================================================================
--- trunk/plearn/math/StatsCollector.h	2007-11-07 20:54:27 UTC (rev 8233)
+++ trunk/plearn/math/StatsCollector.h	2007-11-07 21:24:23 UTC (rev 8234)
@@ -213,6 +213,9 @@
     //! Declares this class' options
     static void declareOptions(OptionList& ol);
 
+    //! Declare the methods that are remote-callable
+    static void declareMethods(RemoteMethodMap& rmm);
+
     //! Sort values stored in 'counts' by magnitude, so as to fill 'sorted_values'.
     void sort_values_by_magnitude() const;
 



From nouiz at mail.berlios.de  Wed Nov  7 22:32:03 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 7 Nov 2007 22:32:03 +0100
Subject: [Plearn-commits] r8235 - in trunk/plearn/math: . DEPRECATED
Message-ID: <200711072132.lA7LW3F9006964@sheep.berlios.de>

Author: nouiz
Date: 2007-11-07 22:32:01 +0100 (Wed, 07 Nov 2007)
New Revision: 8235

Modified:
   trunk/plearn/math/BottomNI.h
   trunk/plearn/math/DEPRECATED/StatsIterator.h
   trunk/plearn/math/GenMat.h
   trunk/plearn/math/Hash.h
   trunk/plearn/math/Mat.h
   trunk/plearn/math/RowMapSparseMatrix.h
   trunk/plearn/math/RowMapSparseValueMatrix.h
   trunk/plearn/math/SparseMatrix.h
   trunk/plearn/math/TMat.h
   trunk/plearn/math/TMatColRowsIterator_decl.h
   trunk/plearn/math/TMatColRowsIterator_impl.h
   trunk/plearn/math/TMatElementIterator_decl.h
   trunk/plearn/math/TMatElementIterator_impl.h
   trunk/plearn/math/TMatRowsAsArraysIterator_decl.h
   trunk/plearn/math/TMatRowsAsArraysIterator_impl.h
   trunk/plearn/math/TMatRowsIterator_decl.h
   trunk/plearn/math/TMatRowsIterator_impl.h
   trunk/plearn/math/TMat_decl.h
   trunk/plearn/math/TMat_impl.h
   trunk/plearn/math/TMat_maths.h
   trunk/plearn/math/TMat_maths_impl.h
   trunk/plearn/math/TMat_sort.h
   trunk/plearn/math/distr_maths.cc
   trunk/plearn/math/pl_erf.h
   trunk/plearn/math/pl_math.cc
   trunk/plearn/math/pl_math.h
   trunk/plearn/math/plapack.h
   trunk/plearn/math/stats_utils.cc
Log:
corrected path for doxygen


Modified: trunk/plearn/math/BottomNI.h
===================================================================
--- trunk/plearn/math/BottomNI.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/BottomNI.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/BottomNI.h */
+/*! \file PLearn/plearn/math/BottomNI.h */
 
 #ifndef BottomNI_INC
 #define BottomNI_INC

Modified: trunk/plearn/math/DEPRECATED/StatsIterator.h
===================================================================
--- trunk/plearn/math/DEPRECATED/StatsIterator.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/DEPRECATED/StatsIterator.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/StatsIterator.h */
+/*! \file PLearn/plearn/math/DEPRECATED/StatsIterator.h */
 
 #ifndef StatsIterator_INC
 #define StatsIterator_INC

Modified: trunk/plearn/math/GenMat.h
===================================================================
--- trunk/plearn/math/GenMat.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/GenMat.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -44,7 +44,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Mat_maths.h */
+/*! \file PLearn/plearn/math/GenMat.h */
 
 #ifndef GenMat_INC
 #define GenMat_INC

Modified: trunk/plearn/math/Hash.h
===================================================================
--- trunk/plearn/math/Hash.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/Hash.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -41,7 +41,7 @@
 
 /*! DEPRECATED!!!  Use <hash_map> instead.  */
 
-/*! \file PLearnLibrary/PLearnCore/Hash.h */
+/*! \file PLearn/plearn/math/Hash.h */
 
 #ifndef MODULE_HASH
 #define MODULE_HASH

Modified: trunk/plearn/math/Mat.h
===================================================================
--- trunk/plearn/math/Mat.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/Mat.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -39,7 +39,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/Mat.h */
+/*! \file PLearn/plearn/math/Mat.h */
 
 #ifndef MAT_INC
 #define MAT_INC

Modified: trunk/plearn/math/RowMapSparseMatrix.h
===================================================================
--- trunk/plearn/math/RowMapSparseMatrix.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/RowMapSparseMatrix.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnCore/RowMapSparseMatrix.h */
+/*! \file PLearn/plearn/math/RowMapSparseMatrix.h */
 
 #ifndef ROWMAPSPARSEMATRIX
 #define ROWMAPSPARSEMATRIX

Modified: trunk/plearn/math/RowMapSparseValueMatrix.h
===================================================================
--- trunk/plearn/math/RowMapSparseValueMatrix.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/RowMapSparseValueMatrix.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnCore/RowMapSparseValueMatrix.h */
+/*! \file PLearn/plearn/math/RowMapSparseValueMatrix.h */
 
 #ifndef ROWMAPSPARSEVALUEMATRIX
 #define ROWMAPSPARSEVALUEMATRIX

Modified: trunk/plearn/math/SparseMatrix.h
===================================================================
--- trunk/plearn/math/SparseMatrix.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/SparseMatrix.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnCore/SparseMatrix.h */
+/*! \file PLearn/plearn/math/SparseMatrix.h */
 
 #ifndef SPARSEMATRIX
 #define SPARSEMATRIX

Modified: trunk/plearn/math/TMat.h
===================================================================
--- trunk/plearn/math/TMat.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMat.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMat.h */
 
 #ifndef TMat_INC
 #define TMat_INC

Modified: trunk/plearn/math/TMatColRowsIterator_decl.h
===================================================================
--- trunk/plearn/math/TMatColRowsIterator_decl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatColRowsIterator_decl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatColRowsIterator_decl.h */
 
 #ifndef TMatColRowsIterator_decl_INC
 #define TMatColRowsIterator_decl_INC

Modified: trunk/plearn/math/TMatColRowsIterator_impl.h
===================================================================
--- trunk/plearn/math/TMatColRowsIterator_impl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatColRowsIterator_impl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatColRowsIterator_impl.h */
 
 #ifndef TMatColRowsIterator_impl_INC
 #define TMatColRowsIterator_impl_INC

Modified: trunk/plearn/math/TMatElementIterator_decl.h
===================================================================
--- trunk/plearn/math/TMatElementIterator_decl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatElementIterator_decl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatTMatElementIterator_decl.h */
 
 #ifndef TMatTMatElementIterator_decl_INC
 #define TMatTMatElementIterator_decl_INC

Modified: trunk/plearn/math/TMatElementIterator_impl.h
===================================================================
--- trunk/plearn/math/TMatElementIterator_impl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatElementIterator_impl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatElementIterator_impl.h */
 
 #ifndef TMatElementIterator_impl_INC
 #define TMatElementIterator_impl_INC

Modified: trunk/plearn/math/TMatRowsAsArraysIterator_decl.h
===================================================================
--- trunk/plearn/math/TMatRowsAsArraysIterator_decl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatRowsAsArraysIterator_decl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatRowsAsArraysIterator_decl.h */
 
 #ifndef TMatRowsAsArraysIterator_decl_INC
 #define TMatRowsAsArraysIterator_decl_INC

Modified: trunk/plearn/math/TMatRowsAsArraysIterator_impl.h
===================================================================
--- trunk/plearn/math/TMatRowsAsArraysIterator_impl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatRowsAsArraysIterator_impl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatRowsAsArraysIterator_impl.h */
 
 #ifndef TMatRowsAsArraysIterator_impl_INC
 #define TMatRowsAsArraysIterator_impl_INC

Modified: trunk/plearn/math/TMatRowsIterator_decl.h
===================================================================
--- trunk/plearn/math/TMatRowsIterator_decl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatRowsIterator_decl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatRowsIterator_decl.h */
 
 #ifndef TMatRowsIterator_decl_INC
 #define TMatRowsIterator_decl_INC

Modified: trunk/plearn/math/TMatRowsIterator_impl.h
===================================================================
--- trunk/plearn/math/TMatRowsIterator_impl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMatRowsIterator_impl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMatRowsIterator_impl.h */
 
 #ifndef TMatRowsIterator_impl_INC
 #define TMatRowsIterator_impl_INC

Modified: trunk/plearn/math/TMat_decl.h
===================================================================
--- trunk/plearn/math/TMat_decl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMat_decl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file PLearn/plearn/math/TMat_decl.h */
 
 #ifndef TMat_decl_INC
 #define TMat_decl_INC

Modified: trunk/plearn/math/TMat_impl.h
===================================================================
--- trunk/plearn/math/TMat_impl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMat_impl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -42,7 +42,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/TMat_impl.h */
+/*! \file PLearn/plearn/math/TMat_impl.h */
 
 #ifndef TMAT_IMPL_H
 #define TMAT_IMPL_H

Modified: trunk/plearn/math/TMat_maths.h
===================================================================
--- trunk/plearn/math/TMat_maths.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMat_maths.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -42,7 +42,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/TMat_maths.h */
+/*! \file PLearn/plearn/math/TMat_maths.h */
 
 #ifndef TMat_maths_INC
 #define TMat_maths_INC

Modified: trunk/plearn/math/TMat_maths_impl.h
===================================================================
--- trunk/plearn/math/TMat_maths_impl.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMat_maths_impl.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -42,7 +42,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/TMat_maths_impl.h */
+/*! \file PLearn/plearn/math/TMat_maths_impl.h */
 
 #ifndef TMat_maths_impl_H
 #define TMat_maths_impl_H

Modified: trunk/plearn/math/TMat_sort.h
===================================================================
--- trunk/plearn/math/TMat_sort.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/TMat_sort.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -42,7 +42,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/TMat_maths.h */
+/*! \file PLearn/plearn/math/TMat_sort.h */
 
 #ifndef TMat_sort_INC
 #define TMat_sort_INC

Modified: trunk/plearn/math/distr_maths.cc
===================================================================
--- trunk/plearn/math/distr_maths.cc	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/distr_maths.cc	2007-11-07 21:32:01 UTC (rev 8235)
@@ -40,7 +40,7 @@
    ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnAlgo/distr_maths.cc */
+/*! \file PLearn/plearn/math/distr_maths.cc */
 
 
 #include "distr_maths.h"

Modified: trunk/plearn/math/pl_erf.h
===================================================================
--- trunk/plearn/math/pl_erf.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/pl_erf.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -33,7 +33,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnCore/pl_erf.h */
+/*! \file PLearn/plearn/math/pl_erf.h */
 
 #ifndef PL_ERF_H
 #define PL_ERF_H

Modified: trunk/plearn/math/pl_math.cc
===================================================================
--- trunk/plearn/math/pl_math.cc	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/pl_math.cc	2007-11-07 21:32:01 UTC (rev 8235)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/pl_io.cc */
+/*! \file PLearn/plearn/math/pl_math.cc */
 
 #include "pl_math.h"
 

Modified: trunk/plearn/math/pl_math.h
===================================================================
--- trunk/plearn/math/pl_math.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/pl_math.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/pl_math.h */
+/*! \file PLearn/plearn/math/pl_math.h */
 
 #ifndef pl_math_INC
 #define pl_math_INC

Modified: trunk/plearn/math/plapack.h
===================================================================
--- trunk/plearn/math/plapack.h	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/plapack.h	2007-11-07 21:32:01 UTC (rev 8235)
@@ -38,7 +38,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/plapack.h */
+/*! \file PLearn/plearn/math/plapack.h */
 
 #ifndef plapack_h
 #define plapack_h

Modified: trunk/plearn/math/stats_utils.cc
===================================================================
--- trunk/plearn/math/stats_utils.cc	2007-11-07 21:24:23 UTC (rev 8234)
+++ trunk/plearn/math/stats_utils.cc	2007-11-07 21:32:01 UTC (rev 8235)
@@ -38,7 +38,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/stats_utils.h */
+/*! \file PLearn/plearn/math/stats_utils.h */
 
 #include "stats_utils.h"
 #include "TMat_maths.h"



From nouiz at mail.berlios.de  Thu Nov  8 15:45:49 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 8 Nov 2007 15:45:49 +0100
Subject: [Plearn-commits] r8236 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711081445.lA8EjnGg001268@sheep.berlios.de>

Author: nouiz
Date: 2007-11-08 15:45:48 +0100 (Thu, 08 Nov 2007)
New Revision: 8236

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc
Log:
changed order of import to remove warning


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file AnalyzeFieldStats.cc */
 
 #define PL_LOG_MODULE_NAME "AnalyzeFieldStats"
-#include <plearn/io/pl_log.h>
 
 #include "AnalyzeFieldStats.h"
+#include <plearn/io/pl_log.h>
 #include <plearn/io/load_and_save.h>          //!<  For save
 #include <plearn/io/fileutils.h>              //!<  For isfile()
 #include <plearn/math/random.h>               //!<  For the seed stuff.

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file CheckDond2FileSequence.cc */
 
 #define PL_LOG_MODULE_NAME "CheckDond2FileSequence"
-#include <plearn/io/pl_log.h>
 
 #include "CheckDond2FileSequence.h"
+#include <plearn/io/pl_log.h>
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file ComputeDond2Target.cc */
 
 #define PL_LOG_MODULE_NAME "ComputeDond2Target"
-#include <plearn/io/pl_log.h>
 
 #include "ComputeDond2Target.h"
+#include <plearn/io/pl_log.h>
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file DichotomizeDond2DiscreteVariables.cc */
 
 #define PL_LOG_MODULE_NAME "DichotomizeDond2DiscreteVariables"
-#include <plearn/io/pl_log.h>
 
 #include "DichotomizeDond2DiscreteVariables.h"
+#include <plearn/io/pl_log.h>
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file FixDond2BinaryVariables.cc */
 
 #define PL_LOG_MODULE_NAME "FixDond2BinaryVariables"
-#include <plearn/io/pl_log.h>
 
 #include "FixDond2BinaryVariables.h"
+#include <plearn/io/pl_log.h>
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file MergeDond2Files.cc */
 
 #define PL_LOG_MODULE_NAME "MergeDond2Files"
-#include <plearn/io/pl_log.h>
 
 #include "MergeDond2Files.h"
+#include <plearn/io/pl_log.h>
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file NeighborhoodConditionalMean.cc */
 
 #define PL_LOG_MODULE_NAME "NeighborhoodConditionalMean"
-#include <plearn/io/pl_log.h>
 
 #include "NeighborhoodConditionalMean.h"
+#include <plearn/io/pl_log.h>
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file Preprocessing.cc */
 
 #define PL_LOG_MODULE_NAME "Preprocessing"
-#include <plearn/io/pl_log.h>
 
 #include "Preprocessing.h"
+#include <plearn/io/pl_log.h>
 #include <plearn/io/load_and_save.h>                 //!<  For save
 #include <plearn/io/fileutils.h>                     //!<  For isfile()
 #include <plearn/math/random.h>                      //!<  For the seed stuff.

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc	2007-11-07 21:32:01 UTC (rev 8235)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc	2007-11-08 14:45:48 UTC (rev 8236)
@@ -37,9 +37,9 @@
 /*! \file TestImputations.cc */
 
 #define PL_LOG_MODULE_NAME "TestImputations"
-#include <plearn/io/pl_log.h>
 
 #include "TestImputations.h"
+#include <plearn/io/pl_log.h>
 
 namespace PLearn {
 using namespace std;



From nouiz at mail.berlios.de  Thu Nov  8 15:47:14 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 8 Nov 2007 15:47:14 +0100
Subject: [Plearn-commits] r8237 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711081447.lA8ElEkj001365@sheep.berlios.de>

Author: nouiz
Date: 2007-11-08 15:47:14 +0100 (Thu, 08 Nov 2007)
New Revision: 8237

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
Log:
print all the field in error at the same time instead of stopping after the first one.
to easy debugging.


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-08 14:45:48 UTC (rev 8236)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-08 14:47:14 UTC (rev 8237)
@@ -238,18 +238,26 @@
     variable_mode.resize(train_width);
     variable_imputation_instruction.resize(train_width);
     variable_imputation_instruction.clear();
+    TVec<string> nofields;
     for (int spec_col = 0; spec_col < imputation_spec.size(); spec_col++)
     {
         for (train_col = 0; train_col < train_width; train_col++)
         {
             if (imputation_spec[spec_col].first == train_field_names[train_col]) break;
         }
-        if (train_col >= train_width) PLERROR("In MeanMedianModeImputationVMatrix: no field with this name in train data set: %s", (imputation_spec[spec_col].first).c_str());
+        if (train_col >= train_width){
+	  nofields.append((imputation_spec[spec_col].first).c_str());
+	  continue;
+	}
         if (imputation_spec[spec_col].second == "mean") variable_imputation_instruction[train_col] = 1;
         else if (imputation_spec[spec_col].second == "median") variable_imputation_instruction[train_col] = 2;
         else if (imputation_spec[spec_col].second == "mode") variable_imputation_instruction[train_col] = 3;
-        else PLERROR("In MeanMedianModeImputationVMatrix: unsupported imputation instruction: %s : %s", (imputation_spec[spec_col].first).c_str(), (imputation_spec[spec_col].second).c_str());
+        else PLERROR("In MeanMedianModeImputationVMatrix: unsupported imputation instruction: %s : %s",
+		     (imputation_spec[spec_col].first).c_str(), (imputation_spec[spec_col].second).c_str());
     }
+    if(nofields.length()>0)
+      PLERROR("In MeanMedianModeImputationVMatrix::build_() Their is %d fields in the imputation_spec that are not in train set: %s",nofields.length(),
+	      tostring(nofields).c_str());
     train_metadata = train_set->getMetaDataDir();
     mean_median_mode_file_name = train_metadata + "mean_median_mode_file.pmat";
     



From nouiz at mail.berlios.de  Thu Nov  8 15:57:25 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 8 Nov 2007 15:57:25 +0100
Subject: [Plearn-commits] r8238 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711081457.lA8EvPmg001980@sheep.berlios.de>

Author: nouiz
Date: 2007-11-08 15:57:25 +0100 (Thu, 08 Nov 2007)
New Revision: 8238

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
Log:
refactoring:
-put global variable local when they where used only locally
-check for more error et better message
-other small modification


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc	2007-11-08 14:47:14 UTC (rev 8237)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc	2007-11-08 14:57:25 UTC (rev 8238)
@@ -184,45 +184,57 @@
 
 void MissingIndicatorVMatrix::buildNewRecordFormat()
 {
-    train_length = train_set->length();
+    int train_length = train_set->length();
     if (number_of_train_samples_to_use > 0.0)
         if (number_of_train_samples_to_use < 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
         else train_length = (int) number_of_train_samples_to_use;
     if (train_length > train_set->length()) train_length = train_set->length();
-    if(train_length < 1) PLERROR("In MissingIndicatorVMatrix::length of the number of train samples to use must be at least 1, got: %i", train_length);
-    train_width = train_set->width();
-    train_targetsize = train_set->targetsize();
-    train_weightsize = train_set->weightsize();
-    train_inputsize = train_set->inputsize();
-    if(train_inputsize < 1) PLERROR("In MissingIndicatorVMatrix::inputsize of the train vmat must be supplied, got : %i", train_inputsize);
-    source_width = source->width();
-    source_targetsize = source->targetsize();
+
+    int train_width = train_set->width();
+    int train_inputsize = train_set->inputsize();
+    int source_width = source->width();
     source_inputsize = source->inputsize();
-    if (train_width != source_width) PLERROR("In MissingIndicatorVMatrix::train set and source width must agree, got : %i, %i", train_width, source_width);
-    if (train_targetsize != source_targetsize) PLERROR("In MissingIndicatorVMatrix::train set and source targetsize must agree, got : %i, %i", train_targetsize, source_targetsize);
-    if (train_weightsize != source->weightsize()) PLERROR("In MissingIndicatorVMatrix::train set and source weightsize must agree, got : %i, %i", train_weightsize, source->weightsize());
-    if (train_inputsize != source_inputsize) PLERROR("In MissingIndicatorVMatrix::train set and source inputsize must agree, got : %i, %i", train_inputsize, source_inputsize);
+
+    if(train_length < 1) 
+      PLERROR("In MissingIndicatorVMatrix::length of the number of train"
+	      " samples to use must be at least 1, got: %i", train_length);
+    if(train_inputsize < 1) 
+      PLERROR("In MissingIndicatorVMatrix::inputsize of the train vmat must"
+	      " be supplied, got : %i", train_inputsize);
+    if (train_width != source_width) 
+      PLERROR("In MissingIndicatorVMatrix::train set and source width must"
+	      " agree, got : %i, %i", train_width, source_width);
+    if (train_set->targetsize() != source->targetsize())
+      PLERROR("In MissingIndicatorVMatrix::train set and source targetsize"
+	      " must agree, got : %i, %i", train_set->targetsize(),
+	      source->targetsize());
+    if (train_set->weightsize() != source->weightsize()) 
+      PLERROR("In MissingIndicatorVMatrix::train set and source weightsize"
+	      " must agree, got : %i, %i", train_set->weightsize(),
+	      source->weightsize());
+    if (train_inputsize != source_inputsize)
+      PLERROR("In MissingIndicatorVMatrix::train set and source inputsize"
+	      " must agree, got : %i, %i", train_inputsize, source_inputsize);
+
     train_input.resize(train_width);
     train_var_missing.resize(train_inputsize);
     train_var_missing.clear();
+
     for (int train_row = 0; train_row < train_length; train_row++)
     {
-        train_set->getRow(train_row, train_input);
-        for (int train_col = 0; train_col < train_inputsize; train_col++)
-        {
-            if (is_missing(train_input[train_col])) train_var_missing[train_col] = 1;
-        }
+         train_set->getRow(train_row, train_input);
+         for (int train_col = 0; train_col < train_inputsize; train_col++)
+         {
+             if (is_missing(train_input[train_col])) train_var_missing[train_col] = 1;
+         }
     }
-    int new_width = train_width;
-    int new_inputsize = train_inputsize;
-    for (int train_col = 0; train_col < train_inputsize; train_col++)
-    {
-        new_width += train_var_missing[train_col];
-        new_inputsize += train_var_missing[train_col];
-    }
-    train_field_names.resize(train_width);
-    source_rel_pos.resize(new_width);
-    TVec<string> new_field_names(new_width);
+
+    int added_colomns = sum(train_var_missing);
+    width_ = train_width + added_colomns;
+
+    TVec<string> train_field_names(train_width);
+    source_rel_pos.resize(width_);
+    TVec<string> new_field_names(width_);
     train_field_names = train_set->fieldNames();
     int new_col = 0;
     for (int train_col = 0; train_col < train_inputsize; train_col++)
@@ -243,12 +255,10 @@
       source_rel_pos[new_col] = train_col;
       new_col += 1;
     }
-    source_length = source->length();
-    length_ = source_length;
-    width_ = new_width;
-    inputsize_ = new_inputsize;
-    targetsize_ = source_targetsize;
-    weightsize_ = train_weightsize;
+    length_ = source->length();
+    inputsize_ = train_inputsize + added_colomns;
+    targetsize_ = source->targetsize();
+    weightsize_ = train_set->weightsize();
     source_input.resize(source_inputsize);
     declareFieldNames(new_field_names);
 }

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-11-08 14:47:14 UTC (rev 8237)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
@@ -91,18 +91,9 @@
 
 private:
   
-  int          train_length;
-  int          train_width;
-  int          train_inputsize;
-  int          train_targetsize;
-  int          train_weightsize;
   Vec          train_input;
-  TVec<string> train_field_names;
   TVec<int>    train_var_missing;
-  int          source_length;
-  int          source_width;
   int          source_inputsize;
-  int          source_targetsize;
   Vec          source_input;
   TVec<int>    source_rel_pos;
 



From nouiz at mail.berlios.de  Fri Nov  9 16:35:37 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 9 Nov 2007 16:35:37 +0100
Subject: [Plearn-commits] r8239 - trunk/plearn/vmat
Message-ID: <200711091535.lA9FZbWb025498@sheep.berlios.de>

Author: nouiz
Date: 2007-11-09 16:35:34 +0100 (Fri, 09 Nov 2007)
New Revision: 8239

Modified:
   trunk/plearn/vmat/AutoVMatrix.h
   trunk/plearn/vmat/BootstrapVMatrix.h
   trunk/plearn/vmat/ByteMemoryVMatrix.h
   trunk/plearn/vmat/CompactFileVMatrix.h
   trunk/plearn/vmat/CompactVMatrix.h
   trunk/plearn/vmat/CompressedVMatrix.h
   trunk/plearn/vmat/ConcatColumnsVMatrix.h
   trunk/plearn/vmat/ConcatRowsSubVMatrix.h
   trunk/plearn/vmat/CrossReferenceVMatrix.h
   trunk/plearn/vmat/DatedVMatrix.h
   trunk/plearn/vmat/DiskVMatrix.h
   trunk/plearn/vmat/ExtendedVMatrix.h
   trunk/plearn/vmat/FileVMatrix.h
   trunk/plearn/vmat/ForwardVMatrix.h
   trunk/plearn/vmat/GeneralizedOneHotVMatrix.h
   trunk/plearn/vmat/InterleaveVMatrix.h
   trunk/plearn/vmat/MeanImputationVMatrix.h
   trunk/plearn/vmat/MemoryVMatrix.h
   trunk/plearn/vmat/OneHotVMatrix.h
   trunk/plearn/vmat/PairsVMatrix.h
   trunk/plearn/vmat/RangeVMatrix.h
   trunk/plearn/vmat/RemapLastColumnVMatrix.h
   trunk/plearn/vmat/RowBufferedVMatrix.h
   trunk/plearn/vmat/SelectColumnsVMatrix.h
   trunk/plearn/vmat/SelectRowsFileIndexVMatrix.h
   trunk/plearn/vmat/SelectRowsVMatrix.h
   trunk/plearn/vmat/SentencesBlocks.h
   trunk/plearn/vmat/SortRowsVMatrix.h
   trunk/plearn/vmat/SparseVMatrix.h
   trunk/plearn/vmat/SubVMatrix.h
   trunk/plearn/vmat/UniformVMatrix.h
   trunk/plearn/vmat/VMField.h
   trunk/plearn/vmat/VMat.h
   trunk/plearn/vmat/VMatrix.h
   trunk/plearn/vmat/VVec.h
   trunk/plearn/vmat/VariableDeletionVMatrix.h
   trunk/plearn/vmat/VecExtendedVMatrix.h
Log:
corrected path for doxygen


Modified: trunk/plearn/vmat/AutoVMatrix.h
===================================================================
--- trunk/plearn/vmat/AutoVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/AutoVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file AutoVMatrix.h */
 
 #ifndef AutoVMatrix_INC
 #define AutoVMatrix_INC

Modified: trunk/plearn/vmat/BootstrapVMatrix.h
===================================================================
--- trunk/plearn/vmat/BootstrapVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/BootstrapVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -37,7 +37,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file BootstrapVMatrix.h */
 
 #ifndef BootstrapVMatrix_INC
 #define BootstrapVMatrix_INC

Modified: trunk/plearn/vmat/ByteMemoryVMatrix.h
===================================================================
--- trunk/plearn/vmat/ByteMemoryVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/ByteMemoryVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ByteMemoryVMatrix.h */
 
 #ifndef ByteMemoryVMatrix_INC
 #define ByteMemoryVMatrix_INC

Modified: trunk/plearn/vmat/CompactFileVMatrix.h
===================================================================
--- trunk/plearn/vmat/CompactFileVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/CompactFileVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -33,7 +33,7 @@
 // library, go to the PLearn Web site at www.plearn.org
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file CompactFileVMatrix.h */
 
 #ifndef CompactFileVMatrix_INC
 #define CompactFileVMatrix_INC

Modified: trunk/plearn/vmat/CompactVMatrix.h
===================================================================
--- trunk/plearn/vmat/CompactVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/CompactVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file CompactVMatrix.h */
 
 #ifndef CompactCompactVMatrix_INC
 #define CompactCompactVMatrix_INC

Modified: trunk/plearn/vmat/CompressedVMatrix.h
===================================================================
--- trunk/plearn/vmat/CompressedVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/CompressedVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file CompressedVMatrix.h */
 
 #ifndef CompressedVMatrix_INC
 #define CompressedVMatrix_INC

Modified: trunk/plearn/vmat/ConcatColumnsVMatrix.h
===================================================================
--- trunk/plearn/vmat/ConcatColumnsVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/ConcatColumnsVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ConcatColumnsVMatrix.h */
 
 #ifndef ConcatColumnsVMatrix_INC
 #define ConcatColumnsVMatrix_INC

Modified: trunk/plearn/vmat/ConcatRowsSubVMatrix.h
===================================================================
--- trunk/plearn/vmat/ConcatRowsSubVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/ConcatRowsSubVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ConcatRowsSubVMatrix.h */
 
 #ifndef ConcatRowsSubVMatrix_INC
 #define ConcatRowsSubVMatrix_INC

Modified: trunk/plearn/vmat/CrossReferenceVMatrix.h
===================================================================
--- trunk/plearn/vmat/CrossReferenceVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/CrossReferenceVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file CrossReferenceVMatrix.h */
 
 #ifndef CrossReferenceVMatrix_INC
 #define CrossReferenceVMatrix_INC

Modified: trunk/plearn/vmat/DatedVMatrix.h
===================================================================
--- trunk/plearn/vmat/DatedVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/DatedVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file DatedVMatrix.h */
 
 #ifndef DatedVMatrix_INC
 #define DatedVMatrix_INC

Modified: trunk/plearn/vmat/DiskVMatrix.h
===================================================================
--- trunk/plearn/vmat/DiskVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/DiskVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file DiskVMatrix.h */
 
 #ifndef DiskVMatrix_INC
 #define DiskVMatrix_INC

Modified: trunk/plearn/vmat/ExtendedVMatrix.h
===================================================================
--- trunk/plearn/vmat/ExtendedVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/ExtendedVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ExtendedVMatrix.h */
 
 #ifndef ExtendedVMatrix_INC
 #define ExtendedVMatrix_INC

Modified: trunk/plearn/vmat/FileVMatrix.h
===================================================================
--- trunk/plearn/vmat/FileVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/FileVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file FileVMatrix.h */
 
 #ifndef FileVMatrix_INC
 #define FileVMatrix_INC

Modified: trunk/plearn/vmat/ForwardVMatrix.h
===================================================================
--- trunk/plearn/vmat/ForwardVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/ForwardVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ForwardVMatrix.h */
 
 #ifndef ForwardVMatrix_INC
 #define ForwardVMatrix_INC

Modified: trunk/plearn/vmat/GeneralizedOneHotVMatrix.h
===================================================================
--- trunk/plearn/vmat/GeneralizedOneHotVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/GeneralizedOneHotVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file GeneralizedOneHotVMatrix.h */
 
 #ifndef GeneralizedOneHotVMatrix_INC
 #define GeneralizedOneHotVMatrix_INC

Modified: trunk/plearn/vmat/InterleaveVMatrix.h
===================================================================
--- trunk/plearn/vmat/InterleaveVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/InterleaveVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file InterleaveVMatrix.h */
 
 #ifndef InterleaveVMatrix_INC
 #define InterleaveVMatrix_INC

Modified: trunk/plearn/vmat/MeanImputationVMatrix.h
===================================================================
--- trunk/plearn/vmat/MeanImputationVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/MeanImputationVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -40,7 +40,7 @@
  ****************************************************************** */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file MeanImputationVMatrix.h */
 
 #ifndef MeanImputationVMatrix_INC
 #define MeanImputationVMatrix_INC

Modified: trunk/plearn/vmat/MemoryVMatrix.h
===================================================================
--- trunk/plearn/vmat/MemoryVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/MemoryVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file MemoryVMatrix.h */
 
 #ifndef MemoryVMatrix_INC
 #define MemoryVMatrix_INC

Modified: trunk/plearn/vmat/OneHotVMatrix.h
===================================================================
--- trunk/plearn/vmat/OneHotVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/OneHotVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file OneHotVMatrix.h */
 
 #ifndef OneHotVMatrix_INC
 #define OneHotVMatrix_INC

Modified: trunk/plearn/vmat/PairsVMatrix.h
===================================================================
--- trunk/plearn/vmat/PairsVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/PairsVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file PairsVMatrix.h */
 
 #ifndef PairsVMatrix_INC
 #define PairsVMatrix_INC

Modified: trunk/plearn/vmat/RangeVMatrix.h
===================================================================
--- trunk/plearn/vmat/RangeVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/RangeVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file RangeVMatrix.h */
 
 #ifndef RangeVMatrix_INC
 #define RangeVMatrix_INC

Modified: trunk/plearn/vmat/RemapLastColumnVMatrix.h
===================================================================
--- trunk/plearn/vmat/RemapLastColumnVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/RemapLastColumnVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file RemapLastColumnVMatrix.h */
 
 #ifndef RemapLastColumnVMatrix_INC
 #define RemapLastColumnVMatrix_INC

Modified: trunk/plearn/vmat/RowBufferedVMatrix.h
===================================================================
--- trunk/plearn/vmat/RowBufferedVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/RowBufferedVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file RowBufferedVMatrix.h */
 
 #ifndef RowBufferedRowBufferedVMatrix_INC
 #define RowBufferedRowBufferedVMatrix_INC

Modified: trunk/plearn/vmat/SelectColumnsVMatrix.h
===================================================================
--- trunk/plearn/vmat/SelectColumnsVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/SelectColumnsVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file SelectColumnsVMatrix.h */
 
 #ifndef SelectColumnsVMatrix_INC
 #define SelectColumnsVMatrix_INC

Modified: trunk/plearn/vmat/SelectRowsFileIndexVMatrix.h
===================================================================
--- trunk/plearn/vmat/SelectRowsFileIndexVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/SelectRowsFileIndexVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file SelectRowsFileIndexVMatrix.h */
 
 #ifndef SelectRowsFileIndexVMatrix_INC
 #define SelectRowsFileIndexVMatrix_INC

Modified: trunk/plearn/vmat/SelectRowsVMatrix.h
===================================================================
--- trunk/plearn/vmat/SelectRowsVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/SelectRowsVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file SelectRowsVMatrix.h */
 
 #ifndef SelectRowsVMatrix_INC
 #define SelectRowsVMatrix_INC

Modified: trunk/plearn/vmat/SentencesBlocks.h
===================================================================
--- trunk/plearn/vmat/SentencesBlocks.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/SentencesBlocks.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file SentencesBlocks.h */
 
 #ifndef SentencesBlocks_INC
 #define SentencesBlocks_INC

Modified: trunk/plearn/vmat/SortRowsVMatrix.h
===================================================================
--- trunk/plearn/vmat/SortRowsVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/SortRowsVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -37,7 +37,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file SortRowsVMatrix.h */
 
 #ifndef SortRowsVMatrix_INC
 #define SortRowsVMatrix_INC

Modified: trunk/plearn/vmat/SparseVMatrix.h
===================================================================
--- trunk/plearn/vmat/SparseVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/SparseVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file SparseVMatrix.h */
 
 #ifndef SparseVMatrix_INC
 #define SparseVMatrix_INC

Modified: trunk/plearn/vmat/SubVMatrix.h
===================================================================
--- trunk/plearn/vmat/SubVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/SubVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file SubVMatrix.h */
 
 #ifndef SubVMatrix_INC
 #define SubVMatrix_INC

Modified: trunk/plearn/vmat/UniformVMatrix.h
===================================================================
--- trunk/plearn/vmat/UniformVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/UniformVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file UniformVMatrix.h */
 
 #ifndef UniformVMatrix_INC
 #define UniformVMatrix_INC

Modified: trunk/plearn/vmat/VMField.h
===================================================================
--- trunk/plearn/vmat/VMField.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/VMField.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMField.h */
+/*! \file VMField.h */
 
 #ifndef VMField_INC
 #define VMField_INC

Modified: trunk/plearn/vmat/VMat.h
===================================================================
--- trunk/plearn/vmat/VMat.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/VMat.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file VMat.h */
 
 #ifndef VMat_INC
 #define VMat_INC

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/VMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -38,7 +38,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file VMatrix.h */
 
 #ifndef VMatrix_INC
 #define VMatrix_INC

Modified: trunk/plearn/vmat/VVec.h
===================================================================
--- trunk/plearn/vmat/VVec.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/VVec.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VVec.h */
+/*! \file VVec.h */
 
 #ifndef VVec_INC
 #define VVec_INC

Modified: trunk/plearn/vmat/VariableDeletionVMatrix.h
===================================================================
--- trunk/plearn/vmat/VariableDeletionVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/VariableDeletionVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -40,7 +40,7 @@
  ******************************************************************** */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file VMat.h */
 
 #ifndef VariableDeletionVMatrix_INC
 #define VariableDeletionVMatrix_INC

Modified: trunk/plearn/vmat/VecExtendedVMatrix.h
===================================================================
--- trunk/plearn/vmat/VecExtendedVMatrix.h	2007-11-08 14:57:25 UTC (rev 8238)
+++ trunk/plearn/vmat/VecExtendedVMatrix.h	2007-11-09 15:35:34 UTC (rev 8239)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file VecExtendedVMatrix.h */
 
 #ifndef VecExtendedVMatrix_INC
 #define VecExtendedVMatrix_INC



From nouiz at mail.berlios.de  Fri Nov  9 19:37:34 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 9 Nov 2007 19:37:34 +0100
Subject: [Plearn-commits] r8240 - in trunk/plearn: base vmat
Message-ID: <200711091837.lA9IbY0C023417@sheep.berlios.de>

Author: nouiz
Date: 2007-11-09 19:37:33 +0100 (Fri, 09 Nov 2007)
New Revision: 8240

Modified:
   trunk/plearn/base/general.cc
   trunk/plearn/vmat/VMatrix.cc
Log:
-modified the PLearn::hostname() function to try first nspr version then environnement variable to find the hostname.
-now PLearn::VMatrix::lockMetaDataDir() use it.


Modified: trunk/plearn/base/general.cc
===================================================================
--- trunk/plearn/base/general.cc	2007-11-09 15:35:34 UTC (rev 8239)
+++ trunk/plearn/base/general.cc	2007-11-09 18:37:33 UTC (rev 8240)
@@ -43,6 +43,8 @@
 
 #include "general.h"
 #include <sys/stat.h>
+#include <nspr/prsystem.h>
+#include <plearn/base/tostring.h>
 #ifdef _MSC_VER
 #include <io.h>
 #endif
@@ -111,12 +113,18 @@
 
 string hostname()
 {
-    char* h = getenv("HOSTNAME");
-    if (!h)
-        h = getenv("HOST");
-    if (!h)
-        PLERROR("hostname: could not find $HOSTNAME nor $HOST in environment!");
-    return h;
+    char tmp[1024];
+    if(PR_GetSystemInfo(PR_SI_HOSTNAME,tmp,500)==PR_SUCCESS)
+        return tostring(tmp);
+    else{
+        char* h = getenv("HOSTNAME");
+        if (!h)
+            h = getenv("HOST");
+        if (!h)
+            PLERROR("hostname: could not find the host name from NSPR"
+                    " or from the variable $HOSTNAME or $HOST in environment!");
+        return h;
+    }
 }
 
 string prgname(const string& setname)

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-11-09 15:35:34 UTC (rev 8239)
+++ trunk/plearn/vmat/VMatrix.cc	2007-11-09 18:37:33 UTC (rev 8240)
@@ -1219,14 +1219,6 @@
         || this->extrasize()  != m->extrasize() );
 }
 
-/////////////
-// getHost //
-/////////////
-string getHost()
-{
-    return "TODO";
-}
-
 ////////////
 // getPid //
 ////////////
@@ -1272,7 +1264,7 @@
         sleep(uniform_multinomial_sample(10) + 1); // Random wait for more safety.
     }
     lockf_ = openFile(lockfile, PStream::raw_ascii, "w");
-    string lock_content = "host " + getHost() + ", pid " + tostring(getPid()) + ", user " + getUser();
+    string lock_content = "host " + hostname() + ", pid " + tostring(getPid()) + ", user " + getUser();
     lockf_ << lock_content;
     lockf_.flush();
 }



From nouiz at mail.berlios.de  Fri Nov  9 21:12:36 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 9 Nov 2007 21:12:36 +0100
Subject: [Plearn-commits] r8241 - in trunk/plearn: base display io
Message-ID: <200711092012.lA9KCae6030543@sheep.berlios.de>

Author: nouiz
Date: 2007-11-09 21:12:36 +0100 (Fri, 09 Nov 2007)
New Revision: 8241

Modified:
   trunk/plearn/base/general.cc
   trunk/plearn/display/MatlabInterface.h
   trunk/plearn/io/fileutils.cc
Log:
changed the use of unix getenv for the NSPR version PR_GetEnv guarentee the cross-compatibility.


Modified: trunk/plearn/base/general.cc
===================================================================
--- trunk/plearn/base/general.cc	2007-11-09 18:37:33 UTC (rev 8240)
+++ trunk/plearn/base/general.cc	2007-11-09 20:12:36 UTC (rev 8241)
@@ -44,6 +44,7 @@
 #include "general.h"
 #include <sys/stat.h>
 #include <nspr/prsystem.h>
+#include <nspr/prenv.h>
 #include <plearn/base/tostring.h>
 #ifdef _MSC_VER
 #include <io.h>
@@ -117,9 +118,9 @@
     if(PR_GetSystemInfo(PR_SI_HOSTNAME,tmp,500)==PR_SUCCESS)
         return tostring(tmp);
     else{
-        char* h = getenv("HOSTNAME");
+        const char* h = PR_GetEnv("HOSTNAME");
         if (!h)
-            h = getenv("HOST");
+            h = PR_GetEnv("HOST");
         if (!h)
             PLERROR("hostname: could not find the host name from NSPR"
                     " or from the variable $HOSTNAME or $HOST in environment!");

Modified: trunk/plearn/display/MatlabInterface.h
===================================================================
--- trunk/plearn/display/MatlabInterface.h	2007-11-09 18:37:33 UTC (rev 8240)
+++ trunk/plearn/display/MatlabInterface.h	2007-11-09 20:12:36 UTC (rev 8241)
@@ -50,6 +50,7 @@
 //#include "stringutils.h"
 #include <plearn/sys/Popen.h>
 #include <plearn/math/RowMapSparseMatrix.h>
+#include <nspr/prenv.h>
 
 namespace PLearn {
 using namespace std;
@@ -141,7 +142,7 @@
     //! will be appended to the matlab path
     static string path() 
     {
-      char* plearndir = getenv("PLEARNDIR");
+      const char* plearndir = PR_GetEnv("PLEARNDIR");
       if(!plearndir)
         PLERROR("PLEARNDIR environment variable not defined");
       return string(plearndir)+"/Contrib/matlab/";

Modified: trunk/plearn/io/fileutils.cc
===================================================================
--- trunk/plearn/io/fileutils.cc	2007-11-09 18:37:33 UTC (rev 8240)
+++ trunk/plearn/io/fileutils.cc	2007-11-09 20:12:36 UTC (rev 8241)
@@ -65,6 +65,7 @@
 #include <nspr/prtime.h>
 #include <nspr/prerror.h>
 #include <nspr/prlong.h>
+#include <nspr/prenv.h>
 
 namespace PLearn {
 using namespace std;
@@ -875,7 +876,8 @@
                     PLERROR("$GETENV syntax is: $GETENV{expr}");
                 PStream expr_stream = openString(expr, PStream::raw_ascii);
                 string var_name = readAndMacroProcess(expr_stream, variables);
-                char* var = getenv(var_name.c_str());
+                const char* var = PR_GetEnv(var_name.c_str());
+
                 if (!var)
                     PLERROR("In readAndMacroProcess - The environment variable %s is not defined", var_name.c_str());
                 text += string(var);



From turian at mail.berlios.de  Fri Nov  9 22:10:34 2007
From: turian at mail.berlios.de (turian at BerliOS)
Date: Fri, 9 Nov 2007 22:10:34 +0100
Subject: [Plearn-commits] r8242 - trunk/doc
Message-ID: <200711092110.lA9LAYK6004945@sheep.berlios.de>

Author: turian
Date: 2007-11-09 22:10:32 +0100 (Fri, 09 Nov 2007)
New Revision: 8242

Added:
   trunk/doc/Doxyfile.joseph
Log:
Created an updated doxygen file

Added: trunk/doc/Doxyfile.joseph
===================================================================
--- trunk/doc/Doxyfile.joseph	2007-11-09 20:12:36 UTC (rev 8241)
+++ trunk/doc/Doxyfile.joseph	2007-11-09 21:10:32 UTC (rev 8242)
@@ -0,0 +1,1272 @@
+# Doxyfile 1.5.1-20070315
+
+# This file describes the settings to be used by the documentation system
+# doxygen (www.doxygen.org) for a project
+#
+# All text after a hash (#) is considered a comment and will be ignored
+# The format is:
+#       TAG = value [value, ...]
+# For lists items can also be appended using:
+#       TAG += value [value, ...]
+# Values that contain spaces should be placed between quotes (" ")
+
+#---------------------------------------------------------------------------
+# Project related configuration options
+#---------------------------------------------------------------------------
+
+# This tag specifies the encoding used for all characters in the config file that 
+# follow. The default is UTF-8 which is also the encoding used for all text before 
+# the first occurrence of this tag. Doxygen uses libiconv (or the iconv built into 
+# libc) for the transcoding. See http://www.gnu.org/software/libiconv for the list of 
+# possible encodings.
+
+DOXYFILE_ENCODING      = UTF-8
+
+# The PROJECT_NAME tag is a single word (or a sequence of words surrounded 
+# by quotes) that should identify the project.
+
+PROJECT_NAME           = PLearn
+
+# The PROJECT_NUMBER tag can be used to enter a project or revision number. 
+# This could be handy for archiving the generated documentation or 
+# if some version control system is used.
+
+PROJECT_NUMBER         = 0.1
+
+# The OUTPUT_DIRECTORY tag is used to specify the (relative or absolute) 
+# base path where the generated documentation will be put. 
+# If a relative path is entered, it will be relative to the location 
+# where doxygen was started. If left blank the current directory will be used.
+
+OUTPUT_DIRECTORY       = LibraryReference.joseph
+
+# If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
+# 4096 sub-directories (in 2 levels) under the output directory of each output 
+# format and will distribute the generated files over these directories. 
+# Enabling this option can be useful when feeding doxygen a huge amount of 
+# source files, where putting all generated files in the same directory would 
+# otherwise cause performance problems for the file system.
+
+CREATE_SUBDIRS         = YES
+
+# The OUTPUT_LANGUAGE tag is used to specify the language in which all 
+# documentation generated by doxygen is written. Doxygen will use this 
+# information to generate all constant output in the proper language. 
+# The default language is English, other supported languages are: 
+# Afrikaans, Arabic, Brazilian, Catalan, Chinese, Chinese-Traditional, 
+# Croatian, Czech, Danish, Dutch, Finnish, French, German, Greek, Hungarian, 
+# Italian, Japanese, Japanese-en (Japanese with English messages), Korean, 
+# Korean-en, Lithuanian, Norwegian, Polish, Portuguese, Romanian, Russian, 
+# Serbian, Slovak, Slovene, Spanish, Swedish, and Ukrainian.
+
+OUTPUT_LANGUAGE        = English
+
+# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will 
+# include brief member descriptions after the members that are listed in 
+# the file and class documentation (similar to JavaDoc). 
+# Set to NO to disable this.
+
+BRIEF_MEMBER_DESC      = YES
+
+# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend 
+# the brief description of a member or function before the detailed description. 
+# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the 
+# brief descriptions will be completely suppressed.
+
+REPEAT_BRIEF           = YES
+
+# This tag implements a quasi-intelligent brief description abbreviator 
+# that is used to form the text in various listings. Each string 
+# in this list, if found as the leading text of the brief description, will be 
+# stripped from the text and the result after processing the whole list, is 
+# used as the annotated text. Otherwise, the brief description is used as-is. 
+# If left blank, the following values are used ("$name" is automatically 
+# replaced with the name of the entity): "The $name class" "The $name widget" 
+# "The $name file" "is" "provides" "specifies" "contains" 
+# "represents" "a" "an" "the"
+
+ABBREVIATE_BRIEF       = 
+
+# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then 
+# Doxygen will generate a detailed section even if there is only a brief 
+# description.
+
+ALWAYS_DETAILED_SEC    = NO
+
+# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all 
+# inherited members of a class in the documentation of that class as if those 
+# members were ordinary class members. Constructors, destructors and assignment 
+# operators of the base classes will not be shown.
+
+INLINE_INHERITED_MEMB  = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full 
+# path before files name in the file list and in the header files. If set 
+# to NO the shortest path that makes the file name unique will be used.
+
+FULL_PATH_NAMES        = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag 
+# can be used to strip a user-defined part of the path. Stripping is 
+# only done if one of the specified strings matches the left-hand part of 
+# the path. The tag can be used to show relative paths in the file list. 
+# If left blank the directory from which doxygen is run is used as the 
+# path to strip.
+
+STRIP_FROM_PATH        = 
+
+# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of 
+# the path mentioned in the documentation of a class, which tells 
+# the reader which header file to include in order to use a class. 
+# If left blank only the name of the header file containing the class 
+# definition is used. Otherwise one should specify the include paths that 
+# are normally passed to the compiler using the -I flag.
+
+STRIP_FROM_INC_PATH    = 
+
+# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter 
+# (but less readable) file names. This can be useful is your file systems 
+# doesn't support long names like on DOS, Mac, or CD-ROM.
+
+SHORT_NAMES            = NO
+
+# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen 
+# will interpret the first line (until the first dot) of a JavaDoc-style 
+# comment as the brief description. If set to NO, the JavaDoc 
+# comments will behave just like the Qt-style comments (thus requiring an 
+# explicit @brief command for a brief description.
+
+JAVADOC_AUTOBRIEF      = YES
+
+# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make Doxygen 
+# treat a multi-line C++ special comment block (i.e. a block of //! or /// 
+# comments) as a brief description. This used to be the default behaviour. 
+# The new default is to treat a multi-line C++ comment block as a detailed 
+# description. Set this tag to YES if you prefer the old behaviour instead.
+
+MULTILINE_CPP_IS_BRIEF = NO
+
+# If the DETAILS_AT_TOP tag is set to YES then Doxygen 
+# will output the detailed description near the top, like JavaDoc.
+# If set to NO, the detailed description appears after the member 
+# documentation.
+
+DETAILS_AT_TOP         = NO
+
+# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented 
+# member inherits the documentation from any documented member that it 
+# re-implements.
+
+INHERIT_DOCS           = YES
+
+# If the SEPARATE_MEMBER_PAGES tag is set to YES, then doxygen will produce 
+# a new page for each member. If set to NO, the documentation of a member will 
+# be part of the file/class/namespace that contains it.
+
+SEPARATE_MEMBER_PAGES  = NO
+
+# The TAB_SIZE tag can be used to set the number of spaces in a tab. 
+# Doxygen uses this value to replace tabs by spaces in code fragments.
+
+TAB_SIZE               = 8
+
+# This tag can be used to specify a number of aliases that acts 
+# as commands in the documentation. An alias has the form "name=value". 
+# For example adding "sideeffect=\par Side Effects:\n" will allow you to 
+# put the command \sideeffect (or @sideeffect) in the documentation, which 
+# will result in a user-defined paragraph with heading "Side Effects:". 
+# You can put \n's in the value part of an alias to insert newlines.
+
+ALIASES                = 
+
+# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C 
+# sources only. Doxygen will then generate output that is more tailored for C. 
+# For instance, some of the names that are used will be different. The list 
+# of all members will be omitted, etc.
+
+OPTIMIZE_OUTPUT_FOR_C  = NO
+
+# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java 
+# sources only. Doxygen will then generate output that is more tailored for Java. 
+# For instance, namespaces will be presented as packages, qualified scopes 
+# will look different, etc.
+
+OPTIMIZE_OUTPUT_JAVA   = NO
+
+# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want to 
+# include (a tag file for) the STL sources as input, then you should 
+# set this tag to YES in order to let doxygen match functions declarations and 
+# definitions whose arguments contain STL classes (e.g. func(std::string); v.s. 
+# func(std::string) {}). This also make the inheritance and collaboration 
+# diagrams that involve STL classes more complete and accurate.
+
+BUILTIN_STL_SUPPORT    = YES
+
+# If you use Microsoft's C++/CLI language, you should set this option to YES to
+# enable parsing support.
+
+CPP_CLI_SUPPORT        = NO
+
+# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC 
+# tag is set to YES, then doxygen will reuse the documentation of the first 
+# member in the group (if any) for the other members of the group. By default 
+# all members of a group must be documented explicitly.
+
+DISTRIBUTE_GROUP_DOC   = NO
+
+# Set the SUBGROUPING tag to YES (the default) to allow class member groups of 
+# the same type (for instance a group of public functions) to be put as a 
+# subgroup of that type (e.g. under the Public Functions section). Set it to 
+# NO to prevent subgrouping. Alternatively, this can be done per class using 
+# the \nosubgrouping command.
+
+SUBGROUPING            = YES
+
+#---------------------------------------------------------------------------
+# Build related configuration options
+#---------------------------------------------------------------------------
+
+# If the EXTRACT_ALL tag is set to YES doxygen will assume all entities in 
+# documentation are documented, even if no documentation was available. 
+# Private class members and static file members will be hidden unless 
+# the EXTRACT_PRIVATE and EXTRACT_STATIC tags are set to YES
+
+EXTRACT_ALL            = YES
+
+# If the EXTRACT_PRIVATE tag is set to YES all private members of a class 
+# will be included in the documentation.
+
+EXTRACT_PRIVATE        = YES
+
+# If the EXTRACT_STATIC tag is set to YES all static members of a file 
+# will be included in the documentation.
+
+EXTRACT_STATIC         = YES
+
+# If the EXTRACT_LOCAL_CLASSES tag is set to YES classes (and structs) 
+# defined locally in source files will be included in the documentation. 
+# If set to NO only classes defined in header files are included.
+
+EXTRACT_LOCAL_CLASSES  = YES
+
+# This flag is only useful for Objective-C code. When set to YES local 
+# methods, which are defined in the implementation section but not in 
+# the interface are included in the documentation. 
+# If set to NO (the default) only methods in the interface are included.
+
+EXTRACT_LOCAL_METHODS  = NO
+
+# If the HIDE_UNDOC_MEMBERS tag is set to YES, Doxygen will hide all 
+# undocumented members of documented classes, files or namespaces. 
+# If set to NO (the default) these members will be included in the 
+# various overviews, but no documentation section is generated. 
+# This option has no effect if EXTRACT_ALL is enabled.
+
+HIDE_UNDOC_MEMBERS     = NO
+
+# If the HIDE_UNDOC_CLASSES tag is set to YES, Doxygen will hide all 
+# undocumented classes that are normally visible in the class hierarchy. 
+# If set to NO (the default) these classes will be included in the various 
+# overviews. This option has no effect if EXTRACT_ALL is enabled.
+
+HIDE_UNDOC_CLASSES     = NO
+
+# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, Doxygen will hide all 
+# friend (class|struct|union) declarations. 
+# If set to NO (the default) these declarations will be included in the 
+# documentation.
+
+HIDE_FRIEND_COMPOUNDS  = NO
+
+# If the HIDE_IN_BODY_DOCS tag is set to YES, Doxygen will hide any 
+# documentation blocks found inside the body of a function. 
+# If set to NO (the default) these blocks will be appended to the 
+# function's detailed documentation block.
+
+HIDE_IN_BODY_DOCS      = NO
+
+# The INTERNAL_DOCS tag determines if documentation 
+# that is typed after a \internal command is included. If the tag is set 
+# to NO (the default) then the documentation will be excluded. 
+# Set it to YES to include the internal documentation.
+
+INTERNAL_DOCS          = NO
+
+# If the CASE_SENSE_NAMES tag is set to NO then Doxygen will only generate 
+# file names in lower-case letters. If set to YES upper-case letters are also 
+# allowed. This is useful if you have classes or files whose names only differ 
+# in case and if your file system supports case sensitive file names. Windows 
+# and Mac users are advised to set this option to NO.
+
+CASE_SENSE_NAMES       = YES
+
+# If the HIDE_SCOPE_NAMES tag is set to NO (the default) then Doxygen 
+# will show members with their full class and namespace scopes in the 
+# documentation. If set to YES the scope will be hidden.
+
+HIDE_SCOPE_NAMES       = NO
+
+# If the SHOW_INCLUDE_FILES tag is set to YES (the default) then Doxygen 
+# will put a list of the files that are included by a file in the documentation 
+# of that file.
+
+SHOW_INCLUDE_FILES     = YES
+
+# If the INLINE_INFO tag is set to YES (the default) then a tag [inline] 
+# is inserted in the documentation for inline members.
+
+INLINE_INFO            = YES
+
+# If the SORT_MEMBER_DOCS tag is set to YES (the default) then doxygen 
+# will sort the (detailed) documentation of file and class members 
+# alphabetically by member name. If set to NO the members will appear in 
+# declaration order.
+
+SORT_MEMBER_DOCS       = YES
+
+# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the 
+# brief documentation of file, namespace and class members alphabetically 
+# by member name. If set to NO (the default) the members will appear in 
+# declaration order.
+
+SORT_BRIEF_DOCS        = NO
+
+# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be 
+# sorted by fully-qualified names, including namespaces. If set to 
+# NO (the default), the class list will be sorted only by class name, 
+# not including the namespace part. 
+# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES.
+# Note: This option applies only to the class list, not to the 
+# alphabetical list.
+
+SORT_BY_SCOPE_NAME     = NO
+
+# The GENERATE_TODOLIST tag can be used to enable (YES) or 
+# disable (NO) the todo list. This list is created by putting \todo 
+# commands in the documentation.
+
+GENERATE_TODOLIST      = YES
+
+# The GENERATE_TESTLIST tag can be used to enable (YES) or 
+# disable (NO) the test list. This list is created by putting \test 
+# commands in the documentation.
+
+GENERATE_TESTLIST      = YES
+
+# The GENERATE_BUGLIST tag can be used to enable (YES) or 
+# disable (NO) the bug list. This list is created by putting \bug 
+# commands in the documentation.
+
+GENERATE_BUGLIST       = YES
+
+# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or 
+# disable (NO) the deprecated list. This list is created by putting 
+# \deprecated commands in the documentation.
+
+GENERATE_DEPRECATEDLIST= YES
+
+# The ENABLED_SECTIONS tag can be used to enable conditional 
+# documentation sections, marked by \if sectionname ... \endif.
+
+ENABLED_SECTIONS       = 
+
+# The MAX_INITIALIZER_LINES tag determines the maximum number of lines 
+# the initial value of a variable or define consists of for it to appear in 
+# the documentation. If the initializer consists of more lines than specified 
+# here it will be hidden. Use a value of 0 to hide initializers completely. 
+# The appearance of the initializer of individual variables and defines in the 
+# documentation can be controlled using \showinitializer or \hideinitializer 
+# command in the documentation regardless of this setting.
+
+MAX_INITIALIZER_LINES  = 30
+
+# Set the SHOW_USED_FILES tag to NO to disable the list of files generated 
+# at the bottom of the documentation of classes and structs. If set to YES the 
+# list will mention the files that were used to generate the documentation.
+
+SHOW_USED_FILES        = YES
+
+# If the sources in your project are distributed over multiple directories 
+# then setting the SHOW_DIRECTORIES tag to YES will show the directory hierarchy 
+# in the documentation. The default is NO.
+
+SHOW_DIRECTORIES       = YES
+
+# The FILE_VERSION_FILTER tag can be used to specify a program or script that 
+# doxygen should invoke to get the current version for each file (typically from the 
+# version control system). Doxygen will invoke the program by executing (via 
+# popen()) the command <command> <input-file>, where <command> is the value of 
+# the FILE_VERSION_FILTER tag, and <input-file> is the name of an input file 
+# provided by doxygen. Whatever the program writes to standard output 
+# is used as the file version. See the manual for examples.
+
+FILE_VERSION_FILTER    = 
+
+#---------------------------------------------------------------------------
+# configuration options related to warning and progress messages
+#---------------------------------------------------------------------------
+
+# The QUIET tag can be used to turn on/off the messages that are generated 
+# by doxygen. Possible values are YES and NO. If left blank NO is used.
+
+QUIET                  = NO
+
+# The WARNINGS tag can be used to turn on/off the warning messages that are 
+# generated by doxygen. Possible values are YES and NO. If left blank 
+# NO is used.
+
+WARNINGS               = YES
+
+# If WARN_IF_UNDOCUMENTED is set to YES, then doxygen will generate warnings 
+# for undocumented members. If EXTRACT_ALL is set to YES then this flag will 
+# automatically be disabled.
+
+WARN_IF_UNDOCUMENTED   = NO
+
+# If WARN_IF_DOC_ERROR is set to YES, doxygen will generate warnings for 
+# potential errors in the documentation, such as not documenting some 
+# parameters in a documented function, or documenting parameters that 
+# don't exist or using markup commands wrongly.
+
+WARN_IF_DOC_ERROR      = YES
+
+# This WARN_NO_PARAMDOC option can be abled to get warnings for 
+# functions that are documented, but have no documentation for their parameters 
+# or return value. If set to NO (the default) doxygen will only warn about 
+# wrong or incomplete parameter documentation, but not about the absence of 
+# documentation.
+
+WARN_NO_PARAMDOC       = NO
+
+# The WARN_FORMAT tag determines the format of the warning messages that 
+# doxygen can produce. The string should contain the $file, $line, and $text 
+# tags, which will be replaced by the file and line number from which the 
+# warning originated and the warning text. Optionally the format may contain 
+# $version, which will be replaced by the version of the file (if it could 
+# be obtained via FILE_VERSION_FILTER)
+
+WARN_FORMAT            = 
+
+# The WARN_LOGFILE tag can be used to specify a file to which warning 
+# and error messages should be written. If left blank the output is written 
+# to stderr.
+
+WARN_LOGFILE           = 
+
+#---------------------------------------------------------------------------
+# configuration options related to the input files
+#---------------------------------------------------------------------------
+
+# The INPUT tag can be used to specify the files and/or directories that contain 
+# documented source files. You may enter file names like "myfile.cpp" or 
+# directories like "/usr/src/myproject". Separate the files or directories 
+# with spaces.
+
+INPUT                  = ../plearn \
+                         ../plearn_learners \
+                         ../plearn_learners_experimental \
+                         ../commands
+
+# This tag can be used to specify the character encoding of the source files that 
+# doxygen parses. Internally doxygen uses the UTF-8 encoding, which is also the default 
+# input encoding. Doxygen uses libiconv (or the iconv built into libc) for the transcoding. 
+# See http://www.gnu.org/software/libiconv for the list of possible encodings.
+
+INPUT_ENCODING         = UTF-8
+
+# If the value of the INPUT tag contains directories, you can use the 
+# FILE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
+# and *.h) to filter out the source-files in the directories. If left 
+# blank the following patterns are tested: 
+# *.c *.cc *.cxx *.cpp *.c++ *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh *.hxx 
+# *.hpp *.h++ *.idl *.odl *.cs *.php *.php3 *.inc *.m *.mm *.py
+
+FILE_PATTERNS          = *.cc \
+                         *.h
+
+# The RECURSIVE tag can be used to turn specify whether or not subdirectories 
+# should be searched for input files as well. Possible values are YES and NO. 
+# If left blank NO is used.
+
+RECURSIVE              = YES
+
+# The EXCLUDE tag can be used to specify files and/or directories that should 
+# excluded from the INPUT source files. This way you can easily exclude a 
+# subdirectory from a directory tree whose root is specified with the INPUT tag.
+
+EXCLUDE                = 
+
+# The EXCLUDE_SYMLINKS tag can be used select whether or not files or 
+# directories that are symbolic links (a Unix filesystem feature) are excluded 
+# from the input.
+
+EXCLUDE_SYMLINKS       = NO
+
+# If the value of the INPUT tag contains directories, you can use the 
+# EXCLUDE_PATTERNS tag to specify one or more wildcard patterns to exclude 
+# certain files from those directories. Note that the wildcards are matched 
+# against the file with absolute path, so to exclude all test directories 
+# for example use the pattern */test/*
+
+EXCLUDE_PATTERNS       = OBJS \
+                         .svn \
+                         .pytest
+
+# The EXCLUDE_SYMBOLS tag can be used to specify one or more symbol names 
+# (namespaces, classes, functions, etc.) that should be excluded from the output. 
+# The symbol name can be a fully qualified name, a word, or if the wildcard * is used, 
+# a substring. Examples: ANamespace, AClass, AClass::ANamespace, ANamespace::*Test
+
+EXCLUDE_SYMBOLS        = 
+
+# The EXAMPLE_PATH tag can be used to specify one or more files or 
+# directories that contain example code fragments that are included (see 
+# the \include command).
+
+EXAMPLE_PATH           = 
+
+# If the value of the EXAMPLE_PATH tag contains directories, you can use the 
+# EXAMPLE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
+# and *.h) to filter out the source-files in the directories. If left 
+# blank all files are included.
+
+EXAMPLE_PATTERNS       = 
+
+# If the EXAMPLE_RECURSIVE tag is set to YES then subdirectories will be 
+# searched for input files to be used with the \include or \dontinclude 
+# commands irrespective of the value of the RECURSIVE tag. 
+# Possible values are YES and NO. If left blank NO is used.
+
+EXAMPLE_RECURSIVE      = NO
+
+# The IMAGE_PATH tag can be used to specify one or more files or 
+# directories that contain image that are included in the documentation (see 
+# the \image command).
+
+IMAGE_PATH             = 
+
+# The INPUT_FILTER tag can be used to specify a program that doxygen should 
+# invoke to filter for each input file. Doxygen will invoke the filter program 
+# by executing (via popen()) the command <filter> <input-file>, where <filter> 
+# is the value of the INPUT_FILTER tag, and <input-file> is the name of an 
+# input file. Doxygen will then use the output that the filter program writes 
+# to standard output.  If FILTER_PATTERNS is specified, this tag will be 
+# ignored.
+
+INPUT_FILTER           = 
+
+# The FILTER_PATTERNS tag can be used to specify filters on a per file pattern 
+# basis.  Doxygen will compare the file name with each pattern and apply the 
+# filter if there is a match.  The filters are a list of the form: 
+# pattern=filter (like *.cpp=my_cpp_filter). See INPUT_FILTER for further 
+# info on how filters are used. If FILTER_PATTERNS is empty, INPUT_FILTER 
+# is applied to all files.
+
+FILTER_PATTERNS        = 
+
+# If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using 
+# INPUT_FILTER) will be used to filter the input files when producing source 
+# files to browse (i.e. when SOURCE_BROWSER is set to YES).
+
+FILTER_SOURCE_FILES    = NO
+
+#---------------------------------------------------------------------------
+# configuration options related to source browsing
+#---------------------------------------------------------------------------
+
+# If the SOURCE_BROWSER tag is set to YES then a list of source files will 
+# be generated. Documented entities will be cross-referenced with these sources. 
+# Note: To get rid of all source code in the generated output, make sure also 
+# VERBATIM_HEADERS is set to NO.
+
+SOURCE_BROWSER         = YES
+
+# Setting the INLINE_SOURCES tag to YES will include the body 
+# of functions and classes directly in the documentation.
+
+INLINE_SOURCES         = YES
+
+# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct 
+# doxygen to hide any special comment blocks from generated source code 
+# fragments. Normal C and C++ comments will always remain visible.
+
+STRIP_CODE_COMMENTS    = YES
+
+# If the REFERENCED_BY_RELATION tag is set to YES (the default) 
+# then for each documented function all documented 
+# functions referencing it will be listed.
+
+REFERENCED_BY_RELATION = YES
+
+# If the REFERENCES_RELATION tag is set to YES (the default) 
+# then for each documented function all documented entities 
+# called/used by that function will be listed.
+
+REFERENCES_RELATION    = YES
+
+# If the REFERENCES_LINK_SOURCE tag is set to YES (the default)
+# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from
+# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will
+# link to the source code.  Otherwise they will link to the documentstion.
+
+REFERENCES_LINK_SOURCE = YES
+
+# If the USE_HTAGS tag is set to YES then the references to source code 
+# will point to the HTML generated by the htags(1) tool instead of doxygen 
+# built-in source browser. The htags tool is part of GNU's global source 
+# tagging system (see http://www.gnu.org/software/global/global.html). You 
+# will need version 4.8.6 or higher.
+
+USE_HTAGS              = NO
+
+# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen 
+# will generate a verbatim copy of the header file for each class for 
+# which an include is specified. Set to NO to disable this.
+
+VERBATIM_HEADERS       = YES
+
+#---------------------------------------------------------------------------
+# configuration options related to the alphabetical class index
+#---------------------------------------------------------------------------
+
+# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index 
+# of all compounds will be generated. Enable this if the project 
+# contains a lot of classes, structs, unions or interfaces.
+
+ALPHABETICAL_INDEX     = YES
+
+# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then 
+# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns 
+# in which this list will be split (can be a number in the range [1..20])
+
+COLS_IN_ALPHA_INDEX    = 5
+
+# In case all classes in a project start with a common prefix, all 
+# classes will be put under the same header in the alphabetical index. 
+# The IGNORE_PREFIX tag can be used to specify one or more prefixes that 
+# should be ignored while generating the index headers.
+
+IGNORE_PREFIX          = 
+
+#---------------------------------------------------------------------------
+# configuration options related to the HTML output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_HTML tag is set to YES (the default) Doxygen will 
+# generate HTML output.
+
+GENERATE_HTML          = YES
+
+# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `html' will be used as the default path.
+
+HTML_OUTPUT            = 
+
+# The HTML_FILE_EXTENSION tag can be used to specify the file extension for 
+# each generated HTML page (for example: .htm,.php,.asp). If it is left blank 
+# doxygen will generate files with .html extension.
+
+HTML_FILE_EXTENSION    = .html
+
+# The HTML_HEADER tag can be used to specify a personal HTML header for 
+# each generated HTML page. If it is left blank doxygen will generate a 
+# standard header.
+
+HTML_HEADER            = 
+
+# The HTML_FOOTER tag can be used to specify a personal HTML footer for 
+# each generated HTML page. If it is left blank doxygen will generate a 
+# standard footer.
+
+HTML_FOOTER            = 
+
+# The HTML_STYLESHEET tag can be used to specify a user-defined cascading 
+# style sheet that is used by each HTML page. It can be used to 
+# fine-tune the look of the HTML output. If the tag is left blank doxygen 
+# will generate a default style sheet. Note that doxygen will try to copy 
+# the style sheet file to the HTML output directory, so don't put your own 
+# stylesheet in the HTML output directory as well, or it will be erased!
+
+HTML_STYLESHEET        = 
+
+# If the HTML_ALIGN_MEMBERS tag is set to YES, the members of classes, 
+# files or namespaces will be aligned in HTML using tables. If set to 
+# NO a bullet list will be used.
+
+HTML_ALIGN_MEMBERS     = YES
+
+# If the GENERATE_HTMLHELP tag is set to YES, additional index files 
+# will be generated that can be used as input for tools like the 
+# Microsoft HTML help workshop to generate a compressed HTML help file (.chm) 
+# of the generated HTML documentation.
+
+GENERATE_HTMLHELP      = NO
+
+# If the GENERATE_HTMLHELP tag is set to YES, the CHM_FILE tag can 
+# be used to specify the file name of the resulting .chm file. You 
+# can add a path in front of the file if the result should not be 
+# written to the html output directory.
+
+CHM_FILE               = 
+
+# If the GENERATE_HTMLHELP tag is set to YES, the HHC_LOCATION tag can 
+# be used to specify the location (absolute path including file name) of 
+# the HTML help compiler (hhc.exe). If non-empty doxygen will try to run 
+# the HTML help compiler on the generated index.hhp.
+
+HHC_LOCATION           = 
+
+# If the GENERATE_HTMLHELP tag is set to YES, the GENERATE_CHI flag 
+# controls if a separate .chi index file is generated (YES) or that 
+# it should be included in the master .chm file (NO).
+
+GENERATE_CHI           = NO
+
+# If the GENERATE_HTMLHELP tag is set to YES, the BINARY_TOC flag 
+# controls whether a binary table of contents is generated (YES) or a 
+# normal table of contents (NO) in the .chm file.
+
+BINARY_TOC             = NO
+
+# The TOC_EXPAND flag can be set to YES to add extra items for group members 
+# to the contents of the HTML help documentation and to the tree view.
+
+TOC_EXPAND             = NO
+
+# The DISABLE_INDEX tag can be used to turn on/off the condensed index at 
+# top of each HTML page. The value NO (the default) enables the index and 
+# the value YES disables it.
+
+DISABLE_INDEX          = NO
+
+# This tag can be used to set the number of enum values (range [1..20]) 
+# that doxygen will group on one line in the generated HTML documentation.
+
+ENUM_VALUES_PER_LINE   = 4
+
+# If the GENERATE_TREEVIEW tag is set to YES, a side panel will be
+# generated containing a tree-like index structure (just like the one that 
+# is generated for HTML Help). For this to work a browser that supports 
+# JavaScript, DHTML, CSS and frames is required (for instance Mozilla 1.0+, 
+# Netscape 6.0+, Internet explorer 5.0+, or Konqueror). Windows users are 
+# probably better off using the HTML help feature.
+
+GENERATE_TREEVIEW      = NO
+
+# If the treeview is enabled (see GENERATE_TREEVIEW) then this tag can be 
+# used to set the initial width (in pixels) of the frame in which the tree 
+# is shown.
+
+TREEVIEW_WIDTH         = 250
+
+#---------------------------------------------------------------------------
+# configuration options related to the LaTeX output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will 
+# generate Latex output.
+
+GENERATE_LATEX         = YES
+
+# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `latex' will be used as the default path.
+
+LATEX_OUTPUT           = 
+
+# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be 
+# invoked. If left blank `latex' will be used as the default command name.
+
+LATEX_CMD_NAME         = latex
+
+# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to 
+# generate index for LaTeX. If left blank `makeindex' will be used as the 
+# default command name.
+
+MAKEINDEX_CMD_NAME     = makeindex
+
+# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact 
+# LaTeX documents. This may be useful for small projects and may help to 
+# save some trees in general.
+
+COMPACT_LATEX          = NO
+
+# The PAPER_TYPE tag can be used to set the paper type that is used 
+# by the printer. Possible values are: a4, a4wide, letter, legal and 
+# executive. If left blank a4wide will be used.
+
+PAPER_TYPE             = letter
+
+# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX 
+# packages that should be included in the LaTeX output.
+
+EXTRA_PACKAGES         = 
+
+# The LATEX_HEADER tag can be used to specify a personal LaTeX header for 
+# the generated latex document. The header should contain everything until 
+# the first chapter. If it is left blank doxygen will generate a 
+# standard header. Notice: only use this tag if you know what you are doing!
+
+LATEX_HEADER           = 
+
+# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated 
+# is prepared for conversion to pdf (using ps2pdf). The pdf file will 
+# contain links (just like the HTML output) instead of page references 
+# This makes the output suitable for online browsing using a pdf viewer.
+
+PDF_HYPERLINKS         = YES
+
+# If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of 
+# plain latex in the generated Makefile. Set this option to YES to get a 
+# higher quality PDF documentation.
+
+USE_PDFLATEX           = YeS
+
+# If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\batchmode. 
+# command to the generated LaTeX files. This will instruct LaTeX to keep 
+# running if errors occur, instead of asking the user for help. 
+# This option is also used when generating formulas in HTML.
+
+LATEX_BATCHMODE        = YES
+
+# If LATEX_HIDE_INDICES is set to YES then doxygen will not 
+# include the index chapters (such as File Index, Compound Index, etc.) 
+# in the output.
+
+LATEX_HIDE_INDICES     = NO
+
+#---------------------------------------------------------------------------
+# configuration options related to the RTF output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_RTF tag is set to YES Doxygen will generate RTF output 
+# The RTF output is optimized for Word 97 and may not look very pretty with 
+# other RTF readers or editors.
+
+GENERATE_RTF           = NO
+
+# The RTF_OUTPUT tag is used to specify where the RTF docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `rtf' will be used as the default path.
+
+RTF_OUTPUT             = 
+
+# If the COMPACT_RTF tag is set to YES Doxygen generates more compact 
+# RTF documents. This may be useful for small projects and may help to 
+# save some trees in general.
+
+COMPACT_RTF            = NO
+
+# If the RTF_HYPERLINKS tag is set to YES, the RTF that is generated 
+# will contain hyperlink fields. The RTF file will 
+# contain links (just like the HTML output) instead of page references. 
+# This makes the output suitable for online browsing using WORD or other 
+# programs which support those fields. 
+# Note: wordpad (write) and others do not support links.
+
+RTF_HYPERLINKS         = NO
+
+# Load stylesheet definitions from file. Syntax is similar to doxygen's 
+# config file, i.e. a series of assignments. You only have to provide 
+# replacements, missing definitions are set to their default value.
+
+RTF_STYLESHEET_FILE    = 
+
+# Set optional variables used in the generation of an rtf document. 
+# Syntax is similar to doxygen's config file.
+
+RTF_EXTENSIONS_FILE    = 
+
+#---------------------------------------------------------------------------
+# configuration options related to the man page output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_MAN tag is set to YES (the default) Doxygen will 
+# generate man pages
+
+GENERATE_MAN           = NO
+
+# The MAN_OUTPUT tag is used to specify where the man pages will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `man' will be used as the default path.
+
+MAN_OUTPUT             = 
+
+# The MAN_EXTENSION tag determines the extension that is added to 
+# the generated man pages (default is the subroutine's section .3)
+
+MAN_EXTENSION          = 
+
+# If the MAN_LINKS tag is set to YES and Doxygen generates man output, 
+# then it will generate one additional man file for each entity 
+# documented in the real man page(s). These additional files 
+# only source the real man page, but without them the man command 
+# would be unable to find the correct page. The default is NO.
+
+MAN_LINKS              = NO
+
+#---------------------------------------------------------------------------
+# configuration options related to the XML output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_XML tag is set to YES Doxygen will 
+# generate an XML file that captures the structure of 
+# the code including all documentation.
+
+GENERATE_XML           = YES
+
+# The XML_OUTPUT tag is used to specify where the XML pages will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `xml' will be used as the default path.
+
+XML_OUTPUT             = xml
+
+# The XML_SCHEMA tag can be used to specify an XML schema, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
+XML_SCHEMA             = 
+
+# The XML_DTD tag can be used to specify an XML DTD, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
+XML_DTD                = 
+
+# If the XML_PROGRAMLISTING tag is set to YES Doxygen will 
+# dump the program listings (including syntax highlighting 
+# and cross-referencing information) to the XML output. Note that 
+# enabling this will significantly increase the size of the XML output.
+
+XML_PROGRAMLISTING     = YES
+
+#---------------------------------------------------------------------------
+# configuration options for the AutoGen Definitions output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_AUTOGEN_DEF tag is set to YES Doxygen will 
+# generate an AutoGen Definitions (see autogen.sf.net) file 
+# that captures the structure of the code including all 
+# documentation. Note that this feature is still experimental 
+# and incomplete at the moment.
+
+GENERATE_AUTOGEN_DEF   = NO
+
+#---------------------------------------------------------------------------
+# configuration options related to the Perl module output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_PERLMOD tag is set to YES Doxygen will 
+# generate a Perl module file that captures the structure of 
+# the code including all documentation. Note that this 
+# feature is still experimental and incomplete at the 
+# moment.
+
+GENERATE_PERLMOD       = NO
+
+# If the PERLMOD_LATEX tag is set to YES Doxygen will generate 
+# the necessary Makefile rules, Perl scripts and LaTeX code to be able 
+# to generate PDF and DVI output from the Perl module output.
+
+PERLMOD_LATEX          = NO
+
+# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be 
+# nicely formatted so it can be parsed by a human reader.  This is useful 
+# if you want to understand what is going on.  On the other hand, if this 
+# tag is set to NO the size of the Perl module output will be much smaller 
+# and Perl will parse it just the same.
+
+PERLMOD_PRETTY         = YES
+
+# The names of the make variables in the generated doxyrules.make file 
+# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX. 
+# This is useful so different doxyrules.make files included by the same 
+# Makefile don't overwrite each other's variables.
+
+PERLMOD_MAKEVAR_PREFIX = 
+
+#---------------------------------------------------------------------------
+# Configuration options related to the preprocessor   
+#---------------------------------------------------------------------------
+
+# If the ENABLE_PREPROCESSING tag is set to YES (the default) Doxygen will 
+# evaluate all C-preprocessor directives found in the sources and include 
+# files.
+
+ENABLE_PREPROCESSING   = YES
+
+# If the MACRO_EXPANSION tag is set to YES Doxygen will expand all macro 
+# names in the source code. If set to NO (the default) only conditional 
+# compilation will be performed. Macro expansion can be done in a controlled 
+# way by setting EXPAND_ONLY_PREDEF to YES.
+
+MACRO_EXPANSION        = YES
+
+# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES 
+# then the macro expansion is limited to the macros specified with the 
+# PREDEFINED and EXPAND_AS_DEFINED tags.
+
+EXPAND_ONLY_PREDEF     = YES
+
+# If the SEARCH_INCLUDES tag is set to YES (the default) the includes files 
+# in the INCLUDE_PATH (see below) will be search if a #include is found.
+
+SEARCH_INCLUDES        = YES
+
+# The INCLUDE_PATH tag can be used to specify one or more directories that 
+# contain include files that are not input files but should be processed by 
+# the preprocessor.
+
+INCLUDE_PATH           = 
+
+# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard 
+# patterns (like *.h and *.hpp) to filter out the header-files in the 
+# directories. If left blank, the patterns specified with FILE_PATTERNS will 
+# be used.
+
+INCLUDE_FILE_PATTERNS  = 
+
+# The PREDEFINED tag can be used to specify one or more macro names that 
+# are defined before the preprocessor is started (similar to the -D option of 
+# gcc). The argument of the tag is a list of macros of the form: name 
+# or name=definition (no spaces). If the definition and the = are 
+# omitted =1 is assumed. To prevent a macro definition from being 
+# undefined via #undef or recursively expanded use the := operator 
+# instead of the = operator.
+
+PREDEFINED             = 
+
+# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then 
+# this tag can be used to specify a list of macro names that should be expanded. 
+# The macro definition that is found in the sources will be used. 
+# Use the PREDEFINED tag if you want to use a different macro definition.
+
+EXPAND_AS_DEFINED      = PLEARN_DECLARE_OBJECT \
+                         PLEARN_IMPLEMENT_OBJECT \
+                         DECLARE_OBJECT_PTR \
+                         DECLARE_TEMPLATE_OBJECT_PTR \
+                         DECLARE_TYPE_TRAITS \
+                         DECLARE_OBJECT_PP \
+                         PLEARN_DECLARE_ABSTRACT_OBJECT \
+                         PLEARN_IMPLEMENT_ABSTRACT_OBJECT \
+                         PLEARN_DECLARE_TEMPLATE_OBJECT \
+                         PLEARN_IMPLEMENT_TEMPLATE_OBJECT
+
+# If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then 
+# doxygen's preprocessor will remove all function-like macros that are alone 
+# on a line, have an all uppercase name, and do not end with a semicolon. Such 
+# function macros are typically used for boiler-plate code, and will confuse 
+# the parser if not removed.
+
+SKIP_FUNCTION_MACROS   = YES
+
+#---------------------------------------------------------------------------
+# Configuration::additions related to external references   
+#---------------------------------------------------------------------------
+
+# The TAGFILES option can be used to specify one or more tagfiles. 
+# Optionally an initial location of the external documentation 
+# can be added for each tagfile. The format of a tag file without 
+# this location is as follows: 
+#   TAGFILES = file1 file2 ... 
+# Adding location for the tag files is done as follows: 
+#   TAGFILES = file1=loc1 "file2 = loc2" ... 
+# where "loc1" and "loc2" can be relative or absolute paths or 
+# URLs. If a location is present for each tag, the installdox tool 
+# does not have to be run to correct the links.
+# Note that each tag file must have a unique name
+# (where the name does NOT include the path)
+# If a tag file is not located in the directory in which doxygen 
+# is run, you must also specify the path to the tagfile here.
+
+TAGFILES               = 
+
+# When a file name is specified after GENERATE_TAGFILE, doxygen will create 
+# a tag file that is based on the input files it reads.
+
+GENERATE_TAGFILE       = plearn.tag
+
+# If the ALLEXTERNALS tag is set to YES all external classes will be listed 
+# in the class index. If set to NO only the inherited external classes 
+# will be listed.
+
+ALLEXTERNALS           = NO
+
+# If the EXTERNAL_GROUPS tag is set to YES all external groups will be listed 
+# in the modules index. If set to NO, only the current project's groups will 
+# be listed.
+
+EXTERNAL_GROUPS        = YES
+
+# The PERL_PATH should be the absolute path and name of the perl script 
+# interpreter (i.e. the result of `which perl').
+
+PERL_PATH              = 
+
+#---------------------------------------------------------------------------
+# Configuration options related to the dot tool   
+#---------------------------------------------------------------------------
+
+# If the CLASS_DIAGRAMS tag is set to YES (the default) Doxygen will 
+# generate a inheritance diagram (in HTML, RTF and LaTeX) for classes with base 
+# or super classes. Setting the tag to NO turns the diagrams off. Note that 
+# this option is superseded by the HAVE_DOT option below. This is only a 
+# fallback. It is recommended to install and use dot, since it yields more 
+# powerful graphs.
+
+CLASS_DIAGRAMS         = YES
+
+# You can define message sequence charts within doxygen comments using the \msc 
+# command. Doxygen will then run the mscgen tool (see http://www.mcternan.me.uk/mscgen/) to 
+# produce the chart and insert it in the documentation. The MSCGEN_PATH tag allows you to 
+# specify the directory where the mscgen tool resides. If left empty the tool is assumed to 
+# be found in the default search path.
+
+MSCGEN_PATH            = 
+
+# If set to YES, the inheritance and collaboration graphs will hide 
+# inheritance and usage relations if the target is undocumented 
+# or is not a class.
+
+HIDE_UNDOC_RELATIONS   = NO
+
+# If you set the HAVE_DOT tag to YES then doxygen will assume the dot tool is 
+# available from the path. This tool is part of Graphviz, a graph visualization 
+# toolkit from AT&T and Lucent Bell Labs. The other options in this section 
+# have no effect if this option is set to NO (the default)
+
+HAVE_DOT               = YES
+
+# If the CLASS_GRAPH and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for each documented class showing the direct and 
+# indirect inheritance relations. Setting this tag to YES will force the 
+# the CLASS_DIAGRAMS tag to NO.
+
+CLASS_GRAPH            = YES
+
+# If the COLLABORATION_GRAPH and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for each documented class showing the direct and 
+# indirect implementation dependencies (inheritance, containment, and 
+# class references variables) of the class with other documented classes.
+
+COLLABORATION_GRAPH    = YES
+
+# If the GROUP_GRAPHS and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for groups, showing the direct groups dependencies
+
+GROUP_GRAPHS           = YES
+
+# If the UML_LOOK tag is set to YES doxygen will generate inheritance and 
+# collaboration diagrams in a style similar to the OMG's Unified Modeling 
+# Language.
+
+UML_LOOK               = NO
+
+# If set to YES, the inheritance and collaboration graphs will show the 
+# relations between templates and their instances.
+
+TEMPLATE_RELATIONS     = YES
+
+# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDE_GRAPH, and HAVE_DOT 
+# tags are set to YES then doxygen will generate a graph for each documented 
+# file showing the direct and indirect include dependencies of the file with 
+# other documented files.
+
+INCLUDE_GRAPH          = YES
+
+# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDED_BY_GRAPH, and 
+# HAVE_DOT tags are set to YES then doxygen will generate a graph for each 
+# documented header file showing the documented files that directly or 
+# indirectly include this file.
+
+INCLUDED_BY_GRAPH      = YES
+
+# If the CALL_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a call dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable call graphs for selected 
+# functions only using the \callgraph command.
+
+CALL_GRAPH             = YES
+
+# If the CALLER_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a caller dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable caller graphs for selected 
+# functions only using the \callergraph command.
+
+CALLER_GRAPH           = YES
+
+# If the GRAPHICAL_HIERARCHY and HAVE_DOT tags are set to YES then doxygen 
+# will graphical hierarchy of all classes instead of a textual one.
+
+GRAPHICAL_HIERARCHY    = YES
+
+# If the DIRECTORY_GRAPH, SHOW_DIRECTORIES and HAVE_DOT tags are set to YES 
+# then doxygen will show the dependencies a directory has on other directories 
+# in a graphical way. The dependency relations are determined by the #include
+# relations between the files in the directories.
+
+DIRECTORY_GRAPH        = YES
+
+# The DOT_IMAGE_FORMAT tag can be used to set the image format of the images 
+# generated by dot. Possible values are png, jpg, or gif
+# If left blank png will be used.
+
+DOT_IMAGE_FORMAT       = png
+
+# The tag DOT_PATH can be used to specify the path where the dot tool can be 
+# found. If left blank, it is assumed the dot tool can be found in the path.
+
+DOT_PATH               = 
+
+# The DOTFILE_DIRS tag can be used to specify one or more directories that 
+# contain dot files that are included in the documentation (see the 
+# \dotfile command).
+
+DOTFILE_DIRS           = 
+
+# The MAX_DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of 
+# nodes that will be shown in the graph. If the number of nodes in a graph 
+# becomes larger than this value, doxygen will truncate the graph, which is 
+# visualized by representing a node as a red box. Note that doxygen will always 
+# show the root nodes and its direct children regardless of this setting.
+
+DOT_GRAPH_MAX_NODES    = 50
+
+# Set the DOT_TRANSPARENT tag to YES to generate images with a transparent 
+# background. This is disabled by default, which results in a white background. 
+# Warning: Depending on the platform used, enabling this option may lead to 
+# badly anti-aliased labels on the edges of a graph (i.e. they become hard to 
+# read).
+
+DOT_TRANSPARENT        = NO
+
+# Set the DOT_MULTI_TARGETS tag to YES allow dot to generate multiple output 
+# files in one run (i.e. multiple -o and -T options on the command line). This 
+# makes dot run faster, but since only newer versions of dot (>1.8.10) 
+# support this, this feature is disabled by default.
+
+DOT_MULTI_TARGETS      = YES
+
+# If the GENERATE_LEGEND tag is set to YES (the default) Doxygen will 
+# generate a legend page explaining the meaning of the various boxes and 
+# arrows in the dot generated graphs.
+
+GENERATE_LEGEND        = YES
+
+# If the DOT_CLEANUP tag is set to YES (the default) Doxygen will 
+# remove the intermediate dot files that are used to generate 
+# the various graphs.
+
+DOT_CLEANUP            = YES
+
+#---------------------------------------------------------------------------
+# Configuration::additions related to the search engine   
+#---------------------------------------------------------------------------
+
+# The SEARCHENGINE tag specifies whether or not a search engine should be 
+# used. If set to NO the values of all tags below this one will be ignored.
+
+SEARCHENGINE           = YES



From nouiz at mail.berlios.de  Mon Nov 12 19:11:31 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 12 Nov 2007 19:11:31 +0100
Subject: [Plearn-commits] r8243 - trunk/plearn/base
Message-ID: <200711121811.lACIBVSK019637@sheep.berlios.de>

Author: nouiz
Date: 2007-11-12 19:11:30 +0100 (Mon, 12 Nov 2007)
New Revision: 8243

Modified:
   trunk/plearn/base/Array.h
   trunk/plearn/base/Array_decl.h
   trunk/plearn/base/Array_impl.h
   trunk/plearn/base/HelpSystem.h
   trunk/plearn/base/Object.h
   trunk/plearn/base/Option.h
   trunk/plearn/base/OptionBase.h
   trunk/plearn/base/PDate.h
   trunk/plearn/base/PDateTime.h
   trunk/plearn/base/PP.h
   trunk/plearn/base/ProgressBar.h
   trunk/plearn/base/Range.h
Log:
corrected path for doxygen


Modified: trunk/plearn/base/Array.h
===================================================================
--- trunk/plearn/base/Array.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/Array.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Array.h */
+/*! \file Array.h */
 
 #include "Array_impl.h"
 

Modified: trunk/plearn/base/Array_decl.h
===================================================================
--- trunk/plearn/base/Array_decl.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/Array_decl.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Array.h */
+/*! \file Array.h */
 
 #ifndef Array_decl_INC
 #define Array_decl_INC

Modified: trunk/plearn/base/Array_impl.h
===================================================================
--- trunk/plearn/base/Array_impl.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/Array_impl.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Array.h */
+/*! \file Array.h */
 
 #ifndef Array_impl_INC
 #define Array_impl_INC

Modified: trunk/plearn/base/HelpSystem.h
===================================================================
--- trunk/plearn/base/HelpSystem.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/HelpSystem.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnCore/HelpSystem.h */
+/*! \file HelpSystem.h */
 
 #ifndef HelpSystem_INC
 #define HelpSystem_INC

Modified: trunk/plearn/base/Object.h
===================================================================
--- trunk/plearn/base/Object.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/Object.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Object.h */
+/*! \file Object.h */
 
 #ifndef Object_INC
 #define Object_INC

Modified: trunk/plearn/base/Option.h
===================================================================
--- trunk/plearn/base/Option.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/Option.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Option.h */
+/*! \file Option.h */
 
 #ifndef Option_INC
 #define Option_INC

Modified: trunk/plearn/base/OptionBase.h
===================================================================
--- trunk/plearn/base/OptionBase.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/OptionBase.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Option.h */
+/*! \file Option.h */
 
 #ifndef OptionBase_INC
 #define OptionBase_INC

Modified: trunk/plearn/base/PDate.h
===================================================================
--- trunk/plearn/base/PDate.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/PDate.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/PDate.h */
+/*! \file PDate.h */
 
 #ifndef PDate_INC
 #define PDate_INC

Modified: trunk/plearn/base/PDateTime.h
===================================================================
--- trunk/plearn/base/PDateTime.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/PDateTime.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -37,7 +37,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/PDateTime.h */
+/*! \file PDateTime.h */
 
 #ifndef PDateTime_INC
 #define PDateTime_INC

Modified: trunk/plearn/base/PP.h
===================================================================
--- trunk/plearn/base/PP.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/PP.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/SmartPointer.h */
+/*! \file SmartPointer.h */
 
 #ifndef SMART_POINTER_INC
 #define SMART_POINTER_INC

Modified: trunk/plearn/base/ProgressBar.h
===================================================================
--- trunk/plearn/base/ProgressBar.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/ProgressBar.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -47,7 +47,7 @@
 // that are used in the PLearn Library
 
 
-/*! \file PLearnLibrary/PLearnCore/ProgressBar.h */
+/*! \file ProgressBar.h */
 
 #ifndef ProgressBar_INC
 #define ProgressBar_INC

Modified: trunk/plearn/base/Range.h
===================================================================
--- trunk/plearn/base/Range.h	2007-11-09 21:10:32 UTC (rev 8242)
+++ trunk/plearn/base/Range.h	2007-11-12 18:11:30 UTC (rev 8243)
@@ -45,7 +45,7 @@
 // See Mat.h for a description the PLearn native binary file format for matrices and vectors (.pmat .pvec)
 
 
-/*! \file PLearnLibrary/PLearnCore/Range.h */
+/*! \file Range.h */
 
 #ifndef Range_INC
 #define Range_INC



From nouiz at mail.berlios.de  Mon Nov 12 19:12:28 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 12 Nov 2007 19:12:28 +0100
Subject: [Plearn-commits] r8244 - trunk/plearn/vmat
Message-ID: <200711121812.lACICSjw020036@sheep.berlios.de>

Author: nouiz
Date: 2007-11-12 19:12:27 +0100 (Mon, 12 Nov 2007)
New Revision: 8244

Modified:
   trunk/plearn/vmat/FilteredVMatrix.cc
Log:
Lock metadata to be sur we do not fileter many time concurently


Modified: trunk/plearn/vmat/FilteredVMatrix.cc
===================================================================
--- trunk/plearn/vmat/FilteredVMatrix.cc	2007-11-12 18:11:30 UTC (rev 8243)
+++ trunk/plearn/vmat/FilteredVMatrix.cc	2007-11-12 18:12:27 UTC (rev 8244)
@@ -89,6 +89,7 @@
         PLERROR("In FilteredVMatrix::openIndex could not create directory %s",getMetaDataDir().absolute().c_str());
 
 
+    lockMetaDataDir();
     if(isfile(idxfname) && mtime(idxfname)>=getMtime())
         indexes.open(idxfname);
     else  // let's (re)create the index
@@ -118,6 +119,7 @@
         indexes.close();
         indexes.open(idxfname);
     }
+    unlockMetaDataDir();
 
     length_ = indexes.length();
 }



From nouiz at mail.berlios.de  Mon Nov 12 19:13:20 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 12 Nov 2007 19:13:20 +0100
Subject: [Plearn-commits] r8245 - trunk/plearn/vmat
Message-ID: <200711121813.lACIDKBo021552@sheep.berlios.de>

Author: nouiz
Date: 2007-11-12 19:13:19 +0100 (Mon, 12 Nov 2007)
New Revision: 8245

Modified:
   trunk/plearn/vmat/SelectColumnsVMatrix.cc
Log:
Added bound check


Modified: trunk/plearn/vmat/SelectColumnsVMatrix.cc
===================================================================
--- trunk/plearn/vmat/SelectColumnsVMatrix.cc	2007-11-12 18:12:27 UTC (rev 8244)
+++ trunk/plearn/vmat/SelectColumnsVMatrix.cc	2007-11-12 18:13:19 UTC (rev 8245)
@@ -101,6 +101,12 @@
 // get //
 /////////
 real SelectColumnsVMatrix::get(int i, int j) const {
+#ifdef BOUNDCHECK
+    if(i>=length_ ||j>=width_||i<0||j<0)
+        PLERROR("In SelectColumnsVMatrix::getSubRow - "
+                "requested index: (%d,%d) but width of %d and length of %d",
+                i,j,width_,length_);
+#endif
     static int col;
     col = indices[j];
     if (col == -1)
@@ -113,6 +119,12 @@
 ///////////////
 void SelectColumnsVMatrix::getSubRow(int i, int j, Vec v) const
 {
+#ifdef BOUNDCHECK
+    if(i>=length_ ||j>=width_||i<0||j<0)
+        PLERROR("In SelectColumnsVMatrix::getSubRow - "
+                "requested index: (%d,%d) but width of %d and length of %d",
+                i,j,width_,length_);
+#endif
     static int col;
     for(int jj=0; jj<v.length(); jj++) {
         col = indices[j+jj];



From nouiz at mail.berlios.de  Mon Nov 12 19:15:31 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 12 Nov 2007 19:15:31 +0100
Subject: [Plearn-commits] r8246 - trunk/plearn/vmat
Message-ID: <200711121815.lACIFVMV026823@sheep.berlios.de>

Author: nouiz
Date: 2007-11-12 19:15:31 +0100 (Mon, 12 Nov 2007)
New Revision: 8246

Modified:
   trunk/plearn/vmat/MissingInstructionVMatrix.cc
Log:
Correctly compute matrix inputsize, targetsize, weightsize


Modified: trunk/plearn/vmat/MissingInstructionVMatrix.cc
===================================================================
--- trunk/plearn/vmat/MissingInstructionVMatrix.cc	2007-11-12 18:13:19 UTC (rev 8245)
+++ trunk/plearn/vmat/MissingInstructionVMatrix.cc	2007-11-12 18:15:31 UTC (rev 8246)
@@ -138,14 +138,19 @@
     TVec<string> source_names = source->fieldNames();
 
     //set default instruction
-    for (int col = 0; col < source->width(); col++)
-    {
-        ins[col] = default_instruction;
-    }
+    ins.fill(default_instruction);
+
+    int skip_instruction_input = 0;
+    int skip_instruction_target = 0;
+    int skip_instruction_weight = 0;
     if(default_instruction!="skip")
         width_=source->width();
-    else
+    else{
         width_=missing_instructions.size();
+        PLWARNING("MissingInstructionVMatrix::build_() - "
+                  "we suppose that the default instruction apply only to input fields");
+        skip_instruction_input = source->width() - missing_instructions.size();
+    }
     int missing_field = 0;
     for (int ins_col = 0; ins_col < missing_instructions.size(); ins_col++)
     {
@@ -175,8 +180,18 @@
             PLWARNING("In MergeDond2Files::build_() - merge instruction empty for field '%s', we keep the previous instruction who could be the default_instruction",(missing_instructions[source_col].first).c_str());
         else PLERROR("In MergeDond2Files::build_() - unsupported merge instruction: '%s'", 
                      (missing_instructions[ins_col].second).c_str());
-        if (ins[source_col] == "skip") width_--;
+        if (ins[source_col] == "skip")
+            if(source_col<source->inputsize())
+                skip_instruction_input++;
+            else if(source_col<(source->inputsize()+source->targetsize()))
+                skip_instruction_target++;
+            else skip_instruction_weight++;
     }
+    setMetaInfoFromSource();
+    inputsize_ = source->inputsize() - skip_instruction_input;
+    targetsize_ = source->targetsize() - skip_instruction_target;
+    weightsize_ = source->weightsize() - skip_instruction_weight;
+    width_ = inputsize_ + targetsize_ + weightsize_;
     int missing_instruction = 0;
     for (int col = 0; col < source->width(); col++)
     {



From nouiz at mail.berlios.de  Mon Nov 12 21:22:14 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 12 Nov 2007 21:22:14 +0100
Subject: [Plearn-commits] r8247 - in trunk/plearn: base math opt randomvar
	sys var vmat vmat/DEPRECATED
Message-ID: <200711122022.lACKME3Q024107@sheep.berlios.de>

Author: nouiz
Date: 2007-11-12 21:22:12 +0100 (Mon, 12 Nov 2007)
New Revision: 8247

Modified:
   trunk/plearn/base/Array_decl.h
   trunk/plearn/base/Array_impl.h
   trunk/plearn/base/SmallVector.h
   trunk/plearn/base/Storage.h
   trunk/plearn/base/TinyVector.h
   trunk/plearn/base/TypeFactory.h
   trunk/plearn/base/TypeTraits.h
   trunk/plearn/base/general.h
   trunk/plearn/math/TMatElementIterator_decl.h
   trunk/plearn/math/TMat_maths_specialisation.h
   trunk/plearn/math/TVec_decl.h
   trunk/plearn/math/TVec_impl.h
   trunk/plearn/math/TopNI.h
   trunk/plearn/math/distr_maths.h
   trunk/plearn/math/stats_utils.h
   trunk/plearn/opt/GradientOptimizer.h
   trunk/plearn/randomvar/RandomVar.h
   trunk/plearn/randomvar/SampleVariable.h
   trunk/plearn/sys/MemoryMap.h
   trunk/plearn/sys/PLMPI.h
   trunk/plearn/sys/Popen.h
   trunk/plearn/sys/Profiler.h
   trunk/plearn/sys/Semaphores.h
   trunk/plearn/var/Var.h
   trunk/plearn/var/VarArray.h
   trunk/plearn/var/VarMeasurer.h
   trunk/plearn/vmat/DEPRECATED/RemoveRowsVMatrix.h
   trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h
   trunk/plearn/vmat/ForwardVMatrix.cc
   trunk/plearn/vmat/VMat_computeConditionalStats.cc
Log:
corrected path for doxygen


Modified: trunk/plearn/base/Array_decl.h
===================================================================
--- trunk/plearn/base/Array_decl.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/Array_decl.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file Array.h */
+/*! \file Array_decl.h */
 
 #ifndef Array_decl_INC
 #define Array_decl_INC

Modified: trunk/plearn/base/Array_impl.h
===================================================================
--- trunk/plearn/base/Array_impl.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/Array_impl.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file Array.h */
+/*! \file Array_impl.h */
 
 #ifndef Array_impl_INC
 #define Array_impl_INC

Modified: trunk/plearn/base/SmallVector.h
===================================================================
--- trunk/plearn/base/SmallVector.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/SmallVector.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -32,7 +32,7 @@
 // library, go to the PLearn Web site at www.plearn.org
 
 
-/*! \file PLearnLibrary/PLearnCore/SmallVector.h */
+/*! \file SmallVector.h */
 
 #ifndef SMALLVECTOR
 #define SMALLVECTOR

Modified: trunk/plearn/base/Storage.h
===================================================================
--- trunk/plearn/base/Storage.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/Storage.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Storage.h */
+/*! \file Storage.h */
 
 #ifndef STORAGE_INC
 #define STORAGE_INC

Modified: trunk/plearn/base/TinyVector.h
===================================================================
--- trunk/plearn/base/TinyVector.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/TinyVector.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -41,7 +41,7 @@
 
 #include "plerror.h"
 
-/*! \file PLearnLibrary/PLearnCore/TinyVector.h */
+/*! \file TinyVector.h */
 
 namespace PLearn {
 using namespace std;

Modified: trunk/plearn/base/TypeFactory.h
===================================================================
--- trunk/plearn/base/TypeFactory.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/TypeFactory.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnCore/TypeFactory.h */
+/*! \file TypeFactory.h */
 
 #ifndef TYPEFACTORY_H
 #define TYPEFACTORY_H

Modified: trunk/plearn/base/TypeTraits.h
===================================================================
--- trunk/plearn/base/TypeTraits.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/TypeTraits.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -40,7 +40,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TypeTraits.h */
+/*! \file TypeTraits.h */
 
 #ifndef TypeTraits_INC
 #define TypeTraits_INC

Modified: trunk/plearn/base/general.h
===================================================================
--- trunk/plearn/base/general.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/base/general.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/general.h */
+/*! \file general.h */
 
 #ifndef GENERAL_INC
 #define GENERAL_INC

Modified: trunk/plearn/math/TMatElementIterator_decl.h
===================================================================
--- trunk/plearn/math/TMatElementIterator_decl.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/math/TMatElementIterator_decl.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearn/plearn/math/TMatTMatElementIterator_decl.h */
+/*! \file PLearn/plearn/math/TMatElementIterator_decl.h */
 
 #ifndef TMatTMatElementIterator_decl_INC
 #define TMatTMatElementIterator_decl_INC

Modified: trunk/plearn/math/TMat_maths_specialisation.h
===================================================================
--- trunk/plearn/math/TMat_maths_specialisation.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/math/TMat_maths_specialisation.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -40,7 +40,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnCore/TMat_maths_specialisation.h */
+/*! \file TMat_maths_specialisation.h */
 
 #ifndef TMat_maths_specialisation_INC
 #define TMat_maths_specialisation_INC

Modified: trunk/plearn/math/TVec_decl.h
===================================================================
--- trunk/plearn/math/TVec_decl.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/math/TVec_decl.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file TMat_decl.h */
 
 #ifndef TVec_decl_INC
 #define TVec_decl_INC

Modified: trunk/plearn/math/TVec_impl.h
===================================================================
--- trunk/plearn/math/TVec_impl.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/math/TVec_impl.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TMat.h */
+/*! \file TMat_impl.h */
 
 #ifndef TVec_impl_INC
 #define TVec_impl_INC

Modified: trunk/plearn/math/TopNI.h
===================================================================
--- trunk/plearn/math/TopNI.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/math/TopNI.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/TopNI.h */
+/*! \file TopNI.h */
 
 #ifndef TopNI_INC
 #define TopNI_INC

Modified: trunk/plearn/math/distr_maths.h
===================================================================
--- trunk/plearn/math/distr_maths.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/math/distr_maths.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -38,7 +38,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnAlgo/distr_maths.h */
+/*! \file distr_maths.h */
 
 #ifndef distr_maths_INC
 #define distr_maths_INC

Modified: trunk/plearn/math/stats_utils.h
===================================================================
--- trunk/plearn/math/stats_utils.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/math/stats_utils.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -38,7 +38,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/stats_utils.h */
+/*! \file stats_utils.h */
 
 #ifndef stats_utils_INC
 #define stats_utils_INC

Modified: trunk/plearn/opt/GradientOptimizer.h
===================================================================
--- trunk/plearn/opt/GradientOptimizer.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/opt/GradientOptimizer.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -41,7 +41,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/GradientOptimizer.h */
+/*! \file GradientOptimizer.h */
 
 #ifndef GRADIENTOPTIMIZER_INC
 #define GRADIENTOPTIMIZER_INC

Modified: trunk/plearn/randomvar/RandomVar.h
===================================================================
--- trunk/plearn/randomvar/RandomVar.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/randomvar/RandomVar.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -326,7 +326,7 @@
 */
 
 
-/*! \file PLearnLibrary/PLearnCore/RandomVar.h */
+/*! \file RandomVar.h */
 
 #ifndef RANDOMVAR_INC
 #define RANDOMVAR_INC

Modified: trunk/plearn/randomvar/SampleVariable.h
===================================================================
--- trunk/plearn/randomvar/SampleVariable.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/randomvar/SampleVariable.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/SampleVariable.h */
+/*! \file SampleVariable.h */
 
 #ifndef SampleVariable_INC
 #define SampleVariable_INC

Modified: trunk/plearn/sys/MemoryMap.h
===================================================================
--- trunk/plearn/sys/MemoryMap.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/sys/MemoryMap.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -1,5 +1,5 @@
 
-/*! \file PLearnLibrary/PLearnCore/MemoryMap.h */
+/*! \file MemoryMap.h */
 
 #ifndef MODULE_MEMORY_MAP
 #define MODULE_MEMORY_MAP

Modified: trunk/plearn/sys/PLMPI.h
===================================================================
--- trunk/plearn/sys/PLMPI.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/sys/PLMPI.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/PLMPI.h */
+/*! \file PLMPI.h */
 
 #ifndef PLMPI_INC
 #define PLMPI_INC

Modified: trunk/plearn/sys/Popen.h
===================================================================
--- trunk/plearn/sys/Popen.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/sys/Popen.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -42,7 +42,7 @@
 // that are used in the PLearn Library
 
 
-/*! \file PLearnLibrary/PLearnCore/Popen.h */
+/*! \file Popen.h */
 
 #ifndef Popen_INC
 #define Popen_INC

Modified: trunk/plearn/sys/Profiler.h
===================================================================
--- trunk/plearn/sys/Profiler.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/sys/Profiler.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -37,7 +37,7 @@
  * This file is part of the PLearn library.
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnUtil/Profiler.h */
+/*! \file Profiler.h */
 
 #ifndef PROFILER_INC
 #define PROFILER_INC

Modified: trunk/plearn/sys/Semaphores.h
===================================================================
--- trunk/plearn/sys/Semaphores.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/sys/Semaphores.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -56,7 +56,7 @@
 //
 
 
-/*! \file PLearnLibrary/PLearnCore/Semaphores.h */
+/*! \file Semaphores.h */
 
 #ifndef SEMAPHORES_INC
 #define SEMAPHORES_INC

Modified: trunk/plearn/var/Var.h
===================================================================
--- trunk/plearn/var/Var.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/var/Var.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Var.h */
+/*! \file Var.h */
 
 #ifndef Var_INC
 #define Var_INC

Modified: trunk/plearn/var/VarArray.h
===================================================================
--- trunk/plearn/var/VarArray.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/var/VarArray.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -41,7 +41,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VarArray.h */
+/*! \file VarArray.h */
 
 #ifndef VARARRAY_INC
 #define VARARRAY_INC

Modified: trunk/plearn/var/VarMeasurer.h
===================================================================
--- trunk/plearn/var/VarMeasurer.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/var/VarMeasurer.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -38,7 +38,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VarMeasurer.h */
+/*! \file VarMeasurer.h */
 
 #ifndef VARMEASURER_INC
 #define VARMEASURER_INC

Modified: trunk/plearn/vmat/DEPRECATED/RemoveRowsVMatrix.h
===================================================================
--- trunk/plearn/vmat/DEPRECATED/RemoveRowsVMatrix.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/vmat/DEPRECATED/RemoveRowsVMatrix.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file VMat.h */
 
 #ifndef RemoveRowsVMatrix_INC
 #define RemoveRowsVMatrix_INC

Modified: trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h
===================================================================
--- trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h	2007-11-12 20:22:12 UTC (rev 8247)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file VMat.h */
 
 #ifndef YMDDatedVMatrix_INC
 #define YMDDatedVMatrix_INC

Modified: trunk/plearn/vmat/ForwardVMatrix.cc
===================================================================
--- trunk/plearn/vmat/ForwardVMatrix.cc	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/vmat/ForwardVMatrix.cc	2007-11-12 20:22:12 UTC (rev 8247)
@@ -41,7 +41,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ForwardVMatrix.cc */
 
 #include "ForwardVMatrix.h"
 

Modified: trunk/plearn/vmat/VMat_computeConditionalStats.cc
===================================================================
--- trunk/plearn/vmat/VMat_computeConditionalStats.cc	2007-11-12 18:15:31 UTC (rev 8246)
+++ trunk/plearn/vmat/VMat_computeConditionalStats.cc	2007-11-12 20:22:12 UTC (rev 8247)
@@ -38,7 +38,7 @@
 
 // Authors: Pascal Vincent
 
-/*! \file computeConditionalStats.cc */
+/*! \file VMat_computeConditionalStats.cc */
 
 
 #include "VMat_computeConditionalStats.h"



From nouiz at mail.berlios.de  Tue Nov 13 18:04:11 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 13 Nov 2007 18:04:11 +0100
Subject: [Plearn-commits] r8248 - trunk/plearn/vmat
Message-ID: <200711131704.lADH4BOc022243@sheep.berlios.de>

Author: nouiz
Date: 2007-11-13 18:04:11 +0100 (Tue, 13 Nov 2007)
New Revision: 8248

Added:
   trunk/plearn/vmat/DichotomizeVMatrix.cc
   trunk/plearn/vmat/DichotomizeVMatrix.h
Log:
Added a new VMatrix that do dichotomization that map a range to a value


Added: trunk/plearn/vmat/DichotomizeVMatrix.cc
===================================================================
--- trunk/plearn/vmat/DichotomizeVMatrix.cc	2007-11-12 20:22:12 UTC (rev 8247)
+++ trunk/plearn/vmat/DichotomizeVMatrix.cc	2007-11-13 17:04:11 UTC (rev 8248)
@@ -0,0 +1,274 @@
+// -*- C++ -*-
+
+// DichotomizeVMatrix.cc
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file DichotomizeVMatrix.cc */
+
+
+#include "DichotomizeVMatrix.h"
+
+namespace PLearn {
+using namespace std;
+
+
+PLEARN_IMPLEMENT_OBJECT(
+    DichotomizeVMatrix,
+    "Dichotomize variables with discrete values",
+    "Instructions are provided with the discrete_variable_instructions option.\n"
+    "Can map range of value to one value for each variable\n"
+    "Variables with no specification will be kept as_is\n"
+    );
+
+DichotomizeVMatrix::DichotomizeVMatrix()
+//    discrete_variable_instructions(NULL)
+/* ### Initialize all fields to their default value */
+{
+    // ...
+
+    // ### You may (or not) want to call build_() to finish building the object
+    // ### (doing so assumes the parent classes' build_() have been called too
+    // ### in the parent classes' constructors, something that you must ensure)
+}
+
+void DichotomizeVMatrix::getNewRow(int i, const Vec& v) const
+{
+    Vec source_row(source->width());
+    source->getRow(i,source_row);
+    
+    for (int source_col = 0,output_col = 0; source_col < source->width(); source_col++)
+        {
+            if (instruction_index[source_col] < 0)
+            {
+                v[output_col] = source_row[source_col];
+                output_col += 1;
+            }
+            else
+            {
+               TVec<pair<real, real> > instruction_ptr = discrete_variable_instructions[instruction_index[source_col]].second;
+               if (instruction_ptr.size() == 0) continue;
+               bool missing = is_missing(source_row[source_col]);
+               bool found_range = false;
+               if(missing)
+                   found_range=true;
+               for (int ins_col = 0; ins_col < instruction_ptr.size(); ins_col++)
+               {
+                   if (missing)
+                       v[output_col] = MISSING_VALUE;
+                   else if (source_row[source_col] < instruction_ptr[ins_col].first 
+                            || source_row[source_col] > instruction_ptr[ins_col].second) 
+                       v[output_col] = 0.0;
+                   else 
+                   {
+                       v[output_col] = 1.0;
+                       found_range=true;
+                   }
+                   output_col += 1;
+               }
+               if(found_range==false)
+               {
+                   PLWARNING("DichotomizeVMatrix::getNewRow() - "
+                             "row %d, fields %s, have a value (%f) that are outside all dichotomize range",
+                             i,source->fieldName(source_col).c_str(),source_row[source_col]);
+               }
+            }    
+        }
+
+}
+
+void DichotomizeVMatrix::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    declareOption(ol, "discrete_variable_instructions", &DichotomizeVMatrix::discrete_variable_instructions,
+                  OptionBase::buildoption,
+                  "The instructions to dichotomize the variables in the form of field_name : TVec<pair>.\n"
+                  "The pairs are values from : to, each creating a 0, 1 variable.\n"
+                  "Variables with no specification will be kept as_is.\n");
+
+    declareOption(ol, "instruction_index", &DichotomizeVMatrix::instruction_index,
+                  OptionBase::learntoption,
+                  "An array that point each columns of the source matrix to its instruction.");
+//instruction_index
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void DichotomizeVMatrix::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+
+    instruction_index.fill(-1);
+    TVec<string> source_names = source->fieldNames();
+
+    instruction_index.resize(source->width());
+    instruction_index.fill(-1);
+
+    //validate the instruction and order them as in the source matrix
+    for (int ins_col = 0; ins_col < discrete_variable_instructions.size();
+         ins_col++)
+    {
+        int source_col;
+        for (source_col = 0; source_col < source->width(); source_col++)
+        {
+            if (discrete_variable_instructions[ins_col].first == source_names[source_col]) break;
+        }
+        if (source_col >= source->width()) 
+            PLERROR("In DichotomizeDond2DiscreteVariables::build_() -  "
+                    "no field with this name in the source data set: %s",
+                    (discrete_variable_instructions[ins_col].first).c_str());
+        else instruction_index[source_col] = ins_col;
+    }
+
+    // initialize inputsize_,targetsize_,weightsize_, width_,length()
+    length_=source->length();
+    int sisize=source->inputsize();
+    int stsize=source->targetsize();
+    int isize=0;
+    int tsize=0;
+    int wsize=0;
+    for (int source_col = 0; source_col < sisize; source_col++)
+    {
+        if (instruction_index[source_col] < 0) isize++;
+        else
+        {
+            TVec<pair<real, real> > instruction_ptr = 
+                discrete_variable_instructions[instruction_index[source_col]].second;
+            isize += instruction_ptr.size();
+        }
+    }
+    for (int source_col = sisize; 
+         source_col < sisize + stsize; source_col++)
+    {
+        if (instruction_index[source_col] < 0) tsize++;
+        else
+        {
+            TVec<pair<real, real> > instruction_ptr = 
+                discrete_variable_instructions[instruction_index[source_col]].second;
+            tsize += instruction_ptr.size();
+        }
+    }
+    for (int source_col = sisize + stsize;
+         source_col < sisize + stsize + source->weightsize() ; source_col++)
+    {
+        if (instruction_index[source_col] < 0) wsize++;
+        else
+        {
+            TVec<pair<real, real> > instruction_ptr = 
+                discrete_variable_instructions[instruction_index[source_col]].second;
+            wsize += instruction_ptr.size();
+        }
+    }
+    defineSizes(isize, tsize, wsize);
+    width_ = isize + tsize + wsize;
+
+    //get the fieldnames
+    TVec<string> fnames(width());
+    int field_col = 0;
+    for (int source_col = 0; source_col < source->width(); source_col++)
+    {
+        if (instruction_index[source_col] < 0)
+        {
+            fnames[field_col] = source_names[source_col];
+            field_col += 1;
+        }
+        else
+        {
+           TVec<pair<real, real> > instruction_ptr =
+               discrete_variable_instructions[instruction_index[source_col]].second;
+           if (instruction_ptr.size() == 0) 
+           {
+               PLWARNING("In DichotomizeDond2DiscreteVariables::build_() -"
+                         "instruction for field %s have no range!",
+                         discrete_variable_instructions[instruction_index[source_col]].first.c_str());
+               continue;
+           }
+           for (int ins_col = 0; ins_col < instruction_ptr.size(); ins_col++)
+           {
+               fnames[field_col] = source_names[source_col] + "_"
+                                        + tostring(instruction_ptr[ins_col].first) + "_" 
+                                        + tostring(instruction_ptr[ins_col].second);
+               field_col += 1;
+           }
+        }    
+    }
+    declareFieldNames(fnames);
+}
+
+// ### Nothing to add here, simply calls build_
+void DichotomizeVMatrix::build()
+{
+    inherited::build();
+    build_();
+}
+
+void DichotomizeVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField(discrete_variable_instructions, copies);
+    deepCopyField(instruction_index, copies);
+
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/vmat/DichotomizeVMatrix.h
===================================================================
--- trunk/plearn/vmat/DichotomizeVMatrix.h	2007-11-12 20:22:12 UTC (rev 8247)
+++ trunk/plearn/vmat/DichotomizeVMatrix.h	2007-11-13 17:04:11 UTC (rev 8248)
@@ -0,0 +1,140 @@
+// -*- C++ -*-
+
+// DichotomizeVMatrix.h
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file DichotomizeVMatrix.h */
+
+
+#ifndef DichotomizeVMatrix_INC
+#define DichotomizeVMatrix_INC
+
+#include <plearn/vmat/SourceVMatrix.h>
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class DichotomizeVMatrix : public SourceVMatrix
+{
+    typedef SourceVMatrix inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    TVec< pair<string, TVec< pair<real, real> > > > discrete_variable_instructions;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    DichotomizeVMatrix();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(DichotomizeVMatrix);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+    //! Fill the vector 'v' with the content of the i-th row.
+    //! 'v' is assumed to be the right size.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void getNewRow(int i, const Vec& v) const;
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    TVec<int> instruction_index;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(DichotomizeVMatrix);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From nouiz at mail.berlios.de  Tue Nov 13 18:39:30 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 13 Nov 2007 18:39:30 +0100
Subject: [Plearn-commits] r8249 - trunk/plearn_learners/online
Message-ID: <200711131739.lADHdU4D014310@sheep.berlios.de>

Author: nouiz
Date: 2007-11-13 18:39:29 +0100 (Tue, 13 Nov 2007)
New Revision: 8249

Modified:
   trunk/plearn_learners/online/LayerCostModule.cc
Log:
changed order of initialization of variable to get rid of compilation warning


Modified: trunk/plearn_learners/online/LayerCostModule.cc
===================================================================
--- trunk/plearn_learners/online/LayerCostModule.cc	2007-11-13 17:04:11 UTC (rev 8248)
+++ trunk/plearn_learners/online/LayerCostModule.cc	2007-11-13 17:39:29 UTC (rev 8249)
@@ -54,14 +54,14 @@
     "Be careful: some are valid only for binomial layers. \n");
 
 LayerCostModule::LayerCostModule():
+    cost_function(""),
     nstages_max(-1),
-    stage(0),
+    alpha(0.),
     momentum(0.),
     histo_size(10),
-    alpha(0.),
-    average_deriv(0.),
-    cost_function(""),
-    cost_function_completename("")
+    cost_function_completename(""),
+    stage(0),
+    average_deriv(0.)
 {
     output_size = 1;
 }



From manzagop at mail.berlios.de  Tue Nov 13 18:41:54 2007
From: manzagop at mail.berlios.de (manzagop at BerliOS)
Date: Tue, 13 Nov 2007 18:41:54 +0100
Subject: [Plearn-commits] r8250 - trunk/plearn_learners/generic/EXPERIMENTAL
Message-ID: <200711131741.lADHfsQb019626@sheep.berlios.de>

Author: manzagop
Date: 2007-11-13 18:41:53 +0100 (Tue, 13 Nov 2007)
New Revision: 8250

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/mNNet.cc
Log:
Minor change to a comment.


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/mNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/mNNet.cc	2007-11-13 17:39:29 UTC (rev 8249)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/mNNet.cc	2007-11-13 17:41:53 UTC (rev 8250)
@@ -443,7 +443,8 @@
     }
 }
 
-//! Performs the backprop update. Must be called after the fbpropNet.
+//! Performs the backprop update. Must be called after the fbpropNet and
+//! fbpropLoss.
 void mNNet::bpropUpdateNet(int t)
 {
     // mean gradient over minibatch_size examples has less variance



From manzagop at mail.berlios.de  Tue Nov 13 18:45:20 2007
From: manzagop at mail.berlios.de (manzagop at BerliOS)
Date: Tue, 13 Nov 2007 18:45:20 +0100
Subject: [Plearn-commits] r8251 - trunk/plearn_learners/generic/EXPERIMENTAL
Message-ID: <200711131745.lADHjKX6023325@sheep.berlios.de>

Author: manzagop
Date: 2007-11-13 18:45:16 +0100 (Tue, 13 Nov 2007)
New Revision: 8251

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h
Log:
- introduced an option for varying the required confidence 
- optimized the pvgrad() function


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc	2007-11-13 17:41:53 UTC (rev 8250)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc	2007-11-13 17:45:16 UTC (rev 8251)
@@ -57,12 +57,15 @@
       pv_deceleration(0.5),
       pv_min_samples(2),
       pv_required_confidence(0.80),
+      pv_conf_ct(0.0),
       pv_strategy(1),
       pv_random_sample_step(false),
       pv_self_discount(0.5),
       pv_other_discount(0.95),
       pv_within_neuron_discount(0.95),
-      n_updates(0)
+      n_updates(0),
+      limit_ratio(0.0),
+      n_small_ratios(0.0)
 {
     random_gen = new PRandom();
 }
@@ -105,6 +108,11 @@
                   OptionBase::buildoption,
                   "Minimum required confidence (probability of being positive or negative) for taking a step.");
 
+    declareOption(ol, "pv_conf_ct",
+                  &PvGradNNet::pv_conf_ct,
+                  OptionBase::buildoption,
+                  "Used for confidence adaptation.");
+
     declareOption(ol, "pv_strategy",
                   &PvGradNNet::pv_strategy,
                   OptionBase::buildoption,
@@ -215,6 +223,8 @@
     n_small_ratios=0.0;
     n_neuron_updates.fill(0);    
 //    pv_gradstats->forget();
+
+    limit_ratio = gauss_01_quantile(pv_required_confidence);
 }
 
 //! Performs the backprop update. Must be called after the fbpropNet.
@@ -249,12 +259,17 @@
         
 }
 
-void PvGradNNet::pvGrad()   
+void PvGradNNet::pvGrad()  
 {
     int np = all_params.length();
     real m, e;//, prob_pos, prob_neg;
-    real ratio;
-    real limit_ratio = gauss_01_quantile(pv_required_confidence);
+    //real ratio;
+    // move this stuff to a train function to avoid repeated computations
+    if( pv_conf_ct != 0.0 ) {     
+        real conf = pv_required_confidence; 
+        conf += (1.0-pv_required_confidence) * (stage/stage+pv_conf_ct);
+        limit_ratio = gauss_01_quantile(conf);
+    }
 
     for(int k=0; k<np; k++) {
         // update stats
@@ -263,13 +278,16 @@
         pv_all_sumsquare[k] += all_params_gradient[k] * all_params_gradient[k];
 
         if(pv_all_nsamples[k]>pv_min_samples)   {
-            m = pv_all_sum[k] / pv_all_nsamples[k];
+            real inv_pv_all_nsamples_k = 1./pv_all_nsamples[k];
+            real pv_all_sum_k = pv_all_sum[k];
+            m = pv_all_sum_k * inv_pv_all_nsamples_k;
             // e is the standard error
-            //e = sqrt( (pv_all_sumsquare[k] - (pv_all_sum[k]*pv_all_sum[k])/pv_all_nsamples[k]) / (real)(pv_all_nsamples[k]*(pv_all_nsamples[k]-1)) );
             // variance
-            e = real((pv_all_sumsquare[k] - square(pv_all_sum[k])/pv_all_nsamples[k])/(pv_all_nsamples[k]-1));
+            //e = real((pv_all_sumsquare[k] - square(pv_all_sum[k])/pv_all_nsamples[k])/(pv_all_nsamples[k]-1));
             // standard error 
-            e = sqrt(e/pv_all_nsamples[k]);
+            //e = sqrt(e*inv_pv_all_nsamples_k);
+            // This is an approxiamtion where we've raplaced a (nsamples-1) by nsamples
+            e = sqrt(pv_all_sumsquare[k]-pv_all_sum_k*m)*inv_pv_all_nsamples_k;
 
             // test to see if numerical problems
             if( fabs(m) < 1e-15 || e < 1e-15 )  {
@@ -282,14 +300,15 @@
             // Comparing the ratio would be sufficient.
             //prob_pos = gauss_01_cum(m/e);
             //prob_neg = 1.-prob_pos;
-            ratio = m/e;
+            //ratio = m/e;
 
             if(!pv_random_sample_step)  {
-    
+                real threshold = limit_ratio*e;
                 // We adapt the stepsize before taking the step
                 // gradient is positive
                 //if(prob_pos>=pv_required_confidence)    {
-                if(ratio>=limit_ratio)  {
+                //if(ratio>=limit_ratio)  {
+                if(m>=threshold)  {
                     //pv_all_stepsizes[k] *= (pv_all_stepsigns[k]?pv_acceleration:pv_deceleration);
                     if(pv_all_stepsigns[k]>0)   {
                         pv_all_stepsizes[k]*=pv_acceleration;
@@ -309,7 +328,7 @@
                 }
                 // gradient is negative
                 //else if(prob_neg>=pv_required_confidence)   {
-                if(ratio<=-limit_ratio) {
+                else if(m<=-threshold) {
                     //pv_all_stepsizes[k] *= ((!pv_all_stepsigns[k])?pv_acceleration:pv_deceleration);
                     if(pv_all_stepsigns[k]<0)   {
                         pv_all_stepsizes[k]*=pv_acceleration;
@@ -356,8 +375,13 @@
     real m, e;//, prob_pos, prob_neg;
     int stepsign;
 
+    // TODO bring the confidenca treatment up to date (see pvGrad)
     real ratio;
-    real limit_ratio = gauss_01_quantile(pv_required_confidence);
+    real conf = pv_required_confidence;
+    if( pv_conf_ct != 0.0 ) {
+        conf += (1.0-pv_required_confidence) * (stage/stage+pv_conf_ct);
+    }
+    real limit_ratio = gauss_01_quantile(conf);
 
     // 
     real discount = pow(pv_other_discount,n_updates);
@@ -444,8 +468,13 @@
     real m, e;//, prob_pos, prob_neg;
     int stepsign;
 
+    // TODO bring the confidenca treatment up to date (see pvGrad)
     real ratio;
-    real limit_ratio = gauss_01_quantile(pv_required_confidence);
+    real conf = pv_required_confidence;
+    if( pv_conf_ct != 0.0 ) {
+        conf += (1.0-pv_required_confidence) * (stage/stage+pv_conf_ct);
+    }
+    real limit_ratio = gauss_01_quantile(conf);
 
     //
     real discount = pow(pv_other_discount,n_updates);

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h	2007-11-13 17:41:53 UTC (rev 8250)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h	2007-11-13 17:45:16 UTC (rev 8251)
@@ -68,6 +68,7 @@
     //! Minimum required confidence (probability of being positive or negative)
     //! for taking a step.
     real pv_required_confidence;
+    real pv_conf_ct;
 
     int pv_strategy;
 
@@ -162,6 +163,7 @@
     //! accumulated statistics of gradients on each parameter.
     //PP<VecStatsCollector> pv_gradstats;
 
+    real limit_ratio;
     real n_small_ratios;
 };
 



From nouiz at mail.berlios.de  Tue Nov 13 19:08:21 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 13 Nov 2007 19:08:21 +0100
Subject: [Plearn-commits] r8252 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711131808.lADI8LHV012713@sheep.berlios.de>

Author: nouiz
Date: 2007-11-13 19:08:20 +0100 (Tue, 13 Nov 2007)
New Revision: 8252

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h
   branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h
Log:
corrected path for doxygen


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
  * This file is part of the PLearn library.                                     *
  ******************************************************************************** */
 
-/*! \file PLearnLibrary/PLearnAlgo/ComputePurenneError.h */
+/*! \file ComputePurenneError.h */
 
 #ifndef ComputePurenneError_INC
 #define ComputePurenneError_INC

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
    * $Id: ConditionalMeanImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
    ****************************************************************** */
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ConditionalMeanImputationVMatrix.h */
 
 #ifndef ConditionalMeanImputationVMatrix_INC
 #define ConditionalMeanImputationVMatrix_INC

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
    * $Id: CovariancePreservationImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
    ****************************************************************** */
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file CovariancePreservationImputationVMatrix.h */
 
 #ifndef CovariancePreservationImputationVMatrix_INC
 #define CovariancePreservationImputationVMatrix_INC

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
    * $Id: ImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
    ****************************************************************** */
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file ImputationVMatrix.h */
 
 #ifndef ImputationVMatrix_INC
 #define ImputationVMatrix_INC

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
    * $Id: MeanMedianModeImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
    ****************************************************************** */
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file MeanMedianModeImputationVMatrix.h */
 
 #ifndef MeanMedianModeImputationVMatrix_INC
 #define MeanMedianModeImputationVMatrix_INC

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
    * $Id: MissingIndicatorVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
    ****************************************************************** */
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file MissingIndicatorVMatrix.h */
 
 #ifndef MissingIndicatorVMatrix_INC
 #define MissingIndicatorVMatrix_INC

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
    * $Id: NeighborhoodImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
    ****************************************************************** */
 
-/*! \file PLearnLibrary/PLearnCore/VMat.h */
+/*! \file NeignborhoodImputationVMatrix.h */
 
 #ifndef NeighborhoodImputationVMatrix_INC
 #define NeighborhoodImputationVMatrix_INC

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h	2007-11-13 17:45:16 UTC (rev 8251)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h	2007-11-13 18:08:20 UTC (rev 8252)
@@ -39,7 +39,7 @@
  * This file is part of the PLearn library.                                     *
  ******************************************************************************** */
 
-/*! \file PLearnLibrary/PLearnAlgo/SecondIterationWrapper.h */
+/*! \file SecondIterationWrapper.h */
 
 #ifndef SecondIterationWrapper_INC
 #define SecondIterationWrapper_INC



From nouiz at mail.berlios.de  Tue Nov 13 19:10:30 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 13 Nov 2007 19:10:30 +0100
Subject: [Plearn-commits] r8253 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711131810.lADIAUxk016866@sheep.berlios.de>

Author: nouiz
Date: 2007-11-13 19:10:29 +0100 (Tue, 13 Nov 2007)
New Revision: 8253

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h
Log:
code clean up
localyse global variable when this make sens


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc	2007-11-13 18:08:20 UTC (rev 8252)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc	2007-11-13 18:10:29 UTC (rev 8253)
@@ -48,6 +48,7 @@
     DichotomizeDond2DiscreteVariables,
     "Dichotomize variables with discrete values.",
     "Instructions are provided with the discrete_variable_instructions option.\n"
+    "DEPRECATED use DichotomizeVMatrix.cc instead"
 );
 
 /////////////////////////
@@ -111,18 +112,17 @@
 void DichotomizeDond2DiscreteVariables::dichotomizeDiscreteVariables()
 {    
     // initialize primary dataset
-    main_row = 0;
-    main_col = 0;
-    main_length = train_set->length();
-    main_width = train_set->width();
-    main_input.resize(main_width);
-    main_names.resize(main_width);
-    main_ins.resize(main_width);
-    ins_width = discrete_variable_instructions.size();
+    int main_length = train_set->length();
+    int main_width = train_set->width();
+    Vec main_input(main_width);
+    TVec<string> main_names(main_width);
+    TVec<int> main_ins(main_width);
+    main_ins.fill(-1);
+    int ins_width = discrete_variable_instructions.size();
     main_names << train_set->fieldNames();
-    main_ins.fill(-1);
-    for (ins_col = 0; ins_col < ins_width; ins_col++)
+    for (int ins_col = 0; ins_col < ins_width; ins_col++)
     {
+        int main_col;
         for (main_col = 0; main_col < main_width; main_col++)
         {
             if (discrete_variable_instructions[ins_col].first == main_names[main_col]) break;
@@ -132,21 +132,20 @@
     }
     
     // initialize output datasets
-    output_length = main_length;
-    output_width = 0;
-    for (main_col = 0; main_col < main_width; main_col++)
+    int output_length = main_length;
+    int output_width = 0;
+    for (int main_col = 0; main_col < main_width; main_col++)
     {
         if (main_ins[main_col] < 0) output_width += 1;
         else
         {
-            instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
+            TVec<pair<real, real> > instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
             output_width += instruction_ptr.size();
         }
     }
-    output_record.resize(output_width);
-    output_names.resize(output_width);
-    output_col = 0;
-    for (main_col = 0; main_col < main_width; main_col++)
+    TVec<string> output_names(output_width);
+    int output_col = 0;
+    for (int main_col = 0; main_col < main_width; main_col++)
     {
         if (main_ins[main_col] < 0)
         {
@@ -155,9 +154,9 @@
         }
         else
         {
-           instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
+           TVec<pair<real, real> > instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
            if (instruction_ptr.size() == 0) continue;
-           for (ins_col = 0; ins_col < instruction_ptr.size(); ins_col++)
+           for (int ins_col = 0; ins_col < instruction_ptr.size(); ins_col++)
            {
                output_names[output_col] = main_names[main_col] + "_"
                                         + tostring(instruction_ptr[ins_col].first) + "_" 
@@ -172,11 +171,13 @@
     //Now, we can process the discrete variables.
     ProgressBar* pb = 0;
     pb = new ProgressBar( "Dichotomizing the discrete variables", main_length);
-    for (main_row = 0; main_row < main_length; main_row++)
+    Vec output_record(output_width);
+
+    for (int main_row = 0; main_row < main_length; main_row++)
     {
         train_set->getRow(main_row, main_input);
         output_col = 0;
-        for (main_col = 0; main_col < main_width; main_col++)
+        for (int main_col = 0; main_col < main_width; main_col++)
         {
             if (main_ins[main_col] < 0)
             {
@@ -185,9 +186,9 @@
             }
             else
             {
-               instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
+               TVec<pair<real, real> > instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
                if (instruction_ptr.size() == 0) continue;
-               for (ins_col = 0; ins_col < instruction_ptr.size(); ins_col++)
+               for (int ins_col = 0; ins_col < instruction_ptr.size(); ins_col++)
                {
                    if (is_missing(main_input[main_col])) output_record[output_col] = MISSING_VALUE;
                    else if (main_input[main_col] < instruction_ptr[ins_col].first || main_input[main_col] > instruction_ptr[ins_col].second) output_record[output_col] = 0.0;

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h	2007-11-13 18:08:20 UTC (rev 8252)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h	2007-11-13 18:10:29 UTC (rev 8253)
@@ -116,26 +116,7 @@
 
     // The rest of the private stuff goes here
     
-    // input instructions variables
-    int ins_width;
-    int ins_col;
-    TVec<pair<real, real> > instruction_ptr;
-    
-    // primary dataset variables
-    int main_length;
-    int main_width;
-    int main_row;
-    int main_col;
-    Vec main_input;
-    TVec<string> main_names;
-    TVec<int> main_ins;
-    
     // output dataset variables
-    int output_length;
-    int output_width;
-    int output_col;
-    Vec output_record;
-    TVec<string> output_names;
     VMat output_file;
 };
 



From nouiz at mail.berlios.de  Tue Nov 13 21:21:10 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 13 Nov 2007 21:21:10 +0100
Subject: [Plearn-commits] r8254 - trunk/plearn/vmat
Message-ID: <200711132021.lADKLAQp017323@sheep.berlios.de>

Author: nouiz
Date: 2007-11-13 21:21:09 +0100 (Tue, 13 Nov 2007)
New Revision: 8254

Modified:
   trunk/plearn/vmat/TextFilesVMatrix.cc
   trunk/plearn/vmat/TextFilesVMatrix.h
Log:
-changed the list of source file to be PPath
-Changed the behavior when their is missing/unnecessary instruction to generate warning and skip the troubled variable.


Modified: trunk/plearn/vmat/TextFilesVMatrix.cc
===================================================================
--- trunk/plearn/vmat/TextFilesVMatrix.cc	2007-11-13 18:10:29 UTC (rev 8253)
+++ trunk/plearn/vmat/TextFilesVMatrix.cc	2007-11-13 20:21:09 UTC (rev 8254)
@@ -193,7 +193,7 @@
     TVec<string> fnames;
     if(reorder_fieldspec_from_headers)
     {
-        //the fieldnames read from the files.
+        //read the fieldnames from the files.
         TVec<string> fn;
         for(int i=0; i<txtfiles.size(); i++)
         {
@@ -241,10 +241,17 @@
             if(j>=fn.size())
                 not_used_fs.append(name);
         }
-        if(not_used_fs.size()!=0 || not_used_fn.size()!=0)
-            PLERROR("UNUSUED field names from header: %s\n"
-                    "UNUSUED fieldspec %s",tostring(not_used_fn).c_str(),
-                    tostring(not_used_fs).c_str());
+        if(not_used_fs.size()!=0)
+            PLWARNING("TextFilesVMatrix::setColumnNamesAndWidth() - "
+                      "Fieldspecs do not exist in source for field(s): %s\n"
+                      "They will be skipped.",
+                      tostring(not_used_fs).c_str());
+        if(not_used_fn.size()!=0)
+            PLWARNING("TextFilesVMatrix::setColumnNamesAndWidth() - "
+                      "Fieldnames in source that don't have fieldspec: %s\n"
+                      "They will be skipped.",
+                      tostring(not_used_fn).c_str());
+    
 
         //the new order for fieldspecs
         TVec< pair<string, string> > fs(fn.size());
@@ -256,10 +263,9 @@
                 if(fieldspec[j].first==name)
                     break;
             if(j>=fieldspec.size())
-                PLERROR("In TextFilesVMatrix::setColumnNamesAndWidth() - "
-                        "fieldspec do not contain spec for field '%s'",
-                        name.c_str());
-            fs[i]=fieldspec[j];
+                fs[i]=pair<string,string>(name,"skip");
+            else
+                fs[i]=fieldspec[j];
         }
         fieldspec=fs;
     }

Modified: trunk/plearn/vmat/TextFilesVMatrix.h
===================================================================
--- trunk/plearn/vmat/TextFilesVMatrix.h	2007-11-13 18:10:29 UTC (rev 8253)
+++ trunk/plearn/vmat/TextFilesVMatrix.h	2007-11-13 20:21:09 UTC (rev 8254)
@@ -95,7 +95,7 @@
     PPath metadatapath; 
 
     //! A list of paths to raw text files containing the records
-    TVec<string> txtfilenames;
+    TVec<PPath> txtfilenames;
 
     //! Delimiter to use to split the fields.  Common delimiters are:
     //! - '\t' : used for SAS files (the default)



From nouiz at mail.berlios.de  Wed Nov 14 15:57:46 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 14 Nov 2007 15:57:46 +0100
Subject: [Plearn-commits] r8255 - in trunk/plearn: base math measure
	vmat/DEPRECATED
Message-ID: <200711141457.lAEEvkNx029237@sheep.berlios.de>

Author: nouiz
Date: 2007-11-14 15:57:45 +0100 (Wed, 14 Nov 2007)
New Revision: 8255

Modified:
   trunk/plearn/base/PP.h
   trunk/plearn/base/plerror.h
   trunk/plearn/base/plexceptions.h
   trunk/plearn/math/stats_utils.cc
   trunk/plearn/measure/Measurer.h
   trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h
Log:
corrected path for doxygen


Modified: trunk/plearn/base/PP.h
===================================================================
--- trunk/plearn/base/PP.h	2007-11-13 20:21:09 UTC (rev 8254)
+++ trunk/plearn/base/PP.h	2007-11-14 14:57:45 UTC (rev 8255)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file SmartPointer.h */
+/*! \file PP.h */
 
 #ifndef SMART_POINTER_INC
 #define SMART_POINTER_INC

Modified: trunk/plearn/base/plerror.h
===================================================================
--- trunk/plearn/base/plerror.h	2007-11-13 20:21:09 UTC (rev 8254)
+++ trunk/plearn/base/plerror.h	2007-11-14 14:57:45 UTC (rev 8255)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/plerror.h */
+/*! \file plerror.h */
 
 #ifndef perror_INC
 #define perror_INC

Modified: trunk/plearn/base/plexceptions.h
===================================================================
--- trunk/plearn/base/plexceptions.h	2007-11-13 20:21:09 UTC (rev 8254)
+++ trunk/plearn/base/plexceptions.h	2007-11-14 14:57:45 UTC (rev 8255)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/plexceptions.h */
+/*! \file plexceptions.h */
 
 #ifndef pexceptions_INC
 #define pexceptions_INC

Modified: trunk/plearn/math/stats_utils.cc
===================================================================
--- trunk/plearn/math/stats_utils.cc	2007-11-13 20:21:09 UTC (rev 8254)
+++ trunk/plearn/math/stats_utils.cc	2007-11-14 14:57:45 UTC (rev 8255)
@@ -38,7 +38,7 @@
  ******************************************************* */
 
 
-/*! \file PLearn/plearn/math/stats_utils.h */
+/*! \file PLearn/plearn/math/stats_utils.cc */
 
 #include "stats_utils.h"
 #include "TMat_maths.h"

Modified: trunk/plearn/measure/Measurer.h
===================================================================
--- trunk/plearn/measure/Measurer.h	2007-11-13 20:21:09 UTC (rev 8254)
+++ trunk/plearn/measure/Measurer.h	2007-11-14 14:57:45 UTC (rev 8255)
@@ -43,7 +43,7 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnCore/Measurer.h */
+/*! \file Measurer.h */
 
 #ifndef MEASURER_INC
 #define MEASURER_INC

Modified: trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h
===================================================================
--- trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h	2007-11-13 20:21:09 UTC (rev 8254)
+++ trunk/plearn/vmat/DEPRECATED/YMDDatedVMatrix.h	2007-11-14 14:57:45 UTC (rev 8255)
@@ -39,7 +39,7 @@
  ******************************************************* */
 
 
-/*! \file VMat.h */
+/*! \file YMDDatedVMatrix.h */
 
 #ifndef YMDDatedVMatrix_INC
 #define YMDDatedVMatrix_INC



From nouiz at mail.berlios.de  Wed Nov 14 19:32:26 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 14 Nov 2007 19:32:26 +0100
Subject: [Plearn-commits] r8256 - trunk/plearn/vmat
Message-ID: <200711141832.lAEIWQpo016468@sheep.berlios.de>

Author: nouiz
Date: 2007-11-14 19:32:26 +0100 (Wed, 14 Nov 2007)
New Revision: 8256

Modified:
   trunk/plearn/vmat/GaussianizeVMatrix.cc
Log:
changed PLASSERT to PLCHECK in build_()


Modified: trunk/plearn/vmat/GaussianizeVMatrix.cc
===================================================================
--- trunk/plearn/vmat/GaussianizeVMatrix.cc	2007-11-14 14:57:45 UTC (rev 8255)
+++ trunk/plearn/vmat/GaussianizeVMatrix.cc	2007-11-14 18:32:26 UTC (rev 8256)
@@ -140,8 +140,8 @@
         return;
 
     if (train_source) {
-        PLASSERT( train_source->width() == source->width() );
-        PLASSERT( train_source->inputsize()  == source->inputsize() &&
+        PLCHECK( train_source->width() == source->width() );
+        PLCHECK( train_source->inputsize()  == source->inputsize() &&
                 train_source->targetsize() == source->targetsize() &&
                 train_source->weightsize() == source->weightsize() &&
                 train_source->extrasize()  == source->extrasize() );
@@ -149,7 +149,7 @@
 
     VMat the_source = train_source ? train_source : source;
 
-    PLASSERT( the_source->inputsize() >= 0 && the_source->targetsize() >= 0 &&
+    PLCHECK( the_source->inputsize() >= 0 && the_source->targetsize() >= 0 &&
             the_source->weightsize() >= 0 && the_source->extrasize() >= 0 );
 
     // Find which dimensions to Gaussianize.



From tihocan at mail.berlios.de  Wed Nov 14 22:19:28 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Wed, 14 Nov 2007 22:19:28 +0100
Subject: [Plearn-commits] r8257 - trunk/plearn/vmat
Message-ID: <200711142119.lAELJS2U003679@sheep.berlios.de>

Author: tihocan
Date: 2007-11-14 22:19:28 +0100 (Wed, 14 Nov 2007)
New Revision: 8257

Modified:
   trunk/plearn/vmat/RandomSamplesVMatrix.cc
Log:
- Fixed bug when no length was specified
- Added a fixed default seed value so as to make experiments reproducible easily
- Added default 'is_preserved' program so that the class can be used without messing with this option


Modified: trunk/plearn/vmat/RandomSamplesVMatrix.cc
===================================================================
--- trunk/plearn/vmat/RandomSamplesVMatrix.cc	2007-11-14 18:32:26 UTC (rev 8256)
+++ trunk/plearn/vmat/RandomSamplesVMatrix.cc	2007-11-14 21:19:28 UTC (rev 8257)
@@ -48,11 +48,11 @@
     "VMat that samples on-the-fly random examples from its source.",
     "More precisely, this VMat will:\n"
     "- contain all examples from its source that match the 'is_preserved'\n"
-    "  VPL program\n"
-    "- fill the rest of the data with random examples that do not match that\n"
-    "  program\n"
+    "  VPL program (by default, no example is systematically preserved)\n"
+    "- fill the rest of the data with random source examples that do not\n"
+    "  match that program\n"
     "\n"
-    "It is important to note that a random example is sampled at each call\n"
+    "It is important to note that random examples are sampled at each call\n"
     "of the 'getNewRow(..)' method, so that the data viewed by this VMatrix\n"
     "is not constant (except for the rows that are preserved).\n"
     "\n"
@@ -65,9 +65,9 @@
 // RandomSamplesVMatrix //
 //////////////////////////////
 RandomSamplesVMatrix::RandomSamplesVMatrix():
-    is_preserved(""),
+    is_preserved("0"),
     n_non_preserved(-1),
-    seed(-1),
+    seed(1827),
     random_gen(new PRandom())
 {
 }
@@ -155,6 +155,8 @@
         length_ = indices.length() + n_non_preserved;
     else if (n_non_preserved == -2)
         length_ = indices.length() * 2;
+    else if (length_ < 0)
+        length_ = source->length();
 
     // Fill in 'indices' with as many -1 as necessary.
     if (indices.length() > length_)



From nouiz at mail.berlios.de  Wed Nov 14 22:21:25 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 14 Nov 2007 22:21:25 +0100
Subject: [Plearn-commits] r8258 - trunk/plearn_learners/regressors
Message-ID: <200711142121.lAELLPlT004176@sheep.berlios.de>

Author: nouiz
Date: 2007-11-14 22:21:25 +0100 (Wed, 14 Nov 2007)
New Revision: 8258

Modified:
   trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
Log:
removed declareOption that was done in class we inherit from


Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-14 21:19:28 UTC (rev 8257)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-14 21:21:25 UTC (rev 8258)
@@ -73,16 +73,6 @@
 
     declareOption(ol, "next_id", &RegressionTreeRegisters::next_id, OptionBase::learntoption,
                   "The next id for creating a new leave\n");
-    declareOption(ol, "length", &RegressionTreeRegisters::length_, OptionBase::learntoption,
-                  "The length of the train set\n");
-    declareOption(ol, "width", &RegressionTreeRegisters::width_, OptionBase::learntoption,
-                  "The width of the train set\n");
-    declareOption(ol, "inputsize", &RegressionTreeRegisters::inputsize_, OptionBase::learntoption,
-                  "The input size of the train set\n");
-    declareOption(ol, "targetsize", &RegressionTreeRegisters::targetsize_, OptionBase::learntoption,
-                  "The target size of the train set\n");
-    declareOption(ol, "weightsize", &RegressionTreeRegisters::weightsize_, OptionBase::learntoption,
-                  "The weight of each sample in the train set\n");
     declareOption(ol, "leave_register", &RegressionTreeRegisters::leave_register, OptionBase::learntoption,
                   "The vector identifying the leave to which, each row belongs\n");
     declareOption(ol, "leave_candidate", &RegressionTreeRegisters::leave_candidate, OptionBase::learntoption,



From tihocan at mail.berlios.de  Wed Nov 14 22:31:15 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Wed, 14 Nov 2007 22:31:15 +0100
Subject: [Plearn-commits] r8259 - trunk/plearn/vmat
Message-ID: <200711142131.lAELVFxt005237@sheep.berlios.de>

Author: tihocan
Date: 2007-11-14 22:31:15 +0100 (Wed, 14 Nov 2007)
New Revision: 8259

Modified:
   trunk/plearn/vmat/TextFilesVMatrix.cc
Log:
Fixed some typos in help

Modified: trunk/plearn/vmat/TextFilesVMatrix.cc
===================================================================
--- trunk/plearn/vmat/TextFilesVMatrix.cc	2007-11-14 21:21:25 UTC (rev 8258)
+++ trunk/plearn/vmat/TextFilesVMatrix.cc	2007-11-14 21:31:15 UTC (rev 8259)
@@ -795,8 +795,8 @@
                   "- \";\"  : used for a variant of CSV files");
 
     declareOption(ol, "quote_delimiter", &TextFilesVMatrix::quote_delimiter, OptionBase::buildoption,
-                  "The escate caractere where the delimiter is not considered."
-                  " //! - '\"' : used frequently.");
+        "The escape character to indicate the delimiter is not considered.\n"
+        "For instance, '\"' is frequently used.");
 
     declareOption(ol, "skipheader", &TextFilesVMatrix::skipheader, OptionBase::buildoption,
                   "An (optional) list of integers, one for each of the txtfilenames,\n"



From nouiz at mail.berlios.de  Wed Nov 14 22:32:02 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 14 Nov 2007 22:32:02 +0100
Subject: [Plearn-commits] r8260 - trunk/plearn_learners/regressors
Message-ID: <200711142132.lAELW2ph005304@sheep.berlios.de>

Author: nouiz
Date: 2007-11-14 22:32:02 +0100 (Wed, 14 Nov 2007)
New Revision: 8260

Modified:
   trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.h
Log:
transposed the source matrix and put it in memory. 
As we make the majority of look up in the columns direction. This get better performance with the cache of the cpu as the data is aligned in the direction of the cache.


Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-14 21:31:15 UTC (rev 8259)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-14 21:32:02 UTC (rev 8260)
@@ -40,6 +40,8 @@
  ********************************************************************************** */
 
 #include "RegressionTreeRegisters.h"
+#include <plearn/vmat/TransposeVMatrix.h>
+#include <plearn/vmat/MemoryVMatrix.h>
 
 namespace PLearn {
 using namespace std;
@@ -68,8 +70,8 @@
                   "The indicator to report progress through a progress bar\n");
     declareOption(ol, "verbosity", &RegressionTreeRegisters::verbosity, OptionBase::buildoption,
                   "The desired level of verbosity\n");
-    declareOption(ol, "source", &RegressionTreeRegisters::source, OptionBase::buildoption,
-                  "The source VMatrix");
+    declareOption(ol, "tsource", &RegressionTreeRegisters::tsource, OptionBase::learntoption,
+                  "The source VMatrix transposed");
 
     declareOption(ol, "next_id", &RegressionTreeRegisters::next_id, OptionBase::learntoption,
                   "The next id for creating a new leave\n");
@@ -95,6 +97,7 @@
     deepCopyField(inverted_sorted_row, copies);
     deepCopyField(leave_register, copies);
     deepCopyField(leave_candidate, copies);
+    deepCopyField(getExample_tmp, copies);
 }
 
 void RegressionTreeRegisters::build()
@@ -109,12 +112,12 @@
 
 void RegressionTreeRegisters::initRegisters(VMat the_train_set)
 {
-    source = the_train_set;
-    length_ = source->length();
-    width_ = source->width();
-    inputsize_ = source->inputsize();
-    targetsize_ = source->targetsize();
-    weightsize_ = source->weightsize();
+    tsource = VMat(MemoryVMatrix(TransposeVMatrix(the_train_set)));
+    length_ = the_train_set->length();
+    width_ = the_train_set->width();
+    inputsize_ = the_train_set->inputsize();
+    targetsize_ = the_train_set->targetsize();
+    weightsize_ = the_train_set->weightsize();
     leave_register.resize(length());
     leave_candidate.resize(length());
     sortRows();
@@ -140,24 +143,24 @@
 
 real RegressionTreeRegisters::get(int i, int j) const
 {
-    return source->get(i,j);
+    return tsource->get(j,i);
 }
 
 real RegressionTreeRegisters::getTarget(int row)
 {
-    return source->get(row, inputsize());
+    return tsource->get(inputsize(), row);
 }
 
 real RegressionTreeRegisters::getWeight(int row)
 {
     if (weightsize() <= 0) return 1.0 / length();
-    else return source->get(row, inputsize() + targetsize() );
+    else return tsource->get(inputsize() + targetsize(), row );
 }
 
 void RegressionTreeRegisters::setWeight(int row, real val)
 {
     PLASSERT(weightsize() > 0);
-    source->put(row, inputsize() + targetsize(), val );
+    tsource->put( inputsize() + targetsize(), row, val );
 }
 
 int RegressionTreeRegisters::getNextId()
@@ -227,7 +230,7 @@
         {
             inverted_sorted_row(sorted_row(each_train_sample_index, sample_dim), sample_dim) = each_train_sample_index;
         }
-    }  
+    }
 }
   
 void RegressionTreeRegisters::sortEachDim(int dim)
@@ -256,22 +259,22 @@
         else
         {
             swapIndex(start_index + 1, (start_index + end_index) / 2, dim);
-            if (compare(source->get(sorted_row(start_index, dim), dim),
-                        source->get(sorted_row(end_index, dim), dim)) > 0.0)
+            if (compare(tsource->get(dim, sorted_row(start_index, dim)),
+                        tsource->get(dim, sorted_row(end_index, dim))) > 0.0)
                 swapIndex(start_index, end_index, dim);
-            if (compare(source->get(sorted_row(start_index + 1, dim), dim),
-                        source->get(sorted_row(end_index, dim), dim)) > 0.0)
+            if (compare(tsource->get(dim, sorted_row(start_index + 1, dim)),
+                        tsource->get(dim, sorted_row(end_index, dim))) > 0.0)
                 swapIndex(start_index + 1, end_index, dim);
-            if (compare(source->get(sorted_row(start_index, dim), dim),
-                        source->get(sorted_row(start_index + 1, dim), dim)) > 0.0)
+            if (compare(tsource->get(dim, sorted_row(start_index, dim)),
+                        tsource->get(dim, sorted_row(start_index + 1, dim))) > 0.0)
                 swapIndex(start_index, start_index + 1, dim);
             forward_index = start_index + 1;
             backward_index = end_index;
-            real sample_feature = source->get(sorted_row(start_index + 1, dim), dim);
+            real sample_feature = tsource->get(dim, sorted_row(start_index + 1, dim));
             for (;;)
             {
-                do forward_index++; while (compare(source->get(sorted_row(forward_index, dim), dim), sample_feature) < 0.0);
-                do backward_index--; while (compare(source->get(sorted_row(backward_index, dim), dim), sample_feature) > 0.0);
+                do forward_index++; while (compare(tsource->get(dim, sorted_row(forward_index, dim)), sample_feature) < 0.0);
+                do backward_index--; while (compare(tsource->get(dim, sorted_row(backward_index, dim)), sample_feature) > 0.0);
                 if (backward_index < forward_index)
                 {
                     break;
@@ -305,13 +308,13 @@
          next_train_sample_index++)
     {
         int saved_index = sorted_row(next_train_sample_index, dim);
-        real sample_feature = source->get(saved_index, dim);
+        real sample_feature = tsource->get(dim,saved_index);
         int each_train_sample_index;
         for (each_train_sample_index = next_train_sample_index - 1;
              each_train_sample_index >= the_start_index;
              each_train_sample_index--)
         {
-            if (compare(source->get(sorted_row(each_train_sample_index, dim), dim), sample_feature) <= 0.0)
+            if (compare(tsource->get(dim,sorted_row(each_train_sample_index, dim)), sample_feature) <= 0.0)
             {
                 break;
             }
@@ -339,9 +342,11 @@
 void RegressionTreeRegisters::printRegisters()
 {
     cout << "candidate: ";
-    for (int ii = 0; ii < length(); ii++) cout << " " << tostring(leave_candidate[ii]);
+    for (int ii = 0; ii < leave_candidate.length(); ii++) 
+        cout << " " << tostring(leave_candidate[ii]);
     cout << " register:  ";
-    for (int ii = 0; ii < length(); ii++) cout << " " << tostring(leave_register[ii]);
+    for (int ii = 0; ii < leave_register.length(); ii++) 
+        cout << " " << tostring(leave_register[ii]);
     cout << endl;
 }
 
@@ -353,25 +358,30 @@
 
 void RegressionTreeRegisters::getExample(int i, Vec& input, Vec& target, real& weight)
 {
+#ifdef BOUNDCHECK
     if(inputsize_<0)
-        PLERROR("In VMatrix::getExample, inputsize_ not defined for this vmat");
+        PLERROR("In RegressionTreeRegisters::getExample, inputsize_ not defined for this vmat");
+    if(targetsize_<0)
+        PLERROR("In RegressionTreeRegisters::getExample, targetsize_ not defined for this vmat");
+    if(weightsize()<0)
+        PLERROR("In RegressionTreeRegisters::getExample, weightsize_ not defined for this vmat");
+#endif
     input.resize(inputsize_);
-    source->getSubRow(i,0,input);
-    if(targetsize_<0)
-        PLERROR("In VMatrix::getExample, targetsize_ not defined for this vmat");
+    getExample_tmp.resize(width());
+    tsource->getColumn(i,getExample_tmp);
+    input << getExample_tmp.subVec(0,input.size());
+
     target.resize(targetsize_);
     if (targetsize_ > 0) {
-        source->getSubRow(i,inputsize_,target);
+        target<<getExample_tmp.subVecSelf(inputsize(),targetsize());
     }
 
     if(weightsize()==0)
         weight = 1;
-    else if(weightsize()<0)
-        PLERROR("In VMatrix::getExample, weightsize_ not defined for this vmat");
     else if(weightsize()>1)
         PLERROR("In VMatrix::getExample, weightsize_ >1 not supported by this call");
     else
-        weight = source->get(i,inputsize()+targetsize());
+        weight = tsource->get(inputsize()+targetsize(),i);
 }
 
 

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-11-14 21:31:15 UTC (rev 8259)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-11-14 21:32:02 UTC (rev 8260)
@@ -73,10 +73,10 @@
     TMat<int> inverted_sorted_row;
     TVec<int> leave_register;
     TVec<int> leave_candidate;
+    VMat tsource;
  
 public:
 
-    VMat source;
     RegressionTreeRegisters();
     virtual              ~RegressionTreeRegisters();
     
@@ -108,6 +108,9 @@
     void         swapIndex(int index_i, int index_j, int dim);
     real         compare(real field1, real field2);
     void         verbose(string msg, int level);
+
+    mutable Vec  getExample_tmp;
+
 };
 
 DECLARE_OBJECT_PTR(RegressionTreeRegisters);



From nouiz at mail.berlios.de  Wed Nov 14 22:58:02 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 14 Nov 2007 22:58:02 +0100
Subject: [Plearn-commits] r8261 - trunk/plearn_learners/regressors
Message-ID: <200711142158.lAELw2SF008471@sheep.berlios.de>

Author: nouiz
Date: 2007-11-14 22:58:02 +0100 (Wed, 14 Nov 2007)
New Revision: 8261

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.h
Log:
moved the tracking of candidate row for splitting to the RegressionTreeNode. This change the logic as to minimize memory acces and as such give a big speedup. On a test the speep up was of 15%.


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-14 21:32:02 UTC (rev 8260)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-14 21:58:02 UTC (rev 8261)
@@ -144,7 +144,6 @@
     weighted_squared_targets_sum += weight * squared_target;  
     computeOutputAndError();
     getOutputAndError(outputv,errorv);
-    train_set->applyForRow(id, row);
 }
 
 void RegressionTreeLeave::removeRow(int row, Vec outputv, Vec errorv)

Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2007-11-14 21:32:02 UTC (rev 8260)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2007-11-14 21:58:02 UTC (rev 8261)
@@ -143,7 +143,6 @@
         PLERROR("RegressionTreeMultilassLeave: Unknown target: %d row: %d\n", target,row);
     computeOutputAndError();
     getOutputAndError(outputv,errorv);
-    train_set->applyForRow(id, row);
 }
 
 void RegressionTreeMulticlassLeave::removeRow(int row, Vec outputv, Vec errorv)

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-14 21:32:02 UTC (rev 8260)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-14 21:58:02 UTC (rev 8261)
@@ -212,33 +212,37 @@
 
 void RegressionTreeNode::lookForBestSplit()
 {
+    TVec<int> candidate;//list of candidate row to split
     for (int col = 0; col < inputsize; col++)
     {
         missing_leave->initStats();
         left_leave->initStats();
         right_leave->initStats();
-        for (int row = train_set->getNextRegisteredRow(leave_id, col, -1); row < length; row = train_set->getNextRegisteredRow(leave_id, col, row))
+        for (int row = train_set->getNextRegisteredRow(leave_id, col, -1);
+             row < length; row = train_set->getNextRegisteredRow(leave_id, col, row))
         {
-            if (is_missing(train_set->get(row, col))) missing_leave->addRow(row, missing_output, missing_error);
-            else right_leave->addRow(row, right_output, right_error);
+            if (is_missing(train_set->get(row, col)))
+                missing_leave->addRow(row, missing_output, missing_error);
+            else {
+                left_leave->addRow(row, right_output, right_error);
+                candidate.append(row);
+            }
         }
-        int row = train_set->getNextCandidateRow(right_leave_id, col, -1);
-        int next_row = train_set->getNextCandidateRow(right_leave_id, col, row);
-
-        while (true)
+        int row = candidate.pop();
+        while (candidate.size()>0)
         {
-            if (next_row >= length) break;
-            right_leave->removeRow(row, right_output, right_error);
-            left_leave->addRow(row, left_output, left_error);
-            compareSplit(col, train_set->get(row, col), train_set->get(next_row, col));
+            int next_row = candidate.pop();
+            left_leave->removeRow(row, left_output, left_error);
+            right_leave->addRow(row, right_output, right_error);
+            compareSplit(col, train_set->get(next_row, col), train_set->get(row, col));
             row = next_row;
-            next_row = train_set->getNextCandidateRow(right_leave_id, col, row);
         }
     }
 }
 
 void RegressionTreeNode::compareSplit(int col, real left_leave_last_feature, real right_leave_first_feature)
 {
+    PLASSERT(left_leave_last_feature<=right_leave_first_feature);
     if (left_leave_last_feature >= right_leave_first_feature) return;
     real work_error = missing_error[0] + missing_error[1] + left_error[0] + left_error[1] + right_error[0] + right_error[1];
     int work_balance = abs(left_leave->getLength() - right_leave->getLength());

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-14 21:32:02 UTC (rev 8260)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-14 21:58:02 UTC (rev 8261)
@@ -77,8 +77,6 @@
                   "The next id for creating a new leave\n");
     declareOption(ol, "leave_register", &RegressionTreeRegisters::leave_register, OptionBase::learntoption,
                   "The vector identifying the leave to which, each row belongs\n");
-    declareOption(ol, "leave_candidate", &RegressionTreeRegisters::leave_candidate, OptionBase::learntoption,
-                  "The vector identifying the candidate leave to which, each row could belong after split\n");
 
     //too big to save
     declareOption(ol, "sorted_row", &RegressionTreeRegisters::sorted_row, OptionBase::nosave,
@@ -96,7 +94,6 @@
     deepCopyField(sorted_row, copies);
     deepCopyField(inverted_sorted_row, copies);
     deepCopyField(leave_register, copies);
-    deepCopyField(leave_candidate, copies);
     deepCopyField(getExample_tmp, copies);
 }
 
@@ -119,7 +116,6 @@
     targetsize_ = the_train_set->targetsize();
     weightsize_ = the_train_set->weightsize();
     leave_register.resize(length());
-    leave_candidate.resize(length());
     sortRows();
 }
 
@@ -131,11 +127,6 @@
     sortRows();
 }
 
-void RegressionTreeRegisters::applyForRow(int leave_id, int row)
-{
-    leave_candidate[row] = leave_id;
-}
-
 void RegressionTreeRegisters::registerLeave(int leave_id, int row)
 {
     leave_register[row] = leave_id;
@@ -184,21 +175,6 @@
     return sorted_row(each_train_sample_index, col);
 }
 
-int RegressionTreeRegisters::getNextCandidateRow(int leave_id, int col, int previous_row)
-{
-    if (previous_row >= length()) return length();
-    int each_train_sample_index;
-    if (previous_row < 0) each_train_sample_index = 0;
-    else each_train_sample_index = inverted_sorted_row(previous_row, col) + 1;
-    while (true)
-    {
-        if (each_train_sample_index >= length()) return length();
-        if (leave_candidate[sorted_row(each_train_sample_index, col)] == leave_id) break;
-        each_train_sample_index += 1;
-    }
-    return sorted_row(each_train_sample_index, col);
-}
-
 void RegressionTreeRegisters::sortRows()
 {
     next_id = 0;
@@ -341,9 +317,6 @@
 
 void RegressionTreeRegisters::printRegisters()
 {
-    cout << "candidate: ";
-    for (int ii = 0; ii < leave_candidate.length(); ii++) 
-        cout << " " << tostring(leave_candidate[ii]);
     cout << " register:  ";
     for (int ii = 0; ii < leave_register.length(); ii++) 
         cout << " " << tostring(leave_register[ii]);
@@ -373,7 +346,7 @@
 
     target.resize(targetsize_);
     if (targetsize_ > 0) {
-        target<<getExample_tmp.subVecSelf(inputsize(),targetsize());
+        target<<getExample_tmp.subVec(inputsize(),targetsize());
     }
 
     if(weightsize()==0)

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-11-14 21:32:02 UTC (rev 8260)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-11-14 21:58:02 UTC (rev 8261)
@@ -72,7 +72,6 @@
     TMat<int> sorted_row;
     TMat<int> inverted_sorted_row;
     TVec<int> leave_register;
-    TVec<int> leave_candidate;
     VMat tsource;
  
 public:
@@ -87,7 +86,6 @@
     virtual void         build();
     void         initRegisters(VMat train_set);
     void         reinitRegisters();
-    void         applyForRow(int leave_id, int row);
     void         registerLeave(int leave_id, int row);
     virtual real get(int row, int col) const;
     real         getTarget(int row);
@@ -95,7 +93,6 @@
     void         setWeight(int row,real val);
     int          getNextId();
     int          getNextRegisteredRow(int leave_id, int col, int previous_row);
-    int          getNextCandidateRow(int leave_id, int col, int previous_row);
     void         sortRows();
     void         printRegisters();
     void         getExample(int i, Vec& input, Vec& target, real& weight);



From nouiz at mail.berlios.de  Thu Nov 15 21:31:38 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 15 Nov 2007 21:31:38 +0100
Subject: [Plearn-commits] r8262 - in trunk: plearn/base
	plearn_learners_experimental
Message-ID: <200711152031.lAFKVct3009050@sheep.berlios.de>

Author: nouiz
Date: 2007-11-15 21:31:37 +0100 (Thu, 15 Nov 2007)
New Revision: 8262

Modified:
   trunk/plearn/base/Object.h
   trunk/plearn_learners_experimental/StructuralLearner.cc
Log:
corrected comment for doxygen


Modified: trunk/plearn/base/Object.h
===================================================================
--- trunk/plearn/base/Object.h	2007-11-14 21:58:02 UTC (rev 8261)
+++ trunk/plearn/base/Object.h	2007-11-15 20:31:37 UTC (rev 8262)
@@ -843,7 +843,7 @@
      *  Subclasses may override this method to provide different outputs
      *  depending on \c out's mode (\c plearn_ascii, \c raw_ascii, ...).
      *
-     *  @param in  Stream onto which serialize the object
+     *  @param out  Stream onto which serialize the object
      */
     virtual void newwrite(PStream& out) const;
 

Modified: trunk/plearn_learners_experimental/StructuralLearner.cc
===================================================================
--- trunk/plearn_learners_experimental/StructuralLearner.cc	2007-11-14 21:58:02 UTC (rev 8261)
+++ trunk/plearn_learners_experimental/StructuralLearner.cc	2007-11-15 20:31:37 UTC (rev 8262)
@@ -1706,10 +1706,8 @@
 *       '00000100' means return only features for the position we're making the
 *       prediction at
 *
-* @returns 
 *
 * @note 
-* @todo 
 **/
 void StructuralLearner::updateFeatures(const Vec& input, const Vec& target,  TVec< TVec<unsigned int> >& theFeatureGroups, char
 featureMask) const
@@ -1777,11 +1775,8 @@
 * @brief Determines 1000 most frequent words and builds 2 TVecs of indices of examples that have respetively
 * a frequent word at current and left positions.
 * 
-* @param 
-* @returns 
 *
 * @note 
-* @todo 
 **/
 void StructuralLearner::initWordProblemsStructures()
 {
@@ -1874,11 +1869,8 @@
 * @brief Determines which "previous label - current word" bigrams are in the
 * training set and indexes them is a stl map.
 * OOV's are ignored.
-* @param 
-* @returns 
 *
 * @note 
-* @todo 
 **/
 void StructuralLearner::initPreviousLabelCurrentWordBigramMapping()
 {



From nouiz at mail.berlios.de  Thu Nov 15 21:43:19 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 15 Nov 2007 21:43:19 +0100
Subject: [Plearn-commits] r8263 - trunk/plearn/vmat
Message-ID: <200711152043.lAFKhJBu009722@sheep.berlios.de>

Author: nouiz
Date: 2007-11-15 21:43:18 +0100 (Thu, 15 Nov 2007)
New Revision: 8263

Modified:
   trunk/plearn/vmat/VMatrix.cc
Log:
implemented getUser() so that when we get a lock, we print the username as well


Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-11-15 20:31:37 UTC (rev 8262)
+++ trunk/plearn/vmat/VMatrix.cc	2007-11-15 20:43:18 UTC (rev 8263)
@@ -50,6 +50,7 @@
 #include <plearn/io/load_and_save.h>
 #include <plearn/math/random.h>      //!< For uniform_multinomial_sample()
 #include <plearn/base/RemoteDeclareMethod.h>
+#include <nspr/prenv.h>
 
 namespace PLearn {
 using namespace std;
@@ -1232,7 +1233,13 @@
 /////////////
 string getUser()
 {
-    return "TODO";
+    const char* h = PR_GetEnv("USER");
+    if (!h)
+        h = PR_GetEnv("LOGNAME");
+    if (!h)
+        return "USERNAME_NOT_FOUND";
+    return tostring(h);
+        
 }
 
 /////////////////////



From nouiz at mail.berlios.de  Fri Nov 16 16:37:52 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 16 Nov 2007 16:37:52 +0100
Subject: [Plearn-commits] r8264 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711161537.lAGFbqa7017567@sheep.berlios.de>

Author: nouiz
Date: 2007-11-16 16:37:52 +0100 (Fri, 16 Nov 2007)
New Revision: 8264

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h
Log:
some speed up by reusing vec


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc	2007-11-15 20:43:18 UTC (rev 8263)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc	2007-11-16 15:37:52 UTC (rev 8264)
@@ -123,12 +123,16 @@
         base_regressor->setTrainingSet(train_set, true);
         base_regressor->setTrainStatsCollector(new VecStatsCollector);
         if (class_prediction == 0) search_table = ref_sales->toMat();
+        sample_input.resize(train_set->inputsize());
+        sample_target.resize(train_set->targetsize());
+        sample_output.resize(base_regressor->outputsize());
+        sample_costs.resize(4);
     }
 }
 
 void SecondIterationWrapper::train()
 {
-    base_regressor->setOption("nstages", tostring(nstages));
+    base_regressor->nstages = nstages;
     base_regressor->train();
     if (class_prediction == 1) computeClassStatistics();
     else computeSalesStatistics();
@@ -136,19 +140,14 @@
 
 void SecondIterationWrapper::computeClassStatistics()
 {
-    int row;
-    Vec sample_input(train_set->inputsize());
-    Vec sample_target(train_set->targetsize());
     real sample_weight;
-    Vec sample_output(base_regressor->outputsize());
-    Vec sample_costs(4);
     ProgressBar* pb = NULL;
     if (report_progress)
-    {
-        pb = new ProgressBar("Second Iteration : computing the train statistics: ", train_set->length());
-    } 
+        pb = new ProgressBar("Second Iteration : computing the train statistics: ",
+                             train_set->length());
+
     train_stats->forget();
-    for (row = 0; row < train_set->length(); row++)
+    for (int row = 0; row < train_set->length(); row++)
     {  
         train_set->getExample(row, sample_input, sample_target, sample_weight);
         computeOutput(sample_input, sample_output);

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h	2007-11-15 20:43:18 UTC (rev 8263)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h	2007-11-16 15:37:52 UTC (rev 8264)
@@ -84,7 +84,11 @@
     int tclass;
     Mat search_table;
     
-   
+    Vec sample_input;
+    Vec sample_target;
+    Vec sample_output;
+    Vec sample_costs;
+
   
 public:
     SecondIterationWrapper();



From nouiz at mail.berlios.de  Fri Nov 16 16:43:38 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 16 Nov 2007 16:43:38 +0100
Subject: [Plearn-commits] r8265 - trunk/plearn_learners/regressors
Message-ID: <200711161543.lAGFhclG017895@sheep.berlios.de>

Author: nouiz
Date: 2007-11-16 16:43:38 +0100 (Fri, 16 Nov 2007)
New Revision: 8265

Modified:
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/RegressionTreeNode.h
   trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.h
Log:
speed up. 
-Store the sorting of row in transposed mode as we always do lookup in columns mode. This is nicer with the cache subsystem.
-Changed the semantic to get all the registered row at the same time. This remove the use of a big matrix and do some speed up.


Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-16 15:37:52 UTC (rev 8264)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-16 15:43:38 UTC (rev 8265)
@@ -213,14 +213,17 @@
 void RegressionTreeNode::lookForBestSplit()
 {
     TVec<int> candidate;//list of candidate row to split
+    TVec<int> registered_row;
     for (int col = 0; col < inputsize; col++)
     {
         missing_leave->initStats();
         left_leave->initStats();
         right_leave->initStats();
-        for (int row = train_set->getNextRegisteredRow(leave_id, col, -1);
-             row < length; row = train_set->getNextRegisteredRow(leave_id, col, row))
+        registered_row.resize(0);
+        train_set->getAllRegisteredRow(leave_id,col,registered_row);
+        for(int row_idx = 0;row_idx<registered_row.size();row_idx++)
         {
+            int row=registered_row[row_idx];
             if (is_missing(train_set->get(row, col)))
                 missing_leave->addRow(row, missing_output, missing_error);
             else {
@@ -265,8 +268,12 @@
     missing_leave->initStats();
     left_leave->initStats();
     right_leave->initStats();
-    for (int row = train_set->getNextRegisteredRow(leave_id, split_col, -1); row < length; row = train_set->getNextRegisteredRow(leave_id, split_col, row))
+    TVec<int>registered_row;
+    train_set->getAllRegisteredRow(leave_id,split_col,registered_row);
+
+    for (int row_index = 0;row_index<registered_row.size();row_index++)
     {
+        int row=registered_row[row_index];
         if (is_missing(train_set->get(row, split_col)))
         {
             missing_leave->addRow(row, missing_output, missing_error);
@@ -277,12 +284,12 @@
             if (train_set->get(row, split_col) < split_feature_value)
             {
                 left_leave->addRow(row, left_output, left_error);
-                left_leave->registerRow(row);    
+                left_leave->registerRow(row);
             }
             else
             {
                 right_leave->addRow(row, right_output, right_error);
-                right_leave->registerRow(row); 
+                right_leave->registerRow(row);
             }
         }
     }

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-16 15:37:52 UTC (rev 8264)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-16 15:43:38 UTC (rev 8265)
@@ -93,7 +93,7 @@
     PP<RegressionTreeLeave> right_leave;
     Vec right_output;
     Vec right_error;
- 
+    
 public:  
     RegressionTreeNode();
     virtual              ~RegressionTreeNode();
@@ -114,7 +114,7 @@
     
 private:
     void         build_();
-    void         verbose(string msg, int level);
+    void         verbose(string msg, int level);    
 };
 
 DECLARE_OBJECT_PTR(RegressionTreeNode);

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-16 15:37:52 UTC (rev 8264)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-16 15:43:38 UTC (rev 8265)
@@ -73,17 +73,18 @@
     declareOption(ol, "tsource", &RegressionTreeRegisters::tsource, OptionBase::learntoption,
                   "The source VMatrix transposed");
 
+    declareOption(ol, "source", &RegressionTreeRegisters::source,
+                  OptionBase::buildoption|OptionBase::nosave,
+                  "DEPRECATED The source VMatrix");
+
     declareOption(ol, "next_id", &RegressionTreeRegisters::next_id, OptionBase::learntoption,
                   "The next id for creating a new leave\n");
     declareOption(ol, "leave_register", &RegressionTreeRegisters::leave_register, OptionBase::learntoption,
                   "The vector identifying the leave to which, each row belongs\n");
 
     //too big to save
-    declareOption(ol, "sorted_row", &RegressionTreeRegisters::sorted_row, OptionBase::nosave,
+    declareOption(ol, "tsorted_row", &RegressionTreeRegisters::tsorted_row, OptionBase::nosave,
                   "The matrix holding the sequence of samples in ascending value order for each dimension\n");
-    //too big to save
-    declareOption(ol, "inverted_sorted_row", &RegressionTreeRegisters::inverted_sorted_row, OptionBase::nosave,
-                  "The matrix holding the position of a given entry in the sorted row matrix\n");
 
     inherited::declareOptions(ol);
 }
@@ -91,8 +92,7 @@
 void RegressionTreeRegisters::makeDeepCopyFromShallowCopy(CopiesMap& copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
-    deepCopyField(sorted_row, copies);
-    deepCopyField(inverted_sorted_row, copies);
+    deepCopyField(tsorted_row, copies);
     deepCopyField(leave_register, copies);
     deepCopyField(getExample_tmp, copies);
 }
@@ -160,53 +160,44 @@
     return next_id;
 }
 
-int RegressionTreeRegisters::getNextRegisteredRow(int leave_id, int col, int previous_row)
+void RegressionTreeRegisters::getAllRegisteredRow(int leave_id, int col, TVec<int> &reg)
 {
-    if (previous_row >= length()) return length();
-    int each_train_sample_index;
-    if (previous_row < 0) each_train_sample_index = 0;
-    else each_train_sample_index = inverted_sorted_row(previous_row, col) + 1;
-    while (true)
+    for(int i=0;i<length();i++)
     {
-        if (each_train_sample_index >= length()) return length();
-        if (leave_register[sorted_row(each_train_sample_index, col)] == leave_id) break;
-        each_train_sample_index += 1;
+        int srow = tsorted_row(col, i);
+        if ( leave_register[srow] == leave_id)
+            reg.append(srow);
     }
-    return sorted_row(each_train_sample_index, col);
 }
 
 void RegressionTreeRegisters::sortRows()
 {
     next_id = 0;
-    if (sorted_row.length() == length() && sorted_row.width() == inputsize())
+    if (tsorted_row.length() == length() && tsorted_row.width() == inputsize())
     {
         verbose("RegressionTreeRegisters: Sorted train set indices are present, no sort required", 3);
         return;
     }
     verbose("RegressionTreeRegisters: The train set is being sorted", 3);
-    sorted_row.resize(length(), inputsize());
+    tsorted_row.resize(inputsize(), length());
     PP<ProgressBar> pb;
     if (report_progress)
     {
         pb = new ProgressBar("RegressionTreeRegisters : sorting the train set on input dimensions: ", inputsize());
     }
-    for (int each_train_sample_index = 0; each_train_sample_index < length(); each_train_sample_index++)
-    {
-        sorted_row(each_train_sample_index).fill(each_train_sample_index);
-    }
+    for(int row=0;row<tsorted_row.length();row++)
+        for(int col=0;col<tsorted_row.width(); col++)
+            tsorted_row(row,col)=col;
+            
+//     for (int each_train_sample_index = 0; each_train_sample_index < length(); each_train_sample_index++)
+//     {
+//         sorted_row(each_train_sample_index).fill(each_train_sample_index);
+//     }
     for (int sample_dim = 0; sample_dim < inputsize(); sample_dim++)
     {
         sortEachDim(sample_dim);
         if (report_progress) pb->update(sample_dim);
     }
-    inverted_sorted_row.resize(length(), inputsize());
-    for (int each_train_sample_index = 0; each_train_sample_index < length(); each_train_sample_index++)
-    {
-        for (int sample_dim = 0; sample_dim < inputsize(); sample_dim++)
-        {
-            inverted_sorted_row(sorted_row(each_train_sample_index, sample_dim), sample_dim) = each_train_sample_index;
-        }
-    }
 }
   
 void RegressionTreeRegisters::sortEachDim(int dim)
@@ -235,22 +226,22 @@
         else
         {
             swapIndex(start_index + 1, (start_index + end_index) / 2, dim);
-            if (compare(tsource->get(dim, sorted_row(start_index, dim)),
-                        tsource->get(dim, sorted_row(end_index, dim))) > 0.0)
+            if (compare(tsource->get(dim, tsorted_row(dim, start_index)),
+                        tsource->get(dim, tsorted_row(dim, end_index))) > 0.0)
                 swapIndex(start_index, end_index, dim);
-            if (compare(tsource->get(dim, sorted_row(start_index + 1, dim)),
-                        tsource->get(dim, sorted_row(end_index, dim))) > 0.0)
+            if (compare(tsource->get(dim, tsorted_row(dim, start_index + 1)),
+                        tsource->get(dim, tsorted_row(dim, end_index))) > 0.0)
                 swapIndex(start_index + 1, end_index, dim);
-            if (compare(tsource->get(dim, sorted_row(start_index, dim)),
-                        tsource->get(dim, sorted_row(start_index + 1, dim))) > 0.0)
+            if (compare(tsource->get(dim, tsorted_row(dim, start_index)),
+                        tsource->get(dim, tsorted_row(dim, start_index + 1))) > 0.0)
                 swapIndex(start_index, start_index + 1, dim);
             forward_index = start_index + 1;
             backward_index = end_index;
-            real sample_feature = tsource->get(dim, sorted_row(start_index + 1, dim));
+            real sample_feature = tsource->get(dim, tsorted_row(dim, start_index + 1));
             for (;;)
             {
-                do forward_index++; while (compare(tsource->get(dim, sorted_row(forward_index, dim)), sample_feature) < 0.0);
-                do backward_index--; while (compare(tsource->get(dim, sorted_row(backward_index, dim)), sample_feature) > 0.0);
+                do forward_index++; while (compare(tsource->get(dim, tsorted_row(dim, forward_index)), sample_feature) < 0.0);
+                do backward_index--; while (compare(tsource->get(dim, tsorted_row(dim, backward_index)), sample_feature) > 0.0);
                 if (backward_index < forward_index)
                 {
                     break;
@@ -283,28 +274,28 @@
          next_train_sample_index <= the_end_index;
          next_train_sample_index++)
     {
-        int saved_index = sorted_row(next_train_sample_index, dim);
+        int saved_index = tsorted_row(dim, next_train_sample_index);
         real sample_feature = tsource->get(dim,saved_index);
         int each_train_sample_index;
         for (each_train_sample_index = next_train_sample_index - 1;
              each_train_sample_index >= the_start_index;
              each_train_sample_index--)
         {
-            if (compare(tsource->get(dim,sorted_row(each_train_sample_index, dim)), sample_feature) <= 0.0)
+            if (compare(tsource->get(dim,tsorted_row(dim, each_train_sample_index)), sample_feature) <= 0.0)
             {
                 break;
             }
-            sorted_row(each_train_sample_index + 1, dim) = sorted_row(each_train_sample_index, dim);
+            tsorted_row(dim, each_train_sample_index + 1) = tsorted_row(dim, each_train_sample_index);
         }
-        sorted_row(each_train_sample_index + 1, dim) = saved_index;
+        tsorted_row(dim, each_train_sample_index + 1) = saved_index;
     }  
 }
 
 void RegressionTreeRegisters::swapIndex(int index_i, int index_j, int dim)
 {
-    int saved_index = sorted_row(index_i, dim);
-    sorted_row(index_i, dim) = sorted_row(index_j, dim);
-    sorted_row(index_j, dim) = saved_index;
+    int saved_index = tsorted_row(dim, index_i);
+    tsorted_row(dim, index_i) = tsorted_row(dim, index_j);
+    tsorted_row(dim, index_j) = saved_index;
 }
 
 real RegressionTreeRegisters::compare(real field1, real field2)

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-11-16 15:37:52 UTC (rev 8264)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-11-16 15:43:38 UTC (rev 8265)
@@ -69,8 +69,8 @@
 */
 
     int       next_id;
-    TMat<int> sorted_row;
-    TMat<int> inverted_sorted_row;
+    //TMat<int> sorted_row;
+    TMat<int> tsorted_row;
     TVec<int> leave_register;
     VMat tsource;
  
@@ -92,11 +92,12 @@
     real         getWeight(int row);
     void         setWeight(int row,real val);
     int          getNextId();
-    int          getNextRegisteredRow(int leave_id, int col, int previous_row);
+    void         getAllRegisteredRow(int leave_id, int col, TVec<int> &reg);
     void         sortRows();
     void         printRegisters();
     void         getExample(int i, Vec& input, Vec& target, real& weight);
 //    virtual void getNewRow(int i, const Vec& v) const;
+    VMat source;
 
 private:
     void         build_();



From larocheh at mail.berlios.de  Mon Nov 19 22:08:29 2007
From: larocheh at mail.berlios.de (larocheh at BerliOS)
Date: Mon, 19 Nov 2007 22:08:29 +0100
Subject: [Plearn-commits] r8266 - trunk/plearn_learners_experimental
Message-ID: <200711192108.lAJL8TgZ012359@sheep.berlios.de>

Author: larocheh
Date: 2007-11-19 22:08:28 +0100 (Mon, 19 Nov 2007)
New Revision: 8266

Modified:
   trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc
Log:
Making code more efficient when not using knn...


Modified: trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc
===================================================================
--- trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc	2007-11-16 15:43:38 UTC (rev 8265)
+++ trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc	2007-11-19 21:08:28 UTC (rev 8266)
@@ -683,11 +683,14 @@
         reconstruction_activation_gradients.resize(layers[i]->size);
         reconstruction_expectation_gradients.resize(layers[i]->size);
 
-        similar_example_representation.resize(layers[i+1]->size);
-        dissimilar_example_representation.resize(layers[i+1]->size);
-        dissimilar_gradient_contribution.resize(layers[i+1]->size);
-        input_representation.resize(layers[i+1]->size);
-
+        if( !fast_exact_is_equal( supervised_greedy_learning_rate, 0 ) )
+        {
+            similar_example_representation.resize(layers[i+1]->size);
+            dissimilar_example_representation.resize(layers[i+1]->size);
+            dissimilar_gradient_contribution.resize(layers[i+1]->size);
+            input_representation.resize(layers[i+1]->size);
+        }
+        
         greedy_activation.resize(greedy_layers[i]->size);
         greedy_expectation.resize(greedy_layers[i]->size);
         greedy_activation_gradient.resize(greedy_layers[i]->size);
@@ -703,32 +706,34 @@
             
             sample = *this_stage % nsamples;
             train_set->getExample(sample, input, target, weight);
-            // Find similar example
+            if( !fast_exact_is_equal( supervised_greedy_learning_rate, 0 ) )
+            {
+                // Find similar example
+                
+                int sim_index = random_gen->uniform_multinomial_sample(k_neighbors);
+                class_datasets[(int)round(target[0])]->getExample(
+                    nearest_neighbors_indices(sample,sim_index),
+                    similar_example, target2, weight2);
+                
+                if(round(target[0]) != round(target2[0]))
+                    PLERROR("StackedFocusedAutoassociatorsNet::train(): similar"
+                            " example is not from same class!");
+                
+                // Find dissimilar example
+                
+                int dissim_class_index = random_gen->multinomial_sample(
+                    other_classes_proportions((int)round(target[0])));
+                
+                int dissim_index = random_gen->uniform_multinomial_sample(
+                    class_datasets[dissim_class_index]->length());
+                
+                class_datasets[dissim_class_index]->getExample(dissim_index,
+                                                               dissimilar_example, target2, weight2);
 
-            int sim_index = random_gen->uniform_multinomial_sample(k_neighbors);
-            class_datasets[(int)round(target[0])]->getExample(
-                nearest_neighbors_indices(sample,sim_index),
-                similar_example, target2, weight2);
-
-            if(round(target[0]) != round(target2[0]))
-                PLERROR("StackedFocusedAutoassociatorsNet::train(): similar"
-                    " example is not from same class!");
-
-            // Find dissimilar example
-
-            int dissim_class_index = random_gen->multinomial_sample(
-                other_classes_proportions((int)round(target[0])));
-
-            int dissim_index = random_gen->uniform_multinomial_sample(
-                class_datasets[dissim_class_index]->length());
-
-            class_datasets[dissim_class_index]->getExample(dissim_index,
-                                  dissimilar_example, target2, weight2);
-
-            if(((int)round(target[0])) == ((int)round(target2[0])))
-                PLERROR("StackedFocusedAutoassociatorsNet::train(): dissimilar"
-                    " example is from same class!");
-
+                if(((int)round(target[0])) == ((int)round(target2[0])))
+                    PLERROR("StackedFocusedAutoassociatorsNet::train(): dissimilar"
+                            " example is from same class!");
+            }
             greedyStep( input, target, i, train_costs, *this_stage,
                         similar_example, dissimilar_example);
             train_stats->update( train_costs );
@@ -757,14 +762,17 @@
         setLearningRate( fine_tuning_learning_rate );
         train_costs.fill(MISSING_VALUE);
 
-        similar_example_representation.resize(
-            layers[n_layers-1]->size);
-        dissimilar_example_representation.resize(
-            layers[n_layers-1]->size);
-        dissimilar_gradient_contribution.resize(
-            layers[n_layers-1]->size);
-        similar_example.resize(inputsize());
-        dissimilar_example.resize(inputsize());
+        if( !do_not_use_knn_classifier )
+        {
+            similar_example_representation.resize(
+                layers[n_layers-1]->size);
+            dissimilar_example_representation.resize(
+                layers[n_layers-1]->size);
+            dissimilar_gradient_contribution.resize(
+                layers[n_layers-1]->size);
+            similar_example.resize(inputsize());
+            dissimilar_example.resize(inputsize());
+        }
 
         final_cost_input.resize(n_classes);
         final_cost_value.resize(2); // Should be resized anyways
@@ -779,32 +787,35 @@
 
             train_set->getExample( sample, input, target, weight );
 
-            // Find similar example
+            if( !do_not_use_knn_classifier )
+            {
+                // Find similar example
+                
+                int sim_index = random_gen->uniform_multinomial_sample(k_neighbors);
+                class_datasets[(int)round(target[0])]->getExample(
+                    nearest_neighbors_indices(sample,sim_index),
+                    similar_example, target2, weight2);
+                
+                if(((int)round(target[0])) != ((int)round(target2[0])))
+                    PLERROR("StackedFocusedAutoassociatorsNet::train(): similar"
+                            " example is not from same class!");
+                
+                // Find dissimilar example
+                
+                int dissim_class_index = random_gen->multinomial_sample(
+                    other_classes_proportions((int)round(target[0])));
 
-            int sim_index = random_gen->uniform_multinomial_sample(k_neighbors);
-            class_datasets[(int)round(target[0])]->getExample(
-                nearest_neighbors_indices(sample,sim_index),
-                similar_example, target2, weight2);
-
-            if(((int)round(target[0])) != ((int)round(target2[0])))
-                PLERROR("StackedFocusedAutoassociatorsNet::train(): similar"
-                    " example is not from same class!");
-
-            // Find dissimilar example
-
-            int dissim_class_index = random_gen->multinomial_sample(
-                other_classes_proportions((int)round(target[0])));
-
-            int dissim_index = random_gen->uniform_multinomial_sample(
-                class_datasets[dissim_class_index]->length());
-
-            class_datasets[dissim_class_index]->getExample(dissim_index,
+                int dissim_index = random_gen->uniform_multinomial_sample(
+                    class_datasets[dissim_class_index]->length());
+                
+                class_datasets[dissim_class_index]->getExample(dissim_index,
                                   dissimilar_example, target2, weight2);
+                
+                if(((int)round(target[0])) == ((int)round(target2[0])))
+                    PLERROR("StackedFocusedAutoassociatorsNet::train(): dissimilar"
+                            " example is from same class!");
+            }
 
-            if(((int)round(target[0])) == ((int)round(target2[0])))
-                PLERROR("StackedFocusedAutoassociatorsNet::train(): dissimilar"
-                    " example is from same class!");
-
             fineTuningStep( input, target, train_costs, 
                             similar_example, dissimilar_example);
             train_stats->update( train_costs );
@@ -846,16 +857,19 @@
     real lr;
     train_set_representations_up_to_date = false;
 
-    // Get similar example representation
+    if( !fast_exact_is_equal( supervised_greedy_learning_rate, 0 ) )
+    {
+        // Get similar example representation
     
-    computeRepresentation(similar_example, similar_example_representation, 
-                          index+1);
+        computeRepresentation(similar_example, similar_example_representation, 
+                              index+1);
+        
+        // Get dissimilar example representation
+        
+        computeRepresentation(dissimilar_example, dissimilar_example_representation, 
+                              index+1);
+    }
 
-    // Get dissimilar example representation
-
-    computeRepresentation(dissimilar_example, dissimilar_example_representation, 
-                          index+1);
-
     // Get example representation
 
     computeRepresentation(input, previous_input_representation, 
@@ -895,33 +909,36 @@
                                   reconstruction_activation_gradients);
     }
 
-    // Compute supervised gradient
-    
-    // Similar example contribution
-    substract(input_representation,similar_example_representation,
-              expectation_gradients[index+1]);
-    expectation_gradients[index+1] *= 4/sqrt(layers[index+1]->size);
-    
-    // Dissimilar example contribution
-    real dist = sqrt(powdistance(input_representation,
-                                 dissimilar_example_representation,
-                                 2));
-
-    //if( dist == 0 )
-    //    PLWARNING("StackedFocusedAutoassociatorsNet::fineTuningStep(): dissimilar"
-    //              " example representation is exactly the sample as the"
-    //              " input example. Gradient would be infinite! Skipping this"
-    //              " example...");
-    //else
-    //{
-    substract(input_representation,dissimilar_example_representation,
-              dissimilar_gradient_contribution);
-    
-    dissimilar_gradient_contribution *= -2* dissimilar_example_cost_precision*
-        safeexp(-dissimilar_example_cost_precision*dist/sqrt(layers[index+1]->size));
-    
-    expectation_gradients[index+1] += dissimilar_gradient_contribution;
+    if( !fast_exact_is_equal( supervised_greedy_learning_rate, 0 ) )
+    {
+        // Compute supervised gradient
+        
+        // Similar example contribution
+        substract(input_representation,similar_example_representation,
+                  expectation_gradients[index+1]);
+        expectation_gradients[index+1] *= 4/sqrt((real)layers[index+1]->size);
+        
+        // Dissimilar example contribution
+        real dist = sqrt(powdistance(input_representation,
+                                     dissimilar_example_representation,
+                                     2));
+        
+        //if( dist == 0 )
+        //    PLWARNING("StackedFocusedAutoassociatorsNet::fineTuningStep(): dissimilar"
+        //              " example representation is exactly the sample as the"
+        //              " input example. Gradient would be infinite! Skipping this"
+        //              " example...");
+        //else
+        //{
+        substract(input_representation,dissimilar_example_representation,
+                  dissimilar_gradient_contribution);
+        
+        dissimilar_gradient_contribution *= -2* dissimilar_example_cost_precision*
+            safeexp(-dissimilar_example_cost_precision*dist/sqrt((real)layers[index+1]->size));
+        
+        expectation_gradients[index+1] += dissimilar_gradient_contribution;
         //}
+    }
 
     // RBM learning
     if( !fast_exact_is_equal( cd_learning_rate, 0 ) )
@@ -978,27 +995,30 @@
     }
      
 
-    if( !fast_exact_is_equal( supervised_greedy_decrease_ct , 0 ) )
-        lr = supervised_greedy_learning_rate/(1 + supervised_greedy_decrease_ct 
-                               * this_stage); 
-    else
-        lr = supervised_greedy_learning_rate;
-    
-    layers[index]->setLearningRate( lr );
-    connections[index]->setLearningRate( lr );
-    layers[index+1]->setLearningRate( lr );
-    
-    layers[ index+1 ]->bpropUpdate( 
-        greedy_activation.subVec(0,layers[index+1]->size),
-        greedy_expectation.subVec(0,layers[index+1]->size),
-        activation_gradients[index+1], 
-        expectation_gradients[index+1]);
-    
-    connections[ index ]->bpropUpdate( 
-        previous_input_representation,
-        greedy_activation.subVec(0,layers[index+1]->size),
-        expectation_gradients[index],
-        activation_gradients[index+1]);
+    if( !fast_exact_is_equal( supervised_greedy_learning_rate, 0 ) )
+    {
+        if( !fast_exact_is_equal( supervised_greedy_decrease_ct , 0 ) )
+            lr = supervised_greedy_learning_rate/(1 + supervised_greedy_decrease_ct 
+                                                  * this_stage); 
+        else
+            lr = supervised_greedy_learning_rate;
+        
+        layers[index]->setLearningRate( lr );
+        connections[index]->setLearningRate( lr );
+        layers[index+1]->setLearningRate( lr );
+        
+        layers[ index+1 ]->bpropUpdate( 
+            greedy_activation.subVec(0,layers[index+1]->size),
+            greedy_expectation.subVec(0,layers[index+1]->size),
+            activation_gradients[index+1], 
+            expectation_gradients[index+1]);
+        
+        connections[ index ]->bpropUpdate( 
+            previous_input_representation,
+            greedy_activation.subVec(0,layers[index+1]->size),
+            expectation_gradients[index],
+            activation_gradients[index+1]);
+    }
 
     // RBM updates
 
@@ -1053,12 +1073,12 @@
         // Similar example contribution
         substract(previous_input_representation,similar_example_representation,
                   expectation_gradients[n_layers-1]);
-        expectation_gradients[n_layers-1] *= 4/sqrt(layers[n_layers-1]->size);
+        expectation_gradients[n_layers-1] *= 4/sqrt((real)layers[n_layers-1]->size);
     
         train_costs[train_costs.length()-3] = 
             2 * sqrt(powdistance(previous_input_representation,
                                  similar_example_representation,
-                                 2)) / sqrt(layers[n_layers-1]->size);
+                                 2)) / sqrt((real)layers[n_layers-1]->size);
         
         // Dissimilar example contribution
         real dist = sqrt(powdistance(previous_input_representation,
@@ -1066,8 +1086,8 @@
                                      2));
 
         train_costs[train_costs.length()-2] = 
-            2 * sqrt(layers[n_layers-1]->size) * safeexp( -dissimilar_example_cost_precision
-                                                          *dist/sqrt(layers[n_layers-1]->size));
+            2 * sqrt((real)layers[n_layers-1]->size) * safeexp( -dissimilar_example_cost_precision
+                                                          *dist/sqrt((real)layers[n_layers-1]->size));
         train_costs.last() = train_costs[train_costs.length()-3] + 
             train_costs[train_costs.length()-2];
         //if( dist == 0 )
@@ -1083,7 +1103,7 @@
                   dissimilar_gradient_contribution);
         
         dissimilar_gradient_contribution *= -2 * dissimilar_example_cost_precision*
-            safeexp(-dissimilar_example_cost_precision*dist/sqrt(layers[n_layers-1]->size));
+            safeexp(-dissimilar_example_cost_precision*dist/sqrt((real)layers[n_layers-1]->size));
         
         expectation_gradients[n_layers-1] += dissimilar_gradient_contribution;
         //}



From nouiz at mail.berlios.de  Mon Nov 19 22:45:29 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 19 Nov 2007 22:45:29 +0100
Subject: [Plearn-commits] r8267 - trunk/plearn_learners/regressors
Message-ID: <200711192145.lAJLjTN3014094@sheep.berlios.de>

Author: nouiz
Date: 2007-11-19 22:45:28 +0100 (Mon, 19 Nov 2007)
New Revision: 8267

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeLeave.h
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h
Log:
reuse existing vec. This save copy and memory


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-19 21:08:28 UTC (rev 8266)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-19 21:45:28 UTC (rev 8267)
@@ -74,10 +74,6 @@
       
     declareOption(ol, "length", &RegressionTreeLeave::length, OptionBase::learntoption,
                   "The number of rows in this leave\n");
-    declareOption(ol, "output", &RegressionTreeLeave::output, OptionBase::learntoption,
-                  "The regression output for this leave\n");
-    declareOption(ol, "error", &RegressionTreeLeave::error, OptionBase::learntoption,
-                  "The error on this leave\n");
     declareOption(ol, "weights_sum", &RegressionTreeLeave::weights_sum, OptionBase::learntoption,
                   "The sum of weights for the samples in this leave\n");
     declareOption(ol, "targets_sum", &RegressionTreeLeave::targets_sum, OptionBase::learntoption,
@@ -95,8 +91,6 @@
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
     deepCopyField(train_set, copies);
-    deepCopyField(output, copies);
-    deepCopyField(error, copies);
 }
 
 void RegressionTreeLeave::build()
@@ -117,13 +111,6 @@
 void RegressionTreeLeave::initStats()
 {
     length = 0;
-    output.resize(2);
-    output[0] = 0.0;
-    output[1] = 0.0;
-    error.resize(3);
-    error[0]  = 0.0;
-    error[1]  = 0.0;
-    error[2] = 0.0;
     weights_sum= 0.0;
     targets_sum = 0.0;
     weighted_targets_sum = 0.0;
@@ -142,7 +129,6 @@
     real squared_target = pow(target, 2);
     weighted_targets_sum += weight * target;
     weighted_squared_targets_sum += weight * squared_target;  
-    computeOutputAndError();
     getOutputAndError(outputv,errorv);
 }
 
@@ -156,11 +142,10 @@
     real squared_target = pow(target, 2);
     weighted_targets_sum -= weight * target;
     weighted_squared_targets_sum -= weight * squared_target; 
-    computeOutputAndError();
     getOutputAndError(outputv,errorv);
 }
 
-void RegressionTreeLeave::computeOutputAndError()
+void RegressionTreeLeave::getOutputAndError(Vec output, Vec error)
 {
     output[0] = weighted_targets_sum / weights_sum;
     if (missing_leave == true)
@@ -196,18 +181,12 @@
     return length;
 }
 
-void RegressionTreeLeave::getOutputAndError(Vec outputv, Vec errorv)
-{
-    outputv[0] = output[0];
-    outputv[1] = output[1];
-    errorv[0] = error[0];
-    errorv[1] = error[1];  
-    errorv[2] = error[2]; 
-}
-
 void RegressionTreeLeave::printStats()
 {
     cout << " l " << length;
+    Vec output(2);
+    Vec error(3);
+    getOutputAndError(output,error);
     cout << " o0 " << output[0];
     cout << " o1 " << output[1];
     cout << " e0 " << error[0];

Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-19 21:08:28 UTC (rev 8266)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-19 21:45:28 UTC (rev 8267)
@@ -69,8 +69,6 @@
 */
 
     int  length;
-    Vec  output;
-    Vec  error;
     real weights_sum;
     real targets_sum;
     real weighted_targets_sum;
@@ -90,11 +88,10 @@
     virtual void         initStats();
     virtual void         addRow(int row, Vec outputv, Vec errorv);
     virtual void         removeRow(int row, Vec outputv, Vec errorv);
-    virtual void         computeOutputAndError();
     void         registerRow(int row);
     int          getId();
     int          getLength();
-    void         getOutputAndError(Vec outputv, Vec errorv);
+    virtual void         getOutputAndError(Vec output, Vec error);
     virtual void         printStats();
   
 private:

Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2007-11-19 21:08:28 UTC (rev 8266)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2007-11-19 21:45:28 UTC (rev 8267)
@@ -101,13 +101,6 @@
 void RegressionTreeMulticlassLeave::initStats()
 {
     length = 0;
-    output.resize(2);
-    output[0] = 0.0;
-    output[1] = 0.0;
-    error.resize(3);
-    error[0]  = 0.0;
-    error[1]  = 0.0;
-    error[2] = 0.0;
     weights_sum = 0.0;
     if (loss_function_weight != 0.0)
     {
@@ -141,7 +134,6 @@
     }
     if (multiclass_found < 1) 
         PLERROR("RegressionTreeMultilassLeave: Unknown target: %d row: %d\n", target,row);
-    computeOutputAndError();
     getOutputAndError(outputv,errorv);
 }
 
@@ -159,15 +151,14 @@
             break;      
         }
     }
-    computeOutputAndError();
     getOutputAndError(outputv,errorv);
 }
 
-void RegressionTreeMulticlassLeave::computeOutputAndError()
+void RegressionTreeMulticlassLeave::getOutputAndError(Vec output, Vec error)
 {
 #ifdef BOUNDCHECK
     if(multiclass_outputs.length()<=0)
-        PLERROR("In RegressionTreeMulticlassLeave::computeOutputAndError() - multiclass_outputs must not be empty");
+        PLERROR("In RegressionTreeMulticlassLeave::getOutputAndError() - multiclass_outputs must not be empty");
 #endif
     multiclass_winer = 0;
     for (int multiclass_ind = 1; multiclass_ind < multiclass_outputs.length(); multiclass_ind++)
@@ -213,6 +204,9 @@
 void RegressionTreeMulticlassLeave::printStats()
 {
     cout << " l " << length;
+    Vec output(2);
+    Vec error(3);
+    getOutputAndError(output,error);
     cout << " o0 " << output[0];
     cout << " o1 " << output[1];
     cout << " e0 " << error[0];

Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h	2007-11-19 21:08:28 UTC (rev 8266)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h	2007-11-19 21:45:28 UTC (rev 8267)
@@ -85,7 +85,7 @@
     void         initStats();
     void         addRow(int row, Vec outputv, Vec errorv);
     void         removeRow(int row, Vec outputv, Vec errorv);
-    void         computeOutputAndError();
+    virtual void getOutputAndError(Vec output, Vec error);
     void         printStats();
   
 private:



From nouiz at mail.berlios.de  Mon Nov 19 22:49:22 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 19 Nov 2007 22:49:22 +0100
Subject: [Plearn-commits] r8268 - trunk/plearn_learners/regressors
Message-ID: <200711192149.lAJLnMlh014304@sheep.berlios.de>

Author: nouiz
Date: 2007-11-19 22:49:22 +0100 (Mon, 19 Nov 2007)
New Revision: 8268

Modified:
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
Log:
Added assert


Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-19 21:45:28 UTC (rev 8267)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-19 21:49:22 UTC (rev 8268)
@@ -221,6 +221,7 @@
         right_leave->initStats();
         registered_row.resize(0);
         train_set->getAllRegisteredRow(leave_id,col,registered_row);
+        PLASSERT(registered_row.size()>0);
         for(int row_idx = 0;row_idx<registered_row.size();row_idx++)
         {
             int row=registered_row[row_idx];
@@ -293,6 +294,9 @@
             }
         }
     }
+    PLASSERT(missing_leave->length>0);
+    PLASSERT(left_leave->length>0);
+    PLASSERT(right_leave->length>0);
 //  leave->printStats();
 //  left_leave->printStats();
 //  right_leave->printStats();



From larocheh at mail.berlios.de  Mon Nov 19 22:58:37 2007
From: larocheh at mail.berlios.de (larocheh at BerliOS)
Date: Mon, 19 Nov 2007 22:58:37 +0100
Subject: [Plearn-commits] r8269 - trunk/plearn_learners_experimental
Message-ID: <200711192158.lAJLwbjD015126@sheep.berlios.de>

Author: larocheh
Date: 2007-11-19 22:58:36 +0100 (Mon, 19 Nov 2007)
New Revision: 8269

Modified:
   trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc
Log:
Corrected some bugs


Modified: trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc
===================================================================
--- trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc	2007-11-19 21:49:22 UTC (rev 8268)
+++ trunk/plearn_learners_experimental/StackedFocusedAutoassociatorsNet.cc	2007-11-19 21:58:36 UTC (rev 8269)
@@ -688,9 +688,9 @@
             similar_example_representation.resize(layers[i+1]->size);
             dissimilar_example_representation.resize(layers[i+1]->size);
             dissimilar_gradient_contribution.resize(layers[i+1]->size);
-            input_representation.resize(layers[i+1]->size);
         }
         
+        input_representation.resize(layers[i+1]->size);
         greedy_activation.resize(greedy_layers[i]->size);
         greedy_expectation.resize(greedy_layers[i]->size);
         greedy_activation_gradient.resize(greedy_layers[i]->size);
@@ -1288,6 +1288,8 @@
     
     train_set_representations_up_to_date = false;
 
+    if( do_not_use_knn_classifier && fast_exact_is_equal( supervised_greedy_learning_rate, 0 ) )
+        return;
     Vec input( inputsize() );
     Vec target( targetsize() );
     real weight; // unused



From nouiz at mail.berlios.de  Tue Nov 20 15:56:01 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 20 Nov 2007 15:56:01 +0100
Subject: [Plearn-commits] r8270 - trunk/plearn_learners/regressors
Message-ID: <200711201456.lAKEu1n9005551@sheep.berlios.de>

Author: nouiz
Date: 2007-11-20 15:56:01 +0100 (Tue, 20 Nov 2007)
New Revision: 8270

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeLeave.h
Log:
re-added old option as deprecated. That way we can reload old serialized version


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-19 21:58:36 UTC (rev 8269)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-20 14:56:01 UTC (rev 8270)
@@ -71,7 +71,6 @@
                   "The desired level of verbosity\n");
     declareOption(ol, "train_set", &RegressionTreeLeave::train_set, OptionBase::buildoption,
                   "The train set with the sorted row index matrix and the leave id vector\n");
-      
     declareOption(ol, "length", &RegressionTreeLeave::length, OptionBase::learntoption,
                   "The number of rows in this leave\n");
     declareOption(ol, "weights_sum", &RegressionTreeLeave::weights_sum, OptionBase::learntoption,
@@ -84,6 +83,12 @@
                   "The sum of squared weighted target values for the samples in this leave\n");
     declareOption(ol, "loss_function_factor", &RegressionTreeLeave::loss_function_factor, OptionBase::learntoption,
                   "2 / pow(loss_function_weight, 2.0).\n");
+
+    declareOption(ol, "output", &RegressionTreeLeave::dummy_vec, OptionBase::buildoption,
+                  "DEPRECATED");
+    declareOption(ol, "error", &RegressionTreeLeave::dummy_vec, OptionBase::buildoption,
+                  "DEPRECATED");
+
     inherited::declareOptions(ol);
 }
 

Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-19 21:58:36 UTC (rev 8269)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-20 14:56:01 UTC (rev 8270)
@@ -47,11 +47,15 @@
 namespace PLearn {
 using namespace std;
 
+
 class RegressionTreeLeave: public Object
 {
     typedef Object inherited;
  
     friend class RegressionTreeNode;
+
+    Vec dummy_vec;
+
 protected:
 
 /*
@@ -75,7 +79,6 @@
     real weighted_squared_targets_sum;
     real loss_function_factor;
  
-
 public:
     RegressionTreeLeave();
     virtual              ~RegressionTreeLeave();



From nouiz at mail.berlios.de  Tue Nov 20 17:52:44 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 20 Nov 2007 17:52:44 +0100
Subject: [Plearn-commits] r8271 - trunk/plearn_learners/regressors
Message-ID: <200711201652.lAKGqiwR015824@sheep.berlios.de>

Author: nouiz
Date: 2007-11-20 17:52:44 +0100 (Tue, 20 Nov 2007)
New Revision: 8271

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeLeave.h
Log:
pass argument by reference explicitly


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-20 14:56:01 UTC (rev 8270)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-20 16:52:44 UTC (rev 8271)
@@ -150,7 +150,7 @@
     getOutputAndError(outputv,errorv);
 }
 
-void RegressionTreeLeave::getOutputAndError(Vec output, Vec error)
+void RegressionTreeLeave::getOutputAndError(Vec& output, Vec& error)
 {
     output[0] = weighted_targets_sum / weights_sum;
     if (missing_leave == true)

Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-20 14:56:01 UTC (rev 8270)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-20 16:52:44 UTC (rev 8271)
@@ -94,7 +94,7 @@
     void         registerRow(int row);
     int          getId();
     int          getLength();
-    virtual void         getOutputAndError(Vec output, Vec error);
+    virtual void         getOutputAndError(Vec& output, Vec& error);
     virtual void         printStats();
   
 private:



From nouiz at mail.berlios.de  Tue Nov 20 18:35:25 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 20 Nov 2007 18:35:25 +0100
Subject: [Plearn-commits] r8272 - trunk/plearn_learners/regressors
Message-ID: <200711201735.lAKHZPQb000300@sheep.berlios.de>

Author: nouiz
Date: 2007-11-20 18:35:23 +0100 (Tue, 20 Nov 2007)
New Revision: 8272

Modified:
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
Log:
corrected assert and a possible small optimisation


Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-20 16:52:44 UTC (rev 8271)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-20 17:35:23 UTC (rev 8272)
@@ -212,7 +212,8 @@
 
 void RegressionTreeNode::lookForBestSplit()
 {
-    TVec<int> candidate;//list of candidate row to split
+    TVec<int> candidate(train_set->length());//list of candidate row to split
+    candidate.resize(0);
     TVec<int> registered_row;
     for (int col = 0; col < inputsize; col++)
     {
@@ -294,9 +295,10 @@
             }
         }
     }
-    PLASSERT(missing_leave->length>0);
     PLASSERT(left_leave->length>0);
     PLASSERT(right_leave->length>0);
+    PLASSERT(left_leave->length + right_leave->length + missing_leave->length
+             == registered_row.size());
 //  leave->printStats();
 //  left_leave->printStats();
 //  right_leave->printStats();



From nouiz at mail.berlios.de  Tue Nov 20 19:43:24 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 20 Nov 2007 19:43:24 +0100
Subject: [Plearn-commits] r8273 - trunk/plearn_learners/regressors
Message-ID: <200711201843.lAKIhOF3007475@sheep.berlios.de>

Author: nouiz
Date: 2007-11-20 19:43:24 +0100 (Tue, 20 Nov 2007)
New Revision: 8273

Modified:
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/RegressionTreeNode.h
Log:
locallysed some fields. Deep them in the declaceOption linked to a dummy value and with nosave option to be able to reload serialized object.


Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-20 17:35:23 UTC (rev 8272)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-20 18:43:24 UTC (rev 8273)
@@ -96,8 +96,6 @@
                   "The error after split\n");
     declareOption(ol, "missing_node", &RegressionTreeNode::missing_node, OptionBase::learntoption,
                   "The node for the missing values when missing_is_valid is set to 1\n");
-    declareOption(ol, "missing_leave_id", &RegressionTreeNode::missing_leave_id, OptionBase::learntoption,
-                  "The id of the missing leave\n");
     declareOption(ol, "missing_leave", &RegressionTreeNode::missing_leave, OptionBase::learntoption,
                   "The leave containing rows with missing values after split\n");
     declareOption(ol, "missing_output", &RegressionTreeNode::missing_output, OptionBase::learntoption,
@@ -106,8 +104,6 @@
                   "The missing leave error vector\n");
     declareOption(ol, "left_node", &RegressionTreeNode::left_node, OptionBase::learntoption,
                   "The node on the left of the split decision\n");
-    declareOption(ol, "left_leave_id", &RegressionTreeNode::left_leave_id, OptionBase::learntoption,
-                  "The id of the left leave\n");
     declareOption(ol, "left_leave", &RegressionTreeNode::left_leave, OptionBase::learntoption,
                   "The leave with the rows lower than the split feature value after split\n");
     declareOption(ol, "left_output", &RegressionTreeNode::left_output, OptionBase::learntoption,
@@ -116,14 +112,23 @@
                   "The left leave error vector\n");
     declareOption(ol, "right_node", &RegressionTreeNode::right_node, OptionBase::learntoption,
                   "The node on the right of the split decision\n"); 
-    declareOption(ol, "right_leave_id", &RegressionTreeNode::right_leave_id, OptionBase::learntoption,
-                  "The id of the right leave\n");     
     declareOption(ol, "right_leave", &RegressionTreeNode::right_leave, OptionBase::learntoption,
                   "The leave with the rows greater thean the split feature value after split\n");
     declareOption(ol, "right_output", &RegressionTreeNode::right_output, OptionBase::learntoption,
                   "The right leave output vector\n");
     declareOption(ol, "right_error", &RegressionTreeNode::right_error, OptionBase::learntoption,
                   "The right leave error vector\n");
+
+    declareOption(ol, "right_leave_id", &RegressionTreeNode::dummy_int,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The id of the right leave\n");     
+    declareOption(ol, "left_leave_id", &RegressionTreeNode::dummy_int,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The id of the left leave\n");
+    declareOption(ol, "missing_leave_id", &RegressionTreeNode::dummy_int,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The id of the missing leave\n");
+
     inherited::declareOptions(ol);
 }
 
@@ -146,17 +151,14 @@
     deepCopyField(split_feature_value, copies);
     deepCopyField(after_split_error, copies);
     deepCopyField(missing_node, copies);
-    deepCopyField(missing_leave_id, copies);
     deepCopyField(missing_leave, copies);
     deepCopyField(missing_output, copies);
     deepCopyField(missing_error, copies);
     deepCopyField(left_node, copies);
-    deepCopyField(left_leave_id, copies);
     deepCopyField(left_leave, copies);
     deepCopyField(left_output, copies);
     deepCopyField(left_error, copies);
     deepCopyField(right_node, copies);
-    deepCopyField(right_leave_id, copies);  
     deepCopyField(right_leave, copies);
     deepCopyField(right_output, copies);
     deepCopyField(right_error, copies);
@@ -179,9 +181,9 @@
     leave_template = the_leave_template;
     split_col = -1;
     leave_id = leave->getId();
-    missing_leave_id = train_set->getNextId();
-    left_leave_id =  train_set->getNextId();
-    right_leave_id =  train_set->getNextId();
+    int missing_leave_id = train_set->getNextId();
+    int left_leave_id =  train_set->getNextId();
+    int right_leave_id =  train_set->getNextId();
     length = train_set->length();
     inputsize = train_set->inputsize();
 

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-20 17:35:23 UTC (rev 8272)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-20 18:43:24 UTC (rev 8273)
@@ -79,21 +79,19 @@
     real split_feature_value;
     real after_split_error;
     PP<RegressionTreeNode> missing_node;
-    int missing_leave_id;
     PP<RegressionTreeLeave> missing_leave;
     Vec missing_output;
     Vec missing_error;
     PP<RegressionTreeNode> left_node;
-    int left_leave_id;
     PP<RegressionTreeLeave> left_leave;
     Vec left_output;
     Vec left_error;
     PP<RegressionTreeNode> right_node;
-    int right_leave_id;
     PP<RegressionTreeLeave> right_leave;
     Vec right_output;
     Vec right_error;
     
+    int dummy_int;
 public:  
     RegressionTreeNode();
     virtual              ~RegressionTreeNode();



From nouiz at mail.berlios.de  Tue Nov 20 21:54:41 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 20 Nov 2007 21:54:41 +0100
Subject: [Plearn-commits] r8274 - trunk/plearn_learners/regressors
Message-ID: <200711202054.lAKKsfxn018929@sheep.berlios.de>

Author: nouiz
Date: 2007-11-20 21:54:39 +0100 (Tue, 20 Nov 2007)
New Revision: 8274

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeLeave.h
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/RegressionTreeNode.h
Log:
removed many unnecessary variable and added a version of addRow function that do less work.


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-20 18:43:24 UTC (rev 8273)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-20 20:54:39 UTC (rev 8274)
@@ -124,7 +124,7 @@
     else loss_function_factor = 1.0;
 }
 
-void RegressionTreeLeave::addRow(int row, Vec outputv, Vec errorv)
+void RegressionTreeLeave::addRow(int row)
 {
     real weight = train_set->getWeight(row);
     real target = train_set->getTarget(row);
@@ -134,6 +134,11 @@
     real squared_target = pow(target, 2);
     weighted_targets_sum += weight * target;
     weighted_squared_targets_sum += weight * squared_target;  
+}
+
+void RegressionTreeLeave::addRow(int row, Vec outputv, Vec errorv)
+{
+    addRow(row);
     getOutputAndError(outputv,errorv);
 }
 

Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-20 18:43:24 UTC (rev 8273)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.h	2007-11-20 20:54:39 UTC (rev 8274)
@@ -90,6 +90,7 @@
     void         initLeave(PP<RegressionTreeRegisters> the_train_set);
     virtual void         initStats();
     virtual void         addRow(int row, Vec outputv, Vec errorv);
+    virtual void         addRow(int row);
     virtual void         removeRow(int row, Vec outputv, Vec errorv);
     void         registerRow(int row);
     int          getId();

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-20 18:43:24 UTC (rev 8273)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-20 20:54:39 UTC (rev 8274)
@@ -76,12 +76,6 @@
     declareOption(ol, "leave", &RegressionTreeNode::leave, OptionBase::buildoption,
                   "The leave of all the  belonging rows when this node is a leave\n");
       
-    declareOption(ol, "length", &RegressionTreeNode::length, OptionBase::learntoption,
-                  "The length of the train set\n");
-    declareOption(ol, "inputsize", &RegressionTreeNode::inputsize, OptionBase::learntoption,
-                  "The inputsize of the train set\n");
-    declareOption(ol, "leave_id", &RegressionTreeNode::leave_id, OptionBase::learntoption,
-                  "The id of the leave\n");
     declareOption(ol, "leave_output", &RegressionTreeNode::leave_output, OptionBase::learntoption,
                   "The leave output vector\n");
     declareOption(ol, "leave_error", &RegressionTreeNode::leave_error, OptionBase::learntoption,
@@ -106,19 +100,23 @@
                   "The node on the left of the split decision\n");
     declareOption(ol, "left_leave", &RegressionTreeNode::left_leave, OptionBase::learntoption,
                   "The leave with the rows lower than the split feature value after split\n");
-    declareOption(ol, "left_output", &RegressionTreeNode::left_output, OptionBase::learntoption,
-                  "The left leave output vector\n");
-    declareOption(ol, "left_error", &RegressionTreeNode::left_error, OptionBase::learntoption,
-                  "The left leave error vector\n");
     declareOption(ol, "right_node", &RegressionTreeNode::right_node, OptionBase::learntoption,
                   "The node on the right of the split decision\n"); 
     declareOption(ol, "right_leave", &RegressionTreeNode::right_leave, OptionBase::learntoption,
                   "The leave with the rows greater thean the split feature value after split\n");
-    declareOption(ol, "right_output", &RegressionTreeNode::right_output, OptionBase::learntoption,
-                  "The right leave output vector\n");
-    declareOption(ol, "right_error", &RegressionTreeNode::right_error, OptionBase::learntoption,
-                  "The right leave error vector\n");
 
+    declareOption(ol, "left_error", &RegressionTreeNode::tmp_vec,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The left leave error vector\n");
+    declareOption(ol, "right_error", &RegressionTreeNode::tmp_vec,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The right leave error vector\n");
+    declareOption(ol, "left_output", &RegressionTreeNode::tmp_vec,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The left leave output vector\n");
+    declareOption(ol, "right_output", &RegressionTreeNode::tmp_vec,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The right leave output vector\n");
     declareOption(ol, "right_leave_id", &RegressionTreeNode::dummy_int,
                   OptionBase::learntoption | OptionBase::nosave,
                   "DEPRECATED The id of the right leave\n");     
@@ -128,6 +126,15 @@
     declareOption(ol, "missing_leave_id", &RegressionTreeNode::dummy_int,
                   OptionBase::learntoption | OptionBase::nosave,
                   "DEPRECATED The id of the missing leave\n");
+    declareOption(ol, "leave_id", &RegressionTreeNode::dummy_int,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The id of the leave\n");
+    declareOption(ol, "length", &RegressionTreeNode::dummy_int,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The length of the train set\n");
+    declareOption(ol, "inputsize", &RegressionTreeNode::dummy_int,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The inputsize of the train set\n");
 
     inherited::declareOptions(ol);
 }
@@ -141,9 +148,6 @@
     deepCopyField(leave_template, copies);
     deepCopyField(train_set, copies);
     deepCopyField(leave, copies);
-    deepCopyField(length, copies);
-    deepCopyField(inputsize, copies);
-    deepCopyField(leave_id, copies);
     deepCopyField(leave_output, copies);
     deepCopyField(leave_error, copies);
     deepCopyField(split_col, copies);
@@ -156,12 +160,8 @@
     deepCopyField(missing_error, copies);
     deepCopyField(left_node, copies);
     deepCopyField(left_leave, copies);
-    deepCopyField(left_output, copies);
-    deepCopyField(left_error, copies);
     deepCopyField(right_node, copies);
     deepCopyField(right_leave, copies);
-    deepCopyField(right_output, copies);
-    deepCopyField(right_error, copies);
 }
 
 void RegressionTreeNode::build()
@@ -180,12 +180,9 @@
     leave = the_leave;
     leave_template = the_leave_template;
     split_col = -1;
-    leave_id = leave->getId();
     int missing_leave_id = train_set->getNextId();
     int left_leave_id =  train_set->getNextId();
     int right_leave_id =  train_set->getNextId();
-    length = train_set->length();
-    inputsize = train_set->inputsize();
 
     missing_leave = ::PLearn::deepCopy(leave_template);
     missing_leave->id=missing_leave_id;
@@ -204,10 +201,6 @@
     leave_error.resize(3);
     missing_output.resize(2);
     missing_error.resize(3);
-    left_output.resize(2);
-    left_error.resize(3);
-    right_output.resize(2);
-    right_error.resize(3);
 
     leave->getOutputAndError(leave_output,leave_error);
 }
@@ -217,7 +210,11 @@
     TVec<int> candidate(train_set->length());//list of candidate row to split
     candidate.resize(0);
     TVec<int> registered_row;
-    for (int col = 0; col < inputsize; col++)
+    tmp_vec.resize(2);
+    Vec left_error(3);
+    Vec right_error(3);
+    int leave_id = leave->id;
+    for (int col = 0; col < train_set->inputsize(); col++)
     {
         missing_leave->initStats();
         left_leave->initStats();
@@ -229,25 +226,28 @@
         {
             int row=registered_row[row_idx];
             if (is_missing(train_set->get(row, col)))
-                missing_leave->addRow(row, missing_output, missing_error);
+                missing_leave->addRow(row);
             else {
-                left_leave->addRow(row, right_output, right_error);
+                left_leave->addRow(row);
                 candidate.append(row);
             }
         }
+        if(candidate.size()==0)
+            return;
         int row = candidate.pop();
         while (candidate.size()>0)
         {
             int next_row = candidate.pop();
-            left_leave->removeRow(row, left_output, left_error);
-            right_leave->addRow(row, right_output, right_error);
-            compareSplit(col, train_set->get(next_row, col), train_set->get(row, col));
+            left_leave->removeRow(row, tmp_vec, left_error);
+            right_leave->addRow(row, tmp_vec, right_error);
+            compareSplit(col, train_set->get(next_row, col), train_set->get(row, col), left_error, right_error);
             row = next_row;
         }
     }
 }
 
-void RegressionTreeNode::compareSplit(int col, real left_leave_last_feature, real right_leave_first_feature)
+void RegressionTreeNode::compareSplit(int col, real left_leave_last_feature, real right_leave_first_feature,
+                                      Vec left_error, Vec right_error )
 {
     PLASSERT(left_leave_last_feature<=right_leave_first_feature);
     if (left_leave_last_feature >= right_leave_first_feature) return;
@@ -273,30 +273,33 @@
     left_leave->initStats();
     right_leave->initStats();
     TVec<int>registered_row;
-    train_set->getAllRegisteredRow(leave_id,split_col,registered_row);
+    train_set->getAllRegisteredRow(leave->id,split_col,registered_row);
 
     for (int row_index = 0;row_index<registered_row.size();row_index++)
     {
         int row=registered_row[row_index];
         if (is_missing(train_set->get(row, split_col)))
         {
-            missing_leave->addRow(row, missing_output, missing_error);
+            missing_leave->addRow(row);
             missing_leave->registerRow(row);
         }
         else
         {
             if (train_set->get(row, split_col) < split_feature_value)
             {
-                left_leave->addRow(row, left_output, left_error);
+                left_leave->addRow(row);
                 left_leave->registerRow(row);
             }
             else
             {
-                right_leave->addRow(row, right_output, right_error);
+                right_leave->addRow(row);
                 right_leave->registerRow(row);
             }
         }
     }
+
+    missing_leave->getOutputAndError(missing_output, missing_error);
+
     PLASSERT(left_leave->length>0);
     PLASSERT(right_leave->length>0);
     PLASSERT(left_leave->length + right_leave->length + missing_leave->length
@@ -330,7 +333,7 @@
 
 int RegressionTreeNode::getSplitBalance()
 {
-    if (split_col < 0) return length;
+    if (split_col < 0) return train_set->length();
     return split_balance;
 }
 

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-20 18:43:24 UTC (rev 8273)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-20 20:54:39 UTC (rev 8274)
@@ -69,29 +69,23 @@
   Learnt options: they are sized and initialized if need be, in initNode(...)
 */
  
-    int length;
-    int inputsize;
-    int leave_id;
     Vec leave_output;
     Vec leave_error;
+    Vec missing_output;
+    Vec missing_error;
     int split_col;
     int split_balance;
     real split_feature_value;
     real after_split_error;
     PP<RegressionTreeNode> missing_node;
     PP<RegressionTreeLeave> missing_leave;
-    Vec missing_output;
-    Vec missing_error;
     PP<RegressionTreeNode> left_node;
     PP<RegressionTreeLeave> left_leave;
-    Vec left_output;
-    Vec left_error;
     PP<RegressionTreeNode> right_node;
     PP<RegressionTreeLeave> right_leave;
-    Vec right_output;
-    Vec right_error;
     
     int dummy_int;
+    Vec tmp_vec;
 public:  
     RegressionTreeNode();
     virtual              ~RegressionTreeNode();
@@ -103,7 +97,8 @@
     virtual void         build();
     void         initNode(PP<RegressionTreeRegisters> train_set, PP<RegressionTreeLeave> leave, PP<RegressionTreeLeave> leave_template);
     void         lookForBestSplit();
-    void         compareSplit(int col, real left_leave_last_feature, real right_leave_first_feature);
+    void         compareSplit(int col, real left_leave_last_feature, real right_leave_first_feature,
+                              Vec left_error, Vec right_error);
     int          expandNode();
     int          getSplitBalance();
     real         getErrorImprovment();



From nouiz at mail.berlios.de  Tue Nov 20 21:56:05 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 20 Nov 2007 21:56:05 +0100
Subject: [Plearn-commits] r8275 - trunk/plearn_learners/regressors
Message-ID: <200711202056.lAKKu5Wx018984@sheep.berlios.de>

Author: nouiz
Date: 2007-11-20 21:56:04 +0100 (Tue, 20 Nov 2007)
New Revision: 8275

Modified:
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h
Log:
forgot those file in the last commit


Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2007-11-20 20:54:39 UTC (rev 8274)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2007-11-20 20:56:04 UTC (rev 8275)
@@ -116,7 +116,7 @@
     multiclass_weights_sum.fill(0);
 }
 
-void RegressionTreeMulticlassLeave::addRow(int row, Vec outputv, Vec errorv)
+void RegressionTreeMulticlassLeave::addRow(int row)
 {
     real weight = train_set->getWeight(row);
     real target = train_set->getTarget(row);
@@ -134,9 +134,14 @@
     }
     if (multiclass_found < 1) 
         PLERROR("RegressionTreeMultilassLeave: Unknown target: %d row: %d\n", target,row);
-    getOutputAndError(outputv,errorv);
 }
 
+void RegressionTreeMulticlassLeave::addRow(int row, Vec outputv, Vec errorv)
+{
+    addRow(row);
+    getOutputAndError(outputv,errorv);    
+}
+
 void RegressionTreeMulticlassLeave::removeRow(int row, Vec outputv, Vec errorv)
 {
     real weight = train_set->getWeight(row);

Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h	2007-11-20 20:54:39 UTC (rev 8274)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.h	2007-11-20 20:56:04 UTC (rev 8275)
@@ -84,6 +84,7 @@
     virtual void         build();
     void         initStats();
     void         addRow(int row, Vec outputv, Vec errorv);
+    void         addRow(int row);
     void         removeRow(int row, Vec outputv, Vec errorv);
     virtual void getOutputAndError(Vec output, Vec error);
     void         printStats();



From nouiz at mail.berlios.de  Tue Nov 20 22:24:23 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 20 Nov 2007 22:24:23 +0100
Subject: [Plearn-commits] r8276 - trunk/plearn_learners/meta
Message-ID: <200711202124.lAKLONML020543@sheep.berlios.de>

Author: nouiz
Date: 2007-11-20 22:24:23 +0100 (Tue, 20 Nov 2007)
New Revision: 8276

Modified:
   trunk/plearn_learners/meta/AdaBoost.cc
Log:
bugfix


Modified: trunk/plearn_learners/meta/AdaBoost.cc
===================================================================
--- trunk/plearn_learners/meta/AdaBoost.cc	2007-11-20 20:56:04 UTC (rev 8275)
+++ trunk/plearn_learners/meta/AdaBoost.cc	2007-11-20 21:24:23 UTC (rev 8276)
@@ -765,9 +765,12 @@
     costs[2] = costs[0];
     costs[3] = train_stats->getStat("E[avg_weight_class_0]");
     costs[4] = train_stats->getStat("E[avg_weight_class_1]");
-    Vec tmp(weak_learner_template->nTestCosts());
     if(forward_sub_learner_test_costs){
-        weak_learners.last()->computeCostsFromOutputs(input,output,target,tmp);
+        //TODO: is this the good beavior to have?
+        //We can't reuse the output from parameter as it is not the same
+        //as the one from the sub learner
+        Vec tmp(weak_learner_template->nTestCosts());
+        weak_learners.last()->computeCostsOnly(input,target,tmp);
         costs.append(tmp);
     }
 }



From nouiz at mail.berlios.de  Wed Nov 21 17:52:20 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 21 Nov 2007 17:52:20 +0100
Subject: [Plearn-commits] r8277 - trunk/plearn_learners/meta
Message-ID: <200711211652.lALGqKhX019301@sheep.berlios.de>

Author: nouiz
Date: 2007-11-21 17:52:19 +0100 (Wed, 21 Nov 2007)
New Revision: 8277

Added:
   trunk/plearn_learners/meta/MultiClassAdaBoost.cc
   trunk/plearn_learners/meta/MultiClassAdaBoost.h
Log:
Added a MultiClassAdaBoost learner that only implement the testing for 3 classes


Added: trunk/plearn_learners/meta/MultiClassAdaBoost.cc
===================================================================
--- trunk/plearn_learners/meta/MultiClassAdaBoost.cc	2007-11-20 21:24:23 UTC (rev 8276)
+++ trunk/plearn_learners/meta/MultiClassAdaBoost.cc	2007-11-21 16:52:19 UTC (rev 8277)
@@ -0,0 +1,296 @@
+// -*- C++ -*-
+
+// plearn_learners/meta/MultiClassAdaBoost.cc
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file MultiClassAdaBoost.cc */
+
+
+#include "MultiClassAdaBoost.h"
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    MultiClassAdaBoost,
+    "ONE LINE DESCRIPTION",
+    "MULTI-LINE \nHELP");
+
+MultiClassAdaBoost::MultiClassAdaBoost():
+    nb_stage_to_use(-1)
+/* ### Initialize all fields to their default value here */
+{
+    // ...
+
+    // ### You may (or not) want to call build_() to finish building the object
+    // ### (doing so assumes the parent classes' build_() have been called too
+    // ### in the parent classes' constructors, something that you must ensure)
+
+    // ### If this learner needs to generate random numbers, uncomment the
+    // ### line below to enable the use of the inherited PRandom object.
+    // random_gen = new PRandom();
+}
+
+void MultiClassAdaBoost::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    // ### ex:
+    // declareOption(ol, "myoption", &MultiClassAdaBoost::myoption,
+    //               OptionBase::buildoption,
+    //               "Help text describing this option");
+    // ...
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+    declareOption(ol, "nb_stage_to_use",
+                  &MultiClassAdaBoost::nb_stage_to_use,
+                  OptionBase::buildoption,
+                  "The number of stage to use when testing."
+                  " Can be lower then the number of trained stage,"
+                  " but can't be higher!");
+    declareOption(ol, "learner1", &MultiClassAdaBoost::learner1,
+                  OptionBase::buildoption,
+                  "The sub learner to use.");
+    declareOption(ol, "learner2", &MultiClassAdaBoost::learner2,
+                  OptionBase::buildoption,
+                  "The sub learner to use.");
+
+}
+
+void MultiClassAdaBoost::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+}
+
+// ### Nothing to add here, simply calls build_
+void MultiClassAdaBoost::build()
+{
+    inherited::build();
+    build_();
+}
+
+
+void MultiClassAdaBoost::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all "pointer-like" fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+
+    // ### Remove this line when you have fully implemented this method.
+    PLERROR("MultiClassAdaBoost::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!");
+}
+
+
+int MultiClassAdaBoost::outputsize() const
+{
+    // Compute and return the size of this learner's output (which typically
+    // may depend on its inputsize(), targetsize() and set options).
+
+    return 3;
+}
+
+void MultiClassAdaBoost::forget()
+{
+    //! (Re-)initialize the PLearner in its fresh state (that state may depend
+    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
+    //! a fresh learner!)
+    /*!
+      A typical forget() method should do the following:
+      - call inherited::forget() to initialize its random number generator
+        with the 'seed' option
+      - initialize the learner's parameters, using this random generator
+      - stage = 0
+    */
+    inherited::forget();
+
+    stage = 0;
+    
+    PLWARNING("In MultiClassAdaBoost::forget() - not implemented, training not implemented");
+}
+
+void MultiClassAdaBoost::train()
+{
+    // The role of the train method is to bring the learner up to
+    // stage==nstages, updating train_stats with training costs measured
+    // on-line in the process.
+
+    /* TYPICAL CODE:
+
+    static Vec input;  // static so we don't reallocate memory each time...
+    static Vec target; // (but be careful that static means shared!)
+    input.resize(inputsize());    // the train_set's inputsize()
+    target.resize(targetsize());  // the train_set's targetsize()
+    real weight;
+
+    // This generic PLearner method does a number of standard stuff useful for
+    // (almost) any learner, and return 'false' if no training should take
+    // place. See PLearner.h for more details.
+    if (!initTrain())
+        return;
+
+    while(stage<nstages)
+    {
+        // clear statistics of previous epoch
+        train_stats->forget();
+
+        //... train for 1 stage, and update train_stats,
+        // using train_set->getExample(input, target, weight)
+        // and train_stats->update(train_costs)
+
+        ++stage;
+        train_stats->finalize(); // finalize statistics for this epoch
+    }
+    */
+    PLWARNING("In MultiClassAdaBoost::train() - not implemented, should be already trained");
+}
+
+
+void MultiClassAdaBoost::computeOutput(const Vec& input, Vec& output) const
+{
+    output.resize(outputsize());
+
+    Vec tmp1(learner1.outputsize());
+    Vec tmp2(learner2.outputsize());
+    if(nb_stage_to_use!=-1){
+        learner1.computeOutput(input,tmp1,nb_stage_to_use);
+        learner2.computeOutput(input,tmp2,nb_stage_to_use);
+    }else{
+        learner1.computeOutput(input,tmp1);
+        learner2.computeOutput(input,tmp2);
+    }
+    int ind1=int(round(tmp1[0]));
+    int ind2=int(round(tmp2[0]));
+    int ind=-1;
+    if(ind1==0 && ind2==0)
+        ind=0;
+    else if(ind1==1 && ind2==0)
+        ind=1;
+    else if(ind1==1 && ind2==1)
+        ind=2;
+    else
+        ind=1;//TODOself.confusion_target;
+    output[0]=ind;
+    output[1]=tmp1[0];
+    output[2]=tmp2[0];
+}
+
+void MultiClassAdaBoost::computeCostsFromOutputs(const Vec& input, const Vec& output,
+                                           const Vec& target, Vec& costs) const
+{
+// Compute the costs from *already* computed output.
+// ...
+    int out = int(round(output[0]));
+    int pred = int(round(target[0]));
+    costs[0]=int(out != pred);//class_error
+    costs[1]=abs(out-pred);//linear_class_error
+    costs[2]=pow(real(abs(out-pred)),2);//square_class_error
+    
+    //append conflict cost
+    if(fast_is_equal(round(output[1]),0) 
+       && fast_is_equal(round(output[2]),1))
+        costs[3]=1;
+    else
+        costs[3]=0;
+
+    costs[4]=0;
+    costs[5]=0;
+    costs[6]=0;
+    costs[out+4]=1;
+
+}
+
+TVec<string> MultiClassAdaBoost::getTestCostNames() const
+{
+    // Return the names of the costs computed by computeCostsFromOutputs
+    // (these may or may not be exactly the same as what's returned by
+    // getTrainCostNames).
+    // ...
+    TVec<string> names;
+    names.append("class_error");
+    names.append("linear_class_error");
+    names.append("square_class_error");
+    names.append("conflict");
+    names.append("class0");
+    names.append("class1");
+    names.append("class2");
+    return names;
+}
+
+TVec<string> MultiClassAdaBoost::getTrainCostNames() const
+{
+    // Return the names of the objective costs that the train method computes
+    // and for which it updates the VecStatsCollector train_stats
+    // (these may or may not be exactly the same as what's returned by
+    // getTestCostNames).
+    // ...
+
+    TVec<string> names;
+    return names;
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners/meta/MultiClassAdaBoost.h
===================================================================
--- trunk/plearn_learners/meta/MultiClassAdaBoost.h	2007-11-20 21:24:23 UTC (rev 8276)
+++ trunk/plearn_learners/meta/MultiClassAdaBoost.h	2007-11-21 16:52:19 UTC (rev 8277)
@@ -0,0 +1,197 @@
+// -*- C++ -*-
+
+// plearn_learners/meta/MultiClassAdaBoost.h
+//
+// Copyright (C) 2007 Frederic Bastien
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Frederic Bastien
+
+/*! \file plearn_learners/meta/MultiClassAdaBoost.h */
+
+
+#ifndef MultiClassAdaBoost_INC
+#define MultiClassAdaBoost_INC
+
+#include <plearn_learners/generic/PLearner.h>
+#include <plearn_learners/meta/AdaBoost.h>
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class MultiClassAdaBoost : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! The number of stage that will be used
+    int nb_stage_to_use;
+
+    //! The learner1 and learner2 must be trained!
+    AdaBoost learner1;
+    AdaBoost learner2;
+
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    MultiClassAdaBoost();
+
+
+    //#####  PLearner Member Functions  #######################################
+
+    //! Returns the size of this learner's output, (which typically
+    //! may depend on its inputsize(), targetsize() and set options).
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual int outputsize() const;
+
+    //! (Re-)initializes the PLearner in its fresh state (that state may depend
+    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
+    //! a fresh learner!).
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void forget();
+
+    //! The role of the train method is to bring the learner up to
+    //! stage==nstages, updating the train_stats collector with training costs
+    //! measured on-line in the process.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void train();
+
+    //! Computes the output from the input.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void computeOutput(const Vec& input, Vec& output) const;
+
+    //! Computes the costs from already computed output.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void computeCostsFromOutputs(const Vec& input, const Vec& output,
+                                         const Vec& target, Vec& costs) const;
+
+    //! Returns the names of the costs computed by computeCostsFromOutpus (and
+    //! thus the test method).
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual TVec<std::string> getTestCostNames() const;
+
+    //! Returns the names of the objective costs that the train method computes
+    //! and for which it updates the VecStatsCollector train_stats.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual TVec<std::string> getTrainCostNames() const;
+
+
+    // *** SUBCLASS WRITING: ***
+    // While in general not necessary, in case of particular needs
+    // (efficiency concerns for ex) you may also want to overload
+    // some of the following methods:
+    // virtual void computeOutputAndCosts(const Vec& input, const Vec& target,
+    //                                    Vec& output, Vec& costs) const;
+    // virtual void computeCostsOnly(const Vec& input, const Vec& target,
+    //                               Vec& costs) const;
+    // virtual void test(VMat testset, PP<VecStatsCollector> test_stats,
+    //                   VMat testoutputs=0, VMat testcosts=0) const;
+    // virtual int nTestCosts() const;
+    // virtual int nTrainCosts() const;
+    // virtual void resetInternalState();
+    // virtual bool isStatefulLearner() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(MultiClassAdaBoost);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(MultiClassAdaBoost);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From nouiz at mail.berlios.de  Wed Nov 21 17:53:41 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 21 Nov 2007 17:53:41 +0100
Subject: [Plearn-commits] r8278 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711211653.lALGrf3N019398@sheep.berlios.de>

Author: nouiz
Date: 2007-11-21 17:53:41 +0100 (Wed, 21 Nov 2007)
New Revision: 8278

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
Log:
localized some variable


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-21 16:52:19 UTC (rev 8277)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-21 16:53:41 UTC (rev 8278)
@@ -212,14 +212,14 @@
     if (train_length > train_set->length()) train_length = train_set->length();
     if(train_length < 1) PLERROR("In MeanMedianModeImputationVMatrix::length of the number of train samples to use must be at least 1, got: %i", train_length);
     train_width = train_set->width();
-    train_targetsize = train_set->targetsize();
-    train_weightsize = train_set->weightsize();
-    train_inputsize = train_set->inputsize();
+    int train_targetsize = train_set->targetsize();
+    int train_weightsize = train_set->weightsize();
+    int train_inputsize = train_set->inputsize();
     if(train_inputsize < 1) PLERROR("In MeanMedianModeImputationVMatrix::inputsize of the train vmat must be supplied, got : %i", train_inputsize);
     source_width = source->width();
-    source_targetsize = source->targetsize();
-    source_weightsize = source->weightsize();
-    source_inputsize = source->inputsize();
+    int source_targetsize = source->targetsize();
+    int source_weightsize = source->weightsize();
+    int source_inputsize = source->inputsize();
     if (train_width != source_width) PLERROR("In MeanMedianModeImputationVMatrix::train set and source width must agree, got : %i, %i", train_width, source_width);
     if (train_targetsize != source_targetsize) PLERROR("In MeanMedianModeImputationVMatrix::train set and source targetsize must agree, got : %i, %i", train_targetsize, source_targetsize);
     if (train_weightsize != source_weightsize) PLERROR("In MeanMedianModeImputationVMatrix::train set and source weightsize must agree, got : %i, %i", train_weightsize, source_weightsize);
@@ -241,6 +241,7 @@
     TVec<string> nofields;
     for (int spec_col = 0; spec_col < imputation_spec.size(); spec_col++)
     {
+        int train_col;
         for (train_col = 0; train_col < train_width; train_col++)
         {
             if (imputation_spec[spec_col].first == train_field_names[train_col]) break;
@@ -305,13 +306,13 @@
     cout << fixed << showpoint;
     ProgressBar* pb = 0;
     pb = new ProgressBar("Computing the mean, median and mode vectors", train_width);
-    for (train_col = 0; train_col < train_width; train_col++)
+    for (int train_col = 0; train_col < train_width; train_col++)
     {
-        current_value = 0.0;
-        current_value_count = 0;
+        real current_value = 0.0;
+        int current_value_count = 0;
         train_set->getColumn(train_col, variable_vec);
         sortColumn(variable_vec, 0, train_length);
-        for (train_row = 0; train_row < train_length; train_row++)
+        for (int train_row = 0; train_row < train_length; train_row++)
         {
             if (is_missing(variable_vec[train_row]))
             {

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-21 16:52:19 UTC (rev 8277)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-21 16:53:41 UTC (rev 8278)
@@ -121,21 +121,11 @@
   
   int                  train_length;
   int                  train_width;
-  int                  train_inputsize;
-  int                  train_targetsize;
-  int                  train_weightsize;
-  int                  train_row;
-  int                  train_col;
   TVec<string>         train_field_names;
   PPath                train_metadata;
   int                  source_length;
   int                  source_width;
-  int                  source_inputsize;
-  int                  source_targetsize;
-  int                  source_weightsize;
   Vec                  variable_vec;
-  int                  current_value_count;
-  real                 current_value;
   PPath                mean_median_mode_file_name;
   VMat                 mean_median_mode_file;
 



From nouiz at mail.berlios.de  Wed Nov 21 17:56:09 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 21 Nov 2007 17:56:09 +0100
Subject: [Plearn-commits] r8279 -
	branches/cgi-desjardin/plearn_learners/second_iteration
	trunk/plearn/vmat
Message-ID: <200711211656.lALGu93H019636@sheep.berlios.de>

Author: nouiz
Date: 2007-11-21 17:56:09 +0100 (Wed, 21 Nov 2007)
New Revision: 8279

Added:
   trunk/plearn/vmat/MissingIndicatorVMatrix.cc
   trunk/plearn/vmat/MissingIndicatorVMatrix.h
Removed:
   branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
Log:
Moved a file from a branch to the trunk.


Deleted: branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc	2007-11-21 16:53:41 UTC (rev 8278)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc	2007-11-21 16:56:09 UTC (rev 8279)
@@ -1,266 +0,0 @@
-// -*- C++ -*-
-
-// PLearn (A C++ Machine Learning Library)
-// Copyright (C) 1998 Pascal Vincent
-// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
-// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
-// Copyright (C) 2003 Olivier Delalleau
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-// 
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-// 
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-// 
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-// 
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-// 
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-
-/* *******************************************************************    
-   * $Id: MissingIndicatorVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
-   ******************************************************************* */
-
-
-#include "MissingIndicatorVMatrix.h"
-
-namespace PLearn {
-using namespace std;
-
-/** MissingIndicatorVMatrix **/
-
-PLEARN_IMPLEMENT_OBJECT(
-  MissingIndicatorVMatrix,
-  "VMat class to add a missing indicator for each variable.",
-  "For each variable with a missing value in the referenced train set, an indicator is added.\n"
-  "It is set to 1 if the value of the corresponding variable`in the underlying dataset is missing.\n"
-  "It is set to 0 otherwise.\n"
-  );
-
-MissingIndicatorVMatrix::MissingIndicatorVMatrix()
-: number_of_train_samples_to_use(0.0)
-{
-}
-
-MissingIndicatorVMatrix::MissingIndicatorVMatrix(VMat the_source, VMat the_train_set, real the_number_of_train_samples_to_use)
-{
-  source = the_source;
-  train_set = the_train_set;
-  number_of_train_samples_to_use = the_number_of_train_samples_to_use;
-}
-
-MissingIndicatorVMatrix::~MissingIndicatorVMatrix()
-{
-}
-
-void MissingIndicatorVMatrix::declareOptions(OptionList &ol)
-{
-  declareOption(ol, "source", &MissingIndicatorVMatrix::source, OptionBase::buildoption, 
-                "The source VMatrix with missing values.\n");
-
-  declareOption(ol, "train_set", &MissingIndicatorVMatrix::train_set, OptionBase::buildoption, 
-                "A referenced train set.\n"
-                "A missing indicator is added for variables with missing values in this data set.\n"
-                "It is used in combination with the option number_of_train_samples_to_use\n");
-
-  declareOption(ol, "number_of_train_samples_to_use", &MissingIndicatorVMatrix::number_of_train_samples_to_use, OptionBase::buildoption, 
-                "The number of samples from the train set that will be examined to see\n"
-                "if an indicator should be added for each variable\n");
-
-  inherited::declareOptions(ol);
-}
-
-void MissingIndicatorVMatrix::build()
-{
-  inherited::build();
-  build_();
-}
-
-void MissingIndicatorVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
-{
-  deepCopyField(source, copies);
-  deepCopyField(train_set, copies);
-  deepCopyField(number_of_train_samples_to_use, copies);
-  inherited::makeDeepCopyFromShallowCopy(copies);
-}
-
-void MissingIndicatorVMatrix::getExample(int i, Vec& input, Vec& target, real& weight)
-{
-    source->getExample(i, source_input, target, weight);
-    for (int source_col = 0, new_col = 0; source_col < source_inputsize;
-	 source_col++)
-    {
-      input[new_col] = source_input[source_col];
-      new_col += 1;
-      if (train_var_missing[source_col] > 0)
-      {
-          if (is_missing(source_input[source_col])) input[new_col] = 1.0;
-          else input[new_col] = 0.0;
-          new_col += 1;
-      }
-    }
-}
-
-real MissingIndicatorVMatrix::get(int i, int j) const
-{
-  if (source_rel_pos[j] < 0)
-  {
-    if (is_missing(source->get(i, source_rel_pos[j - 1]))) return 1.0;
-    else return 0.0;
-  }
-  return source->get(i, source_rel_pos[j]);
-}
-
-void MissingIndicatorVMatrix::put(int i, int j, real value)
-{
-  PLERROR("In MissingIndicatorVMatrix::put not implemented");
-}
-
-void MissingIndicatorVMatrix::getSubRow(int i, int j, Vec v) const
-{  
-  for (int source_col = j; source_col < j + v.length(); source_col++) v[source_col] = get(i, source_col);
-}
-
-void MissingIndicatorVMatrix::putSubRow(int i, int j, Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::putSubRow not implemented");
-}
-
-void MissingIndicatorVMatrix::appendRow(Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::appendRow not implemented");
-}
-
-void MissingIndicatorVMatrix::insertRow(int i, Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::insertRow not implemented");
-}
-
-void MissingIndicatorVMatrix::getRow(int i, Vec v) const
-{  
-  for (int source_col = 0; source_col < width_; source_col++) v[source_col] = get(i, source_col); 
-}
-
-void MissingIndicatorVMatrix::putRow(int i, Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::putRow not implemented");
-}
-
-void MissingIndicatorVMatrix::getColumn(int i, Vec v) const
-{
-  if (source_rel_pos[i] < 0) source->getColumn(source_rel_pos[i - 1], v);
-  else source->getColumn(source_rel_pos[i], v);
-  if (source_rel_pos[i] >= 0) return;
-  for (int source_row = 0; source_row < v->length(); source_row++)
-  {
-    if (is_missing(v[source_row])) v[source_row] = 1.0;
-    else v[source_row] = 0.0;
-  } 
-}
-
-void MissingIndicatorVMatrix::build_()
-{
-    if (!train_set || !source) PLERROR("In MissingIndicatorVMatrix::train set and source vmat must be supplied");
-    buildNewRecordFormat(); 
-}
-
-void MissingIndicatorVMatrix::buildNewRecordFormat()
-{
-    int train_length = train_set->length();
-    if (number_of_train_samples_to_use > 0.0)
-        if (number_of_train_samples_to_use < 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
-        else train_length = (int) number_of_train_samples_to_use;
-    if (train_length > train_set->length()) train_length = train_set->length();
-
-    int train_width = train_set->width();
-    int train_inputsize = train_set->inputsize();
-    int source_width = source->width();
-    source_inputsize = source->inputsize();
-
-    if(train_length < 1) 
-      PLERROR("In MissingIndicatorVMatrix::length of the number of train"
-	      " samples to use must be at least 1, got: %i", train_length);
-    if(train_inputsize < 1) 
-      PLERROR("In MissingIndicatorVMatrix::inputsize of the train vmat must"
-	      " be supplied, got : %i", train_inputsize);
-    if (train_width != source_width) 
-      PLERROR("In MissingIndicatorVMatrix::train set and source width must"
-	      " agree, got : %i, %i", train_width, source_width);
-    if (train_set->targetsize() != source->targetsize())
-      PLERROR("In MissingIndicatorVMatrix::train set and source targetsize"
-	      " must agree, got : %i, %i", train_set->targetsize(),
-	      source->targetsize());
-    if (train_set->weightsize() != source->weightsize()) 
-      PLERROR("In MissingIndicatorVMatrix::train set and source weightsize"
-	      " must agree, got : %i, %i", train_set->weightsize(),
-	      source->weightsize());
-    if (train_inputsize != source_inputsize)
-      PLERROR("In MissingIndicatorVMatrix::train set and source inputsize"
-	      " must agree, got : %i, %i", train_inputsize, source_inputsize);
-
-    train_input.resize(train_width);
-    train_var_missing.resize(train_inputsize);
-    train_var_missing.clear();
-
-    for (int train_row = 0; train_row < train_length; train_row++)
-    {
-         train_set->getRow(train_row, train_input);
-         for (int train_col = 0; train_col < train_inputsize; train_col++)
-         {
-             if (is_missing(train_input[train_col])) train_var_missing[train_col] = 1;
-         }
-    }
-
-    int added_colomns = sum(train_var_missing);
-    width_ = train_width + added_colomns;
-
-    TVec<string> train_field_names(train_width);
-    source_rel_pos.resize(width_);
-    TVec<string> new_field_names(width_);
-    train_field_names = train_set->fieldNames();
-    int new_col = 0;
-    for (int train_col = 0; train_col < train_inputsize; train_col++)
-    {
-      new_field_names[new_col] = train_field_names[train_col];
-      source_rel_pos[new_col] = train_col;
-      new_col += 1;
-      if (train_var_missing[train_col] > 0)
-      {
-          new_field_names[new_col] = train_field_names[train_col] + "_MI";
-          source_rel_pos[new_col] = -1;
-          new_col += 1;
-      }
-    }
-    for (int train_col = train_inputsize; train_col < train_width; train_col++)
-    {
-      new_field_names[new_col] = train_field_names[train_col];
-      source_rel_pos[new_col] = train_col;
-      new_col += 1;
-    }
-    length_ = source->length();
-    inputsize_ = train_inputsize + added_colomns;
-    targetsize_ = source->targetsize();
-    weightsize_ = train_set->weightsize();
-    source_input.resize(source_inputsize);
-    declareFieldNames(new_field_names);
-}
-
-} // end of namespcae PLearn

Deleted: branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-11-21 16:53:41 UTC (rev 8278)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-11-21 16:56:09 UTC (rev 8279)
@@ -1,110 +0,0 @@
-// -*- C++ -*-
-
-// PLearn (A C++ Machine Learning Library)
-// Copyright (C) 1998 Pascal Vincent
-// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
-// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
-// Copyright (C) 2003 Olivier Delalleau
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-// 
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-// 
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-// 
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-// 
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-// 
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-
-/* ******************************************************************      
-   * $Id: MissingIndicatorVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
-   ****************************************************************** */
-
-/*! \file MissingIndicatorVMatrix.h */
-
-#ifndef MissingIndicatorVMatrix_INC
-#define MissingIndicatorVMatrix_INC
-
-#include <plearn/vmat/SourceVMatrix.h>
-#include <plearn/math/BottomNI.h>
-
-namespace PLearn {
-using namespace std;
-
-class MissingIndicatorVMatrix: public VMatrix
-{
-  typedef VMatrix inherited;
-  
-public:
-
-  //! The source VMatrix with missing values.
-  VMat         source;
-  
-  //! A referenced train set.
-  //! A missing indicator is added for variables with missing values in this data set.
-  //! It is used in combination with the option number_of_train_samples_to_use.
-  VMat         train_set;
-  
-  //! The number of samples from the train set that will be examined to see
-  //! if an indicator should be added for each variable.
-  real         number_of_train_samples_to_use;
-  
-
-                        MissingIndicatorVMatrix();
-                        MissingIndicatorVMatrix(VMat the_source, VMat the_train_set, real the_number_of_train_samples_to_use);
-  virtual               ~MissingIndicatorVMatrix();
-
-  static void           declareOptions(OptionList &ol);
-
-  virtual void          build();
-  virtual void          makeDeepCopyFromShallowCopy(CopiesMap& copies);
-
-  virtual void         getExample(int i, Vec& input, Vec& target, real& weight);
-  virtual real         get(int i, int j) const;
-  virtual void         put(int i, int j, real value);
-  virtual void         getSubRow(int i, int j, Vec v) const;
-  virtual void         putSubRow(int i, int j, Vec v);
-  virtual void         appendRow(Vec v);
-  virtual void         insertRow(int i, Vec v);  
-  virtual void         getRow(int i, Vec v) const;
-  virtual void         putRow(int i, Vec v);
-  virtual void         getColumn(int i, Vec v) const;
-
-private:
-  
-  Vec          train_input;
-  TVec<int>    train_var_missing;
-  int          source_inputsize;
-  Vec          source_input;
-  TVec<int>    source_rel_pos;
-
-          void         build_();
-          void         buildNewRecordFormat();
-  
-  PLEARN_DECLARE_OBJECT(MissingIndicatorVMatrix);
-
-};
-
-DECLARE_OBJECT_PTR(MissingIndicatorVMatrix);
-
-} // end of namespcae PLearn
-#endif

Copied: trunk/plearn/vmat/MissingIndicatorVMatrix.cc (from rev 8251, branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc)

Copied: trunk/plearn/vmat/MissingIndicatorVMatrix.h (from rev 8252, branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h)



From nouiz at mail.berlios.de  Wed Nov 21 22:18:51 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 21 Nov 2007 22:18:51 +0100
Subject: [Plearn-commits] r8280 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711212118.lALLIpeo022377@sheep.berlios.de>

Author: nouiz
Date: 2007-11-21 22:18:51 +0100 (Wed, 21 Nov 2007)
New Revision: 8280

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
Log:
locallized many variable


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-21 16:56:09 UTC (rev 8279)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-21 21:18:51 UTC (rev 8280)
@@ -88,15 +88,6 @@
   declareOption(ol, "variable_mode", &MeanMedianModeImputationVMatrix::variable_mode, OptionBase::learntoption, 
                 "The vector of variable modes observed from the train set.");
 
-  declareOption(ol, "variable_present_count", &MeanMedianModeImputationVMatrix::variable_present_count, OptionBase::learntoption, 
-                "The vector of non missing variable counts from the train set.");
-
-  declareOption(ol, "variable_missing_count", &MeanMedianModeImputationVMatrix::variable_missing_count, OptionBase::learntoption, 
-                "The vector of missing variable counts from the train set.");
-
-  declareOption(ol, "variable_mode_count", &MeanMedianModeImputationVMatrix::variable_mode_count, OptionBase::learntoption, 
-                "The vector of variable mode counts from the train set.");
-
   declareOption(ol, "variable_imputation_instruction", &MeanMedianModeImputationVMatrix::variable_imputation_instruction, OptionBase::learntoption, 
                 "The vector of coded instruction for each variables.");
 
@@ -117,8 +108,6 @@
   deepCopyField(variable_mean, copies);
   deepCopyField(variable_median, copies);
   deepCopyField(variable_mode, copies);
-  deepCopyField(variable_present_count, copies);
-  deepCopyField(variable_missing_count, copies);
   deepCopyField(variable_imputation_instruction, copies);
   inherited::makeDeepCopyFromShallowCopy(copies);
 }
@@ -205,18 +194,18 @@
 void MeanMedianModeImputationVMatrix::build_()
 {
     if (!train_set || !source) PLERROR("In MeanMedianModeImputationVMatrix::train set and source vmat must be supplied");
-    train_length = train_set->length();
+    int train_length = train_set->length();
     if (number_of_train_samples_to_use > 0.0)
         if (number_of_train_samples_to_use < 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
         else train_length = (int) number_of_train_samples_to_use;
     if (train_length > train_set->length()) train_length = train_set->length();
     if(train_length < 1) PLERROR("In MeanMedianModeImputationVMatrix::length of the number of train samples to use must be at least 1, got: %i", train_length);
-    train_width = train_set->width();
+    int train_width = train_set->width();
     int train_targetsize = train_set->targetsize();
     int train_weightsize = train_set->weightsize();
     int train_inputsize = train_set->inputsize();
     if(train_inputsize < 1) PLERROR("In MeanMedianModeImputationVMatrix::inputsize of the train vmat must be supplied, got : %i", train_inputsize);
-    source_width = source->width();
+    int source_width = source->width();
     int source_targetsize = source->targetsize();
     int source_weightsize = source->weightsize();
     int source_inputsize = source->inputsize();
@@ -226,8 +215,7 @@
     if (train_inputsize != source_inputsize) PLERROR("In MeanMedianModeImputationVMatrix::train set and source inputsize must agree, got : %i, %i", train_inputsize, source_inputsize);
     train_field_names.resize(train_width);
     train_field_names = train_set->fieldNames();
-    source_length = source->length();
-    length_ = source_length;
+    length_ = source->length();
     width_ = source_width;
     inputsize_ = source_inputsize;
     targetsize_ = source_targetsize;
@@ -259,28 +247,27 @@
     if(nofields.length()>0)
       PLERROR("In MeanMedianModeImputationVMatrix::build_() Their is %d fields in the imputation_spec that are not in train set: %s",nofields.length(),
 	      tostring(nofields).c_str());
-    train_metadata = train_set->getMetaDataDir();
-    mean_median_mode_file_name = train_metadata + "mean_median_mode_file.pmat";
-    
+    PPath train_metadata = train_set->getMetaDataDir();
+    PPath mean_median_mode_file_name = train_metadata + "mean_median_mode_file.pmat";
     if (!isfile(mean_median_mode_file_name))
     {
         computeMeanMedianModeVectors();
-        createMeanMedianModeFile();
+        createMeanMedianModeFile(mean_median_mode_file_name);
     }
-    else loadMeanMedianModeFile();
+    else loadMeanMedianModeFile(mean_median_mode_file_name);
 }
 
-void MeanMedianModeImputationVMatrix::createMeanMedianModeFile()
+void MeanMedianModeImputationVMatrix::createMeanMedianModeFile(PPath file_name)
 {
-    mean_median_mode_file = new FileVMatrix(mean_median_mode_file_name, 3, train_field_names);
+    mean_median_mode_file = new FileVMatrix(file_name, 3, train_field_names);
     mean_median_mode_file->putRow(0, variable_mean);
     mean_median_mode_file->putRow(1, variable_median);
     mean_median_mode_file->putRow(2, variable_mode);
 }
 
-void MeanMedianModeImputationVMatrix::loadMeanMedianModeFile()
+void MeanMedianModeImputationVMatrix::loadMeanMedianModeFile(PPath file_name)
 {
-    mean_median_mode_file = new FileVMatrix(mean_median_mode_file_name);
+    mean_median_mode_file = new FileVMatrix(file_name);
     mean_median_mode_file->getRow(0, variable_mean);
     mean_median_mode_file->getRow(1, variable_median);
     mean_median_mode_file->getRow(2, variable_mode);
@@ -293,26 +280,26 @@
 
 void MeanMedianModeImputationVMatrix::computeMeanMedianModeVectors()
 {
-    variable_present_count.resize(train_width);
-    variable_missing_count.resize(train_width);
-    variable_mode_count.resize(train_width);
+    TVec<int> variable_present_count(width_);
+    TVec<int> variable_missing_count(width_);
+    TVec<int> variable_mode_count(width_);
     variable_mean.clear();
     variable_median.clear();
     variable_mode.clear();
     variable_present_count.clear();
     variable_missing_count.clear();
     variable_mode_count.clear();
-    variable_vec.resize(train_set->length());
+    Vec variable_vec(train_set->length());
     cout << fixed << showpoint;
     ProgressBar* pb = 0;
-    pb = new ProgressBar("Computing the mean, median and mode vectors", train_width);
-    for (int train_col = 0; train_col < train_width; train_col++)
+    pb = new ProgressBar("Computing the mean, median and mode vectors", width_);
+    for (int train_col = 0; train_col < width_; train_col++)
     {
         real current_value = 0.0;
         int current_value_count = 0;
         train_set->getColumn(train_col, variable_vec);
-        sortColumn(variable_vec, 0, train_length);
-        for (int train_row = 0; train_row < train_length; train_row++)
+        sortColumn(variable_vec, 0, train_set->length());
+        for (int train_row = 0; train_row < train_set->length(); train_row++)
         {
             if (is_missing(variable_vec[train_row]))
             {

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-21 16:56:09 UTC (rev 8279)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-21 21:18:51 UTC (rev 8280)
@@ -82,15 +82,6 @@
   //! The vector of variable modes observed from the train set.
   Vec                           variable_mode;
   
-  //! The vector of non missing variable counts from the train set.
-  TVec<int>                     variable_present_count;
-  
-  //! The vector of missing variable counts from the train set.
-  TVec<int>                     variable_missing_count;
-  
-  //! The vector of variable mode counts from the train set.
-  TVec<int>                     variable_mode_count;
-  
   //! The vector of coded instruction for each variables.
   TVec<int>                     variable_imputation_instruction;
   
@@ -119,19 +110,12 @@
 
 private:
   
-  int                  train_length;
-  int                  train_width;
   TVec<string>         train_field_names;
-  PPath                train_metadata;
-  int                  source_length;
-  int                  source_width;
-  Vec                  variable_vec;
-  PPath                mean_median_mode_file_name;
   VMat                 mean_median_mode_file;
 
           void         build_();
-          void         createMeanMedianModeFile(); 
-          void         loadMeanMedianModeFile(); 
+          void         createMeanMedianModeFile(PPath file_name); 
+          void         loadMeanMedianModeFile(PPath file_name); 
           void         computeMeanMedianModeVectors();  
           void         sortColumn(Vec input_vec, int start, int end);
           void         sortSmallSubArray(Vec input_vec, int start_index, int end_index);



From nouiz at mail.berlios.de  Wed Nov 21 22:41:36 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 21 Nov 2007 22:41:36 +0100
Subject: [Plearn-commits] r8281 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711212141.lALLfabC023330@sheep.berlios.de>

Author: nouiz
Date: 2007-11-21 22:41:36 +0100 (Wed, 21 Nov 2007)
New Revision: 8281

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
Log:
-removed unimplemented function as the parent class take care of them
-if no train_set, we use the source as the train_set
-removed the function getExample() as it was bugged(did not imput the value for the targed vector) and the parent class take care of it
-lock the metadatadir when working for the precomputed data
-check the mtime of the precomputed file. Give warning if bad value.


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-21 21:18:51 UTC (rev 8280)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-21 21:41:36 UTC (rev 8281)
@@ -112,18 +112,6 @@
   inherited::makeDeepCopyFromShallowCopy(copies);
 }
 
-void MeanMedianModeImputationVMatrix::getExample(int i, Vec& input, Vec& target, real& weight)
-{
-  source->getExample(i, input, target, weight);
-  for (int source_col = 0; source_col < input->length(); source_col++)
-  {
-    if (is_missing(input[source_col]) && variable_imputation_instruction[source_col] > 0)
-      if (variable_imputation_instruction[source_col] == 1) input[source_col] = variable_mean[source_col];
-      else if (variable_imputation_instruction[source_col] == 2) input[source_col] = variable_median[source_col];
-      else if (variable_imputation_instruction[source_col] == 3) input[source_col] = variable_mode[source_col];
-  }  
-}
-
 real MeanMedianModeImputationVMatrix::get(int i, int j) const
 { 
   real variable_value = source->get(i, j);
@@ -134,11 +122,6 @@
   return variable_value;
 }
 
-void MeanMedianModeImputationVMatrix::put(int i, int j, real value)
-{
-  PLERROR("In MeanMedianModeImputationVMatrix::put not implemented");
-}
-
 void MeanMedianModeImputationVMatrix::getSubRow(int i, int j, Vec v) const
 {  
   source->getSubRow(i, j, v);
@@ -149,21 +132,6 @@
       else if (variable_imputation_instruction[source_col + j] == 3) v[source_col] = variable_mode[source_col + j];
 }
 
-void MeanMedianModeImputationVMatrix::putSubRow(int i, int j, Vec v)
-{
-  PLERROR("In MeanMedianModeImputationVMatrix::putSubRow not implemented");
-}
-
-void MeanMedianModeImputationVMatrix::appendRow(Vec v)
-{
-  PLERROR("In MeanMedianModeImputationVMatrix::appendRow not implemented");
-}
-
-void MeanMedianModeImputationVMatrix::insertRow(int i, Vec v)
-{
-  PLERROR("In MeanMedianModeImputationVMatrix::insertRow not implemented");
-}
-
 void MeanMedianModeImputationVMatrix::getRow(int i, Vec v) const
 {  
   source-> getRow(i, v);
@@ -174,11 +142,6 @@
       else if (variable_imputation_instruction[source_col] == 3) v[source_col] = variable_mode[source_col]; 
 }
 
-void MeanMedianModeImputationVMatrix::putRow(int i, Vec v)
-{
-  PLERROR("In MeanMedianModeImputationVMatrix::putRow not implemented");
-}
-
 void MeanMedianModeImputationVMatrix::getColumn(int i, Vec v) const
 {  
   source-> getColumn(i, v);
@@ -193,7 +156,9 @@
 
 void MeanMedianModeImputationVMatrix::build_()
 {
-    if (!train_set || !source) PLERROR("In MeanMedianModeImputationVMatrix::train set and source vmat must be supplied");
+    if (!source) PLERROR("In MeanMedianModeImputationVMatrix:: source vmat must be supplied");
+    if (!train_set)
+      train_set = source;
     int train_length = train_set->length();
     if (number_of_train_samples_to_use > 0.0)
         if (number_of_train_samples_to_use < 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
@@ -249,12 +214,14 @@
 	      tostring(nofields).c_str());
     PPath train_metadata = train_set->getMetaDataDir();
     PPath mean_median_mode_file_name = train_metadata + "mean_median_mode_file.pmat";
+    train_set->lockMetaDataDir();
     if (!isfile(mean_median_mode_file_name))
     {
         computeMeanMedianModeVectors();
         createMeanMedianModeFile(mean_median_mode_file_name);
     }
     else loadMeanMedianModeFile(mean_median_mode_file_name);
+    train_set->unlockMetaDataDir();
 }
 
 void MeanMedianModeImputationVMatrix::createMeanMedianModeFile(PPath file_name)
@@ -271,6 +238,17 @@
     mean_median_mode_file->getRow(0, variable_mean);
     mean_median_mode_file->getRow(1, variable_median);
     mean_median_mode_file->getRow(2, variable_mode);
+    time_t source_time = source->getMtime();
+    time_t stat_file_time = mean_median_mode_file->getMtime();
+    if(stat_file_time==0)
+      PLWARNING("In MeanMedianModeImputationVMatrix::loadMeanMedianModeFile() - "
+		"The precomputed stats file '%s'"
+		" have a modification time of 0",file_name.c_str());
+    else if(source_time>stat_file_time)
+            PLWARNING("In MeanMedianModeImputationVMatrix::loadMeanMedianModeFile()"
+		      " - The precomputed stats file '%s'"
+		      " was created before the source file. Delete it to have it recreated next time."
+		      ,file_name.c_str());
 }
 
 VMat MeanMedianModeImputationVMatrix::getMeanMedianModeFile()

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-21 21:18:51 UTC (rev 8280)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-21 21:41:36 UTC (rev 8281)
@@ -96,15 +96,9 @@
   virtual void          build();
   virtual void          makeDeepCopyFromShallowCopy(CopiesMap& copies);
 
-  virtual void         getExample(int i, Vec& input, Vec& target, real& weight);
   virtual real         get(int i, int j) const;
-  virtual void         put(int i, int j, real value);
   virtual void         getSubRow(int i, int j, Vec v) const;
-  virtual void         putSubRow(int i, int j, Vec v);
-  virtual void         appendRow(Vec v);
-  virtual void         insertRow(int i, Vec v);  
   virtual void         getRow(int i, Vec v) const;
-  virtual void         putRow(int i, Vec v);
   virtual void         getColumn(int i, Vec v) const;
           VMat         getMeanMedianModeFile();
 



From louradou at mail.berlios.de  Thu Nov 22 22:55:11 2007
From: louradou at mail.berlios.de (louradou at BerliOS)
Date: Thu, 22 Nov 2007 22:55:11 +0100
Subject: [Plearn-commits] r8282 - in trunk: plearn/base
	plearn_learners/online
Message-ID: <200711222155.lAMLtBR7004606@sheep.berlios.de>

Author: louradou
Date: 2007-11-22 22:55:10 +0100 (Thu, 22 Nov 2007)
New Revision: 8282

Modified:
   trunk/plearn/base/stringutils.cc
   trunk/plearn_learners/online/LayerCostModule.cc
   trunk/plearn_learners/online/LayerCostModule.h
Log:


Modified: trunk/plearn/base/stringutils.cc
===================================================================
--- trunk/plearn/base/stringutils.cc	2007-11-21 21:41:36 UTC (rev 8281)
+++ trunk/plearn/base/stringutils.cc	2007-11-22 21:55:10 UTC (rev 8282)
@@ -549,9 +549,9 @@
     {
         endpos = txt.find_first_of("\n",startpos);
         if(endpos!=string::npos)
-            res += prefix + txt.substr(startpos, endpos-startpos) + postfix + "\n";
+            res += prefix + txt.substr(startpos, endpos-startpos) + postfix;
         else
-            res += prefix + txt.substr(startpos) + postfix + "\n";
+            res += prefix + txt.substr(startpos) + postfix;
         startpos = endpos + 1;
     }
     return res;

Modified: trunk/plearn_learners/online/LayerCostModule.cc
===================================================================
--- trunk/plearn_learners/online/LayerCostModule.cc	2007-11-21 21:41:36 UTC (rev 8281)
+++ trunk/plearn_learners/online/LayerCostModule.cc	2007-11-22 21:55:10 UTC (rev 8282)
@@ -54,13 +54,17 @@
     "Be careful: some are valid only for binomial layers. \n");
 
 LayerCostModule::LayerCostModule():
-    cost_function(""),
+    cost_function("correlation"),
     nstages_max(-1),
+    momentum(0.),
+    optimization_strategy("standard"),
     alpha(0.),
-    momentum(0.),
     histo_size(10),
+    penalty_function("square"),
     cost_function_completename(""),
     stage(0),
+    bprop_all_terms(true),
+    random_index_during_bprop(false),
     average_deriv(0.)
 {
     output_size = 1;
@@ -74,7 +78,7 @@
     declareOption(ol, "cost_function", &LayerCostModule::cost_function,
                   OptionBase::buildoption,
         "The cost function applied to the layer:\n"
-        "- \"pascal\" [default]:"
+        "- \"pascal\" :"
         " Pascal Vincent's God given cost function.\n"
         "- \"correlation\":"
         " average of a function applied to the correlations between outputs.\n"
@@ -91,32 +95,45 @@
     declareOption(ol, "nstages_max", &LayerCostModule::nstages_max,
                   OptionBase::buildoption,
         "Maximal number of updates for which the gradient of the cost function will be propagated.\n"
-	"-1 means: always train without limit.\n");
+	"-1 means: always train without limit.\n"
+        );
 
+    declareOption(ol, "optimization_strategy", &LayerCostModule::optimization_strategy,
+                  OptionBase::buildoption,
+        "Strategy to compute the gradient:\n"
+	"- \"standard\": standard computation\n"
+	"- \"half\": we will propagate the gradient only on units tagged as i < j.\n"
+	"- \"random_half\": idem than 'half' with the order of the indices that changes randomly during training.\n"
+        );
+
     declareOption(ol, "momentum", &LayerCostModule::momentum,
                   OptionBase::buildoption,
-        "(in [0,1[) For non stochastic cost functions, momentum to compute the moving means.\n");
+        "(in [0,1[) For non stochastic cost functions, momentum to compute the moving means.\n"
+        );
 
     declareOption(ol, "histo_size", &LayerCostModule::histo_size,
                   OptionBase::buildoption,
         "For \"kl_div\" cost functions,\n"
         "number of bins for the histograms (to estimate distributions of outputs).\n"
-        "The higher is histo_size, the more precise is the estimation.\n");
+        "The higher is histo_size, the more precise is the estimation.\n"
+        );
 
     declareOption(ol, "alpha", &LayerCostModule::alpha,
                   OptionBase::buildoption,
         "(>=0) For \"pascal\" cost function,\n"
         "number of bins for the histograms (to estimate distributions of outputs).\n"
-        "The higher is histo_size, the more precise is the estimation.\n");
-
-    declareOption(ol, "inputs_expectation_trainMemory", &LayerCostModule::inputs_expectation_trainMemory,
-                  OptionBase::learntoption,
-                  "Correlation of the outputs, for all pairs of units.\n"
+        "The higher is histo_size, the more precise is the estimation.\n"
         );
 
-    declareOption(ol, "inputs_cross_quadratic_mean_trainMemory", &LayerCostModule::inputs_cross_quadratic_mean_trainMemory,
-                  OptionBase::learntoption,
-                  "Expectation of the cross products between outputs, for all pairs of units.\n"
+    declareOption(ol, "penalty_function", &LayerCostModule::penalty_function,
+                  OptionBase::buildoption,
+                  "(For non-stochastic cost functions)\n"
+                  "Function applied to the local cost between two inputs to compute\n"
+                  "the global cost on the whole set of inputs (by averaging).\n"
+                  "- \"square\": f(x)= x^2      \n"
+                  "- \"log\":    f(x)= -log( 1 - x) \n"
+                  "- \"exp\":    f(x)= exp( x )     \n"
+                  "- \"linear\": f(x)= x       \n"
         );
 
     declareOption(ol, "cost_function_completename", &LayerCostModule::cost_function_completename,
@@ -128,23 +145,45 @@
                   OptionBase::learntoption,
                   "number of stages that has been done during the training.\n"
         );
+
+    declareOption(ol, "inputs_expectation_trainMemory", &LayerCostModule::inputs_expectation_trainMemory,
+                  OptionBase::nosave,
+                  "Correlation of the outputs, for all pairs of units.\n"
+        );
+
+    declareOption(ol, "inputs_cross_quadratic_mean_trainMemory", &LayerCostModule::inputs_cross_quadratic_mean_trainMemory,
+                  OptionBase::nosave,
+                  "Expectation of the cross products between outputs, for all pairs of units.\n"
+        );
 }
 
 void LayerCostModule::build_()
 {
     PLASSERT( histo_size > 1 );
-    PLASSERT( momentum >= 0.0);
-    PLASSERT( momentum < 1);
+    PLASSERT( momentum >= 0.);
+    PLASSERT( momentum < 1.);
 
     if( input_size > 1 )
         norm_factor = 1./(real)(input_size*(input_size-1));
 
-    string im = lowerstring( cost_function );
+    optimization_strategy = lowerstring( optimization_strategy );
+    if( optimization_strategy == "" )
+        optimization_strategy = "standard";
+    if ( optimization_strategy == "half" )
+         bprop_all_terms = false;
+    else if ( optimization_strategy == "random_half" )
+    {
+         bprop_all_terms = false;
+         random_index_during_bprop = true;
+    }
+    else if ( optimization_strategy != "standard" )
+         PLERROR( "LayerCostModule::build() does not recognize"
+                  "optimization_strategy '%s'", optimization_strategy.c_str() );
+
+    cost_function = lowerstring( cost_function );
     // choose HERE the *default* cost function
-    if( im == "" )
+    if( cost_function == "" )
         cost_function = "pascal";
-    else
-        cost_function = im;
     if( ( cost_function_completename == "" ) || !string_ends_with(cost_function_completename, cost_function) )
         cost_function_completename = string(cost_function);
 
@@ -191,14 +230,29 @@
             inputs_expectation_trainMemory.resize(input_size);
             inputs_cross_quadratic_mean_trainMemory.resize(input_size,input_size);
         }
-        string slink = "_";
-        if( cost_function == "pascal" )
-            cost_function_completename = "exp_pascal"; //addprepostfix( func_pascal_prefix(), slink, cost_function );
-        else if( cost_function == "correlation" )
-            cost_function_completename = "exp_correlation" ; //addprepostfix( func_correlation_prefix(), slink, cost_function );
+        cost_function_completename = addprepostfix( penalty_function, "_", cost_function );
+        LINEAR_FUNC = false;
+        SQUARE_FUNC = false;
+        POW4_FUNC = false;
+        EXP_FUNC = false;
+        LOG_FUNC = false;
+        penalty_function = lowerstring( penalty_function );
+        if( penalty_function == "linear" )
+            LINEAR_FUNC = true;
+        else if( penalty_function == "square" )
+            SQUARE_FUNC = true;
+        else if( penalty_function == "pow4" )
+            POW4_FUNC = true;
+        else if( penalty_function == "exp" )
+            EXP_FUNC = true;
+        else if( penalty_function == "log" )
+            LOG_FUNC = true;
+        else
+            PLERROR("LayerCostModule::build_() does not recognize penalty function '%s'",
+                    penalty_function.c_str());
     }
     else
-        PLERROR("LayerCostModule::build_() does not recognize cost function %s",
+        PLERROR("LayerCostModule::build_() does not recognize cost function '%s'",
                  cost_function.c_str());
 
     // The port story...
@@ -235,6 +289,7 @@
     }
     one_count = 0.;
     stage = 0;
+    average_deriv = 0.;
 }
 
 void LayerCostModule::makeDeepCopyFromShallowCopy(CopiesMap& copies)
@@ -270,12 +325,13 @@
     Mat* p_inputs = ports_value[getPortIndex("input")];
     Mat* p_costs = ports_value[getPortIndex("cost")];
 
+
     PLASSERT( ports_value.length() == nPorts() );
 
     if ( p_costs && p_costs->isEmpty() )
     {
         PLASSERT( p_inputs && !p_inputs->isEmpty() );
-        cout << "fprop" << endl;
+        //cout << "fprop" << endl;
         fprop(*p_inputs, *p_costs);
     }
 }
@@ -381,9 +437,9 @@
             for (int i = 0; i < input_size; i++)
             {
                 if (alpha > 0.0 )
-                    costs(0,0) -= alpha * func_pascal( expectation[i] ) *(real)(input_size-1);
+                    costs(0,0) -= alpha * func_( expectation[i] ) *(real)(input_size-1);
                 for (int j = 0; j < i; j++)
-                    costs(0,0) += func_pascal( cross_quadratic_mean(i,j) );
+                    costs(0,0) += func_( cross_quadratic_mean(i,j) );
             }
             costs(0,0) *= norm_factor;
         }
@@ -413,7 +469,7 @@
             // Computing the cost
             for (int i = 0; i < input_size; i++)
                 for (int j = 0; j < i; j++)
-                    costs(0,0) += func_correlation( correlations(i,j) );
+                    costs(0,0) += func_( correlations(i,j) );
 
             costs(0,0) *= norm_factor;
         }
@@ -511,7 +567,7 @@
     }
 
     else
-        PLERROR("LayerCostModule::fprop() not implemented for cost_cfunction %s\n"
+        PLERROR("LayerCostModule::fprop() not implemented for cost_cfunction '%s'\n"
                 "- It may be a printing error.\n"
                 "- You can try to call LayerCostModule::fprop(const Mat& inputs, Mat& costs)"
                 "  if your cost function is non stochastic.\n"
@@ -552,6 +608,7 @@
 	PLASSERT( p_inputs && !p_inputs->isEmpty());
         int n_samples = p_inputs->length();
 	PLASSERT( p_cost_grad->length() == n_samples );
+	PLASSERT( p_cost_grad->width() == 1 );
 
         bpropUpdate( *p_inputs, *p_inputs_grad);
 
@@ -564,7 +621,7 @@
     else if( !p_inputs_grad && !p_cost_grad )
         return;
     else
-        PLERROR("In LayerCostModule::bpropAccUpdate - Port configuration not implemented ");
+        PLERROR("In LayerCostModule::bpropAccUpdate - Port configuration not implemented.");
 
 }
 
@@ -574,6 +631,9 @@
 void LayerCostModule::bpropUpdate(const Mat& inputs,
                                   Mat& inputs_grad)
 {
+    if( random_index_during_bprop )
+        PLERROR("LayerCostModule::bpropUpdate with random_index_during_bprop not implemented yet.");
+
     PLASSERT( inputs.width() == input_size );
     inputs_grad.resize(inputs.length(), input_size );
     inputs_grad.clear();
@@ -586,16 +646,15 @@
     if( (nstages_max>0) && (stage > nstages_max) )
         return;
 
-    cout << "bpropAccUpdate" << endl;
+    //cout << "bpropAccUpdate" << endl;
 
-    real qi, qj, comp_qi, comp_qj;
-    Vec comp_q(input_size), log_term(input_size);
-
     if( cost_function == "stochastic_cross_entropy" )
     {
         for (int isample = 0; isample < n_samples; isample++)
         {
-            for (int i = 0 ; i < input_size ; i++ )
+            real qi, qj, comp_qi, comp_qj;
+	    Vec comp_q(input_size), log_term(input_size);
+	    for (int i = 0 ; i < input_size ; i++ )
             {
                 qi = inputs(isample,i);
                 comp_qi = 1.0 - qi;
@@ -613,7 +672,8 @@
                     // log(pj) - log(1-pj) + pj/pi - (1-pj)/(1-pi)
                     inputs(isample,i) += log_term[j] + qj/qi - comp_qi/comp_qj;
                     // The symetric part (loop  j=i+1...input_size)
-                    inputs(isample,j) += log_term[i] + qi/qj - comp_qj/comp_qi;
+                    if( bprop_all_terms )
+		        inputs(isample,j) += log_term[i] + qi/qj - comp_qj/comp_qi;
                 }
             }
                 for (int i = 0; i < input_size; i++ )
@@ -625,6 +685,8 @@
     {
         for (int isample = 0; isample < n_samples; isample++)
         {
+            real qi, qj, comp_qi, comp_qj;
+	    Vec comp_q(input_size), log_term(input_size);
             for (int i = 0; i < input_size; i++ )
             {
                 qi = inputs(isample,i);
@@ -647,7 +709,8 @@
                     //   [qj - qi]/[qi (1-qi)] - log[ qi/(1-qi) * (1-qj)/qj]
                     inputs_grad(isample,i) += (qj - qi)*comp_qi - log_term[i] + log_term[j];
                     // The symetric part (loop  j=i+1...input_size)
-                    inputs_grad(isample,j) += (qi - qj)*comp_qj - log_term[j] + log_term[i];
+                    if( bprop_all_terms )
+		        inputs_grad(isample,j) += (qi - qj)*comp_qj - log_term[j] + log_term[i];
                 }
             }
             for (int i = 0; i < input_size; i++ )
@@ -659,9 +722,13 @@
     {
         computeHisto(inputs);
         real cost_before = computeKLdiv( true );
+
+        if( !bprop_all_terms )
+	    PLERROR("kl_div with bprop_all_terms=false not implemented yet");
     
         for (int isample = 0; isample < n_samples; isample++)
         {
+            real qi, qj;
             // Computing the difference of KL divergence
             // for d_q
             for (int i = 0; i < input_size; i++)
@@ -715,6 +782,7 @@
         {
             // Computing the difference of KL divergence
             // for d_q
+            real qi, qj;
             for (int i = 0; i < input_size; i++)
             {
                 inputs_grad(isample, i) = 0.0;
@@ -731,15 +799,18 @@
                 {
                     inputs_grad(isample, i) += delta_SafeKLdivTerm(i, j, index_i, over_dqi);
 
-                    qj = inputs(isample,j);
-                    int index_j = histo_index(qj);
-                    if( ( index_j == histo_size-1 ) || ( index_j == 0 ) )
-                        continue;
-                    real over_dqj=1.0/dq(qj);
-                    // qj + dq(qj) ==> | p_inputs_histo(j,index_j)   - one_count
-                    //                 \ p_inputs_histo(j,index_j+shift_j) + one_count
+                    if( bprop_all_terms )
+		    {
+                        qj = inputs(isample,j);
+                        int index_j = histo_index(qj);
+                        if( ( index_j == histo_size-1 ) || ( index_j == 0 ) )
+                            continue;
+                        real over_dqj=1.0/dq(qj);
+                        // qj + dq(qj) ==> | p_inputs_histo(j,index_j)   - one_count
+                        //                 \ p_inputs_histo(j,index_j+shift_j) + one_count
                         
-                    inputs_grad(isample, j) += delta_SafeKLdivTerm(j, i, index_j, over_dqj);
+		        inputs_grad(isample, j) += delta_SafeKLdivTerm(j, i, index_j, over_dqj);
+		    }
                 }
             }
 
@@ -753,137 +824,121 @@
     {
         computePascalStatistics( inputs );
 
-        if( momentum > 0.0 )
-            for (int isample = 0; isample < n_samples; isample++)
+        for (int isample = 0; isample < n_samples; isample++)
+        {
+            real qi, qj;
+            for (int i = 0; i < input_size; i++)
             {
-                for (int i = 0; i < input_size; i++)
+                qi = inputs(isample, i);
+                if (alpha > 0.0 )
+                    inputs_grad(isample, i) -= alpha*deriv_func_(inputs_expectation[i])
+                                                    *(real)(input_size-1);
+                for (int j = 0; j < i; j++)
                 {
-                    qi = inputs(isample, i);
-                    if (alpha > 0.0 )
-                        inputs_grad(isample, i) -= alpha*deriv_func_pascal(inputs_expectation[i])
-                                                        *(1.0-momentum)
-                                                        *(real)(input_size-1);
-                    for (int j = 0; j < i; j++)
-                    {
-                        real d_temp = deriv_func_pascal(inputs_cross_quadratic_mean(i,j));
-                        qj = inputs(isample,j);
-                        inputs_grad(isample, i) += d_temp *qj*(1.0-momentum);
-                        inputs_grad(isample, j) += d_temp *qi*(1.0-momentum);
-                    }
-                }
-                for (int i = 0; i < input_size; i++)
-                    inputs_grad(isample, i) *= norm_factor;
-            }
-        else
-            for (int isample = 0; isample < n_samples; isample++)
-            {
-                for (int i = 0; i < input_size; i++)
-                {
-                    qi = inputs(isample, i);
-                    if (alpha > 0.0 )
-                        inputs_grad(isample, i) -= alpha*deriv_func_pascal(inputs_expectation[i])
-                                                        *(real)(input_size-1);
-                    for (int j = 0; j < i; j++)
-                    {
-                        real d_temp = deriv_func_pascal(inputs_cross_quadratic_mean(i,j));
-                        qj = inputs(isample,j);
-                        inputs_grad(isample, i) += d_temp *qj;
+                    real d_temp = deriv_func_(inputs_cross_quadratic_mean(i,j));
+                    qj = inputs(isample,j);
+                    inputs_grad(isample, i) += d_temp *qj;
+	            if( bprop_all_terms )
                         inputs_grad(isample, j) += d_temp *qi;
-                    }
                 }
-                for (int i = 0; i < input_size; i++)
-                    inputs_grad(isample, i) *= norm_factor;
             }
+            for (int i = 0; i < input_size; i++)
+                inputs_grad(isample, i) *= norm_factor * (1.-momentum);
+        }
     } // END cost_function == "pascal"
 
     else if( cost_function == "correlation")
     {
         computeCorrelationStatistics( inputs );
 
-        if( momentum > 0.0 )
-            PLERROR( "not implemented yet");
-        else
+        real average_deriv_tmp = 0.;
+        for (int isample = 0; isample < n_samples; isample++)
         {
-            real average_deriv_tmp = 0.;
-            for (int isample = 0; isample < n_samples; isample++)
+            real qi, qj;
+            Vec dSTDi_dqi( input_size ), dCROSSij_dqj( input_size );
+            for (int i = 0; i < input_size; i++)
             {
-                Vec dSTDi_dqi, dCROSSij_dqj;
-                dSTDi_dqi.resize( input_size );
-                dCROSSij_dqj.resize( input_size );
+                if( fast_exact_is_equal( inputs_stds[i], 0. ) )
+                {
+                    if( isample == 0 )
+                        PLWARNING("wired phenomenon: the %dth output have always expectation %f ( at stage=%d )",
+                                   i, inputs_expectation[i], stage);
+                    if( inputs_expectation[i] < 0.1 )
+                    {
+                        // We force to switch on the neuron
+                        // (the cost increase much when the expectation is decreased \ 0)
+                        if( ( isample > 0 ) || ( n_samples == 1 ) )
+                             inputs_grad(isample, i) -= average_deriv;
+                    }
+                    else if( inputs_expectation[i] > 0.9 )
+                    {
+                        // We force to switch off the neuron
+                        // (the cost increase much when we the expectation is increased / 1)
+                        // except for the first sample
+                        if( ( isample > 0 ) || ( n_samples == 1 ) )
+                            inputs_grad(isample, i) += average_deriv;
+                    }
+                    else
+                        if ( !(inputs_expectation[i]>-REAL_MAX) || !(inputs_expectation[i]<REAL_MAX)  )
+                           PLERROR("The %dth output have always value %f ( at stage=%d )",
+                                    i, inputs_expectation[i], stage);
+                    continue;
+                }
+                //!  dCROSSij_dqj[i] = d[ E(QiQj)-E(Qi)E(Qj) ]/d[qj(t)]
+                //!                  = ( qi(t) - E(Qi) ) / n_samples 
+                //!
+                //!  dSTDi_dqi[i] = d[ STD(Qi) ]/d[qi(t)]
+                //!               = d[ sqrt( E(Qi^2) -E(Qi)^2 ]/d[qi(t)]
+                //!               = 1 / [ 2.STD(Qi) ] * d[ E(Qi^2) -E(Qi)^2 ]/d[qi(t)]
+                //!               = 1 / [ 2.STD(Qi) ] * [ 2*qi(t) / n_samples - 2*E(Qi) / n_samples ]
+                //!               = ( qi(t) - E(Qi) ) / ( n_samples * STD(Qi) )
+                //!               = dCROSSij_dqj[i] / STD(Qi)
 
-                for (int i = 0; i < input_size; i++)
+                qi = inputs(isample, i);
+                dCROSSij_dqj[i] = ( qi - inputs_expectation[i] ); //*one_count;
+                dSTDi_dqi[i] = dCROSSij_dqj[i] / inputs_stds[i];
+
+                for (int j = 0; j < i; j++)
                 {
-                    if( fast_exact_is_equal( inputs_stds[i], 0. ) )
-                    {
-                        if( isample == 0 )
-                            PLWARNING("wired phenomenon: the %dth output have always expectation %f ( at stage=%d )",
-                                       i, inputs_expectation[i], stage);
-                        if( inputs_expectation[i] < 0.1 )
-                        {
-              	            // We force to switch on the neuron
-                            // (the cost increase much when the expectation is decreased \ 0)
-                            if( ( isample > 0 ) || ( n_samples == 1 ) )
-                                 inputs_grad(isample, i) -= average_deriv;
-                        }
-                        else if( inputs_expectation[i] > 0.9 )
-                        {
-                            // We force to switch off the neuron
-                            // (the cost increase much when we the expectation is increased / 1)
-                            // except for the first sample
-                            if( ( isample > 0 ) || ( n_samples == 1 ) )
-                                inputs_grad(isample, i) += average_deriv;
-                        }
-                        else
-                            if ( !(inputs_expectation[i]>-REAL_MAX) || !(inputs_expectation[i]<REAL_MAX)  )
-                               PLERROR("The %dth output have always value %f ( at stage=%d )",
-                                        i, inputs_expectation[i], stage);
+                    if( fast_exact_is_equal( inputs_correlations(i,j), 0.) )
+		    {
+			if (isample == 0)
+			    PLWARNING("correlation(i,j)=0 for i=%d, j=%d", i, j);
                         continue;
                     }
-                    //!  dCROSSij_dqj[i] = d[ E(QiQj)-E(Qi)E(Qj) ]/d[qj(t)]
-                    //!                  = ( qi(t) - E(Qi) ) / n_samples 
-                    //!
-                    //!  dSTDi_dqi[i] = d[ STD(Qi) ]/d[qi(t)]
-                    //!               = d[ sqrt( E(Qi^2) -E(Qi)^2 ]/d[qi(t)]
-                    //!               = 1 / [ 2.STD(Qi) ] * d[ E(Qi^2) -E(Qi)^2 ]/d[qi(t)]
-                    //!               = 1 / [ 2.STD(Qi) ] * [ 2*qi(t) / n_samples - 2*E(Qi) / n_samples ]
-                    //!               = ( qi(t) - E(Qi) ) / ( n_samples * STD(Qi) )
-                    //!               = dCROSSij_dqj[i] / STD(Qi)
+                    qj = inputs(isample,j);
+                    real correlation_denum = inputs_stds[i]*inputs_stds[j];
+		    real squared_correlation_denum = correlation_denum * correlation_denum;
+                    if( fast_exact_is_equal( squared_correlation_denum, 0. ) )
+                        continue;
+                    real dfunc_dCorr = deriv_func_( inputs_correlations(i,j) );
+                    real correlation_num = ( inputs_cross_quadratic_mean(i,j)
+                                             - inputs_expectation[i]*inputs_expectation[j] );
 
-                    qi = inputs(isample, i);
-                    dCROSSij_dqj[i] = ( qi - inputs_expectation[i] ); //*one_count;
-                    dSTDi_dqi[i] = dCROSSij_dqj[i] / inputs_stds[i];
+                    if( correlation_num/correlation_denum - inputs_correlations(i,j) > 0.0000001 )
+			PLERROR( "num/denum (%f) <> correlation (%f) for (i,j)=(%d,%d)",
+				 correlation_num/correlation_denum, inputs_correlations(i,j),i,j);
 
-                    for (int j = 0; j < i; j++)
-                    {
-                        qj = inputs(isample,j);
+                    inputs_grad(isample, i) += dfunc_dCorr * ( 
+                                                 correlation_denum * dCROSSij_dqj[j]
+                                               - correlation_num * dSTDi_dqi[i] * inputs_stds[j]
+                                                 ) / squared_correlation_denum;
 
-                        real correlation_denum = inputs_stds[i]*inputs_stds[j];
-                        //if( fast_exact_is_equal( inputs_stds[j], 0 ) (but because of numerical imprecision...)
-                        if( fast_exact_is_equal( correlation_denum * correlation_denum, 0. ) )
-                            continue;
-                        real dfunc_dCorr = deriv_func_correlation( inputs_correlations(i,j) );
-                        real correlation_num = ( inputs_cross_quadratic_mean(i,j)
-                                                 - inputs_expectation[i]*inputs_expectation[j] );
-                        inputs_grad(isample, i) += dfunc_dCorr * ( 
-                                                     correlation_denum * dCROSSij_dqj[j]
-                                                   - correlation_num * dSTDi_dqi[i] * inputs_stds[j]
-                                                     ) / (correlation_denum * correlation_denum);
-
-                        inputs_grad(isample, j) += dfunc_dCorr * ( 
+                    if( bprop_all_terms )
+			inputs_grad(isample, j) += dfunc_dCorr * ( 
                                                      correlation_denum * dCROSSij_dqj[i]
                                                    - correlation_num * dSTDi_dqi[j] * inputs_stds[i]
-                                                     ) / (correlation_denum * correlation_denum);
-                    }
+                                                     ) / squared_correlation_denum;
                 }
-                for (int i = 0; i < input_size; i++)
-                {
-                    average_deriv_tmp += fabs( inputs_grad(isample, i) );
-                    inputs_grad(isample, i) *= norm_factor;
-                }
             }
-            average_deriv = average_deriv_tmp / (real)( input_size * n_samples );
-            PLASSERT( average_deriv >= 0.);
+            for (int i = 0; i < input_size; i++)
+            {
+                average_deriv_tmp += fabs( inputs_grad(isample, i) );
+                inputs_grad(isample, i) *= norm_factor * (1.-momentum);
+            }
         }
+        average_deriv = average_deriv_tmp / (real)( input_size * n_samples );
+        PLASSERT( average_deriv >= 0.);
     } // END cost_function == "correlation"
 
     else
@@ -949,19 +1004,45 @@
         }
     }
 }
-string LayerCostModule::func_pascal_prefix() const
+
+real LayerCostModule::func_(real value) const
 {
-    string prefix = "exp";
-    return prefix;
+    if( SQUARE_FUNC )
+        return value * value;
+    if( POW4_FUNC )
+        return value * value * value * value;
+    if( LOG_FUNC )
+    {
+        if( fast_is_equal( value, 1. ) || value > 1. )
+            return REAL_MAX;
+        return -safeflog( 1.-value );
+    }
+    if( EXP_FUNC )
+        return exp(value);
+    if( LINEAR_FUNC )
+        return value;
+    PLERROR("in LayerCostModule::func_() no boolean *_FUNC has been set.");
+    return REAL_MAX;
 }
-real LayerCostModule::func_pascal(real value) const
+real LayerCostModule::deriv_func_(real value) const
 {
-    return exp(value);
+    if( SQUARE_FUNC )
+        return 2. * value;
+    if( POW4_FUNC )
+        return 4. * value * value * value;
+    if( LOG_FUNC )
+    {
+        if( fast_is_equal( value, 1. ) )
+           return REAL_MAX;
+        return 1. / (1. - value);
+    }
+    if( EXP_FUNC )
+        return exp(value);
+    if( LINEAR_FUNC )
+        return 1.;
+    PLERROR("in LayerCostModule::deriv_func_() no boolean *_FUNC has been set.");
+    return REAL_MAX;
 }
-real LayerCostModule::deriv_func_pascal(real value) const
-{
-    return exp(value);
-}
 
 
 void LayerCostModule::computeCorrelationStatistics(const Mat& inputs)
@@ -971,6 +1052,10 @@
                                  inputs_stds, inputs_correlations);
 }
 
+//! CAUTION: Be careful
+//! 'cross_quadratic_mean' and 'correlations' matrices
+//!  are computed ONLY on the triangle subpart 'i'>='j'
+//!  if we note 'i' (resp.'j') the first (reps.second) coordinate
 void LayerCostModule::computeCorrelationStatistics(const Mat& inputs,
                                                    Vec& expectation, Mat& cross_quadratic_mean,
                                                    Vec& stds, Mat& correlations) const
@@ -1002,52 +1087,70 @@
 
     for (int i = 0; i < input_size; i++)
     {
-        //! Normalization
+        //! Normalization (1/2)
         expectation[i] *= one_count;
         cross_quadratic_mean(i,i) *= one_count;
 
-	//! Required temporary variable because of numerical imprecision !//
-	real tmp = cross_quadratic_mean(i,i) - expectation[i] * expectation[i];
-	if( tmp > 0. )
-	    stds[i] = sqrt( tmp );
-
+        if( fast_is_equal(momentum, 0.)
+	||  !during_training )
+        {
+ 	    //! Computation of the standard deviations
+	    //! requires temporary variable because of numerical imprecision
+	    real tmp = cross_quadratic_mean(i,i) - expectation[i] * expectation[i];
+	    if( tmp > 0. )  //  std[i] = 0 by default
+	        stds[i] = sqrt( tmp );
+        }
+	
         for (int j = 0; j < i; j++)
         {
-            //! Normalization
+            //! Normalization (2/2)
             cross_quadratic_mean(i,j) *= one_count;
 
-            //! Correlations
-	    tmp = stds[i] * stds[j];
-            if( tmp > 0. )
-	        correlations(i,j) = (
-                                  cross_quadratic_mean(i,j)
-                                  - expectation[i]*expectation[j]
-                                  ) / tmp;
+            if( fast_is_equal(momentum, 0.)
+	    ||  !during_training )
+            {	    
+	        //! Correlations
+	        real tmp = stds[i] * stds[j];
+                if( !fast_is_equal(tmp, 0.) )  //  correlations(i,j) = 1 by default
+	            correlations(i,j) = ( cross_quadratic_mean(i,j)
+                                          - expectation[i]*expectation[j] ) / tmp;
+            }
         }
     }
-    //! Be careful: 'correlations' matrix is only computed
-    //!  on the triangle subpart 'i' > 'j'
-    //!  ('i'/'j': first/second argument)
 
-    if(  during_training )
+    if( !fast_is_equal(momentum, 0.) && during_training )
     {
-        if( momentum > 0.0 )
-            PLERROR("not implemented yet");
+        for (int i = 0; i < input_size; i++)
+        {
+            expectation[i] = momentum*inputs_expectation_trainMemory[i]
+                             +(1.0-momentum)*expectation[i];
+
+            inputs_expectation_trainMemory[i] = expectation[i];
+
+            cross_quadratic_mean(i,i) = momentum*inputs_cross_quadratic_mean_trainMemory(i,i)
+                                        +(1.0-momentum)*cross_quadratic_mean(i,i);
+            inputs_cross_quadratic_mean_trainMemory(i,i) = cross_quadratic_mean(i,i);
+
+	    real tmp = cross_quadratic_mean(i,i) - expectation[i] * expectation[i];
+	    if( tmp > 0. )  //  std[i] = 0 by default
+	        stds[i] = sqrt( tmp );
+	    
+            for (int j = 0; j < i; j++)
+            {
+                 cross_quadratic_mean(i,j) = momentum*inputs_cross_quadratic_mean_trainMemory(i,j)
+                                             +(1.0-momentum)*cross_quadratic_mean(i,j);
+                 inputs_cross_quadratic_mean_trainMemory(i,j) = cross_quadratic_mean(i,j);
+
+	         tmp = stds[i] * stds[j];
+                 if( !fast_is_equal(tmp, 0.) )  //  correlations(i,j) = 1 by default
+	             correlations(i,j) = ( cross_quadratic_mean(i,j)
+                                         - expectation[i]*expectation[j] ) / tmp;
+
+            }
+        }
     }
 }
-string LayerCostModule::func_correlation_prefix() const
-{
-    string prefix = "exp";
-    return prefix;
-}
-real LayerCostModule::func_correlation(real correlation) const
-{
-    return exp(correlation);
-}
-real LayerCostModule::deriv_func_correlation(real correlation) const
-{
-    return exp(correlation);
-}
+
 /////////////////////////
 // Auxiliary Functions //
 /////////////////////////

Modified: trunk/plearn_learners/online/LayerCostModule.h
===================================================================
--- trunk/plearn_learners/online/LayerCostModule.h	2007-11-21 21:41:36 UTC (rev 8281)
+++ trunk/plearn_learners/online/LayerCostModule.h	2007-11-22 21:55:10 UTC (rev 8282)
@@ -61,12 +61,15 @@
     //! Maximum number of stages we want to propagate the gradient    
     int nstages_max;
 
-    //! Parameter in pascal's cost function
-    real alpha;
-    
     //! Parameter to compute moving means in non stochastic cost functions
     real momentum;
 
+    //! Kind of optimization
+    string optimization_strategy;
+    
+    //! Parameter in pascal's cost function
+    real alpha;    
+
     //! For non stochastic KL divergence cost function
     int histo_size;
 
@@ -83,8 +86,8 @@
     Vec inputs_expectation;
     Vec inputs_stds;         //! only for 'correlation' cost function
 
+    Mat inputs_cross_quadratic_mean;
     Mat inputs_correlations; //! only for 'correlation' cost function
-    Mat inputs_cross_quadratic_mean;
 
     //! Variables for (non stochastic) Pascal's/correlation function with momentum
     //! -------------------------------------------------------------
@@ -92,6 +95,10 @@
     Vec inputs_expectation_trainMemory;
     Mat inputs_cross_quadratic_mean_trainMemory;
 
+    //! The function applied to the local cost between 2 inputs
+    //! to obtain the global cost (after averaging)
+    string penalty_function;
+
     //! The generic name of the cost function
     string cost_function_completename;
 
@@ -132,19 +139,14 @@
     virtual void computePascalStatistics(const Mat& inputs);
     virtual void computePascalStatistics(const Mat& inputs,
                                          Vec& expectation, Mat& cross_quadratic_mean) const;
-    virtual string func_pascal_prefix() const;
-    virtual real   func_pascal(real correlation) const;
-    virtual real   deriv_func_pascal(real correlation) const;
+    virtual real func_(real correlation) const;
+    virtual real deriv_func_(real correlation) const;
 
     //! Auxiliary function for the correlation's cost function
     virtual void computeCorrelationStatistics(const Mat& inputs);
     virtual void computeCorrelationStatistics(const Mat& inputs,
                                               Vec& expectation, Mat& cross_quadratic_mean,
-                                              Vec& stds, Mat& correlations) const;
-    virtual string func_correlation_prefix() const;
-    virtual real   func_correlation(real correlation) const;
-    virtual real   deriv_func_correlation(real correlation) const;
-
+                                              Vec& stds, Mat& correlations) const;    
     //! Returns all ports in a RBMModule.
     virtual const TVec<string>& getPorts();
 
@@ -179,9 +181,19 @@
 
 protected:
 
+    bool LINEAR_FUNC;
+    bool SQUARE_FUNC;
+    bool POW4_FUNC;
+    bool EXP_FUNC;
+    bool LOG_FUNC;
+
     //! Number of stage the BPropAccUpdate function was called
     int stage;
 
+    //! Boolean determined by the optimization_strategy
+    bool bprop_all_terms;
+    bool random_index_during_bprop;
+
     //! Does stochastic gradient (without memory of the past)
     //! makes sense with our cost function?
     bool is_cost_function_stochastic;



From nouiz at mail.berlios.de  Fri Nov 23 17:23:03 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 17:23:03 +0100
Subject: [Plearn-commits] r8283 - trunk/plearn_learners/hyper
Message-ID: <200711231623.lANGN3U9029494@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 17:23:03 +0100 (Fri, 23 Nov 2007)
New Revision: 8283

Modified:
   trunk/plearn_learners/hyper/HyperOptimize.cc
Log:
better error msg


Modified: trunk/plearn_learners/hyper/HyperOptimize.cc
===================================================================
--- trunk/plearn_learners/hyper/HyperOptimize.cc	2007-11-22 21:55:10 UTC (rev 8282)
+++ trunk/plearn_learners/hyper/HyperOptimize.cc	2007-11-23 16:23:03 UTC (rev 8283)
@@ -291,9 +291,10 @@
 
     TVec<string> option_vals = oracle->generateFirstTrial();
     if (option_vals.size() != option_names.size())
-        PLERROR("HyperOptimize::optimize: the number of option values (%d) "
-                "does not match the number of option names (%d)",
-                option_vals.size(), option_names.size());
+        PLERROR("HyperOptimize::optimize: the number (%d) of option values (%s) "
+                "does not match the number (%d) of option names (%s) ",
+                option_vals.size(), tostring(option_vals).c_str(),
+                option_names.size(), tostring(option_names).c_str());
 
     int trialnum = 0;
 



From nouiz at mail.berlios.de  Fri Nov 23 17:23:30 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 17:23:30 +0100
Subject: [Plearn-commits] r8284 - trunk/plearn_learners/hyper
Message-ID: <200711231623.lANGNUxf029568@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 17:23:30 +0100 (Fri, 23 Nov 2007)
New Revision: 8284

Modified:
   trunk/plearn_learners/hyper/EarlyStoppingOracle.cc
Log:
Added warning


Modified: trunk/plearn_learners/hyper/EarlyStoppingOracle.cc
===================================================================
--- trunk/plearn_learners/hyper/EarlyStoppingOracle.cc	2007-11-23 16:23:03 UTC (rev 8283)
+++ trunk/plearn_learners/hyper/EarlyStoppingOracle.cc	2007-11-23 16:23:30 UTC (rev 8284)
@@ -125,6 +125,9 @@
                     "Maybe you forgot that the end part of the range is not "
                     "included!");
     }
+    if(option_values.length()==0)
+        PLWARNING("In EarlyStoppingOracle::build_ - no range selected.");
+  
 }
 
 // ### Nothing to add here, simply calls build_



From nouiz at mail.berlios.de  Fri Nov 23 17:23:58 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 17:23:58 +0100
Subject: [Plearn-commits] r8285 - trunk/plearn_learners/generic
Message-ID: <200711231623.lANGNwZp029596@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 17:23:58 +0100 (Fri, 23 Nov 2007)
New Revision: 8285

Modified:
   trunk/plearn_learners/generic/AddCostToLearner.cc
Log:
corrected error msg


Modified: trunk/plearn_learners/generic/AddCostToLearner.cc
===================================================================
--- trunk/plearn_learners/generic/AddCostToLearner.cc	2007-11-23 16:23:30 UTC (rev 8284)
+++ trunk/plearn_learners/generic/AddCostToLearner.cc	2007-11-23 16:23:58 UTC (rev 8285)
@@ -573,7 +573,7 @@
             if (the_target >= n_classes
                 ||is_missing(the_target))
                 PLERROR("In AddCostToLearner::computeCostsFromOutputs - bad output value of the_target=%f, missing or higher or egual to n_classes (%d)",
-                        desired_target[confusion_matrix_target], n_classes);
+                        the_target, n_classes);
 #endif
             for(int local_ind = ind_cost ; local_ind < (n_classes*n_classes+ind_cost); local_ind++){
                 costs[local_ind] = 0;



From nouiz at mail.berlios.de  Fri Nov 23 17:24:44 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 17:24:44 +0100
Subject: [Plearn-commits] r8286 - trunk/plearn_learners/regressors
Message-ID: <200711231624.lANGOixB029640@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 17:24:44 +0100 (Fri, 23 Nov 2007)
New Revision: 8286

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
Log:
bugfix in case the length is 0


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-23 16:23:58 UTC (rev 8285)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-23 16:24:44 UTC (rev 8286)
@@ -157,6 +157,12 @@
 
 void RegressionTreeLeave::getOutputAndError(Vec& output, Vec& error)
 {
+    if(length==0){
+        output.clear();
+        error.clear();
+        return;
+    }
+        
     output[0] = weighted_targets_sum / weights_sum;
     if (missing_leave == true)
     {



From nouiz at mail.berlios.de  Fri Nov 23 17:48:54 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 17:48:54 +0100
Subject: [Plearn-commits] r8287 - trunk/plearn_learners/regressors
Message-ID: <200711231648.lANGmsUe030676@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 17:48:53 +0100 (Fri, 23 Nov 2007)
New Revision: 8287

Modified:
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/RegressionTreeNode.h
Log:
removed parameter that can be localised. 


Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-23 16:24:44 UTC (rev 8286)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-23 16:48:53 UTC (rev 8287)
@@ -92,10 +92,6 @@
                   "The node for the missing values when missing_is_valid is set to 1\n");
     declareOption(ol, "missing_leave", &RegressionTreeNode::missing_leave, OptionBase::learntoption,
                   "The leave containing rows with missing values after split\n");
-    declareOption(ol, "missing_output", &RegressionTreeNode::missing_output, OptionBase::learntoption,
-                  "The mising leave output vector\n");
-    declareOption(ol, "missing_error", &RegressionTreeNode::missing_error, OptionBase::learntoption,
-                  "The missing leave error vector\n");
     declareOption(ol, "left_node", &RegressionTreeNode::left_node, OptionBase::learntoption,
                   "The node on the left of the split decision\n");
     declareOption(ol, "left_leave", &RegressionTreeNode::left_leave, OptionBase::learntoption,
@@ -111,12 +107,19 @@
     declareOption(ol, "right_error", &RegressionTreeNode::tmp_vec,
                   OptionBase::learntoption | OptionBase::nosave,
                   "DEPRECATED The right leave error vector\n");
+    declareOption(ol, "missing_error", &RegressionTreeNode::tmp_vec,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The missing leave error vector\n");
     declareOption(ol, "left_output", &RegressionTreeNode::tmp_vec,
                   OptionBase::learntoption | OptionBase::nosave,
                   "DEPRECATED The left leave output vector\n");
     declareOption(ol, "right_output", &RegressionTreeNode::tmp_vec,
                   OptionBase::learntoption | OptionBase::nosave,
                   "DEPRECATED The right leave output vector\n");
+    declareOption(ol, "missing_output", &RegressionTreeNode::tmp_vec,
+                  OptionBase::learntoption | OptionBase::nosave,
+                  "DEPRECATED The mising leave output vector\n");
+
     declareOption(ol, "right_leave_id", &RegressionTreeNode::dummy_int,
                   OptionBase::learntoption | OptionBase::nosave,
                   "DEPRECATED The id of the right leave\n");     
@@ -156,8 +159,6 @@
     deepCopyField(after_split_error, copies);
     deepCopyField(missing_node, copies);
     deepCopyField(missing_leave, copies);
-    deepCopyField(missing_output, copies);
-    deepCopyField(missing_error, copies);
     deepCopyField(left_node, copies);
     deepCopyField(left_leave, copies);
     deepCopyField(right_node, copies);
@@ -199,8 +200,6 @@
 
     leave_output.resize(2);
     leave_error.resize(3);
-    missing_output.resize(2);
-    missing_error.resize(3);
 
     leave->getOutputAndError(leave_output,leave_error);
 }
@@ -213,6 +212,7 @@
     tmp_vec.resize(2);
     Vec left_error(3);
     Vec right_error(3);
+    Vec missing_error(3);
     int leave_id = leave->id;
     for (int col = 0; col < train_set->inputsize(); col++)
     {
@@ -232,6 +232,7 @@
                 candidate.append(row);
             }
         }
+        missing_leave->getOutputAndError(tmp_vec, missing_error);
         if(candidate.size()==0)
             return;
         int row = candidate.pop();
@@ -240,14 +241,14 @@
             int next_row = candidate.pop();
             left_leave->removeRow(row, tmp_vec, left_error);
             right_leave->addRow(row, tmp_vec, right_error);
-            compareSplit(col, train_set->get(next_row, col), train_set->get(row, col), left_error, right_error);
+            compareSplit(col, train_set->get(next_row, col), train_set->get(row, col), left_error, right_error, missing_error);
             row = next_row;
         }
     }
 }
 
 void RegressionTreeNode::compareSplit(int col, real left_leave_last_feature, real right_leave_first_feature,
-                                      Vec left_error, Vec right_error )
+                                      Vec left_error, Vec right_error, Vec missing_error)
 {
     PLASSERT(left_leave_last_feature<=right_leave_first_feature);
     if (left_leave_last_feature >= right_leave_first_feature) return;
@@ -298,8 +299,6 @@
         }
     }
 
-    missing_leave->getOutputAndError(missing_output, missing_error);
-
     PLASSERT(left_leave->length>0);
     PLASSERT(right_leave->length>0);
     PLASSERT(left_leave->length + right_leave->length + missing_leave->length
@@ -375,10 +374,7 @@
             missing_node->computeOutput(inputv, outputv);
         }
         else
-        {
-            outputv[0] = missing_output[0];
-            outputv[1] = missing_output[1];
-        }
+            missing_leave->getOutputAndError(outputv,tmp_vec);
         return;
     }
     if (inputv[split_col] > split_feature_value)

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-23 16:24:44 UTC (rev 8286)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.h	2007-11-23 16:48:53 UTC (rev 8287)
@@ -71,8 +71,6 @@
  
     Vec leave_output;
     Vec leave_error;
-    Vec missing_output;
-    Vec missing_error;
     int split_col;
     int split_balance;
     real split_feature_value;
@@ -98,7 +96,7 @@
     void         initNode(PP<RegressionTreeRegisters> train_set, PP<RegressionTreeLeave> leave, PP<RegressionTreeLeave> leave_template);
     void         lookForBestSplit();
     void         compareSplit(int col, real left_leave_last_feature, real right_leave_first_feature,
-                              Vec left_error, Vec right_error);
+                              Vec left_error, Vec right_error, Vec missing_error);
     int          expandNode();
     int          getSplitBalance();
     real         getErrorImprovment();



From nouiz at mail.berlios.de  Fri Nov 23 18:37:29 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 18:37:29 +0100
Subject: [Plearn-commits] r8288 - trunk/plearn_learners/regressors
Message-ID: <200711231737.lANHbTCU017655@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 18:37:28 +0100 (Fri, 23 Nov 2007)
New Revision: 8288

Modified:
   trunk/plearn_learners/regressors/RegressionTree.cc
   trunk/plearn_learners/regressors/RegressionTree.h
Log:
-removed function that is the same as its parent class.
-initStat of the leave template


Modified: trunk/plearn_learners/regressors/RegressionTree.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTree.cc	2007-11-23 16:48:53 UTC (rev 8287)
+++ trunk/plearn_learners/regressors/RegressionTree.cc	2007-11-23 17:37:28 UTC (rev 8288)
@@ -238,13 +238,14 @@
     leave_template->setOption("missing_leave", "0");
     leave_template->setOption("loss_function_weight", tostring(loss_function_weight));
     leave_template->setOption("verbosity", tostring(verbosity));
+    leave_template->initStats();
 
     first_leave_output.resize(2);
     first_leave_error.resize(3);
     first_leave = ::PLearn::deepCopy(leave_template);
     first_leave->setOption("id", tostring(sorted_train_set->getNextId()));
     first_leave->initLeave(sorted_train_set);
-    first_leave->initStats();
+
     for (each_train_sample_index = 0; each_train_sample_index < length; each_train_sample_index++)
     {
         first_leave->addRow(each_train_sample_index, first_leave_output, first_leave_error);
@@ -335,12 +336,6 @@
     outputv[0] = closest_value;
 }
 
-void RegressionTree::computeOutputAndCosts(const Vec& inputv, const Vec& targetv, Vec& outputv, Vec& costsv) const
-{
-    computeOutput(inputv, outputv);
-    computeCostsFromOutputs(inputv, outputv, targetv, costsv);
-}
-
 void RegressionTree::computeCostsFromOutputs(const Vec& inputv, const Vec& outputv, const Vec& targetv, Vec& costsv) const
 {
     costsv[0] = pow((outputv[0] - targetv[0]), 2);

Modified: trunk/plearn_learners/regressors/RegressionTree.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTree.h	2007-11-23 16:48:53 UTC (rev 8287)
+++ trunk/plearn_learners/regressors/RegressionTree.h	2007-11-23 17:37:28 UTC (rev 8288)
@@ -112,7 +112,6 @@
     virtual TVec<string> getTrainCostNames() const;
     virtual TVec<string> getTestCostNames() const;
     virtual void         computeOutput(const Vec& input, Vec& output) const;
-    virtual void         computeOutputAndCosts(const Vec& input, const Vec& target, Vec& output, Vec& costs) const;
     virtual void         computeCostsFromOutputs(const Vec& input, const Vec& output, const Vec& target, Vec& costs) const;
     void         setSortedTrainSet(PP<RegressionTreeRegisters> the_sorted_train_set);
   



From tihocan at mail.berlios.de  Fri Nov 23 20:18:46 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 23 Nov 2007 20:18:46 +0100
Subject: [Plearn-commits] r8289 - trunk/plearn/vmat
Message-ID: <200711231918.lANJIkYc023834@sheep.berlios.de>

Author: tihocan
Date: 2007-11-23 20:18:45 +0100 (Fri, 23 Nov 2007)
New Revision: 8289

Modified:
   trunk/plearn/vmat/RandomSamplesVMatrix.cc
   trunk/plearn/vmat/RandomSamplesVMatrix.h
Log:
Added a new option 'alternate_targets' to ensure no two examples of the same class are sampled consecutively.


Modified: trunk/plearn/vmat/RandomSamplesVMatrix.cc
===================================================================
--- trunk/plearn/vmat/RandomSamplesVMatrix.cc	2007-11-23 17:37:28 UTC (rev 8288)
+++ trunk/plearn/vmat/RandomSamplesVMatrix.cc	2007-11-23 19:18:45 UTC (rev 8289)
@@ -65,6 +65,7 @@
 // RandomSamplesVMatrix //
 //////////////////////////////
 RandomSamplesVMatrix::RandomSamplesVMatrix():
+    alternate_targets(false),
     is_preserved("0"),
     n_non_preserved(-1),
     seed(1827),
@@ -100,6 +101,12 @@
         " -2: the number of non-preserved examples is set exactly to match\n"
         "     the number of preserved examples.");
 
+    declareOption(ol, "alternate_targets",
+                  &RandomSamplesVMatrix::alternate_targets,
+                  OptionBase::buildoption,
+        "If set to 1, then this VMat will never sample two consecutive rows\n"
+        "having the same target.");
+
     declareOption(ol, "seed", &RandomSamplesVMatrix::seed,
                               OptionBase::buildoption,
         "Seed for random number generation.");
@@ -158,6 +165,62 @@
     else if (length_ < 0)
         length_ = source->length();
 
+    // Specific pre-processing for the case where 'alternate_targets' is true.
+    if (alternate_targets) {
+        // Currently this feature is not implemented when we preserve examples
+        // (just because it is a bit more complex).
+        if (!indices.isEmpty())
+            PLERROR("In RandomSamplesVMatrix::build_ - The 'alternate_targets'"
+                    " option is not implemented yet in the case where some "
+                    "examples are preserved. Please implement it!");
+        if (source->targetsize() != 1)
+            PLERROR("In RandomSamplesVMatrix::build_ - The source must have "
+                    "a targetsize of 1 in order to use the "
+                    "'alternate_targets' option");
+        // First we need to find the number of targets.
+        map<real, TVec<int> > by_target_map; // Map a target to its samples.
+        Vec input, target;
+        real weight;
+        target_to_idx.clear();
+        for (int i = 0; i < source->length(); i++) {
+            source->getExample(i, input, target, weight);
+            by_target_map[target[0]].append(i);
+            if (target_to_idx.count(target[0]) == 0) {
+                int n_cur = target_to_idx.size();
+                target_to_idx[target[0]] = n_cur;
+            }
+        }
+        int n_targets = by_target_map.size();
+        // Convert from map to vector (for convenience).
+        by_target.resize(n_targets);
+        map<real, TVec<int> >::const_iterator it = by_target_map.begin();
+        for (int i = 0; i < n_targets; i++, it++)
+            by_target[i] = it->second;
+        // Build a map from a target index to all other target indices that may
+        // be used afterwards, with corresponding probabilities.
+        target_list.resize(n_targets);
+        target_distr.resize(n_targets);
+        for (int i = 0; i < n_targets; i++) {
+            TVec<int>& tl = target_list[i];
+            tl.resize(0);
+            Vec& td = target_distr[i];
+            td.resize(0);
+            int n_others = 0;
+           
+            for (int j = 0; j < n_targets; j++)
+                if (j != i) {
+                    tl.append(j); // This is the list of all targets,
+                                  // excluding 'i'.
+                    td.append(by_target[j].length());
+                    n_others += by_target[j].length();
+                }
+            td /= real(n_others); // Normalize probabilities.
+        }
+
+        // Resize 'last_targets'.
+        last_targets.resize(source->length());
+    }
+
     // Fill in 'indices' with as many -1 as necessary.
     if (indices.length() > length_)
         PLERROR("In RandomSamplesVMatrix::build_ - The number of preserved"
@@ -180,9 +243,27 @@
     if (indices[i] >= 0)
         source->getRow(indices[i], v);
     else {
-        int random_sample =
-            random_gen->uniform_multinomial_sample(non_preserved.length());
+        int random_sample;
+        if (alternate_targets && i > 0) {
+            // Note that the first sample may be any class since it has no
+            // previous sample in this VMat.
+            real previous_target = last_targets[i - 1];
+            int previous_target_idx = target_to_idx[previous_target];
+            int random_target = random_gen->multinomial_sample(
+                    target_distr[previous_target_idx]);
+            const TVec<int>& candidates =
+                by_target[target_list[previous_target_idx][random_target]];
+            int random_sample_idx = random_gen->uniform_multinomial_sample(
+                    candidates.length());
+            random_sample = candidates[random_sample_idx];
+            PLASSERT( non_preserved.length() == source->length() );
+        } else {
+            random_sample =
+                random_gen->uniform_multinomial_sample(non_preserved.length());
+        }
         source->getRow(non_preserved[random_sample], v);
+        if (alternate_targets)
+            last_targets[i] = v[source->inputsize()];
     }
 }
 
@@ -196,6 +277,10 @@
     deepCopyField(random_gen,       copies);
     deepCopyField(non_preserved,    copies);
     deepCopyField(indices,          copies);
+    deepCopyField(last_targets,     copies);
+    deepCopyField(target_list,      copies);
+    deepCopyField(target_distr,     copies);
+    deepCopyField(by_target,        copies);
 }
 
 } // end of namespace PLearn

Modified: trunk/plearn/vmat/RandomSamplesVMatrix.h
===================================================================
--- trunk/plearn/vmat/RandomSamplesVMatrix.h	2007-11-23 17:37:28 UTC (rev 8288)
+++ trunk/plearn/vmat/RandomSamplesVMatrix.h	2007-11-23 19:18:45 UTC (rev 8289)
@@ -62,6 +62,7 @@
 public:
     //#####  Public Build Options  ############################################
 
+    bool alternate_targets;
     string is_preserved;
     int n_non_preserved;
     int32_t seed;
@@ -105,6 +106,23 @@
     //! be randomly sampled from the 'non_preserved' list.
     TVec<int> indices;
 
+    //! The i-th element is the last target used for the i-th row in this VMat.
+    Vec last_targets;
+
+    //! The i-th element is the list of all target indices, except i.
+    TVec< TVec<int> > target_list;
+
+    //! The i-th element is the distribution weights of all target indices,
+    //! except i (i.e. the distribution to sample from after an example of the
+    //! i-th target).
+    TVec< Vec > target_distr;
+
+    //! Map a real-valued target to its index.
+    mutable map<real, int> target_to_idx;
+
+    //! The i-th element is the list of all samples for the i-th target.
+    TVec< TVec<int> > by_target;
+
     //#####  Protected Options  ###############################################
 
 protected:



From nouiz at mail.berlios.de  Fri Nov 23 21:15:39 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 21:15:39 +0100
Subject: [Plearn-commits] r8290 - trunk/plearn/base
Message-ID: <200711232015.lANKFdEP026276@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 21:15:39 +0100 (Fri, 23 Nov 2007)
New Revision: 8290

Modified:
   trunk/plearn/base/stringutils.cc
   trunk/plearn/base/stringutils.h
Log:
changed the comment of place and made it be doxygen compatible


Modified: trunk/plearn/base/stringutils.cc
===================================================================
--- trunk/plearn/base/stringutils.cc	2007-11-23 19:18:45 UTC (rev 8289)
+++ trunk/plearn/base/stringutils.cc	2007-11-23 20:15:39 UTC (rev 8290)
@@ -364,10 +364,6 @@
     return res;
 }
 
-// One version where we allow to quote a delimiter so that it is not considered as a delimiter.
-// TODO: optimize...
-// the double_quote are only considered if at the boundary of deliminer.
-// should execute in O(n+k) where n is the number of character in s and k is the number of field in k.
 vector<string> split_quoted_delimiter(const string& s, char delimiter, string double_quote){
     if(double_quote.length()==1)
         PLASSERT(delimiter!=double_quote[0]);

Modified: trunk/plearn/base/stringutils.h
===================================================================
--- trunk/plearn/base/stringutils.h	2007-11-23 19:18:45 UTC (rev 8289)
+++ trunk/plearn/base/stringutils.h	2007-11-23 20:15:39 UTC (rev 8290)
@@ -169,6 +169,15 @@
 */
 vector<string> split(const string& s, const string& delimiters=" \t\n\r", bool keepdelimiters=false);
 
+/*! Split a string at deliminer while allowing a delimiter to be quoted so that it is not considered to be as a delimiter.
+  The double_quote are only considered at the boundary of the field.
+  The function should execute in O(n+k) where n is the number of character in s and k is the number of field in k.
+  The delimiter should not be the same as double_quote.
+  @param s the string to split
+  @param delimiter the caractere that separate the fields of s.
+  @double_quote a string that will surround a field if it containt delimiter caractere that should not consider generate a new field.
+  @todo optimize...
+*/
 vector<string> split_quoted_delimiter(const string& s, char delimiter, string double_quote);
 
 /*!     Split the string on the first occurence of a delimiter and returns 



From nouiz at mail.berlios.de  Fri Nov 23 21:16:36 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 21:16:36 +0100
Subject: [Plearn-commits] r8291 - trunk/plearn/vmat
Message-ID: <200711232016.lANKGaoI026326@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 21:16:36 +0100 (Fri, 23 Nov 2007)
New Revision: 8291

Modified:
   trunk/plearn/vmat/MemoryVMatrixNoSave.cc
   trunk/plearn/vmat/MemoryVMatrixNoSave.h
Log:
Added constructor


Modified: trunk/plearn/vmat/MemoryVMatrixNoSave.cc
===================================================================
--- trunk/plearn/vmat/MemoryVMatrixNoSave.cc	2007-11-23 20:15:39 UTC (rev 8290)
+++ trunk/plearn/vmat/MemoryVMatrixNoSave.cc	2007-11-23 20:16:36 UTC (rev 8291)
@@ -60,6 +60,15 @@
     // ### (doing so assumes the parent classes' build_() have been called too
     // ### in the parent classes' constructors, something that you must ensure)
 }
+MemoryVMatrixNoSave::MemoryVMatrixNoSave(int l, int w)
+    : inherited(l,w)
+{}
+MemoryVMatrixNoSave::MemoryVMatrixNoSave(const Mat& the_data)
+    : inherited(the_data)
+{}
+MemoryVMatrixNoSave::MemoryVMatrixNoSave(VMat the_source)
+    : inherited(the_source)
+{}
 
 ////////////////////
 // declareOptions //

Modified: trunk/plearn/vmat/MemoryVMatrixNoSave.h
===================================================================
--- trunk/plearn/vmat/MemoryVMatrixNoSave.h	2007-11-23 20:15:39 UTC (rev 8290)
+++ trunk/plearn/vmat/MemoryVMatrixNoSave.h	2007-11-23 20:16:36 UTC (rev 8291)
@@ -71,6 +71,9 @@
     // ### Make sure the implementation in the .cc
     // ### initializes all fields to reasonable default values.
     MemoryVMatrixNoSave();
+    MemoryVMatrixNoSave(const Mat& the_data);
+    MemoryVMatrixNoSave(int l, int w);
+    MemoryVMatrixNoSave(VMat the_source);
 
     //#####  PLearn::Object Protocol  #########################################
 



From louradou at mail.berlios.de  Fri Nov 23 21:35:36 2007
From: louradou at mail.berlios.de (louradou at BerliOS)
Date: Fri, 23 Nov 2007 21:35:36 +0100
Subject: [Plearn-commits] r8292 - in trunk: commands plearn_learners/online
Message-ID: <200711232035.lANKZaeI027602@sheep.berlios.de>

Author: louradou
Date: 2007-11-23 21:35:35 +0100 (Fri, 23 Nov 2007)
New Revision: 8292

Added:
   trunk/plearn_learners/online/LinearFilterModule.cc
   trunk/plearn_learners/online/LinearFilterModule.h
Modified:
   trunk/commands/plearn_noblas_inc.h
Log:
A Module to learn filter(s) applied to the input.
"Filter": instead of a matrix of weights as in GradNNetLayerModule,
we have here a vectors of weights.



Modified: trunk/commands/plearn_noblas_inc.h
===================================================================
--- trunk/commands/plearn_noblas_inc.h	2007-11-23 20:16:36 UTC (rev 8291)
+++ trunk/commands/plearn_noblas_inc.h	2007-11-23 20:35:35 UTC (rev 8292)
@@ -208,6 +208,7 @@
 #include <plearn_learners/online/IdentityModule.h>
 #include <plearn_learners/online/LayerCostModule.h>
 #include <plearn_learners/online/LinearCombinationModule.h>
+#include <plearn_learners/online/LinearFilterModule.h>
 #include <plearn_learners/online/MatrixModule.h>
 #include <plearn_learners/online/MaxSubsampling2DModule.h>
 #include <plearn_learners/online/ModuleLearner.h>

Added: trunk/plearn_learners/online/LinearFilterModule.cc
===================================================================
--- trunk/plearn_learners/online/LinearFilterModule.cc	2007-11-23 20:16:36 UTC (rev 8291)
+++ trunk/plearn_learners/online/LinearFilterModule.cc	2007-11-23 20:35:35 UTC (rev 8292)
@@ -0,0 +1,521 @@
+// -*- C++ -*-
+
+// LinearFilterModule.cc
+//
+// Copyright (C) 2005 Jerome Louradour
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************
+   * $Id: LinearFilterModule.cc,v 1.3 2006/01/18 04:04:06 lamblinp Exp $
+   ******************************************************* */
+
+// Authors: Jerome Louradour
+
+/*! \file LinearFilterModule.cc */
+
+
+#include "LinearFilterModule.h"
+#include <plearn/math/TMat_maths.h>
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    LinearFilterModule,
+    "Affine transformation module, with stochastic gradient descent updates",
+    "Neural Network layer, using stochastic gradient to update neuron weights\n"
+    "       Output = weights * Input + bias\n"
+    "Weights and bias are updated by online gradient descent, with learning\n"
+    "rate possibly decreasing in 1/(1 + n_updates_done * decrease_constant).\n"
+    "An L1 and L2 regularization penalty can be added to push weights to 0.\n"
+    "Weights can be initialized to 0, to a given initial matrix, or randomly\n"
+    "from a uniform distribution.\n"
+    );
+
+/////////////////////////
+// LinearFilterModule //
+/////////////////////////
+LinearFilterModule::LinearFilterModule():
+    start_learning_rate( .001 ),
+    decrease_constant( 0. ),
+    init_weights_random_scale( 1. ),
+    L1_penalty_factor( 0. ),
+    L2_penalty_factor( 0. ),
+    no_bias(false),
+    between_0_and_1(false),
+    step_number( 0 )
+{}
+
+///////////
+// fprop //
+///////////
+void LinearFilterModule::fprop(const Vec& input, Vec& output) const
+{
+    PLASSERT_MSG( input.size() == input_size,
+                  "input.size() should be equal to this->input_size" );
+
+    output.resize( output_size );
+
+    // Applies linear transformation
+    for( int i=0 ; i<output_size ; i++ )
+        output[i] = weights[i] * input[i % input_size] + bias[i];
+}
+
+void LinearFilterModule::fprop(const Mat& inputs, Mat& outputs)
+{
+    PLASSERT( inputs.width() == input_size );
+    int n = inputs.length();
+    outputs.resize(n, output_size);
+    for(int is=0;is<n;is++)
+        for(int i=0;i<output_size;i++)
+            outputs(is,i) = weights[i] * inputs(is, i % input_size);
+
+    // Add bias.
+    resizeOnes(n);
+    externalProductAcc(outputs, ones, bias); // could be more efficient, but not critical 
+}
+
+/////////////////
+// bpropUpdate //
+/////////////////
+// We are not using blas routines anymore, because we would iterate several
+// times over the weight matrix.
+void LinearFilterModule::bpropUpdate(const Vec& input, const Vec& output,
+                                      const Vec& output_gradient)
+{
+    PLASSERT_MSG( input.size() == input_size,
+                  "input.size() should be equal to this->input_size" );
+    PLASSERT_MSG( output.size() == output_size,
+                  "output.size() should be equal to this->output_size" );
+    PLASSERT_MSG( output_gradient.size() == output_size,
+                  "output_gradient.size() should be equal to this->output_size"
+                );
+
+    learning_rate = start_learning_rate / (1+decrease_constant*step_number);
+
+    for( int i=0; i<output_size; i++ )
+    {
+        real og_i = output_gradient[i];
+
+        real delta_L1 = learning_rate * L1_penalty_factor;
+        real delta_L2 = learning_rate * L2_penalty_factor;
+        if( delta_L2 > 1 )
+            PLWARNING("LinearFilterModule::bpropUpdate:\n"
+                      "learning rate = %f is too large!\n", learning_rate);
+
+        real lr_og_i = learning_rate * og_i;
+        if( !no_bias )
+            bias[i] -= lr_og_i;
+
+            if( delta_L2 > 0. )
+                weights[i] *= (1 - delta_L2);
+
+            weights[i] -= input[i % input_size] * lr_og_i;
+
+            if( delta_L1 > 0. )
+            {
+                if( weights[i] > delta_L1 )
+                    weights[i] -= delta_L1;
+                else if( weights[i] < -delta_L1 )
+                    weights[i] += delta_L1;
+                else
+                    weights[i] = 0.;
+            }
+            
+            if( between_0_and_1 )
+            {
+                if( weights[i] > 1. )
+                    weights[i] = 1.;
+                if( weights[i] < 0. )
+                    weights[i] = 0.;
+            }
+
+    }
+    step_number++;
+}
+
+
+// Simply updates and propagates back gradient
+void LinearFilterModule::bpropUpdate(const Vec& input, const Vec& output,
+                                      Vec& input_gradient,
+                                      const Vec& output_gradient,
+                                      bool accumulate)
+{
+    PLASSERT_MSG( input.size() == input_size,
+                  "input.size() should be equal to this->input_size" );
+    PLASSERT_MSG( output.size() == output_size,
+                  "output.size() should be equal to this->output_size" );
+    PLASSERT_MSG( output_gradient.size() == output_size,
+                  "output_gradient.size() should be equal to this->output_size"
+                );
+
+    if( accumulate )
+    {
+        PLASSERT_MSG( input_gradient.size() == input_size,
+                      "Cannot resize input_gradient AND accumulate into it" );
+    }
+    else
+    {
+        input_gradient.resize( input_size );
+        input_gradient.clear();
+    }
+
+    learning_rate = start_learning_rate / (1+decrease_constant*step_number);
+
+    for( int i=0; i<output_size; i++ )
+    {
+        real og_i = output_gradient[i];
+
+        real delta_L1 = learning_rate * L1_penalty_factor;
+        real delta_L2 = learning_rate * L2_penalty_factor;
+        if( delta_L2 > 1 )
+            PLWARNING("LinearFilterModule::bpropUpdate:\n"
+                      "learning rate = %f is too large!\n", learning_rate);
+
+        real lr_og_i = learning_rate * og_i;
+        if( !no_bias )
+            bias[i] -= lr_og_i;
+
+        input_gradient[i % input_size] += weights[i] * og_i;
+
+        if( delta_L2 > 0. )
+            weights[i] *= (1 - delta_L2);
+
+        weights[i] -= input[i % input_size] * lr_og_i;
+
+        if( delta_L1 > 0. )
+        {
+                if( weights[i] > delta_L1 )
+                    weights[i] -= delta_L1;
+                else if( weights[i] < -delta_L1 )
+                    weights[i] += delta_L1;
+                else
+                    weights[i] = 0.;
+        }
+            if( between_0_and_1 )
+            {
+                if( weights[i] > 1. )
+                    weights[i] = 1.;
+                if( weights[i] < 0. )
+                    weights[i] = 0.;
+            }
+    }
+    step_number++;
+}
+
+void LinearFilterModule::bpropUpdate(const Mat& inputs, const Mat& outputs,
+        Mat& input_gradients,
+        const Mat& output_gradients,
+        bool accumulate)
+{
+    PLASSERT( inputs.width() == input_size );
+    PLASSERT( outputs.width() == output_size );
+    PLASSERT( output_gradients.width() == output_size );
+
+    int n = inputs.length();
+
+    if( accumulate )
+    {
+        PLASSERT_MSG( input_gradients.width() == input_size &&
+                input_gradients.length() == n,
+                "Cannot resize input_gradients and accumulate into it" );
+    }
+    else
+    {
+        input_gradients.resize(n, input_size);
+        input_gradients.fill(0);
+    }
+
+    learning_rate = start_learning_rate / (1+decrease_constant*step_number);
+    real avg_lr = learning_rate / n; // To obtain an average on a mini-batch.
+
+    // With L2 regularization, weights are scaled by a coefficient equal to
+    // 1 - learning rate * penalty.
+    real l2_scaling =
+        L2_penalty_factor > 0 ? 1 - learning_rate * L2_penalty_factor
+                              : 1;
+    PLASSERT_MSG(l2_scaling > 0, "Learning rate too large");
+
+    // Compute input gradient.
+    for(int i_sample = 0; i_sample < outputs.length() ;i_sample++)
+        for(int i = 0; i < output_size; i++)
+            input_gradients(i_sample, i % input_size ) += weights[i] * output_gradients(i_sample,  i );
+
+    // Update bias.
+    if( !no_bias )
+    {
+        resizeOnes(n);
+        transposeProductScaleAcc(bias, output_gradients, ones, -avg_lr, real(1));
+    }
+    
+    // Update weights.
+    for(int i_sample = 0; i_sample < outputs.length() ;i_sample++)
+        for(int i = 0; i < output_size; i++ )
+        {
+            weights[i] -= avg_lr * l2_scaling * output_gradients(i_sample, i) * inputs(i_sample, i % input_size);
+            if( between_0_and_1 )
+            {
+                if( weights[i] > 1. )
+                    weights[i] = 1.;
+                if( weights[i] < 0. )
+                    weights[i] = 0.;
+            }
+        }
+
+    // Apply L1 penalty if needed (note: this is not very efficient).
+    if (L1_penalty_factor > 0) {
+        real delta_L1 = learning_rate * L1_penalty_factor;
+        for( int i=0; i<output_size; i++ )
+        {
+                if( weights[i] > delta_L1 )
+                    weights[i] -= delta_L1;
+                else if( weights[i] < -delta_L1 )
+                    weights[i] += delta_L1;
+                else
+                    weights[i] = 0.;
+        }
+    }
+    step_number += n;
+}
+    
+
+//////////////////
+// bbpropUpdate //
+//////////////////
+void LinearFilterModule::bbpropUpdate(const Vec& input, const Vec& output,
+                                       const Vec& output_gradient,
+                                       const Vec& output_diag_hessian)
+{
+    PLASSERT_MSG( output_diag_hessian.size() == output_size,
+                  "output_diag_hessian.size() should be equal to"
+                  " this->output_size" );
+    bpropUpdate( input, output, output_gradient );
+}
+
+/* This implementation is incorrect. Let the PLERROR defined in parent version
+// Propagates back output_gradient and output_diag_hessian
+void LinearFilterModule::bbpropUpdate(const Vec& input, const Vec& output,
+                                       Vec&  input_gradient,
+                                       const Vec& output_gradient,
+                                       Vec&  input_diag_hessian,
+                                       const Vec& output_diag_hessian,
+                                       bool accumulate)
+{
+    bpropUpdate( input, output, input_gradient, output_gradient, accumulate );
+}
+*/
+
+////////////
+// forget //
+////////////
+// Forget the bias and reinitialize the weights
+void LinearFilterModule::forget()
+{
+    learning_rate = start_learning_rate;
+    step_number = 0;
+
+    bias.resize( output_size );
+    if( init_bias.size() > 0 )
+    {
+        if( init_bias.size() != output_size )
+            PLERROR( "init_bias (%d) should have length equal to output_size (%d)",
+                     init_bias.size(), output_size );
+        bias << init_bias;
+    }
+    else
+        bias.clear();
+    if( no_bias )
+        bias.clear();
+
+    weights.resize( output_size );
+    if( init_weights.size() > 0 )
+    {
+        if( init_weights.length() != output_size )
+            PLERROR( "init_weights (%d) should have size equal to (output_size) (%d)",
+                     init_weights.length(),
+                     output_size );
+
+        weights << init_weights;
+    }
+    else if( init_weights_random_scale < 0. )
+    {
+        real r = - init_weights_random_scale / sqrt( input_size );
+        random_gen->fill_random_uniform(weights, 1.-r, 1.);
+    }
+    else
+    {
+        real r = init_weights_random_scale / sqrt( input_size );
+        random_gen->fill_random_uniform(weights, 0., r);
+    }
+}
+
+void LinearFilterModule::setLearningRate( real dynamic_learning_rate )
+{
+    start_learning_rate = dynamic_learning_rate;
+    step_number = 0;
+    // learning_rate will automatically be set in bpropUpdate()
+}
+
+///////////
+// build //
+///////////
+void LinearFilterModule::build()
+{
+    inherited::build();
+    build_();
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void LinearFilterModule::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField(init_weights, copies);
+    deepCopyField(init_bias,    copies);
+    deepCopyField(weights,      copies);
+    deepCopyField(bias,         copies);
+    deepCopyField(ones,         copies);
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void LinearFilterModule::declareOptions(OptionList& ol)
+{
+    declareOption(ol, "start_learning_rate",
+                  &LinearFilterModule::start_learning_rate,
+                  OptionBase::buildoption,
+                  "Learning-rate of stochastic gradient optimization");
+
+    declareOption(ol, "decrease_constant",
+                  &LinearFilterModule::decrease_constant,
+                  OptionBase::buildoption,
+                  "Decrease constant of stochastic gradient optimization");
+
+    declareOption(ol, "init_weights", &LinearFilterModule::init_weights,
+                  OptionBase::buildoption,
+                  "Optional initial weights of the neurons (one row per neuron).\n"
+                  "If not provided then weights are initialized according to a uniform\n"
+                  "distribution (see init_weights_random_scale)\n");
+
+    declareOption(ol, "init_bias", &LinearFilterModule::init_bias,
+                  OptionBase::buildoption,
+                  "Optional initial bias of the neurons. If not provided, they are set to 0.\n");
+
+    declareOption(ol, "init_weights_random_scale",
+                  &LinearFilterModule::init_weights_random_scale,
+                  OptionBase::buildoption,
+                  "If init_weights is not provided, the weights are initialized randomly\n"
+                  "from a uniform in [-r,r], with r = init_weights_random_scale/input_size.\n"
+                  "To clear the weights initially, just set this option to 0.");
+
+    declareOption(ol, "L1_penalty_factor",
+                  &LinearFilterModule::L1_penalty_factor,
+                  OptionBase::buildoption,
+                  "Optional (default=0) factor of L1 regularization term, i.e.\n"
+                  "minimize L1_penalty_factor * sum_{ij} |weights(i,j)| during training.\n");
+
+    declareOption(ol, "L2_penalty_factor",
+                  &LinearFilterModule::L2_penalty_factor,
+                  OptionBase::buildoption,
+                  "Optional (default=0) factor of L2 regularization term, i.e.\n"
+                  "minimize 0.5 * L2_penalty_factor * sum_{ij} weights(i,j)^2 during training.\n");
+
+    declareOption(ol, "no_bias",
+                  &LinearFilterModule::no_bias,
+                  OptionBase::buildoption,
+                  "Wether or not to add biases.\n");
+
+    declareOption(ol, "between_0_and_1",
+                  &LinearFilterModule::between_0_and_1,
+                  OptionBase::buildoption,
+                  "Should all weights stay between 0 and 1.\n");
+
+    declareOption(ol, "weights", &LinearFilterModule::weights,
+                  OptionBase::learntoption,
+                  "Input weights of the neurons (one weight per neuron)");
+
+    declareOption(ol, "bias", &LinearFilterModule::bias,
+                  OptionBase::learntoption,
+                  "Bias of the neurons");
+
+    inherited::declareOptions(ol);
+}
+
+////////////
+// build_ //
+////////////
+void LinearFilterModule::build_()
+{
+    if( input_size < 0 ) // has not been initialized
+        return;
+
+    if( output_size < 0 )
+        PLERROR("LinearFilterModule::build_: 'output_size' is < 0 (%i),\n"
+                " you should set it to a positive integer (the number of"
+                " neurons).\n", output_size);
+
+    if( weights.length() != output_size
+        || bias.size() != output_size )
+    {
+        forget();
+    }
+}
+
+////////////////
+// resizeOnes //
+////////////////
+void LinearFilterModule::resizeOnes(int n)
+{
+    if (ones.length() < n) {
+        ones.resize(n);
+        ones.fill(1);
+    } else if (ones.length() > n)
+        ones.resize(n);
+}
+
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners/online/LinearFilterModule.h
===================================================================
--- trunk/plearn_learners/online/LinearFilterModule.h	2007-11-23 20:16:36 UTC (rev 8291)
+++ trunk/plearn_learners/online/LinearFilterModule.h	2007-11-23 20:35:35 UTC (rev 8292)
@@ -0,0 +1,205 @@
+// -*- C++ -*-
+
+// LinearFilterModule.h
+//
+// Copyright (C) 2005 Jerome Louradour
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************
+   * $Id: LinearFilterModule.h,v 1.3 2006/01/08 00:14:53 lamblinp Exp $
+   ******************************************************* */
+
+// Authors: Jerome Louradour
+
+/*! \file LinearFilterModule.h */
+
+
+#ifndef LinearFilterModule_INC
+#define LinearFilterModule_INC
+
+#include <plearn/base/Object.h>
+#include <plearn/math/TMat_maths.h>
+#include "OnlineLearningModule.h"
+
+namespace PLearn {
+
+/**
+ * Affine transformation module, with stochastic gradient descent updates.
+ *
+ * Neural Network layer, using stochastic gradient to update neuron weights,
+ *      Output = weights * Input + bias
+ * Weights and bias are updated by online gradient descent, with learning
+ * rate possibly decreasing in 1/(1 + n_updates_done * decrease_constant).
+ * An L1 and L2 regularization penalty can be added to push weights to 0.
+ * Weights can be initialized to 0, to a given initial matrix, or randomly
+ * from a uniform distribution.
+ *
+ */
+class LinearFilterModule : public OnlineLearningModule
+{
+    typedef OnlineLearningModule inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! Starting learning-rate, by which we multiply the gradient step
+    real start_learning_rate;
+
+    //! learning_rate = start_learning_rate / (1 + decrease_constant*t),
+    //! where t is the number of updates since the beginning
+    real decrease_constant;
+
+    //! Optional initial weights of the neurons (one row per neuron).
+    Vec init_weights;
+
+    //! Optional initial bias of the neurons.
+    Vec init_bias;
+
+    //! If init_weights is not provided, the weights are initialized randomly
+    //! from a uniform in [-r,r], with r = init_weights_random_scale/input_size
+    real init_weights_random_scale;
+
+    //! Optional (default=0) factor of L1 regularization term
+    real L1_penalty_factor;
+
+    //! Optional (default=0) factor of L2 regularization term
+    real L2_penalty_factor;
+
+    //! The weights, one neuron per line
+    Vec weights;
+
+    //! The bias
+    Vec bias;
+    
+    bool no_bias;
+    bool between_0_and_1;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    LinearFilterModule();
+
+    // Your other public member functions go here
+
+    virtual void fprop(const Vec& input, Vec& output) const;
+
+    //! Overridden.
+    virtual void fprop(const Mat& inputs, Mat& outputs);
+
+    virtual void bpropUpdate(const Vec& input, const Vec& output,
+                             const Vec& output_gradient);
+
+    virtual void bpropUpdate(const Vec& input, const Vec& output,
+                             Vec& input_gradient, const Vec& output_gradient,
+                             bool accumulate=false);
+
+    virtual void bpropUpdate(const Mat& inputs, const Mat& outputs,
+                             Mat& input_gradients,
+                             const Mat& output_gradients,
+                             bool accumulate = false);
+    
+    virtual void bbpropUpdate(const Vec& input, const Vec& output,
+                              const Vec& output_gradient,
+                              const Vec& output_diag_hessian);
+
+    /* Bad implementation. Let the parent call PLERROR.
+    virtual void bbpropUpdate(const Vec& input, const Vec& output,
+                              Vec& input_gradient,
+                              const Vec& output_gradient,
+                              Vec& input_diag_hessian,
+                              const Vec& output_diag_hessian,
+                              bool accumulate=false);
+    */
+
+    virtual void forget();
+
+    virtual void setLearningRate(real dynamic_learning_rate);
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    PLEARN_DECLARE_OBJECT(LinearFilterModule);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+
+    //! A vector filled with all ones.
+    Vec ones;
+    
+    //#####  Protected Options  ###############################################
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+
+    //! Resize vector 'ones'.
+    void resizeOnes(int n);
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    real learning_rate;
+    int step_number;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(LinearFilterModule);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From louradou at mail.berlios.de  Fri Nov 23 21:48:39 2007
From: louradou at mail.berlios.de (louradou at BerliOS)
Date: Fri, 23 Nov 2007 21:48:39 +0100
Subject: [Plearn-commits] r8293 - trunk/plearn_learners/online
Message-ID: <200711232048.lANKmdJB028889@sheep.berlios.de>

Author: louradou
Date: 2007-11-23 21:48:39 +0100 (Fri, 23 Nov 2007)
New Revision: 8293

Modified:
   trunk/plearn_learners/online/LinearFilterModule.cc
Log:


Modified: trunk/plearn_learners/online/LinearFilterModule.cc
===================================================================
--- trunk/plearn_learners/online/LinearFilterModule.cc	2007-11-23 20:35:35 UTC (rev 8292)
+++ trunk/plearn_learners/online/LinearFilterModule.cc	2007-11-23 20:48:39 UTC (rev 8293)
@@ -366,12 +366,12 @@
     }
     else if( init_weights_random_scale < 0. )
     {
-        real r = - init_weights_random_scale / sqrt( input_size );
+        real r = - init_weights_random_scale / sqrt( (real)input_size );
         random_gen->fill_random_uniform(weights, 1.-r, 1.);
     }
     else
     {
-        real r = init_weights_random_scale / sqrt( input_size );
+        real r = init_weights_random_scale / sqrt( (real)input_size );
         random_gen->fill_random_uniform(weights, 0., r);
     }
 }



From nouiz at mail.berlios.de  Fri Nov 23 21:53:35 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 21:53:35 +0100
Subject: [Plearn-commits] r8294 -
	branches/cgi-desjardin/plearn_learners/second_iteration
Message-ID: <200711232053.lANKrZIB029463@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 21:53:35 +0100 (Fri, 23 Nov 2007)
New Revision: 8294

Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
Log:
some speed up and added warning


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-23 20:48:39 UTC (rev 8293)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-23 20:53:35 UTC (rev 8294)
@@ -126,7 +126,7 @@
 {  
   source->getSubRow(i, j, v);
   for (int source_col = 0; source_col < v->length(); source_col++) 
-    if (is_missing(v[source_col]) && variable_imputation_instruction[source_col + j] > 0)
+    if (is_missing(v[source_col]))
       if (variable_imputation_instruction[source_col + j] == 1) v[source_col] = variable_mean[source_col + j];
       else if (variable_imputation_instruction[source_col + j] == 2) v[source_col] = variable_median[source_col + j];
       else if (variable_imputation_instruction[source_col + j] == 3) v[source_col] = variable_mode[source_col + j];
@@ -136,7 +136,7 @@
 {  
   source-> getRow(i, v);
   for (int source_col = 0; source_col < v->length(); source_col++)
-    if (is_missing(v[source_col]) && variable_imputation_instruction[source_col] > 0)
+    if (is_missing(v[source_col]))
       if (variable_imputation_instruction[source_col] == 1) v[source_col] = variable_mean[source_col];
       else if (variable_imputation_instruction[source_col] == 2) v[source_col] = variable_median[source_col];
       else if (variable_imputation_instruction[source_col] == 3) v[source_col] = variable_mode[source_col]; 
@@ -146,7 +146,7 @@
 {  
   source-> getColumn(i, v);
   for (int source_row = 0; source_row < v->length(); source_row++)
-    if (is_missing(v[source_row]) && variable_imputation_instruction[i] > 0)
+    if (is_missing(v[source_row]))
       if (variable_imputation_instruction[i] == 1) v[source_row] = variable_mean[i];
       else if (variable_imputation_instruction[i] == 2) v[source_row] = variable_median[i];
       else if (variable_imputation_instruction[i] == 3) v[source_row] = variable_mode[i];
@@ -212,6 +212,13 @@
     if(nofields.length()>0)
       PLERROR("In MeanMedianModeImputationVMatrix::build_() Their is %d fields in the imputation_spec that are not in train set: %s",nofields.length(),
 	      tostring(nofields).c_str());
+    TVec<string> no_instruction;
+    for(int i = 0;i<variable_imputation_instruction.size();i++)
+      if(variable_imputation_instruction[i]==0)
+	no_instruction.append(train_field_names[i]);
+    if(no_instruction.size()>0)
+      PLWARNING("In MeanMedianModeImputationVMatrix::build_() In the source VMatrix some fields do not have instruction: '%s'.",
+		tostring(no_instruction).c_str());
     PPath train_metadata = train_set->getMetaDataDir();
     PPath mean_median_mode_file_name = train_metadata + "mean_median_mode_file.pmat";
     train_set->lockMetaDataDir();



From nouiz at mail.berlios.de  Fri Nov 23 22:11:10 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Fri, 23 Nov 2007 22:11:10 +0100
Subject: [Plearn-commits] r8295 -
	branches/cgi-desjardin/plearn_learners/second_iteration
	trunk/plearn/vmat
Message-ID: <200711232111.lANLBAEF030654@sheep.berlios.de>

Author: nouiz
Date: 2007-11-23 22:11:09 +0100 (Fri, 23 Nov 2007)
New Revision: 8295

Added:
   trunk/plearn/vmat/ImputationVMatrix.cc
   trunk/plearn/vmat/ImputationVMatrix.h
   trunk/plearn/vmat/MeanMedianModeImputationVMatrix.cc
   trunk/plearn/vmat/MeanMedianModeImputationVMatrix.h
Removed:
   branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
Modified:
   branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h
Log:
Move the class MeanMedianModeImputationVMatrix and ImputationVMatrix to the main branch.


Modified: branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h	2007-11-23 20:53:35 UTC (rev 8294)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h	2007-11-23 21:11:09 UTC (rev 8295)
@@ -44,7 +44,7 @@
 #ifndef ConditionalMeanImputationVMatrix_INC
 #define ConditionalMeanImputationVMatrix_INC
 
-#include "ImputationVMatrix.h"
+#include <plearn/vmat/ImputationVMatrix.h>
 #include <plearn/vmat/FileVMatrix.h>
 
 namespace PLearn {

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h	2007-11-23 20:53:35 UTC (rev 8294)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h	2007-11-23 21:11:09 UTC (rev 8295)
@@ -44,7 +44,7 @@
 #ifndef CovariancePreservationImputationVMatrix_INC
 #define CovariancePreservationImputationVMatrix_INC
 
-#include "ImputationVMatrix.h"
+#include <plearn/vmat/ImputationVMatrix.h>
 #include <plearn/vmat/SourceVMatrix.h>
 #include <plearn/vmat/FileVMatrix.h>
 #include <plearn/io/fileutils.h>                     //!<  For isfile()

Deleted: branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.cc	2007-11-23 20:53:35 UTC (rev 8294)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.cc	2007-11-23 21:11:09 UTC (rev 8295)
@@ -1,161 +0,0 @@
-// -*- C++ -*-
-
-// PLearn (A C++ Machine Learning Library)
-// Copyright (C) 1998 Pascal Vincent
-// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
-// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
-// Copyright (C) 2003 Olivier Delalleau
-// Copyright (C) 2007 Frederic Bastien
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-// 
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-// 
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-// 
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-// 
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-// 
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-
-/* *******************************************************************    
-   * $Id: NeighborhoodImputationVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
-   ******************************************************************* */
-
-
-#include "ImputationVMatrix.h"
-
-namespace PLearn {
-using namespace std;
-
-/** ImputationVMatrix **/
-
-PLEARN_IMPLEMENT_ABSTRACT_OBJECT(
-  ImputationVMatrix,
-  "Super-class for VMatrices that replace missing value in another one",
-  ""
-  );
-
-  ImputationVMatrix::ImputationVMatrix():
-    test_level(0)
-{
-}
-
-ImputationVMatrix::~ImputationVMatrix()
-{
-}
-
-void ImputationVMatrix::declareOptions(OptionList &ol)
-{
-  declareOption(ol, "source", &ImputationVMatrix::source, OptionBase::buildoption, 
-                "The source VMatrix with missing values that will be filled.\n");
-  declareOption(ol, "test_level", &ImputationVMatrix::test_level, OptionBase::buildoption, 
-                "The level of test of final matrix. 0 : no test, 1: linear in column or row test, 2: linear in cell\n");
-
-  inherited::declareOptions(ol);
-}
-
-void ImputationVMatrix::build()
-{
-  inherited::build();
-  build_();
-}
-
-void ImputationVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
-{
-  deepCopyField(source, copies);
-  inherited::makeDeepCopyFromShallowCopy(copies);
-}
-
-void ImputationVMatrix::build_()
-{
-}
-
-void ImputationVMatrix::testResultantVMatrix()
-{
-  TVec<string> source_names(source->width());
-  source_names = source->fieldNames();
-  
-  if(test_level>=1){
-    for(int row=0;row<length();row++)
-      for(int col=0;col<width();col++){
-        real data=get(row,col);
-        real sourcedata=source->get(row,col);
-
-        //test if variable not missing are not changed.
-        if(!is_missing(sourcedata))
-          if(data!=sourcedata){
-            PLERROR("ImputationImputations::testResultantVMatrix() data at [%d,%d] are different but the data is not missing",row,col);
-          }
-
-        //test if missing variable are replaced by a value not missing.
-        if(is_missing(data))
-          PLERROR("ImputationImputations::testResultantVMatrix() data at [%d,%d] in the final matrix is missing",row,col);
-      }
-  }
-  if(test_level>=2){ //Must verify if source->getStats is linear
-    getStats();
-    source->getStats();
-    //print the variable that the replacement of missing value change the mean by more then 3 times the stderr
-    int nberr = 0;
-    for(int col=0;col<width();col++)
-      {
-        real mean = field_stats[col].mean();
-        real smean = source->getStats(col).mean();
-        real sstderr = source->getStats(col).stddev()/sqrt(source->getStats(col).nnonmissing());
-        real val=(mean-smean)/sstderr;
-        if(fabs(val)>3){
-          PLWARNING("ImputationImputations::testResultantVMatrix() the variable %d(%s) have a value of %f for abs((mean-sourcemean)/source_stderr)",col,source_names[col].c_str(),val);
-          nberr++;
-        }
-      }
-    if(nberr>0)
-      PLWARNING("ImputationImputations::testResultantVMatrix() There have been %d variables with the mean after imputation outside of sourcemean +- 3*source_stderr",nberr);
-  }
-  //    for(int row=0;row<length();row++)
-  /*    for(int col=0;col<width();col++)
-        {
-        StatsCollector sstats=source->getStats(col);
-        StatsCollector stats=getStats(col);
-        if(sstats.nmissing()!=0){
-        real sum=0;
-        condmean_variable_file_name = source_metadata + "/" + condmean_dir + "/dir/" + source_names[col] + "/Split0/test1_outputs.pmat";
-        
-        if (!isfile(condmean_variable_file_name))
-        PLERROR("In ImputationVMatrix::A conditional mean file was not found for variable %s", source_names[col].c_str());
-        condmean_variable_file = new FileVMatrix(condmean_variable_file_name, false);
-        if (condmean_variable_file->length() != source_length)
-        PLERROR("In ImputationVMatrix::Source and conditional mean file length are not equal for variable %s", source_names[col].c_str());
-        for (int source_row = 0; source_row < source_length; source_row++){
-        real rdata = condmean_variable_file->get(source_row, 0);
-        real data = get(source_row, col);
-        if(!is_missing(rdata))
-        sum+=pow(data - rdata, 2.0);
-        }
-        real mse=sum/stats.nnonmissing();
-        real diff=mse/sstats.variance();
-        if(diff >0.9){
-        perr <<col<<" "<<diff<<endl;
-        PLWARNING("ImputationImputations::testresultantVMatrix() the variable %d(%s) have a MSEtreecondmean(%f)/MSEmean(%f) of %f",col,source_names[col].c_str(),mse,sstats.variance(),diff);
-        }
-        }*/
-}
-} // end of namespcae PLearn

Deleted: branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h	2007-11-23 20:53:35 UTC (rev 8294)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h	2007-11-23 21:11:09 UTC (rev 8295)
@@ -1,87 +0,0 @@
-// -*- C++ -*-
-
-// PLearn (A C++ Machine Learning Library)
-// Copyright (C) 1998 Pascal Vincent
-// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
-// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
-// Copyright (C) 2003 Olivier Delalleau
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-// 
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-// 
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-// 
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-// 
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-// 
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-
-/* ******************************************************************      
-   * $Id: ImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
-   ****************************************************************** */
-
-/*! \file ImputationVMatrix.h */
-
-#ifndef ImputationVMatrix_INC
-#define ImputationVMatrix_INC
-
-#include <plearn/vmat/SourceVMatrix.h>
-#include <plearn/vmat/FileVMatrix.h>
-#include <plearn/io/fileutils.h>                     //!<  For isfile()
-#include <plearn/math/BottomNI.h>
-
-namespace PLearn {
-using namespace std;
-
-class ImputationVMatrix: public VMatrix
-{
-  typedef VMatrix inherited;
-  
-public:
-
-  //! The source VMatrix with missing values.
-  VMat                  source;
-  int                   test_level;
-
-                        ImputationVMatrix();
-  virtual               ~ImputationVMatrix();
-
-  virtual void          build();
-  virtual void          makeDeepCopyFromShallowCopy(CopiesMap& copies);
-          void          testResultantVMatrix();
-protected:
-  //! Declares this class' options
-  // (Please implement in .cc)
-  static void           declareOptions(OptionList &ol);
-
-private:
-  
-         void           build_();
-  
-  PLEARN_DECLARE_ABSTRACT_OBJECT(ImputationVMatrix);
-
-};
-
-DECLARE_OBJECT_PTR(ImputationVMatrix);
-
-} // end of namespcae PLearn
-#endif

Deleted: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-23 20:53:35 UTC (rev 8294)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-11-23 21:11:09 UTC (rev 8295)
@@ -1,431 +0,0 @@
-// -*- C++ -*-
-
-// PLearn (A C++ Machine Learning Library)
-// Copyright (C) 1998 Pascal Vincent
-// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
-// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
-// Copyright (C) 2003 Olivier Delalleau
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-// 
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-// 
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-// 
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-// 
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-// 
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-
-/* *******************************************************************    
-   * $Id: MeanMedianModeImputationVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
-   ******************************************************************* */
-
-
-#include "MeanMedianModeImputationVMatrix.h"
-
-namespace PLearn {
-using namespace std;
-
-/** MeanMedianModeImputationVMatrix **/
-
-PLEARN_IMPLEMENT_OBJECT(
-  MeanMedianModeImputationVMatrix,
-  "VMat class to impute the observed variable mean to replace missing values in the source matrix.",
-  "This class will replace missing values in the underlying dataset with the mean, median or mode observed on the train set.\n"
-  "The imputed value is based on the imputation instruction option.\n"
-  );
-
-MeanMedianModeImputationVMatrix::MeanMedianModeImputationVMatrix()
-: number_of_train_samples_to_use(0.0)
-{
-}
-
-MeanMedianModeImputationVMatrix::~MeanMedianModeImputationVMatrix()
-{
-}
-
-void MeanMedianModeImputationVMatrix::declareOptions(OptionList &ol)
-{
-  declareOption(ol, "train_set", &MeanMedianModeImputationVMatrix::train_set, OptionBase::buildoption, 
-                "A referenced train set.\n"
-                "The mean, median or mode is computed with the observed values in this data set.\n"
-                "It is used in combination with the option number_of_train_samples_to_use\n");
-
-  declareOption(ol, "number_of_train_samples_to_use", &MeanMedianModeImputationVMatrix::number_of_train_samples_to_use, OptionBase::buildoption, 
-                "The number of samples from the train set that will be examined to compute the required statistic for each variable.\n" 
-                "If equal to zero, all the samples from the train set are used to calculated the statistics.\n"
-                "If it is a fraction between 0 and 1, this proportion of the samples are used.\n"
-                "If greater or equal to 1, the integer portion is interpreted as the number of samples to use.");
-      
-  declareOption(ol, "imputation_spec", &MeanMedianModeImputationVMatrix::imputation_spec, OptionBase::buildoption, 
-                "Pairs of instruction of the form field_name : mean | median | mode.");
-
-  declareOption(ol, "variable_mean", &MeanMedianModeImputationVMatrix::variable_mean, OptionBase::learntoption, 
-                "The vector of variable means observed from the train set.");
-
-  declareOption(ol, "variable_median", &MeanMedianModeImputationVMatrix::variable_median, OptionBase::learntoption, 
-                "The vector of variable medians observed from the train set.");
-
-  declareOption(ol, "variable_mode", &MeanMedianModeImputationVMatrix::variable_mode, OptionBase::learntoption, 
-                "The vector of variable modes observed from the train set.");
-
-  declareOption(ol, "variable_imputation_instruction", &MeanMedianModeImputationVMatrix::variable_imputation_instruction, OptionBase::learntoption, 
-                "The vector of coded instruction for each variables.");
-
-  inherited::declareOptions(ol);
-}
-
-void MeanMedianModeImputationVMatrix::build()
-{
-  inherited::build();
-  build_();
-}
-
-void MeanMedianModeImputationVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
-{
-  deepCopyField(train_set, copies);
-  deepCopyField(number_of_train_samples_to_use, copies);
-  deepCopyField(imputation_spec, copies);
-  deepCopyField(variable_mean, copies);
-  deepCopyField(variable_median, copies);
-  deepCopyField(variable_mode, copies);
-  deepCopyField(variable_imputation_instruction, copies);
-  inherited::makeDeepCopyFromShallowCopy(copies);
-}
-
-real MeanMedianModeImputationVMatrix::get(int i, int j) const
-{ 
-  real variable_value = source->get(i, j);
-  if (!is_missing(variable_value)) return variable_value;
-  if (variable_imputation_instruction[j] == 1) return variable_mean[j];
-  if (variable_imputation_instruction[j] == 2) return variable_median[j];
-  if (variable_imputation_instruction[j] == 3) return variable_mode[j];
-  return variable_value;
-}
-
-void MeanMedianModeImputationVMatrix::getSubRow(int i, int j, Vec v) const
-{  
-  source->getSubRow(i, j, v);
-  for (int source_col = 0; source_col < v->length(); source_col++) 
-    if (is_missing(v[source_col]))
-      if (variable_imputation_instruction[source_col + j] == 1) v[source_col] = variable_mean[source_col + j];
-      else if (variable_imputation_instruction[source_col + j] == 2) v[source_col] = variable_median[source_col + j];
-      else if (variable_imputation_instruction[source_col + j] == 3) v[source_col] = variable_mode[source_col + j];
-}
-
-void MeanMedianModeImputationVMatrix::getRow(int i, Vec v) const
-{  
-  source-> getRow(i, v);
-  for (int source_col = 0; source_col < v->length(); source_col++)
-    if (is_missing(v[source_col]))
-      if (variable_imputation_instruction[source_col] == 1) v[source_col] = variable_mean[source_col];
-      else if (variable_imputation_instruction[source_col] == 2) v[source_col] = variable_median[source_col];
-      else if (variable_imputation_instruction[source_col] == 3) v[source_col] = variable_mode[source_col]; 
-}
-
-void MeanMedianModeImputationVMatrix::getColumn(int i, Vec v) const
-{  
-  source-> getColumn(i, v);
-  for (int source_row = 0; source_row < v->length(); source_row++)
-    if (is_missing(v[source_row]))
-      if (variable_imputation_instruction[i] == 1) v[source_row] = variable_mean[i];
-      else if (variable_imputation_instruction[i] == 2) v[source_row] = variable_median[i];
-      else if (variable_imputation_instruction[i] == 3) v[source_row] = variable_mode[i];
-}
-
-
-
-void MeanMedianModeImputationVMatrix::build_()
-{
-    if (!source) PLERROR("In MeanMedianModeImputationVMatrix:: source vmat must be supplied");
-    if (!train_set)
-      train_set = source;
-    int train_length = train_set->length();
-    if (number_of_train_samples_to_use > 0.0)
-        if (number_of_train_samples_to_use < 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
-        else train_length = (int) number_of_train_samples_to_use;
-    if (train_length > train_set->length()) train_length = train_set->length();
-    if(train_length < 1) PLERROR("In MeanMedianModeImputationVMatrix::length of the number of train samples to use must be at least 1, got: %i", train_length);
-    int train_width = train_set->width();
-    int train_targetsize = train_set->targetsize();
-    int train_weightsize = train_set->weightsize();
-    int train_inputsize = train_set->inputsize();
-    if(train_inputsize < 1) PLERROR("In MeanMedianModeImputationVMatrix::inputsize of the train vmat must be supplied, got : %i", train_inputsize);
-    int source_width = source->width();
-    int source_targetsize = source->targetsize();
-    int source_weightsize = source->weightsize();
-    int source_inputsize = source->inputsize();
-    if (train_width != source_width) PLERROR("In MeanMedianModeImputationVMatrix::train set and source width must agree, got : %i, %i", train_width, source_width);
-    if (train_targetsize != source_targetsize) PLERROR("In MeanMedianModeImputationVMatrix::train set and source targetsize must agree, got : %i, %i", train_targetsize, source_targetsize);
-    if (train_weightsize != source_weightsize) PLERROR("In MeanMedianModeImputationVMatrix::train set and source weightsize must agree, got : %i, %i", train_weightsize, source_weightsize);
-    if (train_inputsize != source_inputsize) PLERROR("In MeanMedianModeImputationVMatrix::train set and source inputsize must agree, got : %i, %i", train_inputsize, source_inputsize);
-    train_field_names.resize(train_width);
-    train_field_names = train_set->fieldNames();
-    length_ = source->length();
-    width_ = source_width;
-    inputsize_ = source_inputsize;
-    targetsize_ = source_targetsize;
-    weightsize_ = source_weightsize;
-    declareFieldNames(train_field_names);
-    variable_mean.resize(train_width);
-    variable_median.resize(train_width);
-    variable_mode.resize(train_width);
-    variable_imputation_instruction.resize(train_width);
-    variable_imputation_instruction.clear();
-    TVec<string> nofields;
-    for (int spec_col = 0; spec_col < imputation_spec.size(); spec_col++)
-    {
-        int train_col;
-        for (train_col = 0; train_col < train_width; train_col++)
-        {
-            if (imputation_spec[spec_col].first == train_field_names[train_col]) break;
-        }
-        if (train_col >= train_width){
-	  nofields.append((imputation_spec[spec_col].first).c_str());
-	  continue;
-	}
-        if (imputation_spec[spec_col].second == "mean") variable_imputation_instruction[train_col] = 1;
-        else if (imputation_spec[spec_col].second == "median") variable_imputation_instruction[train_col] = 2;
-        else if (imputation_spec[spec_col].second == "mode") variable_imputation_instruction[train_col] = 3;
-        else PLERROR("In MeanMedianModeImputationVMatrix: unsupported imputation instruction: %s : %s",
-		     (imputation_spec[spec_col].first).c_str(), (imputation_spec[spec_col].second).c_str());
-    }
-    if(nofields.length()>0)
-      PLERROR("In MeanMedianModeImputationVMatrix::build_() Their is %d fields in the imputation_spec that are not in train set: %s",nofields.length(),
-	      tostring(nofields).c_str());
-    TVec<string> no_instruction;
-    for(int i = 0;i<variable_imputation_instruction.size();i++)
-      if(variable_imputation_instruction[i]==0)
-	no_instruction.append(train_field_names[i]);
-    if(no_instruction.size()>0)
-      PLWARNING("In MeanMedianModeImputationVMatrix::build_() In the source VMatrix some fields do not have instruction: '%s'.",
-		tostring(no_instruction).c_str());
-    PPath train_metadata = train_set->getMetaDataDir();
-    PPath mean_median_mode_file_name = train_metadata + "mean_median_mode_file.pmat";
-    train_set->lockMetaDataDir();
-    if (!isfile(mean_median_mode_file_name))
-    {
-        computeMeanMedianModeVectors();
-        createMeanMedianModeFile(mean_median_mode_file_name);
-    }
-    else loadMeanMedianModeFile(mean_median_mode_file_name);
-    train_set->unlockMetaDataDir();
-}
-
-void MeanMedianModeImputationVMatrix::createMeanMedianModeFile(PPath file_name)
-{
-    mean_median_mode_file = new FileVMatrix(file_name, 3, train_field_names);
-    mean_median_mode_file->putRow(0, variable_mean);
-    mean_median_mode_file->putRow(1, variable_median);
-    mean_median_mode_file->putRow(2, variable_mode);
-}
-
-void MeanMedianModeImputationVMatrix::loadMeanMedianModeFile(PPath file_name)
-{
-    mean_median_mode_file = new FileVMatrix(file_name);
-    mean_median_mode_file->getRow(0, variable_mean);
-    mean_median_mode_file->getRow(1, variable_median);
-    mean_median_mode_file->getRow(2, variable_mode);
-    time_t source_time = source->getMtime();
-    time_t stat_file_time = mean_median_mode_file->getMtime();
-    if(stat_file_time==0)
-      PLWARNING("In MeanMedianModeImputationVMatrix::loadMeanMedianModeFile() - "
-		"The precomputed stats file '%s'"
-		" have a modification time of 0",file_name.c_str());
-    else if(source_time>stat_file_time)
-            PLWARNING("In MeanMedianModeImputationVMatrix::loadMeanMedianModeFile()"
-		      " - The precomputed stats file '%s'"
-		      " was created before the source file. Delete it to have it recreated next time."
-		      ,file_name.c_str());
-}
-
-VMat MeanMedianModeImputationVMatrix::getMeanMedianModeFile()
-{
-    return mean_median_mode_file;
-}
-
-void MeanMedianModeImputationVMatrix::computeMeanMedianModeVectors()
-{
-    TVec<int> variable_present_count(width_);
-    TVec<int> variable_missing_count(width_);
-    TVec<int> variable_mode_count(width_);
-    variable_mean.clear();
-    variable_median.clear();
-    variable_mode.clear();
-    variable_present_count.clear();
-    variable_missing_count.clear();
-    variable_mode_count.clear();
-    Vec variable_vec(train_set->length());
-    cout << fixed << showpoint;
-    ProgressBar* pb = 0;
-    pb = new ProgressBar("Computing the mean, median and mode vectors", width_);
-    for (int train_col = 0; train_col < width_; train_col++)
-    {
-        real current_value = 0.0;
-        int current_value_count = 0;
-        train_set->getColumn(train_col, variable_vec);
-        sortColumn(variable_vec, 0, train_set->length());
-        for (int train_row = 0; train_row < train_set->length(); train_row++)
-        {
-            if (is_missing(variable_vec[train_row]))
-            {
-                variable_missing_count[train_col] += 1;
-                continue;
-            }
-            variable_mean[train_col] += variable_vec[train_row];
-            variable_present_count[train_col] += 1;
-            if (variable_vec[train_row] != current_value)
-            {
-                if (current_value_count > variable_mode_count[train_col])
-                {
-                    variable_mode[train_col] = current_value;
-                    variable_mode_count[train_col] = current_value_count;
-                }
-                current_value_count = 0;
-                current_value = variable_vec[train_row];
-            }
-            current_value_count += 1;
-        }
-        if (variable_present_count[train_col] > 0)
-        {
-            variable_mean[train_col] = variable_mean[train_col] / variable_present_count[train_col];
-            variable_median[train_col] = variable_vec[(variable_present_count[train_col] / 2)];
-        }
-        if (current_value_count > variable_mode_count[train_col])
-        {
-            variable_mode[train_col] = current_value;
-            variable_mode_count[train_col] = current_value_count;
-        }
-        pb->update( train_col );
-        /*
-        cout << "col: "         << setw(3)  <<                     train_col
-             << " present: "    << setw(5)  <<                     variable_present_count[train_col]
-             << " missing: "    << setw(5)  <<                     variable_missing_count[train_col]
-             << " mean: "       << setw(11) << setprecision(2) <<  variable_mean[train_col]
-             << " median: "     << setw(11) << setprecision(2) <<  variable_median[train_col]
-             << " mode count: " << setw(5)  <<                     variable_mode_count[train_col]
-             << " mode: "       << setw(11) << setprecision(2) <<  variable_mode[train_col]
-             << " name: "       <<                                 train_field_names[train_col]
-             << endl;
-        */
-    }
-    delete pb;
-}
-
-void MeanMedianModeImputationVMatrix::sortColumn(Vec input_vec, int start, int end)
-{
-  int start_index = start;
-  int end_index = end - 1;
-  int forward_index;
-  int backward_index;
-  int stack_index = -1;
-  real pivot_value;
-  TVec<int> stack(50);
-  for (;;)
-  {
-    if ((end_index - start_index) < 7)
-    {
-      if (end_index > start_index)
-      {
-        sortSmallSubArray(input_vec, start_index, end_index);
-      }
-      if (stack_index < 0)
-      {
-        break;
-      }
-      end_index = stack[stack_index--];
-      start_index = stack[stack_index--];
-    }
-    else
-    {
-      swapValues(input_vec, start_index + 1, (start_index + end_index) / 2);
-      if (compare(input_vec[start_index], input_vec[end_index]) > 0.0) swapValues(input_vec, start_index, end_index);
-      if (compare(input_vec[start_index + 1], input_vec[end_index]) > 0.0) swapValues(input_vec, start_index + 1, end_index);
-      if (compare(input_vec[start_index], input_vec[start_index + 1]) > 0.0) swapValues(input_vec, start_index, start_index + 1);
-      forward_index = start_index + 1;
-      backward_index = end_index;
-      pivot_value = input_vec[start_index + 1];
-      for (;;)
-      {
-        do forward_index++; while (compare(input_vec[forward_index], pivot_value) < 0.0);
-        do backward_index--; while (compare(input_vec[backward_index], pivot_value) > 0.0);
-        if (backward_index < forward_index)
-        {
-          break;
-        }
-        swapValues(input_vec, forward_index, backward_index);
-      }
-      swapValues(input_vec, start_index + 1, backward_index);
-      stack_index += 2;
-      if (stack_index > 50)
-        PLERROR("RegressionTreeRegistersVMatrix: the stack for sorting the rows is too small");
-      if ((end_index - forward_index + 1) >= (backward_index - start_index))
-      {
-        stack[stack_index] = end_index;
-        stack[stack_index - 1] = forward_index;
-        end_index = backward_index - 1;
-      }
-      else
-      {
-        stack[stack_index] = backward_index - 1;
-        stack[stack_index - 1] = start_index;
-        start_index = forward_index;
-      }
-    }
-  }
-}
-  
-void MeanMedianModeImputationVMatrix::sortSmallSubArray(Vec input_vec, int start_index, int end_index)
-{
-  int index_i;
-  int index_j;
-  for (index_i = start_index + 1; index_i <= end_index; index_i++)
-  {
-    real saved_value = input_vec[index_i];
-    for (index_j = index_i - 1; index_j >= start_index; index_j--)
-    {
-      if (compare(input_vec[index_j], saved_value) <= 0.0)
-      {
-        break;
-      }
-      input_vec[index_j + 1] = input_vec[index_j];
-    }
-    input_vec[index_j + 1] = saved_value;
-  }  
-}
-
-void MeanMedianModeImputationVMatrix::swapValues(Vec input_vec, int index_i, int index_j)
-{
-  real saved_value = input_vec[index_i];
-  input_vec[index_i] = input_vec[index_j];
-  input_vec[index_j] = saved_value;
-}
-
-real MeanMedianModeImputationVMatrix::compare(real field1, real field2)
-{
-  if (is_missing(field1) && is_missing(field2)) return 0.0;
-  if (is_missing(field1)) return +1.0;
-  if (is_missing(field2)) return -1.0;
-  return field1 - field2;
-}
-
-} // end of namespcae PLearn

Deleted: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-23 20:53:35 UTC (rev 8294)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-11-23 21:11:09 UTC (rev 8295)
@@ -1,126 +0,0 @@
-// -*- C++ -*-
-
-// PLearn (A C++ Machine Learning Library)
-// Copyright (C) 1998 Pascal Vincent
-// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
-// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
-// Copyright (C) 2003 Olivier Delalleau
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-// 
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-// 
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-// 
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-// 
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-// 
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-
-/* ******************************************************************      
-   * $Id: MeanMedianModeImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
-   ****************************************************************** */
-
-/*! \file MeanMedianModeImputationVMatrix.h */
-
-#ifndef MeanMedianModeImputationVMatrix_INC
-#define MeanMedianModeImputationVMatrix_INC
-
-#include "ImputationVMatrix.h"
-#include <plearn/vmat/FileVMatrix.h>
-#include <plearn/io/fileutils.h>                     //!<  For isfile()
-#include <plearn/math/BottomNI.h>
-
-namespace PLearn {
-using namespace std;
-
-class MeanMedianModeImputationVMatrix: public ImputationVMatrix
-{
-  typedef ImputationVMatrix inherited;
-  
-public:
-
-  
-  //! A referenced train set.
-  //! The mean, median or mode is computed with the observed values in this data set.
-  //! It is used in combination with the option number_of_train_samples_to_use.
-  VMat                          train_set;
-  
-  //! The number of samples from the train set that will be examined to compute the required statistic for each variable.
-  //! If equal to zero, all the samples from the train set are used to calculated the statistics.
-  //! If it is a fraction between 0 and 1, this proportion of the samples are used.
-  //! If greater or equal to 1, the integer portion is interpreted as the number of samples to use.
-  real                          number_of_train_samples_to_use;
-  
-  //! Pairs of instruction of the form field_name : mean | median | mode.
-  TVec< pair<string, string> >  imputation_spec;
-  
-  //! The vector of variable means observed from the train set.
-  Vec                           variable_mean;
-  
-  //! The vector of variable medians observed from the train set.
-  Vec                           variable_median;
-  
-  //! The vector of variable modes observed from the train set.
-  Vec                           variable_mode;
-  
-  //! The vector of coded instruction for each variables.
-  TVec<int>                     variable_imputation_instruction;
-  
-  //! Pairs of instruction of the form field_name : mean | median | mode.
-  
-
-                        MeanMedianModeImputationVMatrix();
-  virtual               ~MeanMedianModeImputationVMatrix();
-
-  static void           declareOptions(OptionList &ol);
-
-  virtual void          build();
-  virtual void          makeDeepCopyFromShallowCopy(CopiesMap& copies);
-
-  virtual real         get(int i, int j) const;
-  virtual void         getSubRow(int i, int j, Vec v) const;
-  virtual void         getRow(int i, Vec v) const;
-  virtual void         getColumn(int i, Vec v) const;
-          VMat         getMeanMedianModeFile();
-
-private:
-  
-  TVec<string>         train_field_names;
-  VMat                 mean_median_mode_file;
-
-          void         build_();
-          void         createMeanMedianModeFile(PPath file_name); 
-          void         loadMeanMedianModeFile(PPath file_name); 
-          void         computeMeanMedianModeVectors();  
-          void         sortColumn(Vec input_vec, int start, int end);
-          void         sortSmallSubArray(Vec input_vec, int start_index, int end_index);
-          void         swapValues(Vec input_vec, int index_i, int index_j);
-          real         compare(real field1, real field2);
-  
-  PLEARN_DECLARE_OBJECT(MeanMedianModeImputationVMatrix);
-
-};
-
-DECLARE_OBJECT_PTR(MeanMedianModeImputationVMatrix);
-
-} // end of namespcae PLearn
-#endif

Modified: branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h	2007-11-23 20:53:35 UTC (rev 8294)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h	2007-11-23 21:11:09 UTC (rev 8295)
@@ -44,7 +44,7 @@
 #ifndef NeighborhoodImputationVMatrix_INC
 #define NeighborhoodImputationVMatrix_INC
 
-#include "ImputationVMatrix.h"
+#include <plearn/vmat/ImputationVMatrix.h>
 #include <plearn/vmat/FileVMatrix.h>
 #include <plearn/io/fileutils.h>                     //!<  For isfile()
 #include <plearn/math/BottomNI.h>

Copied: trunk/plearn/vmat/ImputationVMatrix.cc (from rev 8251, branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.cc)

Copied: trunk/plearn/vmat/ImputationVMatrix.h (from rev 8252, branches/cgi-desjardin/plearn_learners/second_iteration/ImputationVMatrix.h)

Copied: trunk/plearn/vmat/MeanMedianModeImputationVMatrix.cc (from rev 8294, branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc)

Copied: trunk/plearn/vmat/MeanMedianModeImputationVMatrix.h (from rev 8281, branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h)



From tihocan at mail.berlios.de  Sat Nov 24 00:10:23 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Sat, 24 Nov 2007 00:10:23 +0100
Subject: [Plearn-commits] r8296 - in trunk/plearn/base: . test
	test/.pytest/PL_stringutils/expected_results
Message-ID: <200711232310.lANNAN5q006564@sheep.berlios.de>

Author: tihocan
Date: 2007-11-24 00:10:22 +0100 (Sat, 24 Nov 2007)
New Revision: 8296

Modified:
   trunk/plearn/base/stringutils.cc
   trunk/plearn/base/test/.pytest/PL_stringutils/expected_results/RUN.log
   trunk/plearn/base/test/PLStringutilsTest.cc
Log:
Fixed addprepostfix so that it does what the .h says it is supposed to do, and added a test of this function

Modified: trunk/plearn/base/stringutils.cc
===================================================================
--- trunk/plearn/base/stringutils.cc	2007-11-23 21:11:09 UTC (rev 8295)
+++ trunk/plearn/base/stringutils.cc	2007-11-23 23:10:22 UTC (rev 8296)
@@ -539,15 +539,15 @@
 {
     size_t startpos = 0;
     size_t endpos = 0;
-    string txt = removenewline(text);
     string res;
     while(endpos!=string::npos)
     {
-        endpos = txt.find_first_of("\n",startpos);
+        endpos = text.find_first_of("\n",startpos);
         if(endpos!=string::npos)
-            res += prefix + txt.substr(startpos, endpos-startpos) + postfix;
+            res += prefix + text.substr(startpos, endpos-startpos) + postfix
+                                                                  + "\n";
         else
-            res += prefix + txt.substr(startpos) + postfix;
+            res += prefix + text.substr(startpos) + postfix;
         startpos = endpos + 1;
     }
     return res;

Modified: trunk/plearn/base/test/.pytest/PL_stringutils/expected_results/RUN.log
===================================================================
--- trunk/plearn/base/test/.pytest/PL_stringutils/expected_results/RUN.log	2007-11-23 21:11:09 UTC (rev 8295)
+++ trunk/plearn/base/test/.pytest/PL_stringutils/expected_results/RUN.log	2007-11-23 23:10:22 UTC (rev 8296)
@@ -3,3 +3,11 @@
 1
 0
 0
+pre-Hello-post
+pre- -post
+pre--post
+pre-World-post
+pre--post
+pre--post
+pre-Hello-post
+pre-World-post

Modified: trunk/plearn/base/test/PLStringutilsTest.cc
===================================================================
--- trunk/plearn/base/test/PLStringutilsTest.cc	2007-11-23 21:11:09 UTC (rev 8295)
+++ trunk/plearn/base/test/PLStringutilsTest.cc	2007-11-23 23:10:22 UTC (rev 8296)
@@ -113,11 +113,15 @@
     string s4 = "Say Hello";
     string s5 = "Say Hello!";
     string s6 = "Say Jello";
+    string s7 = "Hello\n \n\nWorld\n";
+    string s8 = "\nHello\nWorld";
     pout << string_begins_with(s2, s1) << endl;
     pout << string_begins_with(s3, s1) << endl;
     pout << string_ends_with(s4, s1) << endl;
     pout << string_ends_with(s5, s1) << endl;
     pout << string_ends_with(s6, s1) << endl;
+    pout << addprepostfix("pre-", s7, "-post") << endl;
+    pout << addprepostfix("pre-", s8, "-post") << endl;
 }
 
 } // end of namespace PLearn



From larocheh at mail.berlios.de  Mon Nov 26 13:35:36 2007
From: larocheh at mail.berlios.de (larocheh at BerliOS)
Date: Mon, 26 Nov 2007 13:35:36 +0100
Subject: [Plearn-commits] r8297 - trunk/plearn_learners_experimental
Message-ID: <200711261235.lAQCZaGN007002@sheep.berlios.de>

Author: larocheh
Date: 2007-11-26 13:35:33 +0100 (Mon, 26 Nov 2007)
New Revision: 8297

Added:
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
Log:
Blu


Added: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2007-11-23 23:10:22 UTC (rev 8296)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2007-11-26 12:35:33 UTC (rev 8297)
@@ -0,0 +1,1121 @@
+// -*- C++ -*-
+
+// DeepNonLocalManifoldParzen.cc
+//
+// Copyright (C) 2007 Hugo Larochelle
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Hugo Larochelle
+
+/*! \file DeepNonLocalManifoldParzen.cc */
+
+
+#define PL_LOG_MODULE_NAME "DeepNonLocalManifoldParzen"
+#include <plearn/io/pl_log.h>
+
+#include "DeepNonLocalManifoldParzen.h"
+#include <plearn/vmat/VMat_computeNearestNeighbors.h>
+#include <plearn/vmat/GetInputVMatrix.h>
+#include <plearn_learners/online/GradNNetLayerModule.h>
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    DeepNonLocalManifoldParzen,
+    "Neural net, trained layer-wise to predict the manifold structure of the data.",
+    "This information is used in a Manifold Parzen Windows classifier."
+    );
+
+DeepNonLocalManifoldParzen::DeepNonLocalManifoldParzen() :
+    cd_learning_rate( 0. ),
+    cd_decrease_ct( 0. ),
+    greedy_learning_rate( 0. ),
+    greedy_decrease_ct( 0. ),
+    fine_tuning_learning_rate( 0. ),
+    fine_tuning_decrease_ct( 0. ),
+    k_neighbors( 1 ),
+    n_components( 1 ),
+    min_sigma_noise( 0 ),
+    n_classes( -1 ),
+    output_connections_l1_penalty_factor( 0 ),
+    output_connections_l2_penalty_factor( 0 ),
+    n_layers( 0 ),
+    save_manifold_parzen_parameters( false ),
+    manifold_parzen_parameters_are_up_to_date( false ),
+    currently_trained_layer( 0 )
+{
+    // random_gen will be initialized in PLearner::build_()
+    random_gen = new PRandom();
+    nstages = 0;
+}
+
+void DeepNonLocalManifoldParzen::declareOptions(OptionList& ol)
+{
+    declareOption(ol, "cd_learning_rate", 
+                  &DeepNonLocalManifoldParzen::cd_learning_rate,
+                  OptionBase::buildoption,
+                  "The learning rate used during the RBM "
+                  "contrastive divergence training");
+
+    declareOption(ol, "cd_decrease_ct", 
+                  &DeepNonLocalManifoldParzen::cd_decrease_ct,
+                  OptionBase::buildoption,
+                  "The decrease constant of the learning rate used during "
+                  "the RBMs contrastive\n"
+                  "divergence training. When a hidden layer has finished "
+                  "its training,\n"
+                  "the learning rate is reset to it's initial value.\n");
+
+    declareOption(ol, "greedy_learning_rate", 
+                  &DeepNonLocalManifoldParzen::greedy_learning_rate,
+                  OptionBase::buildoption,
+                  "The learning rate used during the autoassociator "
+                  "gradient descent training");
+
+    declareOption(ol, "greedy_decrease_ct", 
+                  &DeepNonLocalManifoldParzen::greedy_decrease_ct,
+                  OptionBase::buildoption,
+                  "The decrease constant of the learning rate used during "
+                  "the autoassociator\n"
+                  "gradient descent training. When a hidden layer has finished "
+                  "its training,\n"
+                  "the learning rate is reset to it's initial value.\n");
+
+    declareOption(ol, "fine_tuning_learning_rate", 
+                  &DeepNonLocalManifoldParzen::fine_tuning_learning_rate,
+                  OptionBase::buildoption,
+                  "The learning rate used during the fine tuning gradient descent");
+
+    declareOption(ol, "fine_tuning_decrease_ct", 
+                  &DeepNonLocalManifoldParzen::fine_tuning_decrease_ct,
+                  OptionBase::buildoption,
+                  "The decrease constant of the learning rate used during "
+                  "fine tuning\n"
+                  "gradient descent.\n");
+
+    declareOption(ol, "training_schedule", 
+                  &DeepNonLocalManifoldParzen::training_schedule,
+                  OptionBase::buildoption,
+                  "Number of examples to use during each phase of greedy pre-training.\n"
+                  "The number of fine-tunig steps is defined by nstages.\n"
+        );
+
+    declareOption(ol, "layers", &DeepNonLocalManifoldParzen::layers,
+                  OptionBase::buildoption,
+                  "The layers of units in the network. The first element\n"
+                  "of this vector should be the input layer and the\n"
+                  "subsequent elements should be the hidden layers. The\n"
+                  "output layer should not be included in layers.\n");
+
+    declareOption(ol, "connections", &DeepNonLocalManifoldParzen::connections,
+                  OptionBase::buildoption,
+                  "The weights of the connections between the layers");
+
+    declareOption(ol, "reconstruction_connections", 
+                  &DeepNonLocalManifoldParzen::reconstruction_connections,
+                  OptionBase::buildoption,
+                  "The reconstruction weights of the autoassociators");
+
+    declareOption(ol, "unsupervised_layers", 
+                  &DeepNonLocalManifoldParzen::unsupervised_layers,
+                  OptionBase::buildoption,
+                  "Additional units for greedy unsupervised learning");
+
+    declareOption(ol, "unsupervised_connections", 
+                  &DeepNonLocalManifoldParzen::unsupervised_connections,
+                  OptionBase::buildoption,
+                  "Additional connections for greedy unsupervised learning");
+
+    declareOption(ol, "k_neighbors", 
+                  &DeepNonLocalManifoldParzen::k_neighbors,
+                  OptionBase::buildoption,
+                  "Number of good nearest neighbors to attract and bad nearest "
+                  "neighbors to repel.");
+
+    declareOption(ol, "n_components", 
+                  &DeepNonLocalManifoldParzen::n_components,
+                  OptionBase::buildoption,
+                  "Dimensionality of the manifold");
+
+    declareOption(ol, "n_classes", 
+                  &DeepNonLocalManifoldParzen::n_classes,
+                  OptionBase::buildoption,
+                  "Number of classes.");
+
+    declareOption(ol, "output_connections_l1_penalty_factor", 
+                  &DeepNonLocalManifoldParzen::output_connections_l1_penalty_factor,
+                  OptionBase::buildoption,
+                  "Output weights L1 penalty factor");
+
+    declareOption(ol, "output_connections_l2_penalty_factor", 
+                  &DeepNonLocalManifoldParzen::output_connections_l2_penalty_factor,
+                  OptionBase::buildoption,
+                  "Output weights L2 penalty factor");
+
+    declareOption(ol, "save_manifold_parzen_parameters", 
+                  &DeepNonLocalManifoldParzen::save_manifold_parzen_parameters,
+                  OptionBase::buildoption,
+                  "Indication that the parameters for the manifold parzen\n"
+                  "windows estimator should be saved during test, to speed up "
+                  "testing.");
+
+    declareOption(ol, "manifold_parzen_parameters_are_up_to_date", 
+                  &DeepNonLocalManifoldParzen::manifold_parzen_parameters_are_up_to_date,
+                  OptionBase::buildoption,
+                  "Indication that the saved manifold parzen parameters are\n"
+                  "up to date.");
+
+    declareOption(ol, "greedy_stages", 
+                  &DeepNonLocalManifoldParzen::greedy_stages,
+                  OptionBase::learntoption,
+                  "Number of training samples seen in the different greedy "
+                  "phases.\n"
+        );
+
+    declareOption(ol, "n_layers", &DeepNonLocalManifoldParzen::n_layers,
+                  OptionBase::learntoption,
+                  "Number of layers"
+        );
+
+    declareOption(ol, "output_connections", 
+                  &DeepNonLocalManifoldParzen::output_connections,
+                  OptionBase::learntoption,
+                  "Output weights"
+        );
+
+    declareOption(ol, "train_set", 
+                  &DeepNonLocalManifoldParzen::train_set,
+                  OptionBase::learntoption,
+                  "Training set"
+        );
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void DeepNonLocalManifoldParzen::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+
+    MODULE_LOG << "build_() called" << endl;
+
+    if(inputsize_ > 0 && targetsize_ > 0)
+    {
+        // Initialize some learnt variables
+        n_layers = layers.length();
+        
+        // Builds some variables using the training set
+        setTrainingSet(train_set, false);
+
+        if( n_classes <= 0 )
+            PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
+                    "n_classes should be > 0.\n");
+        test_votes.resize(n_classes);
+
+        if( k_neighbors <= 0 )
+            PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
+                    "k_neighbors should be > 0.\n");
+        test_nearest_neighbors_indices.resize(k_neighbors);
+
+        if( weightsize_ > 0 )
+            PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
+                    "usage of weighted samples (weight size > 0) is not\n"
+                    "implemented yet.\n");
+
+        if( training_schedule.length() != n_layers-1 )        
+            PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
+                    "training_schedule should have %d elements.\n",
+                    n_layers-1);
+        
+        if( n_components < 1 || n_components > inputsize_)
+            PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
+                    "n_components should be > 0 and < or = to inputsize.\n");
+
+        if( min_sigma_noise < 0)
+            PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
+                    "min_sigma_noise should be > or = to 0.\n")
+
+        if(greedy_stages.length() == 0)
+        {
+            greedy_stages.resize(n_layers-1);
+            greedy_stages.clear();
+        }        
+        
+        if(stage > 0)
+            currently_trained_layer = n_layers;
+        else
+        {            
+            currently_trained_layer = n_layers-1;
+            while(currently_trained_layer>1
+                  && greedy_stages[currently_trained_layer-1] <= 0)
+                currently_trained_layer--;
+        }
+
+        build_layers_and_connections();
+    }
+}
+
+void DeepNonLocalManifoldParzen::build_layers_and_connections()
+{
+    MODULE_LOG << "build_layers_and_connections() called" << endl;
+
+    if( connections.length() != n_layers-1 )
+        PLERROR("DeepNonLocalManifoldParzen::build_layers_and_connections() - \n"
+                "there should be %d connections.\n",
+                n_layers-1);
+
+    if( !fast_exact_is_equal( greedy_learning_rate, 0 ) 
+        && reconstruction_connections.length() != n_layers-1 )
+        PLERROR("DeepNonLocalManifoldParzen::build_layers_and_connections() - \n"
+                "there should be %d reconstruction connections.\n",
+                n_layers-1);
+    
+    if(  !( reconstruction_connections.length() == 0
+            || reconstruction_connections.length() == n_layers-1 ) )
+        PLERROR("DeepNonLocalManifoldParzen::build_layers_and_connections() - \n"
+                "there should be either 0 or %d reconstruction connections.\n",
+                n_layers-1);
+        
+
+    if(layers[0]->size != inputsize_)
+        PLERROR("DeepNonLocalManifoldParzen::build_layers_and_connections() - \n"
+                "layers[0] should have a size of %d.\n",
+                inputsize_);
+
+    activations.resize( n_layers );
+    expectations.resize( n_layers );
+    activation_gradients.resize( n_layers );
+    expectation_gradients.resize( n_layers );
+
+    for( int i=0 ; i<n_layers-1 ; i++ )
+    {
+        if( layers[i]->size != connections[i]->down_size )
+            PLERROR("DeepNonLocalManifoldParzen::build_layers_and_connections() "
+                    "- \n"
+                    "connections[%i] should have a down_size of %d.\n",
+                    i, layers[i]->size);
+
+        if( connections[i]->up_size != layers[i+1]->size )
+            PLERROR("DeepNonLocalManifoldParzen::build_layers_and_connections() "
+                    "- \n"
+                    "connections[%i] should have a up_size of %d.\n",
+                    i, layers[i+1]->size);
+
+        if( !(layers[i]->random_gen) )
+        {
+            layers[i]->random_gen = random_gen;
+            layers[i]->forget();
+        }
+
+        if( !(connections[i]->random_gen) )
+        {
+            connections[i]->random_gen = random_gen;
+            connections[i]->forget();
+        }
+
+        if( reconstruction_connections.length() != 0
+            && !(reconstruction_connections[i]->random_gen) )
+        {
+            reconstruction_connections[i]->random_gen = random_gen;
+            reconstruction_connections[i]->forget();
+        }        
+
+        activations[i].resize( layers[i]->size );
+        expectations[i].resize( layers[i]->size );
+        activation_gradients[i].resize( layers[i]->size );
+        expectation_gradients[i].resize( layers[i]->size );
+    }
+
+    if( !(layers[n_layers-1]->random_gen) )
+    {
+        layers[n_layers-1]->random_gen = random_gen;
+        layers[n_layers-1]->forget();
+    }
+    activations[n_layers-1].resize( layers[n_layers-1]->size );
+    expectations[n_layers-1].resize( layers[n_layers-1]->size );
+    activation_gradients[n_layers-1].resize( layers[n_layers-1]->size );
+    expectation_gradients[n_layers-1].resize( layers[n_layers-1]->size );
+
+    int output_size = n_components*inputsize + (predict_mu ? inputsize : 0) + 1;
+    all_outputs.resize( output_size );
+
+    if( !output_connections || output_connections->output_size != output_size)
+    {
+        PP<GradNNetLayerModule> ow = new GradNNetLayerModule;
+        ow->input_size = layers[n_layers-1]->size;
+        ow->output_size = output_size;
+        ow->L1_penalty_factor = output_connections_l1_penalty_factor;
+        ow->L2_penalty_factor = output_connections_l2_penalty_factor;
+        ow->build();
+        output_connections = ow;
+    }
+}
+
+// ### Nothing to add here, simply calls build_
+void DeepNonLocalManifoldParzen::build()
+{
+    inherited::build();
+    build_();
+}
+
+
+void DeepNonLocalManifoldParzen::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    PLERROR("NOT IMPLEMENTED YET!");
+
+    // deepCopyField(, copies);
+
+    // Public options
+    deepCopyField(training_schedule, copies);
+    deepCopyField(layers, copies);
+    deepCopyField(connections, copies);
+    deepCopyField(reconstruction_connections, copies);
+    deepCopyField(unsupervised_layers, copies);
+    deepCopyField(unsupervised_connections, copies);
+
+    // Protected options
+    deepCopyField(activations, copies);
+    deepCopyField(expectations, copies);
+    deepCopyField(activation_gradients, copies);
+    deepCopyField(expectation_gradients, copies);
+    deepCopyField(greedy_activation, copies);
+    deepCopyField(greedy_expectation, copies);
+    deepCopyField(greedy_activation_gradient, copies);
+    deepCopyField(greedy_expectation_gradient, copies);
+    deepCopyField(reconstruction_activations, copies);
+    deepCopyField(reconstruction_activation_gradients, copies);
+    deepCopyField(reconstruction_expectation_gradients, copies);
+    deepCopyField(output_connections, copies);
+    deepCopyField(input_representation, copies);
+    deepCopyField(previous_input_representation, copies);
+    deepCopyField(dissimilar_gradient_contribution, copies);
+    deepCopyField(pos_down_val, copies);
+    deepCopyField(pos_up_val, copies);
+    deepCopyField(neg_down_val, copies);
+    deepCopyField(neg_up_val, copies);
+    deepCopyField(class_datasets, copies);
+    deepCopyField(other_classes_proportions, copies);
+    deepCopyField(nearest_neighbors_indices, copies);
+    deepCopyField(test_nearest_neighbors_indices, copies);
+    deepCopyField(test_votes, copies);
+    deepCopyField(train_set_representations, copies);
+    deepCopyField(train_set_representations_vmat, copies);
+    deepCopyField(train_set_targets, copies);
+    deepCopyField(greedy_stages, copies);
+}
+
+
+int DeepNonLocalManifoldParzen::outputsize() const
+{
+    //if(currently_trained_layer < n_layers)
+    //    return layers[currently_trained_layer]->size;
+    //return layers[n_layers-1]->size;
+    return n_classes;
+}
+
+void DeepNonLocalManifoldParzen::forget()
+{
+    //! (Re-)initialize the PLearner in its fresh state (that state may depend
+    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
+    //! a fresh learner!)
+    /*!
+      A typical forget() method should do the following:
+      - call inherited::forget() to initialize its random number generator
+        with the 'seed' option
+      - initialize the learner's parameters, using this random generator
+      - stage = 0
+    */
+    inherited::forget();
+
+    manifold_parzen_parameters_are_up_to_date = false;
+
+    for( int i=0 ; i<n_layers-1 ; i++ )
+        connections[i]->forget();
+    
+    for( int i=0 ; i<n_layers ; i++ )
+        layers[i]->forget();
+    
+    for( int i=0; i<reconstruction_connections.length(); i++)
+        reconstruction_connections[i]->forget();
+
+    if( output_connections )
+        output_connections->forget();
+
+    stage = 0;
+    greedy_stages.clear();
+}
+
+void DeepNonLocalManifoldParzen::train()
+{
+    MODULE_LOG << "train() called " << endl;
+    MODULE_LOG << "  training_schedule = " << training_schedule << endl;
+
+    Vec input( inputsize() );
+    Vec nearest_neighbor( inputsize() );
+    Mat nearest_neighbors( k_neighbors, inputsize() );
+    Vec target( targetsize() );
+    Vec target2( targetsize() );
+    real weight; // unused
+    real weight2; // unused
+
+    TVec<string> train_cost_names = getTrainCostNames() ;
+    Vec train_costs( train_cost_names.length() );
+    train_costs.fill(MISSING_VALUE) ;
+
+    int nsamples = train_set->length();
+    int sample;
+
+    PP<ProgressBar> pb;
+
+    // clear stats of previous epoch
+    train_stats->forget();
+
+    int init_stage;
+
+    /***** initial greedy training *****/
+    for( int i=0 ; i<n_layers-1 ; i++ )
+    {
+        MODULE_LOG << "Training connection weights between layers " << i
+            << " and " << i+1 << endl;
+
+        int end_stage = training_schedule[i];
+        int* this_stage = greedy_stages.subVec(i,1).data();
+        init_stage = *this_stage;
+
+        MODULE_LOG << "  stage = " << *this_stage << endl;
+        MODULE_LOG << "  end_stage = " << end_stage << endl;
+        MODULE_LOG << "  greedy_learning_rate = " << greedy_learning_rate << endl;
+
+        if( report_progress && *this_stage < end_stage )
+            pb = new ProgressBar( "Training layer "+tostring(i)
+                                  +" of "+classname(),
+                                  end_stage - init_stage );
+
+        train_costs.fill(MISSING_VALUE);
+        reconstruction_activations.resize(layers[i]->size);
+        reconstruction_activation_gradients.resize(layers[i]->size);
+        reconstruction_expectation_gradients.resize(layers[i]->size);
+
+        pos_down_val.resize(layers[i]->size);
+        pos_up_val.resize(greedy_layers[i]->size);
+        neg_down_val.resize(layers[i]->size);
+        neg_up_val.resize(greedy_layers[i]->size);
+
+        for( ; *this_stage<end_stage ; (*this_stage)++ )
+        {
+            sample = *this_stage % nsamples;
+            train_set->getExample(sample, input, target, weight);
+            greedyStep( input, target, i, train_costs, *this_stage);
+            train_stats->update( train_costs );
+
+            if( pb )
+                pb->update( *this_stage - init_stage + 1 );
+        }
+    }
+
+    /***** fine-tuning by gradient descent *****/
+    if( stage < nstages )
+    {
+
+        if( stage == 0 )
+        {
+            MODULE_LOG << "Finding the nearest neighbors" << endl;
+            // Find training nearest neighbors
+            TVec<int> nearest_neighbors_indices_row;
+            for(int k=0; k<n_classes; k++)
+            {
+                for(int i=0; i<class_datasets[k]->length(); i++)
+                {
+                    class_datasets[k]->getExample(i,input,target,weight);
+                    nearest_neighbors_indices_row = nearest_neighbors_indices(
+                        class_datasets[k]->indices[i]);
+                    computeNearestNeighbors(
+                        new GetInputVMatrix((VMatrix *)class_datasets[k]),input,
+                        nearest_neighbors_indices_row,
+                        i);
+                }
+            }
+        }
+
+        MODULE_LOG << "Fine-tuning all parameters, by gradient descent" << endl;
+        MODULE_LOG << "  stage = " << stage << endl;
+        MODULE_LOG << "  nstages = " << nstages << endl;
+        MODULE_LOG << "  fine_tuning_learning_rate = " << 
+            fine_tuning_learning_rate << endl;
+
+        init_stage = stage;
+        if( report_progress && stage < nstages )
+            pb = new ProgressBar( "Fine-tuning parameters of all layers of "
+                                  + classname(),
+                                  nstages - init_stage );
+
+        setLearningRate( fine_tuning_learning_rate );
+        train_costs.fill(MISSING_VALUE);
+
+        for( ; stage<nstages ; stage++ )
+        {
+            sample = stage % nsamples;
+            if( !fast_exact_is_equal( fine_tuning_decrease_ct, 0. ) )
+                setLearningRate( fine_tuning_learning_rate
+                                 / (1. + fine_tuning_decrease_ct * stage ) );
+
+            train_set->getExample( sample, input, target, weight );
+
+            // Find nearest neighbors
+            for( int k=0; k<k_neighbors; k++ )
+            {
+                class_datasets[(int)round(target[0])]->getExample(
+                    nearest_neighbors_indices(sample,k),
+                    nearest_neighbor, target2, weight2);
+
+                if(round(target[0]) != round(target2[0]))
+                    PLERROR("DeepNonLocalManifoldParzen::train(): similar"
+                            " example is not from same class!");
+                nearest_neighbors(k) << nearest_neighbor;
+            }
+
+
+            fineTuningStep( input, target, train_costs, 
+                            nearest_neighbors);
+            train_stats->update( train_costs );
+
+            if( pb )
+                pb->update( stage - init_stage + 1 );
+        }
+    }
+    
+    train_stats->finalize();
+    MODULE_LOG << "  train costs = " << train_stats->getMean() << endl;
+
+    // Update currently_trained_layer
+    if(stage > 0)
+        currently_trained_layer = n_layers;
+    else
+    {            
+        currently_trained_layer = n_layers-1;
+        while(currently_trained_layer>1 
+              && greedy_stages[currently_trained_layer-1] <= 0)
+            currently_trained_layer--;
+    }
+}
+
+void DeepNonLocalManifoldParzen::greedyStep( 
+    const Vec& input, const Vec& target, int index, 
+    Vec train_costs, int this_stage)
+{
+    PLASSERT( index < n_layers );
+    real lr;
+    manifold_parzen_parameters_are_up_to_date = false;
+
+    // Get example representation
+
+    computeRepresentation(input, previous_input_representation, 
+                          index);
+    connections[index]->fprop(previous_input_representation,
+                                     activations[index+1]);
+    layers[index+1]->fprop(activations[index+1],
+                           expectations[index+1]);
+
+    // Autoassociator learning
+    if( !fast_exact_is_equal( greedy_learning_rate, 0 ) )
+    {
+        if( !fast_exact_is_equal( greedy_decrease_ct , 0 ) )
+            lr = greedy_learning_rate/(1 + greedy_decrease_ct 
+                                       * this_stage); 
+        else
+            lr = greedy_learning_rate;
+
+        layers[index]->setLearningRate( lr );
+        connections[index]->setLearningRate( lr );
+        reconstruction_connections[index]->setLearningRate( lr );
+        layers[index+1]->setLearningRate( lr );
+
+        reconstruction_connections[ index ]->fprop( expectations[index+1],
+                                                    reconstruction_activations);
+        layers[ index ]->fprop( reconstruction_activations,
+                                layers[ index ]->expectation);
+        
+        layers[ index ]->activation << reconstruction_activations;
+        layers[ index ]->setExpectationByRef(layers[ index ]->expectation);
+        real rec_err = layers[ index ]->fpropNLL(previous_input_representation);
+        train_costs[index] = rec_err;
+        
+        layers[ index ]->bpropNLL(previous_input_representation, rec_err,
+                                  reconstruction_activation_gradients);
+    }
+
+    // RBM learning
+    if( !fast_exact_is_equal( cd_learning_rate, 0 ) )
+    {
+        layers[index+1]->setExpectation( expectations[index+1] );
+        layers[index+1]->generateSample();
+        
+        // accumulate positive stats using the expectation
+        // we deep-copy because the value will change during negative phase
+        pos_down_val = expectations[index];
+        pos_up_val << layers[index+1]->expectation;
+        
+        // down propagation, starting from a sample of layers[index+1]
+        connections[index]->setAsUpInput( layers[index+1]->sample );
+        
+        layers[index]->getAllActivations( connections[index] );
+        layers[index]->computeExpectation();
+        layers[index]->generateSample();
+        
+        // negative phase
+        connections[index]->setAsDownInput( layers[index]->sample );
+        layers[index+1]->getAllActivations( connections[index+1] );
+        layers[index+1]->computeExpectation();
+        // accumulate negative stats
+        // no need to deep-copy because the values won't change before update
+        neg_down_val = layers[index]->sample;
+        neg_up_val = layers[index+1]->expectation;
+    }
+    
+    // Update hidden layer bias and weights
+
+    if( !fast_exact_is_equal( greedy_learning_rate, 0 ) )
+    {
+        layers[ index ]->update(reconstruction_activation_gradients);
+    
+        reconstruction_connections[ index ]->bpropUpdate( 
+            expectations[index+1],
+            reconstruction_activations, 
+            reconstruction_expectation_gradients, 
+            reconstruction_activation_gradients);
+
+        layers[ index+1 ]->bpropUpdate( 
+            activations[index+1],
+            expectations[index+1],
+            // reused
+            reconstruction_activation_gradients,
+            reconstruction_expectation_gradients);
+        
+        connections[ index ]->bpropUpdate( 
+            previous_input_representation,
+            activations[index+1],
+            reconstruction_expectation_gradients, //reused
+            reconstruction_activation_gradients);
+    }
+     
+    // RBM updates
+
+    if( !fast_exact_is_equal( cd_learning_rate, 0 ) )
+    {
+        if( !fast_exact_is_equal( cd_decrease_ct , 0 ) )
+            lr = cd_learning_rate/(1 + cd_decrease_ct 
+                                       * this_stage); 
+        else
+            lr = cd_learning_rate;
+
+        layers[index]->setLearningRate( lr );
+        connections[index]->setLearningRate( lr );
+        layers[index+1]->setLearningRate( lr );
+
+        layers[index]->update( pos_down_val, neg_down_val );
+        connections[index]->update( pos_down_val, pos_up_val,
+                                    neg_down_val, neg_up_val );
+        layers[index+1]->update( pos_up_val, neg_up_val );
+    }
+}
+
+void DeepNonLocalManifoldParzen::fineTuningStep( 
+    const Vec& input, const Vec& target,
+    Vec& train_costs, Mat nearest_neighbors )
+{
+    manifold_parzen_parameters_are_up_to_date = false;
+
+    // Get example representation
+
+    computeRepresentation(input, input_representation, 
+                          n_layers-1);
+
+    F = all_outputs.subVec(0,n_components * inputsize()).toMat(
+        n_components, inputsize());
+    F_copy.resize(F.length(), F.width());
+    mu = all_outputs.subVec(n_components * inputsize(),inputsize());
+    pre_sigma_noise = all_outputs.subVec( n_components * (inputsize() + 1), 1 );
+
+    output_connections->fprop( input_representation, all_outputs );
+    real sigma_noise = square(sigma_noise, 2) + min_sigma_noise;
+
+    F_copy.resize(F.length(),F.width());
+    sm_svd.resize(n_components);
+    // N.B. this is the SVD of F'
+    F_copy << F;
+    lapackSVD(F_copy, Ut, S, V,'A',1.5);
+    for (int k=0;k<ncomponents;k++)
+    {
+        sm_svd[k] = mypow(S[k],2);
+        U(k) << Ut(k);
+    }
+
+    real mahal = 0;
+    real norm_term = 0;
+    real dotp = 0;
+    real coef = 0;
+    inv_Sigma_z.clear();
+    real tr_inv_Sigma = 0;
+    train_costs.last() = 0;
+    for(int j=0; j<nneighbors;j++)
+    {
+        zj = z(j);
+        substract(neighbors(j),input,diff_neighbor_input); 
+        substract(diff_neighbor_input,mu,zj); 
+      
+        mahal = -0.5*pownorm(zj)/sn[0];      
+        norm_term = - n/2.0 * Log2Pi - 0.5*(n-ncomponents)*pl_log(sn[0]);
+
+        inv_sigma_zj = inv_Sigma_z(j);
+        inv_sigma_zj << zj; 
+        inv_sigma_zj /= sn[0];
+
+        if(j==0)
+            tr_inv_Sigma = n/sn[0];
+
+        for(int k=0; k<ncomponents; k++)
+        { 
+            uk = U(k);
+            dotp = dot(zj,uk);
+            coef = (1.0/(sm_svd[k]+sn[0]) - 1.0/sn[0]);
+            multiplyAcc(inv_sigma_zj,uk,dotp*coef);
+            mahal -= square(dotp)*0.5*coef;
+            norm_term -= 0.5*pl_log(sm_svd[k]);
+            if(j==0)
+                tr_inv_Sigma += coef;
+        }
+
+        train_costs.last() += -1*(norm_term + mahal);
+    }
+
+    train_costs.last() / k_neighbors;
+
+    inv_Sigma_F.clear();
+    for(int k=0; k<ncomponents; k++)
+    { 
+        fk = F(k);
+        inv_sigma_fk = inv_Sigma_F(k);
+        inv_sigma_fk << fk;
+        inv_sigma_fk /= sn[0];
+        for(int k2=0; k2<ncomponents;k2++)
+        {
+            uk2 = U(k2);
+            multiplyAcc(inv_sigma_fk,uk2,
+                        (1.0/(sm_svd[k2]+sn[0]) - 1.0/sn[0])*dot(fk,uk2));
+        }
+    }
+
+    all_outputs_gradient.clear();
+    real coef = 1/train_set->length();
+    for(int neighbor=0; neighbor<nneighbors; neighbor++)
+    {
+        // dNLL/dF
+        product(temp_ncomp,F,inv_Sigma_z(neighbor));
+        bprop_to_bases(all_outputs_gradient.toVec(0,n_components * inputsize()).toMat(n_components,inputsize()),
+                       inv_Sigma_F,
+                       temp_ncomp,inv_Sigma_z(neighbor),
+                       coef);
+
+        // dNLL/dmu
+        multiplyAcc(all_outputs_gradient.subVec(n_components * inputsize(),
+                                                inputsize()), 
+                    inv_Sigma_z(neighbor),
+                    -coef) ;
+
+        // dNLL/dsn
+        all_outputs_gradient[(n_components + 1 )* inputsize()] += coef* 
+            0.5*(tr_inv_Sigma - pownorm(inv_Sigma_z(neighbor))) * 
+            2 * pre_sigma_noise[0];
+    }
+
+    // Propagating supervised gradient
+    output_connections->bpropUpdate( input_representation, all_outputs,
+                                     expectation_gradients[n_layers-1], 
+                                     all_outputs_gradient);
+
+    for( int i=n_layers-1 ; i>0 ; i-- )
+    {
+        layers[i]->bpropUpdate( activations[i],
+                                expectations[i],
+                                activation_gradients[i],
+                                expectation_gradients[i] );
+        
+        
+        connections[i-1]->bpropUpdate( expectations[i-1],
+                                       activations[i],
+                                       expectation_gradients[i-1],
+                                       activation_gradients[i] );
+    }        
+}
+
+// grad_F += alpa ( M - v1 v2')
+void DeepNonLocalManifoldParzen::bprop_to_bases(const Mat& R, const Mat& M, 
+                                                const Vec& v1, 
+                                                const Vec& v2, real alpha)
+{
+#ifdef BOUNDCHECK
+    if (M.length() != R.length() || M.width() != R.width() 
+        || v1.length()!=M.length() || M.width()!=v2.length() )
+        PLERROR("DeepNonLocalManifoldParzen::bprop_to_bases(): incompatible "
+                "arguments' sizes");
+#endif
+
+    const real* v_1=v1.data();
+    const real* v_2=v2.data();
+    for (int i=0;i<M.length();i++)
+    {
+        real* mi = M[i];
+        real* ri = R[i];
+        real v1i = v_1[i];
+        for (int j=0;j<M.width();j++)
+            ri[j] += alpha*(mi[j] - v1i * v_2[j]);
+    }
+}
+
+
+void DeepNonLocalManifoldParzen::computeRepresentation(const Vec& input,
+                                                             Vec& representation,
+                                                             int layer) const
+{
+    if(layer == 0)
+    {
+        representation.resize(input.length());
+        expectations[0] << input;
+        representation << input;
+        return;
+    }
+
+    for( int i=0 ; i<layer; i++ )
+    {
+        connections[i]->fprop( expectations[i], activations[i+1] );
+        layers[i+1]->fprop(activations[i+1],expectations[i+1]);
+    }
+    representation.resize(expectations[layer].length());
+    representation << expectations[layer];
+}
+
+void DeepNonLocalManifoldParzen::computeOutput(const Vec& input, Vec& output) const
+{
+    updateTrainSetRepresentations();
+
+    // Penser aux variables
+    // - ..._are_up_to_date
+    // - save_manifold_parzen...
+
+    computeRepresentation(input,input_representation, 
+                          min(currently_trained_layer,n_layers-1));
+
+    computeNearestNeighbors(train_set_representations_vmat,input_representation,
+                            test_nearest_neighbors_indices);
+
+    test_votes.clear();
+    for(int i=0; i<test_nearest_neighbors_indices.length(); i++)
+        test_votes[train_set_targets[test_nearest_neighbors_indices[i]]]++;
+
+    output[0] = argmax(test_votes);
+
+}
+
+void DeepNonLocalManifoldParzen::computeCostsFromOutputs(const Vec& input, const Vec& output,
+                                           const Vec& target, Vec& costs) const
+{
+
+    //Assumes that computeOutput has been called
+
+    costs.resize( getTestCostNames().length() );
+    costs.fill( MISSING_VALUE );
+
+    if( currently_trained_layer<n_layers 
+        && reconstruction_connections.length() != 0 )
+    {
+        greedy_connections[currently_trained_layer-1]->fprop(
+            expectations[currently_trained_layer-1],
+            greedy_activation);
+        
+        greedy_layers[currently_trained_layer-1]->fprop(greedy_activation,
+                                    greedy_expectation);
+        
+        reconstruction_connections[ currently_trained_layer-1 ]->fprop( 
+            greedy_expectation,
+            reconstruction_activations);
+        layers[ currently_trained_layer-1 ]->fprop( 
+            reconstruction_activations,
+            layers[ currently_trained_layer-1 ]->expectation);
+        
+        layers[ currently_trained_layer-1 ]->activation << 
+            reconstruction_activations;
+        layers[ currently_trained_layer-1 ]->setExpectationByRef( 
+            layers[ currently_trained_layer-1 ]->expectation);
+        costs[ currently_trained_layer-1 ]  = 
+            layers[ currently_trained_layer-1 ]->fpropNLL(
+                expectations[currently_trained_layer-1]);
+    }
+
+    if( ((int)round(output[0])) == ((int)round(target[0])) )
+        costs[n_layers-1] = 0;
+    else
+        costs[n_layers-1] = 1;
+}
+
+//////////
+// test //
+//////////
+void DeepNonLocalManifoldParzen::updateTrainSetRepresentations() const
+{
+    if(!train_set_representations_up_to_date)
+    {
+        // Precompute training set examples' representation
+        int l = min(currently_trained_layer,n_layers-1);
+        Vec input( inputsize() );
+        Vec target( targetsize() );
+        Vec train_set_representation;
+        real weight;
+
+        train_set_representations.resize(train_set->length(), layers[l]->size);
+        train_set_targets.resize(train_set->length());
+        
+        for(int i=0; i<train_set->length(); i++)
+        {
+            train_set->getExample(i,input,target,weight);
+            computeRepresentation(input,train_set_representation,l);
+            train_set_representations(i) << train_set_representation;
+            train_set_targets[i] = (int)round(target[0]);
+        }
+        train_set_representations_vmat = VMat(train_set_representations);
+
+        train_set_representations_up_to_date = true;
+    }
+}
+
+TVec<string> DeepNonLocalManifoldParzen::getTestCostNames() const
+{
+    // Return the names of the costs computed by computeCostsFromOutputs
+    // (these may or may not be exactly the same as what's returned by
+    // getTrainCostNames).
+
+    TVec<string> cost_names(0);
+
+    for( int i=0; i<layers.size()-1; i++)
+        cost_names.push_back("reconstruction_error_" + tostring(i+1));
+    
+    cost_names.append( "class_error" );
+
+    return cost_names;
+}
+
+TVec<string> DeepNonLocalManifoldParzen::getTrainCostNames() const
+{
+    TVec<string> cost_names = getTestCostNames();
+    cost_names.append( "NLL_neighbors" );
+    return cost_names ;    
+}
+
+void DeepNonLocalManifoldParzen::setTrainingSet(VMat training_set, bool call_forget)
+{
+    inherited::setTrainingSet(training_set,call_forget);
+    
+    manifold_parzen_parameters_are_up_to_date = false;
+
+    if( save_manifold_parzen_parameters )
+    {
+        eigenvectors.resize(train_set->length());
+        eigenvalues.resize(train_set->length(),n_components);
+        sigma_noises.resize(train_set->length());
+        mus.resize(train_set->length(), inputsize());
+    }
+
+    Vec input( inputsize() );
+    Vec target( targetsize() );
+    real weight; // unused
+    
+    // Separate classes
+    class_datasets.resize(n_classes);
+    for(int k=0; k<n_classes; k++)
+    {
+        class_datasets[k] = new ClassSubsetVMatrix();
+        class_datasets[k]->classes.resize(1);
+        class_datasets[k]->classes[0] = k;
+        class_datasets[k]->source = training_set;
+        class_datasets[k]->build();
+    }
+    
+    // Find other classes proportions
+    class_proportions.resize(n_classes);
+    class_proportions.fill(0);
+    real sum = 0;
+    for(int k=0; k<n_classes; k++)
+    {
+        class_proportions[k] = class_datasets[k]->length();
+        sum += class_datasets[k]->length();
+    }
+    class_proportions /= sum;
+}
+
+
+//#####  Helper functions  ##################################################
+
+void DeepNonLocalManifoldParzen::setLearningRate( real the_learning_rate )
+{
+    for( int i=0 ; i<n_layers-1 ; i++ )
+    {
+        layers[i]->setLearningRate( the_learning_rate );
+        connections[i]->setLearningRate( the_learning_rate );
+    }
+    layers[n_layers-1]->setLearningRate( the_learning_rate );
+    output_connections->setLearningRate( the_learning_rate );
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2007-11-23 23:10:22 UTC (rev 8296)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2007-11-26 12:35:33 UTC (rev 8297)
@@ -0,0 +1,360 @@
+// -*- C++ -*-
+
+// DeepNonLocalManifoldParzen.h
+//
+// Copyright (C) 2007 Hugo Larochelle
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Hugo Larochelle
+
+/*! \file DeepNonLocalManifoldParzen.h */
+
+
+#ifndef DeepNonLocalManifoldParzen_INC
+#define DeepNonLocalManifoldParzen_INC
+
+#include <plearn/vmat/ClassSubsetVMatrix.h>
+#include <plearn_learners/generic/PLearner.h>
+#include <plearn_learners/online/OnlineLearningModule.h>
+#include <plearn_learners/online/CostModule.h>
+#include <plearn_learners/online/NLLCostModule.h>
+#include <plearn_learners/online/RBMClassificationModule.h>
+#include <plearn_learners/online/RBMLayer.h>
+#include <plearn_learners/online/RBMMixedLayer.h>
+#include <plearn_learners/online/RBMConnection.h>
+#include <plearn/misc/PTimer.h>
+
+namespace PLearn {
+
+/**
+ * Neural net, trained layer-wise to predict the manifold structure of the data.
+ * This information is used in a Manifold Parzen Windows classifier.
+ */
+class DeepNonLocalManifoldParzen : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! Contrastive divergence learning rate
+    real cd_learning_rate;
+    
+    //! Contrastive divergence decrease constant
+    real cd_decrease_ct;
+
+    //! The learning rate used during the autoassociator gradient descent training
+    real greedy_learning_rate;
+
+    //! The decrease constant of the learning rate used during the autoassociator
+    //! gradient descent training. When a hidden layer has finished its training,
+    //! the learning rate is reset to it's initial value.
+    real greedy_decrease_ct;
+
+    //! The learning rate used during the fine tuning gradient descent
+    real fine_tuning_learning_rate;
+
+    //! The decrease constant of the learning rate used during fine tuning
+    //! gradient descent
+    real fine_tuning_decrease_ct;
+
+    //! Number of examples to use during each phase of greedy pre-training.
+    //! The number of fine-tunig steps is defined by nstages.
+    TVec<int> training_schedule;
+
+    //! The layers of units in the network
+    TVec< PP<RBMLayer> > layers;
+
+    //! The weights of the connections between the layers
+    TVec< PP<RBMConnection> > connections;
+
+    //! The reconstruction weights of the autoassociators
+    TVec< PP<RBMConnection> > reconstruction_connections;
+
+    //! Number of nearest neighbors to use to learn
+    //! the manifold structure.
+    int k_neighbors;
+
+    //! Dimensionality of the manifold
+    real n_components;
+
+    //! Minimum value for the noise variance.
+    real min_sigma_noise;
+
+    //! Number of classes
+    int n_classes;
+
+    //! Output weights L1 penalty factor
+    real output_connections_l1_penalty_factor;
+
+    //! Output weights L2 penalty factor
+    real output_connections_l2_penalty_factor;
+
+    //! Indication that the parameters for the manifold parzen
+    //! windows estimator should be saved during test, to speed up testing.
+    bool save_manifold_parzen_parameters;
+
+    //! Indication that the saved manifold parzen parameters are up to date.
+    bool manifold_parzen_parameters_are_up_to_date;
+
+    //#####  Public Learnt Options  ###########################################
+
+    //! Number of layers
+    int n_layers;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    DeepNonLocalManifoldParzen();
+
+    //#####  PLearner Member Functions  #######################################
+
+    //! Returns the size of this learner's output, (which typically
+    //! may depend on its inputsize(), targetsize() and set options).
+    virtual int outputsize() const;
+
+    //! (Re-)initializes the PLearner in its fresh state (that state may depend
+    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
+    //! a fresh learner!).
+    virtual void forget();
+
+    //! The role of the train method is to bring the learner up to
+    //! stage==nstages, updating the train_stats collector with training costs
+    //! measured on-line in the process.
+    virtual void train();
+
+    //! Computes the output from the input.
+    virtual void computeOutput(const Vec& input, Vec& output) const;
+
+    //! Computes the costs from already computed output.
+    virtual void computeCostsFromOutputs(const Vec& input, const Vec& output,
+                                         const Vec& target, Vec& costs) const;
+
+    /**
+     *  Precomputes the representations of the training set examples, 
+     *  to speed up nearest neighbors searches in that space.
+     */
+    virtual void updateTrainSetRepresentations() const;
+
+    //! Returns the names of the costs computed by computeCostsFromOutpus (and
+    //! thus the test method).
+    virtual TVec<std::string> getTestCostNames() const;
+
+    //! Returns the names of the objective costs that the train method computes
+    //! and  for which it updates the VecStatsCollector train_stats.
+    virtual TVec<std::string> getTrainCostNames() const;
+
+    /**
+     *  Declares the training set.  Then calls build() and forget() if
+     *  necessary.  Also sets this learner's inputsize_ targetsize_ weightsize_
+     *  from those of the training_set.  Note: You shouldn't have to override
+     *  this in subclasses, except in maybe to forward the call to an
+     *  underlying learner.
+     */
+    virtual void setTrainingSet(VMat training_set, bool call_forget=true);
+
+    void greedyStep( const Vec& input, const Vec& target, int index, 
+                     Vec train_costs, int stage, Vec similar_example,
+                     Vec dissimilar_example);
+
+    void fineTuningStep( const Vec& input, const Vec& target,
+                         Vec& train_costs, Mat nearest_neighbors);
+
+    void computeRepresentation( const Vec& input, 
+                                Vec& representation, int layer) const;
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(DeepNonLocalManifoldParzen);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Not Options  #####################################################
+
+    //! Stores the activations of the input and hidden layers
+    //! (at the input of the layers)
+    mutable TVec<Vec> activations;
+
+    //! Stores the expectations of the input and hidden layers
+    //! (at the output of the layers)
+    mutable TVec<Vec> expectations;
+
+    //! Stores the gradient of the cost wrt the activations of 
+    //! the input and hidden layers
+    //! (at the input of the layers)
+    mutable TVec<Vec> activation_gradients;
+
+    //! Stores the gradient of the cost wrt the expectations of 
+    //! the input and hidden layers
+    //! (at the output of the layers)
+    mutable TVec<Vec> expectation_gradients;
+
+    //! Reconstruction activations
+    mutable Vec reconstruction_activations;
+    
+    //! Reconstruction activation gradients
+    mutable Vec reconstruction_activation_gradients;
+
+    //! Reconstruction expectation gradients
+    mutable Vec reconstruction_expectation_gradients;
+
+    //! Output weights
+    mutable PP<OnlineLearningModuling> output_connections;
+    
+    //! Example representation
+    mutable Vec input_representation;
+
+    //! Example representation at the previous layer, in a greedy step
+    Vec previous_input_representation;
+
+    //! All outputs that give the components and sigma_noise values.
+    mutable Vec all_outputs;
+
+    //! All outputs' gradients
+    Vec all_outputs_gradient;
+
+    //! Variables for density of a Gaussian
+    Mat F, F_copy;
+    Vec mu;
+    Vec pre_sigma_noise;
+
+    //! Variables for the SVD and gradient computation
+    Mat Ut, U, V, z, invSigma_F, invSigma_z;
+    Vec temp_ncomp, diff_neighbor_input, sm_svd, sn, S;
+    Vec uk, fk, uk2, inv_sigma_zj, zj, inv_sigma_fk;
+
+    //! Positive down statistic
+    Vec pos_down_val;
+    //! Positive up statistic
+    Vec pos_up_val;
+    //! Negative down statistic
+    Vec neg_down_val;
+    //! Negative up statistic
+    Vec neg_up_val;
+
+    // Saved components of manifold parzen windows
+
+    //! Eigenvectors
+    TVec<Mat> eigenvectors;
+    //! Eigenvalues
+    Mat eigenvalues;
+    //! Sigma noises
+    Vec sigma_noises;
+    //! Mus
+    Mat mus;
+
+    //! Datasets for each class
+    TVec< PP<ClassSubsetVMatrix> > class_datasets;
+
+    //! Proportions of examples from the other classes (columns), for each
+    //! class (rows)
+    Vec class_proportions;
+
+    //! Nearest neighbors for each training example
+    TMat<int> nearest_neighbors_indices;
+
+    //! Nearest neighbors for each test example
+    mutable TVec<int> test_nearest_neighbors_indices;
+
+    //! Nearest neighbor votes for test example
+    TVec<int> test_votes;
+
+    //! Data set mapped to last hidden layer space
+    mutable Mat train_set_representations;
+    mutable VMat train_set_representations_vmat;
+    mutable TVec<int> train_set_targets;
+
+    //! Indication that train_set_representations is up to date
+    mutable bool train_set_representations_up_to_date;
+
+    //! Stages of the different greedy phases
+    TVec<int> greedy_stages;
+
+    //! Currently trained layer (1 means the first hidden layer,
+    //! n_layers means the output layer)
+    int currently_trained_layer;
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+
+    void build_layers_and_connections();
+
+    void build_classification_cost();
+
+    void bprop_to_bases(const Mat& R, const Mat& M, 
+                        const Vec& v1, 
+                        const Vec& v2, real alpha);
+        
+    void setLearningRate( real the_learning_rate );
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here    
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(DeepNonLocalManifoldParzen);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From nouiz at mail.berlios.de  Mon Nov 26 16:56:09 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 26 Nov 2007 16:56:09 +0100
Subject: [Plearn-commits] r8298 - trunk/plearn/vmat
Message-ID: <200711261556.lAQFu924019881@sheep.berlios.de>

Author: nouiz
Date: 2007-11-26 16:56:08 +0100 (Mon, 26 Nov 2007)
New Revision: 8298

Modified:
   trunk/plearn/vmat/MissingIndicatorVMatrix.cc
   trunk/plearn/vmat/MissingIndicatorVMatrix.h
Log:
code clean up


Modified: trunk/plearn/vmat/MissingIndicatorVMatrix.cc
===================================================================
--- trunk/plearn/vmat/MissingIndicatorVMatrix.cc	2007-11-26 12:35:33 UTC (rev 8297)
+++ trunk/plearn/vmat/MissingIndicatorVMatrix.cc	2007-11-26 15:56:08 UTC (rev 8298)
@@ -129,41 +129,6 @@
   return source->get(i, source_rel_pos[j]);
 }
 
-void MissingIndicatorVMatrix::put(int i, int j, real value)
-{
-  PLERROR("In MissingIndicatorVMatrix::put not implemented");
-}
-
-void MissingIndicatorVMatrix::getSubRow(int i, int j, Vec v) const
-{  
-  for (int source_col = j; source_col < j + v.length(); source_col++) v[source_col] = get(i, source_col);
-}
-
-void MissingIndicatorVMatrix::putSubRow(int i, int j, Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::putSubRow not implemented");
-}
-
-void MissingIndicatorVMatrix::appendRow(Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::appendRow not implemented");
-}
-
-void MissingIndicatorVMatrix::insertRow(int i, Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::insertRow not implemented");
-}
-
-void MissingIndicatorVMatrix::getRow(int i, Vec v) const
-{  
-  for (int source_col = 0; source_col < width_; source_col++) v[source_col] = get(i, source_col); 
-}
-
-void MissingIndicatorVMatrix::putRow(int i, Vec v)
-{
-  PLERROR("In MissingIndicatorVMatrix::putRow not implemented");
-}
-
 void MissingIndicatorVMatrix::getColumn(int i, Vec v) const
 {
   if (source_rel_pos[i] < 0) source->getColumn(source_rel_pos[i - 1], v);
@@ -184,6 +149,8 @@
 
 void MissingIndicatorVMatrix::buildNewRecordFormat()
 {
+    source_inputsize = source->inputsize();
+  
     int train_length = train_set->length();
     if (number_of_train_samples_to_use > 0.0)
         if (number_of_train_samples_to_use < 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
@@ -193,7 +160,6 @@
     int train_width = train_set->width();
     int train_inputsize = train_set->inputsize();
     int source_width = source->width();
-    source_inputsize = source->inputsize();
 
     if(train_length < 1) 
       PLERROR("In MissingIndicatorVMatrix::length of the number of train"
@@ -216,7 +182,7 @@
       PLERROR("In MissingIndicatorVMatrix::train set and source inputsize"
 	      " must agree, got : %i, %i", train_inputsize, source_inputsize);
 
-    train_input.resize(train_width);
+    Vec train_input(train_width);
     train_var_missing.resize(train_inputsize);
     train_var_missing.clear();
 

Modified: trunk/plearn/vmat/MissingIndicatorVMatrix.h
===================================================================
--- trunk/plearn/vmat/MissingIndicatorVMatrix.h	2007-11-26 12:35:33 UTC (rev 8297)
+++ trunk/plearn/vmat/MissingIndicatorVMatrix.h	2007-11-26 15:56:08 UTC (rev 8298)
@@ -80,18 +80,10 @@
 
   virtual void         getExample(int i, Vec& input, Vec& target, real& weight);
   virtual real         get(int i, int j) const;
-  virtual void         put(int i, int j, real value);
-  virtual void         getSubRow(int i, int j, Vec v) const;
-  virtual void         putSubRow(int i, int j, Vec v);
-  virtual void         appendRow(Vec v);
-  virtual void         insertRow(int i, Vec v);  
-  virtual void         getRow(int i, Vec v) const;
-  virtual void         putRow(int i, Vec v);
   virtual void         getColumn(int i, Vec v) const;
 
 private:
   
-  Vec          train_input;
   TVec<int>    train_var_missing;
   int          source_inputsize;
   Vec          source_input;



From tihocan at mail.berlios.de  Mon Nov 26 18:18:39 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Mon, 26 Nov 2007 18:18:39 +0100
Subject: [Plearn-commits] r8299 - trunk/plearn_learners/online
Message-ID: <200711261718.lAQHIdrp026624@sheep.berlios.de>

Author: tihocan
Date: 2007-11-26 18:18:39 +0100 (Mon, 26 Nov 2007)
New Revision: 8299

Modified:
   trunk/plearn_learners/online/SplitModule.cc
Log:
The bpropAccUpdate was completely bugged when using as a split

Modified: trunk/plearn_learners/online/SplitModule.cc
===================================================================
--- trunk/plearn_learners/online/SplitModule.cc	2007-11-26 15:56:08 UTC (rev 8298)
+++ trunk/plearn_learners/online/SplitModule.cc	2007-11-26 17:18:39 UTC (rev 8299)
@@ -183,12 +183,13 @@
         for (int i=0;i<up_port_sizes.length();i++)
         {
             int width = up_port_sizes[i];
-            if (ports_gradient[i+1])
-            {
-                PLASSERT_MSG(ports_gradient[i+1]->isEmpty(),"In SplitModule, when the down_port is an input, the up_ports should either be outputs or not connected.\n");
-                input_gradient.resize(ports_gradient[i+1]->length(),width);
-                input_gradient.subMatColumns(start,width) += *ports_value[i+1];
-            }
+            PLASSERT_MSG( ports_gradient[i+1] &&
+                          !ports_gradient[i+1]->isEmpty(),
+                          "In SplitModule::bpropAccUpdate - When the down_port"
+                          " is an input and its gradient is required, one must"
+                          " provide a gradient on the up_ports" );
+            input_gradient.resize(ports_gradient[i+1]->length(), width);
+            input_gradient.subMatColumns(start, width) += *ports_gradient[i+1];
             start += width;
         }
         return;



From tihocan at mail.berlios.de  Mon Nov 26 18:40:36 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Mon, 26 Nov 2007 18:40:36 +0100
Subject: [Plearn-commits] r8300 - trunk/plearn_learners/online
Message-ID: <200711261740.lAQHeaNH017565@sheep.berlios.de>

Author: tihocan
Date: 2007-11-26 18:40:35 +0100 (Mon, 26 Nov 2007)
New Revision: 8300

Modified:
   trunk/plearn_learners/online/SplitModule.cc
Log:
Fixed another bug in bpropAccUpdate

Modified: trunk/plearn_learners/online/SplitModule.cc
===================================================================
--- trunk/plearn_learners/online/SplitModule.cc	2007-11-26 17:18:39 UTC (rev 8299)
+++ trunk/plearn_learners/online/SplitModule.cc	2007-11-26 17:40:35 UTC (rev 8300)
@@ -188,7 +188,8 @@
                           "In SplitModule::bpropAccUpdate - When the down_port"
                           " is an input and its gradient is required, one must"
                           " provide a gradient on the up_ports" );
-            input_gradient.resize(ports_gradient[i+1]->length(), width);
+            input_gradient.resize(ports_gradient[i+1]->length(),
+                                  input_gradient.width());
             input_gradient.subMatColumns(start, width) += *ports_gradient[i+1];
             start += width;
         }



From nouiz at mail.berlios.de  Mon Nov 26 20:10:35 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 26 Nov 2007 20:10:35 +0100
Subject: [Plearn-commits] r8301 - trunk/plearn/vmat
Message-ID: <200711261910.lAQJAZeO019419@sheep.berlios.de>

Author: nouiz
Date: 2007-11-26 20:10:34 +0100 (Mon, 26 Nov 2007)
New Revision: 8301

Modified:
   trunk/plearn/vmat/VMatrix.cc
Log:
better error message


Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-11-26 17:40:35 UTC (rev 8300)
+++ trunk/plearn/vmat/VMatrix.cc	2007-11-26 19:10:34 UTC (rev 8301)
@@ -395,7 +395,8 @@
             i = -1;
     }
     if (i < 0 || i >= width())
-        PLERROR("In VMatrix::getFieldIndex - Asked for an invalid column number");
+        PLERROR("In VMatrix::getFieldIndex - Asked for an invalid column number: '%s'",
+                fieldname_or_num.c_str()));
     return i;
 }
 



From nouiz at mail.berlios.de  Mon Nov 26 20:12:22 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 26 Nov 2007 20:12:22 +0100
Subject: [Plearn-commits] r8302 - trunk/plearn/vmat
Message-ID: <200711261912.lAQJCMoL019512@sheep.berlios.de>

Author: nouiz
Date: 2007-11-26 20:12:21 +0100 (Mon, 26 Nov 2007)
New Revision: 8302

Modified:
   trunk/plearn/vmat/VMatrix.cc
Log:
fix last commit


Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-11-26 19:10:34 UTC (rev 8301)
+++ trunk/plearn/vmat/VMatrix.cc	2007-11-26 19:12:21 UTC (rev 8302)
@@ -396,7 +396,7 @@
     }
     if (i < 0 || i >= width())
         PLERROR("In VMatrix::getFieldIndex - Asked for an invalid column number: '%s'",
-                fieldname_or_num.c_str()));
+                fieldname_or_num.c_str());
     return i;
 }
 



From nouiz at mail.berlios.de  Mon Nov 26 21:31:40 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 26 Nov 2007 21:31:40 +0100
Subject: [Plearn-commits] r8303 - trunk/plearn/vmat
Message-ID: <200711262031.lAQKVeCP024278@sheep.berlios.de>

Author: nouiz
Date: 2007-11-26 21:31:38 +0100 (Mon, 26 Nov 2007)
New Revision: 8303

Modified:
   trunk/plearn/vmat/GaussianizeVMatrix.cc
   trunk/plearn/vmat/VMatrix.cc
   trunk/plearn/vmat/VMatrix.h
Log:
Added function VMatrix::getPrecomputedStatsFromFile(const string filename, const int maxnvalues, bool progress_bar) that will compute the stats for a vmat and store the result in a file. Will reuse the result from the file if it already exist.


Modified: trunk/plearn/vmat/GaussianizeVMatrix.cc
===================================================================
--- trunk/plearn/vmat/GaussianizeVMatrix.cc	2007-11-26 19:12:21 UTC (rev 8302)
+++ trunk/plearn/vmat/GaussianizeVMatrix.cc	2007-11-26 20:31:38 UTC (rev 8303)
@@ -172,8 +172,10 @@
                 TVec<int>(col, col + the_source->extrasize() - 1, 1));
     col += the_source->extrasize();
 
-    // Compute source statistics.
-    TVec<StatsCollector> stats = PLearn::computeStats(the_source, -1, false);
+    the_source->lockMetaDataDir();
+    TVec<StatsCollector> stats = the_source->
+        getPrecomputedStatsFromFile("stats_gaussianizeVMatrix.psave", -1, true);
+    the_source->unlockMetaDataDir();
 
     // See which dimensions violate the Gaussian assumption and will be
     // actually Gaussianized, and store the corresponding list of values.

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-11-26 19:12:21 UTC (rev 8302)
+++ trunk/plearn/vmat/VMatrix.cc	2007-11-26 20:31:38 UTC (rev 8303)
@@ -1372,24 +1372,33 @@
 TVec<StatsCollector> VMatrix::getStats() const
 {
     if(!field_stats)
+        field_stats = getPrecomputedStatsFromFile("stats.psave", 2000, false);
+    return field_stats;
+}
+
+/////////////////////////
+// getPrecomputedStats //
+/////////////////////////
+TVec<StatsCollector> VMatrix::getPrecomputedStatsFromFile(const string filename, const int maxnvalues, bool progress_bar) const
+{
+    TVec<StatsCollector> stats;
+    PPath metadatadir = getMetaDataDir();
+    PPath statsfile =  metadatadir + filename;
+    if (isfile(statsfile) && getMtime()<mtime(statsfile))
     {
-        PPath metadatadir = getMetaDataDir();
-        PPath statsfile =  metadatadir / "stats.psave";
-        if (isfile(statsfile) && getMtime()<mtime(statsfile))
-        {
-            if(getMtime()==0)
-                PLWARNING("Warning: using a saved stat file (%s) but mtime is 0.\n(cannot be sure file is up to date)",statsfile.absolute().c_str());
-            PLearn::load(statsfile, field_stats);
-        }
-        else
-        {
-            VMat vm = const_cast<VMatrix*>(this);
-            field_stats = PLearn::computeStats(vm, 2000);
-            if(!metadatadir.isEmpty())
-                PLearn::save(statsfile, field_stats);
-        }
+        if(getMtime()==0)
+            PLWARNING("Warning: using a saved stat file (%s) but mtime is 0.\n(cannot be sure file is up to date)",
+                      statsfile.absolute().c_str());
+        PLearn::load(statsfile, stats);
     }
-    return field_stats;
+    else
+    {
+        VMat vm = const_cast<VMatrix*>(this);
+        stats = PLearn::computeStats(vm, maxnvalues, progress_bar);
+        if(!metadatadir.isEmpty())
+            PLearn::save(statsfile, stats);
+    }
+    return stats;
 }
 
 TVec<PP<StatsCollector> > VMatrix::remote_getStats() const

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2007-11-26 19:12:21 UTC (rev 8302)
+++ trunk/plearn/vmat/VMatrix.h	2007-11-26 20:31:38 UTC (rev 8303)
@@ -589,6 +589,8 @@
      *  created).
      */
     TVec<StatsCollector> getStats() const;
+    TVec<StatsCollector> getPrecomputedStatsFromFile(const string filename, const int maxnvalues, bool progress_bar) const;
+
     TVec<PP<StatsCollector> > remote_getStats() const;
 
     StatsCollector& getStats(int fieldnum) const



From nouiz at mail.berlios.de  Mon Nov 26 21:50:59 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 26 Nov 2007 21:50:59 +0100
Subject: [Plearn-commits] r8304 - trunk/python_modules/plearn/learners
Message-ID: <200711262050.lAQKoxMA026248@sheep.berlios.de>

Author: nouiz
Date: 2007-11-26 21:50:57 +0100 (Mon, 26 Nov 2007)
New Revision: 8304

Modified:
   trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py
Log:
-use = in file name instead of # as # is a comment char in plearn script and this cause trouble.
-reuse the mat file so that we don't renereta it often


Modified: trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py
===================================================================
--- trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py	2007-11-26 20:31:38 UTC (rev 8303)
+++ trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py	2007-11-26 20:50:57 UTC (rev 8304)
@@ -165,7 +165,7 @@
         costs=self.computeCostsFromOutput(input,output,target)
         return (output,costs)
 
-    def test(self,testSet,test_stats,return_outputs,return_costs):
+    def test(self,testSet,testMat,test_stats,return_outputs,return_costs):
         testSet1=pl.ProcessingVMatrix(source=testSet,
                                prg = "[%0:%"+str(testSet.inputsize-1)+"] @CLASSE_REEL 1 0 ifelse :CLASSE_REEL")
         testSet2=pl.ProcessingVMatrix(source=testSet,
@@ -182,8 +182,7 @@
         outputs=[]
         costs=[]
         #calculate stats, outputs, costs
-        test_mat=testSet.getMat()
-        for i in range(len(test_mat)):
+        for i in range(len(testMat)):
             out1=testoutputs1[i][0]
             out2=testoutputs2[i][0]
             ind1=int(round(out1))
@@ -199,8 +198,8 @@
             output=[ind,out1,out2]
             if return_outputs:
                 outputs.append(output)
-            input=test_mat[i][:-1]
-            target=test_mat[i][-1]
+            input=testMat[i][:-1]
+            target=testMat[i][-1]
             cost=self.computeCostsFromOutput(input,output,target,
                                              forward_sub_learner_costs=False)
             cost.extend(testcosts1[i])
@@ -220,8 +219,8 @@
             path+="/"
         else:
             print "WARNING: AdaBoost3PLearner - no path for saving the learner, we use the current directory"
-        self.learner1.save(path+"learner1_stage#"+str(self.stage)+".psave",encoding)
-        self.learner2.save(path+"learner2_stage#"+str(self.stage)+".psave",encoding)
+        self.learner1.save(path+"learner1_stage="+str(self.stage)+".psave",encoding)
+        self.learner2.save(path+"learner2_stage="+str(self.stage)+".psave",encoding)
     
     def load_old_learner(self,filepath=None,trainSet1=None,trainSet2=None,stage1=-1,stage2=-1):
         assert(trainSet1 and trainSet2)



From nouiz at mail.berlios.de  Mon Nov 26 22:08:41 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Mon, 26 Nov 2007 22:08:41 +0100
Subject: [Plearn-commits] r8305 - trunk/plearn_learners/regressors
Message-ID: <200711262108.lAQL8ft8027722@sheep.berlios.de>

Author: nouiz
Date: 2007-11-26 22:08:40 +0100 (Mon, 26 Nov 2007)
New Revision: 8305

Modified:
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
Log:
bugfix


Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-26 20:50:57 UTC (rev 8304)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-26 21:08:40 UTC (rev 8305)
@@ -374,7 +374,10 @@
             missing_node->computeOutput(inputv, outputv);
         }
         else
+        {
+            tmp_vec.resize(3);
             missing_leave->getOutputAndError(outputv,tmp_vec);
+        }
         return;
     }
     if (inputv[split_col] > split_feature_value)



From nouiz at mail.berlios.de  Tue Nov 27 18:52:17 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 18:52:17 +0100
Subject: [Plearn-commits] r8306 - trunk/plearn/vmat
Message-ID: <200711271752.lARHqHmf004847@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 18:52:17 +0100 (Tue, 27 Nov 2007)
New Revision: 8306

Modified:
   trunk/plearn/vmat/MeanMedianModeImputationVMatrix.cc
Log:
better error message


Modified: trunk/plearn/vmat/MeanMedianModeImputationVMatrix.cc
===================================================================
--- trunk/plearn/vmat/MeanMedianModeImputationVMatrix.cc	2007-11-26 21:08:40 UTC (rev 8305)
+++ trunk/plearn/vmat/MeanMedianModeImputationVMatrix.cc	2007-11-27 17:52:17 UTC (rev 8306)
@@ -217,8 +217,8 @@
       if(variable_imputation_instruction[i]==0)
 	no_instruction.append(train_field_names[i]);
     if(no_instruction.size()>0)
-      PLWARNING("In MeanMedianModeImputationVMatrix::build_() In the source VMatrix some fields do not have instruction: '%s'.",
-		tostring(no_instruction).c_str());
+      PLWARNING("In MeanMedianModeImputationVMatrix::build_() In the source VMatrix their is %d field(s) that do not have instruction: '%s'.",
+		no_instruction.size(),tostring(no_instruction).c_str());
     PPath train_metadata = train_set->getMetaDataDir();
     PPath mean_median_mode_file_name = train_metadata + "mean_median_mode_file.pmat";
     train_set->lockMetaDataDir();



From nouiz at mail.berlios.de  Tue Nov 27 18:52:44 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 18:52:44 +0100
Subject: [Plearn-commits] r8307 - trunk/plearn/vmat
Message-ID: <200711271752.lARHqis5005371@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 18:52:39 +0100 (Tue, 27 Nov 2007)
New Revision: 8307

Modified:
   trunk/plearn/vmat/MemoryVMatrixNoSave.cc
Log:
call parent constructor


Modified: trunk/plearn/vmat/MemoryVMatrixNoSave.cc
===================================================================
--- trunk/plearn/vmat/MemoryVMatrixNoSave.cc	2007-11-27 17:52:17 UTC (rev 8306)
+++ trunk/plearn/vmat/MemoryVMatrixNoSave.cc	2007-11-27 17:52:39 UTC (rev 8307)
@@ -52,6 +52,7 @@
 // MemoryVMatrixNoSave //
 //////////////////
 MemoryVMatrixNoSave::MemoryVMatrixNoSave()
+    : inherited()
 /* ### Initialize all fields to their default value here */
 {
     // ...



From nouiz at mail.berlios.de  Tue Nov 27 18:53:28 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 18:53:28 +0100
Subject: [Plearn-commits] r8308 - trunk/plearn/vmat
Message-ID: <200711271753.lARHrSjY006245@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 18:53:25 +0100 (Tue, 27 Nov 2007)
New Revision: 8308

Modified:
   trunk/plearn/vmat/MemoryVMatrix.cc
Log:
init option


Modified: trunk/plearn/vmat/MemoryVMatrix.cc
===================================================================
--- trunk/plearn/vmat/MemoryVMatrix.cc	2007-11-27 17:52:39 UTC (rev 8307)
+++ trunk/plearn/vmat/MemoryVMatrix.cc	2007-11-27 17:53:25 UTC (rev 8308)
@@ -86,6 +86,7 @@
     : inherited(the_source->length(), the_source->width()),
       memory_data(the_source->toMat()),
       synch_data(false),
+      source(the_source),
       deep_copy_memory_data(true)
 
 {



From nouiz at mail.berlios.de  Tue Nov 27 18:59:09 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 18:59:09 +0100
Subject: [Plearn-commits] r8309 - trunk/plearn/math
Message-ID: <200711271759.lARHx9mw010753@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 18:59:08 +0100 (Tue, 27 Nov 2007)
New Revision: 8309

Modified:
   trunk/plearn/math/VecStatsCollector.cc
Log:
we should be able to append empty VecStatsCollector


Modified: trunk/plearn/math/VecStatsCollector.cc
===================================================================
--- trunk/plearn/math/VecStatsCollector.cc	2007-11-27 17:53:25 UTC (rev 8308)
+++ trunk/plearn/math/VecStatsCollector.cc	2007-11-27 17:59:08 UTC (rev 8309)
@@ -758,7 +758,7 @@
     }
     else {
         const int n = vsc.stats.size();
-        assert (vsc.fieldnames.size() == n );
+        PLASSERT(vsc.fieldnames.size() == n || n == 0);
         fieldnames.resize(fieldnames.size(), n);
         for (int i=0 ; i<n ; ++i)
             fieldnames.append(fieldname_prefix + vsc.fieldnames[i]);



From nouiz at mail.berlios.de  Tue Nov 27 19:14:17 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 19:14:17 +0100
Subject: [Plearn-commits] r8310 - trunk/plearn/vmat
Message-ID: <200711271814.lARIEH1C029052@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 19:14:12 +0100 (Tue, 27 Nov 2007)
New Revision: 8310

Modified:
   trunk/plearn/vmat/MissingIndicatorVMatrix.cc
   trunk/plearn/vmat/MissingIndicatorVMatrix.h
Log:
Allow to give a list of the variable to add an indicator instead of giving a training_set


Modified: trunk/plearn/vmat/MissingIndicatorVMatrix.cc
===================================================================
--- trunk/plearn/vmat/MissingIndicatorVMatrix.cc	2007-11-27 17:59:08 UTC (rev 8309)
+++ trunk/plearn/vmat/MissingIndicatorVMatrix.cc	2007-11-27 18:14:12 UTC (rev 8310)
@@ -85,6 +85,9 @@
                 "The number of samples from the train set that will be examined to see\n"
                 "if an indicator should be added for each variable\n");
 
+  declareOption(ol, "fields", &MissingIndicatorVMatrix::fields, OptionBase::buildoption,
+		"The names of the fields to extract if the train_set is not provided.");
+
   inherited::declareOptions(ol);
 }
 
@@ -99,6 +102,10 @@
   deepCopyField(source, copies);
   deepCopyField(train_set, copies);
   deepCopyField(number_of_train_samples_to_use, copies);
+  deepCopyField(train_var_missing, copies);
+  deepCopyField(source_rel_pos, copies);
+  deepCopyField(fields, copies);
+
   inherited::makeDeepCopyFromShallowCopy(copies);
 }
 
@@ -143,88 +150,106 @@
 
 void MissingIndicatorVMatrix::build_()
 {
-    if (!train_set || !source) PLERROR("In MissingIndicatorVMatrix::train set and source vmat must be supplied");
+    if (!source) PLERROR("In MissingIndicatorVMatrix:: source vmat must be supplied");
+    if(!train_set && !fields)
+      PLERROR("In MissingIndicatorVMatrix:: train_set or fields must be supplied");
     buildNewRecordFormat(); 
 }
 
 void MissingIndicatorVMatrix::buildNewRecordFormat()
 {
     source_inputsize = source->inputsize();
-  
-    int train_length = train_set->length();
-    if (number_of_train_samples_to_use > 0.0)
+    train_var_missing.resize(source_inputsize);
+    train_var_missing.clear();
+    int source_width = source->width();
+
+    if(train_set){
+      int train_length = train_set->length();
+      if (number_of_train_samples_to_use > 0.0)
         if (number_of_train_samples_to_use < 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
         else train_length = (int) number_of_train_samples_to_use;
-    if (train_length > train_set->length()) train_length = train_set->length();
+      if (train_length > train_set->length()) train_length = train_set->length();
 
-    int train_width = train_set->width();
-    int train_inputsize = train_set->inputsize();
-    int source_width = source->width();
+      int train_width = train_set->width();
+      int train_inputsize = train_set->inputsize();
 
-    if(train_length < 1) 
-      PLERROR("In MissingIndicatorVMatrix::length of the number of train"
-	      " samples to use must be at least 1, got: %i", train_length);
-    if(train_inputsize < 1) 
-      PLERROR("In MissingIndicatorVMatrix::inputsize of the train vmat must"
-	      " be supplied, got : %i", train_inputsize);
-    if (train_width != source_width) 
-      PLERROR("In MissingIndicatorVMatrix::train set and source width must"
-	      " agree, got : %i, %i", train_width, source_width);
-    if (train_set->targetsize() != source->targetsize())
-      PLERROR("In MissingIndicatorVMatrix::train set and source targetsize"
-	      " must agree, got : %i, %i", train_set->targetsize(),
-	      source->targetsize());
-    if (train_set->weightsize() != source->weightsize()) 
-      PLERROR("In MissingIndicatorVMatrix::train set and source weightsize"
-	      " must agree, got : %i, %i", train_set->weightsize(),
-	      source->weightsize());
-    if (train_inputsize != source_inputsize)
-      PLERROR("In MissingIndicatorVMatrix::train set and source inputsize"
-	      " must agree, got : %i, %i", train_inputsize, source_inputsize);
+      if(train_length < 1) 
+	PLERROR("In MissingIndicatorVMatrix::length of the number of train"
+		" samples to use must be at least 1, got: %i", train_length);
+      if(train_inputsize < 1) 
+	PLERROR("In MissingIndicatorVMatrix::inputsize of the train vmat must"
+		" be supplied, got : %i", train_inputsize);
+      if (train_width != source_width) 
+	PLERROR("In MissingIndicatorVMatrix::train set and source width must"
+		" agree, got : %i, %i", train_width, source_width);
+      if (train_set->targetsize() != source->targetsize())
+	PLERROR("In MissingIndicatorVMatrix::train set and source targetsize"
+		" must agree, got : %i, %i", train_set->targetsize(),
+		source->targetsize());
+      if (train_set->weightsize() != source->weightsize()) 
+	PLERROR("In MissingIndicatorVMatrix::train set and source weightsize"
+		" must agree, got : %i, %i", train_set->weightsize(),
+		source->weightsize());
+      if (train_inputsize != source_inputsize)
+	PLERROR("In MissingIndicatorVMatrix::train set and source inputsize"
+		" must agree, got : %i, %i", train_inputsize, source_inputsize);
 
-    Vec train_input(train_width);
-    train_var_missing.resize(train_inputsize);
-    train_var_missing.clear();
+      Vec train_input(train_width);
 
-    for (int train_row = 0; train_row < train_length; train_row++)
-    {
-         train_set->getRow(train_row, train_input);
-         for (int train_col = 0; train_col < train_inputsize; train_col++)
-         {
-             if (is_missing(train_input[train_col])) train_var_missing[train_col] = 1;
-         }
-    }
+      for (int train_row = 0; train_row < train_length; train_row++)
+	{
+	  train_set->getRow(train_row, train_input);
+	  for (int train_col = 0; train_col < train_inputsize; train_col++)
+	    {
+	      if (is_missing(train_input[train_col])) 
+		train_var_missing[train_col] = 1;
+	    }
+	}
+    }else if(fields.size()>0){
+      TVec<string> source_field_names = source->fieldNames();
+      for(int i=0;i<fields.size();i++)
+	{
+	  int index=source->getFieldIndex(fields[i]);
+	  if(index<0)
+	    PLERROR("In MissingIndicatorVMatrix::buildNewRecordFormat() - The fields '%s' is not in the source",
+		    fields[i].c_str());
+	  else
+	    train_var_missing[index]=1;
+ 	}
+      
+    }else
+       PLERROR("In MissingIndicatorVMatrix, the train_set or fields option should be provided.");
 
     int added_colomns = sum(train_var_missing);
-    width_ = train_width + added_colomns;
+    width_ = source_width + added_colomns;
 
-    TVec<string> train_field_names(train_width);
+    TVec<string> source_field_names(source_width);
     source_rel_pos.resize(width_);
     TVec<string> new_field_names(width_);
-    train_field_names = train_set->fieldNames();
+    source_field_names = source->fieldNames();
     int new_col = 0;
-    for (int train_col = 0; train_col < train_inputsize; train_col++)
+    for (int source_col = 0; source_col < source_inputsize; source_col++)
     {
-      new_field_names[new_col] = train_field_names[train_col];
-      source_rel_pos[new_col] = train_col;
+      new_field_names[new_col] = source_field_names[source_col];
+      source_rel_pos[new_col] = source_col;
       new_col += 1;
-      if (train_var_missing[train_col] > 0)
+      if (train_var_missing[source_col] > 0)
       {
-          new_field_names[new_col] = train_field_names[train_col] + "_MI";
+          new_field_names[new_col] = source_field_names[source_col] + "_MI";
           source_rel_pos[new_col] = -1;
           new_col += 1;
       }
     }
-    for (int train_col = train_inputsize; train_col < train_width; train_col++)
+    for (int source_col = source_inputsize; source_col < source_width; source_col++)
     {
-      new_field_names[new_col] = train_field_names[train_col];
-      source_rel_pos[new_col] = train_col;
+      new_field_names[new_col] = source_field_names[source_col];
+      source_rel_pos[new_col] = source_col;
       new_col += 1;
     }
     length_ = source->length();
-    inputsize_ = train_inputsize + added_colomns;
+    inputsize_ = source_inputsize + added_colomns;
     targetsize_ = source->targetsize();
-    weightsize_ = train_set->weightsize();
+    weightsize_ = source->weightsize();
     source_input.resize(source_inputsize);
     declareFieldNames(new_field_names);
 }

Modified: trunk/plearn/vmat/MissingIndicatorVMatrix.h
===================================================================
--- trunk/plearn/vmat/MissingIndicatorVMatrix.h	2007-11-27 17:59:08 UTC (rev 8309)
+++ trunk/plearn/vmat/MissingIndicatorVMatrix.h	2007-11-27 18:14:12 UTC (rev 8310)
@@ -67,8 +67,10 @@
   //! The number of samples from the train set that will be examined to see
   //! if an indicator should be added for each variable.
   real         number_of_train_samples_to_use;
-  
 
+  //!
+  TVec<string> fields; 
+
                         MissingIndicatorVMatrix();
                         MissingIndicatorVMatrix(VMat the_source, VMat the_train_set, real the_number_of_train_samples_to_use);
   virtual               ~MissingIndicatorVMatrix();



From nouiz at mail.berlios.de  Tue Nov 27 19:24:19 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 19:24:19 +0100
Subject: [Plearn-commits] r8311 - trunk/plearn/vmat
Message-ID: <200711271824.lARIOJFE021823@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 19:24:19 +0100 (Tue, 27 Nov 2007)
New Revision: 8311

Modified:
   trunk/plearn/vmat/MissingIndicatorVMatrix.cc
   trunk/plearn/vmat/MissingIndicatorVMatrix.h
Log:
localysed one variable


Modified: trunk/plearn/vmat/MissingIndicatorVMatrix.cc
===================================================================
--- trunk/plearn/vmat/MissingIndicatorVMatrix.cc	2007-11-27 18:14:12 UTC (rev 8310)
+++ trunk/plearn/vmat/MissingIndicatorVMatrix.cc	2007-11-27 18:24:19 UTC (rev 8311)
@@ -102,7 +102,6 @@
   deepCopyField(source, copies);
   deepCopyField(train_set, copies);
   deepCopyField(number_of_train_samples_to_use, copies);
-  deepCopyField(train_var_missing, copies);
   deepCopyField(source_rel_pos, copies);
   deepCopyField(fields, copies);
 
@@ -117,7 +116,7 @@
     {
       input[new_col] = source_input[source_col];
       new_col += 1;
-      if (train_var_missing[source_col] > 0)
+      if (source_rel_pos[source_col] < 0)
       {
           if (is_missing(source_input[source_col])) input[new_col] = 1.0;
           else input[new_col] = 0.0;
@@ -159,7 +158,7 @@
 void MissingIndicatorVMatrix::buildNewRecordFormat()
 {
     source_inputsize = source->inputsize();
-    train_var_missing.resize(source_inputsize);
+    TVec<int> train_var_missing(source_inputsize);
     train_var_missing.clear();
     int source_width = source->width();
 

Modified: trunk/plearn/vmat/MissingIndicatorVMatrix.h
===================================================================
--- trunk/plearn/vmat/MissingIndicatorVMatrix.h	2007-11-27 18:14:12 UTC (rev 8310)
+++ trunk/plearn/vmat/MissingIndicatorVMatrix.h	2007-11-27 18:24:19 UTC (rev 8311)
@@ -86,7 +86,6 @@
 
 private:
   
-  TVec<int>    train_var_missing;
   int          source_inputsize;
   Vec          source_input;
   TVec<int>    source_rel_pos;



From nouiz at mail.berlios.de  Tue Nov 27 19:30:12 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 19:30:12 +0100
Subject: [Plearn-commits] r8312 - trunk/plearn_learners/regressors
Message-ID: <200711271830.lARIUCs9022198@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 19:30:12 +0100 (Tue, 27 Nov 2007)
New Revision: 8312

Modified:
   trunk/plearn_learners/regressors/RegressionTree.cc
   trunk/plearn_learners/regressors/RegressionTree.h
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
Log:
Added a list of the order of the fields used to split


Modified: trunk/plearn_learners/regressors/RegressionTree.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTree.cc	2007-11-27 18:24:19 UTC (rev 8311)
+++ trunk/plearn_learners/regressors/RegressionTree.cc	2007-11-27 18:30:12 UTC (rev 8312)
@@ -104,7 +104,9 @@
     declareOption(ol, "first_leave_output", &RegressionTree::first_leave_output, OptionBase::learntoption,
                   "The vector to compute the ouput and the confidence function of the first leave.\n");
     declareOption(ol, "first_leave_error", &RegressionTree::first_leave_error, OptionBase::learntoption,
-                  "The vector to compute the errors of the first leave.n");
+                  "The vector to compute the errors of the first leave.\n");
+    declareOption(ol, "split_cols", &RegressionTree::split_cols, OptionBase::learntoption,
+                  "contain in order of first to last the columns used to split the tree.\n");
     inherited::declareOptions(ol);
 }
 
@@ -124,6 +126,7 @@
     deepCopyField(first_leave, copies);
     deepCopyField(first_leave_output, copies);
     deepCopyField(first_leave_error, copies);
+    deepCopyField(split_cols, copies);
 }
 
 void RegressionTree::build()
@@ -188,7 +191,9 @@
     {    
         if (stage > 0)
         {
-            if (expandTree() < 0) break;
+            int split_col = expandTree();
+            split_cols.append(split_col);
+            if (split_col < 0) break;
         }
         if (report_progress) pb->update(stage);
     }
@@ -207,12 +212,13 @@
         if (report_progress) pb->update(each_train_sample_index);
     }
     train_stats->finalize();
+    verbose("split_cols: "+tostring(split_cols),2);
 }
 
 void RegressionTree::verbose(string the_msg, int the_level)
 {
     if (verbosity >= the_level)
-        cout << the_msg << endl;
+        pout << the_msg << endl;
 }
 
 void RegressionTree::forget()
@@ -280,7 +286,8 @@
                 + ", penalty: " + tostring(complexity_penalty_factor * sqrt((real)stage)), 3);
         return -1;
     }
-    if (node->expandNode() < 0)
+    int split_col = node->expandNode();
+    if (split_col < 0)
     {
         verbose("RegressionTree: expand is negative?", 3);
         return -1;
@@ -289,7 +296,7 @@
     priority_queue->addHeap(subnode[0]); 
     priority_queue->addHeap(subnode[1]);
     if (missing_is_valid) priority_queue->addHeap(subnode[2]);
-    return 1; 
+    return split_col; 
 }
 
 void RegressionTree::setSortedTrainSet(PP<RegressionTreeRegisters> the_sorted_train_set)

Modified: trunk/plearn_learners/regressors/RegressionTree.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTree.h	2007-11-27 18:24:19 UTC (rev 8311)
+++ trunk/plearn_learners/regressors/RegressionTree.h	2007-11-27 18:30:12 UTC (rev 8312)
@@ -96,7 +96,8 @@
     Vec sample_costs;
     real sample_weight;
     PP<RegressionTreeNode> node;
-  
+    TVec<int> split_cols;
+
 public:
     RegressionTree();
     virtual              ~RegressionTree();

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-27 18:24:19 UTC (rev 8311)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-11-27 18:30:12 UTC (rev 8312)
@@ -327,7 +327,7 @@
     right_node->verbosity=verbosity;
     right_node->initNode(train_set, right_leave, leave_template);
     right_node->lookForBestSplit();
-    return +1;
+    return split_col;
 }
 
 int RegressionTreeNode::getSplitBalance()



From nouiz at mail.berlios.de  Tue Nov 27 19:34:24 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 27 Nov 2007 19:34:24 +0100
Subject: [Plearn-commits] r8313 - trunk/plearn_learners/regressors
Message-ID: <200711271834.lARIYObP022476@sheep.berlios.de>

Author: nouiz
Date: 2007-11-27 19:34:24 +0100 (Tue, 27 Nov 2007)
New Revision: 8313

Modified:
   trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
Log:
tsorted is transposed!


Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-27 18:30:12 UTC (rev 8312)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-11-27 18:34:24 UTC (rev 8313)
@@ -173,7 +173,7 @@
 void RegressionTreeRegisters::sortRows()
 {
     next_id = 0;
-    if (tsorted_row.length() == length() && tsorted_row.width() == inputsize())
+    if (tsorted_row.length() == inputsize() && tsorted_row.width() == length())
     {
         verbose("RegressionTreeRegisters: Sorted train set indices are present, no sort required", 3);
         return;



From tihocan at mail.berlios.de  Wed Nov 28 16:36:09 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Wed, 28 Nov 2007 16:36:09 +0100
Subject: [Plearn-commits] r8314 - trunk/plearn_learners/generic/EXPERIMENTAL
Message-ID: <200711281536.lASFa9FW029242@sheep.berlios.de>

Author: tihocan
Date: 2007-11-28 16:36:09 +0100 (Wed, 28 Nov 2007)
New Revision: 8314

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
Log:
Added a new debug cost

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-11-27 18:34:24 UTC (rev 8313)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-11-28 15:36:09 UTC (rev 8314)
@@ -560,8 +560,7 @@
             neuron_gradients.subMatColumns(k,layer_sizes[i]);
     }
     example_weights.resize(minibatch_size);
-    TVec<string> train_cost_names = getTrainCostNames() ;
-    train_costs.resize(minibatch_size,train_cost_names.length()-2 );
+    train_costs.resize(minibatch_size, nTestCosts());
 
     Profiler::activate();
 
@@ -763,15 +762,13 @@
 
     Profiler::reset("training");
     Profiler::start("training");
-    Profiler::pl_profile_start("Totaltraining");
+    //Profiler::pl_profile_start("Totaltraining");
     if( report_progress && stage < nstages )
         pb = new ProgressBar( "Training "+classname(),
                               nstages - stage );
 
-    Vec costs_plus_time(train_costs.width()+2);
-    costs_plus_time[train_costs.width()] = MISSING_VALUE;
-    costs_plus_time[train_costs.width()+1] = MISSING_VALUE;
-    Vec costs = costs_plus_time.subVec(0,train_costs.width());
+    Vec costs_plus_time(nTrainCosts(), MISSING_VALUE);
+    Vec costs = costs_plus_time.subVec(0, train_costs.width());
     int nsamples = train_set->length();
 
     // Obtain the number of CPUs we want to use.
@@ -873,8 +870,11 @@
     if (iam == 0) {
         //tmp_log << "Starting loop" << endl;
         //tmp_log.flush();
+        Profiler::reset("big_loop");
+        Profiler::start("big_loop");
     }
 
+    //pout << "CPU " << iam << ": my_stage_incr = " << my_stage_incr << endl;
     for(int i = 0; i < my_stage_incr; i++)
     {
         int sample = start + i % my_n_samples;
@@ -991,9 +991,11 @@
         */
     }
 
+
     if (iam == 0) {
         //tmp_log << "Loop ended" << endl;
         //tmp_log.flush();
+        Profiler::end("big_loop");
     }
 
     if (!wait_for_final_update) {
@@ -1018,8 +1020,8 @@
         }
     }
 
-    Profiler::reset("Synchronization");
-    Profiler::start("Synchronization");
+    //Profiler::reset("Synchronization");
+    //Profiler::start("Synchronization");
 
     //tmp_log << "Synchronization" << endl;
     //tmp_log.flush();
@@ -1083,7 +1085,7 @@
 
     //tmp_log << "Synchronized" << endl;
     //tmp_log.flush();
-    Profiler::end("Synchronization");
+    //Profiler::end("Synchronization");
     /*
     const Profiler::Stats& synch_stats = Profiler::getStats("Synchronization");
     real synch_time = (synch_stats.user_duration + synch_stats.system_duration)
@@ -1114,16 +1116,22 @@
                 "stage: %d)", stage, cur_stage);
 
     Profiler::end("training");
-    Profiler::pl_profile_end("Totaltraining");
+    //Profiler::pl_profile_end("Totaltraining");
+    /*
     if (verbosity>0)
         Profiler::report(cout);
+        */
     const Profiler::Stats& stats = Profiler::getStats("training");
+    const Profiler::Stats& big_loop_stats = Profiler::getStats("big_loop");
     costs.fill(MISSING_VALUE);
     real ticksPerSec = Profiler::ticksPerSecond();
     real cpu_time = (stats.user_duration+stats.system_duration)/ticksPerSec;
     cumulative_training_time += cpu_time;
     costs_plus_time[train_costs.width()] = cpu_time;
     costs_plus_time[train_costs.width()+1] = cumulative_training_time;
+    costs_plus_time[train_costs.width()+2] =
+        (big_loop_stats.user_duration + big_loop_stats.system_duration) /
+        ticksPerSec;
     train_stats->update( costs_plus_time );
     train_stats->finalize(); // finalize statistics for this epoch
 
@@ -1218,17 +1226,13 @@
 //alternate
             PLERROR("No, I just want stochastic gradient!");
             if( params_natgrad_per_input_template && i==1 ){ // parameters are transposed
-                Profiler::pl_profile_start("ProducScaleAccOnlineStep");
                 productScaleAcc(layer_params_gradient[i-1],
                             neuron_extended_outputs_per_layer[i-1], true,
                             next_neurons_gradient, false, 
                             1, 0);
-                Profiler::pl_profile_end("ProducScaleAccOnlineStep");
             }else{
-                Profiler::pl_profile_start("ProducScaleAccOnlineStep");
                 productScaleAcc(layer_params_gradient[i-1],next_neurons_gradient,true,
                             neuron_extended_outputs_per_layer[i-1],false,1,0);
-                Profiler::pl_profile_end("ProducScaleAccOnlineStep");
             }
             layer_params_gradient[i-1] *= 1.0/minibatch_size; // use the MEAN gradient
         } else {// just regular stochastic gradient
@@ -1372,11 +1376,11 @@
     out_log_file << "Starting to compute output on " << input << endl;
     out_log_file.flush();
     */
-    Profiler::pl_profile_start("computeOutput");
+    //Profiler::pl_profile_start("computeOutput");
     neuron_outputs_per_layer[0](0) << input;
     fpropNet(1,false);
     output << neuron_outputs_per_layer[n_layers-1](0);
-    Profiler::pl_profile_end("computeOutput");
+    //Profiler::pl_profile_end("computeOutput");
     /*
     out_log_file << "Output computed" << endl;
     out_log_file.flush();
@@ -1405,31 +1409,15 @@
 
         // try to use BLAS for the expensive operation
         if (self_adjusted_scaling_and_bias && i+1<n_layers-1){
-            if (during_training)
-                Profiler::pl_profile_start("ProducScaleAccFpropTrain");
-            else
-                Profiler::pl_profile_start("ProducScaleAccFpropNoTrain");
             productScaleAcc(next_layer, prev_layer, false, 
                             (during_training || params_averaging_coeff==1.0)?
                             weights[i]:mweights[i], 
                             tw, 1, 0);
-            if (during_training)
-                Profiler::pl_profile_end("ProducScaleAccFpropTrain");
-            else
-                Profiler::pl_profile_end("ProducScaleAcccFpropNoTrain");
         }else{
-            if (during_training)
-                Profiler::pl_profile_start("ProducScaleAccFpropTrain");
-            else
-                Profiler::pl_profile_start("ProducScaleAcccFpropNoTrain");
             productScaleAcc(next_layer, prev_layer, false, 
                             (during_training || params_averaging_coeff==1.0)?
                             layer_params[i]:layer_mparams[i], 
                             tw, 1, 0);
-            if (during_training)
-                Profiler::pl_profile_end("ProducScaleAccFpropTrain");
-            else
-                Profiler::pl_profile_end("ProducScaleAcccFpropNoTrain");
         }
         // compute layer's output non-linearity
         if (i+1<n_layers-1)
@@ -1467,32 +1455,24 @@
                                 *v *= rescale_factor*rescale_factor;
                             }
                         }
-                        Profiler::pl_profile_start("activation function");
                         *a = tanh((*a + *b) * *s);
-                        Profiler::pl_profile_end("activation function");
                     }
                 }
                 else{
-                    Profiler::pl_profile_start("activation function");
                     compute_tanh(L,L);
-                    Profiler::pl_profile_end("activation function");
                 }
             }
         else if (output_type=="NLL")
             for (int k=0;k<n_examples;k++)
             {
                 Vec L=next_layer(k);
-                Profiler::pl_profile_start("activation function");
                 log_softmax(L,L);
-                Profiler::pl_profile_end("activation function");
             }
         else if (output_type=="cross_entropy")  {
             for (int k=0;k<n_examples;k++)
             {
                 Vec L=next_layer(k);
-                Profiler::pl_profile_start("activation function");
                 log_sigmoid(L,L);
-                Profiler::pl_profile_end("activation function");
             }
          }
     }
@@ -1595,6 +1575,7 @@
     TVec<string> costs = getTestCostNames();
     costs.append("train_seconds");
     costs.append("cum_train_seconds");
+    costs.append("big_loop_seconds");
     return costs;
 }
 



From nouiz at mail.berlios.de  Wed Nov 28 16:59:14 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 28 Nov 2007 16:59:14 +0100
Subject: [Plearn-commits] r8315 - trunk/doc
Message-ID: <200711281559.lASFxEFn030442@sheep.berlios.de>

Author: nouiz
Date: 2007-11-28 16:59:06 +0100 (Wed, 28 Nov 2007)
New Revision: 8315

Removed:
   trunk/doc/Doxyfile.joseph
Modified:
   trunk/doc/Doxyfile
   trunk/doc/Doxyfile2
   trunk/doc/Doxyfile3
Log:
-Put the version of joseph for doxygen config as the default one.
-He updated it to a newer version of doxygen that allow generation of graph in an acceptable time.


Modified: trunk/doc/Doxyfile
===================================================================
--- trunk/doc/Doxyfile	2007-11-28 15:36:09 UTC (rev 8314)
+++ trunk/doc/Doxyfile	2007-11-28 15:59:06 UTC (rev 8315)
@@ -1,4 +1,4 @@
-# Doxyfile 1.2.16
+# Doxyfile 1.5.1-20070315
 
 # This file describes the settings to be used by the documentation system
 # doxygen (www.doxygen.org) for a project
@@ -11,9 +11,17 @@
 # Values that contain spaces should be placed between quotes (" ")
 
 #---------------------------------------------------------------------------
-# General configuration options
+# Project related configuration options
 #---------------------------------------------------------------------------
 
+# This tag specifies the encoding used for all characters in the config file that 
+# follow. The default is UTF-8 which is also the encoding used for all text before 
+# the first occurrence of this tag. Doxygen uses libiconv (or the iconv built into 
+# libc) for the transcoding. See http://www.gnu.org/software/libiconv for the list of 
+# possible encodings.
+
+DOXYFILE_ENCODING      = UTF-8
+
 # The PROJECT_NAME tag is a single word (or a sequence of words surrounded 
 # by quotes) that should identify the project.
 
@@ -30,19 +38,194 @@
 # If a relative path is entered, it will be relative to the location 
 # where doxygen was started. If left blank the current directory will be used.
 
-OUTPUT_DIRECTORY       = LibraryReference
+OUTPUT_DIRECTORY       = LibraryReference.joseph
 
+# If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
+# 4096 sub-directories (in 2 levels) under the output directory of each output 
+# format and will distribute the generated files over these directories. 
+# Enabling this option can be useful when feeding doxygen a huge amount of 
+# source files, where putting all generated files in the same directory would 
+# otherwise cause performance problems for the file system.
+
+CREATE_SUBDIRS         = YES
+
 # The OUTPUT_LANGUAGE tag is used to specify the language in which all 
 # documentation generated by doxygen is written. Doxygen will use this 
 # information to generate all constant output in the proper language. 
 # The default language is English, other supported languages are: 
-# Brazilian, Chinese, Chinese-Traditional, Croatian, Czech, Danish, Dutch, 
-# Finnish, French, German, Greek, Hungarian, Italian, Japanese, Korean, 
-# Norwegian, Polish, Portuguese, Romanian, Russian, Slovak, Slovene, 
-# Spanish, Swedish and Ukrainian.
+# Afrikaans, Arabic, Brazilian, Catalan, Chinese, Chinese-Traditional, 
+# Croatian, Czech, Danish, Dutch, Finnish, French, German, Greek, Hungarian, 
+# Italian, Japanese, Japanese-en (Japanese with English messages), Korean, 
+# Korean-en, Lithuanian, Norwegian, Polish, Portuguese, Romanian, Russian, 
+# Serbian, Slovak, Slovene, Spanish, Swedish, and Ukrainian.
 
 OUTPUT_LANGUAGE        = English
 
+# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will 
+# include brief member descriptions after the members that are listed in 
+# the file and class documentation (similar to JavaDoc). 
+# Set to NO to disable this.
+
+BRIEF_MEMBER_DESC      = YES
+
+# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend 
+# the brief description of a member or function before the detailed description. 
+# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the 
+# brief descriptions will be completely suppressed.
+
+REPEAT_BRIEF           = YES
+
+# This tag implements a quasi-intelligent brief description abbreviator 
+# that is used to form the text in various listings. Each string 
+# in this list, if found as the leading text of the brief description, will be 
+# stripped from the text and the result after processing the whole list, is 
+# used as the annotated text. Otherwise, the brief description is used as-is. 
+# If left blank, the following values are used ("$name" is automatically 
+# replaced with the name of the entity): "The $name class" "The $name widget" 
+# "The $name file" "is" "provides" "specifies" "contains" 
+# "represents" "a" "an" "the"
+
+ABBREVIATE_BRIEF       = 
+
+# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then 
+# Doxygen will generate a detailed section even if there is only a brief 
+# description.
+
+ALWAYS_DETAILED_SEC    = NO
+
+# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all 
+# inherited members of a class in the documentation of that class as if those 
+# members were ordinary class members. Constructors, destructors and assignment 
+# operators of the base classes will not be shown.
+
+INLINE_INHERITED_MEMB  = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full 
+# path before files name in the file list and in the header files. If set 
+# to NO the shortest path that makes the file name unique will be used.
+
+FULL_PATH_NAMES        = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag 
+# can be used to strip a user-defined part of the path. Stripping is 
+# only done if one of the specified strings matches the left-hand part of 
+# the path. The tag can be used to show relative paths in the file list. 
+# If left blank the directory from which doxygen is run is used as the 
+# path to strip.
+
+STRIP_FROM_PATH        = 
+
+# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of 
+# the path mentioned in the documentation of a class, which tells 
+# the reader which header file to include in order to use a class. 
+# If left blank only the name of the header file containing the class 
+# definition is used. Otherwise one should specify the include paths that 
+# are normally passed to the compiler using the -I flag.
+
+STRIP_FROM_INC_PATH    = 
+
+# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter 
+# (but less readable) file names. This can be useful is your file systems 
+# doesn't support long names like on DOS, Mac, or CD-ROM.
+
+SHORT_NAMES            = NO
+
+# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen 
+# will interpret the first line (until the first dot) of a JavaDoc-style 
+# comment as the brief description. If set to NO, the JavaDoc 
+# comments will behave just like the Qt-style comments (thus requiring an 
+# explicit @brief command for a brief description.
+
+JAVADOC_AUTOBRIEF      = YES
+
+# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make Doxygen 
+# treat a multi-line C++ special comment block (i.e. a block of //! or /// 
+# comments) as a brief description. This used to be the default behaviour. 
+# The new default is to treat a multi-line C++ comment block as a detailed 
+# description. Set this tag to YES if you prefer the old behaviour instead.
+
+MULTILINE_CPP_IS_BRIEF = NO
+
+# If the DETAILS_AT_TOP tag is set to YES then Doxygen 
+# will output the detailed description near the top, like JavaDoc.
+# If set to NO, the detailed description appears after the member 
+# documentation.
+
+DETAILS_AT_TOP         = NO
+
+# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented 
+# member inherits the documentation from any documented member that it 
+# re-implements.
+
+INHERIT_DOCS           = YES
+
+# If the SEPARATE_MEMBER_PAGES tag is set to YES, then doxygen will produce 
+# a new page for each member. If set to NO, the documentation of a member will 
+# be part of the file/class/namespace that contains it.
+
+SEPARATE_MEMBER_PAGES  = NO
+
+# The TAB_SIZE tag can be used to set the number of spaces in a tab. 
+# Doxygen uses this value to replace tabs by spaces in code fragments.
+
+TAB_SIZE               = 8
+
+# This tag can be used to specify a number of aliases that acts 
+# as commands in the documentation. An alias has the form "name=value". 
+# For example adding "sideeffect=\par Side Effects:\n" will allow you to 
+# put the command \sideeffect (or @sideeffect) in the documentation, which 
+# will result in a user-defined paragraph with heading "Side Effects:". 
+# You can put \n's in the value part of an alias to insert newlines.
+
+ALIASES                = 
+
+# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C 
+# sources only. Doxygen will then generate output that is more tailored for C. 
+# For instance, some of the names that are used will be different. The list 
+# of all members will be omitted, etc.
+
+OPTIMIZE_OUTPUT_FOR_C  = NO
+
+# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java 
+# sources only. Doxygen will then generate output that is more tailored for Java. 
+# For instance, namespaces will be presented as packages, qualified scopes 
+# will look different, etc.
+
+OPTIMIZE_OUTPUT_JAVA   = NO
+
+# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want to 
+# include (a tag file for) the STL sources as input, then you should 
+# set this tag to YES in order to let doxygen match functions declarations and 
+# definitions whose arguments contain STL classes (e.g. func(std::string); v.s. 
+# func(std::string) {}). This also make the inheritance and collaboration 
+# diagrams that involve STL classes more complete and accurate.
+
+BUILTIN_STL_SUPPORT    = YES
+
+# If you use Microsoft's C++/CLI language, you should set this option to YES to
+# enable parsing support.
+
+CPP_CLI_SUPPORT        = NO
+
+# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC 
+# tag is set to YES, then doxygen will reuse the documentation of the first 
+# member in the group (if any) for the other members of the group. By default 
+# all members of a group must be documented explicitly.
+
+DISTRIBUTE_GROUP_DOC   = NO
+
+# Set the SUBGROUPING tag to YES (the default) to allow class member groups of 
+# the same type (for instance a group of public functions) to be put as a 
+# subgroup of that type (e.g. under the Public Functions section). Set it to 
+# NO to prevent subgrouping. Alternatively, this can be done per class using 
+# the \nosubgrouping command.
+
+SUBGROUPING            = YES
+
+#---------------------------------------------------------------------------
+# Build related configuration options
+#---------------------------------------------------------------------------
+
 # If the EXTRACT_ALL tag is set to YES doxygen will assume all entities in 
 # documentation are documented, even if no documentation was available. 
 # Private class members and static file members will be hidden unless 
@@ -66,6 +249,13 @@
 
 EXTRACT_LOCAL_CLASSES  = YES
 
+# This flag is only useful for Objective-C code. When set to YES local 
+# methods, which are defined in the implementation section but not in 
+# the interface are included in the documentation. 
+# If set to NO (the default) only methods in the interface are included.
+
+EXTRACT_LOCAL_METHODS  = NO
+
 # If the HIDE_UNDOC_MEMBERS tag is set to YES, Doxygen will hide all 
 # undocumented members of documented classes, files or namespaces. 
 # If set to NO (the default) these members will be included in the 
@@ -76,51 +266,25 @@
 
 # If the HIDE_UNDOC_CLASSES tag is set to YES, Doxygen will hide all 
 # undocumented classes that are normally visible in the class hierarchy. 
-# If set to NO (the default) these class will be included in the various 
+# If set to NO (the default) these classes will be included in the various 
 # overviews. This option has no effect if EXTRACT_ALL is enabled.
 
 HIDE_UNDOC_CLASSES     = NO
 
-# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will 
-# include brief member descriptions after the members that are listed in 
-# the file and class documentation (similar to JavaDoc). 
-# Set to NO to disable this.
+# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, Doxygen will hide all 
+# friend (class|struct|union) declarations. 
+# If set to NO (the default) these declarations will be included in the 
+# documentation.
 
-BRIEF_MEMBER_DESC      = YES
+HIDE_FRIEND_COMPOUNDS  = NO
 
-# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend 
-# the brief description of a member or function before the detailed description. 
-# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the 
-# brief descriptions will be completely suppressed.
+# If the HIDE_IN_BODY_DOCS tag is set to YES, Doxygen will hide any 
+# documentation blocks found inside the body of a function. 
+# If set to NO (the default) these blocks will be appended to the 
+# function's detailed documentation block.
 
-REPEAT_BRIEF           = YES
+HIDE_IN_BODY_DOCS      = NO
 
-# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then 
-# Doxygen will generate a detailed section even if there is only a brief 
-# description.
-
-ALWAYS_DETAILED_SEC    = NO
-
-# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all inherited 
-# members of a class in the documentation of that class as if those members were 
-# ordinary class members. Constructors, destructors and assignment operators of 
-# the base classes will not be shown.
-
-INLINE_INHERITED_MEMB  = NO
-
-# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full 
-# path before files name in the file list and in the header files. If set 
-# to NO the shortest path that makes the file name unique will be used.
-
-FULL_PATH_NAMES        = NO
-
-# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag 
-# can be used to strip a user defined part of the path. Stripping is 
-# only done if one of the specified strings matches the left-hand part of 
-# the path. It is allowed to use relative paths in the argument list.
-
-STRIP_FROM_PATH        = 
-
 # The INTERNAL_DOCS tag determines if documentation 
 # that is typed after a \internal command is included. If the tag is set 
 # to NO (the default) then the documentation will be excluded. 
@@ -128,65 +292,26 @@
 
 INTERNAL_DOCS          = NO
 
-# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct 
-# doxygen to hide any special comment blocks from generated source code 
-# fragments. Normal C and C++ comments will always remain visible.
-
-STRIP_CODE_COMMENTS    = YES
-
 # If the CASE_SENSE_NAMES tag is set to NO then Doxygen will only generate 
-# file names in lower case letters. If set to YES upper case letters are also 
+# file names in lower-case letters. If set to YES upper-case letters are also 
 # allowed. This is useful if you have classes or files whose names only differ 
 # in case and if your file system supports case sensitive file names. Windows 
-# users are adviced to set this option to NO.
+# and Mac users are advised to set this option to NO.
 
 CASE_SENSE_NAMES       = YES
 
-# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter 
-# (but less readable) file names. This can be useful is your file systems 
-# doesn't support long names like on DOS, Mac, or CD-ROM.
-
-SHORT_NAMES            = NO
-
 # If the HIDE_SCOPE_NAMES tag is set to NO (the default) then Doxygen 
 # will show members with their full class and namespace scopes in the 
 # documentation. If set to YES the scope will be hidden.
 
 HIDE_SCOPE_NAMES       = NO
 
-# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen 
-# will generate a verbatim copy of the header file for each class for 
-# which an include is specified. Set to NO to disable this.
-
-VERBATIM_HEADERS       = YES
-
 # If the SHOW_INCLUDE_FILES tag is set to YES (the default) then Doxygen 
-# will put list of the files that are included by a file in the documentation 
+# will put a list of the files that are included by a file in the documentation 
 # of that file.
 
 SHOW_INCLUDE_FILES     = YES
 
-# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen 
-# will interpret the first line (until the first dot) of a JavaDoc-style 
-# comment as the brief description. If set to NO, the JavaDoc 
-# comments  will behave just like the Qt-style comments (thus requiring an 
-# explict @brief command for a brief description.
-
-JAVADOC_AUTOBRIEF      = YES
-
-# If the DETAILS_AT_TOP tag is set to YES then Doxygen 
-# will output the detailed description near the top, like JavaDoc.
-# If set to NO, the detailed description appears after the member 
-# documentation.
-
-DETAILS_AT_TOP         = NO
-
-# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented 
-# member inherits the documentation from any documented member that it 
-# reimplements.
-
-INHERIT_DOCS           = YES
-
 # If the INLINE_INFO tag is set to YES (the default) then a tag [inline] 
 # is inserted in the documentation for inline members.
 
@@ -199,17 +324,22 @@
 
 SORT_MEMBER_DOCS       = YES
 
-# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC 
-# tag is set to YES, then doxygen will reuse the documentation of the first 
-# member in the group (if any) for the other members of the group. By default 
-# all members of a group must be documented explicitly.
+# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the 
+# brief documentation of file, namespace and class members alphabetically 
+# by member name. If set to NO (the default) the members will appear in 
+# declaration order.
 
-DISTRIBUTE_GROUP_DOC   = NO
+SORT_BRIEF_DOCS        = NO
 
-# The TAB_SIZE tag can be used to set the number of spaces in a tab. 
-# Doxygen uses this value to replace tabs by spaces in code fragments.
+# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be 
+# sorted by fully-qualified names, including namespaces. If set to 
+# NO (the default), the class list will be sorted only by class name, 
+# not including the namespace part. 
+# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES.
+# Note: This option applies only to the class list, not to the 
+# alphabetical list.
 
-TAB_SIZE               = 8
+SORT_BY_SCOPE_NAME     = NO
 
 # The GENERATE_TODOLIST tag can be used to enable (YES) or 
 # disable (NO) the todo list. This list is created by putting \todo 
@@ -229,14 +359,11 @@
 
 GENERATE_BUGLIST       = YES
 
-# This tag can be used to specify a number of aliases that acts 
-# as commands in the documentation. An alias has the form "name=value". 
-# For example adding "sideeffect=\par Side Effects:\n" will allow you to 
-# put the command \sideeffect (or @sideeffect) in the documentation, which 
-# will result in a user defined paragraph with heading "Side Effects:". 
-# You can put \n's in the value part of an alias to insert newlines.
+# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or 
+# disable (NO) the deprecated list. This list is created by putting 
+# \deprecated commands in the documentation.
 
-ALIASES                = 
+GENERATE_DEPRECATEDLIST= YES
 
 # The ENABLED_SECTIONS tag can be used to enable conditional 
 # documentation sections, marked by \if sectionname ... \endif.
@@ -244,7 +371,7 @@
 ENABLED_SECTIONS       = 
 
 # The MAX_INITIALIZER_LINES tag determines the maximum number of lines 
-# the initial value of a variable or define consist of for it to appear in 
+# the initial value of a variable or define consists of for it to appear in 
 # the documentation. If the initializer consists of more lines than specified 
 # here it will be hidden. Use a value of 0 to hide initializers completely. 
 # The appearance of the initializer of individual variables and defines in the 
@@ -253,26 +380,28 @@
 
 MAX_INITIALIZER_LINES  = 30
 
-# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C sources 
-# only. Doxygen will then generate output that is more tailored for C. 
-# For instance some of the names that are used will be different. The list 
-# of all members will be omitted, etc.
-
-OPTIMIZE_OUTPUT_FOR_C  = NO
-
-# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java sources 
-# only. Doxygen will then generate output that is more tailored for Java. 
-# For instance namespaces will be presented as packages, qualified scopes 
-# will look different, etc.
-
-OPTIMIZE_OUTPUT_JAVA   = NO
-
 # Set the SHOW_USED_FILES tag to NO to disable the list of files generated 
 # at the bottom of the documentation of classes and structs. If set to YES the 
 # list will mention the files that were used to generate the documentation.
 
 SHOW_USED_FILES        = YES
 
+# If the sources in your project are distributed over multiple directories 
+# then setting the SHOW_DIRECTORIES tag to YES will show the directory hierarchy 
+# in the documentation. The default is NO.
+
+SHOW_DIRECTORIES       = YES
+
+# The FILE_VERSION_FILTER tag can be used to specify a program or script that 
+# doxygen should invoke to get the current version for each file (typically from the 
+# version control system). Doxygen will invoke the program by executing (via 
+# popen()) the command <command> <input-file>, where <command> is the value of 
+# the FILE_VERSION_FILTER tag, and <input-file> is the name of an input file 
+# provided by doxygen. Whatever the program writes to standard output 
+# is used as the file version. See the manual for examples.
+
+FILE_VERSION_FILTER    = 
+
 #---------------------------------------------------------------------------
 # configuration options related to warning and progress messages
 #---------------------------------------------------------------------------
@@ -294,10 +423,27 @@
 
 WARN_IF_UNDOCUMENTED   = NO
 
+# If WARN_IF_DOC_ERROR is set to YES, doxygen will generate warnings for 
+# potential errors in the documentation, such as not documenting some 
+# parameters in a documented function, or documenting parameters that 
+# don't exist or using markup commands wrongly.
+
+WARN_IF_DOC_ERROR      = YES
+
+# This WARN_NO_PARAMDOC option can be abled to get warnings for 
+# functions that are documented, but have no documentation for their parameters 
+# or return value. If set to NO (the default) doxygen will only warn about 
+# wrong or incomplete parameter documentation, but not about the absence of 
+# documentation.
+
+WARN_NO_PARAMDOC       = NO
+
 # The WARN_FORMAT tag determines the format of the warning messages that 
 # doxygen can produce. The string should contain the $file, $line, and $text 
 # tags, which will be replaced by the file and line number from which the 
-# warning originated and the warning text.
+# warning originated and the warning text. Optionally the format may contain 
+# $version, which will be replaced by the version of the file (if it could 
+# be obtained via FILE_VERSION_FILTER)
 
 WARN_FORMAT            = 
 
@@ -319,14 +465,21 @@
 INPUT                  = ../plearn \
                          ../plearn_learners \
                          ../plearn_learners_experimental \
-			                   ../commands
+                         ../commands
 
+# This tag can be used to specify the character encoding of the source files that 
+# doxygen parses. Internally doxygen uses the UTF-8 encoding, which is also the default 
+# input encoding. Doxygen uses libiconv (or the iconv built into libc) for the transcoding. 
+# See http://www.gnu.org/software/libiconv for the list of possible encodings.
+
+INPUT_ENCODING         = UTF-8
+
 # If the value of the INPUT tag contains directories, you can use the 
 # FILE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
 # and *.h) to filter out the source-files in the directories. If left 
 # blank the following patterns are tested: 
-# *.c *.cc *.cxx *.cpp *.c++ *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh *.hxx *.hpp 
-# *.h++ *.idl *.odl
+# *.c *.cc *.cxx *.cpp *.c++ *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh *.hxx 
+# *.hpp *.h++ *.idl *.odl *.cs *.php *.php3 *.inc *.m *.mm *.py
 
 FILE_PATTERNS          = *.cc \
                          *.h
@@ -343,17 +496,29 @@
 
 EXCLUDE                = 
 
-# The EXCLUDE_SYMLINKS tag can be used select whether or not files or directories 
-# that are symbolic links (a Unix filesystem feature) are excluded from the input.
+# The EXCLUDE_SYMLINKS tag can be used select whether or not files or 
+# directories that are symbolic links (a Unix filesystem feature) are excluded 
+# from the input.
 
 EXCLUDE_SYMLINKS       = NO
 
 # If the value of the INPUT tag contains directories, you can use the 
 # EXCLUDE_PATTERNS tag to specify one or more wildcard patterns to exclude 
-# certain files from those directories.
+# certain files from those directories. Note that the wildcards are matched 
+# against the file with absolute path, so to exclude all test directories 
+# for example use the pattern */test/*
 
-EXCLUDE_PATTERNS       = OBJS .svn .pytest
+EXCLUDE_PATTERNS       = OBJS \
+                         .svn \
+                         .pytest
 
+# The EXCLUDE_SYMBOLS tag can be used to specify one or more symbol names 
+# (namespaces, classes, functions, etc.) that should be excluded from the output. 
+# The symbol name can be a fully qualified name, a word, or if the wildcard * is used, 
+# a substring. Examples: ANamespace, AClass, AClass::ANamespace, ANamespace::*Test
+
+EXCLUDE_SYMBOLS        = 
+
 # The EXAMPLE_PATH tag can be used to specify one or more files or 
 # directories that contain example code fragments that are included (see 
 # the \include command).
@@ -385,13 +550,23 @@
 # by executing (via popen()) the command <filter> <input-file>, where <filter> 
 # is the value of the INPUT_FILTER tag, and <input-file> is the name of an 
 # input file. Doxygen will then use the output that the filter program writes 
-# to standard output.
+# to standard output.  If FILTER_PATTERNS is specified, this tag will be 
+# ignored.
 
 INPUT_FILTER           = 
 
+# The FILTER_PATTERNS tag can be used to specify filters on a per file pattern 
+# basis.  Doxygen will compare the file name with each pattern and apply the 
+# filter if there is a match.  The filters are a list of the form: 
+# pattern=filter (like *.cpp=my_cpp_filter). See INPUT_FILTER for further 
+# info on how filters are used. If FILTER_PATTERNS is empty, INPUT_FILTER 
+# is applied to all files.
+
+FILTER_PATTERNS        = 
+
 # If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using 
 # INPUT_FILTER) will be used to filter the input files when producing source 
-# files to browse.
+# files to browse (i.e. when SOURCE_BROWSER is set to YES).
 
 FILTER_SOURCE_FILES    = NO
 
@@ -400,15 +575,23 @@
 #---------------------------------------------------------------------------
 
 # If the SOURCE_BROWSER tag is set to YES then a list of source files will 
-# be generated. Documented entities will be cross-referenced with these sources.
+# be generated. Documented entities will be cross-referenced with these sources. 
+# Note: To get rid of all source code in the generated output, make sure also 
+# VERBATIM_HEADERS is set to NO.
 
 SOURCE_BROWSER         = YES
 
 # Setting the INLINE_SOURCES tag to YES will include the body 
 # of functions and classes directly in the documentation.
 
-INLINE_SOURCES         = NO
+INLINE_SOURCES         = YES
 
+# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct 
+# doxygen to hide any special comment blocks from generated source code 
+# fragments. Normal C and C++ comments will always remain visible.
+
+STRIP_CODE_COMMENTS    = YES
+
 # If the REFERENCED_BY_RELATION tag is set to YES (the default) 
 # then for each documented function all documented 
 # functions referencing it will be listed.
@@ -421,6 +604,27 @@
 
 REFERENCES_RELATION    = YES
 
+# If the REFERENCES_LINK_SOURCE tag is set to YES (the default)
+# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from
+# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will
+# link to the source code.  Otherwise they will link to the documentstion.
+
+REFERENCES_LINK_SOURCE = YES
+
+# If the USE_HTAGS tag is set to YES then the references to source code 
+# will point to the HTML generated by the htags(1) tool instead of doxygen 
+# built-in source browser. The htags tool is part of GNU's global source 
+# tagging system (see http://www.gnu.org/software/global/global.html). You 
+# will need version 4.8.6 or higher.
+
+USE_HTAGS              = NO
+
+# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen 
+# will generate a verbatim copy of the header file for each class for 
+# which an include is specified. Set to NO to disable this.
+
+VERBATIM_HEADERS       = YES
+
 #---------------------------------------------------------------------------
 # configuration options related to the alphabetical class index
 #---------------------------------------------------------------------------
@@ -477,10 +681,12 @@
 
 HTML_FOOTER            = 
 
-# The HTML_STYLESHEET tag can be used to specify a user defined cascading 
+# The HTML_STYLESHEET tag can be used to specify a user-defined cascading 
 # style sheet that is used by each HTML page. It can be used to 
 # fine-tune the look of the HTML output. If the tag is left blank doxygen 
-# will generate a default style sheet
+# will generate a default style sheet. Note that doxygen will try to copy 
+# the style sheet file to the HTML output directory, so don't put your own 
+# stylesheet in the HTML output directory as well, or it will be erased!
 
 HTML_STYLESHEET        = 
 
@@ -497,6 +703,20 @@
 
 GENERATE_HTMLHELP      = NO
 
+# If the GENERATE_HTMLHELP tag is set to YES, the CHM_FILE tag can 
+# be used to specify the file name of the resulting .chm file. You 
+# can add a path in front of the file if the result should not be 
+# written to the html output directory.
+
+CHM_FILE               = 
+
+# If the GENERATE_HTMLHELP tag is set to YES, the HHC_LOCATION tag can 
+# be used to specify the location (absolute path including file name) of 
+# the HTML help compiler (hhc.exe). If non-empty doxygen will try to run 
+# the HTML help compiler on the generated index.hhp.
+
+HHC_LOCATION           = 
+
 # If the GENERATE_HTMLHELP tag is set to YES, the GENERATE_CHI flag 
 # controls if a separate .chi index file is generated (YES) or that 
 # it should be included in the master .chm file (NO).
@@ -510,7 +730,7 @@
 BINARY_TOC             = NO
 
 # The TOC_EXPAND flag can be set to YES to add extra items for group members 
-# to the contents of the Html help documentation and to the tree view.
+# to the contents of the HTML help documentation and to the tree view.
 
 TOC_EXPAND             = NO
 
@@ -528,10 +748,9 @@
 # If the GENERATE_TREEVIEW tag is set to YES, a side panel will be
 # generated containing a tree-like index structure (just like the one that 
 # is generated for HTML Help). For this to work a browser that supports 
-# JavaScript and frames is required (for instance Mozilla, Netscape 4.0+, 
-# or Internet explorer 4.0+). Note that for large projects the tree generation 
-# can take a very long time. In such cases it is better to disable this feature. 
-# Windows users are probably better off using the HTML help feature.
+# JavaScript, DHTML, CSS and frames is required (for instance Mozilla 1.0+, 
+# Netscape 6.0+, Internet explorer 5.0+, or Konqueror). Windows users are 
+# probably better off using the HTML help feature.
 
 GENERATE_TREEVIEW      = NO
 
@@ -548,7 +767,7 @@
 # If the GENERATE_LATEX tag is set to YES (the default) Doxygen will 
 # generate Latex output.
 
-GENERATE_LATEX         = NO
+GENERATE_LATEX         = YES
 
 # The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. 
 # If a relative path is entered the value of OUTPUT_DIRECTORY will be 
@@ -556,7 +775,8 @@
 
 LATEX_OUTPUT           = 
 
-# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be invoked. If left blank `latex' will be used as the default command name.
+# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be 
+# invoked. If left blank `latex' will be used as the default command name.
 
 LATEX_CMD_NAME         = latex
 
@@ -576,7 +796,7 @@
 # by the printer. Possible values are: a4, a4wide, letter, legal and 
 # executive. If left blank a4wide will be used.
 
-PAPER_TYPE             = a4wide
+PAPER_TYPE             = letter
 
 # The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX 
 # packages that should be included in the LaTeX output.
@@ -595,27 +815,33 @@
 # contain links (just like the HTML output) instead of page references 
 # This makes the output suitable for online browsing using a pdf viewer.
 
-PDF_HYPERLINKS         = NO
+PDF_HYPERLINKS         = YES
 
 # If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of 
 # plain latex in the generated Makefile. Set this option to YES to get a 
 # higher quality PDF documentation.
 
-USE_PDFLATEX           = NO
+USE_PDFLATEX           = YeS
 
 # If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\batchmode. 
 # command to the generated LaTeX files. This will instruct LaTeX to keep 
 # running if errors occur, instead of asking the user for help. 
 # This option is also used when generating formulas in HTML.
 
-LATEX_BATCHMODE        = NO
+LATEX_BATCHMODE        = YES
 
+# If LATEX_HIDE_INDICES is set to YES then doxygen will not 
+# include the index chapters (such as File Index, Compound Index, etc.) 
+# in the output.
+
+LATEX_HIDE_INDICES     = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to the RTF output
 #---------------------------------------------------------------------------
 
 # If the GENERATE_RTF tag is set to YES Doxygen will generate RTF output 
-# The RTF output is optimised for Word 97 and may not look very pretty with 
+# The RTF output is optimized for Word 97 and may not look very pretty with 
 # other RTF readers or editors.
 
 GENERATE_RTF           = NO
@@ -642,7 +868,7 @@
 RTF_HYPERLINKS         = NO
 
 # Load stylesheet definitions from file. Syntax is similar to doxygen's 
-# config file, i.e. a series of assigments. You only have to provide 
+# config file, i.e. a series of assignments. You only have to provide 
 # replacements, missing definitions are set to their default value.
 
 RTF_STYLESHEET_FILE    = 
@@ -686,12 +912,35 @@
 
 # If the GENERATE_XML tag is set to YES Doxygen will 
 # generate an XML file that captures the structure of 
-# the code including all documentation. Note that this 
-# feature is still experimental and incomplete at the 
-# moment.
+# the code including all documentation.
 
-GENERATE_XML           = NO
+GENERATE_XML           = YES
 
+# The XML_OUTPUT tag is used to specify where the XML pages will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `xml' will be used as the default path.
+
+XML_OUTPUT             = xml
+
+# The XML_SCHEMA tag can be used to specify an XML schema, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
+XML_SCHEMA             = 
+
+# The XML_DTD tag can be used to specify an XML DTD, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
+XML_DTD                = 
+
+# If the XML_PROGRAMLISTING tag is set to YES Doxygen will 
+# dump the program listings (including syntax highlighting 
+# and cross-referencing information) to the XML output. Note that 
+# enabling this will significantly increase the size of the XML output.
+
+XML_PROGRAMLISTING     = YES
+
 #---------------------------------------------------------------------------
 # configuration options for the AutoGen Definitions output
 #---------------------------------------------------------------------------
@@ -705,6 +954,39 @@
 GENERATE_AUTOGEN_DEF   = NO
 
 #---------------------------------------------------------------------------
+# configuration options related to the Perl module output
+#---------------------------------------------------------------------------
+
+# If the GENERATE_PERLMOD tag is set to YES Doxygen will 
+# generate a Perl module file that captures the structure of 
+# the code including all documentation. Note that this 
+# feature is still experimental and incomplete at the 
+# moment.
+
+GENERATE_PERLMOD       = NO
+
+# If the PERLMOD_LATEX tag is set to YES Doxygen will generate 
+# the necessary Makefile rules, Perl scripts and LaTeX code to be able 
+# to generate PDF and DVI output from the Perl module output.
+
+PERLMOD_LATEX          = NO
+
+# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be 
+# nicely formatted so it can be parsed by a human reader.  This is useful 
+# if you want to understand what is going on.  On the other hand, if this 
+# tag is set to NO the size of the Perl module output will be much smaller 
+# and Perl will parse it just the same.
+
+PERLMOD_PRETTY         = YES
+
+# The names of the make variables in the generated doxyrules.make file 
+# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX. 
+# This is useful so different doxyrules.make files included by the same 
+# Makefile don't overwrite each other's variables.
+
+PERLMOD_MAKEVAR_PREFIX = 
+
+#---------------------------------------------------------------------------
 # Configuration options related to the preprocessor   
 #---------------------------------------------------------------------------
 
@@ -723,7 +1005,7 @@
 
 # If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES 
 # then the macro expansion is limited to the macros specified with the 
-# PREDEFINED and EXPAND_AS_PREDEFINED tags.
+# PREDEFINED and EXPAND_AS_DEFINED tags.
 
 EXPAND_ONLY_PREDEF     = YES
 
@@ -749,42 +1031,61 @@
 # are defined before the preprocessor is started (similar to the -D option of 
 # gcc). The argument of the tag is a list of macros of the form: name 
 # or name=definition (no spaces). If the definition and the = are 
-# omitted =1 is assumed.
+# omitted =1 is assumed. To prevent a macro definition from being 
+# undefined via #undef or recursively expanded use the := operator 
+# instead of the = operator.
 
 PREDEFINED             = 
 
-# If the MACRO_EXPANSION and EXPAND_PREDEF_ONLY tags are set to YES then 
+# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then 
 # this tag can be used to specify a list of macro names that should be expanded. 
 # The macro definition that is found in the sources will be used. 
 # Use the PREDEFINED tag if you want to use a different macro definition.
 
-EXPAND_AS_DEFINED      = PLEARN_DECLARE_OBJECT PLEARN_IMPLEMENT_OBJECT \
-		         DECLARE_OBJECT_PTR DECLARE_TEMPLATE_OBJECT_PTR \
-			 DECLARE_TYPE_TRAITS DECLARE_OBJECT_PP \
-			 PLEARN_DECLARE_ABSTRACT_OBJECT \
-			 PLEARN_IMPLEMENT_ABSTRACT_OBJECT \
-			 PLEARN_DECLARE_TEMPLATE_OBJECT \
-			 PLEARN_IMPLEMENT_TEMPLATE_OBJECT
+EXPAND_AS_DEFINED      = PLEARN_DECLARE_OBJECT \
+                         PLEARN_IMPLEMENT_OBJECT \
+                         DECLARE_OBJECT_PTR \
+                         DECLARE_TEMPLATE_OBJECT_PTR \
+                         DECLARE_TYPE_TRAITS \
+                         DECLARE_OBJECT_PP \
+                         PLEARN_DECLARE_ABSTRACT_OBJECT \
+                         PLEARN_IMPLEMENT_ABSTRACT_OBJECT \
+                         PLEARN_DECLARE_TEMPLATE_OBJECT \
+                         PLEARN_IMPLEMENT_TEMPLATE_OBJECT
 
 # If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then 
 # doxygen's preprocessor will remove all function-like macros that are alone 
-# on a line and do not end with a semicolon. Such function macros are typically 
-# used for boiler-plate code, and will confuse the parser if not removed.
+# on a line, have an all uppercase name, and do not end with a semicolon. Such 
+# function macros are typically used for boiler-plate code, and will confuse 
+# the parser if not removed.
 
 SKIP_FUNCTION_MACROS   = YES
 
 #---------------------------------------------------------------------------
-# Configuration::addtions related to external references   
+# Configuration::additions related to external references   
 #---------------------------------------------------------------------------
 
-# The TAGFILES tag can be used to specify one or more tagfiles.
+# The TAGFILES option can be used to specify one or more tagfiles. 
+# Optionally an initial location of the external documentation 
+# can be added for each tagfile. The format of a tag file without 
+# this location is as follows: 
+#   TAGFILES = file1 file2 ... 
+# Adding location for the tag files is done as follows: 
+#   TAGFILES = file1=loc1 "file2 = loc2" ... 
+# where "loc1" and "loc2" can be relative or absolute paths or 
+# URLs. If a location is present for each tag, the installdox tool 
+# does not have to be run to correct the links.
+# Note that each tag file must have a unique name
+# (where the name does NOT include the path)
+# If a tag file is not located in the directory in which doxygen 
+# is run, you must also specify the path to the tagfile here.
 
 TAGFILES               = 
 
 # When a file name is specified after GENERATE_TAGFILE, doxygen will create 
 # a tag file that is based on the input files it reads.
 
-GENERATE_TAGFILE       = 
+GENERATE_TAGFILE       = plearn.tag
 
 # If the ALLEXTERNALS tag is set to YES all external classes will be listed 
 # in the class index. If set to NO only the inherited external classes 
@@ -808,13 +1109,22 @@
 #---------------------------------------------------------------------------
 
 # If the CLASS_DIAGRAMS tag is set to YES (the default) Doxygen will 
-# generate a inheritance diagram (in Html, RTF and LaTeX) for classes with base or 
-# super classes. Setting the tag to NO turns the diagrams off. Note that this 
-# option is superceded by the HAVE_DOT option below. This is only a fallback. It is 
-# recommended to install and use dot, since it yield more powerful graphs.
+# generate a inheritance diagram (in HTML, RTF and LaTeX) for classes with base 
+# or super classes. Setting the tag to NO turns the diagrams off. Note that 
+# this option is superseded by the HAVE_DOT option below. This is only a 
+# fallback. It is recommended to install and use dot, since it yields more 
+# powerful graphs.
 
 CLASS_DIAGRAMS         = YES
 
+# You can define message sequence charts within doxygen comments using the \msc 
+# command. Doxygen will then run the mscgen tool (see http://www.mcternan.me.uk/mscgen/) to 
+# produce the chart and insert it in the documentation. The MSCGEN_PATH tag allows you to 
+# specify the directory where the mscgen tool resides. If left empty the tool is assumed to 
+# be found in the default search path.
+
+MSCGEN_PATH            = 
+
 # If set to YES, the inheritance and collaboration graphs will hide 
 # inheritance and usage relations if the target is undocumented 
 # or is not a class.
@@ -842,6 +1152,17 @@
 
 COLLABORATION_GRAPH    = YES
 
+# If the GROUP_GRAPHS and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for groups, showing the direct groups dependencies
+
+GROUP_GRAPHS           = YES
+
+# If the UML_LOOK tag is set to YES doxygen will generate inheritance and 
+# collaboration diagrams in a style similar to the OMG's Unified Modeling 
+# Language.
+
+UML_LOOK               = NO
+
 # If set to YES, the inheritance and collaboration graphs will show the 
 # relations between templates and their instances.
 
@@ -861,11 +1182,34 @@
 
 INCLUDED_BY_GRAPH      = YES
 
+# If the CALL_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a call dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable call graphs for selected 
+# functions only using the \callgraph command.
+
+CALL_GRAPH             = YES
+
+# If the CALLER_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a caller dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable caller graphs for selected 
+# functions only using the \callergraph command.
+
+CALLER_GRAPH           = YES
+
 # If the GRAPHICAL_HIERARCHY and HAVE_DOT tags are set to YES then doxygen 
 # will graphical hierarchy of all classes instead of a textual one.
 
 GRAPHICAL_HIERARCHY    = YES
 
+# If the DIRECTORY_GRAPH, SHOW_DIRECTORIES and HAVE_DOT tags are set to YES 
+# then doxygen will show the dependencies a directory has on other directories 
+# in a graphical way. The dependency relations are determined by the #include
+# relations between the files in the directories.
+
+DIRECTORY_GRAPH        = YES
+
 # The DOT_IMAGE_FORMAT tag can be used to set the image format of the images 
 # generated by dot. Possible values are png, jpg, or gif
 # If left blank png will be used.
@@ -873,7 +1217,7 @@
 DOT_IMAGE_FORMAT       = png
 
 # The tag DOT_PATH can be used to specify the path where the dot tool can be 
-# found. If left blank, it is assumed the dot tool can be found on the path.
+# found. If left blank, it is assumed the dot tool can be found in the path.
 
 DOT_PATH               = 
 
@@ -883,22 +1227,29 @@
 
 DOTFILE_DIRS           = 
 
-# The MAX_DOT_GRAPH_WIDTH tag can be used to set the maximum allowed width 
-# (in pixels) of the graphs generated by dot. If a graph becomes larger than 
-# this value, doxygen will try to truncate the graph, so that it fits within 
-# the specified constraint. Beware that most browsers cannot cope with very 
-# large images.
+# The MAX_DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of 
+# nodes that will be shown in the graph. If the number of nodes in a graph 
+# becomes larger than this value, doxygen will truncate the graph, which is 
+# visualized by representing a node as a red box. Note that doxygen will always 
+# show the root nodes and its direct children regardless of this setting.
 
-MAX_DOT_GRAPH_WIDTH    = 1024
+DOT_GRAPH_MAX_NODES    = 50
 
-# The MAX_DOT_GRAPH_HEIGHT tag can be used to set the maximum allows height 
-# (in pixels) of the graphs generated by dot. If a graph becomes larger than 
-# this value, doxygen will try to truncate the graph, so that it fits within 
-# the specified constraint. Beware that most browsers cannot cope with very 
-# large images.
+# Set the DOT_TRANSPARENT tag to YES to generate images with a transparent 
+# background. This is disabled by default, which results in a white background. 
+# Warning: Depending on the platform used, enabling this option may lead to 
+# badly anti-aliased labels on the edges of a graph (i.e. they become hard to 
+# read).
 
-MAX_DOT_GRAPH_HEIGHT   = 1024
+DOT_TRANSPARENT        = NO
 
+# Set the DOT_MULTI_TARGETS tag to YES allow dot to generate multiple output 
+# files in one run (i.e. multiple -o and -T options on the command line). This 
+# makes dot run faster, but since only newer versions of dot (>1.8.10) 
+# support this, this feature is disabled by default.
+
+DOT_MULTI_TARGETS      = YES
+
 # If the GENERATE_LEGEND tag is set to YES (the default) Doxygen will 
 # generate a legend page explaining the meaning of the various boxes and 
 # arrows in the dot generated graphs.
@@ -906,51 +1257,16 @@
 GENERATE_LEGEND        = YES
 
 # If the DOT_CLEANUP tag is set to YES (the default) Doxygen will 
-# remove the intermedate dot files that are used to generate 
+# remove the intermediate dot files that are used to generate 
 # the various graphs.
 
 DOT_CLEANUP            = YES
 
 #---------------------------------------------------------------------------
-# Configuration::addtions related to the search engine   
+# Configuration::additions related to the search engine   
 #---------------------------------------------------------------------------
 
 # The SEARCHENGINE tag specifies whether or not a search engine should be 
 # used. If set to NO the values of all tags below this one will be ignored.
 
-SEARCHENGINE           = NO
-
-# The CGI_NAME tag should be the name of the CGI script that 
-# starts the search engine (doxysearch) with the correct parameters. 
-# A script with this name will be generated by doxygen.
-
-CGI_NAME               = 
-
-# The CGI_URL tag should be the absolute URL to the directory where the 
-# cgi binaries are located. See the documentation of your http daemon for 
-# details.
-
-CGI_URL                = 
-
-# The DOC_URL tag should be the absolute URL to the directory where the 
-# documentation is located. If left blank the absolute path to the 
-# documentation, with file:// prepended to it, will be used.
-
-DOC_URL                = 
-
-# The DOC_ABSPATH tag should be the absolute path to the directory where the 
-# documentation is located. If left blank the directory on the local machine 
-# will be used.
-
-DOC_ABSPATH            = 
-
-# The BIN_ABSPATH tag must point to the directory where the doxysearch binary 
-# is installed.
-
-BIN_ABSPATH            = 
-
-# The EXT_DOC_PATHS tag can be used to specify one or more paths to 
-# documentation generated for other projects. This allows doxysearch to search 
-# the documentation for these projects as well.
-
-EXT_DOC_PATHS          = 
+SEARCHENGINE           = YES

Deleted: trunk/doc/Doxyfile.joseph
===================================================================
--- trunk/doc/Doxyfile.joseph	2007-11-28 15:36:09 UTC (rev 8314)
+++ trunk/doc/Doxyfile.joseph	2007-11-28 15:59:06 UTC (rev 8315)
@@ -1,1272 +0,0 @@
-# Doxyfile 1.5.1-20070315
-
-# This file describes the settings to be used by the documentation system
-# doxygen (www.doxygen.org) for a project
-#
-# All text after a hash (#) is considered a comment and will be ignored
-# The format is:
-#       TAG = value [value, ...]
-# For lists items can also be appended using:
-#       TAG += value [value, ...]
-# Values that contain spaces should be placed between quotes (" ")
-
-#---------------------------------------------------------------------------
-# Project related configuration options
-#---------------------------------------------------------------------------
-
-# This tag specifies the encoding used for all characters in the config file that 
-# follow. The default is UTF-8 which is also the encoding used for all text before 
-# the first occurrence of this tag. Doxygen uses libiconv (or the iconv built into 
-# libc) for the transcoding. See http://www.gnu.org/software/libiconv for the list of 
-# possible encodings.
-
-DOXYFILE_ENCODING      = UTF-8
-
-# The PROJECT_NAME tag is a single word (or a sequence of words surrounded 
-# by quotes) that should identify the project.
-
-PROJECT_NAME           = PLearn
-
-# The PROJECT_NUMBER tag can be used to enter a project or revision number. 
-# This could be handy for archiving the generated documentation or 
-# if some version control system is used.
-
-PROJECT_NUMBER         = 0.1
-
-# The OUTPUT_DIRECTORY tag is used to specify the (relative or absolute) 
-# base path where the generated documentation will be put. 
-# If a relative path is entered, it will be relative to the location 
-# where doxygen was started. If left blank the current directory will be used.
-
-OUTPUT_DIRECTORY       = LibraryReference.joseph
-
-# If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
-# 4096 sub-directories (in 2 levels) under the output directory of each output 
-# format and will distribute the generated files over these directories. 
-# Enabling this option can be useful when feeding doxygen a huge amount of 
-# source files, where putting all generated files in the same directory would 
-# otherwise cause performance problems for the file system.
-
-CREATE_SUBDIRS         = YES
-
-# The OUTPUT_LANGUAGE tag is used to specify the language in which all 
-# documentation generated by doxygen is written. Doxygen will use this 
-# information to generate all constant output in the proper language. 
-# The default language is English, other supported languages are: 
-# Afrikaans, Arabic, Brazilian, Catalan, Chinese, Chinese-Traditional, 
-# Croatian, Czech, Danish, Dutch, Finnish, French, German, Greek, Hungarian, 
-# Italian, Japanese, Japanese-en (Japanese with English messages), Korean, 
-# Korean-en, Lithuanian, Norwegian, Polish, Portuguese, Romanian, Russian, 
-# Serbian, Slovak, Slovene, Spanish, Swedish, and Ukrainian.
-
-OUTPUT_LANGUAGE        = English
-
-# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will 
-# include brief member descriptions after the members that are listed in 
-# the file and class documentation (similar to JavaDoc). 
-# Set to NO to disable this.
-
-BRIEF_MEMBER_DESC      = YES
-
-# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend 
-# the brief description of a member or function before the detailed description. 
-# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the 
-# brief descriptions will be completely suppressed.
-
-REPEAT_BRIEF           = YES
-
-# This tag implements a quasi-intelligent brief description abbreviator 
-# that is used to form the text in various listings. Each string 
-# in this list, if found as the leading text of the brief description, will be 
-# stripped from the text and the result after processing the whole list, is 
-# used as the annotated text. Otherwise, the brief description is used as-is. 
-# If left blank, the following values are used ("$name" is automatically 
-# replaced with the name of the entity): "The $name class" "The $name widget" 
-# "The $name file" "is" "provides" "specifies" "contains" 
-# "represents" "a" "an" "the"
-
-ABBREVIATE_BRIEF       = 
-
-# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then 
-# Doxygen will generate a detailed section even if there is only a brief 
-# description.
-
-ALWAYS_DETAILED_SEC    = NO
-
-# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all 
-# inherited members of a class in the documentation of that class as if those 
-# members were ordinary class members. Constructors, destructors and assignment 
-# operators of the base classes will not be shown.
-
-INLINE_INHERITED_MEMB  = NO
-
-# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full 
-# path before files name in the file list and in the header files. If set 
-# to NO the shortest path that makes the file name unique will be used.
-
-FULL_PATH_NAMES        = NO
-
-# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag 
-# can be used to strip a user-defined part of the path. Stripping is 
-# only done if one of the specified strings matches the left-hand part of 
-# the path. The tag can be used to show relative paths in the file list. 
-# If left blank the directory from which doxygen is run is used as the 
-# path to strip.
-
-STRIP_FROM_PATH        = 
-
-# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of 
-# the path mentioned in the documentation of a class, which tells 
-# the reader which header file to include in order to use a class. 
-# If left blank only the name of the header file containing the class 
-# definition is used. Otherwise one should specify the include paths that 
-# are normally passed to the compiler using the -I flag.
-
-STRIP_FROM_INC_PATH    = 
-
-# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter 
-# (but less readable) file names. This can be useful is your file systems 
-# doesn't support long names like on DOS, Mac, or CD-ROM.
-
-SHORT_NAMES            = NO
-
-# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen 
-# will interpret the first line (until the first dot) of a JavaDoc-style 
-# comment as the brief description. If set to NO, the JavaDoc 
-# comments will behave just like the Qt-style comments (thus requiring an 
-# explicit @brief command for a brief description.
-
-JAVADOC_AUTOBRIEF      = YES
-
-# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make Doxygen 
-# treat a multi-line C++ special comment block (i.e. a block of //! or /// 
-# comments) as a brief description. This used to be the default behaviour. 
-# The new default is to treat a multi-line C++ comment block as a detailed 
-# description. Set this tag to YES if you prefer the old behaviour instead.
-
-MULTILINE_CPP_IS_BRIEF = NO
-
-# If the DETAILS_AT_TOP tag is set to YES then Doxygen 
-# will output the detailed description near the top, like JavaDoc.
-# If set to NO, the detailed description appears after the member 
-# documentation.
-
-DETAILS_AT_TOP         = NO
-
-# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented 
-# member inherits the documentation from any documented member that it 
-# re-implements.
-
-INHERIT_DOCS           = YES
-
-# If the SEPARATE_MEMBER_PAGES tag is set to YES, then doxygen will produce 
-# a new page for each member. If set to NO, the documentation of a member will 
-# be part of the file/class/namespace that contains it.
-
-SEPARATE_MEMBER_PAGES  = NO
-
-# The TAB_SIZE tag can be used to set the number of spaces in a tab. 
-# Doxygen uses this value to replace tabs by spaces in code fragments.
-
-TAB_SIZE               = 8
-
-# This tag can be used to specify a number of aliases that acts 
-# as commands in the documentation. An alias has the form "name=value". 
-# For example adding "sideeffect=\par Side Effects:\n" will allow you to 
-# put the command \sideeffect (or @sideeffect) in the documentation, which 
-# will result in a user-defined paragraph with heading "Side Effects:". 
-# You can put \n's in the value part of an alias to insert newlines.
-
-ALIASES                = 
-
-# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C 
-# sources only. Doxygen will then generate output that is more tailored for C. 
-# For instance, some of the names that are used will be different. The list 
-# of all members will be omitted, etc.
-
-OPTIMIZE_OUTPUT_FOR_C  = NO
-
-# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java 
-# sources only. Doxygen will then generate output that is more tailored for Java. 
-# For instance, namespaces will be presented as packages, qualified scopes 
-# will look different, etc.
-
-OPTIMIZE_OUTPUT_JAVA   = NO
-
-# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want to 
-# include (a tag file for) the STL sources as input, then you should 
-# set this tag to YES in order to let doxygen match functions declarations and 
-# definitions whose arguments contain STL classes (e.g. func(std::string); v.s. 
-# func(std::string) {}). This also make the inheritance and collaboration 
-# diagrams that involve STL classes more complete and accurate.
-
-BUILTIN_STL_SUPPORT    = YES
-
-# If you use Microsoft's C++/CLI language, you should set this option to YES to
-# enable parsing support.
-
-CPP_CLI_SUPPORT        = NO
-
-# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC 
-# tag is set to YES, then doxygen will reuse the documentation of the first 
-# member in the group (if any) for the other members of the group. By default 
-# all members of a group must be documented explicitly.
-
-DISTRIBUTE_GROUP_DOC   = NO
-
-# Set the SUBGROUPING tag to YES (the default) to allow class member groups of 
-# the same type (for instance a group of public functions) to be put as a 
-# subgroup of that type (e.g. under the Public Functions section). Set it to 
-# NO to prevent subgrouping. Alternatively, this can be done per class using 
-# the \nosubgrouping command.
-
-SUBGROUPING            = YES
-
-#---------------------------------------------------------------------------
-# Build related configuration options
-#---------------------------------------------------------------------------
-
-# If the EXTRACT_ALL tag is set to YES doxygen will assume all entities in 
-# documentation are documented, even if no documentation was available. 
-# Private class members and static file members will be hidden unless 
-# the EXTRACT_PRIVATE and EXTRACT_STATIC tags are set to YES
-
-EXTRACT_ALL            = YES
-
-# If the EXTRACT_PRIVATE tag is set to YES all private members of a class 
-# will be included in the documentation.
-
-EXTRACT_PRIVATE        = YES
-
-# If the EXTRACT_STATIC tag is set to YES all static members of a file 
-# will be included in the documentation.
-
-EXTRACT_STATIC         = YES
-
-# If the EXTRACT_LOCAL_CLASSES tag is set to YES classes (and structs) 
-# defined locally in source files will be included in the documentation. 
-# If set to NO only classes defined in header files are included.
-
-EXTRACT_LOCAL_CLASSES  = YES
-
-# This flag is only useful for Objective-C code. When set to YES local 
-# methods, which are defined in the implementation section but not in 
-# the interface are included in the documentation. 
-# If set to NO (the default) only methods in the interface are included.
-
-EXTRACT_LOCAL_METHODS  = NO
-
-# If the HIDE_UNDOC_MEMBERS tag is set to YES, Doxygen will hide all 
-# undocumented members of documented classes, files or namespaces. 
-# If set to NO (the default) these members will be included in the 
-# various overviews, but no documentation section is generated. 
-# This option has no effect if EXTRACT_ALL is enabled.
-
-HIDE_UNDOC_MEMBERS     = NO
-
-# If the HIDE_UNDOC_CLASSES tag is set to YES, Doxygen will hide all 
-# undocumented classes that are normally visible in the class hierarchy. 
-# If set to NO (the default) these classes will be included in the various 
-# overviews. This option has no effect if EXTRACT_ALL is enabled.
-
-HIDE_UNDOC_CLASSES     = NO
-
-# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, Doxygen will hide all 
-# friend (class|struct|union) declarations. 
-# If set to NO (the default) these declarations will be included in the 
-# documentation.
-
-HIDE_FRIEND_COMPOUNDS  = NO
-
-# If the HIDE_IN_BODY_DOCS tag is set to YES, Doxygen will hide any 
-# documentation blocks found inside the body of a function. 
-# If set to NO (the default) these blocks will be appended to the 
-# function's detailed documentation block.
-
-HIDE_IN_BODY_DOCS      = NO
-
-# The INTERNAL_DOCS tag determines if documentation 
-# that is typed after a \internal command is included. If the tag is set 
-# to NO (the default) then the documentation will be excluded. 
-# Set it to YES to include the internal documentation.
-
-INTERNAL_DOCS          = NO
-
-# If the CASE_SENSE_NAMES tag is set to NO then Doxygen will only generate 
-# file names in lower-case letters. If set to YES upper-case letters are also 
-# allowed. This is useful if you have classes or files whose names only differ 
-# in case and if your file system supports case sensitive file names. Windows 
-# and Mac users are advised to set this option to NO.
-
-CASE_SENSE_NAMES       = YES
-
-# If the HIDE_SCOPE_NAMES tag is set to NO (the default) then Doxygen 
-# will show members with their full class and namespace scopes in the 
-# documentation. If set to YES the scope will be hidden.
-
-HIDE_SCOPE_NAMES       = NO
-
-# If the SHOW_INCLUDE_FILES tag is set to YES (the default) then Doxygen 
-# will put a list of the files that are included by a file in the documentation 
-# of that file.
-
-SHOW_INCLUDE_FILES     = YES
-
-# If the INLINE_INFO tag is set to YES (the default) then a tag [inline] 
-# is inserted in the documentation for inline members.
-
-INLINE_INFO            = YES
-
-# If the SORT_MEMBER_DOCS tag is set to YES (the default) then doxygen 
-# will sort the (detailed) documentation of file and class members 
-# alphabetically by member name. If set to NO the members will appear in 
-# declaration order.
-
-SORT_MEMBER_DOCS       = YES
-
-# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the 
-# brief documentation of file, namespace and class members alphabetically 
-# by member name. If set to NO (the default) the members will appear in 
-# declaration order.
-
-SORT_BRIEF_DOCS        = NO
-
-# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be 
-# sorted by fully-qualified names, including namespaces. If set to 
-# NO (the default), the class list will be sorted only by class name, 
-# not including the namespace part. 
-# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES.
-# Note: This option applies only to the class list, not to the 
-# alphabetical list.
-
-SORT_BY_SCOPE_NAME     = NO
-
-# The GENERATE_TODOLIST tag can be used to enable (YES) or 
-# disable (NO) the todo list. This list is created by putting \todo 
-# commands in the documentation.
-
-GENERATE_TODOLIST      = YES
-
-# The GENERATE_TESTLIST tag can be used to enable (YES) or 
-# disable (NO) the test list. This list is created by putting \test 
-# commands in the documentation.
-
-GENERATE_TESTLIST      = YES
-
-# The GENERATE_BUGLIST tag can be used to enable (YES) or 
-# disable (NO) the bug list. This list is created by putting \bug 
-# commands in the documentation.
-
-GENERATE_BUGLIST       = YES
-
-# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or 
-# disable (NO) the deprecated list. This list is created by putting 
-# \deprecated commands in the documentation.
-
-GENERATE_DEPRECATEDLIST= YES
-
-# The ENABLED_SECTIONS tag can be used to enable conditional 
-# documentation sections, marked by \if sectionname ... \endif.
-
-ENABLED_SECTIONS       = 
-
-# The MAX_INITIALIZER_LINES tag determines the maximum number of lines 
-# the initial value of a variable or define consists of for it to appear in 
-# the documentation. If the initializer consists of more lines than specified 
-# here it will be hidden. Use a value of 0 to hide initializers completely. 
-# The appearance of the initializer of individual variables and defines in the 
-# documentation can be controlled using \showinitializer or \hideinitializer 
-# command in the documentation regardless of this setting.
-
-MAX_INITIALIZER_LINES  = 30
-
-# Set the SHOW_USED_FILES tag to NO to disable the list of files generated 
-# at the bottom of the documentation of classes and structs. If set to YES the 
-# list will mention the files that were used to generate the documentation.
-
-SHOW_USED_FILES        = YES
-
-# If the sources in your project are distributed over multiple directories 
-# then setting the SHOW_DIRECTORIES tag to YES will show the directory hierarchy 
-# in the documentation. The default is NO.
-
-SHOW_DIRECTORIES       = YES
-
-# The FILE_VERSION_FILTER tag can be used to specify a program or script that 
-# doxygen should invoke to get the current version for each file (typically from the 
-# version control system). Doxygen will invoke the program by executing (via 
-# popen()) the command <command> <input-file>, where <command> is the value of 
-# the FILE_VERSION_FILTER tag, and <input-file> is the name of an input file 
-# provided by doxygen. Whatever the program writes to standard output 
-# is used as the file version. See the manual for examples.
-
-FILE_VERSION_FILTER    = 
-
-#---------------------------------------------------------------------------
-# configuration options related to warning and progress messages
-#---------------------------------------------------------------------------
-
-# The QUIET tag can be used to turn on/off the messages that are generated 
-# by doxygen. Possible values are YES and NO. If left blank NO is used.
-
-QUIET                  = NO
-
-# The WARNINGS tag can be used to turn on/off the warning messages that are 
-# generated by doxygen. Possible values are YES and NO. If left blank 
-# NO is used.
-
-WARNINGS               = YES
-
-# If WARN_IF_UNDOCUMENTED is set to YES, then doxygen will generate warnings 
-# for undocumented members. If EXTRACT_ALL is set to YES then this flag will 
-# automatically be disabled.
-
-WARN_IF_UNDOCUMENTED   = NO
-
-# If WARN_IF_DOC_ERROR is set to YES, doxygen will generate warnings for 
-# potential errors in the documentation, such as not documenting some 
-# parameters in a documented function, or documenting parameters that 
-# don't exist or using markup commands wrongly.
-
-WARN_IF_DOC_ERROR      = YES
-
-# This WARN_NO_PARAMDOC option can be abled to get warnings for 
-# functions that are documented, but have no documentation for their parameters 
-# or return value. If set to NO (the default) doxygen will only warn about 
-# wrong or incomplete parameter documentation, but not about the absence of 
-# documentation.
-
-WARN_NO_PARAMDOC       = NO
-
-# The WARN_FORMAT tag determines the format of the warning messages that 
-# doxygen can produce. The string should contain the $file, $line, and $text 
-# tags, which will be replaced by the file and line number from which the 
-# warning originated and the warning text. Optionally the format may contain 
-# $version, which will be replaced by the version of the file (if it could 
-# be obtained via FILE_VERSION_FILTER)
-
-WARN_FORMAT            = 
-
-# The WARN_LOGFILE tag can be used to specify a file to which warning 
-# and error messages should be written. If left blank the output is written 
-# to stderr.
-
-WARN_LOGFILE           = 
-
-#---------------------------------------------------------------------------
-# configuration options related to the input files
-#---------------------------------------------------------------------------
-
-# The INPUT tag can be used to specify the files and/or directories that contain 
-# documented source files. You may enter file names like "myfile.cpp" or 
-# directories like "/usr/src/myproject". Separate the files or directories 
-# with spaces.
-
-INPUT                  = ../plearn \
-                         ../plearn_learners \
-                         ../plearn_learners_experimental \
-                         ../commands
-
-# This tag can be used to specify the character encoding of the source files that 
-# doxygen parses. Internally doxygen uses the UTF-8 encoding, which is also the default 
-# input encoding. Doxygen uses libiconv (or the iconv built into libc) for the transcoding. 
-# See http://www.gnu.org/software/libiconv for the list of possible encodings.
-
-INPUT_ENCODING         = UTF-8
-
-# If the value of the INPUT tag contains directories, you can use the 
-# FILE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
-# and *.h) to filter out the source-files in the directories. If left 
-# blank the following patterns are tested: 
-# *.c *.cc *.cxx *.cpp *.c++ *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh *.hxx 
-# *.hpp *.h++ *.idl *.odl *.cs *.php *.php3 *.inc *.m *.mm *.py
-
-FILE_PATTERNS          = *.cc \
-                         *.h
-
-# The RECURSIVE tag can be used to turn specify whether or not subdirectories 
-# should be searched for input files as well. Possible values are YES and NO. 
-# If left blank NO is used.
-
-RECURSIVE              = YES
-
-# The EXCLUDE tag can be used to specify files and/or directories that should 
-# excluded from the INPUT source files. This way you can easily exclude a 
-# subdirectory from a directory tree whose root is specified with the INPUT tag.
-
-EXCLUDE                = 
-
-# The EXCLUDE_SYMLINKS tag can be used select whether or not files or 
-# directories that are symbolic links (a Unix filesystem feature) are excluded 
-# from the input.
-
-EXCLUDE_SYMLINKS       = NO
-
-# If the value of the INPUT tag contains directories, you can use the 
-# EXCLUDE_PATTERNS tag to specify one or more wildcard patterns to exclude 
-# certain files from those directories. Note that the wildcards are matched 
-# against the file with absolute path, so to exclude all test directories 
-# for example use the pattern */test/*
-
-EXCLUDE_PATTERNS       = OBJS \
-                         .svn \
-                         .pytest
-
-# The EXCLUDE_SYMBOLS tag can be used to specify one or more symbol names 
-# (namespaces, classes, functions, etc.) that should be excluded from the output. 
-# The symbol name can be a fully qualified name, a word, or if the wildcard * is used, 
-# a substring. Examples: ANamespace, AClass, AClass::ANamespace, ANamespace::*Test
-
-EXCLUDE_SYMBOLS        = 
-
-# The EXAMPLE_PATH tag can be used to specify one or more files or 
-# directories that contain example code fragments that are included (see 
-# the \include command).
-
-EXAMPLE_PATH           = 
-
-# If the value of the EXAMPLE_PATH tag contains directories, you can use the 
-# EXAMPLE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
-# and *.h) to filter out the source-files in the directories. If left 
-# blank all files are included.
-
-EXAMPLE_PATTERNS       = 
-
-# If the EXAMPLE_RECURSIVE tag is set to YES then subdirectories will be 
-# searched for input files to be used with the \include or \dontinclude 
-# commands irrespective of the value of the RECURSIVE tag. 
-# Possible values are YES and NO. If left blank NO is used.
-
-EXAMPLE_RECURSIVE      = NO
-
-# The IMAGE_PATH tag can be used to specify one or more files or 
-# directories that contain image that are included in the documentation (see 
-# the \image command).
-
-IMAGE_PATH             = 
-
-# The INPUT_FILTER tag can be used to specify a program that doxygen should 
-# invoke to filter for each input file. Doxygen will invoke the filter program 
-# by executing (via popen()) the command <filter> <input-file>, where <filter> 
-# is the value of the INPUT_FILTER tag, and <input-file> is the name of an 
-# input file. Doxygen will then use the output that the filter program writes 
-# to standard output.  If FILTER_PATTERNS is specified, this tag will be 
-# ignored.
-
-INPUT_FILTER           = 
-
-# The FILTER_PATTERNS tag can be used to specify filters on a per file pattern 
-# basis.  Doxygen will compare the file name with each pattern and apply the 
-# filter if there is a match.  The filters are a list of the form: 
-# pattern=filter (like *.cpp=my_cpp_filter). See INPUT_FILTER for further 
-# info on how filters are used. If FILTER_PATTERNS is empty, INPUT_FILTER 
-# is applied to all files.
-
-FILTER_PATTERNS        = 
-
-# If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using 
-# INPUT_FILTER) will be used to filter the input files when producing source 
-# files to browse (i.e. when SOURCE_BROWSER is set to YES).
-
-FILTER_SOURCE_FILES    = NO
-
-#---------------------------------------------------------------------------
-# configuration options related to source browsing
-#---------------------------------------------------------------------------
-
-# If the SOURCE_BROWSER tag is set to YES then a list of source files will 
-# be generated. Documented entities will be cross-referenced with these sources. 
-# Note: To get rid of all source code in the generated output, make sure also 
-# VERBATIM_HEADERS is set to NO.
-
-SOURCE_BROWSER         = YES
-
-# Setting the INLINE_SOURCES tag to YES will include the body 
-# of functions and classes directly in the documentation.
-
-INLINE_SOURCES         = YES
-
-# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct 
-# doxygen to hide any special comment blocks from generated source code 
-# fragments. Normal C and C++ comments will always remain visible.
-
-STRIP_CODE_COMMENTS    = YES
-
-# If the REFERENCED_BY_RELATION tag is set to YES (the default) 
-# then for each documented function all documented 
-# functions referencing it will be listed.
-
-REFERENCED_BY_RELATION = YES
-
-# If the REFERENCES_RELATION tag is set to YES (the default) 
-# then for each documented function all documented entities 
-# called/used by that function will be listed.
-
-REFERENCES_RELATION    = YES
-
-# If the REFERENCES_LINK_SOURCE tag is set to YES (the default)
-# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from
-# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will
-# link to the source code.  Otherwise they will link to the documentstion.
-
-REFERENCES_LINK_SOURCE = YES
-
-# If the USE_HTAGS tag is set to YES then the references to source code 
-# will point to the HTML generated by the htags(1) tool instead of doxygen 
-# built-in source browser. The htags tool is part of GNU's global source 
-# tagging system (see http://www.gnu.org/software/global/global.html). You 
-# will need version 4.8.6 or higher.
-
-USE_HTAGS              = NO
-
-# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen 
-# will generate a verbatim copy of the header file for each class for 
-# which an include is specified. Set to NO to disable this.
-
-VERBATIM_HEADERS       = YES
-
-#---------------------------------------------------------------------------
-# configuration options related to the alphabetical class index
-#---------------------------------------------------------------------------
-
-# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index 
-# of all compounds will be generated. Enable this if the project 
-# contains a lot of classes, structs, unions or interfaces.
-
-ALPHABETICAL_INDEX     = YES
-
-# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then 
-# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns 
-# in which this list will be split (can be a number in the range [1..20])
-
-COLS_IN_ALPHA_INDEX    = 5
-
-# In case all classes in a project start with a common prefix, all 
-# classes will be put under the same header in the alphabetical index. 
-# The IGNORE_PREFIX tag can be used to specify one or more prefixes that 
-# should be ignored while generating the index headers.
-
-IGNORE_PREFIX          = 
-
-#---------------------------------------------------------------------------
-# configuration options related to the HTML output
-#---------------------------------------------------------------------------
-
-# If the GENERATE_HTML tag is set to YES (the default) Doxygen will 
-# generate HTML output.
-
-GENERATE_HTML          = YES
-
-# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. 
-# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
-# put in front of it. If left blank `html' will be used as the default path.
-
-HTML_OUTPUT            = 
-
-# The HTML_FILE_EXTENSION tag can be used to specify the file extension for 
-# each generated HTML page (for example: .htm,.php,.asp). If it is left blank 
-# doxygen will generate files with .html extension.
-
-HTML_FILE_EXTENSION    = .html
-
-# The HTML_HEADER tag can be used to specify a personal HTML header for 
-# each generated HTML page. If it is left blank doxygen will generate a 
-# standard header.
-
-HTML_HEADER            = 
-
-# The HTML_FOOTER tag can be used to specify a personal HTML footer for 
-# each generated HTML page. If it is left blank doxygen will generate a 
-# standard footer.
-
-HTML_FOOTER            = 
-
-# The HTML_STYLESHEET tag can be used to specify a user-defined cascading 
-# style sheet that is used by each HTML page. It can be used to 
-# fine-tune the look of the HTML output. If the tag is left blank doxygen 
-# will generate a default style sheet. Note that doxygen will try to copy 
-# the style sheet file to the HTML output directory, so don't put your own 
-# stylesheet in the HTML output directory as well, or it will be erased!
-
-HTML_STYLESHEET        = 
-
-# If the HTML_ALIGN_MEMBERS tag is set to YES, the members of classes, 
-# files or namespaces will be aligned in HTML using tables. If set to 
-# NO a bullet list will be used.
-
-HTML_ALIGN_MEMBERS     = YES
-
-# If the GENERATE_HTMLHELP tag is set to YES, additional index files 
-# will be generated that can be used as input for tools like the 
-# Microsoft HTML help workshop to generate a compressed HTML help file (.chm) 
-# of the generated HTML documentation.
-
-GENERATE_HTMLHELP      = NO
-
-# If the GENERATE_HTMLHELP tag is set to YES, the CHM_FILE tag can 
-# be used to specify the file name of the resulting .chm file. You 
-# can add a path in front of the file if the result should not be 
-# written to the html output directory.
-
-CHM_FILE               = 
-
-# If the GENERATE_HTMLHELP tag is set to YES, the HHC_LOCATION tag can 
-# be used to specify the location (absolute path including file name) of 
-# the HTML help compiler (hhc.exe). If non-empty doxygen will try to run 
-# the HTML help compiler on the generated index.hhp.
-
-HHC_LOCATION           = 
-
-# If the GENERATE_HTMLHELP tag is set to YES, the GENERATE_CHI flag 
-# controls if a separate .chi index file is generated (YES) or that 
-# it should be included in the master .chm file (NO).
-
-GENERATE_CHI           = NO
-
-# If the GENERATE_HTMLHELP tag is set to YES, the BINARY_TOC flag 
-# controls whether a binary table of contents is generated (YES) or a 
-# normal table of contents (NO) in the .chm file.
-
-BINARY_TOC             = NO
-
-# The TOC_EXPAND flag can be set to YES to add extra items for group members 
-# to the contents of the HTML help documentation and to the tree view.
-
-TOC_EXPAND             = NO
-
-# The DISABLE_INDEX tag can be used to turn on/off the condensed index at 
-# top of each HTML page. The value NO (the default) enables the index and 
-# the value YES disables it.
-
-DISABLE_INDEX          = NO
-
-# This tag can be used to set the number of enum values (range [1..20]) 
-# that doxygen will group on one line in the generated HTML documentation.
-
-ENUM_VALUES_PER_LINE   = 4
-
-# If the GENERATE_TREEVIEW tag is set to YES, a side panel will be
-# generated containing a tree-like index structure (just like the one that 
-# is generated for HTML Help). For this to work a browser that supports 
-# JavaScript, DHTML, CSS and frames is required (for instance Mozilla 1.0+, 
-# Netscape 6.0+, Internet explorer 5.0+, or Konqueror). Windows users are 
-# probably better off using the HTML help feature.
-
-GENERATE_TREEVIEW      = NO
-
-# If the treeview is enabled (see GENERATE_TREEVIEW) then this tag can be 
-# used to set the initial width (in pixels) of the frame in which the tree 
-# is shown.
-
-TREEVIEW_WIDTH         = 250
-
-#---------------------------------------------------------------------------
-# configuration options related to the LaTeX output
-#---------------------------------------------------------------------------
-
-# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will 
-# generate Latex output.
-
-GENERATE_LATEX         = YES
-
-# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. 
-# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
-# put in front of it. If left blank `latex' will be used as the default path.
-
-LATEX_OUTPUT           = 
-
-# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be 
-# invoked. If left blank `latex' will be used as the default command name.
-
-LATEX_CMD_NAME         = latex
-
-# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to 
-# generate index for LaTeX. If left blank `makeindex' will be used as the 
-# default command name.
-
-MAKEINDEX_CMD_NAME     = makeindex
-
-# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact 
-# LaTeX documents. This may be useful for small projects and may help to 
-# save some trees in general.
-
-COMPACT_LATEX          = NO
-
-# The PAPER_TYPE tag can be used to set the paper type that is used 
-# by the printer. Possible values are: a4, a4wide, letter, legal and 
-# executive. If left blank a4wide will be used.
-
-PAPER_TYPE             = letter
-
-# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX 
-# packages that should be included in the LaTeX output.
-
-EXTRA_PACKAGES         = 
-
-# The LATEX_HEADER tag can be used to specify a personal LaTeX header for 
-# the generated latex document. The header should contain everything until 
-# the first chapter. If it is left blank doxygen will generate a 
-# standard header. Notice: only use this tag if you know what you are doing!
-
-LATEX_HEADER           = 
-
-# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated 
-# is prepared for conversion to pdf (using ps2pdf). The pdf file will 
-# contain links (just like the HTML output) instead of page references 
-# This makes the output suitable for online browsing using a pdf viewer.
-
-PDF_HYPERLINKS         = YES
-
-# If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of 
-# plain latex in the generated Makefile. Set this option to YES to get a 
-# higher quality PDF documentation.
-
-USE_PDFLATEX           = YeS
-
-# If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\batchmode. 
-# command to the generated LaTeX files. This will instruct LaTeX to keep 
-# running if errors occur, instead of asking the user for help. 
-# This option is also used when generating formulas in HTML.
-
-LATEX_BATCHMODE        = YES
-
-# If LATEX_HIDE_INDICES is set to YES then doxygen will not 
-# include the index chapters (such as File Index, Compound Index, etc.) 
-# in the output.
-
-LATEX_HIDE_INDICES     = NO
-
-#---------------------------------------------------------------------------
-# configuration options related to the RTF output
-#---------------------------------------------------------------------------
-
-# If the GENERATE_RTF tag is set to YES Doxygen will generate RTF output 
-# The RTF output is optimized for Word 97 and may not look very pretty with 
-# other RTF readers or editors.
-
-GENERATE_RTF           = NO
-
-# The RTF_OUTPUT tag is used to specify where the RTF docs will be put. 
-# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
-# put in front of it. If left blank `rtf' will be used as the default path.
-
-RTF_OUTPUT             = 
-
-# If the COMPACT_RTF tag is set to YES Doxygen generates more compact 
-# RTF documents. This may be useful for small projects and may help to 
-# save some trees in general.
-
-COMPACT_RTF            = NO
-
-# If the RTF_HYPERLINKS tag is set to YES, the RTF that is generated 
-# will contain hyperlink fields. The RTF file will 
-# contain links (just like the HTML output) instead of page references. 
-# This makes the output suitable for online browsing using WORD or other 
-# programs which support those fields. 
-# Note: wordpad (write) and others do not support links.
-
-RTF_HYPERLINKS         = NO
-
-# Load stylesheet definitions from file. Syntax is similar to doxygen's 
-# config file, i.e. a series of assignments. You only have to provide 
-# replacements, missing definitions are set to their default value.
-
-RTF_STYLESHEET_FILE    = 
-
-# Set optional variables used in the generation of an rtf document. 
-# Syntax is similar to doxygen's config file.
-
-RTF_EXTENSIONS_FILE    = 
-
-#---------------------------------------------------------------------------
-# configuration options related to the man page output
-#---------------------------------------------------------------------------
-
-# If the GENERATE_MAN tag is set to YES (the default) Doxygen will 
-# generate man pages
-
-GENERATE_MAN           = NO
-
-# The MAN_OUTPUT tag is used to specify where the man pages will be put. 
-# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
-# put in front of it. If left blank `man' will be used as the default path.
-
-MAN_OUTPUT             = 
-
-# The MAN_EXTENSION tag determines the extension that is added to 
-# the generated man pages (default is the subroutine's section .3)
-
-MAN_EXTENSION          = 
-
-# If the MAN_LINKS tag is set to YES and Doxygen generates man output, 
-# then it will generate one additional man file for each entity 
-# documented in the real man page(s). These additional files 
-# only source the real man page, but without them the man command 
-# would be unable to find the correct page. The default is NO.
-
-MAN_LINKS              = NO
-
-#---------------------------------------------------------------------------
-# configuration options related to the XML output
-#---------------------------------------------------------------------------
-
-# If the GENERATE_XML tag is set to YES Doxygen will 
-# generate an XML file that captures the structure of 
-# the code including all documentation.
-
-GENERATE_XML           = YES
-
-# The XML_OUTPUT tag is used to specify where the XML pages will be put. 
-# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
-# put in front of it. If left blank `xml' will be used as the default path.
-
-XML_OUTPUT             = xml
-
-# The XML_SCHEMA tag can be used to specify an XML schema, 
-# which can be used by a validating XML parser to check the 
-# syntax of the XML files.
-
-XML_SCHEMA             = 
-
-# The XML_DTD tag can be used to specify an XML DTD, 
-# which can be used by a validating XML parser to check the 
-# syntax of the XML files.
-
-XML_DTD                = 
-
-# If the XML_PROGRAMLISTING tag is set to YES Doxygen will 
-# dump the program listings (including syntax highlighting 
-# and cross-referencing information) to the XML output. Note that 
-# enabling this will significantly increase the size of the XML output.
-
-XML_PROGRAMLISTING     = YES
-
-#---------------------------------------------------------------------------
-# configuration options for the AutoGen Definitions output
-#---------------------------------------------------------------------------
-
-# If the GENERATE_AUTOGEN_DEF tag is set to YES Doxygen will 
-# generate an AutoGen Definitions (see autogen.sf.net) file 
-# that captures the structure of the code including all 
-# documentation. Note that this feature is still experimental 
-# and incomplete at the moment.
-
-GENERATE_AUTOGEN_DEF   = NO
-
-#---------------------------------------------------------------------------
-# configuration options related to the Perl module output
-#---------------------------------------------------------------------------
-
-# If the GENERATE_PERLMOD tag is set to YES Doxygen will 
-# generate a Perl module file that captures the structure of 
-# the code including all documentation. Note that this 
-# feature is still experimental and incomplete at the 
-# moment.
-
-GENERATE_PERLMOD       = NO
-
-# If the PERLMOD_LATEX tag is set to YES Doxygen will generate 
-# the necessary Makefile rules, Perl scripts and LaTeX code to be able 
-# to generate PDF and DVI output from the Perl module output.
-
-PERLMOD_LATEX          = NO
-
-# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be 
-# nicely formatted so it can be parsed by a human reader.  This is useful 
-# if you want to understand what is going on.  On the other hand, if this 
-# tag is set to NO the size of the Perl module output will be much smaller 
-# and Perl will parse it just the same.
-
-PERLMOD_PRETTY         = YES
-
-# The names of the make variables in the generated doxyrules.make file 
-# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX. 
-# This is useful so different doxyrules.make files included by the same 
-# Makefile don't overwrite each other's variables.
-
-PERLMOD_MAKEVAR_PREFIX = 
-
-#---------------------------------------------------------------------------
-# Configuration options related to the preprocessor   
-#---------------------------------------------------------------------------
-
-# If the ENABLE_PREPROCESSING tag is set to YES (the default) Doxygen will 
-# evaluate all C-preprocessor directives found in the sources and include 
-# files.
-
-ENABLE_PREPROCESSING   = YES
-
-# If the MACRO_EXPANSION tag is set to YES Doxygen will expand all macro 
-# names in the source code. If set to NO (the default) only conditional 
-# compilation will be performed. Macro expansion can be done in a controlled 
-# way by setting EXPAND_ONLY_PREDEF to YES.
-
-MACRO_EXPANSION        = YES
-
-# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES 
-# then the macro expansion is limited to the macros specified with the 
-# PREDEFINED and EXPAND_AS_DEFINED tags.
-
-EXPAND_ONLY_PREDEF     = YES
-
-# If the SEARCH_INCLUDES tag is set to YES (the default) the includes files 
-# in the INCLUDE_PATH (see below) will be search if a #include is found.
-
-SEARCH_INCLUDES        = YES
-
-# The INCLUDE_PATH tag can be used to specify one or more directories that 
-# contain include files that are not input files but should be processed by 
-# the preprocessor.
-
-INCLUDE_PATH           = 
-
-# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard 
-# patterns (like *.h and *.hpp) to filter out the header-files in the 
-# directories. If left blank, the patterns specified with FILE_PATTERNS will 
-# be used.
-
-INCLUDE_FILE_PATTERNS  = 
-
-# The PREDEFINED tag can be used to specify one or more macro names that 
-# are defined before the preprocessor is started (similar to the -D option of 
-# gcc). The argument of the tag is a list of macros of the form: name 
-# or name=definition (no spaces). If the definition and the = are 
-# omitted =1 is assumed. To prevent a macro definition from being 
-# undefined via #undef or recursively expanded use the := operator 
-# instead of the = operator.
-
-PREDEFINED             = 
-
-# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then 
-# this tag can be used to specify a list of macro names that should be expanded. 
-# The macro definition that is found in the sources will be used. 
-# Use the PREDEFINED tag if you want to use a different macro definition.
-
-EXPAND_AS_DEFINED      = PLEARN_DECLARE_OBJECT \
-                         PLEARN_IMPLEMENT_OBJECT \
-                         DECLARE_OBJECT_PTR \
-                         DECLARE_TEMPLATE_OBJECT_PTR \
-                         DECLARE_TYPE_TRAITS \
-                         DECLARE_OBJECT_PP \
-                         PLEARN_DECLARE_ABSTRACT_OBJECT \
-                         PLEARN_IMPLEMENT_ABSTRACT_OBJECT \
-                         PLEARN_DECLARE_TEMPLATE_OBJECT \
-                         PLEARN_IMPLEMENT_TEMPLATE_OBJECT
-
-# If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then 
-# doxygen's preprocessor will remove all function-like macros that are alone 
-# on a line, have an all uppercase name, and do not end with a semicolon. Such 
-# function macros are typically used for boiler-plate code, and will confuse 
-# the parser if not removed.
-
-SKIP_FUNCTION_MACROS   = YES
-
-#---------------------------------------------------------------------------
-# Configuration::additions related to external references   
-#---------------------------------------------------------------------------
-
-# The TAGFILES option can be used to specify one or more tagfiles. 
-# Optionally an initial location of the external documentation 
-# can be added for each tagfile. The format of a tag file without 
-# this location is as follows: 
-#   TAGFILES = file1 file2 ... 
-# Adding location for the tag files is done as follows: 
-#   TAGFILES = file1=loc1 "file2 = loc2" ... 
-# where "loc1" and "loc2" can be relative or absolute paths or 
-# URLs. If a location is present for each tag, the installdox tool 
-# does not have to be run to correct the links.
-# Note that each tag file must have a unique name
-# (where the name does NOT include the path)
-# If a tag file is not located in the directory in which doxygen 
-# is run, you must also specify the path to the tagfile here.
-
-TAGFILES               = 
-
-# When a file name is specified after GENERATE_TAGFILE, doxygen will create 
-# a tag file that is based on the input files it reads.
-
-GENERATE_TAGFILE       = plearn.tag
-
-# If the ALLEXTERNALS tag is set to YES all external classes will be listed 
-# in the class index. If set to NO only the inherited external classes 
-# will be listed.
-
-ALLEXTERNALS           = NO
-
-# If the EXTERNAL_GROUPS tag is set to YES all external groups will be listed 
-# in the modules index. If set to NO, only the current project's groups will 
-# be listed.
-
-EXTERNAL_GROUPS        = YES
-
-# The PERL_PATH should be the absolute path and name of the perl script 
-# interpreter (i.e. the result of `which perl').
-
-PERL_PATH              = 
-
-#---------------------------------------------------------------------------
-# Configuration options related to the dot tool   
-#---------------------------------------------------------------------------
-
-# If the CLASS_DIAGRAMS tag is set to YES (the default) Doxygen will 
-# generate a inheritance diagram (in HTML, RTF and LaTeX) for classes with base 
-# or super classes. Setting the tag to NO turns the diagrams off. Note that 
-# this option is superseded by the HAVE_DOT option below. This is only a 
-# fallback. It is recommended to install and use dot, since it yields more 
-# powerful graphs.
-
-CLASS_DIAGRAMS         = YES
-
-# You can define message sequence charts within doxygen comments using the \msc 
-# command. Doxygen will then run the mscgen tool (see http://www.mcternan.me.uk/mscgen/) to 
-# produce the chart and insert it in the documentation. The MSCGEN_PATH tag allows you to 
-# specify the directory where the mscgen tool resides. If left empty the tool is assumed to 
-# be found in the default search path.
-
-MSCGEN_PATH            = 
-
-# If set to YES, the inheritance and collaboration graphs will hide 
-# inheritance and usage relations if the target is undocumented 
-# or is not a class.
-
-HIDE_UNDOC_RELATIONS   = NO
-
-# If you set the HAVE_DOT tag to YES then doxygen will assume the dot tool is 
-# available from the path. This tool is part of Graphviz, a graph visualization 
-# toolkit from AT&T and Lucent Bell Labs. The other options in this section 
-# have no effect if this option is set to NO (the default)
-
-HAVE_DOT               = YES
-
-# If the CLASS_GRAPH and HAVE_DOT tags are set to YES then doxygen 
-# will generate a graph for each documented class showing the direct and 
-# indirect inheritance relations. Setting this tag to YES will force the 
-# the CLASS_DIAGRAMS tag to NO.
-
-CLASS_GRAPH            = YES
-
-# If the COLLABORATION_GRAPH and HAVE_DOT tags are set to YES then doxygen 
-# will generate a graph for each documented class showing the direct and 
-# indirect implementation dependencies (inheritance, containment, and 
-# class references variables) of the class with other documented classes.
-
-COLLABORATION_GRAPH    = YES
-
-# If the GROUP_GRAPHS and HAVE_DOT tags are set to YES then doxygen 
-# will generate a graph for groups, showing the direct groups dependencies
-
-GROUP_GRAPHS           = YES
-
-# If the UML_LOOK tag is set to YES doxygen will generate inheritance and 
-# collaboration diagrams in a style similar to the OMG's Unified Modeling 
-# Language.
-
-UML_LOOK               = NO
-
-# If set to YES, the inheritance and collaboration graphs will show the 
-# relations between templates and their instances.
-
-TEMPLATE_RELATIONS     = YES
-
-# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDE_GRAPH, and HAVE_DOT 
-# tags are set to YES then doxygen will generate a graph for each documented 
-# file showing the direct and indirect include dependencies of the file with 
-# other documented files.
-
-INCLUDE_GRAPH          = YES
-
-# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDED_BY_GRAPH, and 
-# HAVE_DOT tags are set to YES then doxygen will generate a graph for each 
-# documented header file showing the documented files that directly or 
-# indirectly include this file.
-
-INCLUDED_BY_GRAPH      = YES
-
-# If the CALL_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
-# generate a call dependency graph for every global function or class method. 
-# Note that enabling this option will significantly increase the time of a run. 
-# So in most cases it will be better to enable call graphs for selected 
-# functions only using the \callgraph command.
-
-CALL_GRAPH             = YES
-
-# If the CALLER_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
-# generate a caller dependency graph for every global function or class method. 
-# Note that enabling this option will significantly increase the time of a run. 
-# So in most cases it will be better to enable caller graphs for selected 
-# functions only using the \callergraph command.
-
-CALLER_GRAPH           = YES
-
-# If the GRAPHICAL_HIERARCHY and HAVE_DOT tags are set to YES then doxygen 
-# will graphical hierarchy of all classes instead of a textual one.
-
-GRAPHICAL_HIERARCHY    = YES
-
-# If the DIRECTORY_GRAPH, SHOW_DIRECTORIES and HAVE_DOT tags are set to YES 
-# then doxygen will show the dependencies a directory has on other directories 
-# in a graphical way. The dependency relations are determined by the #include
-# relations between the files in the directories.
-
-DIRECTORY_GRAPH        = YES
-
-# The DOT_IMAGE_FORMAT tag can be used to set the image format of the images 
-# generated by dot. Possible values are png, jpg, or gif
-# If left blank png will be used.
-
-DOT_IMAGE_FORMAT       = png
-
-# The tag DOT_PATH can be used to specify the path where the dot tool can be 
-# found. If left blank, it is assumed the dot tool can be found in the path.
-
-DOT_PATH               = 
-
-# The DOTFILE_DIRS tag can be used to specify one or more directories that 
-# contain dot files that are included in the documentation (see the 
-# \dotfile command).
-
-DOTFILE_DIRS           = 
-
-# The MAX_DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of 
-# nodes that will be shown in the graph. If the number of nodes in a graph 
-# becomes larger than this value, doxygen will truncate the graph, which is 
-# visualized by representing a node as a red box. Note that doxygen will always 
-# show the root nodes and its direct children regardless of this setting.
-
-DOT_GRAPH_MAX_NODES    = 50
-
-# Set the DOT_TRANSPARENT tag to YES to generate images with a transparent 
-# background. This is disabled by default, which results in a white background. 
-# Warning: Depending on the platform used, enabling this option may lead to 
-# badly anti-aliased labels on the edges of a graph (i.e. they become hard to 
-# read).
-
-DOT_TRANSPARENT        = NO
-
-# Set the DOT_MULTI_TARGETS tag to YES allow dot to generate multiple output 
-# files in one run (i.e. multiple -o and -T options on the command line). This 
-# makes dot run faster, but since only newer versions of dot (>1.8.10) 
-# support this, this feature is disabled by default.
-
-DOT_MULTI_TARGETS      = YES
-
-# If the GENERATE_LEGEND tag is set to YES (the default) Doxygen will 
-# generate a legend page explaining the meaning of the various boxes and 
-# arrows in the dot generated graphs.
-
-GENERATE_LEGEND        = YES
-
-# If the DOT_CLEANUP tag is set to YES (the default) Doxygen will 
-# remove the intermediate dot files that are used to generate 
-# the various graphs.
-
-DOT_CLEANUP            = YES
-
-#---------------------------------------------------------------------------
-# Configuration::additions related to the search engine   
-#---------------------------------------------------------------------------
-
-# The SEARCHENGINE tag specifies whether or not a search engine should be 
-# used. If set to NO the values of all tags below this one will be ignored.
-
-SEARCHENGINE           = YES

Modified: trunk/doc/Doxyfile2
===================================================================
--- trunk/doc/Doxyfile2	2007-11-28 15:36:09 UTC (rev 8314)
+++ trunk/doc/Doxyfile2	2007-11-28 15:59:06 UTC (rev 8315)
@@ -1,199 +1,1047 @@
-# Doxyfile 1.4.4
+# Doxyfile 1.5.1-20070315
 
+# This file describes the settings to be used by the documentation system
+# doxygen (www.doxygen.org) for a project
+#
+# All text after a hash (#) is considered a comment and will be ignored
+# The format is:
+#       TAG = value [value, ...]
+# For lists items can also be appended using:
+#       TAG += value [value, ...]
+# Values that contain spaces should be placed between quotes (" ")
+
 #---------------------------------------------------------------------------
 # Project related configuration options
 #---------------------------------------------------------------------------
+
+# This tag specifies the encoding used for all characters in the config file that 
+# follow. The default is UTF-8 which is also the encoding used for all text before 
+# the first occurrence of this tag. Doxygen uses libiconv (or the iconv built into 
+# libc) for the transcoding. See http://www.gnu.org/software/libiconv for the list of 
+# possible encodings.
+
+DOXYFILE_ENCODING      = UTF-8
+
+# The PROJECT_NAME tag is a single word (or a sequence of words surrounded 
+# by quotes) that should identify the project.
+
 PROJECT_NAME           = PLearn
+
+# The PROJECT_NUMBER tag can be used to enter a project or revision number. 
+# This could be handy for archiving the generated documentation or 
+# if some version control system is used.
+
 PROJECT_NUMBER         = 0.1
-OUTPUT_DIRECTORY       = LibraryReference-No-Dot
-CREATE_SUBDIRS         = NO
+
+# The OUTPUT_DIRECTORY tag is used to specify the (relative or absolute) 
+# base path where the generated documentation will be put. 
+# If a relative path is entered, it will be relative to the location 
+# where doxygen was started. If left blank the current directory will be used.
+
+OUTPUT_DIRECTORY       = LibraryReference.joseph
+
+# If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
+# 4096 sub-directories (in 2 levels) under the output directory of each output 
+# format and will distribute the generated files over these directories. 
+# Enabling this option can be useful when feeding doxygen a huge amount of 
+# source files, where putting all generated files in the same directory would 
+# otherwise cause performance problems for the file system.
+
+CREATE_SUBDIRS         = YES
+
+# The OUTPUT_LANGUAGE tag is used to specify the language in which all 
+# documentation generated by doxygen is written. Doxygen will use this 
+# information to generate all constant output in the proper language. 
+# The default language is English, other supported languages are: 
+# Afrikaans, Arabic, Brazilian, Catalan, Chinese, Chinese-Traditional, 
+# Croatian, Czech, Danish, Dutch, Finnish, French, German, Greek, Hungarian, 
+# Italian, Japanese, Japanese-en (Japanese with English messages), Korean, 
+# Korean-en, Lithuanian, Norwegian, Polish, Portuguese, Romanian, Russian, 
+# Serbian, Slovak, Slovene, Spanish, Swedish, and Ukrainian.
+
 OUTPUT_LANGUAGE        = English
-USE_WINDOWS_ENCODING   = NO
+
+# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will 
+# include brief member descriptions after the members that are listed in 
+# the file and class documentation (similar to JavaDoc). 
+# Set to NO to disable this.
+
 BRIEF_MEMBER_DESC      = YES
+
+# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend 
+# the brief description of a member or function before the detailed description. 
+# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the 
+# brief descriptions will be completely suppressed.
+
 REPEAT_BRIEF           = YES
-ABBREVIATE_BRIEF       = "The $name class" \
-                         "The $name widget" \
-                         "The $name file" \
-                         is \
-                         provides \
-                         specifies \
-                         contains \
-                         represents \
-                         a \
-                         an \
-                         the
+
+# This tag implements a quasi-intelligent brief description abbreviator 
+# that is used to form the text in various listings. Each string 
+# in this list, if found as the leading text of the brief description, will be 
+# stripped from the text and the result after processing the whole list, is 
+# used as the annotated text. Otherwise, the brief description is used as-is. 
+# If left blank, the following values are used ("$name" is automatically 
+# replaced with the name of the entity): "The $name class" "The $name widget" 
+# "The $name file" "is" "provides" "specifies" "contains" 
+# "represents" "a" "an" "the"
+
+ABBREVIATE_BRIEF       = 
+
+# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then 
+# Doxygen will generate a detailed section even if there is only a brief 
+# description.
+
 ALWAYS_DETAILED_SEC    = NO
+
+# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all 
+# inherited members of a class in the documentation of that class as if those 
+# members were ordinary class members. Constructors, destructors and assignment 
+# operators of the base classes will not be shown.
+
 INLINE_INHERITED_MEMB  = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full 
+# path before files name in the file list and in the header files. If set 
+# to NO the shortest path that makes the file name unique will be used.
+
 FULL_PATH_NAMES        = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag 
+# can be used to strip a user-defined part of the path. Stripping is 
+# only done if one of the specified strings matches the left-hand part of 
+# the path. The tag can be used to show relative paths in the file list. 
+# If left blank the directory from which doxygen is run is used as the 
+# path to strip.
+
 STRIP_FROM_PATH        = 
+
+# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of 
+# the path mentioned in the documentation of a class, which tells 
+# the reader which header file to include in order to use a class. 
+# If left blank only the name of the header file containing the class 
+# definition is used. Otherwise one should specify the include paths that 
+# are normally passed to the compiler using the -I flag.
+
 STRIP_FROM_INC_PATH    = 
+
+# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter 
+# (but less readable) file names. This can be useful is your file systems 
+# doesn't support long names like on DOS, Mac, or CD-ROM.
+
 SHORT_NAMES            = NO
+
+# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen 
+# will interpret the first line (until the first dot) of a JavaDoc-style 
+# comment as the brief description. If set to NO, the JavaDoc 
+# comments will behave just like the Qt-style comments (thus requiring an 
+# explicit @brief command for a brief description.
+
 JAVADOC_AUTOBRIEF      = YES
+
+# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make Doxygen 
+# treat a multi-line C++ special comment block (i.e. a block of //! or /// 
+# comments) as a brief description. This used to be the default behaviour. 
+# The new default is to treat a multi-line C++ comment block as a detailed 
+# description. Set this tag to YES if you prefer the old behaviour instead.
+
 MULTILINE_CPP_IS_BRIEF = NO
+
+# If the DETAILS_AT_TOP tag is set to YES then Doxygen 
+# will output the detailed description near the top, like JavaDoc.
+# If set to NO, the detailed description appears after the member 
+# documentation.
+
 DETAILS_AT_TOP         = NO
+
+# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented 
+# member inherits the documentation from any documented member that it 
+# re-implements.
+
 INHERIT_DOCS           = YES
-DISTRIBUTE_GROUP_DOC   = NO
+
+# If the SEPARATE_MEMBER_PAGES tag is set to YES, then doxygen will produce 
+# a new page for each member. If set to NO, the documentation of a member will 
+# be part of the file/class/namespace that contains it.
+
 SEPARATE_MEMBER_PAGES  = NO
+
+# The TAB_SIZE tag can be used to set the number of spaces in a tab. 
+# Doxygen uses this value to replace tabs by spaces in code fragments.
+
 TAB_SIZE               = 8
+
+# This tag can be used to specify a number of aliases that acts 
+# as commands in the documentation. An alias has the form "name=value". 
+# For example adding "sideeffect=\par Side Effects:\n" will allow you to 
+# put the command \sideeffect (or @sideeffect) in the documentation, which 
+# will result in a user-defined paragraph with heading "Side Effects:". 
+# You can put \n's in the value part of an alias to insert newlines.
+
 ALIASES                = 
+
+# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C 
+# sources only. Doxygen will then generate output that is more tailored for C. 
+# For instance, some of the names that are used will be different. The list 
+# of all members will be omitted, etc.
+
 OPTIMIZE_OUTPUT_FOR_C  = NO
+
+# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java 
+# sources only. Doxygen will then generate output that is more tailored for Java. 
+# For instance, namespaces will be presented as packages, qualified scopes 
+# will look different, etc.
+
 OPTIMIZE_OUTPUT_JAVA   = NO
+
+# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want to 
+# include (a tag file for) the STL sources as input, then you should 
+# set this tag to YES in order to let doxygen match functions declarations and 
+# definitions whose arguments contain STL classes (e.g. func(std::string); v.s. 
+# func(std::string) {}). This also make the inheritance and collaboration 
+# diagrams that involve STL classes more complete and accurate.
+
+BUILTIN_STL_SUPPORT    = YES
+
+# If you use Microsoft's C++/CLI language, you should set this option to YES to
+# enable parsing support.
+
+CPP_CLI_SUPPORT        = NO
+
+# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC 
+# tag is set to YES, then doxygen will reuse the documentation of the first 
+# member in the group (if any) for the other members of the group. By default 
+# all members of a group must be documented explicitly.
+
+DISTRIBUTE_GROUP_DOC   = NO
+
+# Set the SUBGROUPING tag to YES (the default) to allow class member groups of 
+# the same type (for instance a group of public functions) to be put as a 
+# subgroup of that type (e.g. under the Public Functions section). Set it to 
+# NO to prevent subgrouping. Alternatively, this can be done per class using 
+# the \nosubgrouping command.
+
 SUBGROUPING            = YES
+
 #---------------------------------------------------------------------------
 # Build related configuration options
 #---------------------------------------------------------------------------
+
+# If the EXTRACT_ALL tag is set to YES doxygen will assume all entities in 
+# documentation are documented, even if no documentation was available. 
+# Private class members and static file members will be hidden unless 
+# the EXTRACT_PRIVATE and EXTRACT_STATIC tags are set to YES
+
 EXTRACT_ALL            = YES
+
+# If the EXTRACT_PRIVATE tag is set to YES all private members of a class 
+# will be included in the documentation.
+
 EXTRACT_PRIVATE        = YES
+
+# If the EXTRACT_STATIC tag is set to YES all static members of a file 
+# will be included in the documentation.
+
 EXTRACT_STATIC         = YES
+
+# If the EXTRACT_LOCAL_CLASSES tag is set to YES classes (and structs) 
+# defined locally in source files will be included in the documentation. 
+# If set to NO only classes defined in header files are included.
+
 EXTRACT_LOCAL_CLASSES  = YES
-EXTRACT_LOCAL_METHODS  = YES
+
+# This flag is only useful for Objective-C code. When set to YES local 
+# methods, which are defined in the implementation section but not in 
+# the interface are included in the documentation. 
+# If set to NO (the default) only methods in the interface are included.
+
+EXTRACT_LOCAL_METHODS  = NO
+
+# If the HIDE_UNDOC_MEMBERS tag is set to YES, Doxygen will hide all 
+# undocumented members of documented classes, files or namespaces. 
+# If set to NO (the default) these members will be included in the 
+# various overviews, but no documentation section is generated. 
+# This option has no effect if EXTRACT_ALL is enabled.
+
 HIDE_UNDOC_MEMBERS     = NO
+
+# If the HIDE_UNDOC_CLASSES tag is set to YES, Doxygen will hide all 
+# undocumented classes that are normally visible in the class hierarchy. 
+# If set to NO (the default) these classes will be included in the various 
+# overviews. This option has no effect if EXTRACT_ALL is enabled.
+
 HIDE_UNDOC_CLASSES     = NO
+
+# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, Doxygen will hide all 
+# friend (class|struct|union) declarations. 
+# If set to NO (the default) these declarations will be included in the 
+# documentation.
+
 HIDE_FRIEND_COMPOUNDS  = NO
+
+# If the HIDE_IN_BODY_DOCS tag is set to YES, Doxygen will hide any 
+# documentation blocks found inside the body of a function. 
+# If set to NO (the default) these blocks will be appended to the 
+# function's detailed documentation block.
+
 HIDE_IN_BODY_DOCS      = NO
+
+# The INTERNAL_DOCS tag determines if documentation 
+# that is typed after a \internal command is included. If the tag is set 
+# to NO (the default) then the documentation will be excluded. 
+# Set it to YES to include the internal documentation.
+
 INTERNAL_DOCS          = NO
+
+# If the CASE_SENSE_NAMES tag is set to NO then Doxygen will only generate 
+# file names in lower-case letters. If set to YES upper-case letters are also 
+# allowed. This is useful if you have classes or files whose names only differ 
+# in case and if your file system supports case sensitive file names. Windows 
+# and Mac users are advised to set this option to NO.
+
 CASE_SENSE_NAMES       = YES
+
+# If the HIDE_SCOPE_NAMES tag is set to NO (the default) then Doxygen 
+# will show members with their full class and namespace scopes in the 
+# documentation. If set to YES the scope will be hidden.
+
 HIDE_SCOPE_NAMES       = NO
+
+# If the SHOW_INCLUDE_FILES tag is set to YES (the default) then Doxygen 
+# will put a list of the files that are included by a file in the documentation 
+# of that file.
+
 SHOW_INCLUDE_FILES     = YES
+
+# If the INLINE_INFO tag is set to YES (the default) then a tag [inline] 
+# is inserted in the documentation for inline members.
+
 INLINE_INFO            = YES
+
+# If the SORT_MEMBER_DOCS tag is set to YES (the default) then doxygen 
+# will sort the (detailed) documentation of file and class members 
+# alphabetically by member name. If set to NO the members will appear in 
+# declaration order.
+
 SORT_MEMBER_DOCS       = YES
+
+# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the 
+# brief documentation of file, namespace and class members alphabetically 
+# by member name. If set to NO (the default) the members will appear in 
+# declaration order.
+
 SORT_BRIEF_DOCS        = NO
+
+# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be 
+# sorted by fully-qualified names, including namespaces. If set to 
+# NO (the default), the class list will be sorted only by class name, 
+# not including the namespace part. 
+# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES.
+# Note: This option applies only to the class list, not to the 
+# alphabetical list.
+
 SORT_BY_SCOPE_NAME     = NO
+
+# The GENERATE_TODOLIST tag can be used to enable (YES) or 
+# disable (NO) the todo list. This list is created by putting \todo 
+# commands in the documentation.
+
 GENERATE_TODOLIST      = YES
+
+# The GENERATE_TESTLIST tag can be used to enable (YES) or 
+# disable (NO) the test list. This list is created by putting \test 
+# commands in the documentation.
+
 GENERATE_TESTLIST      = YES
+
+# The GENERATE_BUGLIST tag can be used to enable (YES) or 
+# disable (NO) the bug list. This list is created by putting \bug 
+# commands in the documentation.
+
 GENERATE_BUGLIST       = YES
+
+# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or 
+# disable (NO) the deprecated list. This list is created by putting 
+# \deprecated commands in the documentation.
+
 GENERATE_DEPRECATEDLIST= YES
+
+# The ENABLED_SECTIONS tag can be used to enable conditional 
+# documentation sections, marked by \if sectionname ... \endif.
+
 ENABLED_SECTIONS       = 
+
+# The MAX_INITIALIZER_LINES tag determines the maximum number of lines 
+# the initial value of a variable or define consists of for it to appear in 
+# the documentation. If the initializer consists of more lines than specified 
+# here it will be hidden. Use a value of 0 to hide initializers completely. 
+# The appearance of the initializer of individual variables and defines in the 
+# documentation can be controlled using \showinitializer or \hideinitializer 
+# command in the documentation regardless of this setting.
+
 MAX_INITIALIZER_LINES  = 30
+
+# Set the SHOW_USED_FILES tag to NO to disable the list of files generated 
+# at the bottom of the documentation of classes and structs. If set to YES the 
+# list will mention the files that were used to generate the documentation.
+
 SHOW_USED_FILES        = YES
+
+# If the sources in your project are distributed over multiple directories 
+# then setting the SHOW_DIRECTORIES tag to YES will show the directory hierarchy 
+# in the documentation. The default is NO.
+
 SHOW_DIRECTORIES       = YES
+
+# The FILE_VERSION_FILTER tag can be used to specify a program or script that 
+# doxygen should invoke to get the current version for each file (typically from the 
+# version control system). Doxygen will invoke the program by executing (via 
+# popen()) the command <command> <input-file>, where <command> is the value of 
+# the FILE_VERSION_FILTER tag, and <input-file> is the name of an input file 
+# provided by doxygen. Whatever the program writes to standard output 
+# is used as the file version. See the manual for examples.
+
 FILE_VERSION_FILTER    = 
+
 #---------------------------------------------------------------------------
 # configuration options related to warning and progress messages
 #---------------------------------------------------------------------------
+
+# The QUIET tag can be used to turn on/off the messages that are generated 
+# by doxygen. Possible values are YES and NO. If left blank NO is used.
+
 QUIET                  = NO
+
+# The WARNINGS tag can be used to turn on/off the warning messages that are 
+# generated by doxygen. Possible values are YES and NO. If left blank 
+# NO is used.
+
 WARNINGS               = YES
+
+# If WARN_IF_UNDOCUMENTED is set to YES, then doxygen will generate warnings 
+# for undocumented members. If EXTRACT_ALL is set to YES then this flag will 
+# automatically be disabled.
+
 WARN_IF_UNDOCUMENTED   = NO
+
+# If WARN_IF_DOC_ERROR is set to YES, doxygen will generate warnings for 
+# potential errors in the documentation, such as not documenting some 
+# parameters in a documented function, or documenting parameters that 
+# don't exist or using markup commands wrongly.
+
 WARN_IF_DOC_ERROR      = YES
+
+# This WARN_NO_PARAMDOC option can be abled to get warnings for 
+# functions that are documented, but have no documentation for their parameters 
+# or return value. If set to NO (the default) doxygen will only warn about 
+# wrong or incomplete parameter documentation, but not about the absence of 
+# documentation.
+
 WARN_NO_PARAMDOC       = NO
+
+# The WARN_FORMAT tag determines the format of the warning messages that 
+# doxygen can produce. The string should contain the $file, $line, and $text 
+# tags, which will be replaced by the file and line number from which the 
+# warning originated and the warning text. Optionally the format may contain 
+# $version, which will be replaced by the version of the file (if it could 
+# be obtained via FILE_VERSION_FILTER)
+
 WARN_FORMAT            = 
+
+# The WARN_LOGFILE tag can be used to specify a file to which warning 
+# and error messages should be written. If left blank the output is written 
+# to stderr.
+
 WARN_LOGFILE           = 
+
 #---------------------------------------------------------------------------
 # configuration options related to the input files
 #---------------------------------------------------------------------------
+
+# The INPUT tag can be used to specify the files and/or directories that contain 
+# documented source files. You may enter file names like "myfile.cpp" or 
+# directories like "/usr/src/myproject". Separate the files or directories 
+# with spaces.
+
 INPUT                  = ../plearn \
                          ../plearn_learners \
                          ../plearn_learners_experimental \
                          ../commands
+
+# This tag can be used to specify the character encoding of the source files that 
+# doxygen parses. Internally doxygen uses the UTF-8 encoding, which is also the default 
+# input encoding. Doxygen uses libiconv (or the iconv built into libc) for the transcoding. 
+# See http://www.gnu.org/software/libiconv for the list of possible encodings.
+
+INPUT_ENCODING         = UTF-8
+
+# If the value of the INPUT tag contains directories, you can use the 
+# FILE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
+# and *.h) to filter out the source-files in the directories. If left 
+# blank the following patterns are tested: 
+# *.c *.cc *.cxx *.cpp *.c++ *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh *.hxx 
+# *.hpp *.h++ *.idl *.odl *.cs *.php *.php3 *.inc *.m *.mm *.py
+
 FILE_PATTERNS          = *.cc \
                          *.h
+
+# The RECURSIVE tag can be used to turn specify whether or not subdirectories 
+# should be searched for input files as well. Possible values are YES and NO. 
+# If left blank NO is used.
+
 RECURSIVE              = YES
+
+# The EXCLUDE tag can be used to specify files and/or directories that should 
+# excluded from the INPUT source files. This way you can easily exclude a 
+# subdirectory from a directory tree whose root is specified with the INPUT tag.
+
 EXCLUDE                = 
+
+# The EXCLUDE_SYMLINKS tag can be used select whether or not files or 
+# directories that are symbolic links (a Unix filesystem feature) are excluded 
+# from the input.
+
 EXCLUDE_SYMLINKS       = NO
-EXCLUDE_PATTERNS       = OBJS .svn .pytest
+
+# If the value of the INPUT tag contains directories, you can use the 
+# EXCLUDE_PATTERNS tag to specify one or more wildcard patterns to exclude 
+# certain files from those directories. Note that the wildcards are matched 
+# against the file with absolute path, so to exclude all test directories 
+# for example use the pattern */test/*
+
+EXCLUDE_PATTERNS       = OBJS \
+                         .svn \
+                         .pytest
+
+# The EXCLUDE_SYMBOLS tag can be used to specify one or more symbol names 
+# (namespaces, classes, functions, etc.) that should be excluded from the output. 
+# The symbol name can be a fully qualified name, a word, or if the wildcard * is used, 
+# a substring. Examples: ANamespace, AClass, AClass::ANamespace, ANamespace::*Test
+
+EXCLUDE_SYMBOLS        = 
+
+# The EXAMPLE_PATH tag can be used to specify one or more files or 
+# directories that contain example code fragments that are included (see 
+# the \include command).
+
 EXAMPLE_PATH           = 
+
+# If the value of the EXAMPLE_PATH tag contains directories, you can use the 
+# EXAMPLE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
+# and *.h) to filter out the source-files in the directories. If left 
+# blank all files are included.
+
 EXAMPLE_PATTERNS       = 
+
+# If the EXAMPLE_RECURSIVE tag is set to YES then subdirectories will be 
+# searched for input files to be used with the \include or \dontinclude 
+# commands irrespective of the value of the RECURSIVE tag. 
+# Possible values are YES and NO. If left blank NO is used.
+
 EXAMPLE_RECURSIVE      = NO
+
+# The IMAGE_PATH tag can be used to specify one or more files or 
+# directories that contain image that are included in the documentation (see 
+# the \image command).
+
 IMAGE_PATH             = 
+
+# The INPUT_FILTER tag can be used to specify a program that doxygen should 
+# invoke to filter for each input file. Doxygen will invoke the filter program 
+# by executing (via popen()) the command <filter> <input-file>, where <filter> 
+# is the value of the INPUT_FILTER tag, and <input-file> is the name of an 
+# input file. Doxygen will then use the output that the filter program writes 
+# to standard output.  If FILTER_PATTERNS is specified, this tag will be 
+# ignored.
+
 INPUT_FILTER           = 
+
+# The FILTER_PATTERNS tag can be used to specify filters on a per file pattern 
+# basis.  Doxygen will compare the file name with each pattern and apply the 
+# filter if there is a match.  The filters are a list of the form: 
+# pattern=filter (like *.cpp=my_cpp_filter). See INPUT_FILTER for further 
+# info on how filters are used. If FILTER_PATTERNS is empty, INPUT_FILTER 
+# is applied to all files.
+
 FILTER_PATTERNS        = 
+
+# If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using 
+# INPUT_FILTER) will be used to filter the input files when producing source 
+# files to browse (i.e. when SOURCE_BROWSER is set to YES).
+
 FILTER_SOURCE_FILES    = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to source browsing
 #---------------------------------------------------------------------------
+
+# If the SOURCE_BROWSER tag is set to YES then a list of source files will 
+# be generated. Documented entities will be cross-referenced with these sources. 
+# Note: To get rid of all source code in the generated output, make sure also 
+# VERBATIM_HEADERS is set to NO.
+
 SOURCE_BROWSER         = YES
-INLINE_SOURCES         = NO
+
+# Setting the INLINE_SOURCES tag to YES will include the body 
+# of functions and classes directly in the documentation.
+
+INLINE_SOURCES         = YES
+
+# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct 
+# doxygen to hide any special comment blocks from generated source code 
+# fragments. Normal C and C++ comments will always remain visible.
+
 STRIP_CODE_COMMENTS    = YES
+
+# If the REFERENCED_BY_RELATION tag is set to YES (the default) 
+# then for each documented function all documented 
+# functions referencing it will be listed.
+
 REFERENCED_BY_RELATION = YES
+
+# If the REFERENCES_RELATION tag is set to YES (the default) 
+# then for each documented function all documented entities 
+# called/used by that function will be listed.
+
 REFERENCES_RELATION    = YES
+
+# If the REFERENCES_LINK_SOURCE tag is set to YES (the default)
+# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from
+# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will
+# link to the source code.  Otherwise they will link to the documentstion.
+
+REFERENCES_LINK_SOURCE = YES
+
+# If the USE_HTAGS tag is set to YES then the references to source code 
+# will point to the HTML generated by the htags(1) tool instead of doxygen 
+# built-in source browser. The htags tool is part of GNU's global source 
+# tagging system (see http://www.gnu.org/software/global/global.html). You 
+# will need version 4.8.6 or higher.
+
 USE_HTAGS              = NO
+
+# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen 
+# will generate a verbatim copy of the header file for each class for 
+# which an include is specified. Set to NO to disable this.
+
 VERBATIM_HEADERS       = YES
+
 #---------------------------------------------------------------------------
 # configuration options related to the alphabetical class index
 #---------------------------------------------------------------------------
+
+# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index 
+# of all compounds will be generated. Enable this if the project 
+# contains a lot of classes, structs, unions or interfaces.
+
 ALPHABETICAL_INDEX     = YES
+
+# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then 
+# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns 
+# in which this list will be split (can be a number in the range [1..20])
+
 COLS_IN_ALPHA_INDEX    = 5
+
+# In case all classes in a project start with a common prefix, all 
+# classes will be put under the same header in the alphabetical index. 
+# The IGNORE_PREFIX tag can be used to specify one or more prefixes that 
+# should be ignored while generating the index headers.
+
 IGNORE_PREFIX          = 
+
 #---------------------------------------------------------------------------
 # configuration options related to the HTML output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_HTML tag is set to YES (the default) Doxygen will 
+# generate HTML output.
+
 GENERATE_HTML          = YES
+
+# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `html' will be used as the default path.
+
 HTML_OUTPUT            = 
+
+# The HTML_FILE_EXTENSION tag can be used to specify the file extension for 
+# each generated HTML page (for example: .htm,.php,.asp). If it is left blank 
+# doxygen will generate files with .html extension.
+
 HTML_FILE_EXTENSION    = .html
+
+# The HTML_HEADER tag can be used to specify a personal HTML header for 
+# each generated HTML page. If it is left blank doxygen will generate a 
+# standard header.
+
 HTML_HEADER            = 
+
+# The HTML_FOOTER tag can be used to specify a personal HTML footer for 
+# each generated HTML page. If it is left blank doxygen will generate a 
+# standard footer.
+
 HTML_FOOTER            = 
+
+# The HTML_STYLESHEET tag can be used to specify a user-defined cascading 
+# style sheet that is used by each HTML page. It can be used to 
+# fine-tune the look of the HTML output. If the tag is left blank doxygen 
+# will generate a default style sheet. Note that doxygen will try to copy 
+# the style sheet file to the HTML output directory, so don't put your own 
+# stylesheet in the HTML output directory as well, or it will be erased!
+
 HTML_STYLESHEET        = 
+
+# If the HTML_ALIGN_MEMBERS tag is set to YES, the members of classes, 
+# files or namespaces will be aligned in HTML using tables. If set to 
+# NO a bullet list will be used.
+
 HTML_ALIGN_MEMBERS     = YES
+
+# If the GENERATE_HTMLHELP tag is set to YES, additional index files 
+# will be generated that can be used as input for tools like the 
+# Microsoft HTML help workshop to generate a compressed HTML help file (.chm) 
+# of the generated HTML documentation.
+
 GENERATE_HTMLHELP      = NO
+
+# If the GENERATE_HTMLHELP tag is set to YES, the CHM_FILE tag can 
+# be used to specify the file name of the resulting .chm file. You 
+# can add a path in front of the file if the result should not be 
+# written to the html output directory.
+
 CHM_FILE               = 
+
+# If the GENERATE_HTMLHELP tag is set to YES, the HHC_LOCATION tag can 
+# be used to specify the location (absolute path including file name) of 
+# the HTML help compiler (hhc.exe). If non-empty doxygen will try to run 
+# the HTML help compiler on the generated index.hhp.
+
 HHC_LOCATION           = 
+
+# If the GENERATE_HTMLHELP tag is set to YES, the GENERATE_CHI flag 
+# controls if a separate .chi index file is generated (YES) or that 
+# it should be included in the master .chm file (NO).
+
 GENERATE_CHI           = NO
+
+# If the GENERATE_HTMLHELP tag is set to YES, the BINARY_TOC flag 
+# controls whether a binary table of contents is generated (YES) or a 
+# normal table of contents (NO) in the .chm file.
+
 BINARY_TOC             = NO
+
+# The TOC_EXPAND flag can be set to YES to add extra items for group members 
+# to the contents of the HTML help documentation and to the tree view.
+
 TOC_EXPAND             = NO
+
+# The DISABLE_INDEX tag can be used to turn on/off the condensed index at 
+# top of each HTML page. The value NO (the default) enables the index and 
+# the value YES disables it.
+
 DISABLE_INDEX          = NO
+
+# This tag can be used to set the number of enum values (range [1..20]) 
+# that doxygen will group on one line in the generated HTML documentation.
+
 ENUM_VALUES_PER_LINE   = 4
+
+# If the GENERATE_TREEVIEW tag is set to YES, a side panel will be
+# generated containing a tree-like index structure (just like the one that 
+# is generated for HTML Help). For this to work a browser that supports 
+# JavaScript, DHTML, CSS and frames is required (for instance Mozilla 1.0+, 
+# Netscape 6.0+, Internet explorer 5.0+, or Konqueror). Windows users are 
+# probably better off using the HTML help feature.
+
 GENERATE_TREEVIEW      = NO
+
+# If the treeview is enabled (see GENERATE_TREEVIEW) then this tag can be 
+# used to set the initial width (in pixels) of the frame in which the tree 
+# is shown.
+
 TREEVIEW_WIDTH         = 250
+
 #---------------------------------------------------------------------------
 # configuration options related to the LaTeX output
 #---------------------------------------------------------------------------
-GENERATE_LATEX         = NO
+
+# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will 
+# generate Latex output.
+
+GENERATE_LATEX         = YES
+
+# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `latex' will be used as the default path.
+
 LATEX_OUTPUT           = 
+
+# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be 
+# invoked. If left blank `latex' will be used as the default command name.
+
 LATEX_CMD_NAME         = latex
+
+# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to 
+# generate index for LaTeX. If left blank `makeindex' will be used as the 
+# default command name.
+
 MAKEINDEX_CMD_NAME     = makeindex
+
+# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact 
+# LaTeX documents. This may be useful for small projects and may help to 
+# save some trees in general.
+
 COMPACT_LATEX          = NO
-PAPER_TYPE             = a4wide
+
+# The PAPER_TYPE tag can be used to set the paper type that is used 
+# by the printer. Possible values are: a4, a4wide, letter, legal and 
+# executive. If left blank a4wide will be used.
+
+PAPER_TYPE             = letter
+
+# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX 
+# packages that should be included in the LaTeX output.
+
 EXTRA_PACKAGES         = 
+
+# The LATEX_HEADER tag can be used to specify a personal LaTeX header for 
+# the generated latex document. The header should contain everything until 
+# the first chapter. If it is left blank doxygen will generate a 
+# standard header. Notice: only use this tag if you know what you are doing!
+
 LATEX_HEADER           = 
-PDF_HYPERLINKS         = NO
-USE_PDFLATEX           = NO
-LATEX_BATCHMODE        = NO
+
+# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated 
+# is prepared for conversion to pdf (using ps2pdf). The pdf file will 
+# contain links (just like the HTML output) instead of page references 
+# This makes the output suitable for online browsing using a pdf viewer.
+
+PDF_HYPERLINKS         = YES
+
+# If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of 
+# plain latex in the generated Makefile. Set this option to YES to get a 
+# higher quality PDF documentation.
+
+USE_PDFLATEX           = YeS
+
+# If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\batchmode. 
+# command to the generated LaTeX files. This will instruct LaTeX to keep 
+# running if errors occur, instead of asking the user for help. 
+# This option is also used when generating formulas in HTML.
+
+LATEX_BATCHMODE        = YES
+
+# If LATEX_HIDE_INDICES is set to YES then doxygen will not 
+# include the index chapters (such as File Index, Compound Index, etc.) 
+# in the output.
+
 LATEX_HIDE_INDICES     = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to the RTF output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_RTF tag is set to YES Doxygen will generate RTF output 
+# The RTF output is optimized for Word 97 and may not look very pretty with 
+# other RTF readers or editors.
+
 GENERATE_RTF           = NO
+
+# The RTF_OUTPUT tag is used to specify where the RTF docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `rtf' will be used as the default path.
+
 RTF_OUTPUT             = 
+
+# If the COMPACT_RTF tag is set to YES Doxygen generates more compact 
+# RTF documents. This may be useful for small projects and may help to 
+# save some trees in general.
+
 COMPACT_RTF            = NO
+
+# If the RTF_HYPERLINKS tag is set to YES, the RTF that is generated 
+# will contain hyperlink fields. The RTF file will 
+# contain links (just like the HTML output) instead of page references. 
+# This makes the output suitable for online browsing using WORD or other 
+# programs which support those fields. 
+# Note: wordpad (write) and others do not support links.
+
 RTF_HYPERLINKS         = NO
+
+# Load stylesheet definitions from file. Syntax is similar to doxygen's 
+# config file, i.e. a series of assignments. You only have to provide 
+# replacements, missing definitions are set to their default value.
+
 RTF_STYLESHEET_FILE    = 
+
+# Set optional variables used in the generation of an rtf document. 
+# Syntax is similar to doxygen's config file.
+
 RTF_EXTENSIONS_FILE    = 
+
 #---------------------------------------------------------------------------
 # configuration options related to the man page output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_MAN tag is set to YES (the default) Doxygen will 
+# generate man pages
+
 GENERATE_MAN           = NO
+
+# The MAN_OUTPUT tag is used to specify where the man pages will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `man' will be used as the default path.
+
 MAN_OUTPUT             = 
+
+# The MAN_EXTENSION tag determines the extension that is added to 
+# the generated man pages (default is the subroutine's section .3)
+
 MAN_EXTENSION          = 
+
+# If the MAN_LINKS tag is set to YES and Doxygen generates man output, 
+# then it will generate one additional man file for each entity 
+# documented in the real man page(s). These additional files 
+# only source the real man page, but without them the man command 
+# would be unable to find the correct page. The default is NO.
+
 MAN_LINKS              = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to the XML output
 #---------------------------------------------------------------------------
-GENERATE_XML           = NO
+
+# If the GENERATE_XML tag is set to YES Doxygen will 
+# generate an XML file that captures the structure of 
+# the code including all documentation.
+
+GENERATE_XML           = YES
+
+# The XML_OUTPUT tag is used to specify where the XML pages will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `xml' will be used as the default path.
+
 XML_OUTPUT             = xml
+
+# The XML_SCHEMA tag can be used to specify an XML schema, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
 XML_SCHEMA             = 
+
+# The XML_DTD tag can be used to specify an XML DTD, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
 XML_DTD                = 
+
+# If the XML_PROGRAMLISTING tag is set to YES Doxygen will 
+# dump the program listings (including syntax highlighting 
+# and cross-referencing information) to the XML output. Note that 
+# enabling this will significantly increase the size of the XML output.
+
 XML_PROGRAMLISTING     = YES
+
 #---------------------------------------------------------------------------
 # configuration options for the AutoGen Definitions output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_AUTOGEN_DEF tag is set to YES Doxygen will 
+# generate an AutoGen Definitions (see autogen.sf.net) file 
+# that captures the structure of the code including all 
+# documentation. Note that this feature is still experimental 
+# and incomplete at the moment.
+
 GENERATE_AUTOGEN_DEF   = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to the Perl module output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_PERLMOD tag is set to YES Doxygen will 
+# generate a Perl module file that captures the structure of 
+# the code including all documentation. Note that this 
+# feature is still experimental and incomplete at the 
+# moment.
+
 GENERATE_PERLMOD       = NO
+
+# If the PERLMOD_LATEX tag is set to YES Doxygen will generate 
+# the necessary Makefile rules, Perl scripts and LaTeX code to be able 
+# to generate PDF and DVI output from the Perl module output.
+
 PERLMOD_LATEX          = NO
+
+# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be 
+# nicely formatted so it can be parsed by a human reader.  This is useful 
+# if you want to understand what is going on.  On the other hand, if this 
+# tag is set to NO the size of the Perl module output will be much smaller 
+# and Perl will parse it just the same.
+
 PERLMOD_PRETTY         = YES
+
+# The names of the make variables in the generated doxyrules.make file 
+# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX. 
+# This is useful so different doxyrules.make files included by the same 
+# Makefile don't overwrite each other's variables.
+
 PERLMOD_MAKEVAR_PREFIX = 
+
 #---------------------------------------------------------------------------
 # Configuration options related to the preprocessor   
 #---------------------------------------------------------------------------
+
+# If the ENABLE_PREPROCESSING tag is set to YES (the default) Doxygen will 
+# evaluate all C-preprocessor directives found in the sources and include 
+# files.
+
 ENABLE_PREPROCESSING   = YES
+
+# If the MACRO_EXPANSION tag is set to YES Doxygen will expand all macro 
+# names in the source code. If set to NO (the default) only conditional 
+# compilation will be performed. Macro expansion can be done in a controlled 
+# way by setting EXPAND_ONLY_PREDEF to YES.
+
 MACRO_EXPANSION        = YES
+
+# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES 
+# then the macro expansion is limited to the macros specified with the 
+# PREDEFINED and EXPAND_AS_DEFINED tags.
+
 EXPAND_ONLY_PREDEF     = YES
+
+# If the SEARCH_INCLUDES tag is set to YES (the default) the includes files 
+# in the INCLUDE_PATH (see below) will be search if a #include is found.
+
 SEARCH_INCLUDES        = YES
+
+# The INCLUDE_PATH tag can be used to specify one or more directories that 
+# contain include files that are not input files but should be processed by 
+# the preprocessor.
+
 INCLUDE_PATH           = 
+
+# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard 
+# patterns (like *.h and *.hpp) to filter out the header-files in the 
+# directories. If left blank, the patterns specified with FILE_PATTERNS will 
+# be used.
+
 INCLUDE_FILE_PATTERNS  = 
+
+# The PREDEFINED tag can be used to specify one or more macro names that 
+# are defined before the preprocessor is started (similar to the -D option of 
+# gcc). The argument of the tag is a list of macros of the form: name 
+# or name=definition (no spaces). If the definition and the = are 
+# omitted =1 is assumed. To prevent a macro definition from being 
+# undefined via #undef or recursively expanded use the := operator 
+# instead of the = operator.
+
 PREDEFINED             = 
+
+# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then 
+# this tag can be used to specify a list of macro names that should be expanded. 
+# The macro definition that is found in the sources will be used. 
+# Use the PREDEFINED tag if you want to use a different macro definition.
+
 EXPAND_AS_DEFINED      = PLEARN_DECLARE_OBJECT \
                          PLEARN_IMPLEMENT_OBJECT \
                          DECLARE_OBJECT_PTR \
@@ -204,42 +1052,221 @@
                          PLEARN_IMPLEMENT_ABSTRACT_OBJECT \
                          PLEARN_DECLARE_TEMPLATE_OBJECT \
                          PLEARN_IMPLEMENT_TEMPLATE_OBJECT
+
+# If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then 
+# doxygen's preprocessor will remove all function-like macros that are alone 
+# on a line, have an all uppercase name, and do not end with a semicolon. Such 
+# function macros are typically used for boiler-plate code, and will confuse 
+# the parser if not removed.
+
 SKIP_FUNCTION_MACROS   = YES
+
 #---------------------------------------------------------------------------
 # Configuration::additions related to external references   
 #---------------------------------------------------------------------------
+
+# The TAGFILES option can be used to specify one or more tagfiles. 
+# Optionally an initial location of the external documentation 
+# can be added for each tagfile. The format of a tag file without 
+# this location is as follows: 
+#   TAGFILES = file1 file2 ... 
+# Adding location for the tag files is done as follows: 
+#   TAGFILES = file1=loc1 "file2 = loc2" ... 
+# where "loc1" and "loc2" can be relative or absolute paths or 
+# URLs. If a location is present for each tag, the installdox tool 
+# does not have to be run to correct the links.
+# Note that each tag file must have a unique name
+# (where the name does NOT include the path)
+# If a tag file is not located in the directory in which doxygen 
+# is run, you must also specify the path to the tagfile here.
+
 TAGFILES               = 
-GENERATE_TAGFILE       = 
+
+# When a file name is specified after GENERATE_TAGFILE, doxygen will create 
+# a tag file that is based on the input files it reads.
+
+GENERATE_TAGFILE       = plearn.tag
+
+# If the ALLEXTERNALS tag is set to YES all external classes will be listed 
+# in the class index. If set to NO only the inherited external classes 
+# will be listed.
+
 ALLEXTERNALS           = NO
+
+# If the EXTERNAL_GROUPS tag is set to YES all external groups will be listed 
+# in the modules index. If set to NO, only the current project's groups will 
+# be listed.
+
 EXTERNAL_GROUPS        = YES
+
+# The PERL_PATH should be the absolute path and name of the perl script 
+# interpreter (i.e. the result of `which perl').
+
 PERL_PATH              = 
+
 #---------------------------------------------------------------------------
 # Configuration options related to the dot tool   
 #---------------------------------------------------------------------------
-CLASS_DIAGRAMS         = NO
+
+# If the CLASS_DIAGRAMS tag is set to YES (the default) Doxygen will 
+# generate a inheritance diagram (in HTML, RTF and LaTeX) for classes with base 
+# or super classes. Setting the tag to NO turns the diagrams off. Note that 
+# this option is superseded by the HAVE_DOT option below. This is only a 
+# fallback. It is recommended to install and use dot, since it yields more 
+# powerful graphs.
+
+CLASS_DIAGRAMS         = YES
+
+# You can define message sequence charts within doxygen comments using the \msc 
+# command. Doxygen will then run the mscgen tool (see http://www.mcternan.me.uk/mscgen/) to 
+# produce the chart and insert it in the documentation. The MSCGEN_PATH tag allows you to 
+# specify the directory where the mscgen tool resides. If left empty the tool is assumed to 
+# be found in the default search path.
+
+MSCGEN_PATH            = 
+
+# If set to YES, the inheritance and collaboration graphs will hide 
+# inheritance and usage relations if the target is undocumented 
+# or is not a class.
+
 HIDE_UNDOC_RELATIONS   = NO
+
+# If you set the HAVE_DOT tag to YES then doxygen will assume the dot tool is 
+# available from the path. This tool is part of Graphviz, a graph visualization 
+# toolkit from AT&T and Lucent Bell Labs. The other options in this section 
+# have no effect if this option is set to NO (the default)
+
 HAVE_DOT               = NO
+
+# If the CLASS_GRAPH and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for each documented class showing the direct and 
+# indirect inheritance relations. Setting this tag to YES will force the 
+# the CLASS_DIAGRAMS tag to NO.
+
 CLASS_GRAPH            = YES
+
+# If the COLLABORATION_GRAPH and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for each documented class showing the direct and 
+# indirect implementation dependencies (inheritance, containment, and 
+# class references variables) of the class with other documented classes.
+
 COLLABORATION_GRAPH    = YES
+
+# If the GROUP_GRAPHS and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for groups, showing the direct groups dependencies
+
 GROUP_GRAPHS           = YES
+
+# If the UML_LOOK tag is set to YES doxygen will generate inheritance and 
+# collaboration diagrams in a style similar to the OMG's Unified Modeling 
+# Language.
+
 UML_LOOK               = NO
+
+# If set to YES, the inheritance and collaboration graphs will show the 
+# relations between templates and their instances.
+
 TEMPLATE_RELATIONS     = YES
+
+# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDE_GRAPH, and HAVE_DOT 
+# tags are set to YES then doxygen will generate a graph for each documented 
+# file showing the direct and indirect include dependencies of the file with 
+# other documented files.
+
 INCLUDE_GRAPH          = YES
+
+# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDED_BY_GRAPH, and 
+# HAVE_DOT tags are set to YES then doxygen will generate a graph for each 
+# documented header file showing the documented files that directly or 
+# indirectly include this file.
+
 INCLUDED_BY_GRAPH      = YES
-CALL_GRAPH             = NO
+
+# If the CALL_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a call dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable call graphs for selected 
+# functions only using the \callgraph command.
+
+CALL_GRAPH             = YES
+
+# If the CALLER_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a caller dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable caller graphs for selected 
+# functions only using the \callergraph command.
+
+CALLER_GRAPH           = YES
+
+# If the GRAPHICAL_HIERARCHY and HAVE_DOT tags are set to YES then doxygen 
+# will graphical hierarchy of all classes instead of a textual one.
+
 GRAPHICAL_HIERARCHY    = YES
+
+# If the DIRECTORY_GRAPH, SHOW_DIRECTORIES and HAVE_DOT tags are set to YES 
+# then doxygen will show the dependencies a directory has on other directories 
+# in a graphical way. The dependency relations are determined by the #include
+# relations between the files in the directories.
+
 DIRECTORY_GRAPH        = YES
+
+# The DOT_IMAGE_FORMAT tag can be used to set the image format of the images 
+# generated by dot. Possible values are png, jpg, or gif
+# If left blank png will be used.
+
 DOT_IMAGE_FORMAT       = png
+
+# The tag DOT_PATH can be used to specify the path where the dot tool can be 
+# found. If left blank, it is assumed the dot tool can be found in the path.
+
 DOT_PATH               = 
+
+# The DOTFILE_DIRS tag can be used to specify one or more directories that 
+# contain dot files that are included in the documentation (see the 
+# \dotfile command).
+
 DOTFILE_DIRS           = 
-MAX_DOT_GRAPH_WIDTH    = 1024
-MAX_DOT_GRAPH_HEIGHT   = 1024
-MAX_DOT_GRAPH_DEPTH    = 1000
+
+# The MAX_DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of 
+# nodes that will be shown in the graph. If the number of nodes in a graph 
+# becomes larger than this value, doxygen will truncate the graph, which is 
+# visualized by representing a node as a red box. Note that doxygen will always 
+# show the root nodes and its direct children regardless of this setting.
+
+DOT_GRAPH_MAX_NODES    = 50
+
+# Set the DOT_TRANSPARENT tag to YES to generate images with a transparent 
+# background. This is disabled by default, which results in a white background. 
+# Warning: Depending on the platform used, enabling this option may lead to 
+# badly anti-aliased labels on the edges of a graph (i.e. they become hard to 
+# read).
+
 DOT_TRANSPARENT        = NO
-DOT_MULTI_TARGETS      = NO
+
+# Set the DOT_MULTI_TARGETS tag to YES allow dot to generate multiple output 
+# files in one run (i.e. multiple -o and -T options on the command line). This 
+# makes dot run faster, but since only newer versions of dot (>1.8.10) 
+# support this, this feature is disabled by default.
+
+DOT_MULTI_TARGETS      = YES
+
+# If the GENERATE_LEGEND tag is set to YES (the default) Doxygen will 
+# generate a legend page explaining the meaning of the various boxes and 
+# arrows in the dot generated graphs.
+
 GENERATE_LEGEND        = YES
+
+# If the DOT_CLEANUP tag is set to YES (the default) Doxygen will 
+# remove the intermediate dot files that are used to generate 
+# the various graphs.
+
 DOT_CLEANUP            = YES
+
 #---------------------------------------------------------------------------
 # Configuration::additions related to the search engine   
 #---------------------------------------------------------------------------
-SEARCHENGINE           = NO
+
+# The SEARCHENGINE tag specifies whether or not a search engine should be 
+# used. If set to NO the values of all tags below this one will be ignored.
+
+SEARCHENGINE           = YES

Modified: trunk/doc/Doxyfile3
===================================================================
--- trunk/doc/Doxyfile3	2007-11-28 15:36:09 UTC (rev 8314)
+++ trunk/doc/Doxyfile3	2007-11-28 15:59:06 UTC (rev 8315)
@@ -1,199 +1,1047 @@
-# Doxyfile 1.4.4
+# Doxyfile 1.5.1-20070315
 
+# This file describes the settings to be used by the documentation system
+# doxygen (www.doxygen.org) for a project
+#
+# All text after a hash (#) is considered a comment and will be ignored
+# The format is:
+#       TAG = value [value, ...]
+# For lists items can also be appended using:
+#       TAG += value [value, ...]
+# Values that contain spaces should be placed between quotes (" ")
+
 #---------------------------------------------------------------------------
 # Project related configuration options
 #---------------------------------------------------------------------------
+
+# This tag specifies the encoding used for all characters in the config file that 
+# follow. The default is UTF-8 which is also the encoding used for all text before 
+# the first occurrence of this tag. Doxygen uses libiconv (or the iconv built into 
+# libc) for the transcoding. See http://www.gnu.org/software/libiconv for the list of 
+# possible encodings.
+
+DOXYFILE_ENCODING      = UTF-8
+
+# The PROJECT_NAME tag is a single word (or a sequence of words surrounded 
+# by quotes) that should identify the project.
+
 PROJECT_NAME           = PLearn
+
+# The PROJECT_NUMBER tag can be used to enter a project or revision number. 
+# This could be handy for archiving the generated documentation or 
+# if some version control system is used.
+
 PROJECT_NUMBER         = 0.1
-OUTPUT_DIRECTORY       = LibraryReference-No-Source
-CREATE_SUBDIRS         = NO
+
+# The OUTPUT_DIRECTORY tag is used to specify the (relative or absolute) 
+# base path where the generated documentation will be put. 
+# If a relative path is entered, it will be relative to the location 
+# where doxygen was started. If left blank the current directory will be used.
+
+OUTPUT_DIRECTORY       = LibraryReference.joseph
+
+# If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
+# 4096 sub-directories (in 2 levels) under the output directory of each output 
+# format and will distribute the generated files over these directories. 
+# Enabling this option can be useful when feeding doxygen a huge amount of 
+# source files, where putting all generated files in the same directory would 
+# otherwise cause performance problems for the file system.
+
+CREATE_SUBDIRS         = YES
+
+# The OUTPUT_LANGUAGE tag is used to specify the language in which all 
+# documentation generated by doxygen is written. Doxygen will use this 
+# information to generate all constant output in the proper language. 
+# The default language is English, other supported languages are: 
+# Afrikaans, Arabic, Brazilian, Catalan, Chinese, Chinese-Traditional, 
+# Croatian, Czech, Danish, Dutch, Finnish, French, German, Greek, Hungarian, 
+# Italian, Japanese, Japanese-en (Japanese with English messages), Korean, 
+# Korean-en, Lithuanian, Norwegian, Polish, Portuguese, Romanian, Russian, 
+# Serbian, Slovak, Slovene, Spanish, Swedish, and Ukrainian.
+
 OUTPUT_LANGUAGE        = English
-USE_WINDOWS_ENCODING   = NO
+
+# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will 
+# include brief member descriptions after the members that are listed in 
+# the file and class documentation (similar to JavaDoc). 
+# Set to NO to disable this.
+
 BRIEF_MEMBER_DESC      = YES
+
+# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend 
+# the brief description of a member or function before the detailed description. 
+# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the 
+# brief descriptions will be completely suppressed.
+
 REPEAT_BRIEF           = YES
-ABBREVIATE_BRIEF       = "The $name class" \
-                         "The $name widget" \
-                         "The $name file" \
-                         is \
-                         provides \
-                         specifies \
-                         contains \
-                         represents \
-                         a \
-                         an \
-                         the
+
+# This tag implements a quasi-intelligent brief description abbreviator 
+# that is used to form the text in various listings. Each string 
+# in this list, if found as the leading text of the brief description, will be 
+# stripped from the text and the result after processing the whole list, is 
+# used as the annotated text. Otherwise, the brief description is used as-is. 
+# If left blank, the following values are used ("$name" is automatically 
+# replaced with the name of the entity): "The $name class" "The $name widget" 
+# "The $name file" "is" "provides" "specifies" "contains" 
+# "represents" "a" "an" "the"
+
+ABBREVIATE_BRIEF       = 
+
+# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then 
+# Doxygen will generate a detailed section even if there is only a brief 
+# description.
+
 ALWAYS_DETAILED_SEC    = NO
+
+# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all 
+# inherited members of a class in the documentation of that class as if those 
+# members were ordinary class members. Constructors, destructors and assignment 
+# operators of the base classes will not be shown.
+
 INLINE_INHERITED_MEMB  = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full 
+# path before files name in the file list and in the header files. If set 
+# to NO the shortest path that makes the file name unique will be used.
+
 FULL_PATH_NAMES        = NO
+
+# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag 
+# can be used to strip a user-defined part of the path. Stripping is 
+# only done if one of the specified strings matches the left-hand part of 
+# the path. The tag can be used to show relative paths in the file list. 
+# If left blank the directory from which doxygen is run is used as the 
+# path to strip.
+
 STRIP_FROM_PATH        = 
+
+# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of 
+# the path mentioned in the documentation of a class, which tells 
+# the reader which header file to include in order to use a class. 
+# If left blank only the name of the header file containing the class 
+# definition is used. Otherwise one should specify the include paths that 
+# are normally passed to the compiler using the -I flag.
+
 STRIP_FROM_INC_PATH    = 
+
+# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter 
+# (but less readable) file names. This can be useful is your file systems 
+# doesn't support long names like on DOS, Mac, or CD-ROM.
+
 SHORT_NAMES            = NO
+
+# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen 
+# will interpret the first line (until the first dot) of a JavaDoc-style 
+# comment as the brief description. If set to NO, the JavaDoc 
+# comments will behave just like the Qt-style comments (thus requiring an 
+# explicit @brief command for a brief description.
+
 JAVADOC_AUTOBRIEF      = YES
+
+# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make Doxygen 
+# treat a multi-line C++ special comment block (i.e. a block of //! or /// 
+# comments) as a brief description. This used to be the default behaviour. 
+# The new default is to treat a multi-line C++ comment block as a detailed 
+# description. Set this tag to YES if you prefer the old behaviour instead.
+
 MULTILINE_CPP_IS_BRIEF = NO
+
+# If the DETAILS_AT_TOP tag is set to YES then Doxygen 
+# will output the detailed description near the top, like JavaDoc.
+# If set to NO, the detailed description appears after the member 
+# documentation.
+
 DETAILS_AT_TOP         = NO
+
+# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented 
+# member inherits the documentation from any documented member that it 
+# re-implements.
+
 INHERIT_DOCS           = YES
-DISTRIBUTE_GROUP_DOC   = NO
+
+# If the SEPARATE_MEMBER_PAGES tag is set to YES, then doxygen will produce 
+# a new page for each member. If set to NO, the documentation of a member will 
+# be part of the file/class/namespace that contains it.
+
 SEPARATE_MEMBER_PAGES  = NO
+
+# The TAB_SIZE tag can be used to set the number of spaces in a tab. 
+# Doxygen uses this value to replace tabs by spaces in code fragments.
+
 TAB_SIZE               = 8
+
+# This tag can be used to specify a number of aliases that acts 
+# as commands in the documentation. An alias has the form "name=value". 
+# For example adding "sideeffect=\par Side Effects:\n" will allow you to 
+# put the command \sideeffect (or @sideeffect) in the documentation, which 
+# will result in a user-defined paragraph with heading "Side Effects:". 
+# You can put \n's in the value part of an alias to insert newlines.
+
 ALIASES                = 
+
+# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C 
+# sources only. Doxygen will then generate output that is more tailored for C. 
+# For instance, some of the names that are used will be different. The list 
+# of all members will be omitted, etc.
+
 OPTIMIZE_OUTPUT_FOR_C  = NO
+
+# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java 
+# sources only. Doxygen will then generate output that is more tailored for Java. 
+# For instance, namespaces will be presented as packages, qualified scopes 
+# will look different, etc.
+
 OPTIMIZE_OUTPUT_JAVA   = NO
+
+# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want to 
+# include (a tag file for) the STL sources as input, then you should 
+# set this tag to YES in order to let doxygen match functions declarations and 
+# definitions whose arguments contain STL classes (e.g. func(std::string); v.s. 
+# func(std::string) {}). This also make the inheritance and collaboration 
+# diagrams that involve STL classes more complete and accurate.
+
+BUILTIN_STL_SUPPORT    = YES
+
+# If you use Microsoft's C++/CLI language, you should set this option to YES to
+# enable parsing support.
+
+CPP_CLI_SUPPORT        = NO
+
+# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC 
+# tag is set to YES, then doxygen will reuse the documentation of the first 
+# member in the group (if any) for the other members of the group. By default 
+# all members of a group must be documented explicitly.
+
+DISTRIBUTE_GROUP_DOC   = NO
+
+# Set the SUBGROUPING tag to YES (the default) to allow class member groups of 
+# the same type (for instance a group of public functions) to be put as a 
+# subgroup of that type (e.g. under the Public Functions section). Set it to 
+# NO to prevent subgrouping. Alternatively, this can be done per class using 
+# the \nosubgrouping command.
+
 SUBGROUPING            = YES
+
 #---------------------------------------------------------------------------
 # Build related configuration options
 #---------------------------------------------------------------------------
+
+# If the EXTRACT_ALL tag is set to YES doxygen will assume all entities in 
+# documentation are documented, even if no documentation was available. 
+# Private class members and static file members will be hidden unless 
+# the EXTRACT_PRIVATE and EXTRACT_STATIC tags are set to YES
+
 EXTRACT_ALL            = YES
+
+# If the EXTRACT_PRIVATE tag is set to YES all private members of a class 
+# will be included in the documentation.
+
 EXTRACT_PRIVATE        = YES
+
+# If the EXTRACT_STATIC tag is set to YES all static members of a file 
+# will be included in the documentation.
+
 EXTRACT_STATIC         = YES
+
+# If the EXTRACT_LOCAL_CLASSES tag is set to YES classes (and structs) 
+# defined locally in source files will be included in the documentation. 
+# If set to NO only classes defined in header files are included.
+
 EXTRACT_LOCAL_CLASSES  = YES
-EXTRACT_LOCAL_METHODS  = YES
+
+# This flag is only useful for Objective-C code. When set to YES local 
+# methods, which are defined in the implementation section but not in 
+# the interface are included in the documentation. 
+# If set to NO (the default) only methods in the interface are included.
+
+EXTRACT_LOCAL_METHODS  = NO
+
+# If the HIDE_UNDOC_MEMBERS tag is set to YES, Doxygen will hide all 
+# undocumented members of documented classes, files or namespaces. 
+# If set to NO (the default) these members will be included in the 
+# various overviews, but no documentation section is generated. 
+# This option has no effect if EXTRACT_ALL is enabled.
+
 HIDE_UNDOC_MEMBERS     = NO
+
+# If the HIDE_UNDOC_CLASSES tag is set to YES, Doxygen will hide all 
+# undocumented classes that are normally visible in the class hierarchy. 
+# If set to NO (the default) these classes will be included in the various 
+# overviews. This option has no effect if EXTRACT_ALL is enabled.
+
 HIDE_UNDOC_CLASSES     = NO
+
+# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, Doxygen will hide all 
+# friend (class|struct|union) declarations. 
+# If set to NO (the default) these declarations will be included in the 
+# documentation.
+
 HIDE_FRIEND_COMPOUNDS  = NO
+
+# If the HIDE_IN_BODY_DOCS tag is set to YES, Doxygen will hide any 
+# documentation blocks found inside the body of a function. 
+# If set to NO (the default) these blocks will be appended to the 
+# function's detailed documentation block.
+
 HIDE_IN_BODY_DOCS      = NO
+
+# The INTERNAL_DOCS tag determines if documentation 
+# that is typed after a \internal command is included. If the tag is set 
+# to NO (the default) then the documentation will be excluded. 
+# Set it to YES to include the internal documentation.
+
 INTERNAL_DOCS          = NO
+
+# If the CASE_SENSE_NAMES tag is set to NO then Doxygen will only generate 
+# file names in lower-case letters. If set to YES upper-case letters are also 
+# allowed. This is useful if you have classes or files whose names only differ 
+# in case and if your file system supports case sensitive file names. Windows 
+# and Mac users are advised to set this option to NO.
+
 CASE_SENSE_NAMES       = YES
+
+# If the HIDE_SCOPE_NAMES tag is set to NO (the default) then Doxygen 
+# will show members with their full class and namespace scopes in the 
+# documentation. If set to YES the scope will be hidden.
+
 HIDE_SCOPE_NAMES       = NO
+
+# If the SHOW_INCLUDE_FILES tag is set to YES (the default) then Doxygen 
+# will put a list of the files that are included by a file in the documentation 
+# of that file.
+
 SHOW_INCLUDE_FILES     = YES
+
+# If the INLINE_INFO tag is set to YES (the default) then a tag [inline] 
+# is inserted in the documentation for inline members.
+
 INLINE_INFO            = YES
+
+# If the SORT_MEMBER_DOCS tag is set to YES (the default) then doxygen 
+# will sort the (detailed) documentation of file and class members 
+# alphabetically by member name. If set to NO the members will appear in 
+# declaration order.
+
 SORT_MEMBER_DOCS       = YES
+
+# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the 
+# brief documentation of file, namespace and class members alphabetically 
+# by member name. If set to NO (the default) the members will appear in 
+# declaration order.
+
 SORT_BRIEF_DOCS        = NO
+
+# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be 
+# sorted by fully-qualified names, including namespaces. If set to 
+# NO (the default), the class list will be sorted only by class name, 
+# not including the namespace part. 
+# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES.
+# Note: This option applies only to the class list, not to the 
+# alphabetical list.
+
 SORT_BY_SCOPE_NAME     = NO
+
+# The GENERATE_TODOLIST tag can be used to enable (YES) or 
+# disable (NO) the todo list. This list is created by putting \todo 
+# commands in the documentation.
+
 GENERATE_TODOLIST      = YES
+
+# The GENERATE_TESTLIST tag can be used to enable (YES) or 
+# disable (NO) the test list. This list is created by putting \test 
+# commands in the documentation.
+
 GENERATE_TESTLIST      = YES
+
+# The GENERATE_BUGLIST tag can be used to enable (YES) or 
+# disable (NO) the bug list. This list is created by putting \bug 
+# commands in the documentation.
+
 GENERATE_BUGLIST       = YES
+
+# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or 
+# disable (NO) the deprecated list. This list is created by putting 
+# \deprecated commands in the documentation.
+
 GENERATE_DEPRECATEDLIST= YES
+
+# The ENABLED_SECTIONS tag can be used to enable conditional 
+# documentation sections, marked by \if sectionname ... \endif.
+
 ENABLED_SECTIONS       = 
+
+# The MAX_INITIALIZER_LINES tag determines the maximum number of lines 
+# the initial value of a variable or define consists of for it to appear in 
+# the documentation. If the initializer consists of more lines than specified 
+# here it will be hidden. Use a value of 0 to hide initializers completely. 
+# The appearance of the initializer of individual variables and defines in the 
+# documentation can be controlled using \showinitializer or \hideinitializer 
+# command in the documentation regardless of this setting.
+
 MAX_INITIALIZER_LINES  = 30
+
+# Set the SHOW_USED_FILES tag to NO to disable the list of files generated 
+# at the bottom of the documentation of classes and structs. If set to YES the 
+# list will mention the files that were used to generate the documentation.
+
 SHOW_USED_FILES        = YES
+
+# If the sources in your project are distributed over multiple directories 
+# then setting the SHOW_DIRECTORIES tag to YES will show the directory hierarchy 
+# in the documentation. The default is NO.
+
 SHOW_DIRECTORIES       = YES
+
+# The FILE_VERSION_FILTER tag can be used to specify a program or script that 
+# doxygen should invoke to get the current version for each file (typically from the 
+# version control system). Doxygen will invoke the program by executing (via 
+# popen()) the command <command> <input-file>, where <command> is the value of 
+# the FILE_VERSION_FILTER tag, and <input-file> is the name of an input file 
+# provided by doxygen. Whatever the program writes to standard output 
+# is used as the file version. See the manual for examples.
+
 FILE_VERSION_FILTER    = 
+
 #---------------------------------------------------------------------------
 # configuration options related to warning and progress messages
 #---------------------------------------------------------------------------
+
+# The QUIET tag can be used to turn on/off the messages that are generated 
+# by doxygen. Possible values are YES and NO. If left blank NO is used.
+
 QUIET                  = NO
+
+# The WARNINGS tag can be used to turn on/off the warning messages that are 
+# generated by doxygen. Possible values are YES and NO. If left blank 
+# NO is used.
+
 WARNINGS               = YES
+
+# If WARN_IF_UNDOCUMENTED is set to YES, then doxygen will generate warnings 
+# for undocumented members. If EXTRACT_ALL is set to YES then this flag will 
+# automatically be disabled.
+
 WARN_IF_UNDOCUMENTED   = NO
+
+# If WARN_IF_DOC_ERROR is set to YES, doxygen will generate warnings for 
+# potential errors in the documentation, such as not documenting some 
+# parameters in a documented function, or documenting parameters that 
+# don't exist or using markup commands wrongly.
+
 WARN_IF_DOC_ERROR      = YES
+
+# This WARN_NO_PARAMDOC option can be abled to get warnings for 
+# functions that are documented, but have no documentation for their parameters 
+# or return value. If set to NO (the default) doxygen will only warn about 
+# wrong or incomplete parameter documentation, but not about the absence of 
+# documentation.
+
 WARN_NO_PARAMDOC       = NO
+
+# The WARN_FORMAT tag determines the format of the warning messages that 
+# doxygen can produce. The string should contain the $file, $line, and $text 
+# tags, which will be replaced by the file and line number from which the 
+# warning originated and the warning text. Optionally the format may contain 
+# $version, which will be replaced by the version of the file (if it could 
+# be obtained via FILE_VERSION_FILTER)
+
 WARN_FORMAT            = 
+
+# The WARN_LOGFILE tag can be used to specify a file to which warning 
+# and error messages should be written. If left blank the output is written 
+# to stderr.
+
 WARN_LOGFILE           = 
+
 #---------------------------------------------------------------------------
 # configuration options related to the input files
 #---------------------------------------------------------------------------
+
+# The INPUT tag can be used to specify the files and/or directories that contain 
+# documented source files. You may enter file names like "myfile.cpp" or 
+# directories like "/usr/src/myproject". Separate the files or directories 
+# with spaces.
+
 INPUT                  = ../plearn \
                          ../plearn_learners \
                          ../plearn_learners_experimental \
                          ../commands
+
+# This tag can be used to specify the character encoding of the source files that 
+# doxygen parses. Internally doxygen uses the UTF-8 encoding, which is also the default 
+# input encoding. Doxygen uses libiconv (or the iconv built into libc) for the transcoding. 
+# See http://www.gnu.org/software/libiconv for the list of possible encodings.
+
+INPUT_ENCODING         = UTF-8
+
+# If the value of the INPUT tag contains directories, you can use the 
+# FILE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
+# and *.h) to filter out the source-files in the directories. If left 
+# blank the following patterns are tested: 
+# *.c *.cc *.cxx *.cpp *.c++ *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh *.hxx 
+# *.hpp *.h++ *.idl *.odl *.cs *.php *.php3 *.inc *.m *.mm *.py
+
 FILE_PATTERNS          = *.cc \
                          *.h
+
+# The RECURSIVE tag can be used to turn specify whether or not subdirectories 
+# should be searched for input files as well. Possible values are YES and NO. 
+# If left blank NO is used.
+
 RECURSIVE              = YES
+
+# The EXCLUDE tag can be used to specify files and/or directories that should 
+# excluded from the INPUT source files. This way you can easily exclude a 
+# subdirectory from a directory tree whose root is specified with the INPUT tag.
+
 EXCLUDE                = 
+
+# The EXCLUDE_SYMLINKS tag can be used select whether or not files or 
+# directories that are symbolic links (a Unix filesystem feature) are excluded 
+# from the input.
+
 EXCLUDE_SYMLINKS       = NO
-EXCLUDE_PATTERNS       = OBJS .svn .pytest
+
+# If the value of the INPUT tag contains directories, you can use the 
+# EXCLUDE_PATTERNS tag to specify one or more wildcard patterns to exclude 
+# certain files from those directories. Note that the wildcards are matched 
+# against the file with absolute path, so to exclude all test directories 
+# for example use the pattern */test/*
+
+EXCLUDE_PATTERNS       = OBJS \
+                         .svn \
+                         .pytest
+
+# The EXCLUDE_SYMBOLS tag can be used to specify one or more symbol names 
+# (namespaces, classes, functions, etc.) that should be excluded from the output. 
+# The symbol name can be a fully qualified name, a word, or if the wildcard * is used, 
+# a substring. Examples: ANamespace, AClass, AClass::ANamespace, ANamespace::*Test
+
+EXCLUDE_SYMBOLS        = 
+
+# The EXAMPLE_PATH tag can be used to specify one or more files or 
+# directories that contain example code fragments that are included (see 
+# the \include command).
+
 EXAMPLE_PATH           = 
+
+# If the value of the EXAMPLE_PATH tag contains directories, you can use the 
+# EXAMPLE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp 
+# and *.h) to filter out the source-files in the directories. If left 
+# blank all files are included.
+
 EXAMPLE_PATTERNS       = 
+
+# If the EXAMPLE_RECURSIVE tag is set to YES then subdirectories will be 
+# searched for input files to be used with the \include or \dontinclude 
+# commands irrespective of the value of the RECURSIVE tag. 
+# Possible values are YES and NO. If left blank NO is used.
+
 EXAMPLE_RECURSIVE      = NO
+
+# The IMAGE_PATH tag can be used to specify one or more files or 
+# directories that contain image that are included in the documentation (see 
+# the \image command).
+
 IMAGE_PATH             = 
+
+# The INPUT_FILTER tag can be used to specify a program that doxygen should 
+# invoke to filter for each input file. Doxygen will invoke the filter program 
+# by executing (via popen()) the command <filter> <input-file>, where <filter> 
+# is the value of the INPUT_FILTER tag, and <input-file> is the name of an 
+# input file. Doxygen will then use the output that the filter program writes 
+# to standard output.  If FILTER_PATTERNS is specified, this tag will be 
+# ignored.
+
 INPUT_FILTER           = 
+
+# The FILTER_PATTERNS tag can be used to specify filters on a per file pattern 
+# basis.  Doxygen will compare the file name with each pattern and apply the 
+# filter if there is a match.  The filters are a list of the form: 
+# pattern=filter (like *.cpp=my_cpp_filter). See INPUT_FILTER for further 
+# info on how filters are used. If FILTER_PATTERNS is empty, INPUT_FILTER 
+# is applied to all files.
+
 FILTER_PATTERNS        = 
+
+# If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using 
+# INPUT_FILTER) will be used to filter the input files when producing source 
+# files to browse (i.e. when SOURCE_BROWSER is set to YES).
+
 FILTER_SOURCE_FILES    = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to source browsing
 #---------------------------------------------------------------------------
-SOURCE_BROWSER         = NO
+
+# If the SOURCE_BROWSER tag is set to YES then a list of source files will 
+# be generated. Documented entities will be cross-referenced with these sources. 
+# Note: To get rid of all source code in the generated output, make sure also 
+# VERBATIM_HEADERS is set to NO.
+
+SOURCE_BROWSER         = YES
+
+# Setting the INLINE_SOURCES tag to YES will include the body 
+# of functions and classes directly in the documentation.
+
 INLINE_SOURCES         = NO
+
+# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct 
+# doxygen to hide any special comment blocks from generated source code 
+# fragments. Normal C and C++ comments will always remain visible.
+
 STRIP_CODE_COMMENTS    = YES
+
+# If the REFERENCED_BY_RELATION tag is set to YES (the default) 
+# then for each documented function all documented 
+# functions referencing it will be listed.
+
 REFERENCED_BY_RELATION = YES
+
+# If the REFERENCES_RELATION tag is set to YES (the default) 
+# then for each documented function all documented entities 
+# called/used by that function will be listed.
+
 REFERENCES_RELATION    = YES
+
+# If the REFERENCES_LINK_SOURCE tag is set to YES (the default)
+# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from
+# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will
+# link to the source code.  Otherwise they will link to the documentstion.
+
+REFERENCES_LINK_SOURCE = YES
+
+# If the USE_HTAGS tag is set to YES then the references to source code 
+# will point to the HTML generated by the htags(1) tool instead of doxygen 
+# built-in source browser. The htags tool is part of GNU's global source 
+# tagging system (see http://www.gnu.org/software/global/global.html). You 
+# will need version 4.8.6 or higher.
+
 USE_HTAGS              = NO
-VERBATIM_HEADERS       = NO
+
+# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen 
+# will generate a verbatim copy of the header file for each class for 
+# which an include is specified. Set to NO to disable this.
+
+VERBATIM_HEADERS       = YES
+
 #---------------------------------------------------------------------------
 # configuration options related to the alphabetical class index
 #---------------------------------------------------------------------------
+
+# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index 
+# of all compounds will be generated. Enable this if the project 
+# contains a lot of classes, structs, unions or interfaces.
+
 ALPHABETICAL_INDEX     = YES
+
+# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then 
+# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns 
+# in which this list will be split (can be a number in the range [1..20])
+
 COLS_IN_ALPHA_INDEX    = 5
+
+# In case all classes in a project start with a common prefix, all 
+# classes will be put under the same header in the alphabetical index. 
+# The IGNORE_PREFIX tag can be used to specify one or more prefixes that 
+# should be ignored while generating the index headers.
+
 IGNORE_PREFIX          = 
+
 #---------------------------------------------------------------------------
 # configuration options related to the HTML output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_HTML tag is set to YES (the default) Doxygen will 
+# generate HTML output.
+
 GENERATE_HTML          = YES
+
+# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `html' will be used as the default path.
+
 HTML_OUTPUT            = 
+
+# The HTML_FILE_EXTENSION tag can be used to specify the file extension for 
+# each generated HTML page (for example: .htm,.php,.asp). If it is left blank 
+# doxygen will generate files with .html extension.
+
 HTML_FILE_EXTENSION    = .html
+
+# The HTML_HEADER tag can be used to specify a personal HTML header for 
+# each generated HTML page. If it is left blank doxygen will generate a 
+# standard header.
+
 HTML_HEADER            = 
+
+# The HTML_FOOTER tag can be used to specify a personal HTML footer for 
+# each generated HTML page. If it is left blank doxygen will generate a 
+# standard footer.
+
 HTML_FOOTER            = 
+
+# The HTML_STYLESHEET tag can be used to specify a user-defined cascading 
+# style sheet that is used by each HTML page. It can be used to 
+# fine-tune the look of the HTML output. If the tag is left blank doxygen 
+# will generate a default style sheet. Note that doxygen will try to copy 
+# the style sheet file to the HTML output directory, so don't put your own 
+# stylesheet in the HTML output directory as well, or it will be erased!
+
 HTML_STYLESHEET        = 
+
+# If the HTML_ALIGN_MEMBERS tag is set to YES, the members of classes, 
+# files or namespaces will be aligned in HTML using tables. If set to 
+# NO a bullet list will be used.
+
 HTML_ALIGN_MEMBERS     = YES
+
+# If the GENERATE_HTMLHELP tag is set to YES, additional index files 
+# will be generated that can be used as input for tools like the 
+# Microsoft HTML help workshop to generate a compressed HTML help file (.chm) 
+# of the generated HTML documentation.
+
 GENERATE_HTMLHELP      = NO
+
+# If the GENERATE_HTMLHELP tag is set to YES, the CHM_FILE tag can 
+# be used to specify the file name of the resulting .chm file. You 
+# can add a path in front of the file if the result should not be 
+# written to the html output directory.
+
 CHM_FILE               = 
+
+# If the GENERATE_HTMLHELP tag is set to YES, the HHC_LOCATION tag can 
+# be used to specify the location (absolute path including file name) of 
+# the HTML help compiler (hhc.exe). If non-empty doxygen will try to run 
+# the HTML help compiler on the generated index.hhp.
+
 HHC_LOCATION           = 
+
+# If the GENERATE_HTMLHELP tag is set to YES, the GENERATE_CHI flag 
+# controls if a separate .chi index file is generated (YES) or that 
+# it should be included in the master .chm file (NO).
+
 GENERATE_CHI           = NO
+
+# If the GENERATE_HTMLHELP tag is set to YES, the BINARY_TOC flag 
+# controls whether a binary table of contents is generated (YES) or a 
+# normal table of contents (NO) in the .chm file.
+
 BINARY_TOC             = NO
+
+# The TOC_EXPAND flag can be set to YES to add extra items for group members 
+# to the contents of the HTML help documentation and to the tree view.
+
 TOC_EXPAND             = NO
+
+# The DISABLE_INDEX tag can be used to turn on/off the condensed index at 
+# top of each HTML page. The value NO (the default) enables the index and 
+# the value YES disables it.
+
 DISABLE_INDEX          = NO
+
+# This tag can be used to set the number of enum values (range [1..20]) 
+# that doxygen will group on one line in the generated HTML documentation.
+
 ENUM_VALUES_PER_LINE   = 4
+
+# If the GENERATE_TREEVIEW tag is set to YES, a side panel will be
+# generated containing a tree-like index structure (just like the one that 
+# is generated for HTML Help). For this to work a browser that supports 
+# JavaScript, DHTML, CSS and frames is required (for instance Mozilla 1.0+, 
+# Netscape 6.0+, Internet explorer 5.0+, or Konqueror). Windows users are 
+# probably better off using the HTML help feature.
+
 GENERATE_TREEVIEW      = NO
+
+# If the treeview is enabled (see GENERATE_TREEVIEW) then this tag can be 
+# used to set the initial width (in pixels) of the frame in which the tree 
+# is shown.
+
 TREEVIEW_WIDTH         = 250
+
 #---------------------------------------------------------------------------
 # configuration options related to the LaTeX output
 #---------------------------------------------------------------------------
-GENERATE_LATEX         = NO
+
+# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will 
+# generate Latex output.
+
+GENERATE_LATEX         = YES
+
+# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `latex' will be used as the default path.
+
 LATEX_OUTPUT           = 
+
+# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be 
+# invoked. If left blank `latex' will be used as the default command name.
+
 LATEX_CMD_NAME         = latex
+
+# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to 
+# generate index for LaTeX. If left blank `makeindex' will be used as the 
+# default command name.
+
 MAKEINDEX_CMD_NAME     = makeindex
+
+# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact 
+# LaTeX documents. This may be useful for small projects and may help to 
+# save some trees in general.
+
 COMPACT_LATEX          = NO
-PAPER_TYPE             = a4wide
+
+# The PAPER_TYPE tag can be used to set the paper type that is used 
+# by the printer. Possible values are: a4, a4wide, letter, legal and 
+# executive. If left blank a4wide will be used.
+
+PAPER_TYPE             = letter
+
+# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX 
+# packages that should be included in the LaTeX output.
+
 EXTRA_PACKAGES         = 
+
+# The LATEX_HEADER tag can be used to specify a personal LaTeX header for 
+# the generated latex document. The header should contain everything until 
+# the first chapter. If it is left blank doxygen will generate a 
+# standard header. Notice: only use this tag if you know what you are doing!
+
 LATEX_HEADER           = 
-PDF_HYPERLINKS         = NO
-USE_PDFLATEX           = NO
-LATEX_BATCHMODE        = NO
+
+# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated 
+# is prepared for conversion to pdf (using ps2pdf). The pdf file will 
+# contain links (just like the HTML output) instead of page references 
+# This makes the output suitable for online browsing using a pdf viewer.
+
+PDF_HYPERLINKS         = YES
+
+# If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of 
+# plain latex in the generated Makefile. Set this option to YES to get a 
+# higher quality PDF documentation.
+
+USE_PDFLATEX           = YeS
+
+# If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\batchmode. 
+# command to the generated LaTeX files. This will instruct LaTeX to keep 
+# running if errors occur, instead of asking the user for help. 
+# This option is also used when generating formulas in HTML.
+
+LATEX_BATCHMODE        = YES
+
+# If LATEX_HIDE_INDICES is set to YES then doxygen will not 
+# include the index chapters (such as File Index, Compound Index, etc.) 
+# in the output.
+
 LATEX_HIDE_INDICES     = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to the RTF output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_RTF tag is set to YES Doxygen will generate RTF output 
+# The RTF output is optimized for Word 97 and may not look very pretty with 
+# other RTF readers or editors.
+
 GENERATE_RTF           = NO
+
+# The RTF_OUTPUT tag is used to specify where the RTF docs will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `rtf' will be used as the default path.
+
 RTF_OUTPUT             = 
+
+# If the COMPACT_RTF tag is set to YES Doxygen generates more compact 
+# RTF documents. This may be useful for small projects and may help to 
+# save some trees in general.
+
 COMPACT_RTF            = NO
+
+# If the RTF_HYPERLINKS tag is set to YES, the RTF that is generated 
+# will contain hyperlink fields. The RTF file will 
+# contain links (just like the HTML output) instead of page references. 
+# This makes the output suitable for online browsing using WORD or other 
+# programs which support those fields. 
+# Note: wordpad (write) and others do not support links.
+
 RTF_HYPERLINKS         = NO
+
+# Load stylesheet definitions from file. Syntax is similar to doxygen's 
+# config file, i.e. a series of assignments. You only have to provide 
+# replacements, missing definitions are set to their default value.
+
 RTF_STYLESHEET_FILE    = 
+
+# Set optional variables used in the generation of an rtf document. 
+# Syntax is similar to doxygen's config file.
+
 RTF_EXTENSIONS_FILE    = 
+
 #---------------------------------------------------------------------------
 # configuration options related to the man page output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_MAN tag is set to YES (the default) Doxygen will 
+# generate man pages
+
 GENERATE_MAN           = NO
+
+# The MAN_OUTPUT tag is used to specify where the man pages will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `man' will be used as the default path.
+
 MAN_OUTPUT             = 
+
+# The MAN_EXTENSION tag determines the extension that is added to 
+# the generated man pages (default is the subroutine's section .3)
+
 MAN_EXTENSION          = 
+
+# If the MAN_LINKS tag is set to YES and Doxygen generates man output, 
+# then it will generate one additional man file for each entity 
+# documented in the real man page(s). These additional files 
+# only source the real man page, but without them the man command 
+# would be unable to find the correct page. The default is NO.
+
 MAN_LINKS              = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to the XML output
 #---------------------------------------------------------------------------
-GENERATE_XML           = NO
+
+# If the GENERATE_XML tag is set to YES Doxygen will 
+# generate an XML file that captures the structure of 
+# the code including all documentation.
+
+GENERATE_XML           = YES
+
+# The XML_OUTPUT tag is used to specify where the XML pages will be put. 
+# If a relative path is entered the value of OUTPUT_DIRECTORY will be 
+# put in front of it. If left blank `xml' will be used as the default path.
+
 XML_OUTPUT             = xml
+
+# The XML_SCHEMA tag can be used to specify an XML schema, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
 XML_SCHEMA             = 
+
+# The XML_DTD tag can be used to specify an XML DTD, 
+# which can be used by a validating XML parser to check the 
+# syntax of the XML files.
+
 XML_DTD                = 
+
+# If the XML_PROGRAMLISTING tag is set to YES Doxygen will 
+# dump the program listings (including syntax highlighting 
+# and cross-referencing information) to the XML output. Note that 
+# enabling this will significantly increase the size of the XML output.
+
 XML_PROGRAMLISTING     = YES
+
 #---------------------------------------------------------------------------
 # configuration options for the AutoGen Definitions output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_AUTOGEN_DEF tag is set to YES Doxygen will 
+# generate an AutoGen Definitions (see autogen.sf.net) file 
+# that captures the structure of the code including all 
+# documentation. Note that this feature is still experimental 
+# and incomplete at the moment.
+
 GENERATE_AUTOGEN_DEF   = NO
+
 #---------------------------------------------------------------------------
 # configuration options related to the Perl module output
 #---------------------------------------------------------------------------
+
+# If the GENERATE_PERLMOD tag is set to YES Doxygen will 
+# generate a Perl module file that captures the structure of 
+# the code including all documentation. Note that this 
+# feature is still experimental and incomplete at the 
+# moment.
+
 GENERATE_PERLMOD       = NO
+
+# If the PERLMOD_LATEX tag is set to YES Doxygen will generate 
+# the necessary Makefile rules, Perl scripts and LaTeX code to be able 
+# to generate PDF and DVI output from the Perl module output.
+
 PERLMOD_LATEX          = NO
+
+# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be 
+# nicely formatted so it can be parsed by a human reader.  This is useful 
+# if you want to understand what is going on.  On the other hand, if this 
+# tag is set to NO the size of the Perl module output will be much smaller 
+# and Perl will parse it just the same.
+
 PERLMOD_PRETTY         = YES
+
+# The names of the make variables in the generated doxyrules.make file 
+# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX. 
+# This is useful so different doxyrules.make files included by the same 
+# Makefile don't overwrite each other's variables.
+
 PERLMOD_MAKEVAR_PREFIX = 
+
 #---------------------------------------------------------------------------
 # Configuration options related to the preprocessor   
 #---------------------------------------------------------------------------
+
+# If the ENABLE_PREPROCESSING tag is set to YES (the default) Doxygen will 
+# evaluate all C-preprocessor directives found in the sources and include 
+# files.
+
 ENABLE_PREPROCESSING   = YES
+
+# If the MACRO_EXPANSION tag is set to YES Doxygen will expand all macro 
+# names in the source code. If set to NO (the default) only conditional 
+# compilation will be performed. Macro expansion can be done in a controlled 
+# way by setting EXPAND_ONLY_PREDEF to YES.
+
 MACRO_EXPANSION        = YES
+
+# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES 
+# then the macro expansion is limited to the macros specified with the 
+# PREDEFINED and EXPAND_AS_DEFINED tags.
+
 EXPAND_ONLY_PREDEF     = YES
+
+# If the SEARCH_INCLUDES tag is set to YES (the default) the includes files 
+# in the INCLUDE_PATH (see below) will be search if a #include is found.
+
 SEARCH_INCLUDES        = YES
+
+# The INCLUDE_PATH tag can be used to specify one or more directories that 
+# contain include files that are not input files but should be processed by 
+# the preprocessor.
+
 INCLUDE_PATH           = 
+
+# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard 
+# patterns (like *.h and *.hpp) to filter out the header-files in the 
+# directories. If left blank, the patterns specified with FILE_PATTERNS will 
+# be used.
+
 INCLUDE_FILE_PATTERNS  = 
+
+# The PREDEFINED tag can be used to specify one or more macro names that 
+# are defined before the preprocessor is started (similar to the -D option of 
+# gcc). The argument of the tag is a list of macros of the form: name 
+# or name=definition (no spaces). If the definition and the = are 
+# omitted =1 is assumed. To prevent a macro definition from being 
+# undefined via #undef or recursively expanded use the := operator 
+# instead of the = operator.
+
 PREDEFINED             = 
+
+# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then 
+# this tag can be used to specify a list of macro names that should be expanded. 
+# The macro definition that is found in the sources will be used. 
+# Use the PREDEFINED tag if you want to use a different macro definition.
+
 EXPAND_AS_DEFINED      = PLEARN_DECLARE_OBJECT \
                          PLEARN_IMPLEMENT_OBJECT \
                          DECLARE_OBJECT_PTR \
@@ -204,42 +1052,221 @@
                          PLEARN_IMPLEMENT_ABSTRACT_OBJECT \
                          PLEARN_DECLARE_TEMPLATE_OBJECT \
                          PLEARN_IMPLEMENT_TEMPLATE_OBJECT
+
+# If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then 
+# doxygen's preprocessor will remove all function-like macros that are alone 
+# on a line, have an all uppercase name, and do not end with a semicolon. Such 
+# function macros are typically used for boiler-plate code, and will confuse 
+# the parser if not removed.
+
 SKIP_FUNCTION_MACROS   = YES
+
 #---------------------------------------------------------------------------
 # Configuration::additions related to external references   
 #---------------------------------------------------------------------------
+
+# The TAGFILES option can be used to specify one or more tagfiles. 
+# Optionally an initial location of the external documentation 
+# can be added for each tagfile. The format of a tag file without 
+# this location is as follows: 
+#   TAGFILES = file1 file2 ... 
+# Adding location for the tag files is done as follows: 
+#   TAGFILES = file1=loc1 "file2 = loc2" ... 
+# where "loc1" and "loc2" can be relative or absolute paths or 
+# URLs. If a location is present for each tag, the installdox tool 
+# does not have to be run to correct the links.
+# Note that each tag file must have a unique name
+# (where the name does NOT include the path)
+# If a tag file is not located in the directory in which doxygen 
+# is run, you must also specify the path to the tagfile here.
+
 TAGFILES               = 
-GENERATE_TAGFILE       = 
+
+# When a file name is specified after GENERATE_TAGFILE, doxygen will create 
+# a tag file that is based on the input files it reads.
+
+GENERATE_TAGFILE       = plearn.tag
+
+# If the ALLEXTERNALS tag is set to YES all external classes will be listed 
+# in the class index. If set to NO only the inherited external classes 
+# will be listed.
+
 ALLEXTERNALS           = NO
+
+# If the EXTERNAL_GROUPS tag is set to YES all external groups will be listed 
+# in the modules index. If set to NO, only the current project's groups will 
+# be listed.
+
 EXTERNAL_GROUPS        = YES
+
+# The PERL_PATH should be the absolute path and name of the perl script 
+# interpreter (i.e. the result of `which perl').
+
 PERL_PATH              = 
+
 #---------------------------------------------------------------------------
 # Configuration options related to the dot tool   
 #---------------------------------------------------------------------------
-CLASS_DIAGRAMS         = NO
+
+# If the CLASS_DIAGRAMS tag is set to YES (the default) Doxygen will 
+# generate a inheritance diagram (in HTML, RTF and LaTeX) for classes with base 
+# or super classes. Setting the tag to NO turns the diagrams off. Note that 
+# this option is superseded by the HAVE_DOT option below. This is only a 
+# fallback. It is recommended to install and use dot, since it yields more 
+# powerful graphs.
+
+CLASS_DIAGRAMS         = YES
+
+# You can define message sequence charts within doxygen comments using the \msc 
+# command. Doxygen will then run the mscgen tool (see http://www.mcternan.me.uk/mscgen/) to 
+# produce the chart and insert it in the documentation. The MSCGEN_PATH tag allows you to 
+# specify the directory where the mscgen tool resides. If left empty the tool is assumed to 
+# be found in the default search path.
+
+MSCGEN_PATH            = 
+
+# If set to YES, the inheritance and collaboration graphs will hide 
+# inheritance and usage relations if the target is undocumented 
+# or is not a class.
+
 HIDE_UNDOC_RELATIONS   = NO
+
+# If you set the HAVE_DOT tag to YES then doxygen will assume the dot tool is 
+# available from the path. This tool is part of Graphviz, a graph visualization 
+# toolkit from AT&T and Lucent Bell Labs. The other options in this section 
+# have no effect if this option is set to NO (the default)
+
 HAVE_DOT               = NO
+
+# If the CLASS_GRAPH and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for each documented class showing the direct and 
+# indirect inheritance relations. Setting this tag to YES will force the 
+# the CLASS_DIAGRAMS tag to NO.
+
 CLASS_GRAPH            = YES
+
+# If the COLLABORATION_GRAPH and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for each documented class showing the direct and 
+# indirect implementation dependencies (inheritance, containment, and 
+# class references variables) of the class with other documented classes.
+
 COLLABORATION_GRAPH    = YES
+
+# If the GROUP_GRAPHS and HAVE_DOT tags are set to YES then doxygen 
+# will generate a graph for groups, showing the direct groups dependencies
+
 GROUP_GRAPHS           = YES
+
+# If the UML_LOOK tag is set to YES doxygen will generate inheritance and 
+# collaboration diagrams in a style similar to the OMG's Unified Modeling 
+# Language.
+
 UML_LOOK               = NO
+
+# If set to YES, the inheritance and collaboration graphs will show the 
+# relations between templates and their instances.
+
 TEMPLATE_RELATIONS     = YES
+
+# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDE_GRAPH, and HAVE_DOT 
+# tags are set to YES then doxygen will generate a graph for each documented 
+# file showing the direct and indirect include dependencies of the file with 
+# other documented files.
+
 INCLUDE_GRAPH          = YES
+
+# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDED_BY_GRAPH, and 
+# HAVE_DOT tags are set to YES then doxygen will generate a graph for each 
+# documented header file showing the documented files that directly or 
+# indirectly include this file.
+
 INCLUDED_BY_GRAPH      = YES
-CALL_GRAPH             = NO
+
+# If the CALL_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a call dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable call graphs for selected 
+# functions only using the \callgraph command.
+
+CALL_GRAPH             = YES
+
+# If the CALLER_GRAPH and HAVE_DOT tags are set to YES then doxygen will 
+# generate a caller dependency graph for every global function or class method. 
+# Note that enabling this option will significantly increase the time of a run. 
+# So in most cases it will be better to enable caller graphs for selected 
+# functions only using the \callergraph command.
+
+CALLER_GRAPH           = YES
+
+# If the GRAPHICAL_HIERARCHY and HAVE_DOT tags are set to YES then doxygen 
+# will graphical hierarchy of all classes instead of a textual one.
+
 GRAPHICAL_HIERARCHY    = YES
+
+# If the DIRECTORY_GRAPH, SHOW_DIRECTORIES and HAVE_DOT tags are set to YES 
+# then doxygen will show the dependencies a directory has on other directories 
+# in a graphical way. The dependency relations are determined by the #include
+# relations between the files in the directories.
+
 DIRECTORY_GRAPH        = YES
+
+# The DOT_IMAGE_FORMAT tag can be used to set the image format of the images 
+# generated by dot. Possible values are png, jpg, or gif
+# If left blank png will be used.
+
 DOT_IMAGE_FORMAT       = png
+
+# The tag DOT_PATH can be used to specify the path where the dot tool can be 
+# found. If left blank, it is assumed the dot tool can be found in the path.
+
 DOT_PATH               = 
+
+# The DOTFILE_DIRS tag can be used to specify one or more directories that 
+# contain dot files that are included in the documentation (see the 
+# \dotfile command).
+
 DOTFILE_DIRS           = 
-MAX_DOT_GRAPH_WIDTH    = 1024
-MAX_DOT_GRAPH_HEIGHT   = 1024
-MAX_DOT_GRAPH_DEPTH    = 1000
+
+# The MAX_DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of 
+# nodes that will be shown in the graph. If the number of nodes in a graph 
+# becomes larger than this value, doxygen will truncate the graph, which is 
+# visualized by representing a node as a red box. Note that doxygen will always 
+# show the root nodes and its direct children regardless of this setting.
+
+DOT_GRAPH_MAX_NODES    = 50
+
+# Set the DOT_TRANSPARENT tag to YES to generate images with a transparent 
+# background. This is disabled by default, which results in a white background. 
+# Warning: Depending on the platform used, enabling this option may lead to 
+# badly anti-aliased labels on the edges of a graph (i.e. they become hard to 
+# read).
+
 DOT_TRANSPARENT        = NO
-DOT_MULTI_TARGETS      = NO
+
+# Set the DOT_MULTI_TARGETS tag to YES allow dot to generate multiple output 
+# files in one run (i.e. multiple -o and -T options on the command line). This 
+# makes dot run faster, but since only newer versions of dot (>1.8.10) 
+# support this, this feature is disabled by default.
+
+DOT_MULTI_TARGETS      = YES
+
+# If the GENERATE_LEGEND tag is set to YES (the default) Doxygen will 
+# generate a legend page explaining the meaning of the various boxes and 
+# arrows in the dot generated graphs.
+
 GENERATE_LEGEND        = YES
+
+# If the DOT_CLEANUP tag is set to YES (the default) Doxygen will 
+# remove the intermediate dot files that are used to generate 
+# the various graphs.
+
 DOT_CLEANUP            = YES
+
 #---------------------------------------------------------------------------
 # Configuration::additions related to the search engine   
 #---------------------------------------------------------------------------
-SEARCHENGINE           = NO
+
+# The SEARCHENGINE tag specifies whether or not a search engine should be 
+# used. If set to NO the values of all tags below this one will be ignored.
+
+SEARCHENGINE           = YES



From nouiz at mail.berlios.de  Wed Nov 28 19:45:33 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 28 Nov 2007 19:45:33 +0100
Subject: [Plearn-commits] r8316 - trunk/plearn/misc
Message-ID: <200711281845.lASIjXxT026437@sheep.berlios.de>

Author: nouiz
Date: 2007-11-28 19:45:33 +0100 (Wed, 28 Nov 2007)
New Revision: 8316

Modified:
   trunk/plearn/misc/vmatmain.cc
Log:
allow to give that field name or the field number


Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2007-11-28 15:59:06 UTC (rev 8315)
+++ trunk/plearn/misc/vmatmain.cc	2007-11-28 18:45:33 UTC (rev 8316)
@@ -203,7 +203,7 @@
                 vmats[0]->printFields(pout);
             else
             {
-                varnum = toint(command[0]);
+                varnum = vmats[0]->getFieldIndex(command[0]);
                 if(varnum<0 || varnum>=w)
                     vmats[0]->printFields(pout);
                 else if(command.size()==3)



From louradou at mail.berlios.de  Wed Nov 28 21:23:19 2007
From: louradou at mail.berlios.de (louradou at BerliOS)
Date: Wed, 28 Nov 2007 21:23:19 +0100
Subject: [Plearn-commits] r8317 - trunk/scripts
Message-ID: <200711282023.lASKNJ9i032371@sheep.berlios.de>

Author: louradou
Date: 2007-11-28 21:23:19 +0100 (Wed, 28 Nov 2007)
New Revision: 8317

Modified:
   trunk/scripts/appendresults
   trunk/scripts/makeresults
Log:
Fixed: a problem with makeresults (that did not lock the .amat file,
so appendresults could write in this .amat file at the same time as appendresults)

Added: the possibility to also give the statistics values as arguments
(instead of the path to the global_stats.pmat which contains them)



Modified: trunk/scripts/appendresults
===================================================================
--- trunk/scripts/appendresults	2007-11-28 18:45:33 UTC (rev 8316)
+++ trunk/scripts/appendresults	2007-11-28 20:23:19 UTC (rev 8317)
@@ -5,14 +5,25 @@
 #   appendresults ${dir} results.amat ${param_1} ${param_2} ... ${param_n}
 
 if [ "$3" = "" ]; then
-  echo Usage: $0 dir output param_1 ... param_n
-  echo See code for more info.
+  echo "Usage:"
+  echo "     $0 dir output param_1 ... param_n"
+  echo "OR   $0 output param_1 ... param_n perf_1 ... perf_m"
+  echo "See code for more info."
   exit 127
 fi
 DIR="$1"
-OUTPUT="$2"
 shift
-shift
+if [ -d $DIR ];then
+    OUTPUT="$1"
+    shift
+else
+    OUTPUT=$DIR
+fi
+if [ ! -f $OUTPUT ];then
+    echo "$OUTPUT is not a file!"
+    exit 69
+fi
+
 PARAMS="$1 "
 shift
 for PARAM in $@; do
@@ -22,8 +33,12 @@
 # Wait until nobody else is messing with the output file.
 lockfile $OUTPUT.lock
 
-echo -n "$PARAMS" >> $OUTPUT
-plearn vmat cat $DIR/global_stats.pmat "rowindex 1 ==" >> $OUTPUT
+if [ -d $DIR ];then
+    echo -n "$PARAMS" >> $OUTPUT
+    plearn vmat cat $DIR/global_stats.pmat "rowindex 1 ==" >> $OUTPUT
+else
+    echo "$PARAMS" >> $OUTPUT
+fi
 
 # Release the lock
 rm -f $OUTPUT.lock

Modified: trunk/scripts/makeresults
===================================================================
--- trunk/scripts/makeresults	2007-11-28 18:45:33 UTC (rev 8316)
+++ trunk/scripts/makeresults	2007-11-28 20:23:19 UTC (rev 8317)
@@ -9,20 +9,27 @@
 #   <template_mat> : a matrix file readable by 'plearn vmat fields', whose fields names
 #                    will be copied into the .amat field names
 #   <parameter_i>  : the name of the i-th parameter to be reported in the results
+#   <performance_i> : the name of the i-th statistics to be reported in the results
 #
 # Output: two files (.vmat and .amat), used respectively to visualize and store the results of
 #         the experiments (using the appendresults script)
 
 if [ "$2" = "" ]; then
-  echo "Usage: makeresults <matrix_name> <template_mat> <parameter_1> ... <parameter_N>"
+  echo "Usage:"
+  echo "     $0 <matrix_name> <template_mat> <parameter_1> ... <parameter_N>"
+  echo "OR   $0 <matrix_name> <parameter_1> ... <parameter_N> <performance_1> ... <performance_M>"
   exit 127
 fi
 
 MATNAME="$1"
 shift
 
+# Wait until nobody else is messing with the output file.
+lockfile $MATNAME.amat.lock
+
 # Don't do anything if files already exist.
 if [ -f $MATNAME.amat ] && [ -f $MATNAME.vmat ]; then
+  rm -f $MATNAME.amat.lock
   exit 0
 fi
 
@@ -31,12 +38,10 @@
   echo "In makeresults script: one of the following files already exist:"
   echo "  $MATNAME.amat, or"
   echo "  $MATNAME.vmat"
+  rm -f $MATNAME.amat.lock
   exit 127
 fi
 
-TEMPLATEMAT="$1"
-shift
-
 # Make the .vmat.
 echo "# Wrapper to visualize the results stored in $MATNAME.amat." > $MATNAME.vmat
 echo "SortRowsVMatrix(" >> $MATNAME.vmat
@@ -47,16 +52,39 @@
 echo "  ]" >> $MATNAME.vmat
 echo ")" >> $MATNAME.vmat
 
+
+TEMPLATEMAT="$1"
+if [ -f $TEMPLATEMAT ];then
+   if [ ! -r $TEMPLATEMAT ];then
+       echo "ERROR: file "$TEMPLATEMAT" exists but cannot be read!"
+       rm -f $MATNAME.amat.lock
+       exit 69
+   fi
+   shift
+fi
+
 # Make the .amat.
 echo "# Data collected from PLearn experiments, to be visualized through $MATNAME.vmat." > $MATNAME.amat
 echo "# Fieldnames:" >> $MATNAME.amat
 echo -n "#: " >> $MATNAME.amat
-for PARAM in $@; do
-  echo -n "$PARAM " >> $MATNAME.amat
-done
 
-# Now uses the template matrix to complete the field names.
-plearn vmat fields $TEMPLATEMAT name_only transpose >> $MATNAME.amat
+# Write the parameters and statistics names
+if [ -f $TEMPLATEMAT ];then
+    for PARAM in $@; do
+        echo -n "$PARAM " >> $MATNAME.amat
+    done
+    # Now uses the template matrix to complete the field names.
+    plearn vmat fields $TEMPLATEMAT name_only transpose >> $MATNAME.amat
+else
+    for PARAM in $@; do
+        echo -n "$PARAM " >> $MATNAME.amat
+    done
+    echo >> $MATNAME.amat
+fi
 
+# Release the lock
+rm -f $MATNAME.amat.lock
+
+
 # Display exit message.
 echo "Files $MATNAME.vmat and $MATNAME.amat successfully created"



From nouiz at mail.berlios.de  Wed Nov 28 22:15:37 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 28 Nov 2007 22:15:37 +0100
Subject: [Plearn-commits] r8318 - trunk/plearn/base
Message-ID: <200711282115.lASLFbrT002361@sheep.berlios.de>

Author: nouiz
Date: 2007-11-28 22:15:36 +0100 (Wed, 28 Nov 2007)
New Revision: 8318

Modified:
   trunk/plearn/base/ObjectGraphIterator.h
   trunk/plearn/base/OptionBase.h
Log:
corrected comment for doxygen


Modified: trunk/plearn/base/ObjectGraphIterator.h
===================================================================
--- trunk/plearn/base/ObjectGraphIterator.h	2007-11-28 20:23:19 UTC (rev 8317)
+++ trunk/plearn/base/ObjectGraphIterator.h	2007-11-28 21:15:36 UTC (rev 8318)
@@ -536,9 +536,9 @@
  *  induced by ObjectGraphIterator) of a class derived from that specified.
  *
  *  @param o             Root of the graph
- *  @param class-name    String representation of the class to filter on
- *  @param option-name   Name of the option to set
- *  @param option-value  Value of the option to set
+ *  @param class_name    String representation of the class to filter on
+ *  @param option_name   Name of the option to set
+ *  @param option_value  Value of the option to set
  */
 void setoption_broadcast(const Object* o, const string& class_name,
                          const string& option_name, const string& option_value,

Modified: trunk/plearn/base/OptionBase.h
===================================================================
--- trunk/plearn/base/OptionBase.h	2007-11-28 20:23:19 UTC (rev 8317)
+++ trunk/plearn/base/OptionBase.h	2007-11-28 21:15:36 UTC (rev 8318)
@@ -42,7 +42,7 @@
  ******************************************************* */
 
 
-/*! \file Option.h */
+/*! \file OptionBase.h */
 
 #ifndef OptionBase_INC
 #define OptionBase_INC



From nouiz at mail.berlios.de  Wed Nov 28 22:31:05 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 28 Nov 2007 22:31:05 +0100
Subject: [Plearn-commits] r8319 - in trunk/plearn: math vmat
Message-ID: <200711282131.lASLV55b003223@sheep.berlios.de>

Author: nouiz
Date: 2007-11-28 22:31:04 +0100 (Wed, 28 Nov 2007)
New Revision: 8319

Modified:
   trunk/plearn/math/TVec_decl.h
   trunk/plearn/math/TVec_impl.h
   trunk/plearn/vmat/VariableDeletionVMatrix.h
Log:
corrected comment for doxygen


Modified: trunk/plearn/math/TVec_decl.h
===================================================================
--- trunk/plearn/math/TVec_decl.h	2007-11-28 21:15:36 UTC (rev 8318)
+++ trunk/plearn/math/TVec_decl.h	2007-11-28 21:31:04 UTC (rev 8319)
@@ -43,7 +43,6 @@
  ******************************************************* */
 
 
-/*! \file TMat_decl.h */
 
 #ifndef TVec_decl_INC
 #define TVec_decl_INC

Modified: trunk/plearn/math/TVec_impl.h
===================================================================
--- trunk/plearn/math/TVec_impl.h	2007-11-28 21:15:36 UTC (rev 8318)
+++ trunk/plearn/math/TVec_impl.h	2007-11-28 21:31:04 UTC (rev 8319)
@@ -43,7 +43,6 @@
  ******************************************************* */
 
 
-/*! \file TMat_impl.h */
 
 #ifndef TVec_impl_INC
 #define TVec_impl_INC

Modified: trunk/plearn/vmat/VariableDeletionVMatrix.h
===================================================================
--- trunk/plearn/vmat/VariableDeletionVMatrix.h	2007-11-28 21:15:36 UTC (rev 8318)
+++ trunk/plearn/vmat/VariableDeletionVMatrix.h	2007-11-28 21:31:04 UTC (rev 8319)
@@ -40,7 +40,6 @@
  ******************************************************************** */
 
 
-/*! \file VMat.h */
 
 #ifndef VariableDeletionVMatrix_INC
 #define VariableDeletionVMatrix_INC



From larocheh at mail.berlios.de  Wed Nov 28 22:34:02 2007
From: larocheh at mail.berlios.de (larocheh at BerliOS)
Date: Wed, 28 Nov 2007 22:34:02 +0100
Subject: [Plearn-commits] r8320 - trunk/plearn_learners_experimental
Message-ID: <200711282134.lASLY2je003446@sheep.berlios.de>

Author: larocheh
Date: 2007-11-28 22:34:02 +0100 (Wed, 28 Nov 2007)
New Revision: 8320

Modified:
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
Log:
Continuing to code...


Modified: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2007-11-28 21:31:04 UTC (rev 8319)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2007-11-28 21:34:02 UTC (rev 8320)
@@ -252,7 +252,6 @@
         if( k_neighbors <= 0 )
             PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
                     "k_neighbors should be > 0.\n");
-        test_nearest_neighbors_indices.resize(k_neighbors);
 
         if( weightsize_ > 0 )
             PLERROR("DeepNonLocalManifoldParzen::build_() - \n"
@@ -400,8 +399,6 @@
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
 
-    PLERROR("NOT IMPLEMENTED YET!");
-
     // deepCopyField(, copies);
 
     // Public options
@@ -409,37 +406,53 @@
     deepCopyField(layers, copies);
     deepCopyField(connections, copies);
     deepCopyField(reconstruction_connections, copies);
-    deepCopyField(unsupervised_layers, copies);
-    deepCopyField(unsupervised_connections, copies);
 
     // Protected options
     deepCopyField(activations, copies);
     deepCopyField(expectations, copies);
     deepCopyField(activation_gradients, copies);
     deepCopyField(expectation_gradients, copies);
-    deepCopyField(greedy_activation, copies);
-    deepCopyField(greedy_expectation, copies);
-    deepCopyField(greedy_activation_gradient, copies);
-    deepCopyField(greedy_expectation_gradient, copies);
     deepCopyField(reconstruction_activations, copies);
     deepCopyField(reconstruction_activation_gradients, copies);
     deepCopyField(reconstruction_expectation_gradients, copies);
     deepCopyField(output_connections, copies);
     deepCopyField(input_representation, copies);
     deepCopyField(previous_input_representation, copies);
-    deepCopyField(dissimilar_gradient_contribution, copies);
+    deepCopyField(all_outputs, copies);
+    deepCopyField(all_outputs_gradient, copies);
+    deepCopyField(F, copies);
+    deepCopyField(F_copy, copies);
+    deepCopyField(mu, copies);
+    deepCopyField(pre_sigma_noise, copies);
+    deepCopyField(Ut, copies);
+    deepCopyField(U, copies);
+    deepCopyField(V, copies);
+    deepCopyField(z, copies);
+    deepCopyField(invSigma_F, copies);
+    deepCopyField(invSigma_z, copies);
+    deepCopyField(temp_ncomp, copies);
+    deepCopyField(diff_neighbor_input, copies);
+    deepCopyField(sm_svd, copies);
+    deepCopyField(sn, copies);
+    deepCopyField(S, copies);
+    deepCopyField(uk, copies);
+    deepCopyField(fk, copies);
+    deepCopyField(uk2, copies);
+    deepCopyField(inv_sigma_zj, copies);
+    deepCopyField(zj, copies);
+    deepCopyField(inv_sigma_fk, copies);
+    deepCopyField(diff, copies);
     deepCopyField(pos_down_val, copies);
     deepCopyField(pos_up_val, copies);
     deepCopyField(neg_down_val, copies);
     deepCopyField(neg_up_val, copies);
+    deepCopyField(eigenvectors, copies);
+    deepCopyField(eigenvalues, copies);
+    deepCopyField(sigma_noises, copies);
+    deepCopyField(mus, copies);
     deepCopyField(class_datasets, copies);
-    deepCopyField(other_classes_proportions, copies);
     deepCopyField(nearest_neighbors_indices, copies);
-    deepCopyField(test_nearest_neighbors_indices, copies);
     deepCopyField(test_votes, copies);
-    deepCopyField(train_set_representations, copies);
-    deepCopyField(train_set_representations_vmat, copies);
-    deepCopyField(train_set_targets, copies);
     deepCopyField(greedy_stages, copies);
 }
 
@@ -758,65 +771,80 @@
     }
 }
 
-void DeepNonLocalManifoldParzen::fineTuningStep( 
-    const Vec& input, const Vec& target,
-    Vec& train_costs, Mat nearest_neighbors )
+void DeepNonLocalManifoldParzen::computeManifoldParzenParameters( 
+    const Vec& input, Mat& F, Vec& mu, 
+    Vec& pre_sigma_noise, Mat& U, Vec& sm_svd) const
 {
-    manifold_parzen_parameters_are_up_to_date = false;
-
     // Get example representation
-
     computeRepresentation(input, input_representation, 
                           n_layers-1);
 
-    F = all_outputs.subVec(0,n_components * inputsize()).toMat(
+    // Get parameters
+    output_connections->fprop( input_representation, all_outputs );
+
+    F.resize(n_components, inputsize());
+    mu.resize(inputsize());
+    pre_sigma_noise.resize(1);
+
+    F << all_outputs.subVec(0,n_components * inputsize()).toMat(
         n_components, inputsize());
-    F_copy.resize(F.length(), F.width());
-    mu = all_outputs.subVec(n_components * inputsize(),inputsize());
-    pre_sigma_noise = all_outputs.subVec( n_components * (inputsize() + 1), 1 );
+    mu << all_outputs.subVec(n_components * inputsize(),inputsize());
+    pre_sigma_noise << all_outputs.subVec( n_components * (inputsize() + 1), 1 );
 
-    output_connections->fprop( input_representation, all_outputs );
-    real sigma_noise = square(sigma_noise, 2) + min_sigma_noise;
-
     F_copy.resize(F.length(),F.width());
     sm_svd.resize(n_components);
     // N.B. this is the SVD of F'
     F_copy << F;
     lapackSVD(F_copy, Ut, S, V,'A',1.5);
-    for (int k=0;k<ncomponents;k++)
+    U.resize(n_components,inputsize());
+    for (int k=0;k<n_components;k++)
     {
         sm_svd[k] = mypow(S[k],2);
         U(k) << Ut(k);
     }
+}
 
+
+void DeepNonLocalManifoldParzen::fineTuningStep( 
+    const Vec& input, const Vec& target,
+    Vec& train_costs, Mat nearest_neighbors )
+{
+    manifold_parzen_parameters_are_up_to_date = false;
+
+    computeManifoldParzenParameters( input, F, mu, pre_sigma_noise, U, sm_svd );
+
+    real sigma_noise = square(pre_sigma_noise[0], 2) + min_sigma_noise;
+
     real mahal = 0;
     real norm_term = 0;
     real dotp = 0;
     real coef = 0;
+    real n = inputsize();
+    inv_Sigma_z.resize(inputsize());
     inv_Sigma_z.clear();
     real tr_inv_Sigma = 0;
     train_costs.last() = 0;
-    for(int j=0; j<nneighbors;j++)
+    for(int j=0; j<k_neighbors;j++)
     {
         zj = z(j);
-        substract(neighbors(j),input,diff_neighbor_input); 
+        substract(nearest_neighbors(j),input,diff_neighbor_input); 
         substract(diff_neighbor_input,mu,zj); 
       
-        mahal = -0.5*pownorm(zj)/sn[0];      
-        norm_term = - n/2.0 * Log2Pi - 0.5*(n-ncomponents)*pl_log(sn[0]);
+        mahal = -0.5*pownorm(zj)/sigma_noise;      
+        norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*pl_log(sigma_noise);
 
         inv_sigma_zj = inv_Sigma_z(j);
         inv_sigma_zj << zj; 
-        inv_sigma_zj /= sn[0];
+        inv_sigma_zj /= sigma_noise;
 
         if(j==0)
-            tr_inv_Sigma = n/sn[0];
+            tr_inv_Sigma = n/sigma_noise;
 
-        for(int k=0; k<ncomponents; k++)
+        for(int k=0; k<n_components; k++)
         { 
             uk = U(k);
             dotp = dot(zj,uk);
-            coef = (1.0/(sm_svd[k]+sn[0]) - 1.0/sn[0]);
+            coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
             multiplyAcc(inv_sigma_zj,uk,dotp*coef);
             mahal -= square(dotp)*0.5*coef;
             norm_term -= 0.5*pl_log(sm_svd[k]);
@@ -829,24 +857,26 @@
 
     train_costs.last() / k_neighbors;
 
+    inv_Sigma_F.resize( n_components, inputsize() );
     inv_Sigma_F.clear();
-    for(int k=0; k<ncomponents; k++)
+    for(int k=0; k<n_components; k++)
     { 
         fk = F(k);
         inv_sigma_fk = inv_Sigma_F(k);
         inv_sigma_fk << fk;
-        inv_sigma_fk /= sn[0];
-        for(int k2=0; k2<ncomponents;k2++)
+        inv_sigma_fk /= sigma_noise;
+        for(int k2=0; k2<n_components;k2++)
         {
             uk2 = U(k2);
             multiplyAcc(inv_sigma_fk,uk2,
-                        (1.0/(sm_svd[k2]+sn[0]) - 1.0/sn[0])*dot(fk,uk2));
+                        (1.0/(sm_svd[k2]+sigma_noise) - 1.0/sigma_noise)*
+                        dot(fk,uk2));
         }
     }
 
     all_outputs_gradient.clear();
     real coef = 1/train_set->length();
-    for(int neighbor=0; neighbor<nneighbors; neighbor++)
+    for(int neighbor=0; neighbor<k_neighbors; neighbor++)
     {
         // dNLL/dF
         product(temp_ncomp,F,inv_Sigma_z(neighbor));
@@ -935,24 +965,106 @@
 
 void DeepNonLocalManifoldParzen::computeOutput(const Vec& input, Vec& output) const
 {
-    updateTrainSetRepresentations();
+    test_votes.resize(n_classes);
+    test_votes.clear();
 
-    // Penser aux variables
-    // - ..._are_up_to_date
-    // - save_manifold_parzen...
+    // Variables for probability computations
+    real log_p_x_g_y = 0;
+    real mahal = 0;
+    real norm_term = 0;
+    real n = inputsize();
+    real dotp = 0;
+    real coef = 0;
+    real sigma_noise = 0;
+    
+    Vec input_j(inputsize());
+    Vec target(targetsize());
+    real weight;
 
-    computeRepresentation(input,input_representation, 
-                          min(currently_trained_layer,n_layers-1));
+    if( save_manifold_parzen_parameters )
+    {
+        updateManifoldParzenParameters();
 
-    computeNearestNeighbors(train_set_representations_vmat,input_representation,
-                            test_nearest_neighbors_indices);
+        int input_j_index;
+        for( int i=0; i<n_classes; i++ )
+        {
+            for( int j=0; j<class_datasets[i]->length(); j++ )
+            {
+                class_datasets[i]->getExample(input_j,target,weight);
 
-    test_votes.clear();
-    for(int i=0; i<test_nearest_neighbors_indices.length(); i++)
-        test_votes[train_set_targets[test_nearest_neighbors_indices[i]]]++;
+                input_j_index = class_datasets[i]->indices[j];
+                U << eigenvectors[input_j_index];
+                sm_svd << eigenvalues[input_j_index];
+                sigma_noise = sigma_noises[input_j_index];
+                mu << mus[input_j_index];
 
+                substract(input,input_j,diff_neighbor_input); 
+                substract(diff_neighbor_input,mu,diff); 
+                    
+                mahal = -0.5*pownorm(diff)/sigma_noise;      
+                norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*
+                    pl_log(sigma_noise);
+
+                for(int k=0; k<n_components; k++)
+                { 
+                    uk = U(k);
+                    dotp = dot(diff,uk);
+                    coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
+                    mahal -= square(dotp)*0.5*coef;
+                    norm_term -= 0.5*pl_log(sm_svd[k]);
+                }
+                
+                if( j==0 )
+                    log_p_x_g_y = norm_term + mahal;
+                else
+                    log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
+            }
+
+            test_votes[i] = log_p_x_g_y;
+        }
+    }
+    else
+    {
+
+        for( int i=0; i<n_classes; i++ )
+        {
+            for( int j=0; j<class_datasets[i]->length(); j++ )
+            {
+                class_datasets[i]->getExample(input_j,target,weight);
+
+                computeManifoldParzenParameters( input_j, F, mu, 
+                                                 pre_sigma_noise, U, sm_svd );
+                
+                sigma_noise = square(pre_sigma_noise[0], 2) + min_sigma_noise;
+                
+                substract(input,input_j,diff_neighbor_input); 
+                substract(diff_neighbor_input,mu,diff); 
+                    
+                mahal = -0.5*pownorm(diff)/sigma_noise;      
+                norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*
+                    pl_log(sigma_noise);
+
+                for(int k=0; k<n_components; k++)
+                { 
+                    uk = U(k);
+                    dotp = dot(diff,uk);
+                    coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
+                    mahal -= square(dotp)*0.5*coef;
+                    norm_term -= 0.5*pl_log(sm_svd[k]);
+                }
+                
+                if( j==0 )
+                    log_p_x_g_y = norm_term + mahal;
+                else
+                    log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
+            }
+
+            test_votes[i] = log_p_x_g_y;
+        }
+    }
+
+
     output[0] = argmax(test_votes);
-
 }
 
 void DeepNonLocalManifoldParzen::computeCostsFromOutputs(const Vec& input, const Vec& output,
@@ -999,30 +1111,37 @@
 //////////
 // test //
 //////////
-void DeepNonLocalManifoldParzen::updateTrainSetRepresentations() const
+void DeepNonLocalManifoldParzen::updateManifoldParzenParameters() const
 {
-    if(!train_set_representations_up_to_date)
+    if(!manifold_parzen_parameters_are_up_to_date)
     {
-        // Precompute training set examples' representation
-        int l = min(currently_trained_layer,n_layers-1);
+        // Precompute manifold parzen parameters
         Vec input( inputsize() );
         Vec target( targetsize() );
-        Vec train_set_representation;
         real weight;
 
-        train_set_representations.resize(train_set->length(), layers[l]->size);
-        train_set_targets.resize(train_set->length());
-        
-        for(int i=0; i<train_set->length(); i++)
+        eigenvectors.resize(train_set->length());
+        eigenvalues.resize(train_set->length(),n_components);
+        sigma_noises.resize(train_set->length());
+        mus.resize(train_set->length(), inputsize());
+
+        for( int i=0; i<train_set->length(); i++ )
         {
-            train_set->getExample(i,input,target,weight);
-            computeRepresentation(input,train_set_representation,l);
-            train_set_representations(i) << train_set_representation;
-            train_set_targets[i] = (int)round(target[0]);
+            train_set[i]->getExample(input,target,weight);
+
+            computeManifoldParzenParameters( input, F, mu, 
+                                             pre_sigma_noise, U, sm_svd );
+            
+            sigma_noise = square(pre_sigma_noise[0], 2) + min_sigma_noise;
+
+            eigenvectors[i].resize(n_components,inputsize());
+            eigenvectors[i] << U;
+            eigenvalues[i] << sm_svd;
+            sigma_noises[i] = sigma_noise;
+            mus[i] << mu;
         }
-        train_set_representations_vmat = VMat(train_set_representations);
-
-        train_set_representations_up_to_date = true;
+        
+        manifold_parzen_parameters_are_up_to_date = true;
     }
 }
 
@@ -1055,14 +1174,6 @@
     
     manifold_parzen_parameters_are_up_to_date = false;
 
-    if( save_manifold_parzen_parameters )
-    {
-        eigenvectors.resize(train_set->length());
-        eigenvalues.resize(train_set->length(),n_components);
-        sigma_noises.resize(train_set->length());
-        mus.resize(train_set->length(), inputsize());
-    }
-
     Vec input( inputsize() );
     Vec target( targetsize() );
     real weight; // unused
@@ -1078,16 +1189,16 @@
         class_datasets[k]->build();
     }
     
-    // Find other classes proportions
-    class_proportions.resize(n_classes);
-    class_proportions.fill(0);
-    real sum = 0;
-    for(int k=0; k<n_classes; k++)
-    {
-        class_proportions[k] = class_datasets[k]->length();
-        sum += class_datasets[k]->length();
-    }
-    class_proportions /= sum;
+    //// Find other classes proportions
+    //class_proportions.resize(n_classes);
+    //class_proportions.fill(0);
+    //real sum = 0;
+    //for(int k=0; k<n_classes; k++)
+    //{
+    //    class_proportions[k] = class_datasets[k]->length();
+    //    sum += class_datasets[k]->length();
+    //}
+    //class_proportions /= sum;
 }
 
 

Modified: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2007-11-28 21:31:04 UTC (rev 8319)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2007-11-28 21:34:02 UTC (rev 8320)
@@ -162,7 +162,7 @@
      *  Precomputes the representations of the training set examples, 
      *  to speed up nearest neighbors searches in that space.
      */
-    virtual void updateTrainSetRepresentations() const;
+    virtual void updateManifoldParzenParameters() const;
 
     //! Returns the names of the costs computed by computeCostsFromOutpus (and
     //! thus the test method).
@@ -191,6 +191,11 @@
     void computeRepresentation( const Vec& input, 
                                 Vec& representation, int layer) const;
 
+    void computeManifoldParzenParameters( const Vec& input, 
+                                          Mat& F, Vec& mu, Vec& pre_sigma_noise,
+                                          Mat& U, Vec& sm_svd) const;
+                                          
+
     //#####  PLearn::Object Protocol  #########################################
 
     // Declares other standard object methods.
@@ -251,14 +256,14 @@
     Vec all_outputs_gradient;
 
     //! Variables for density of a Gaussian
-    Mat F, F_copy;
-    Vec mu;
-    Vec pre_sigma_noise;
+    mutable Mat F, F_copy;
+    mutable Vec mu;
+    mutable Vec pre_sigma_noise;
 
     //! Variables for the SVD and gradient computation
-    Mat Ut, U, V, z, invSigma_F, invSigma_z;
-    Vec temp_ncomp, diff_neighbor_input, sm_svd, sn, S;
-    Vec uk, fk, uk2, inv_sigma_zj, zj, inv_sigma_fk;
+    mutable Mat Ut, U, V, z, invSigma_F, invSigma_z;
+    mutable Vec temp_ncomp, diff_neighbor_input, sm_svd, sn, S;
+    mutable Vec uk, fk, uk2, inv_sigma_zj, zj, inv_sigma_fk, diff;
 
     //! Positive down statistic
     Vec pos_down_val;
@@ -285,7 +290,7 @@
 
     //! Proportions of examples from the other classes (columns), for each
     //! class (rows)
-    Vec class_proportions;
+    //Vec class_proportions;
 
     //! Nearest neighbors for each training example
     TMat<int> nearest_neighbors_indices;
@@ -296,14 +301,6 @@
     //! Nearest neighbor votes for test example
     TVec<int> test_votes;
 
-    //! Data set mapped to last hidden layer space
-    mutable Mat train_set_representations;
-    mutable VMat train_set_representations_vmat;
-    mutable TVec<int> train_set_targets;
-
-    //! Indication that train_set_representations is up to date
-    mutable bool train_set_representations_up_to_date;
-
     //! Stages of the different greedy phases
     TVec<int> greedy_stages;
 



From nouiz at mail.berlios.de  Wed Nov 28 22:37:10 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 28 Nov 2007 22:37:10 +0100
Subject: [Plearn-commits] r8321 - in trunk: plearn_learners/classifiers
	plearn_learners/distributions plearn_learners/generic
	plearn_learners/generic/DEPRECATED plearn_learners/misc
	plearn_learners/regressors plearn_learners_experimental
Message-ID: <200711282137.lASLbA3N003650@sheep.berlios.de>

Author: nouiz
Date: 2007-11-28 22:37:09 +0100 (Wed, 28 Nov 2007)
New Revision: 8321

Modified:
   trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.cc
   trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.h
   trunk/plearn_learners/classifiers/MultiInstanceNNet.cc
   trunk/plearn_learners/distributions/GaussianDistribution.h
   trunk/plearn_learners/generic/DEPRECATED/Learner.h
   trunk/plearn_learners/generic/DEPRECATED/NeuralNet.cc
   trunk/plearn_learners/generic/DEPRECATED/NeuralNet.h
   trunk/plearn_learners/generic/DistRepNNet.cc
   trunk/plearn_learners/generic/DistRepNNet.h
   trunk/plearn_learners/generic/FeatureSetNNet.cc
   trunk/plearn_learners/generic/FeatureSetNNet.h
   trunk/plearn_learners/generic/NNet.cc
   trunk/plearn_learners/generic/NNet.h
   trunk/plearn_learners/generic/NeighborhoodSmoothnessNNet.cc
   trunk/plearn_learners/generic/PLearner.h
   trunk/plearn_learners/misc/VariableSelectionWithDirectedGradientDescent.h
   trunk/plearn_learners/regressors/BaseRegressorConfidence.h
   trunk/plearn_learners_experimental/FeatureSetSequentialCRF.cc
   trunk/plearn_learners_experimental/FeatureSetSequentialCRF.h
Log:
corrected comment for doxygen


Modified: trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.cc
===================================================================
--- trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -33,7 +33,6 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnAlgo/FeatureSetNaiveBayesClassifier.h */
 
 
 #include "FeatureSetNaiveBayesClassifier.h"

Modified: trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.h
===================================================================
--- trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/classifiers/FeatureSetNaiveBayesClassifier.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -33,7 +33,6 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnAlgo/FeatureSetNaiveBayesClassifier.h */
 
 #ifndef FeatureSetNaiveBayesClassifier_INC
 #define FeatureSetNaiveBayesClassifier_INC

Modified: trunk/plearn_learners/classifiers/MultiInstanceNNet.cc
===================================================================
--- trunk/plearn_learners/classifiers/MultiInstanceNNet.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/classifiers/MultiInstanceNNet.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id$
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/MultiInstanceNNet.h */
 
 
 #include <plearn/var/AffineTransformVariable.h>

Modified: trunk/plearn_learners/distributions/GaussianDistribution.h
===================================================================
--- trunk/plearn_learners/distributions/GaussianDistribution.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/distributions/GaussianDistribution.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -40,7 +40,6 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnAlgo/GaussianDistribution.h */
 
 #ifndef GaussianDistribution_INC
 #define GaussianDistribution_INC

Modified: trunk/plearn_learners/generic/DEPRECATED/Learner.h
===================================================================
--- trunk/plearn_learners/generic/DEPRECATED/Learner.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/DEPRECATED/Learner.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -43,7 +43,6 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnAlgo/Learner.h */
 
 #ifndef Learner_INC
 #define Learner_INC

Modified: trunk/plearn_learners/generic/DEPRECATED/NeuralNet.cc
===================================================================
--- trunk/plearn_learners/generic/DEPRECATED/NeuralNet.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/DEPRECATED/NeuralNet.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id$
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/NeuralNet.h */
 
 #include <plearn/var/AffineTransformVariable.h>
 #include <plearn/var/AffineTransformWeightPenalty.h>

Modified: trunk/plearn_learners/generic/DEPRECATED/NeuralNet.h
===================================================================
--- trunk/plearn_learners/generic/DEPRECATED/NeuralNet.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/DEPRECATED/NeuralNet.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id$
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/NeuralNet.h */
 
 #ifndef NeuralNet_INC
 #define NeuralNet_INC

Modified: trunk/plearn_learners/generic/DistRepNNet.cc
===================================================================
--- trunk/plearn_learners/generic/DistRepNNet.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/DistRepNNet.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id: DistRepNNet.cc 3994 2005-08-25 13:35:03Z chapados $
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/DistRepNNet.h */
 
 #include <plearn/var/SourceVariable.h>
 #include <plearn/var/VarRowsVariable.h>

Modified: trunk/plearn_learners/generic/DistRepNNet.h
===================================================================
--- trunk/plearn_learners/generic/DistRepNNet.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/DistRepNNet.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id: DistRepNNet.h 3994 2005-08-25 13:35:03Z chapados $
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/DistRepNNet.h */
 
 #ifndef DistRepNNet_INC
 #define DistRepNNet_INC

Modified: trunk/plearn_learners/generic/FeatureSetNNet.cc
===================================================================
--- trunk/plearn_learners/generic/FeatureSetNNet.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/FeatureSetNNet.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -33,7 +33,6 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnAlgo/FeatureSetNNet.h */
 
 
 #include "FeatureSetNNet.h"

Modified: trunk/plearn_learners/generic/FeatureSetNNet.h
===================================================================
--- trunk/plearn_learners/generic/FeatureSetNNet.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/FeatureSetNNet.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -33,7 +33,6 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnAlgo/FeatureSetNNet.h */
 
 #ifndef FeatureSetNNet_INC
 #define FeatureSetNNet_INC

Modified: trunk/plearn_learners/generic/NNet.cc
===================================================================
--- trunk/plearn_learners/generic/NNet.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/NNet.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id$
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/NNet.h */
 
 #include <plearn/var/AffineTransformVariable.h>
 #include <plearn/var/AffineTransformWeightPenalty.h>

Modified: trunk/plearn_learners/generic/NNet.h
===================================================================
--- trunk/plearn_learners/generic/NNet.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/NNet.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id$
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/NNet.h */
 
 #ifndef NNet_INC
 #define NNet_INC

Modified: trunk/plearn_learners/generic/NeighborhoodSmoothnessNNet.cc
===================================================================
--- trunk/plearn_learners/generic/NeighborhoodSmoothnessNNet.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/NeighborhoodSmoothnessNNet.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -38,7 +38,6 @@
  * $Id$
  ******************************************************* */
 
-/*! \file PLearnLibrary/PLearnAlgo/NeighborhoodSmoothnessNNet.h */
 
 
 #include <plearn/var/AffineTransformVariable.h>

Modified: trunk/plearn_learners/generic/PLearner.h
===================================================================
--- trunk/plearn_learners/generic/PLearner.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/generic/PLearner.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -44,7 +44,6 @@
  ******************************************************* */
 
 
-/*! \file PLearnLibrary/PLearnAlgo/PLearner.h */
 
 #ifndef PLearner_INC
 #define PLearner_INC

Modified: trunk/plearn_learners/misc/VariableSelectionWithDirectedGradientDescent.h
===================================================================
--- trunk/plearn_learners/misc/VariableSelectionWithDirectedGradientDescent.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/misc/VariableSelectionWithDirectedGradientDescent.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -39,7 +39,6 @@
  * This file is part of the PLearn library.                                                                   *
  ************************************************************************************************************** */
 
-/*! \file PLearnLibrary/PLearnAlgo/VariableSelectionWithDirectedGradientDescent.h */
 
 #ifndef VariableSelectionWithDirectedGradientDescent_INC
 #define VariableSelectionWithDirectedGradientDescent_INC

Modified: trunk/plearn_learners/regressors/BaseRegressorConfidence.h
===================================================================
--- trunk/plearn_learners/regressors/BaseRegressorConfidence.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners/regressors/BaseRegressorConfidence.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -39,7 +39,6 @@
  * This file is part of the PLearn library.                                     *
  ******************************************************************************** */
 
-/*! \file PLearnLibrary/PLearnAlgo/BaseRegressorConfidence.h */
 
 #ifndef BaseRegressorConfidence_INC
 #define BaseRegressorConfidence_INC

Modified: trunk/plearn_learners_experimental/FeatureSetSequentialCRF.cc
===================================================================
--- trunk/plearn_learners_experimental/FeatureSetSequentialCRF.cc	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners_experimental/FeatureSetSequentialCRF.cc	2007-11-28 21:37:09 UTC (rev 8321)
@@ -33,7 +33,6 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnAlgo/FeatureSetSequentialCRF.h */
 
 
 #include "FeatureSetSequentialCRF.h"

Modified: trunk/plearn_learners_experimental/FeatureSetSequentialCRF.h
===================================================================
--- trunk/plearn_learners_experimental/FeatureSetSequentialCRF.h	2007-11-28 21:34:02 UTC (rev 8320)
+++ trunk/plearn_learners_experimental/FeatureSetSequentialCRF.h	2007-11-28 21:37:09 UTC (rev 8321)
@@ -33,7 +33,6 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-/*! \file PLearnLibrary/PLearnAlgo/FeatureSetSequentialCRF.h */
 
 #ifndef FeatureSetSequentialCRF_INC
 #define FeatureSetSequentialCRF_INC



From nouiz at mail.berlios.de  Thu Nov 29 17:38:45 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 29 Nov 2007 17:38:45 +0100
Subject: [Plearn-commits] r8322 - trunk/speedtest
Message-ID: <200711291638.lATGcjx0020026@sheep.berlios.de>

Author: nouiz
Date: 2007-11-29 17:38:45 +0100 (Thu, 29 Nov 2007)
New Revision: 8322

Added:
   trunk/speedtest/Makefile
   trunk/speedtest/xgemm.cc
Log:
Added test programm that test matrix multiplication


Added: trunk/speedtest/Makefile
===================================================================
--- trunk/speedtest/Makefile	2007-11-28 21:37:09 UTC (rev 8321)
+++ trunk/speedtest/Makefile	2007-11-29 16:38:45 UTC (rev 8322)
@@ -0,0 +1,111 @@
+CC=g++
+CFLAGS=-Wall -fPIC -O3
+LIBCBLAS=~/CBLAS/lib/${OSARCH}/libcblas.a
+LIBBLAS=-lblas ${LIBCBLAS}
+LIBGOTO=-lgoto -lgfortran ${LIBCBLAS}
+LIBNVIDIA=-L/u/bastienf/NVIDIA_CUDA_SDK/cuda/lib -L/u/bastienf/NVIDIA_CUDA_SDK/lib/ -I/u/bastienf/NVIDIA_CUDA_SDK/cuda/include/ -lcuda -lcudart -lGL -lGLU -lcublas -l cutil
+ACMLBASE=/u/lisa/local/acml-3-6-1beta/gfortran64
+ACMLBASE=/u/lisa/local/acml-3-6-0/gfortran32
+
+LIBACML= ${LIBCBLAS} ${ACMLBASE}/lib/libacml.a -lgfortran
+LIBACMLPT= ${LIBCBLAS} ${ACMLBASE}_mp/lib/libacml_mp.a -lg2c -lgfortran
+LIBATLAS=-lcblas -lf77blas -latlas -lg2c
+LIBMKL=-lmkl -lvml ${LIBCBLAS}
+LIBMKLPT=-lmkl -lvml -lguide -lpthread ${LIBCBLAS}
+
+all: xgemm
+
+xgemm: xgemm-atlas xgemm-blas xgemm-blas-compare xgemm-goto xgemm-goto-compare xgemm-mkl xgemm-nvidia xgemm-nvidia-compare xgemm-cxgemm xgemm-sgemm-goto xgemm-dgemm-goto xgemm-sgemm-blas xgemm-dgemm-blas
+	true
+xgemm-sgemm: xgemm-sgemm-acml xgemm-sgemm-atlas xgemm-sgemm-blas xgemm-sgemm-c xgemm-sgemm-goto xgemm-sgemm-mkl xgemm-sgemm-nvidia
+
+xgemm-sgemm-acml: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBACML}
+
+xgemm-sgemm-acmlpt: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< -fopenmp ${LIBACMLPT}
+
+xgemm-sgemm-atlas: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBATLAS}
+
+xgemm-sgemm-blas: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBBLAS}
+
+xgemm-dgemm-blas: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBBLAS}
+
+xgemm-sgemm-blas-compare: xgemm.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBBLAS} -DCOMPARE
+
+xgemm-sgemm-c: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< -DCXGEMM 
+
+xgemm-dgemm-c: xgemm.c
+	${CC} ${CFLAGS} -o $@ $< -DCXGEMM -USEDOUBLE
+
+xgemm-sgemm-goto: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBGOTO}
+
+xgemm-dgemm-goto: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBGOTO}
+
+xgemm-sgemm-goto-compare: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< -DCOMPARE ${LIBGOTO}
+
+xgemm-sgemm-mkl: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBMKL}
+
+xgemm-sgemm-mklpt: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBMKLPT}
+
+xgemm-sgemm-nvidia: xgemm.c
+	${CC} ${CFLAGS} -m32 -o $@ -USEFLOAT $<  ${LIBNVIDIA} -DNVIDIA
+
+xgemm-sgemm-nvidia-compare: xgemm.c
+	${CC} ${CFLAGS} -m32 -o $@ -USEFLOAT $< ${LIBNVIDIA} -DNVIDIA -DCOMPARE
+
+xgemv: xgemv-blas xgemv-blas-compare xgemv-cxgemm xgemv-goto xgemv-goto-compare xgemv-nvidia xgemv-nvidia-compare xgemv-sgemv-goto xgemv-dgemv-goto xgemv-sgemv-blas xgemv-dgemv-blas
+	true
+
+clean-xgemv: 
+	rm -f xgemv xgemv-blas xgemv-blas-compare xgemv-cxgemm xgemv-goto xgemv-goto-compare xgemv-sgemv-goto xgemv-dgemv-goto xgemv-sgemv-blas xgemv-dgemv-blas
+
+xgemv-blas: xgemv.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBBLAS}
+
+xgemv-blas-compare: xgemv.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBBLAS} -DCOMPARE
+
+xgemv-goto: xgemv.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBGOTO}
+
+xgemv-goto-compare: xgemv.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBGOTO} -DCOMPARE
+
+xgemv-cxgemm: xgemv.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBBLAS} -DCXGEMV
+
+xgemv-nvidia: xgemv.c
+	${CC} ${CFLAGS} -m32 -o $@ $< ${LIBNVIDIA} -DNVIDIA
+
+xgemv-nvidia-compare: xgemv.c
+	${CC} ${CFLAGS} -m32 -o $@ $< ${LIBNVIDIA} -DNVIDIA -DCOMPARE
+
+xgemv-sgemv-goto: xgemv.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBGOTO}
+
+xgemv-dgemv-goto: xgemv.c
+	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBGOTO}
+
+xgemv-sgemv-blas: xgemv.c
+	${CC} ${CFLAGS} -o $@ $< ${LIBBLAS}
+
+xgemv-dgemv-blas: xgemv.c
+	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBBLAS}
+
+clean: clean-xgemv
+	rm -f xgemm-blas-compare xgemm-goto-compare xgemm-nvidia-compare xgemm-blas xgemm-goto xgemm-nvidia xgemm-cxgemm
+	rm -f xgemm-sgemm-goto xgemm-dgemm-goto xgemm-sgemm-blas xgemm-dgemm-blas
+	rm -f xgemm-acml xgemm-acmlpt xgemm-atlas xgemm-mkl xgemm-mklpt xgemv-nvidia xgemv-nvidia-compare
+
+

Added: trunk/speedtest/xgemm.cc
===================================================================
--- trunk/speedtest/xgemm.cc	2007-11-28 21:37:09 UTC (rev 8321)
+++ trunk/speedtest/xgemm.cc	2007-11-29 16:38:45 UTC (rev 8322)
@@ -0,0 +1,230 @@
+
+/* Includes, system */
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <math.h>
+
+#ifdef NVIDIA
+  /* Includes, cuda */
+  #include <cublas.h>
+#else
+  /* Includes, cblas */
+  #include <gsl/gsl_cblas.h>
+#endif
+#ifdef USEDOUBLE
+  typedef double real;
+  #define cblas_xgemm cblas_dgemm
+#elif USEFLOAT
+  typedef float real;
+  #define cblas_xgemm cblas_sgemm
+#endif
+//#include <iostream>
+//using namespace std;
+
+#if defined(CXGEMM) || defined(COMPARE)
+/* Host implementation of a simple version of sgemm */
+static void c_xgemm(int M, int N, int K, const real alpha, const real *A, 
+		  const real *B, const real beta, real *C)
+{
+  int i;
+  int j;
+  int k;
+  for (i = 0; i < M; ++i) {
+    for (j = 0; j < N; ++j) {
+      float prod = 0;
+      for (k = 0; k < K; ++k) {
+	prod += A[i * K + k] * B[k * N + j];
+      }
+      C[i * N + j] = alpha * prod + beta * C[i * N + j];
+    }
+  }
+}
+#endif
+/* Main */
+int main(int argc, char** argv)
+{    
+  if (argc!=5){ 
+    fprintf (stderr, "Usage: %s <sizeM> <sizeN> <sizeK> <Nb iter>\n",argv[0]); 
+    exit(0); 
+  } 
+  const int M=strtol(argv[1],0,0);
+  const int N=strtol(argv[2],0,0);
+  const int K=strtol(argv[3],0,0);
+  const int NBITER=strtol(argv[4],0,0);
+  const int NA= M * K;
+  const int NB= K * N;
+  const int NC= M * N;
+  real* h_A;
+  real* h_B;
+  real* h_C;
+  const real alpha = 1.0f;
+  const real beta = 0.0f;
+#ifdef NVIDIA
+  cublasStatus status;
+  real* d_A = 0;
+  real* d_B = 0;
+  real* d_C = 0;
+#endif
+
+#ifdef COMPARE
+  real* h_C_ref;
+  real error_norm;
+  real ref_norm;
+  real diff;
+#endif
+
+    /* Allocate host memory for the matrices */
+    h_A = (real*)malloc(NA * sizeof(h_A[0]));
+    if (h_A == 0) {
+        fprintf (stderr, "!!!! host memory allocation error (A)\n");
+        return EXIT_FAILURE;
+    }
+    h_B = (real*)malloc(NB * sizeof(h_B[0]));
+    if (h_B == 0) {
+        fprintf (stderr, "!!!! host memory allocation error (B)\n");
+        return EXIT_FAILURE;
+    }
+    h_C = (real*)malloc(NC * sizeof(h_C[0]));
+    if (h_C == 0) {
+        fprintf (stderr, "!!!! host memory allocation error (C)\n");
+        return EXIT_FAILURE;
+    }
+
+    for (int i = 0; i < NA; ++i) h_A[i] = M_PI+(real)i;
+    for (int i = 0; i < NB; ++i) h_B[i] = M_PI+(real)i;
+
+#ifdef NVIDIA
+    /* Initialize CUBLAS */
+    status = cublasInit();
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! CUBLAS initialization error\n");
+        return EXIT_FAILURE;
+    }
+    /* Allocate device memory for the matrices */
+    status = cublasAlloc(NA, sizeof(d_A[0]), (void**)&d_A);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! device memory allocation error (A)\n");
+        return EXIT_FAILURE;
+    }
+    status = cublasAlloc(NB, sizeof(d_B[0]), (void**)&d_B);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! device memory allocation error (B)\n");
+        return EXIT_FAILURE;
+    }
+    status = cublasAlloc(NC, sizeof(d_C[0]), (void**)&d_C);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! device memory allocation error (C)\n");
+        return EXIT_FAILURE;
+    }
+
+    /* Initialize the device matrices with the host matrices */
+    status = cublasSetVector(NA, sizeof(h_A[0]), h_A, 1, d_A, 1);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! device access error (write A)\n");
+        return EXIT_FAILURE;
+    }
+    status = cublasSetVector(NB, sizeof(h_B[0]), h_B, 1, d_B, 1);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! device access error (write B)\n");
+        return EXIT_FAILURE;
+    }
+    status = cublasSetVector(NC, sizeof(h_C[0]), h_C, 1, d_C, 1);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! device access error (write C)\n");
+        return EXIT_FAILURE;
+    }
+
+    /* Clear last error */
+    cublasGetError();
+#endif
+#ifdef COMPARE
+    /* Performs operation using plain C code */
+    for (int i=0;i<NBITER;i++)
+      c_xgemm(M,N,K, alpha, h_A, h_B, beta, h_C);
+    h_C_ref = h_C;
+    /* Allocate host memory for reading back the result from device memory */
+    h_C = (float*)malloc(NC * sizeof(h_C[0]));
+    if (h_C == 0) {
+        fprintf (stderr, "!!!! host memory allocation error (C)\n");
+        return EXIT_FAILURE;
+    }
+#endif
+#ifdef NVIDIA
+    /* Performs operation using cublas */
+    for (int i=0;i<NBITER;i++)
+      //We must Change the order of the parameter as cublas take
+      //matrix as colomn major and C matrix is row major
+      cublasSgemm('n', 'n', N, M, K, alpha, d_B, N, d_A, K, beta, d_C, N);
+
+    status = cublasGetError();
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! kernel execution error.\n");
+        return EXIT_FAILURE;
+    }
+    /* Read the result back */
+    status = cublasGetVector(NC, sizeof(h_C[0]), d_C, 1, h_C, 1);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! device access error (read C)\n");
+        return EXIT_FAILURE;
+    }
+#elif defined( CXGEMM )
+    for (int i=0;i<NBITER;i++)
+      c_xgemm(M,N,K, alpha, h_A, h_B, beta, h_C);
+#else
+    for (int i=0;i<NBITER;i++)
+      cblas_xgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, M,N,K, alpha, h_A, K, h_B, N, beta, h_C, N);
+#endif
+#ifdef COMPARE
+    /* Check result against reference */
+    error_norm = 0;
+    ref_norm = 0;
+    for (int i = 0; i < NC; ++i) {
+        diff = h_C_ref[i] - h_C[i];
+        error_norm += diff * diff;
+        ref_norm += h_C_ref[i] * h_C_ref[i];
+    }
+    error_norm = (float)sqrt((double)error_norm);
+    ref_norm = (float)sqrt((double)ref_norm);
+    if (fabs(ref_norm) < 1e-7) {
+        fprintf (stderr, "!!!! reference norm is 0\n");
+        return EXIT_FAILURE;
+    }
+    printf( "Test %s\n", (error_norm / ref_norm < 1e-6f) ? "PASSED" : "FAILED");
+#endif
+
+    /* Memory clean up */
+    free(h_A);
+    free(h_B);
+    free(h_C);
+
+#ifdef NVIDIA
+    status = cublasFree(d_A);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! memory free error (A)\n");
+        return EXIT_FAILURE;
+    }
+    status = cublasFree(d_B);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! memory free error (B)\n");
+        return EXIT_FAILURE;
+    }
+    status = cublasFree(d_C);
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! memory free error (C)\n");
+        return EXIT_FAILURE;
+    }
+
+    /* Shutdown */
+    status = cublasShutdown();
+    if (status != CUBLAS_STATUS_SUCCESS) {
+        fprintf (stderr, "!!!! shutdown error (A)\n");
+        return EXIT_FAILURE;
+    }
+#endif
+    //    if (argc <= 1 || strcmp(argv[1], "-noprompt")) {
+    //        printf("\nPress ENTER to exit...\n");
+    //        getchar();
+    //    }
+    return EXIT_SUCCESS;
+}



From nouiz at mail.berlios.de  Thu Nov 29 18:09:40 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 29 Nov 2007 18:09:40 +0100
Subject: [Plearn-commits] r8323 - trunk/speedtest
Message-ID: <200711291709.lATH9eaU022350@sheep.berlios.de>

Author: nouiz
Date: 2007-11-29 18:09:40 +0100 (Thu, 29 Nov 2007)
New Revision: 8323

Modified:
   trunk/speedtest/Makefile
Log:
correction


Modified: trunk/speedtest/Makefile
===================================================================
--- trunk/speedtest/Makefile	2007-11-29 16:38:45 UTC (rev 8322)
+++ trunk/speedtest/Makefile	2007-11-29 17:09:40 UTC (rev 8323)
@@ -1,24 +1,39 @@
 CC=g++
 CFLAGS=-Wall -fPIC -O3
-LIBCBLAS=~/CBLAS/lib/${OSARCH}/libcblas.a
+LIBCBLAS=~bastienf/.NOBACKUP/CBLAS/lib/${OSARCH}/libcblas.a
+
 LIBBLAS=-lblas ${LIBCBLAS}
 LIBGOTO=-lgoto -lgfortran ${LIBCBLAS}
-LIBNVIDIA=-L/u/bastienf/NVIDIA_CUDA_SDK/cuda/lib -L/u/bastienf/NVIDIA_CUDA_SDK/lib/ -I/u/bastienf/NVIDIA_CUDA_SDK/cuda/include/ -lcuda -lcudart -lGL -lGLU -lcublas -l cutil
+LIBATLAS=-lcblas -lf77blas -latlas -lg2c
+LIBMKL=-lmkl -lvml ${LIBCBLAS}
+LIBMKLPT=-lmkl -lvml -lguide -lpthread ${LIBCBLAS}
+
 ACMLBASE=/u/lisa/local/acml-3-6-1beta/gfortran64
 ACMLBASE=/u/lisa/local/acml-3-6-0/gfortran32
-
 LIBACML= ${LIBCBLAS} ${ACMLBASE}/lib/libacml.a -lgfortran
 LIBACMLPT= ${LIBCBLAS} ${ACMLBASE}_mp/lib/libacml_mp.a -lg2c -lgfortran
-LIBATLAS=-lcblas -lf77blas -latlas -lg2c
-LIBMKL=-lmkl -lvml ${LIBCBLAS}
-LIBMKLPT=-lmkl -lvml -lguide -lpthread ${LIBCBLAS}
+LIBNVIDIA=-L/u/bastienf/NVIDIA_CUDA_SDK/cuda/lib -L/u/bastienf/NVIDIA_CUDA_SDK/lib/ -I/u/bastienf/NVIDIA_CUDA_SDK/cuda/include/ -lcuda -lcudart -lGL -lGLU -lcublas -l cutil
 
 all: xgemm
 
-xgemm: xgemm-atlas xgemm-blas xgemm-blas-compare xgemm-goto xgemm-goto-compare xgemm-mkl xgemm-nvidia xgemm-nvidia-compare xgemm-cxgemm xgemm-sgemm-goto xgemm-dgemm-goto xgemm-sgemm-blas xgemm-dgemm-blas
+xgemm: xgemm-atlas xgemm-blas xgemm-goto xgemm-mkl xgemm-nvidia xgemm-cxgemm xgemm-sgemm-goto xgemm-dgemm-goto xgemm-sgemm-blas xgemm-dgemm-blas
 	true
+#xgemm-blas-compare xgemm-goto-compare xgemm-nvidia-compare
+
 xgemm-sgemm: xgemm-sgemm-acml xgemm-sgemm-atlas xgemm-sgemm-blas xgemm-sgemm-c xgemm-sgemm-goto xgemm-sgemm-mkl xgemm-sgemm-nvidia
 
+xgemm-atlas: xgemm-sgemm-atlas xgemm-dgemm-atlas
+
+xgemm-blas: xgemm-sgemm-blas xgemm-dgemm-blas
+
+xgemm-goto: xgemm-sgemm-goto xgemm-dgemm-goto
+
+xgemm-mkl: xgemm-sgemm-mkl xgemm-dgemm-mkl
+
+xgemm-nvidia: xgemm-sgemm-nvidia
+
+xgemm-cxgemm: xgemm-sgemm-c xgemm-dgemm-c
+
 xgemm-sgemm-acml: xgemm.c
 	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBACML}
 
@@ -28,6 +43,9 @@
 xgemm-sgemm-atlas: xgemm.c
 	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBATLAS}
 
+xgemm-dgemm-atlas: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBATLAS}
+
 xgemm-sgemm-blas: xgemm.c
 	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBBLAS}
 
@@ -53,6 +71,9 @@
 	${CC} ${CFLAGS} -o $@ -USEFLOAT $< -DCOMPARE ${LIBGOTO}
 
 xgemm-sgemm-mkl: xgemm.c
+	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBMKL}
+
+xgemm-dgemm-mkl: xgemm.c
 	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBMKL}
 
 xgemm-sgemm-mklpt: xgemm.c



From nouiz at mail.berlios.de  Thu Nov 29 18:31:07 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 29 Nov 2007 18:31:07 +0100
Subject: [Plearn-commits] r8324 - trunk/speedtest
Message-ID: <200711291731.lATHV71n026414@sheep.berlios.de>

Author: nouiz
Date: 2007-11-29 18:31:06 +0100 (Thu, 29 Nov 2007)
New Revision: 8324

Modified:
   trunk/speedtest/Makefile
   trunk/speedtest/xgemm.c
Log:
corrected the handling of float vs double


Modified: trunk/speedtest/Makefile
===================================================================
--- trunk/speedtest/Makefile	2007-11-29 17:09:40 UTC (rev 8323)
+++ trunk/speedtest/Makefile	2007-11-29 17:31:06 UTC (rev 8324)
@@ -35,55 +35,55 @@
 xgemm-cxgemm: xgemm-sgemm-c xgemm-dgemm-c
 
 xgemm-sgemm-acml: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBACML}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< ${LIBACML}
 
 xgemm-sgemm-acmlpt: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< -fopenmp ${LIBACMLPT}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< -fopenmp ${LIBACMLPT}
 
 xgemm-sgemm-atlas: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBATLAS}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< ${LIBATLAS}
 
 xgemm-dgemm-atlas: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBATLAS}
+	${CC} ${CFLAGS} -o $@ -DUSEDOUBLE $< ${LIBATLAS}
 
 xgemm-sgemm-blas: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBBLAS}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< ${LIBBLAS}
 
 xgemm-dgemm-blas: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBBLAS}
+	${CC} ${CFLAGS} -o $@ -DUSEDOUBLE $< ${LIBBLAS}
 
 xgemm-sgemm-blas-compare: xgemm.c
 	${CC} ${CFLAGS} -o $@ $< ${LIBBLAS} -DCOMPARE
 
 xgemm-sgemm-c: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< -DCXGEMM 
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< -DCXGEMM 
 
 xgemm-dgemm-c: xgemm.c
-	${CC} ${CFLAGS} -o $@ $< -DCXGEMM -USEDOUBLE
+	${CC} ${CFLAGS} -o $@ $< -DCXGEMM -DUSEDOUBLE
 
 xgemm-sgemm-goto: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBGOTO}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< ${LIBGOTO}
 
 xgemm-dgemm-goto: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBGOTO}
+	${CC} ${CFLAGS} -o $@ -DUSEDOUBLE $< ${LIBGOTO}
 
 xgemm-sgemm-goto-compare: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< -DCOMPARE ${LIBGOTO}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< -DCOMPARE ${LIBGOTO}
 
 xgemm-sgemm-mkl: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBMKL}
+	${CC} ${CFLAGS} -o $@ -DUSEDOUBLE $< ${LIBMKL}
 
 xgemm-dgemm-mkl: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBMKL}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< ${LIBMKL}
 
 xgemm-sgemm-mklpt: xgemm.c
-	${CC} ${CFLAGS} -o $@ -USEFLOAT $< ${LIBMKLPT}
+	${CC} ${CFLAGS} -o $@ -DUSEFLOAT $< ${LIBMKLPT}
 
 xgemm-sgemm-nvidia: xgemm.c
-	${CC} ${CFLAGS} -m32 -o $@ -USEFLOAT $<  ${LIBNVIDIA} -DNVIDIA
+	${CC} ${CFLAGS} -m32 -o $@ -DUSEFLOAT $<  ${LIBNVIDIA} -DNVIDIA
 
 xgemm-sgemm-nvidia-compare: xgemm.c
-	${CC} ${CFLAGS} -m32 -o $@ -USEFLOAT $< ${LIBNVIDIA} -DNVIDIA -DCOMPARE
+	${CC} ${CFLAGS} -m32 -o $@ -DUSEFLOAT $< ${LIBNVIDIA} -DNVIDIA -DCOMPARE
 
 xgemv: xgemv-blas xgemv-blas-compare xgemv-cxgemm xgemv-goto xgemv-goto-compare xgemv-nvidia xgemv-nvidia-compare xgemv-sgemv-goto xgemv-dgemv-goto xgemv-sgemv-blas xgemv-dgemv-blas
 	true
@@ -116,13 +116,13 @@
 	${CC} ${CFLAGS} -o $@ $< ${LIBGOTO}
 
 xgemv-dgemv-goto: xgemv.c
-	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBGOTO}
+	${CC} ${CFLAGS} -o $@ -DUSEDOUBLE $< ${LIBGOTO}
 
 xgemv-sgemv-blas: xgemv.c
 	${CC} ${CFLAGS} -o $@ $< ${LIBBLAS}
 
 xgemv-dgemv-blas: xgemv.c
-	${CC} ${CFLAGS} -o $@ -USEDOUBLE $< ${LIBBLAS}
+	${CC} ${CFLAGS} -o $@ -DUSEDOUBLE $< ${LIBBLAS}
 
 clean: clean-xgemv
 	rm -f xgemm-blas-compare xgemm-goto-compare xgemm-nvidia-compare xgemm-blas xgemm-goto xgemm-nvidia xgemm-cxgemm

Modified: trunk/speedtest/xgemm.c
===================================================================
--- trunk/speedtest/xgemm.c	2007-11-29 17:09:40 UTC (rev 8323)
+++ trunk/speedtest/xgemm.c	2007-11-29 17:31:06 UTC (rev 8324)
@@ -12,12 +12,14 @@
   /* Includes, cblas */
   #include <gsl/gsl_cblas.h>
 #endif
-#ifdef DOUBLE
+#ifdef USEDOUBLE
   typedef double real;
   #define cblas_xgemm cblas_dgemm
-#else
+#elif USEFLOAT
   typedef float real;
   #define cblas_xgemm cblas_sgemm
+#else
+  #error "USEDOUBLE or USEFLOAT must be defined"
 #endif
 //#include <iostream>
 //using namespace std;



From nouiz at mail.berlios.de  Thu Nov 29 18:32:23 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 29 Nov 2007 18:32:23 +0100
Subject: [Plearn-commits] r8325 - trunk/speedtest
Message-ID: <200711291732.lATHWNW7028314@sheep.berlios.de>

Author: nouiz
Date: 2007-11-29 18:32:17 +0100 (Thu, 29 Nov 2007)
New Revision: 8325

Removed:
   trunk/speedtest/xgemm.cc
Log:
removed duplicated file


Deleted: trunk/speedtest/xgemm.cc
===================================================================
--- trunk/speedtest/xgemm.cc	2007-11-29 17:31:06 UTC (rev 8324)
+++ trunk/speedtest/xgemm.cc	2007-11-29 17:32:17 UTC (rev 8325)
@@ -1,230 +0,0 @@
-
-/* Includes, system */
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <math.h>
-
-#ifdef NVIDIA
-  /* Includes, cuda */
-  #include <cublas.h>
-#else
-  /* Includes, cblas */
-  #include <gsl/gsl_cblas.h>
-#endif
-#ifdef USEDOUBLE
-  typedef double real;
-  #define cblas_xgemm cblas_dgemm
-#elif USEFLOAT
-  typedef float real;
-  #define cblas_xgemm cblas_sgemm
-#endif
-//#include <iostream>
-//using namespace std;
-
-#if defined(CXGEMM) || defined(COMPARE)
-/* Host implementation of a simple version of sgemm */
-static void c_xgemm(int M, int N, int K, const real alpha, const real *A, 
-		  const real *B, const real beta, real *C)
-{
-  int i;
-  int j;
-  int k;
-  for (i = 0; i < M; ++i) {
-    for (j = 0; j < N; ++j) {
-      float prod = 0;
-      for (k = 0; k < K; ++k) {
-	prod += A[i * K + k] * B[k * N + j];
-      }
-      C[i * N + j] = alpha * prod + beta * C[i * N + j];
-    }
-  }
-}
-#endif
-/* Main */
-int main(int argc, char** argv)
-{    
-  if (argc!=5){ 
-    fprintf (stderr, "Usage: %s <sizeM> <sizeN> <sizeK> <Nb iter>\n",argv[0]); 
-    exit(0); 
-  } 
-  const int M=strtol(argv[1],0,0);
-  const int N=strtol(argv[2],0,0);
-  const int K=strtol(argv[3],0,0);
-  const int NBITER=strtol(argv[4],0,0);
-  const int NA= M * K;
-  const int NB= K * N;
-  const int NC= M * N;
-  real* h_A;
-  real* h_B;
-  real* h_C;
-  const real alpha = 1.0f;
-  const real beta = 0.0f;
-#ifdef NVIDIA
-  cublasStatus status;
-  real* d_A = 0;
-  real* d_B = 0;
-  real* d_C = 0;
-#endif
-
-#ifdef COMPARE
-  real* h_C_ref;
-  real error_norm;
-  real ref_norm;
-  real diff;
-#endif
-
-    /* Allocate host memory for the matrices */
-    h_A = (real*)malloc(NA * sizeof(h_A[0]));
-    if (h_A == 0) {
-        fprintf (stderr, "!!!! host memory allocation error (A)\n");
-        return EXIT_FAILURE;
-    }
-    h_B = (real*)malloc(NB * sizeof(h_B[0]));
-    if (h_B == 0) {
-        fprintf (stderr, "!!!! host memory allocation error (B)\n");
-        return EXIT_FAILURE;
-    }
-    h_C = (real*)malloc(NC * sizeof(h_C[0]));
-    if (h_C == 0) {
-        fprintf (stderr, "!!!! host memory allocation error (C)\n");
-        return EXIT_FAILURE;
-    }
-
-    for (int i = 0; i < NA; ++i) h_A[i] = M_PI+(real)i;
-    for (int i = 0; i < NB; ++i) h_B[i] = M_PI+(real)i;
-
-#ifdef NVIDIA
-    /* Initialize CUBLAS */
-    status = cublasInit();
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! CUBLAS initialization error\n");
-        return EXIT_FAILURE;
-    }
-    /* Allocate device memory for the matrices */
-    status = cublasAlloc(NA, sizeof(d_A[0]), (void**)&d_A);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! device memory allocation error (A)\n");
-        return EXIT_FAILURE;
-    }
-    status = cublasAlloc(NB, sizeof(d_B[0]), (void**)&d_B);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! device memory allocation error (B)\n");
-        return EXIT_FAILURE;
-    }
-    status = cublasAlloc(NC, sizeof(d_C[0]), (void**)&d_C);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! device memory allocation error (C)\n");
-        return EXIT_FAILURE;
-    }
-
-    /* Initialize the device matrices with the host matrices */
-    status = cublasSetVector(NA, sizeof(h_A[0]), h_A, 1, d_A, 1);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! device access error (write A)\n");
-        return EXIT_FAILURE;
-    }
-    status = cublasSetVector(NB, sizeof(h_B[0]), h_B, 1, d_B, 1);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! device access error (write B)\n");
-        return EXIT_FAILURE;
-    }
-    status = cublasSetVector(NC, sizeof(h_C[0]), h_C, 1, d_C, 1);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! device access error (write C)\n");
-        return EXIT_FAILURE;
-    }
-
-    /* Clear last error */
-    cublasGetError();
-#endif
-#ifdef COMPARE
-    /* Performs operation using plain C code */
-    for (int i=0;i<NBITER;i++)
-      c_xgemm(M,N,K, alpha, h_A, h_B, beta, h_C);
-    h_C_ref = h_C;
-    /* Allocate host memory for reading back the result from device memory */
-    h_C = (float*)malloc(NC * sizeof(h_C[0]));
-    if (h_C == 0) {
-        fprintf (stderr, "!!!! host memory allocation error (C)\n");
-        return EXIT_FAILURE;
-    }
-#endif
-#ifdef NVIDIA
-    /* Performs operation using cublas */
-    for (int i=0;i<NBITER;i++)
-      //We must Change the order of the parameter as cublas take
-      //matrix as colomn major and C matrix is row major
-      cublasSgemm('n', 'n', N, M, K, alpha, d_B, N, d_A, K, beta, d_C, N);
-
-    status = cublasGetError();
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! kernel execution error.\n");
-        return EXIT_FAILURE;
-    }
-    /* Read the result back */
-    status = cublasGetVector(NC, sizeof(h_C[0]), d_C, 1, h_C, 1);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! device access error (read C)\n");
-        return EXIT_FAILURE;
-    }
-#elif defined( CXGEMM )
-    for (int i=0;i<NBITER;i++)
-      c_xgemm(M,N,K, alpha, h_A, h_B, beta, h_C);
-#else
-    for (int i=0;i<NBITER;i++)
-      cblas_xgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, M,N,K, alpha, h_A, K, h_B, N, beta, h_C, N);
-#endif
-#ifdef COMPARE
-    /* Check result against reference */
-    error_norm = 0;
-    ref_norm = 0;
-    for (int i = 0; i < NC; ++i) {
-        diff = h_C_ref[i] - h_C[i];
-        error_norm += diff * diff;
-        ref_norm += h_C_ref[i] * h_C_ref[i];
-    }
-    error_norm = (float)sqrt((double)error_norm);
-    ref_norm = (float)sqrt((double)ref_norm);
-    if (fabs(ref_norm) < 1e-7) {
-        fprintf (stderr, "!!!! reference norm is 0\n");
-        return EXIT_FAILURE;
-    }
-    printf( "Test %s\n", (error_norm / ref_norm < 1e-6f) ? "PASSED" : "FAILED");
-#endif
-
-    /* Memory clean up */
-    free(h_A);
-    free(h_B);
-    free(h_C);
-
-#ifdef NVIDIA
-    status = cublasFree(d_A);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! memory free error (A)\n");
-        return EXIT_FAILURE;
-    }
-    status = cublasFree(d_B);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! memory free error (B)\n");
-        return EXIT_FAILURE;
-    }
-    status = cublasFree(d_C);
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! memory free error (C)\n");
-        return EXIT_FAILURE;
-    }
-
-    /* Shutdown */
-    status = cublasShutdown();
-    if (status != CUBLAS_STATUS_SUCCESS) {
-        fprintf (stderr, "!!!! shutdown error (A)\n");
-        return EXIT_FAILURE;
-    }
-#endif
-    //    if (argc <= 1 || strcmp(argv[1], "-noprompt")) {
-    //        printf("\nPress ENTER to exit...\n");
-    //        getchar();
-    //    }
-    return EXIT_SUCCESS;
-}



From tihocan at mail.berlios.de  Thu Nov 29 21:49:47 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Thu, 29 Nov 2007 21:49:47 +0100
Subject: [Plearn-commits] r8326 - trunk/plearn/vmat
Message-ID: <200711292049.lATKnl7r021502@sheep.berlios.de>

Author: tihocan
Date: 2007-11-29 21:49:46 +0100 (Thu, 29 Nov 2007)
New Revision: 8326

Modified:
   trunk/plearn/vmat/SubVMatrix.cc
Log:
Fixed dangerous bug in getString

Modified: trunk/plearn/vmat/SubVMatrix.cc
===================================================================
--- trunk/plearn/vmat/SubVMatrix.cc	2007-11-29 17:32:17 UTC (rev 8325)
+++ trunk/plearn/vmat/SubVMatrix.cc	2007-11-29 20:49:46 UTC (rev 8326)
@@ -306,7 +306,7 @@
     if(row<0 || row>=length() || col<0 || col>=width())
         PLERROR("In SubVMatrix::getString(): OUT OF BOUND access");
 #endif
-    return source->getString(row, jstart+col); 
+    return source->getString(row + istart, jstart+col); 
 }
 
 void SubVMatrix::getMat(int i, int j, Mat m) const



From tihocan at mail.berlios.de  Thu Nov 29 21:50:52 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Thu, 29 Nov 2007 21:50:52 +0100
Subject: [Plearn-commits] r8327 - trunk/plearn/misc
Message-ID: <200711292050.lATKoqWd021665@sheep.berlios.de>

Author: tihocan
Date: 2007-11-29 21:50:51 +0100 (Thu, 29 Nov 2007)
New Revision: 8327

Modified:
   trunk/plearn/misc/vmatmain.cc
Log:
When converting to .amat, string mappings are now explicitely saved as strings so they are not lost in the conversion

Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2007-11-29 20:49:46 UTC (rev 8326)
+++ trunk/plearn/misc/vmatmain.cc	2007-11-29 20:50:51 UTC (rev 8327)
@@ -596,7 +596,8 @@
                       ext.c_str());
 
         if(ext==".amat")
-            vm->saveAMAT(destination);
+            // Save strings as strings so they are not lost.
+            vm->saveAMAT(destination, true, false, true);
         else if(ext==".pmat")
             vm->savePMAT(destination);
         else if(ext==".dmat")



From nouiz at mail.berlios.de  Thu Nov 29 22:50:11 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 29 Nov 2007 22:50:11 +0100
Subject: [Plearn-commits] r8328 - trunk/plearn_learners/regressors
Message-ID: <200711292150.lATLoBqf026435@sheep.berlios.de>

Author: nouiz
Date: 2007-11-29 22:50:10 +0100 (Thu, 29 Nov 2007)
New Revision: 8328

Modified:
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
Log:
if we have length==0, we should set the prediction to MISSING


Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-29 20:50:51 UTC (rev 8327)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2007-11-29 21:50:10 UTC (rev 8328)
@@ -157,8 +157,9 @@
 
 void RegressionTreeLeave::getOutputAndError(Vec& output, Vec& error)
 {
-    if(length==0){
+    if(length==0){        
         output.clear();
+        output[0]=MISSING_VALUE;
         error.clear();
         return;
     }



