<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8569 - trunk/plearn_learners/generic
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-February/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8569%20-%20trunk/plearn_learners/generic&In-Reply-To=%3C200802251653.m1PGrEKg026977%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002016.html">
   <LINK REL="Next"  HREF="002018.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8569 - trunk/plearn_learners/generic</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8569%20-%20trunk/plearn_learners/generic&In-Reply-To=%3C200802251653.m1PGrEKg026977%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8569 - trunk/plearn_learners/generic">tihocan at mail.berlios.de
       </A><BR>
    <I>Mon Feb 25 17:53:14 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002016.html">[Plearn-commits] r8568 - trunk/plearn/vmat
</A></li>
        <LI>Next message: <A HREF="002018.html">[Plearn-commits] r8570 - trunk/plearn/vmat
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2017">[ date ]</a>
              <a href="thread.html#2017">[ thread ]</a>
              <a href="subject.html#2017">[ subject ]</a>
              <a href="author.html#2017">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2008-02-25 17:53:13 +0100 (Mon, 25 Feb 2008)
New Revision: 8569

Modified:
   trunk/plearn_learners/generic/NNet.cc
Log:
The data is now stored in row vectors rather than column ones: this is to make it easier in the future to use bags of multiple inputs stored as row vectors of a matrix

Modified: trunk/plearn_learners/generic/NNet.cc
===================================================================
--- trunk/plearn_learners/generic/NNet.cc	2008-02-25 16:50:14 UTC (rev 8568)
+++ trunk/plearn_learners/generic/NNet.cc	2008-02-25 16:53:13 UTC (rev 8569)
@@ -55,6 +55,7 @@
 #include &lt;plearn/var/NegCrossEntropySigmoidVariable.h&gt;
 #include &lt;plearn/var/NegLogPoissonVariable.h&gt;
 #include &lt;plearn/var/OneHotSquaredLoss.h&gt;
+#include &lt;plearn/var/ProductVariable.h&gt;
 // #include &quot;RBFLayerVariable.h&quot; //TODO Put it back when the file exists.
 #include &lt;plearn/var/SigmoidVariable.h&gt;
 #include &lt;plearn/var/SoftmaxVariable.h&gt;
@@ -65,7 +66,6 @@
 #include &lt;plearn/var/SumSquareVariable.h&gt;
 #include &lt;plearn/var/TanhVariable.h&gt;
 #include &lt;plearn/var/TransposeVariable.h&gt;
-#include &lt;plearn/var/TransposeProductVariable.h&gt;
 #include &lt;plearn/var/UnaryHardSlopeVariable.h&gt;
 #include &lt;plearn/var/Var_operators.h&gt;
 #include &lt;plearn/var/Var_utils.h&gt;
@@ -429,7 +429,7 @@
             PLERROR(&quot;NNet: the option 'noutputs' must be specified&quot;);
 
         // Initialize the input.
-        input = Var(inputsize(), &quot;input&quot;);
+        input = Var(1, inputsize(), &quot;input&quot;);
 
         params.resize(0);
         Var before_transfer_func;
@@ -529,7 +529,7 @@
             costs[k] = onehot_squared_loss(the_output, the_target);
         else if (cost_funcs[k]==&quot;NLL&quot;) 
         {
-            if (the_output-&gt;size() == 1) {
+            if (the_output-&gt;width() == 1) {
                 // Assume sigmoid output here!
                 costs[k] = stable_cross_entropy(before_transfer_func, the_target);
             } else {
@@ -541,7 +541,7 @@
         } 
         else if (cost_funcs[k]==&quot;class_error&quot;)
         {
-            if (the_output-&gt;size()==1)
+            if (the_output-&gt;width()==1)
                 costs[k] = binary_classification_loss(the_output, the_target);
             else
                 costs[k] = classification_loss(the_output, the_target);
@@ -674,9 +674,9 @@
     if (train_set &amp;&amp; train_set-&gt;length() &gt;= the_input-&gt;width()) {
         Vec input, target;
         real weight;
-        for (int i = 0; i &lt; the_input-&gt;width(); i++) {
+        for (int i = 0; i &lt; the_input-&gt;length(); i++) {
             train_set-&gt;getExample(i, input, target, weight);
-            the_input-&gt;matValue.column(i) &lt;&lt; input;
+            the_input-&gt;matValue(i) &lt;&lt; input;
         }
     }
     output_and_target_to_cost-&gt;recomputeParents();
@@ -714,7 +714,7 @@
     }
     else if(nhidden&gt;0)
     {
-        w1 = Var(1 + the_input-&gt;size(), nhidden, &quot;w1&quot;);      
+        w1 = Var(1 + the_input-&gt;width(), nhidden, &quot;w1&quot;);      
         params.append(w1);
         hidden_layer = hiddenLayer(output, w1);
         output = hidden_layer;
@@ -725,7 +725,7 @@
     if(nhidden2&gt;0)
     {
         PLASSERT( !first_hidden_layer_is_output );
-        w2 = Var(1 + output.length(), nhidden2, &quot;w2&quot;);
+        w2 = Var(1 + output.width(), nhidden2, &quot;w2&quot;);
         params.append(w2);
         output = hiddenLayer(output, w2);
     }
@@ -757,13 +757,14 @@
 
     // Output layer before transfer function.
     if (!first_hidden_layer_is_output) {
-        wout = Var(1 + output-&gt;size(), outputsize(), &quot;wout&quot;);
+        wout = Var(1 + output-&gt;width(), outputsize(), &quot;wout&quot;);
         output = affine_transform(output, wout);
+        output-&gt;setName(&quot;output_activations&quot;);
         if (!fixed_output_weights)
             params.append(wout);
         else
         {
-            outbias = Var(output-&gt;size(), &quot;outbias&quot;);
+            outbias = Var(1, output-&gt;width(), &quot;outbias&quot;);
             output = output + outbias;
             params.append(outbias);
         }
@@ -780,8 +781,8 @@
     // Direct in-to-out layer.
     if(direct_in_to_out)
     {
-        wdirect = Var(the_input-&gt;size(), outputsize(), &quot;wdirect&quot;);
-        output += transposeProduct(wdirect, the_input);
+        wdirect = Var(the_input-&gt;width(), outputsize(), &quot;wdirect&quot;);
+        output += product(the_input, wdirect);
         params.append(wdirect);
         if (nhidden &lt;= 0)
             PLERROR(&quot;In NNet::buildOutputFromInput - It seems weird to use direct in-to-out connections if there is no hidden layer anyway&quot;);
@@ -853,7 +854,7 @@
     }
     if (input_reconstruction_penalty&gt;0)
     {
-        wrec = Var(1 + hidden_layer-&gt;size(),input-&gt;size(),&quot;wrec&quot;);
+        wrec = Var(1 + hidden_layer-&gt;width(),input-&gt;width(),&quot;wrec&quot;);
         predicted_input = affine_transform(hidden_layer, wrec);
         params.append(wrec);
         penalties.append(input_reconstruction_penalty*sumsquare(predicted_input - input));
@@ -864,7 +865,7 @@
 // buildTargetAndWeight //
 //////////////////////////
 void NNet::buildTargetAndWeight() {
-    target = Var(targetsize(), &quot;target&quot;);
+    target = Var(1, targetsize(), &quot;target&quot;);
     if(weightsize_&gt;0)
     {
         if (weightsize_!=1)
@@ -971,6 +972,7 @@
 /////////////////
 Var NNet::hiddenLayer(const Var&amp; input, const Var&amp; weights, string transfer_func) {
     Var hidden = affine_transform(input, weights); 
+    hidden-&gt;setName(&quot;hidden_layer_activations&quot;);
     Var result;
     if (transfer_func == &quot;default&quot;)
         transfer_func = hidden_transfer_func;


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002016.html">[Plearn-commits] r8568 - trunk/plearn/vmat
</A></li>
	<LI>Next message: <A HREF="002018.html">[Plearn-commits] r8570 - trunk/plearn/vmat
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2017">[ date ]</a>
              <a href="thread.html#2017">[ thread ]</a>
              <a href="subject.html#2017">[ subject ]</a>
              <a href="author.html#2017">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
