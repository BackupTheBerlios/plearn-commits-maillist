<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8579 - trunk/plearn/var
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-February/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8579%20-%20trunk/plearn/var&In-Reply-To=%3C200802261647.m1QGlKuH026962%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002026.html">
   <LINK REL="Next"  HREF="002028.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8579 - trunk/plearn/var</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8579%20-%20trunk/plearn/var&In-Reply-To=%3C200802261647.m1QGlKuH026962%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8579 - trunk/plearn/var">tihocan at mail.berlios.de
       </A><BR>
    <I>Tue Feb 26 17:47:20 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002026.html">[Plearn-commits] r8578 - trunk/plearn/var
</A></li>
        <LI>Next message: <A HREF="002028.html">[Plearn-commits] r8580 - trunk/plearn/var
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2027">[ date ]</a>
              <a href="thread.html#2027">[ thread ]</a>
              <a href="subject.html#2027">[ subject ]</a>
              <a href="author.html#2027">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2008-02-26 17:47:20 +0100 (Tue, 26 Feb 2008)
New Revision: 8579

Modified:
   trunk/plearn/var/LogAddVariable.cc
   trunk/plearn/var/LogAddVariable.h
Log:
- Implemented proper Object methods (build, deep copy, options, etc.)
- Added a new option to perform a logadd over the rows or columns of the first input, possibly controlling the range with the second input


Modified: trunk/plearn/var/LogAddVariable.cc
===================================================================
--- trunk/plearn/var/LogAddVariable.cc	2008-02-26 16:45:00 UTC (rev 8578)
+++ trunk/plearn/var/LogAddVariable.cc	2008-02-26 16:47:20 UTC (rev 8579)
@@ -50,75 +50,203 @@
 namespace PLearn {
 using namespace std;
 
-
-
-/** LogAddVariable **/
-
-
 PLEARN_IMPLEMENT_OBJECT(
         LogAddVariable,
         &quot;Stable computation of log(exp(input1) + exp(input2)).&quot;,
-        &quot;&quot;);
+        &quot;This Variable may be used:\n&quot;
+        &quot;   - with two inputs of the same sizes, to compute an element-wize\n&quot;
+        &quot;     logadd over both input matrices, or\n&quot;
+        &quot;   - with one matrix input (input1) and one scalar input (input2)\n&quot;
+        &quot;     to compute a vector logadd (i.e. log(exp(a1) + ... + exp(an)))\n&quot;
+        &quot;     over the first 'n' rows (or columns, depending on the option\n&quot;
+        &quot;     'vector_logadd'), where 'n' is an integer value provided by\n&quot;
+        &quot;     the input2 Variable. If input2 is not provided, then the\n&quot;
+        &quot;     logadd is performed over all rows/columns of input1.\n&quot;
+        &quot;Note that in order to use the second mechanism, one must change the\n&quot;
+        &quot;value of the 'vector_logadd' option, to remove any ambiguity, e.g\n&quot;
+        &quot;in the case of two scalar inputs.&quot;
+);
 
-LogAddVariable::LogAddVariable(Variable* input1, Variable* input2)
-    : inherited(input1, input2, input1-&gt;length(), input1-&gt;width())
+////////////////////
+// LogAddVariable //
+////////////////////
+LogAddVariable::LogAddVariable(Variable* input1, Variable* input2,
+                               const string&amp; vl,
+                               bool call_build_):
+    inherited(input1, input2,
+              vl == &quot;none&quot; || vl == &quot;per_row&quot; ? input1-&gt;length()
+                                              : 1,
+              vl == &quot;none&quot; || vl == &quot;per_column&quot; ? input1-&gt;width()
+                                                 : 1,
+              call_build_),
+    vector_logadd(vl),
+    vector_logadd_id(0)
 {
-    build_();
+    if (call_build_)
+        build_();
 }
 
-void
-LogAddVariable::build()
+////////////////////
+// declareOptions //
+////////////////////
+void LogAddVariable::declareOptions(OptionList&amp; ol)
 {
+    declareOption(ol, &quot;vector_logadd&quot;, &amp;LogAddVariable::vector_logadd,
+                  OptionBase::buildoption, 
+        &quot;Must be one of:\n&quot;
+        &quot;   - 'none'      : element-wize logadd over the two input matrices\n&quot;
+        &quot;   - 'per_column': vector logadd on each column of input1, using\n&quot;
+        &quot;                   the first 'n' rows as given by input2\n&quot;
+        &quot;   - 'per_row'   : vector logadd on each row of input1, using the\n&quot;
+        &quot;                   first 'n' columns as given by input2.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+///////////
+// build //
+///////////
+void LogAddVariable::build()
+{
     inherited::build();
     build_();
 }
 
-void
-LogAddVariable::build_()
+////////////
+// build_ //
+////////////
+void LogAddVariable::build_()
 {
-    if (input1 &amp;&amp; input2) {
-        if (input1-&gt;length() != input2-&gt;length()  ||  input1-&gt;width() != input2-&gt;width())
-            PLERROR(&quot;PLogPVariable LogAddVariable input1 and input2 must have the same size&quot;);
+    // Transform the string 'vector_logadd' into an integer for faster
+    // computations.
+    if (vector_logadd == &quot;none&quot;)
+        vector_logadd_id = 0;
+    else if (vector_logadd == &quot;per_row&quot;)
+        vector_logadd_id = 1;
+    else if (vector_logadd == &quot;per_column&quot;)
+        vector_logadd_id = -1;
+    else
+        PLERROR(&quot;In LogAddVariable::build_ - Invalid value for &quot;
+                &quot;'vector_logadd': %s&quot;, vector_logadd.c_str());
+    
+    if (!vector_logadd_id &amp;&amp; input1 &amp;&amp; input2) {
+        if (input1-&gt;length() != input2-&gt;length() ||
+            input1-&gt;width() != input2-&gt;width())
+            PLERROR(&quot;In LogAddVariable::build_ - input1 and input2 must &quot;
+                    &quot;have the same size&quot;);
     }
 }
 
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void LogAddVariable::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+    deepCopyField(work,     copies);
+    deepCopyField(work_ptr, copies);
+}
+///////////////////
+// recomputeSize //
+///////////////////
 void LogAddVariable::recomputeSize(int&amp; l, int&amp; w) const
 {
     if (input1) {
-        l = input1-&gt;length();
-        w = input1-&gt;width();
+        l = vector_logadd_id &gt;= 0 ? input1-&gt;length()
+                                  : 1;
+        w = vector_logadd_id &lt;= 0 ? input1-&gt;width()
+                                  : 1;
     } else
         l = w = 0;
 }
 
+///////////
+// fprop //
+///////////
 void LogAddVariable::fprop()
 {
-    // Ugly hack to make it compile with ICC.
+    if (!vector_logadd_id) {
+        // Ugly hack to make it compile with ICC.
 #ifdef __INTEL_COMPILER
-    PLearn::apply(input1-&gt;value,input2-&gt;value,value, logadd_for_icc);
+        PLearn::apply(input1-&gt;value, input2-&gt;value, value, logadd_for_icc);
 #else
-    PLearn::apply(input1-&gt;value,input2-&gt;value,value, logadd);
+        PLearn::apply(input1-&gt;value, input2-&gt;value, value, logadd);
 #endif
+    } else if (vector_logadd_id &gt; 0) {
+        int n = input2 ? int(round(input2-&gt;value[0]))
+                       : width();
+        for (int i = 0; i &lt; length(); i++) {
+            work_ptr = input1-&gt;matValue(i);
+            if (input2)
+                work_ptr = work_ptr.subVec(0, n);
+            value[i] = logadd(work_ptr);
+        }
+    } else {
+        int n = input2 ? int(round(input2-&gt;value[0]))
+                       : length();
+        work.resize(n);
+        for (int i = 0; i &lt; width(); i++) {
+            if (input2)
+                work &lt;&lt; input1-&gt;matValue.subMat(0, i, n, 1);
+            else
+                work &lt;&lt; input1-&gt;matValue.column(i);
+            value[i] = logadd(work);
+        }
+    }
 }
 
+///////////
+// bprop //
+///////////
 void LogAddVariable::bprop()
 {
-    Vec grad1(nelems());
-    grad1 = input1-&gt;value - value;
-    apply(grad1, grad1, safeexp);
-    input1-&gt;gradient += grad1%gradient;
-    // TODO Note that the '%' operator is inefficient.
+    if (!vector_logadd_id) {
+        // TODO Note that these computations are not efficient at all.
+        Vec grad1(nelems());
+        grad1 = input1-&gt;value - value;
+        apply(grad1, grad1, safeexp);
+        input1-&gt;gradient += grad1%gradient;
 
-    Vec grad2(nelems());
-    grad2 = input2-&gt;value - value;
-    apply(grad2, grad2, safeexp);
-    input2-&gt;gradient += grad2%gradient;
+        Vec grad2(nelems());
+        grad2 = input2-&gt;value - value;
+        apply(grad2, grad2, safeexp);
+        input2-&gt;gradient += grad2%gradient;
+    } else if (vector_logadd_id &gt; 0) {
+        int n = input2 ? int(round(input2-&gt;value[0]))
+                       : width();
+        work.resize(n);
+        for (int i = 0; i &lt; length(); i++) {
+            work &lt;&lt; input1-&gt;matValue.subMat(i, 0, 1, n);
+            work -= value[i];
+            apply(work, work, safeexp);
+            multiplyAcc(input1-&gt;matGradient.subMat(i, 0, 1, n).toVec(),
+                        work, gradient[i]);
+        }
+    } else {
+        int n = input2 ? int(round(input2-&gt;value[0]))
+                       : length();
+        work.resize(n);
+        for (int i = 0; i &lt; width(); i++) {
+            work &lt;&lt; input1-&gt;matValue.subMat(0, i, n, 1);
+            work -= value[i];
+            apply(work, work, safeexp);
+            work *= gradient[i];
+            input1-&gt;matGradient.subMat(0, i, n, 1) += work;
+        }
+    }
 }
 
+///////////////////
+// symbolicBprop //
+///////////////////
 void LogAddVariable::symbolicBprop()
 {
-    input1-&gt;accg(g * (exp(input1)/(exp(input1)+exp(input2))));
-    input2-&gt;accg(g * (exp(input2)/(exp(input1)+exp(input2))));
+    if (!vector_logadd_id) {
+        input1-&gt;accg(g * (exp(input1)/(exp(input1)+exp(input2))));
+        input2-&gt;accg(g * (exp(input2)/(exp(input1)+exp(input2))));
+    } else {
+        PLERROR(&quot;In LogAddVariable::symbolicBprop - Not implemented&quot;);
+    }
 }
 
 

Modified: trunk/plearn/var/LogAddVariable.h
===================================================================
--- trunk/plearn/var/LogAddVariable.h	2008-02-26 16:45:00 UTC (rev 8578)
+++ trunk/plearn/var/LogAddVariable.h	2008-02-26 16:47:20 UTC (rev 8579)
@@ -62,20 +62,46 @@
     typedef BinaryVariable inherited;
 
 public:
-    //!  Default constructor for persistence
+
+    string vector_logadd;
+
+    //! Default constructor.
     LogAddVariable() {}
-    LogAddVariable(Variable* input1, Variable* input2);
 
+    //! Convenience constructor.
+    LogAddVariable(Variable* input1, Variable* input2,
+                   const string&amp; the_vector_logadd = &quot;none&quot;,
+                   bool call_build_ = true);
+
     PLEARN_DECLARE_OBJECT(LogAddVariable);
 
     virtual void build();
 
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
     virtual void recomputeSize(int&amp; l, int&amp; w) const;  
     virtual void fprop();
     virtual void bprop();
     virtual void symbolicBprop();
 
 protected:
+
+    //! Integer coding for 'vector_logadd':
+    //!     0 &lt;-&gt; 'none'
+    //!    -1 &lt;-&gt; 'per_column'
+    //!    +1 &lt;-&gt; 'per_row'
+    int vector_logadd_id;
+
+    //! Temporary work vector.
+    Vec work;
+
+    //! Temporary work vector whose content must not be modified: it can only
+    //! be used to point to other data in memory.
+    Vec work_ptr;
+
+    static void declareOptions(OptionList &amp; ol);
+
+private:
     void build_();
 };
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002026.html">[Plearn-commits] r8578 - trunk/plearn/var
</A></li>
	<LI>Next message: <A HREF="002028.html">[Plearn-commits] r8580 - trunk/plearn/var
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2027">[ date ]</a>
              <a href="thread.html#2027">[ thread ]</a>
              <a href="subject.html#2027">[ subject ]</a>
              <a href="author.html#2027">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
