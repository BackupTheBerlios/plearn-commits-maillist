<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7856 - in trunk/python_modules/plearn: .	learners/autolr learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-July/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7856%20-%20in%20trunk/python_modules/plearn%3A%20.%0A%09learners/autolr%20learners/online&In-Reply-To=%3C200707281610.l6SGAZoo018082%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001303.html">
   <LINK REL="Next"  HREF="001305.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7856 - in trunk/python_modules/plearn: .	learners/autolr learners/online</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7856%20-%20in%20trunk/python_modules/plearn%3A%20.%0A%09learners/autolr%20learners/online&In-Reply-To=%3C200707281610.l6SGAZoo018082%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7856 - in trunk/python_modules/plearn: .	learners/autolr learners/online">yoshua at mail.berlios.de
       </A><BR>
    <I>Sat Jul 28 18:10:35 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001303.html">[Plearn-commits] r7855 - trunk/plearn/python
</A></li>
        <LI>Next message: <A HREF="001305.html">[Plearn-commits] r7857 - in trunk/plearn_learners/online: .	EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1304">[ date ]</a>
              <a href="thread.html#1304">[ thread ]</a>
              <a href="subject.html#1304">[ subject ]</a>
              <a href="author.html#1304">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-07-28 18:10:34 +0200 (Sat, 28 Jul 2007)
New Revision: 7856

Modified:
   trunk/python_modules/plearn/__init__.py
   trunk/python_modules/plearn/learners/autolr/__init__.py
   trunk/python_modules/plearn/learners/online/__init__.py
Log:
Transferred ifthenelse from online to plearn module.
Encapsulated getTestCostNames in a global function in autolr,
to allow redefining the set of costs measured on a learner.


Modified: trunk/python_modules/plearn/__init__.py
===================================================================
--- trunk/python_modules/plearn/__init__.py	2007-07-28 04:33:24 UTC (rev 7855)
+++ trunk/python_modules/plearn/__init__.py	2007-07-28 16:10:34 UTC (rev 7856)
@@ -3,3 +3,12 @@
 It shall englobe all and only python_modules that are relative to the
 original PLearn branch (vs LisaPLearn or apstatsoft).
 &quot;&quot;&quot;
+
+# generically useful things...
+
+def ifthenelse(cond,elsep,condp):
+    if cond:
+        return elsep
+    else:
+        return condp
+

Modified: trunk/python_modules/plearn/learners/autolr/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/autolr/__init__.py	2007-07-28 04:33:24 UTC (rev 7855)
+++ trunk/python_modules/plearn/learners/autolr/__init__.py	2007-07-28 16:10:34 UTC (rev 7856)
@@ -1,6 +1,6 @@
-
 from math import *
 from numarray import *
+from plearn import *
 from plearn.bridge import *
 from threading import *
 
@@ -93,14 +93,18 @@
         lock.release()
     return o
 
+def getTestCostNames(learner):
+    return learner.getTestCostNames()
+
 def testlearner(learner,dataset,costs=[],ts=None):
     if not ts:
         ts = pl.VecStatsCollector()
         if plearn.bridgemode.useserver:
             ts=learner.server.new(ts)
     learner.test(dataset,ts,0,0)
+    names = learner.getTestCostNames()
     del costs[:]
-    for k in range(len(learner.getTestCostNames())):
+    for k in range(len(names)):
         costs.append(ts.getStat(&quot;E[&quot;+str(k)+&quot;]&quot;))
     return costs
 
@@ -156,6 +160,7 @@
                         trainset, testsets, expdir,
                         cost_to_select_best=0,
                         selected_costnames = None,
+                        get_train_costs = True,
                         logfile=None):
     &quot;&quot;&quot;Train a learner with one or more schedules of learning rates.
 lr_options is a list of list of option strings. Each list in lr_options
@@ -168,7 +173,7 @@
 each of the other columns (just like the result of the call to merge_schedules).
 &quot;&quot;&quot;
     train_costnames = learner.getTrainCostNames()
-    test_costnames = learner.getTestCostNames()
+    test_costnames = getTestCostNames(learner)
 
     # Filter out unwanted costnames
     if selected_costnames is not None:
@@ -178,6 +183,8 @@
                            if name in selected_costnames ]
 
     n_train_costs = len(train_costnames)
+    if not get_train_costs:
+        n_train_costs = 0
     n_test_costs = len(test_costnames)
 
     learner.setTrainingSet(trainset,False)
@@ -204,26 +211,28 @@
         for s in range(n_schedules):
             results[i,1+s] = learning_rates[i][s]
 
-        # Report approximate training error
-        train_vsc = learner.getTrainStatsCollector()
-        if train_vsc.fieldnames == []:
-            # learner did not set train_stats fieldnames
-            train_vsc.fieldnames = learner.getTrainCostNames()
-        if logfile:
-            print &gt;&gt;logfile, &quot;At stage &quot;, learner.stage, &quot; train :&quot;,
-        for k, costname in zip(range(n_train_costs), train_costnames):
-            err = train_vsc.getStat('E['+costname+']')
-            results[i, k+1+n_schedules] = err
+        if get_train_costs:
+            # Report approximate training error
+            train_vsc = learner.getTrainStatsCollector()
+            if train_vsc.fieldnames == []:
+                # learner did not set train_stats fieldnames
+                train_vsc.fieldnames = learner.getTrainCostNames()
+        if get_train_costs:
             if logfile:
-                print &gt;&gt;logfile, costname, '=', err,
-            if plearn.bridgemode.interactive:
-                plot(   results[0:i+1, 0],
-                        results[0:i+1, 1+n_schedules+k],
-                        colors[k%7]+styles[0],
-                        label='train:'+costname)
-        if logfile:
-            print &gt;&gt;logfile
-            logfile.flush()
+                print &gt;&gt;logfile, &quot;At stage &quot;, learner.stage, &quot; train :&quot;,
+            for k, costname in zip(range(n_train_costs), train_costnames):
+                err = train_vsc.getStat('E['+costname+']')
+                results[i, k+1+n_schedules] = err
+                if logfile:
+                    print &gt;&gt;logfile, costname, '=', err,
+                if plearn.bridgemode.interactive:
+                    plot(   results[0:i+1, 0],
+                            results[0:i+1, 1+n_schedules+k],
+                            colors[k%7]+styles[0],
+                            label='train:'+costname)
+            if logfile:
+                print &gt;&gt;logfile
+                logfile.flush()
 
         # Report error on test sets
         for j in range(n_tests):
@@ -250,8 +259,11 @@
         if plearn.bridgemode.interactive and i==0:
             legend()
     # Return headers for the result matrix, and the results themselves
-    return (['stage', 'learning_rate']
-            + ['train.' + costname for costname in train_costnames]
+    train_names = []
+    if get_train_costs:
+        train_names = ['train.' + costname for costname in train_costnames]
+    return (['pstage', 'learning_rate']
+            + train_names
             + ['test'+str(j+1)+'.'+costname for j in range(n_tests)
                                             for costname in test_costnames],
             results)
@@ -360,7 +372,10 @@
                       min_epochs_to_delete = 2,
                       # Scaling coefficient when modifying learning rates
                       lr_steps=exp(log(10)/2),
+                      # file (or sys.stdout) where to report progress
                       logfile=None,
+                      # whether to get and report train costs
+                      get_train_costs=True,
                       # do not try to go below this learning rate
                       min_lr=1e-6,
                       # Learning rate interval for heuristic
@@ -416,8 +431,8 @@
             return False
         return True
 
-    train_costnames = learner.getTestCostNames()
-    test_costnames = learner.getTestCostNames()
+    train_costnames = learner.getTrainCostNames()
+    test_costnames = getTestCostNames(learner)
     if selected_costnames is not None:
         # Filter out unwanted costnames
         train_costnames = [ name for name in train_costnames
@@ -427,7 +442,7 @@
 
     n_tests = len(testsets)
     #n_costs = len(cost_indices)
-    n_train_costs = len(train_costnames)
+    n_train_costs = ifthenelse(get_train_costs,len(train_costnames),0)
     n_test_costs = len(test_costnames)
 
     if schedules:
@@ -441,9 +456,10 @@
         schedules = zeros([len(stages),2],Float)
         schedules[:,0]=stages
         schedules[:,1]=learning_rates[:,0]
-        if optimized_group != 0 and optimized_group != -1:
-            print &quot;Incorrect value for 'optimized_group'&quot;
-            raise Error
+        # YB: QUI A MIS CA? POURQUOI???
+        #if optimized_group != 0 and optimized_group != -1:
+        #    print &quot;Incorrect value for 'optimized_group'&quot;
+        #    raise Error
         if len(lr_options)!=1:
             lr_options=[lr_options[0]]
 
@@ -487,10 +503,11 @@
                         options[lr_option]=str(learning_rates[t,s])
             candidate.changeOptions(options)
             candidate.setTrainingSet(trainset,False)
-            train_vsc = pl.VecStatsCollector();
-            if plearn.bridgemode.useserver:
-                train_vsc = candidate.server.new(train_vsc)
-            candidate.setTrainStatsCollector(train_vsc)
+            if get_train_costs:
+                train_vsc = pl.VecStatsCollector();
+                if plearn.bridgemode.useserver:
+                    train_vsc = candidate.server.new(train_vsc)
+                candidate.setTrainStatsCollector(train_vsc)
             tasks = [('train', ())]
             stats = []
             for j in range(0,n_tests):
@@ -519,15 +536,16 @@
             results[t,1] = all_lr[active]
             if logfile:
                 print &gt;&gt;logfile, &quot;candidate &quot;,active,&quot;:&quot;,
-            # Report approximate training statistics
-            if logfile:
-                print &gt;&gt;logfile, 'train :',
-            ts=candidate.getTrainStatsCollector()
-            for k, costname in zip(range(n_train_costs), train_costnames):
-                err = ts.getStat('E['+costname+']')
-                results[t, 2+k] = err
+            if get_train_costs:
+                # Report approximate training statistics
                 if logfile:
-                    print &gt;&gt;logfile, costname, '=', err,
+                    print &gt;&gt;logfile, 'train :',
+                ts=candidate.getTrainStatsCollector()
+                for k, costname in zip(range(n_train_costs), train_costnames):
+                    err = ts.getStat('E['+costname+']')
+                    results[t, 2+k] = err
+                    if logfile:
+                        print &gt;&gt;logfile, costname, '=', err,
 
             # Report testing statistics
             for j, costs in zip(range(0,n_tests), stats):
@@ -571,9 +589,10 @@
             if logfile:
                 print &gt;&gt;logfile,&quot;BEST to now is candidate &quot;,best_active,&quot; with err=&quot;,best_err
                 print &gt;&gt;logfile, &quot;stage\tl.rate\t&quot;,
-                for costname in train_costnames:
-                    print &gt;&gt;logfile, 'train.'+costname+&quot;\t&quot;,
-                print &gt;&gt;logfile
+                if get_train_costs:
+                    for costname in train_costnames:
+                        print &gt;&gt;logfile, 'train.'+costname+&quot;\t&quot;,
+                    print &gt;&gt;logfile
                 for costname in test_costnames:
                     print &gt;&gt;logfile, 'test.'+costname+'\t',
                 print &gt;&gt;logfile

Modified: trunk/python_modules/plearn/learners/online/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/online/__init__.py	2007-07-28 04:33:24 UTC (rev 7855)
+++ trunk/python_modules/plearn/learners/online/__init__.py	2007-07-28 16:10:34 UTC (rev 7856)
@@ -1,15 +1,9 @@
 &quot;&quot;&quot;Code to define and manipulate online learning modules and related learners&quot;&quot;&quot;
 
 import plearn.bridgemode
+from plearn import *
 from plearn.bridge import *
 
-# THIS SHOULD GO SOMEWHERE ELSE!
-def ifthenelse(cond,elsep,condp):
-    if cond:
-        return elsep
-    else:
-        return condp
-
 def supervised_classification_mlp(name,input_size,n_hidden,n_classes,
                                   L1wd=0,L2wd=0,lrate=0.01):
     return pl.NetworkModule(name=name,


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001303.html">[Plearn-commits] r7855 - trunk/plearn/python
</A></li>
	<LI>Next message: <A HREF="001305.html">[Plearn-commits] r7857 - in trunk/plearn_learners/online: .	EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1304">[ date ]</a>
              <a href="thread.html#1304">[ thread ]</a>
              <a href="subject.html#1304">[ subject ]</a>
              <a href="author.html#1304">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
