<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6608 - in trunk: commands plearn_learners/online	plearn_learners/online/DEPRECATED
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-January/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6608%20-%20in%20trunk%3A%20commands%20plearn_learners/online%0A%09plearn_learners/online/DEPRECATED&In-Reply-To=%3C200701240621.l0O6LBuE012213%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000056.html">
   <LINK REL="Next"  HREF="000058.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6608 - in trunk: commands plearn_learners/online	plearn_learners/online/DEPRECATED</H1>
    <B>lamblin at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6608%20-%20in%20trunk%3A%20commands%20plearn_learners/online%0A%09plearn_learners/online/DEPRECATED&In-Reply-To=%3C200701240621.l0O6LBuE012213%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6608 - in trunk: commands plearn_learners/online	plearn_learners/online/DEPRECATED">lamblin at mail.berlios.de
       </A><BR>
    <I>Wed Jan 24 07:21:11 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000056.html">[Plearn-commits] r6607 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000058.html">[Plearn-commits] r6609 - in trunk: commands plearn_learners/online	plearn_learners/online/DEPRECATED
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#57">[ date ]</a>
              <a href="thread.html#57">[ thread ]</a>
              <a href="subject.html#57">[ subject ]</a>
              <a href="author.html#57">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: lamblin
Date: 2007-01-24 07:21:10 +0100 (Wed, 24 Jan 2007)
New Revision: 6608

Added:
   trunk/plearn_learners/online/DEPRECATED/StackedModulesModule.cc
   trunk/plearn_learners/online/DEPRECATED/StackedModulesModule.h
Removed:
   trunk/plearn_learners/online/StackedModulesModule.cc
   trunk/plearn_learners/online/StackedModulesModule.h
Modified:
   trunk/commands/plearn_light_inc.h
   trunk/commands/plearn_noblas_inc.h
   trunk/plearn_learners/online/ModulesLearner.h
Log:
Deprecate StackedModulesModules.
Please use ModuleStackModule (if you didn't use last_layer_is_cost),
ProcessInputCostModule or a combination of both (if you did).


Modified: trunk/commands/plearn_light_inc.h
===================================================================
--- trunk/commands/plearn_light_inc.h	2007-01-24 06:11:41 UTC (rev 6607)
+++ trunk/commands/plearn_light_inc.h	2007-01-24 06:21:10 UTC (rev 6608)
@@ -201,6 +201,8 @@
 #include &lt;plearn_learners/online/CostModule.h&gt;
 #include &lt;plearn_learners/online/DeepBeliefNet.h&gt;
 #include &lt;plearn_learners/online/GradNNetLayerModule.h&gt;
+#include &lt;plearn_learners/online/ModulesLearner.h&gt;
+#include &lt;plearn_learners/online/ModuleStackModule.h&gt;
 #include &lt;plearn_learners/online/NLLCostModule.h&gt;
 #include &lt;plearn_learners/online/NLLErrModule.h&gt;
 #include &lt;plearn_learners/online/OnlineLearningModule.h&gt;
@@ -217,8 +219,6 @@
 #include &lt;plearn_learners/online/RBMTruncExpLayer.h&gt;
 #include &lt;plearn_learners/online/SoftmaxModule.h&gt;
 #include &lt;plearn_learners/online/SquaredErrorCostModule.h&gt;
-#include &lt;plearn_learners/online/ModulesLearner.h&gt;
-#include &lt;plearn_learners/online/StackedModulesModule.h&gt;
 #include &lt;plearn_learners/online/Subsampling2DModule.h&gt;
 #include &lt;plearn_learners/online/Supersampling2DModule.h&gt;
 #include &lt;plearn_learners/online/TanhModule.h&gt;

Modified: trunk/commands/plearn_noblas_inc.h
===================================================================
--- trunk/commands/plearn_noblas_inc.h	2007-01-24 06:11:41 UTC (rev 6607)
+++ trunk/commands/plearn_noblas_inc.h	2007-01-24 06:21:10 UTC (rev 6608)
@@ -209,7 +209,6 @@
 #include &lt;plearn_learners/online/RBMTruncExpLayer.h&gt;
 #include &lt;plearn_learners/online/SoftmaxModule.h&gt;
 #include &lt;plearn_learners/online/SquaredErrorCostModule.h&gt;
-#include &lt;plearn_learners/online/StackedModulesModule.h&gt;
 #include &lt;plearn_learners/online/Subsampling2DModule.h&gt;
 #include &lt;plearn_learners/online/Supersampling2DModule.h&gt;
 #include &lt;plearn_learners/online/TanhModule.h&gt;

Copied: trunk/plearn_learners/online/DEPRECATED/StackedModulesModule.cc (from rev 6596, trunk/plearn_learners/online/StackedModulesModule.cc)

Copied: trunk/plearn_learners/online/DEPRECATED/StackedModulesModule.h (from rev 6596, trunk/plearn_learners/online/StackedModulesModule.h)
===================================================================
--- trunk/plearn_learners/online/StackedModulesModule.h	2007-01-23 20:43:54 UTC (rev 6596)
+++ trunk/plearn_learners/online/DEPRECATED/StackedModulesModule.h	2007-01-24 06:21:10 UTC (rev 6608)
@@ -0,0 +1,216 @@
+// -*- C++ -*-
+
+// StackedModulesModule.h
+//
+// Copyright (C) 2006 Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Lamblin
+
+/*! \file StackedModulesModule.h */
+
+
+#ifndef StackedModulesModule_INC
+#define StackedModulesModule_INC
+
+#include &lt;plearn_learners/online/OnlineLearningModule.h&gt;
+
+namespace PLearn {
+
+/**
+ * Wraps a stack of OnlineLearningModule, which are layers.
+ * The OnlineLearningModule's are disposed like superposed layers:
+ * outputs of module i are the inputs of module (i+1), the last layer is
+ * the output layer.
+ *
+ * @deprecated: use ../ModuleStackModule or ../ProcessInputCostModule instead
+ */
+class StackedModulesModule : public OnlineLearningModule
+{
+    typedef OnlineLearningModule inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! Underlying layers of the Module
+    TVec&lt; PP&lt;OnlineLearningModule&gt; &gt; modules;
+
+    //! Indicates if the last layer is a cost layer (taking input and target as
+    //! input, and outputing the cost we will minimize), allowing this module
+    //! to behave the same way.
+    bool last_layer_is_cost;
+
+    //! If last_layer_is_cost, the size of the target
+    int target_size;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    StackedModulesModule();
+
+    // Your other public member functions go here
+
+    //! given the input, compute the output (possibly resize it  appropriately)
+    virtual void fprop(const Vec&amp; input, Vec&amp; output) const;
+
+    //! Adapt based on the output gradient: this method should only
+    //! be called just after a corresponding fprop; it should be
+    //! called with the same arguments as fprop for the first two arguments
+    //! (and output should not have been modified since then).
+    //! Since sub-classes are supposed to learn ONLINE, the object
+    //! is 'ready-to-be-used' just after any bpropUpdate.
+    //! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS, WHICH
+    //! JUST CALLS
+    //!     bpropUpdate(input, output, input_gradient, output_gradient)
+    //! AND IGNORES INPUT GRADIENT.
+    // virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
+    //                          const Vec&amp; output_gradient);
+
+    //! this version allows to obtain the input gradient as well
+    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
+                             Vec&amp; input_gradient,
+                             const Vec&amp; output_gradient);
+
+    //! Similar to bpropUpdate, but adapt based also on the estimation
+    //! of the diagonal of the Hessian matrix, and propagates this
+    //! back. If these methods are defined, you can use them INSTEAD of
+    //! bpropUpdate(...)
+    //! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS,
+    //! WHICH JUST CALLS
+    //!     bbpropUpdate(input, output, input_gradient, output_gradient,
+    //!                  out_hess, in_hess)
+    //! AND IGNORES INPUT HESSIAN AND INPUT GRADIENT.
+    // virtual void bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
+    //                           const Vec&amp; output_gradient,
+    //                           const Vec&amp; output_diag_hessian);
+
+    //! this version allows to obtain the input gradient and diag_hessian
+    virtual void bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
+                              Vec&amp; input_gradient,
+                              const Vec&amp; output_gradient,
+                              Vec&amp; input_diag_hessian,
+                              const Vec&amp; output_diag_hessian);
+
+    //! reset the parameters to the state they would be BEFORE starting
+    //! training.  Note that this method is necessarily called from
+    //! build().
+    virtual void forget();
+
+
+    //! optionally perform some processing after training, or after a
+    //! series of fprop/bpropUpdate calls to prepare the model for truly
+    //! out-of-sample operation.  THE DEFAULT IMPLEMENTATION PROVIDED IN
+    //! THE SUPER-CLASS DOES NOT DO ANYTHING.
+    // virtual void finalize();
+
+    //! in case bpropUpdate does not do anything, make it known
+    //! THE DEFAULT IMPLEMENTATION PROVIDED IN THE SUPER-CLASS RETURNS false;
+    // virtual bool bpropDoesNothing();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(StackedModulesModule);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    //! Number of module layers
+    int nmodules;
+
+    //####  Not Options  ######################################################
+
+public: // hack
+    //! stores the input and output values of the functions
+    TVec&lt;Vec&gt; values;
+
+    //! stores the input of the last module, and the target if there is one
+    Vec cost_layer_input;
+
+    //! stores the gradients
+    TVec&lt;Vec&gt; gradients;
+
+    //! stores the diagonal of Hessians
+    TVec&lt;Vec&gt; diag_hessians;
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+
+    void buildOptions();
+    void buildLayers();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(StackedModulesModule);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Modified: trunk/plearn_learners/online/ModulesLearner.h
===================================================================
--- trunk/plearn_learners/online/ModulesLearner.h	2007-01-24 06:11:41 UTC (rev 6607)
+++ trunk/plearn_learners/online/ModulesLearner.h	2007-01-24 06:21:10 UTC (rev 6608)
@@ -53,8 +53,6 @@
  * In order to stack layers, you can use StackedModulesModule,
  * and in order to compute several costs, you can use CombinedCostsModule.
  *
- * @todo Finish this class...
- *
  */
 class ModulesLearner : public PLearner
 {

Deleted: trunk/plearn_learners/online/StackedModulesModule.cc
===================================================================
--- trunk/plearn_learners/online/StackedModulesModule.cc	2007-01-24 06:11:41 UTC (rev 6607)
+++ trunk/plearn_learners/online/StackedModulesModule.cc	2007-01-24 06:21:10 UTC (rev 6608)
@@ -1,303 +0,0 @@
-// -*- C++ -*-
-
-// StackedModulesModule.cc
-//
-// Copyright (C) 2006 Pascal Lamblin
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-//
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-//
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-//
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-//
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-// Authors: Pascal Lamblin
-
-/*! \file StackedModulesModule.cc */
-
-
-
-#include &quot;StackedModulesModule.h&quot;
-
-namespace PLearn {
-using namespace std;
-
-PLEARN_IMPLEMENT_OBJECT(
-    StackedModulesModule,
-    &quot;Wraps a stack of OnlineLearningModule, which are layers&quot;,
-    &quot;The OnlineLearningModule's are disposed like superposed layers:\n&quot;
-    &quot;outputs of module i are the inputs of module (i+1), the last layer is\n&quot;
-    &quot;the output layer.\n&quot;);
-
-StackedModulesModule::StackedModulesModule() :
-    last_layer_is_cost( false ),
-    target_size( 0 ),
-    nmodules( 0 )
-{
-}
-
-void StackedModulesModule::declareOptions(OptionList&amp; ol)
-{
-    /*
-    declareOption(ol, &quot;&quot;, &amp;StackedModulesModule::,
-                  OptionBase::buildoption,
-                  &quot;&quot;);
-     */
-    declareOption(ol, &quot;modules&quot;, &amp;StackedModulesModule::modules,
-                  OptionBase::buildoption,
-                  &quot;Underlying layers of the Module&quot;);
-
-    declareOption(ol, &quot;last_layer_is_cost&quot;,
-                  &amp;StackedModulesModule::last_layer_is_cost,
-                  OptionBase::buildoption,
-                  &quot;Indicates if the last layer is a cost layer (taking input&quot;
-                  &quot; and target\n&quot;
-                  &quot;as input, and outputing the cost we will minimize),&quot;
-                  &quot; allowing this\n&quot;
-                  &quot;module to behave the same way.\n&quot;);
-
-    declareOption(ol, &quot;target_size&quot;, &amp;StackedModulesModule::target_size,
-                  OptionBase::buildoption,
-                  &quot;If last_layer_is_cost, the size of the target&quot;);
-
-    declareOption(ol, &quot;nmodules&quot;, &amp;StackedModulesModule::nmodules,
-                  OptionBase::learntoption,
-                  &quot;Number of module layers&quot;);
-
-    // Now call the parent class' declareOptions
-    inherited::declareOptions(ol);
-}
-
-void StackedModulesModule::build_()
-{
-    // initialize random generator from seed
-    if( !random_gen )
-        random_gen = new PRandom();
-    else
-        random_gen-&gt;manual_seed( random_gen-&gt;seed_ );
-
-    // get some options
-    nmodules = modules.length();
-    if( nmodules == 0 )
-        return;
-
-    if( last_layer_is_cost &amp;&amp; target_size &lt;= 0 )
-        PLERROR(&quot;StackedModulesModule::build_() - Please provide a target_size&quot;
-                &quot;  &gt; 0\n&quot;
-                &quot;(is '%d').\n&quot;, target_size );
-    if( !last_layer_is_cost )
-        target_size = 0;
-
-    PLASSERT( modules[0]-&gt;input_size &gt;= 0 );
-    input_size = modules[0]-&gt;input_size + target_size;
-
-//    int last_module_output_size = modules[nmodules-1]-&gt;output_size;
-//    if( last_layer_is_cost )
-//        last_module_output_size = 1;
-
-    output_size = modules[nmodules-1]-&gt;output_size;
-
-    // build the modules
-    buildLayers();
-
-}
-
-void StackedModulesModule::buildLayers()
-{
-    // first values will be &quot;input&quot; values
-    int size = input_size - target_size;
-    values.resize( nmodules+1 );
-    values[0].resize( size );
-    gradients.resize( nmodules+1 );
-    gradients[0].resize( size );
-    // TODO: use it only if we actually use bbprop?
-    diag_hessians.resize( nmodules+1 );
-    diag_hessians[0].resize( size );
-
-    for( int i=0 ; i&lt;nmodules ; i++ )
-    {
-        modules[i]-&gt;estimate_simpler_diag_hessian =
-            estimate_simpler_diag_hessian;
-        modules[i]-&gt;random_gen = random_gen;
-        modules[i]-&gt;build();
-
-        size = modules[i]-&gt;output_size;
-        values[i+1].resize( size );
-        gradients[i+1].resize( size );
-        diag_hessians[i+1].resize( size );
-    }
-
-    // stores the input of the last module, and the target if there is one
-    cost_layer_input = values[nmodules-1];
-    if( last_layer_is_cost )
-        cost_layer_input.resize( cost_layer_input.size() + target_size );
-}
-
-void StackedModulesModule::build()
-{
-    inherited::build();
-    build_();
-}
-
-
-void StackedModulesModule::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
-{
-    inherited::makeDeepCopyFromShallowCopy(copies);
-
-    deepCopyField(modules, copies);
-    deepCopyField(values, copies);
-    deepCopyField(cost_layer_input, copies);
-    deepCopyField(gradients, copies);
-    deepCopyField(diag_hessians, copies);
-}
-
-//! given the input, compute the output (possibly resize it  appropriately)
-void StackedModulesModule::fprop(const Vec&amp; input, Vec&amp; output) const
-{
-    PLASSERT( input.size() == input_size );
-    PLASSERT( modules[0]-&gt;input_size + target_size == input_size );
-    int last_input_size = values[nmodules-1].size();
-
-    values[0] &lt;&lt; input.subVec(0, input_size - target_size );
-
-    for( int i=0 ; i&lt;nmodules-1 ; i++ )
-        modules[i]-&gt;fprop( values[i], values[i+1] );
-
-    if( last_layer_is_cost )
-    {
-        cost_layer_input.subVec( last_input_size, target_size )
-            &lt;&lt; input.subVec( input_size - target_size, target_size );
-    }
-
-    modules[nmodules-1]-&gt;fprop( cost_layer_input, values[nmodules] );
-    output.resize( output_size );
-    output &lt;&lt; values[ nmodules ];
-}
-
-//! this version allows to obtain the input gradient as well
-//! N.B. THE DEFAULT IMPLEMENTATION IN SUPER-CLASS JUST RAISES A PLERROR.
-void StackedModulesModule::bpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                                       Vec&amp; input_gradient,
-                                       const Vec&amp; output_gradient)
-{
-    // If last_layer_is_cost, the gradient wrt it is 1
-    if( last_layer_is_cost )
-        gradients[nmodules][0] = 1;
-    else
-        gradients[nmodules] &lt;&lt; output_gradient;
-
-    // values should have the values given by fprop(), so
-    // values[nmodules] should already be equal to output
-    modules[nmodules-1]-&gt;bpropUpdate( cost_layer_input, values[nmodules],
-                                      gradients[nmodules-1],
-                                      gradients[nmodules] );
-
-    for( int i=nmodules-2 ; i&gt;=0 ; i-- )
-        modules[i]-&gt;bpropUpdate( values[i], values[i+1],
-                                 gradients[i], gradients[i+1] );
-
-    input_gradient = gradients[0].copy();
-}
-
-//! reset the parameters to the state they would be BEFORE starting training.
-//! Note that this method is necessarily called from build().
-void StackedModulesModule::forget()
-{
-    random_gen-&gt;manual_seed( random_gen-&gt;seed_ );
-
-    // reset inputs
-    values[0].clear();
-    gradients[0].clear();
-    diag_hessians[0].clear();
-
-    // reset modules and outputs
-    for( int i=0 ; i&lt;nmodules ; i++ )
-    {
-        modules[i]-&gt;forget();
-        values[i+1].clear();
-        gradients[i+1].clear();
-        diag_hessians[i+1].clear();
-    }
-}
-
-/* THIS METHOD IS OPTIONAL
-//! reset the parameters to the state they would be BEFORE starting training.
-//! Note that this method is necessarily called from build().
-//! THE DEFAULT IMPLEMENTATION PROVIDED IN THE SUPER-CLASS DOES NOT DO
-//! ANYTHING.
-void StackedModulesModule::finalize()
-{
-}
-*/
-
-//! Similar to bpropUpdate, but adapt based also on the estimation
-//! of the diagonal of the Hessian matrix, and propagates this
-//! back. If these methods are defined, you can use them INSTEAD of
-//! bpropUpdate(...)
-//! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS, WHICH
-//! RAISES A PLERROR.
-void StackedModulesModule::bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                                        Vec&amp; input_gradient,
-                                        const Vec&amp; output_gradient,
-                                        Vec&amp; input_diag_hessian,
-                                        const Vec&amp; output_diag_hessian)
-{
-    // If last_layer_is_cost, the gradient wrt it is 1 and hessian is 0
-    if( last_layer_is_cost )
-    {
-        gradients[nmodules][0] = 1;
-        diag_hessians[nmodules][0] = 1;
-    }
-    else
-    {
-        gradients[nmodules] &lt;&lt; output_gradient;
-        diag_hessians[nmodules] &lt;&lt; output_diag_hessian;
-    }
-
-    // values should have the values given by fprop(), so
-    // values[nmodules] should already be equal to output
-    for( int i=nmodules-1 ; i&gt;=0 ; i-- )
-        modules[i]-&gt;bbpropUpdate( values[i], values[i+1],
-                                  gradients[i], gradients[i+1],
-                                  diag_hessians[i], diag_hessians[i+1] );
-
-    input_gradient = gradients[0].copy();
-    input_diag_hessian = diag_hessians[0].copy();
-}
-
-
-} // end of namespace PLearn
-
-
-/*
-  Local Variables:
-  mode:c++
-  c-basic-offset:4
-  c-file-style:&quot;stroustrup&quot;
-  c-file-offsets:((innamespace . 0)(inline-open . 0))
-  indent-tabs-mode:nil
-  fill-column:79
-  End:
-*/
-// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Deleted: trunk/plearn_learners/online/StackedModulesModule.h
===================================================================
--- trunk/plearn_learners/online/StackedModulesModule.h	2007-01-24 06:11:41 UTC (rev 6607)
+++ trunk/plearn_learners/online/StackedModulesModule.h	2007-01-24 06:21:10 UTC (rev 6608)
@@ -1,214 +0,0 @@
-// -*- C++ -*-
-
-// StackedModulesModule.h
-//
-// Copyright (C) 2006 Pascal Lamblin
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-//
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-//
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-//
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-//
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-// Authors: Pascal Lamblin
-
-/*! \file StackedModulesModule.h */
-
-
-#ifndef StackedModulesModule_INC
-#define StackedModulesModule_INC
-
-#include &lt;plearn_learners/online/OnlineLearningModule.h&gt;
-
-namespace PLearn {
-
-/**
- * Wraps a stack of OnlineLearningModule, which are layers.
- * The OnlineLearningModule's are disposed like superposed layers:
- * outputs of module i are the inputs of module (i+1), the last layer is
- * the output layer.
- */
-class StackedModulesModule : public OnlineLearningModule
-{
-    typedef OnlineLearningModule inherited;
-
-public:
-    //#####  Public Build Options  ############################################
-
-    //! ### declare public option fields (such as build options) here
-    //! Start your comments with Doxygen-compatible comments such as //!
-
-    //! Underlying layers of the Module
-    TVec&lt; PP&lt;OnlineLearningModule&gt; &gt; modules;
-
-    //! Indicates if the last layer is a cost layer (taking input and target as
-    //! input, and outputing the cost we will minimize), allowing this module
-    //! to behave the same way.
-    bool last_layer_is_cost;
-
-    //! If last_layer_is_cost, the size of the target
-    int target_size;
-
-public:
-    //#####  Public Member Functions  #########################################
-
-    //! Default constructor
-    // ### Make sure the implementation in the .cc
-    // ### initializes all fields to reasonable default values.
-    StackedModulesModule();
-
-    // Your other public member functions go here
-
-    //! given the input, compute the output (possibly resize it  appropriately)
-    virtual void fprop(const Vec&amp; input, Vec&amp; output) const;
-
-    //! Adapt based on the output gradient: this method should only
-    //! be called just after a corresponding fprop; it should be
-    //! called with the same arguments as fprop for the first two arguments
-    //! (and output should not have been modified since then).
-    //! Since sub-classes are supposed to learn ONLINE, the object
-    //! is 'ready-to-be-used' just after any bpropUpdate.
-    //! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS, WHICH
-    //! JUST CALLS
-    //!     bpropUpdate(input, output, input_gradient, output_gradient)
-    //! AND IGNORES INPUT GRADIENT.
-    // virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
-    //                          const Vec&amp; output_gradient);
-
-    //! this version allows to obtain the input gradient as well
-    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                             Vec&amp; input_gradient,
-                             const Vec&amp; output_gradient);
-
-    //! Similar to bpropUpdate, but adapt based also on the estimation
-    //! of the diagonal of the Hessian matrix, and propagates this
-    //! back. If these methods are defined, you can use them INSTEAD of
-    //! bpropUpdate(...)
-    //! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS,
-    //! WHICH JUST CALLS
-    //!     bbpropUpdate(input, output, input_gradient, output_gradient,
-    //!                  out_hess, in_hess)
-    //! AND IGNORES INPUT HESSIAN AND INPUT GRADIENT.
-    // virtual void bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
-    //                           const Vec&amp; output_gradient,
-    //                           const Vec&amp; output_diag_hessian);
-
-    //! this version allows to obtain the input gradient and diag_hessian
-    virtual void bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                              Vec&amp; input_gradient,
-                              const Vec&amp; output_gradient,
-                              Vec&amp; input_diag_hessian,
-                              const Vec&amp; output_diag_hessian);
-
-    //! reset the parameters to the state they would be BEFORE starting
-    //! training.  Note that this method is necessarily called from
-    //! build().
-    virtual void forget();
-
-
-    //! optionally perform some processing after training, or after a
-    //! series of fprop/bpropUpdate calls to prepare the model for truly
-    //! out-of-sample operation.  THE DEFAULT IMPLEMENTATION PROVIDED IN
-    //! THE SUPER-CLASS DOES NOT DO ANYTHING.
-    // virtual void finalize();
-
-    //! in case bpropUpdate does not do anything, make it known
-    //! THE DEFAULT IMPLEMENTATION PROVIDED IN THE SUPER-CLASS RETURNS false;
-    // virtual bool bpropDoesNothing();
-
-    //#####  PLearn::Object Protocol  #########################################
-
-    // Declares other standard object methods.
-    // ### If your class is not instantiatable (it has pure virtual methods)
-    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
-    PLEARN_DECLARE_OBJECT(StackedModulesModule);
-
-    // Simply calls inherited::build() then build_()
-    virtual void build();
-
-    //! Transforms a shallow copy into a deep copy
-    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
-
-protected:
-    //#####  Protected Options  ###############################################
-
-    //! Number of module layers
-    int nmodules;
-
-    //####  Not Options  ######################################################
-
-public: // hack
-    //! stores the input and output values of the functions
-    TVec&lt;Vec&gt; values;
-
-    //! stores the input of the last module, and the target if there is one
-    Vec cost_layer_input;
-
-    //! stores the gradients
-    TVec&lt;Vec&gt; gradients;
-
-    //! stores the diagonal of Hessians
-    TVec&lt;Vec&gt; diag_hessians;
-
-protected:
-    //#####  Protected Member Functions  ######################################
-
-    //! Declares the class options.
-    static void declareOptions(OptionList&amp; ol);
-
-private:
-    //#####  Private Member Functions  ########################################
-
-    //! This does the actual building.
-    void build_();
-
-    void buildOptions();
-    void buildLayers();
-
-private:
-    //#####  Private Data Members  ############################################
-
-    // The rest of the private stuff goes here
-};
-
-// Declares a few other classes and functions related to this class
-DECLARE_OBJECT_PTR(StackedModulesModule);
-
-} // end of namespace PLearn
-
-#endif
-
-
-/*
-  Local Variables:
-  mode:c++
-  c-basic-offset:4
-  c-file-style:&quot;stroustrup&quot;
-  c-file-offsets:((innamespace . 0)(inline-open . 0))
-  indent-tabs-mode:nil
-  fill-column:79
-  End:
-*/
-// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000056.html">[Plearn-commits] r6607 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000058.html">[Plearn-commits] r6609 - in trunk: commands plearn_learners/online	plearn_learners/online/DEPRECATED
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#57">[ date ]</a>
              <a href="thread.html#57">[ thread ]</a>
              <a href="subject.html#57">[ subject ]</a>
              <a href="author.html#57">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
