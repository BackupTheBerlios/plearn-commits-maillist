<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6585 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-January/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6585%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200701170414.l0H4EOb6002423%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000033.html">
   <LINK REL="Next"  HREF="000035.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6585 - trunk/plearn_learners/online</H1>
    <B>lamblin at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6585%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200701170414.l0H4EOb6002423%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6585 - trunk/plearn_learners/online">lamblin at mail.berlios.de
       </A><BR>
    <I>Wed Jan 17 05:14:24 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000033.html">[Plearn-commits] r6584 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000035.html">[Plearn-commits] r6586 - in trunk/python_modules/plearn/math: .	stats stats/.pytest stats/.pytest/PL_cvx_numpy_matrix_conversions	stats/.pytest/PL_cvx_numpy_matrix_conversions/expected_results
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#34">[ date ]</a>
              <a href="thread.html#34">[ thread ]</a>
              <a href="subject.html#34">[ subject ]</a>
              <a href="author.html#34">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: lamblin
Date: 2007-01-17 05:14:23 +0100 (Wed, 17 Jan 2007)
New Revision: 6585

Modified:
   trunk/plearn_learners/online/DeepBeliefNet.h
   trunk/plearn_learners/online/GradNNetLayerModule.cc
   trunk/plearn_learners/online/RBMBinomialLayer.cc
   trunk/plearn_learners/online/RBMBinomialLayer.h
   trunk/plearn_learners/online/RBMLayer.cc
   trunk/plearn_learners/online/RBMLayer.h
   trunk/plearn_learners/online/RBMMixedLayer.cc
   trunk/plearn_learners/online/RBMMixedLayer.h
   trunk/plearn_learners/online/RBMMultinomialLayer.cc
   trunk/plearn_learners/online/RBMMultinomialLayer.h
Log:
Remove trailing spaces (s/ +$//)


Modified: trunk/plearn_learners/online/DeepBeliefNet.h
===================================================================
--- trunk/plearn_learners/online/DeepBeliefNet.h	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/DeepBeliefNet.h	2007-01-17 04:14:23 UTC (rev 6585)
@@ -263,16 +263,16 @@
     mutable Vec pos_up_values;
 
     //! Keeps the index of the NLL cost in train_costs
-    int nll_cost_index; 
-    
-    //! Keeps the index of the CLASS cost in train_costs    
-    int class_cost_index; 
-    
+    int nll_cost_index;
+
+    //! Keeps the index of the CLASS cost in train_costs
+    int class_cost_index;
+
     //! Keeps the index of the final cost in train_costs
-    int final_cost_index; 
-    
+    int final_cost_index;
+
     //! Keeps the index of the reconstruction cost in train_costs
-    int recons_cost_index; 
+    int recons_cost_index;
 
 protected:
     //#####  Protected Member Functions  ######################################

Modified: trunk/plearn_learners/online/GradNNetLayerModule.cc
===================================================================
--- trunk/plearn_learners/online/GradNNetLayerModule.cc	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/GradNNetLayerModule.cc	2007-01-17 04:14:23 UTC (rev 6585)
@@ -154,7 +154,7 @@
 // Simply updates and propagates back gradient
 // PA - the original version of this function propagated the error to the inputs,
 // then called the above bpropUpdate() - this proved inefficient as the weight
-// matrix had to be iterated over twice. 
+// matrix had to be iterated over twice.
 // However, since we're not using blas anymore, the speedup is only when
 // compiled in optimized mode (ie debug is much slower).
 void GradNNetLayerModule::bpropUpdate(const Vec&amp; input, const Vec&amp; output,

Modified: trunk/plearn_learners/online/RBMBinomialLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMBinomialLayer.cc	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMBinomialLayer.cc	2007-01-17 04:14:23 UTC (rev 6585)
@@ -157,7 +157,7 @@
     }
 }
 
-void RBMBinomialLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+void RBMBinomialLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                            const Vec&amp; output,
                            Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                            const Vec&amp; output_gradient)
@@ -192,7 +192,7 @@
         expectation_i = expectation[i];
         if(!fast_exact_is_equal(target_i,0.0))
             ret -= target_i * pl_log(expectation_i);
-        if(!fast_exact_is_equal(target_i,1.0)) 
+        if(!fast_exact_is_equal(target_i,1.0))
             ret -= (1-target_i) * pl_log(1-expectation_i);
     }
     return ret;

Modified: trunk/plearn_learners/online/RBMBinomialLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMBinomialLayer.h	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMBinomialLayer.h	2007-01-17 04:14:23 UTC (rev 6585)
@@ -90,7 +90,7 @@
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
     //! forward propagation with provided bias
-    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,
                         Vec&amp; output ) const;
 
     //! back-propagates the output gradient to the input
@@ -98,15 +98,15 @@
                              Vec&amp; input_gradient, const Vec&amp; output_gradient);
 
     //! back-propagates the output gradient to the input and the bias
-    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                              const Vec&amp; output,
                              Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                              const Vec&amp; output_gradient) ;
 
-    //! Computes the negative log-likelihood of target given the 
+    //! Computes the negative log-likelihood of target given the
     //! internal activations of the layer
     virtual real fpropNLL(const Vec&amp; target);
-    
+
     //! Computes the gradient of the negative log-likelihood of target
     //! with respect to the layer's bias, given the internal activations
     virtual void bpropNLL(const Vec&amp; target, real nll, Vec bias_gradient);

Modified: trunk/plearn_learners/online/RBMLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMLayer.cc	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMLayer.cc	2007-01-17 04:14:23 UTC (rev 6585)
@@ -205,7 +205,7 @@
     PLERROR(&quot;In RBMLayer::fprop(): not implemented&quot;);
 }
 
-void RBMLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+void RBMLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                            const Vec&amp; output,
                            Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                            const Vec&amp; output_gradient)
@@ -316,7 +316,7 @@
         bg[i] = bps[i]/pos_count - bns[i]/neg_count;
 }
 
-void RBMLayer::bpropCD(const Vec&amp; pos_values, const Vec&amp; neg_values, 
+void RBMLayer::bpropCD(const Vec&amp; pos_values, const Vec&amp; neg_values,
                        Vec&amp; bias_gradient)
 {
     // grad = bias_pos_stats/pos_count - bias_neg_stats/neg_count

Modified: trunk/plearn_learners/online/RBMLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMLayer.h	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMLayer.h	2007-01-17 04:14:23 UTC (rev 6585)
@@ -128,9 +128,9 @@
     //! the expectation
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
-    //! computes the expectation given the conditional input 
+    //! computes the expectation given the conditional input
     //! and the given bias
-    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,
                         Vec&amp; output ) const;
 
     //! back-propagates the output gradient to the input,
@@ -140,15 +140,15 @@
                              const Vec&amp; output_gradient) = 0 ;
 
     //! back-propagates the output gradient to the input and the bias
-    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                              const Vec&amp; output,
                              Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                              const Vec&amp; output_gradient) ;
 
-    //! Computes the negative log-likelihood of target given the 
+    //! Computes the negative log-likelihood of target given the
     //! internal activations of the layer
     virtual real fpropNLL(const Vec&amp; target);
-    
+
     //! Computes the gradient of the negative log-likelihood of target
     //! with respect to the layer's bias, given the internal activations
     virtual void bpropNLL(const Vec&amp; target, real nll, Vec bias_gradient);
@@ -184,7 +184,7 @@
     //! Computes the contrastive divergence bias with respect to the bias
     //! (or activations, which is equivalent), given the positive and
     //! negative phase values.
-    virtual void bpropCD(const Vec&amp; pos_values, const Vec&amp; neg_values, 
+    virtual void bpropCD(const Vec&amp; pos_values, const Vec&amp; neg_values,
                     Vec&amp; bias_gradient);
 
     //#####  PLearn::Object Protocol  #########################################

Modified: trunk/plearn_learners/online/RBMMixedLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMMixedLayer.cc	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMMixedLayer.cc	2007-01-17 04:14:23 UTC (rev 6585)
@@ -128,7 +128,7 @@
     }
 }
 
-void RBMMixedLayer::fprop( const Vec&amp; input, const Vec&amp; rbm_bias, 
+void RBMMixedLayer::fprop( const Vec&amp; input, const Vec&amp; rbm_bias,
                            Vec&amp; output ) const
 {
     PLASSERT( input.size() == input_size );
@@ -172,7 +172,7 @@
     }
 }
 
-void RBMMixedLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+void RBMMixedLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                                 const Vec&amp; output,
                                 Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                                 const Vec&amp; output_gradient)

Modified: trunk/plearn_learners/online/RBMMixedLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMMixedLayer.h	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMMixedLayer.h	2007-01-17 04:14:23 UTC (rev 6585)
@@ -96,7 +96,7 @@
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
     //! forward propagation with provided bias
-    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,
                         Vec&amp; output ) const;
 
     //! back-propagates the output gradient to the input
@@ -104,15 +104,15 @@
                              Vec&amp; input_gradient, const Vec&amp; output_gradient);
 
     //! back-propagates the output gradient to the input and the bias
-    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                              const Vec&amp; output,
                              Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                              const Vec&amp; output_gradient) ;
 
-    //! Computes the negative log-likelihood of target given the 
+    //! Computes the negative log-likelihood of target given the
     //! internal activations of the layer
     virtual real fpropNLL(const Vec&amp; target);
-    
+
     //! Computes the gradient of the negative log-likelihood of target
     //! with respect to the layer's bias, given the internal activations
     virtual void bpropNLL(const Vec&amp; target, real nll, Vec bias_gradient);

Modified: trunk/plearn_learners/online/RBMMultinomialLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMMultinomialLayer.cc	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMMultinomialLayer.cc	2007-01-17 04:14:23 UTC (rev 6585)
@@ -159,7 +159,7 @@
     }
 }
 
-void RBMMultinomialLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+void RBMMultinomialLayer::bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                                       const Vec&amp; output,
                                       Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                                       const Vec&amp; output_gradient)
@@ -190,7 +190,7 @@
     PLASSERT( target.size() == input_size );
 
     real ret = 0;
-    
+
     real target_i, expectation_i;
     for( int i=0 ; i&lt;size ; i++ )
     {
@@ -214,7 +214,7 @@
     real* tar = target.data();
     real* biasg = bias_gradient.data();
     for( int i=0 ; i&lt;size ; i++ )
-        biasg[i] = tar[i] - sum_tar * exp[i];    
+        biasg[i] = tar[i] - sum_tar * exp[i];
 }
 
 void RBMMultinomialLayer::declareOptions(OptionList&amp; ol)

Modified: trunk/plearn_learners/online/RBMMultinomialLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMMultinomialLayer.h	2007-01-16 23:12:37 UTC (rev 6584)
+++ trunk/plearn_learners/online/RBMMultinomialLayer.h	2007-01-17 04:14:23 UTC (rev 6585)
@@ -90,7 +90,7 @@
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
     //! forward propagation with provided bias
-    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,
                         Vec&amp; output ) const;
 
     //! back-propagates the output gradient to the input
@@ -98,15 +98,15 @@
                              Vec&amp; input_gradient, const Vec&amp; output_gradient);
 
     //! back-propagates the output gradient to the input and the bias
-    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias, 
+    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; rbm_bias,
                              const Vec&amp; output,
                              Vec&amp; input_gradient, Vec&amp; rbm_bias_gradient,
                              const Vec&amp; output_gradient) ;
 
-    //! Computes the negative log-likelihood of target given the 
+    //! Computes the negative log-likelihood of target given the
     //! internal activations of the layer
     virtual real fpropNLL(const Vec&amp; target);
-    
+
     //! Computes the gradient of the negative log-likelihood of target
     //! with respect to the layer's bias, given the internal activations
     virtual void bpropNLL(const Vec&amp; target, real nll, Vec bias_gradient);


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000033.html">[Plearn-commits] r6584 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000035.html">[Plearn-commits] r6586 - in trunk/python_modules/plearn/math: .	stats stats/.pytest stats/.pytest/PL_cvx_numpy_matrix_conversions	stats/.pytest/PL_cvx_numpy_matrix_conversions/expected_results
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#34">[ date ]</a>
              <a href="thread.html#34">[ thread ]</a>
              <a href="subject.html#34">[ subject ]</a>
              <a href="author.html#34">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
