<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6607 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-January/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6607%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200701240611.l0O6BfwX030093%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000055.html">
   <LINK REL="Next"  HREF="000057.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6607 - trunk/plearn_learners/online</H1>
    <B>lamblin at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6607%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200701240611.l0O6BfwX030093%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6607 - trunk/plearn_learners/online">lamblin at mail.berlios.de
       </A><BR>
    <I>Wed Jan 24 07:11:41 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000055.html">[Plearn-commits] r6606 - in trunk/plearn_learners/online: .	DEPRECATED
</A></li>
        <LI>Next message: <A HREF="000057.html">[Plearn-commits] r6608 - in trunk: commands plearn_learners/online	plearn_learners/online/DEPRECATED
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#56">[ date ]</a>
              <a href="thread.html#56">[ thread ]</a>
              <a href="subject.html#56">[ subject ]</a>
              <a href="author.html#56">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: lamblin
Date: 2007-01-24 07:11:41 +0100 (Wed, 24 Jan 2007)
New Revision: 6607

Modified:
   trunk/plearn_learners/online/rbm_todo_and_ideas.txt
Log:
Update this file with the results we've had.
TODO: where do we put such files?


Modified: trunk/plearn_learners/online/rbm_todo_and_ideas.txt
===================================================================
--- trunk/plearn_learners/online/rbm_todo_and_ideas.txt	2007-01-24 05:56:29 UTC (rev 6606)
+++ trunk/plearn_learners/online/rbm_todo_and_ideas.txt	2007-01-24 06:11:41 UTC (rev 6607)
@@ -5,19 +5,29 @@
 
 * Implement DeepBeliefNet as a PDistribution, trained the way Hinton
   trains its network
+    -&gt; PDistribution was a bad idea (too complicated).
+    -&gt; It is implemented as a PLearner, in $PLEARNDIR/plearn_learners/online.
+    -&gt; It still lacks the generating functions.
 
 * Make an OnlineLearningModule stacking RBMLayers and RBMParameters doing the
   same thing? Encapsulating DeepBeliefNet? Make DeepBeliefNet encapsulate the
   module?
+    -&gt; Nope.
+    -&gt; We can use ModuleStackModule if we only want to use the mean-field
+approximation.
 
+
 Questions
 =========
 
 * How do we initialize the weights? Is the sampling process enough to break
   the symmetry if all weights are initialized to 0? Should we initialize them
   randomly ?
+    -&gt; Initializing to 0 can lead to sub-optimal results. Initializing
+    randomly experimentally led to better solutions.
 
-* When do we update the weights? After each sampe? At the end of a batch?
+* When do we update the weights? After each sample? At the end of a batch?
+    -&gt; After each sample seems to be OK.
 
 * How to learn the weights V between Last layer and Previous layer, and W
   between Last layer and output/target layer (Y) if trained in a supervised
@@ -29,10 +39,17 @@
   - Learn V by contrastive divergence, but clamping Y to the true target
     during both positive and negative phases
 
-* Can we compute the predicted probability (or density?) of an input? Of the
-  label given the input? The input given the label?
+    -&gt; Second solutions seems to work OK, but Hinton uses V unsupervisedly and
+    then fine-tunes the whole network (no pre-training of W).
 
+* Can we compute the predicted probability (or density?) of an input?
+    -&gt; Not without sampling, or summing an exponential number of terms
+  Of the label given the input?
+    -&gt; Yes
+  The input given the label?
+    -&gt; Nope (see 1.)
 
+
 Ideas
 =====
 
@@ -40,8 +57,11 @@
 the up (and down) layer have the same type ('l' or 'q'), because
 RBMGenericParameters has to check every unit. So we could use matrix-matrix
 products instead of n matrix-vector products.
+    -&gt; Obsoleted by new version. RBMConnection (RBMParameter's successor) does
+    not depend on the type of the units anymore.
 
 * How to combine error gradient and likelihood gradient?
+    -&gt; Add them with two different learning rates.
 
 * Implement global wake-sleep (on every layer at one time) learning of the
   weights ==&gt; this would seem necessary in order to have simultaneous
@@ -49,22 +69,31 @@
 
 * See if we share biases (and quadratic term) of one layer between the &quot;upper&quot;
   and &quot;lower&quot; RBMParameters modules
+    -&gt; Yes. They are now integrated into RBMLayer, which is shared between the
+    wo RBMs.
 
 * Is there a way to compute analytically the &quot;undirected softmax&quot; if the
   output layer has Gaussian units?
-  -&gt; maybe if only one Gaussian, probably not otherwise
+    -&gt; maybe if only one Gaussian, probably not otherwise
 
 * See when we should sample from a layer, and when we should compute the
   expectation. Is it a problem if some statistics during the positive phase
   are expectations, and are samples during the negative phase (or vice-versa)?
+    -&gt; The solution that works best experimentally is:
+        v_0: expectation (or original input)
+        h_0: expectation, but initialize the Markov chain with a sample
+        v_1: sample
+        h_1: expectation
 
 * introducing temporal structure into the model:
-   - time delays in the connections
-   - recurrent connections (e.g. from layer i at t to layer i at t+1)
-   - supervised targets (and corresponding gradients) from the task of
-     predicting layer i at t+1 from layer j at t
+  - time delays in the connections
+  - recurrent connections (e.g. from layer i at t to layer i at t+1)
+  - supervised targets (and corresponding gradients) from the task of
+    predicting layer i at t+1 from layer j at t
 
+    -&gt; See $PLEARNDIR/plearn_learners_experimental/DynamicallyLinkedRBMsModel
+    -&gt; Still lots of things to do.
 
+    -&gt; Where do we put this document?
 
 
-


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000055.html">[Plearn-commits] r6606 - in trunk/plearn_learners/online: .	DEPRECATED
</A></li>
	<LI>Next message: <A HREF="000057.html">[Plearn-commits] r6608 - in trunk: commands plearn_learners/online	plearn_learners/online/DEPRECATED
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#56">[ date ]</a>
              <a href="thread.html#56">[ thread ]</a>
              <a href="subject.html#56">[ subject ]</a>
              <a href="author.html#56">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
