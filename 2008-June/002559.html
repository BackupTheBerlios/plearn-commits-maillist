<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9111 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9111%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200806110210.m5B2APIm023102%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002558.html">
   <LINK REL="Next"  HREF="002560.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9111 - trunk/plearn_learners/online</H1>
    <B>lamblin at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9111%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200806110210.m5B2APIm023102%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9111 - trunk/plearn_learners/online">lamblin at mail.berlios.de
       </A><BR>
    <I>Wed Jun 11 04:10:25 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002558.html">[Plearn-commits] r9110 - trunk/python_modules/plearn/math
</A></li>
        <LI>Next message: <A HREF="002560.html">[Plearn-commits] r9112 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2559">[ date ]</a>
              <a href="thread.html#2559">[ thread ]</a>
              <a href="subject.html#2559">[ subject ]</a>
              <a href="author.html#2559">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: lamblin
Date: 2008-06-11 04:10:22 +0200 (Wed, 11 Jun 2008)
New Revision: 9111

Modified:
   trunk/plearn_learners/online/RBMBinomialLayer.cc
   trunk/plearn_learners/online/RBMBinomialLayer.h
   trunk/plearn_learners/online/RBMGaussianLayer.cc
   trunk/plearn_learners/online/RBMLateralBinomialLayer.cc
   trunk/plearn_learners/online/RBMLateralBinomialLayer.h
   trunk/plearn_learners/online/RBMLayer.cc
   trunk/plearn_learners/online/RBMLayer.h
   trunk/plearn_learners/online/RBMMixedLayer.cc
   trunk/plearn_learners/online/RBMMixedLayer.h
   trunk/plearn_learners/online/RBMWoodsLayer.cc
   trunk/plearn_learners/online/RBMWoodsLayer.h
Log:
Correct prototype for minibatch fprop() (without ports).
Implement a version in base class RBMLayer.


Modified: trunk/plearn_learners/online/RBMBinomialLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMBinomialLayer.cc	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMBinomialLayer.cc	2008-06-11 02:10:22 UTC (rev 9111)
@@ -87,7 +87,7 @@
             sample[i] = 2*random_gen-&gt;binomial_sample( (expectation[i]+1)/2 )-1;
     else
         for( int i=0 ; i&lt;size ; i++ )
-            sample[i] = random_gen-&gt;binomial_sample( expectation[i] );        
+            sample[i] = random_gen-&gt;binomial_sample( expectation[i] );
 }
 
 /////////////////////
@@ -115,7 +115,7 @@
             for (int i=0 ; i&lt;size ; i++)
                 samples(k, i) = random_gen-&gt;binomial_sample( expectations(k, i) );
         }
-        
+
 }
 
 ////////////////////////
@@ -149,6 +149,7 @@
 /////////////////////////
 void RBMBinomialLayer::computeExpectations()
 {
+    PLASSERT( activations.length() == batch_size );
     if( expectations_are_up_to_date )
         return;
 
@@ -201,7 +202,7 @@
 
 }
 
-void RBMBinomialLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs ) const
+void RBMBinomialLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs )
 {
     int mbatch_size = inputs.length();
     PLASSERT( inputs.width() == size );
@@ -285,7 +286,7 @@
             real in_grad_i;
             in_grad_i = (1 -  output_i * output_i) * output_gradient[i];
             input_gradient[i] += in_grad_i;
-            
+
             if( momentum == 0. )
             {
                 // update the bias: bias -= learning_rate * input_gradient
@@ -309,7 +310,7 @@
             real in_grad_i;
             in_grad_i = output_i * (1-output_i) * output_gradient[i];
             input_gradient[i] += in_grad_i;
-            
+
             if( momentum == 0. )
             {
                 // update the bias: bias -= learning_rate * input_gradient
@@ -371,7 +372,7 @@
                 real in_grad_i;
                 in_grad_i = (1 - output_i * output_i) * output_gradients(j, i);
                 input_gradients(j, i) += in_grad_i;
-                
+
                 if( momentum == 0. )
                 {
                     // update the bias: bias -= learning_rate * input_gradient
@@ -400,7 +401,7 @@
                 real in_grad_i;
                 in_grad_i = output_i * (1-output_i) * output_gradients(j, i);
                 input_gradients(j, i) += in_grad_i;
-                
+
                 if( momentum == 0. )
                 {
                     // update the bias: bias -= learning_rate * input_gradient
@@ -441,7 +442,7 @@
         for( int i=0 ; i&lt;size ; i++ )
         {
             real output_i = output[i];
-            
+
             input_gradient[i] = ( 1 - output_i * output_i ) * output_gradient[i];
         }
     }
@@ -451,7 +452,7 @@
         {
             real output_i = output[i];
             input_gradient[i] = output_i * (1-output_i) * output_gradient[i];
-        }   
+        }
     }
 
     rbm_bias_gradient &lt;&lt; input_gradient;
@@ -470,19 +471,19 @@
             {
                 target_i = (target[i]+1)/2;
                 activation_i = 2*activation[i];
-                
+
                 ret += tabulated_softplus(activation_i) - target_i * activation_i;
                 // nll = - target*log(sigmoid(act)) -(1-target)*log(1-sigmoid(act))
                 // but it is numerically unstable, so use instead the following identity:
                 //     = target*softplus(-act) +(1-target)*(act+softplus(-act))
-                //     = act + softplus(-act) - target*act 
+                //     = act + softplus(-act) - target*act
                 //     = softplus(act) - target*act
             }
         } else {
             for( int i=0 ; i&lt;size ; i++ )
             {
                 target_i = (target[i]+1)/2;
-                activation_i = 2*activation[i];                
+                activation_i = 2*activation[i];
                 ret += softplus(activation_i) - target_i * activation_i;
             }
         }
@@ -498,7 +499,7 @@
                 // nll = - target*log(sigmoid(act)) -(1-target)*log(1-sigmoid(act))
                 // but it is numerically unstable, so use instead the following identity:
                 //     = target*softplus(-act) +(1-target)*(act+softplus(-act))
-                //     = act + softplus(-act) - target*act 
+                //     = act + softplus(-act) - target*act
                 //     = softplus(act) - target*act
             }
         } else {
@@ -516,8 +517,6 @@
 
 void RBMBinomialLayer::fpropNLL(const Mat&amp; targets, const Mat&amp; costs_column)
 {
-    // computeExpectations(); // why?
-
     PLASSERT( targets.width() == input_size );
     PLASSERT( targets.length() == batch_size );
     PLASSERT( costs_column.width() == 1 );
@@ -703,13 +702,13 @@
 {
     PLASSERT( output.length() == size );
     PLASSERT( conf_index &gt;= 0 &amp;&amp; conf_index &lt; getConfigurationCount() );
-    
+
     if( use_signed_samples )
     {
         for ( int i = 0; i &lt; size; ++i ) {
             output[i] = 2 * (conf_index &amp; 1) - 1;
             conf_index &gt;&gt;= 1;
-        }        
+        }
     }
     else
     {

Modified: trunk/plearn_learners/online/RBMBinomialLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMBinomialLayer.h	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMBinomialLayer.h	2008-06-11 02:10:22 UTC (rev 9111)
@@ -84,7 +84,7 @@
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
     //! Batch forward propagation
-    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs ) const;
+    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs );
 
     //! forward propagation with provided bias
     virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,

Modified: trunk/plearn_learners/online/RBMGaussianLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMGaussianLayer.cc	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMGaussianLayer.cc	2008-06-11 02:10:22 UTC (rev 9111)
@@ -827,7 +827,7 @@
             }
     }
 }
-    
+
 void RBMGaussianLayer::bpropNLL(const Vec&amp; target, real nll, Vec&amp; bias_gradient)
 {
     computeExpectation();
@@ -839,7 +839,7 @@
     substract(expectation, target, bias_gradient);
 
     if( compute_mse_instead_of_nll )
-        bias_gradient *= 2;
+        bias_gradient *= 2.;
     addBiasDecay(bias_gradient);
 
 }
@@ -859,7 +859,7 @@
     substract(expectations, targets, bias_gradients);
 
     if( compute_mse_instead_of_nll )
-        bias_gradients *= 2;
+        bias_gradients *= 2.;
     addBiasDecay(bias_gradients);
 
 }

Modified: trunk/plearn_learners/online/RBMLateralBinomialLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMLateralBinomialLayer.cc	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMLateralBinomialLayer.cc	2008-06-11 02:10:22 UTC (rev 9111)
@@ -450,7 +450,7 @@
     }
 }
 
-void RBMLateralBinomialLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs ) const
+void RBMLateralBinomialLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs )
 {
     int mbatch_size = inputs.length();
     PLASSERT( inputs.width() == size );

Modified: trunk/plearn_learners/online/RBMLateralBinomialLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMLateralBinomialLayer.h	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMLateralBinomialLayer.h	2008-06-11 02:10:22 UTC (rev 9111)
@@ -141,7 +141,7 @@
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
     //! Batch forward propagation
-    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs ) const;
+    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs );
 
     //! forward propagation with provided bias
     virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,

Modified: trunk/plearn_learners/online/RBMLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMLayer.cc	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMLayer.cc	2008-06-11 02:10:22 UTC (rev 9111)
@@ -319,6 +319,23 @@
     output &lt;&lt; This-&gt;expectation;
 }
 
+void RBMLayer::fprop(const Mat&amp; inputs, Mat&amp; outputs)
+{
+    // Note: inefficient.
+    PLASSERT( inputs.width() == input_size );
+    int mbatch_size = inputs.length();
+    outputs.resize(mbatch_size, output_size);
+
+    setBatchSize(mbatch_size);
+    activations &lt;&lt; inputs;
+    for (int k = 0; k &lt; mbatch_size; k++)
+        activations(k) += bias;
+
+    expectations_are_up_to_date = false;
+    computeExpectations();
+    outputs &lt;&lt; expectations;
+}
+
 void RBMLayer::fprop( const Vec&amp; input, const Vec&amp; rbm_bias,
                       Vec&amp; output ) const
 {
@@ -365,7 +382,7 @@
         selectRows( activations, TVec&lt;int&gt;(1, k), tmp );
         activation &lt;&lt; tmp;
         selectRows( targets, TVec&lt;int&gt;(1, k), tmp );
-	target &lt;&lt; tmp;
+        target &lt;&lt; tmp;
         costs_column(k,0) = fpropNLL( target );
     }
 }

Modified: trunk/plearn_learners/online/RBMLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMLayer.h	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMLayer.h	2008-06-11 02:10:22 UTC (rev 9111)
@@ -182,7 +182,8 @@
 
     //! Adds the bias to input, consider this as the activation, then compute
     //! the expectation
-    virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
+    virtual void fprop(const Vec&amp; input, Vec&amp; output) const;
+    virtual void fprop(const Mat&amp; inputs, Mat&amp; outputs);
 
     //! computes the expectation given the conditional input
     //! and the given bias

Modified: trunk/plearn_learners/online/RBMMixedLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMMixedLayer.cc	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMMixedLayer.cc	2008-06-11 02:10:22 UTC (rev 9111)
@@ -258,7 +258,7 @@
 ///////////
 // fprop //
 ///////////
-void RBMMixedLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs ) const
+void RBMMixedLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs )
 {
     int mbatch_size = inputs.length();
     PLASSERT( inputs.width() == size );

Modified: trunk/plearn_learners/online/RBMMixedLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMMixedLayer.h	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMMixedLayer.h	2008-06-11 02:10:22 UTC (rev 9111)
@@ -120,7 +120,7 @@
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
     //! Batch forward propagation
-    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs ) const;
+    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs );
 
     //! forward propagation with provided bias
     virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,

Modified: trunk/plearn_learners/online/RBMWoodsLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMWoodsLayer.cc	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMWoodsLayer.cc	2008-06-11 02:10:22 UTC (rev 9111)
@@ -473,7 +473,7 @@
     }
 }
 
-void RBMWoodsLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs ) const
+void RBMWoodsLayer::fprop( const Mat&amp; inputs, Mat&amp; outputs )
 {
     int mbatch_size = inputs.length();
     PLASSERT( inputs.width() == size );

Modified: trunk/plearn_learners/online/RBMWoodsLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMWoodsLayer.h	2008-06-10 18:21:36 UTC (rev 9110)
+++ trunk/plearn_learners/online/RBMWoodsLayer.h	2008-06-11 02:10:22 UTC (rev 9111)
@@ -89,7 +89,7 @@
     virtual void fprop( const Vec&amp; input, Vec&amp; output ) const;
 
     //! Batch forward propagation
-    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs ) const;
+    virtual void fprop( const Mat&amp; inputs, Mat&amp; outputs );
 
     //! forward propagation with provided bias
     virtual void fprop( const Vec&amp; input, const Vec&amp; rbm_bias,


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002558.html">[Plearn-commits] r9110 - trunk/python_modules/plearn/math
</A></li>
	<LI>Next message: <A HREF="002560.html">[Plearn-commits] r9112 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2559">[ date ]</a>
              <a href="thread.html#2559">[ thread ]</a>
              <a href="subject.html#2559">[ subject ]</a>
              <a href="author.html#2559">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
