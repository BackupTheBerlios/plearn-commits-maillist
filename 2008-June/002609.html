<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9161 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9161%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806201959.m5KJx7HV011343%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002608.html">
   <LINK REL="Next"  HREF="002610.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9161 - trunk/plearn_learners_experimental</H1>
    <B>laulysta at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9161%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806201959.m5KJx7HV011343%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9161 - trunk/plearn_learners_experimental">laulysta at mail.berlios.de
       </A><BR>
    <I>Fri Jun 20 21:59:07 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002608.html">[Plearn-commits] r9160 - trunk/python_modules/plearn/pymake
</A></li>
        <LI>Next message: <A HREF="002610.html">[Plearn-commits] r9162 - trunk/python_modules/plearn/learners
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2609">[ date ]</a>
              <a href="thread.html#2609">[ thread ]</a>
              <a href="subject.html#2609">[ subject ]</a>
              <a href="author.html#2609">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: laulysta
Date: 2008-06-20 21:59:07 +0200 (Fri, 20 Jun 2008)
New Revision: 9161

Modified:
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
Log:


Modified: trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2008-06-20 19:38:59 UTC (rev 9160)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2008-06-20 19:59:07 UTC (rev 9161)
@@ -457,6 +457,10 @@
 {
     MODULE_LOG &lt;&lt; &quot;train() called &quot; &lt;&lt; endl;
 
+    // reserve memory for sequences
+    Mat seq(5000,2); // contains the current sequence
+    Mat encoded_seq(5000, 4);
+
     Vec input( inputsize() );
     Vec target( targetsize() );
     real weight = 0; // Unused
@@ -503,26 +507,497 @@
             pb = new ProgressBar( &quot;Recurrent training phase of &quot;+classname(),
                                   end_stage - init_stage );
 
+        // TO DO: check this line
         setLearningRate( recurrent_net_learning_rate );
 
         int ith_sample_in_sequence = 0;
         int inputsize_without_masks = inputsize() 
             - ( use_target_layers_masks ? targetsize() : 0 );
         int sum_target_elements = 0;
+
         while(stage &lt; end_stage)
         {
+            train_costs.clear();
+            train_n_items.clear();
+
+            int nseq = nSequences();
+            for(int i=0; i&lt;nseq; i++)
+            {
+                getSequence(i, seq);
+                if(encoding==&quot;raw_masked_supervised&quot;)
+                {
+                    splitMaskedSupervisedSequence(seq);
+                }
+                else
+                {
+                    encodeSequence(seq, encoded_seq);
+                    createSupervisedSequence(encoded_seq);
+                }
+
+                fbpropupdate();
+            }
+
+            if( pb )
+                pb-&gt;update( stage + 1 - init_stage);
+            
+            for(int i=0; i&lt;train_costs.length(); i++)
+            {
+                if( !fast_exact_is_equal(target_layers_weights[i],0) )
+                    train_costs[i] /= train_n_items[i];
+                else
+                    train_costs[i] = MISSING_VALUE;
+            }
+
+            if(verbosity&gt;0)
+                cout &lt;&lt; &quot;mean costs at stage &quot; &lt;&lt; stage &lt;&lt; 
+                    &quot; = &quot; &lt;&lt; train_costs &lt;&lt; endl;
+            stage++;
+            train_stats-&gt;update(train_costs);
+        }
+
+        if( pb )
+        {
+            delete pb;
+            pb = 0;
+        }
+    }
+
+    train_stats-&gt;finalize();        
+}
+
+// TO DO: penser a gestion des prepended dans ce cas
+// Populates: inputslist, targets_list, masks_list
+void DenoisingRecurrentNet::createSupervisedSequence(Mat encoded_seq)
+{
+    PLERROR(&quot;Not implemented yet&quot;);
+}
+
+
+
+// TO DO: penser a prepend dans ce cas
+
+// Populates: input_list, targets_list, masks_list
+void DenoisingRecurrentNet::splitMaskedSupervisedSequence(Mat seq)
+{
+    int inputsize_without_masks = inputsize()-targetsize();
+    Mat input_part = seq.subMatColumns(0,inputsize_without_masks);
+    Mat mask_part = seq.subMatColumns(inputsize_without_masks, targetsize());
+    Mat target_part = seq.subMatColumns(inputsize_without_masks+targetsize(), targetsize());
+
+    int l = input_part.length();
+    input_list.resize(l);
+    for(int i=0; i&lt;l; i++)
+        input_list[i] = input_part(i);
+
+    int ntargets = target_layers.length();
+    targets_list.resize(ntagets);
+    masks_list.resize(ntargets);
+    int startcol = 0; // starting column of next target in target_part and mask_part
+    for(int k=0; k&lt;ntargets; k++)
+    {
+        int targsize = target_layers[k]-&gt;size;
+        targets_list[k] = target_part.subMatColumns(startcol, targsize);
+        masks_list[k] = mask_part.subMatColumns(startcol, targsize);
+        startcol += targsize;
+    }
+}
+
+
+void DenoisingRecurrentNet::fbpropupdate()
+{
+    resize_lists();
+    fprop();
+    recurrent_update();
+}
+
+
+void DenoisingRecurrentNet::resize_lists()
+{
+    int l = input_list.length();
+
+    hidden_list.resize(l, hidden_layer-&gt;size);
+    hidden_act_no_bias_list.resize(l, hidden_layer-&gt;size);
+
+    if( hidden_layer2 )
+    {
+        hidden2_list.resize(l, hidden_layer2-&gt;size);
+        hidden2_act_no_bias_list.resize(l, hidden_layer2-&gt;size);
+    }
+
+    int ntargets = target_layers.length();
+    target_prediction_list.resize( ntargets );
+    target_prediction_act_no_bias_list.resize( ntargets );
+
+    for( int tar=0; tar &lt; ntargets; tar++ )
+    {
+        int targsize = target_layers[k]-&gt;size;
+        target_prediction_list[tar].resize(l, targsize);
+        target_prediction_act_no_bias_list[tar].resize(l, targsize);
+    }
+
+    nll_list.resize(l,ntargets);
+}
+
+// TODO: think properly about prepended stuff
+
+void DenoisingRecurrentNet::fprop()
+{
+    int l = input_list.length();
+    int ntargets = target_layers.length();
+
+    for(int i=0; i&lt;input_list.length(); i++ )
+    {
+        Vec hidden_act_no_bias_i = hidden_act_no_bias_list(i);
+        input_connections-&gt;fprop( input_list[i], hidden_act_no_bias_i);
+
+        if( i &gt; 0 &amp;&amp; dynamic_connections )
+        {
+            Vec hidden_i_prev = hidden_list(i-1);
+            dynamic_connections-&gt;fprop(hidden_i_prev,dynamic_act_no_bias_contribution );
+            hidden_act_no_bias_i += dynamic_act_no_bias_contribution;
+        }
+        
+        Vec hidden_i = hidden_list(i);
+        hidden_layer-&gt;fprop( hidden_act_no_bias_i, 
+                             hidden_i);
+        
+        Vec last_hidden = hidden_i;
+                 
+        if( hidden_layer2 )
+        {
+            Vec hidden2_i = hidden2_list(i); 
+            Vec hidden2_act_no_bias_i = hidden2_act_no_bias_list(i);
+
+            hidden_connections-&gt;fprop(hidden_i, hidden2_act_no_bias_i);            
+            hidden_layer2-&gt;fprop(hidden2_act_no_bias_i, hidden2_i);
+
+            last_hidden = hidden2_i; // last hidden layer vec 
+        }
+
+        for( int tar=0; tar &lt; ntargets; tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                Vec target_prediction_i = target_prediction_list[tar](i);
+                Vec target_prediction_act_no_bias_i = target_prediction_act_no_bias_i;
+                target_connections[tar]-&gt;fprop(last_hidden, target_prediction_act_no_bias_list_i);
+                target_layers[tar]-&gt;fprop(target_prediction_act_no_bias_i, target_prediction_list_i);
+                if( use_target_layers_masks )
+                    target_prediction_i *= masks_list[tar](i);
+            }
+        }
+
+        sum_target_elements = 0;
+        for( int tar=0; tar &lt; ntargets; tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar](i);
+                target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                target_layers[tar]-&gt;setExpectation(target_prediction_list[tar](i));
+                Vec target_vec = targets_list[tar](i);
+                nll_list(i,tar) = target_layers[tar]-&gt;fpropNLL(target_vec); 
+                train_costs[tar] += nll_list(i,tar);
+                        
+                // Normalize by the number of things to predict
+                if( use_target_layers_masks )
+                {
+                    train_n_items[tar] += sum(
+                        input.subVec( inputsize_without_masks 
+                                      + sum_target_elements, 
+                                      target_layers_n_of_target_elements[tar]) );
+                }
+                else
+                    train_n_items[tar]++;
+            }
+            if( use_target_layers_masks )
+                sum_target_elements += target_layers_n_of_target_elements[tar];
+                    
+        }
+    }
+}
+
 /*
-                TMat&lt;real&gt; U,V;//////////crap James
-                TVec&lt;real&gt; S;
-                U.resize(hidden_layer-&gt;size,hidden_layer-&gt;size);
-                V.resize(hidden_layer-&gt;size,hidden_layer-&gt;size);
-                S.resize(hidden_layer-&gt;size);
-                U &lt;&lt; dynamic_connections-&gt;weights;
+input_list
+targets_list
+masks_list
+hidden_list
+hidden_act_no_bias_list
+hidden2_list
+hidden2_act_no_bias_list
+target_prediction_list
+target_prediction_act_no_bias_list
+nll_list
+*/
+
+void DenoisingRecurrentNet::recurrent_update()
+{
+    hidden_temporal_gradient.resize(hidden_layer-&gt;size);
+    hidden_temporal_gradient.clear();
+    for(int i=hidden_list.length()-1; i&gt;=0; i--){   
+
+        if( hidden_layer2 )
+            hidden_gradient.resize(hidden_layer2-&gt;size);
+        else
+            hidden_gradient.resize(hidden_layer-&gt;size);
+        hidden_gradient.clear();
+        if(use_target_layers_masks)
+        {
+            for( int tar=0; tar&lt;target_layers.length(); tar++)
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar](i);
+                    target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                    target_layers[tar]-&gt;setExpectation(target_prediction_list[tar](i));
+                    target_layers[tar]-&gt;bpropNLL(targets_list[tar](i),nll_list(i,tar),bias_gradient);
+                    bias_gradient *= target_layers_weights[tar];
+                    bias_gradient *= masks_list[tar](i);
+                    target_layers[tar]-&gt;update(bias_gradient);
+                    if( hidden_layer2 )
+                        target_connections[tar]-&gt;bpropUpdate(hidden2_list(i),target_prediction_act_no_bias_list[tar](i),
+                                                             hidden_gradient, bias_gradient,true);
+                    else
+                        target_connections[tar]-&gt;bpropUpdate(hidden_list(i),target_prediction_act_no_bias_list[tar](i),
+                                                             hidden_gradient, bias_gradient,true);
+                }
+            }
+        }
+        else
+        {
+            for( int tar=0; tar&lt;target_layers.length(); tar++)
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar](i);
+                    target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                    target_layers[tar]-&gt;setExpectation(target_prediction_list[tar](i));
+                    target_layers[tar]-&gt;bpropNLL(targets_list[tar](i),nll_list(i,tar),bias_gradient);
+                    bias_gradient *= target_layers_weights[tar];
+                    target_layers[tar]-&gt;update(bias_gradient);
+                    if( hidden_layer2 )
+                        target_connections[tar]-&gt;bpropUpdate(hidden2_list(i),target_prediction_act_no_bias_list[tar](i),
+                                                             hidden_gradient, bias_gradient,true); 
+                    else
+                        target_connections[tar]-&gt;bpropUpdate(hidden_list(i),target_prediction_act_no_bias_list[tar](i),
+                                                             hidden_gradient, bias_gradient,true); 
+                        
+                }
+            }
+        }
+
+        if (hidden_layer2)
+        {
+            hidden_layer2-&gt;bpropUpdate(
+                hidden2_act_no_bias_list(i), hidden2_list(i),
+                bias_gradient, hidden_gradient);
                 
-                SVD(U,dynamic_connections-&gt;weights,S,V);
-                S.fill(-0.5);
-                productScaleAcc(dynamic_connections-&gt;bias,dynamic_connections-&gt;weights,S,1,0);
+            hidden_connections-&gt;bpropUpdate(
+                hidden_list(i),
+                hidden2_act_no_bias_list(i), 
+                hidden_gradient, bias_gradient);
+        }
+            
+        if(i!=0 &amp;&amp; dynamic_connections )
+        {   
+            hidden_gradient += hidden_temporal_gradient;
+                
+            hidden_layer-&gt;bpropUpdate(
+                hidden_act_no_bias_list(i), hidden_list(i),
+                hidden_temporal_gradient, hidden_gradient);
+                
+            dynamic_connections-&gt;bpropUpdate(
+                hidden_list[i-1],
+                hidden_act_no_bias_list(i), // Here, it should be cond_bias, but doesn't matter
+                hidden_gradient, hidden_temporal_gradient);
+                
+            hidden_temporal_gradient &lt;&lt; hidden_gradient;
+                
+            input_connections-&gt;bpropUpdate(
+                input_list(i),
+                hidden_act_no_bias_list(i), 
+                visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
+                
+        }
+        else
+        {
+            hidden_layer-&gt;bpropUpdate(
+                hidden_act_no_bias_list(i), hidden_list(i),
+                hidden_temporal_gradient, hidden_gradient); // Not really temporal gradient, but this is the final iteration...
+            input_connections-&gt;bpropUpdate(
+                input_list(i),
+                hidden_act_no_bias_list(i), 
+                visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
+
+        }
+    }
+    
+}
+
+/*
+void DenoisingRecurrentNet::old_recurrent_update()
+{
+    hidden_temporal_gradient.resize(hidden_layer-&gt;size);
+    hidden_temporal_gradient.clear();
+    for(int i=hidden_list.length()-1; i&gt;=0; i--){   
+
+        if( hidden_layer2 )
+            hidden_gradient.resize(hidden_layer2-&gt;size);
+        else
+            hidden_gradient.resize(hidden_layer-&gt;size);
+        hidden_gradient.clear();
+        if(use_target_layers_masks)
+        {
+            for( int tar=0; tar&lt;target_layers.length(); tar++)
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar][i];
+                    target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                    target_layers[tar]-&gt;setExpectation(target_prediction_list[tar][i]);
+                    target_layers[tar]-&gt;bpropNLL(targets_list[tar][i],nll_list(i,tar),bias_gradient);
+                    bias_gradient *= target_layers_weights[tar];
+                    bias_gradient *= masks_list[tar][i];
+                    target_layers[tar]-&gt;update(bias_gradient);
+                    if( hidden_layer2 )
+                        target_connections[tar]-&gt;bpropUpdate(hidden2_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                             hidden_gradient, bias_gradient,true);
+                    else
+                        target_connections[tar]-&gt;bpropUpdate(hidden_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                             hidden_gradient, bias_gradient,true);
+                }
+            }
+        }
+        else
+        {
+            for( int tar=0; tar&lt;target_layers.length(); tar++)
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar][i];
+                    target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                    target_layers[tar]-&gt;setExpectation(target_prediction_list[tar][i]);
+                    target_layers[tar]-&gt;bpropNLL(targets_list[tar][i],nll_list(i,tar),bias_gradient);
+                    bias_gradient *= target_layers_weights[tar];
+                    target_layers[tar]-&gt;update(bias_gradient);
+                    if( hidden_layer2 )
+                        target_connections[tar]-&gt;bpropUpdate(hidden2_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                             hidden_gradient, bias_gradient,true); 
+                    else
+                        target_connections[tar]-&gt;bpropUpdate(hidden_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                             hidden_gradient, bias_gradient,true); 
+                        
+                }
+            }
+        }
+
+        if (hidden_layer2)
+        {
+            hidden_layer2-&gt;bpropUpdate(
+                hidden2_act_no_bias_list[i], hidden2_list[i],
+                bias_gradient, hidden_gradient);
+                
+            hidden_connections-&gt;bpropUpdate(
+                hidden_list[i],
+                hidden2_act_no_bias_list[i], 
+                hidden_gradient, bias_gradient);
+        }
+            
+        if(i!=0 &amp;&amp; dynamic_connections )
+        {   
+            hidden_gradient += hidden_temporal_gradient;
+                
+            hidden_layer-&gt;bpropUpdate(
+                hidden_act_no_bias_list[i], hidden_list[i],
+                hidden_temporal_gradient, hidden_gradient);
+                
+            dynamic_connections-&gt;bpropUpdate(
+                hidden_list[i-1],
+                hidden_act_no_bias_list[i], // Here, it should be cond_bias, but doesn't matter
+                hidden_gradient, hidden_temporal_gradient);
+                
+            hidden_temporal_gradient &lt;&lt; hidden_gradient;
+                
+            input_connections-&gt;bpropUpdate(
+                input_list[i],
+                hidden_act_no_bias_list[i], 
+                visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
+                
+        }
+        else
+        {
+            hidden_layer-&gt;bpropUpdate(
+                hidden_act_no_bias_list[i], hidden_list[i],
+                hidden_temporal_gradient, hidden_gradient); // Not really temporal gradient, but this is the final iteration...
+            input_connections-&gt;bpropUpdate(
+                input_list[i],
+                hidden_act_no_bias_list[i], 
+                visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
+
+        }
+    }
+    
+}
 */
+
+
+/*
+void DenoisingRecurrentNet::oldtrain()
+{
+    MODULE_LOG &lt;&lt; &quot;train() called &quot; &lt;&lt; endl;
+
+    Vec input( inputsize() );
+    Vec target( targetsize() );
+    real weight = 0; // Unused
+    Vec train_costs( getTrainCostNames().length() );
+    train_costs.clear();
+    Vec train_n_items( getTrainCostNames().length() );
+
+    if( !initTrain() )
+    {
+        MODULE_LOG &lt;&lt; &quot;train() aborted&quot; &lt;&lt; endl;
+        return;
+    }
+
+    ProgressBar* pb = 0;
+
+    // clear stats of previous epoch
+    train_stats-&gt;forget();
+
+
+//    if(rbm_stage &lt; rbm_nstages)
+//    {
+//    }
+
+
+    if( stage &gt;= nstages )
+        return;
+
+    if( stage &lt; nstages )
+    {        
+
+        MODULE_LOG &lt;&lt; &quot;Training the whole model&quot; &lt;&lt; endl;
+
+        int init_stage = stage;
+        //int end_stage = max(0,nstages-(rbm_nstages + dynamic_nstages));
+        int end_stage = nstages;
+
+        MODULE_LOG &lt;&lt; &quot;  stage = &quot; &lt;&lt; stage &lt;&lt; endl;
+        MODULE_LOG &lt;&lt; &quot;  end_stage = &quot; &lt;&lt; end_stage &lt;&lt; endl;
+        MODULE_LOG &lt;&lt; &quot;  recurrent_net_learning_rate = &quot; &lt;&lt; recurrent_net_learning_rate &lt;&lt; endl;
+
+        if( report_progress &amp;&amp; stage &lt; end_stage )
+            pb = new ProgressBar( &quot;Recurrent training phase of &quot;+classname(),
+                                  end_stage - init_stage );
+
+        setLearningRate( recurrent_net_learning_rate );
+
+        int ith_sample_in_sequence = 0;
+        int inputsize_without_masks = inputsize() 
+            - ( use_target_layers_masks ? targetsize() : 0 );
+        int sum_target_elements = 0;
+        while(stage &lt; end_stage)
+        {
             train_costs.clear();
             train_n_items.clear();
             for(int sample=0 ; sample&lt;train_set-&gt;length() ; sample++ )
@@ -761,9 +1236,220 @@
 
     train_stats-&gt;finalize();
 }
+*/
 
+/* TO DO:
+verifier nombre de temps
+implementer correctmeent duration_to_number_of_timeframes(duration)
+declare nouvelles options et valeurs par defaut correctes
+*/
 
 
+/*
+Format de donnees:
+
+matrice de 2 colonnes:
+note, duree
+
+note: midi_number (21..108 numero de touche sur piano)
+      ou 0  (silence)
+      ou -1 (missing)
+      ou -999 (fin de sequence)
+
+duree: 1 double-croche
+       2 
+..16   exprimee en 1/16 de mesure (resultat du quantize de Stan)
+
+
+ */
+
+void DenoisingRecurrentNet::encodeSequence(Mat sequence, Mat&amp; encoded_sequence)
+{
+    //! Possibilities: &quot;timeframe&quot;, &quot;note_duration&quot;, &quot;note_octav_duration&quot;, &quot;generic&quot;
+    int prepend_zero_rows = input_window_size;
+
+    if(encoding==&quot;timeframe&quot;)
+        encode_onehot_timeframe(sequence, encoded_sequence, prepend_zero_rows);
+    else if(encoding==&quot;note_duration&quot;)
+        encode_onehot_note_octav_duration(sequence, encoded_sequence, prepend_zero_rows);
+    else if(encoding==&quot;note_octav_duration&quot;)
+        encode_onehot_note_octav_duration(sequence, encoded_sequence, prepend_zero_rows, true, 4);    
+    else if(encoding==&quot;raw_masked_supervised&quot;)
+        PLERROR(&quot;raw_masked_supervised encoding not yet implemented&quot;);
+    else if(encoding==&quot;generic&quot;)
+        PLERROR(&quot;generic encoding not yet implemented&quot;);
+    else
+        PLERROR(&quot;unsupported encoding: %s&quot;,encoding.c_str());
+}
+
+
+void DenoisingRecurrentNet::getSequence(int i, Mat&amp; seq) const
+{ 
+    int start = 0;
+    if(i&gt;0)
+        start = boundaries[i-1]+1;
+    int end = boundaries[i];
+    int w = train_set-&gt;width();
+    seq.resize(end-start, w);
+    train_set-&gt;getMat(start,0,seq);
+}
+
+
+void DenoisingRecurrentNet::setTrainingSet(VMat training_set, bool call_forget)
+{
+    inherited::setTrainingSet(training_set, call_forget);
+    locateSequenceBoundaries(training_set, boundaries, end_of_sequence_symbol);
+}
+
+
+void DenoisingRecurrentNet::locateSequenceBoundaries(VMat dataset, TVec&lt;int&gt;&amp; boundaries, real end_of_sequence_symbol)
+{
+    boundaries.resize(0);
+    int l = dataset-&gt;length();
+    for(int i=0; i&lt;l; i++)
+    {
+        if(dataset(i,0)==end_of_sequence_symbol)
+            boundaries.append(i);
+    }
+}
+
+
+
+
+// encodings
+
+
+/*
+  use note_nbits=13 bits for note + octav_nbits bits for octav + duration_nbits bits for duration
+  bit positions are numbered starting at 0.
+
+  if note is a silence (midi_number==0) then bit at position 12 is on
+  otherwise bit at position midi_number%12 is on
+
+  To compute octav bit position, we first compute the min and max of midi_number/12
+  this gives us the octav_min.
+  Then bit at position note_nbits+(midi_number/12)-octav_min is switched to on.
+
+  bit at position note_nbits+octav_nbits+duration is on
+ */
+
+void DenoisingRecurrentNet::encode_onehot_note_octav_duration(Mat sequence, Mat&amp; encoded_sequence, int prepend_zero_rows,
+                                                              bool use_silence, in octav_nbits, int duration_nbits)
+{
+    int l = sequence.length();
+    encoded_sequence.resize(prepend_zero_rows+l,note_nbits+octav_nbits+duration_nbits);
+    encoded_sequence.clear();
+    int octav_min = 10000;
+    int octav_max = -10000;
+
+    int note_nbits = use_silence ?13 :12;
+
+    if(octav_nbits&gt;0)
+    {
+        for(int i=0; i&lt;l; i++)
+        {
+            int midi_number = int(sequence(i,0));
+            int octav = midi_number/12;
+            if(octav&lt;octav_min)
+                octav_min = octav;
+            if(octav&gt;octav_max)
+                octav_max = octav;
+        }
+        if(octav_max-octav_min &gt; octav_nbits)
+            PLERROR(&quot;Octav range too big. Does not fit in octav_nbits&quot;);
+    }
+
+    
+    for(int i=0; i&lt;l; i++)
+    {
+        int midi_number = int(sequence(i,0));
+        if(midi_number==0) // silence
+        {
+            if(use_silence)
+                encoded_sequence(prepend_zero_rows+i,12) = 1;
+        }
+        else
+            encoded_sequence(prepend_zero_rows+i,midi_number%12) = 1;
+
+        if(octav_nbits&gt;0)
+        {
+            int octavpos = midi_number/12-octav_min;
+            encoded_sequence(prepend_zero_rows+i,note_nbits+octavpos) = 1;
+        }
+
+        int duration = int(sequence(i,1));
+        if(duration&lt;0 || duration&gt;=duration_nbits)
+            PLERROR(&quot;duration out of valid range&quot;);
+        encoded_sequence(prepend_zero_rows+i,note_nbits+octav_nbits+duration) = 1;
+    }
+}
+
+
+int DenoisingRecurrentNet::duration_to_number_of_timeframes(int duration)
+{
+    return duration+1;
+}
+
+/*
+  use note_nbits+1 bits for note at every timeframe
+  last bit indicates continuation of the preceeding note.
+ */
+
+void DenoisingRecurrentNet::encode_onehot_timeframe(Mat sequence, Mat&amp; encoded_sequence, 
+                                                    int prepend_zero_rows, bool use_silence)
+{
+    int l = sequence.length();
+    int newl = 0;
+
+    // First compute length of timeframe sequence
+    for(int i=0; i&lt;l; i++)
+    {
+        int duration = int(sequence(i,1));
+        newl += duration_to_number_of_timeframes(duration);
+    }
+
+    int nnotes = use_silence ?13 :12;
+
+    // reserve one extra bit to mean repetition
+    encoded_sequence.resize(prepend_zero_rows+newl, nnotes+1);
+    encoded_sequence.clear();
+
+    int k=prepend_zero_rows;
+    for(int i=0; i&lt;l; i++)
+    {
+        int midi_number = int(sequence(i,0));
+        if(midi_number==0) // silence
+        {
+            if(use_silence)
+                encoded_sequence(k++,12) = 1;
+        }
+        else
+            encoded_sequence(k++,midi_number%12) = 1;
+
+        int duration = int(sequence(i,1));
+        int nframes = duration_to_number_of_timeframes(duration);
+        while(--nframes&gt;0) // setb repetition bit
+            encoded_sequence(k++,nnotes) = 1;            
+    }    
+}
+    
+
+// input noise injection
+void inject_zero_forcing_noise(Mat sequence, double noise_prob)
+{
+    if(!sequence.isCompact())
+        PLEERROR(&quot;Expected a compact sequence&quot;);
+    real* p = sequence.data();
+    int n = sequence.size();
+    while(n--)
+    {
+        if(*p!=real(0.) &amp;&amp; random_gen-&gt;uniform_sample()&lt;noise_prob)
+            *p = real(0.);
+        ++p;
+    }
+}
+
+
 void DenoisingRecurrentNet::clamp_units(const Vec layer_vector,
                                              PP&lt;RBMLayer&gt; layer,
                                              TVec&lt;int&gt; symbol_sizes) const
@@ -840,110 +1526,7 @@
     }
 }
 
-void DenoisingRecurrentNet::recurrent_update()
-{
-        hidden_temporal_gradient.resize(hidden_layer-&gt;size);
-        hidden_temporal_gradient.clear();
-        for(int i=hidden_list.length()-1; i&gt;=0; i--){   
 
-            if( hidden_layer2 )
-                hidden_gradient.resize(hidden_layer2-&gt;size);
-            else
-                hidden_gradient.resize(hidden_layer-&gt;size);
-            hidden_gradient.clear();
-            if(use_target_layers_masks)
-            {
-                for( int tar=0; tar&lt;target_layers.length(); tar++)
-                {
-                    if( !fast_exact_is_equal(target_layers_weights[tar],0) )
-                    {
-                        target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar][i];
-                        target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
-                        target_layers[tar]-&gt;setExpectation(target_prediction_list[tar][i]);
-                        target_layers[tar]-&gt;bpropNLL(targets_list[tar][i],nll_list(i,tar),bias_gradient);
-                        bias_gradient *= target_layers_weights[tar];
-                        bias_gradient *= masks_list[tar][i];
-                        target_layers[tar]-&gt;update(bias_gradient);
-                        if( hidden_layer2 )
-                            target_connections[tar]-&gt;bpropUpdate(hidden2_list[i],target_prediction_act_no_bias_list[tar][i],
-                                                                 hidden_gradient, bias_gradient,true);
-                        else
-                            target_connections[tar]-&gt;bpropUpdate(hidden_list[i],target_prediction_act_no_bias_list[tar][i],
-                                                                 hidden_gradient, bias_gradient,true);
-                    }
-                }
-            }
-            else
-            {
-                for( int tar=0; tar&lt;target_layers.length(); tar++)
-                {
-                    if( !fast_exact_is_equal(target_layers_weights[tar],0) )
-                    {
-                        target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar][i];
-                        target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
-                        target_layers[tar]-&gt;setExpectation(target_prediction_list[tar][i]);
-                        target_layers[tar]-&gt;bpropNLL(targets_list[tar][i],nll_list(i,tar),bias_gradient);
-                        bias_gradient *= target_layers_weights[tar];
-                        target_layers[tar]-&gt;update(bias_gradient);
-                        if( hidden_layer2 )
-                            target_connections[tar]-&gt;bpropUpdate(hidden2_list[i],target_prediction_act_no_bias_list[tar][i],
-                                                                 hidden_gradient, bias_gradient,true); 
-                        else
-                            target_connections[tar]-&gt;bpropUpdate(hidden_list[i],target_prediction_act_no_bias_list[tar][i],
-                                                                 hidden_gradient, bias_gradient,true); 
-                        
-                    }
-                }
-            }
-
-            if (hidden_layer2)
-            {
-                hidden_layer2-&gt;bpropUpdate(
-                    hidden2_act_no_bias_list[i], hidden2_list[i],
-                    bias_gradient, hidden_gradient);
-                
-                hidden_connections-&gt;bpropUpdate(
-                    hidden_list[i],
-                    hidden2_act_no_bias_list[i], 
-                    hidden_gradient, bias_gradient);
-            }
-            
-            if(i!=0 &amp;&amp; dynamic_connections )
-            {   
-                hidden_gradient += hidden_temporal_gradient;
-                
-                hidden_layer-&gt;bpropUpdate(
-                    hidden_act_no_bias_list[i], hidden_list[i],
-                    hidden_temporal_gradient, hidden_gradient);
-                
-                dynamic_connections-&gt;bpropUpdate(
-                    hidden_list[i-1],
-                    hidden_act_no_bias_list[i], // Here, it should be cond_bias, but doesn't matter
-                    hidden_gradient, hidden_temporal_gradient);
-                
-                hidden_temporal_gradient &lt;&lt; hidden_gradient;
-                
-                input_connections-&gt;bpropUpdate(
-                    input_list[i],
-                    hidden_act_no_bias_list[i], 
-                    visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
-                
-            }
-            else
-            {
-                hidden_layer-&gt;bpropUpdate(
-                    hidden_act_no_bias_list[i], hidden_list[i],
-                    hidden_temporal_gradient, hidden_gradient); // Not really temporal gradient, but this is the final iteration...
-                input_connections-&gt;bpropUpdate(
-                    input_list[i],
-                    hidden_act_no_bias_list[i], 
-                    visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
-
-            }
-        }
-    
-}
-
 void DenoisingRecurrentNet::computeOutput(const Vec&amp; input, Vec&amp; output) const
 {
     PLERROR(&quot;DenoisingRecurrentNet::computeOutput(): this is a dynamic, &quot;

Modified: trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2008-06-20 19:38:59 UTC (rev 9160)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2008-06-20 19:59:07 UTC (rev 9161)
@@ -120,12 +120,61 @@
     //! Number of symbols for each symbolic field of train_set
     TVec&lt; TVec&lt;int&gt; &gt; target_symbol_sizes;
 
+    //! Chooses what type of encoding to apply to an input sequence
+    //! Possibilities: &quot;timeframe&quot;, &quot;note_duration&quot;, &quot;note_octav_duration&quot;, &quot;raw_masked_supervised&quot;
+    string encoding;
     
+    //! Input window size
+    int input_window_size;
+
+    // Phase greedy (unsupervised)
+    double input_noise_prob;
+    double input_reconstruction_lr;
+    double hidden_noise_prob;
+    double hidden_reconstruciton_lr;
+
+    // Phase noisy recurrent (supervised): uses input_noise_prob
+    double noisy_recurrent_lr;
+    double dynamic_gradient_scale_factor;
     
+    // Phase recurrent no noise (supervised fine tuning)
+    double recurrent_lr;
+
+    
     //#####  Not Options  #####################################################
 
 
 public:
+    //#####  Public static Functions  #########################################
+        
+    // Finding sequence end indexes
+    static TVec&lt;int&gt; locateSequenceBoundaries(VMat dataset, real end_of_sequence_symbol);
+
+    // encodings
+
+    static void encode_onehot_note_octav_duration(Mat sequence, Mat&amp; encoded_sequence, int prepend_zero_rows,
+                                                  bool use_silence=true, int octav_nbits=0, int duration_nbits=8);
+    
+    static void encode_onehot_timeframe(Mat sequence, Mat&amp; encoded_sequence, int prepend_zero_rows, 
+                                        bool use_silence=true);
+    
+
+    // input noise injection
+    void inject_zero_forcing_noise(Mat sequence, double noise_prob);
+
+    inline static Vec getInputWindow(Mat sequence, int startpos, int winsize)
+    { return sequence.subMatRows(startpos, winsize).toVec(); }
+          
+    // 
+    inline static void getNoteAndOctave(int midi_number, int&amp; note, int&amp; octave)
+    {
+        note = midi_number%12;
+        octave = midi_number/12;
+    }
+    
+
+
+public:
     //#####  Public Member Functions  #########################################
 
     //! Default constructor
@@ -138,6 +187,8 @@
     //! may depend on its inputsize(), targetsize() and set options).
     virtual int outputsize() const;
 
+    void setTrainingSet(VMat training_set, bool call_forget=true);
+
     //! (Re-)initializes the PLearner in its fresh state (that state may depend
     //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
     //! a fresh learner!).
@@ -162,11 +213,16 @@
     //! thus the test method).
     virtual TVec&lt;std::string&gt; getTestCostNames() const;
 
-    
+    //! Returns the number of sequences in the training_set
+    int nSequences() const
+    { return boundaries.length(); }
 
-//    //! Generate music in a folder
+    //! Returns the ith sequence
+    void getSequence(int i, Mat&amp; seq) const;
+
+    //! Generate music in a folder
     void generate(int t, int n);
-//
+
 //    //! Generate a part of the data in a folder
 //    void gen();
 
@@ -243,32 +299,43 @@
     mutable Vec hidden_temporal_gradient;
         
     //! List of hidden layers values
-    mutable TVec&lt; Vec &gt; hidden_list;
-    mutable TVec&lt; Vec &gt; hidden_act_no_bias_list;
+    // mutable TVec&lt; Vec &gt; hidden_list;
+    mutable Mat hidden_list;
+    // mutable TVec&lt; Vec &gt; hidden_act_no_bias_list;
+    mutable Mat hidden_act_no_bias_list;
 
     //! List of second hidden layers values
-    mutable TVec&lt; Vec &gt; hidden2_list;
-    mutable TVec&lt; Vec &gt; hidden2_act_no_bias_list;
+    // mutable TVec&lt; Vec &gt; hidden2_list;
+    mutable Mat hidden2_list;
+    // mutable TVec&lt; Vec &gt; hidden2_act_no_bias_list;
+    mutable Mat hidden2_act_no_bias_list;
 
     //! List of target prediction values
-    mutable TVec&lt; TVec&lt; Vec &gt; &gt; target_prediction_list;
-    mutable TVec&lt; TVec&lt; Vec &gt; &gt; target_prediction_act_no_bias_list;
+    // mutable TVec&lt; TVec&lt; Vec &gt; &gt; target_prediction_list;
+    mutable TVec&lt;Mat&gt; target_prediction_list;
+    // mutable TVec&lt; TVec&lt; Vec &gt; &gt; target_prediction_act_no_bias_list;
+    mutable TVec&lt;Mat&gt; target_prediction_act_no_bias_list;
 
     //! List of inputs values
     mutable TVec&lt; Vec &gt; input_list;
 
     //! List of inputs values
-    mutable TVec&lt; TVec&lt; Vec &gt; &gt; targets_list;
+    // mutable TVec&lt; TVec&lt; Vec &gt; &gt; targets_list;
+    mutable TVec&lt;Mat&gt; targets_list;
 
     //! List of the nll of the input samples in a sequence
     mutable Mat nll_list;
 
     //! List of all targets' masks
-    mutable TVec&lt; TVec&lt; Vec &gt; &gt; masks_list;
+    // mutable TVec&lt; TVec&lt; Vec &gt; &gt; masks_list;
+    mutable TVec&lt; Mat &gt; masks_list;
 
     //! Contribution of dynamic weights to hidden layer activation
     mutable Vec dynamic_act_no_bias_contribution;
 
+    TVec&lt;int&gt; boundaries;
+
+
 protected:
     //#####  Protected Member Functions  ######################################
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002608.html">[Plearn-commits] r9160 - trunk/python_modules/plearn/pymake
</A></li>
	<LI>Next message: <A HREF="002610.html">[Plearn-commits] r9162 - trunk/python_modules/plearn/learners
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2609">[ date ]</a>
              <a href="thread.html#2609">[ thread ]</a>
              <a href="subject.html#2609">[ subject ]</a>
              <a href="author.html#2609">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
