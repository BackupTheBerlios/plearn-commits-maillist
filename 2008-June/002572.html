<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9124 - trunk/python_modules/plearn/learners
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9124%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200806121336.m5CDarO4021103%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002571.html">
   <LINK REL="Next"  HREF="002573.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9124 - trunk/python_modules/plearn/learners</H1>
    <B>louradou at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9124%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200806121336.m5CDarO4021103%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9124 - trunk/python_modules/plearn/learners">louradou at mail.berlios.de
       </A><BR>
    <I>Thu Jun 12 15:36:53 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002571.html">[Plearn-commits] r9123 - trunk/python_modules/plearn/gui_tools
</A></li>
        <LI>Next message: <A HREF="002573.html">[Plearn-commits] r9125 - trunk/python_modules/plearn/utilities
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2572">[ date ]</a>
              <a href="thread.html#2572">[ thread ]</a>
              <a href="subject.html#2572">[ subject ]</a>
              <a href="author.html#2572">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: louradou
Date: 2008-06-12 15:36:52 +0200 (Thu, 12 Jun 2008)
New Revision: 9124

Modified:
   trunk/python_modules/plearn/learners/SVM.py
Log:
- added the number of train/valid/test samples in the table of results
- added an initial seed in the run to have always the same results



Modified: trunk/python_modules/plearn/learners/SVM.py
===================================================================
--- trunk/python_modules/plearn/learners/SVM.py	2008-06-11 22:52:10 UTC (rev 9123)
+++ trunk/python_modules/plearn/learners/SVM.py	2008-06-12 13:36:52 UTC (rev 9124)
@@ -1,3 +1,10 @@
+#! /usr/bin/env python
+#
+# This python code is to use with PLearn (A C++ Machine Learning Library)
+# Copyright (C) 2008 Jerome Louradour
+#
+# For any information or problem regarding this code, please contact <A HREF="https://lists.berlios.de/mailman/listinfo/plearn-commits">jeromelouradour at gmail.com</A>
+
 import os
 
 from libsvm import *
@@ -26,7 +33,6 @@
 
     user options:
 
-
         'C_initvalue': &lt;float&gt; Default value for 'C'.
 
         'verbosity': &lt;int&gt; Level of verbosity.
@@ -61,8 +67,6 @@
                        always includes at first the positive     
                        constant 'C' (trade-off bias/variance).   
 
-    private:
-
         'trials_param_list': &lt;list&gt; of &lt;dict&gt; hyperparameter values
                             that have been already tried.
 
@@ -1013,7 +1017,10 @@
                         valid_stats,
                         test_stats = None,
                         train_stats= None,
-                        only_stdout=False ):
+                        ntrain = None,
+                        nvalid = None,
+                        ntest = None,
+                        only_stdout= False ):
         if valid_stats==None and param == self.best_param:
                 valid_stats = self.valid_stats
         if test_stats==None and param == self.best_param:
@@ -1102,6 +1109,11 @@
                 else:
                     costvalues_string += &quot;None &quot;
         
+        for variable_name in ['ntrain','nvalid','ntest']:
+            if eval(variable_name) &lt;&gt; None:
+                preproc_optionnames += ' %s ' % variable_name
+                preproc_optionvalues += ' %s ' % eval(variable_name)
+        
         # Write the result in the file specified by 'results_filename'
         os.system('makeresults  %s %s %s %s;' % \
                             (self.results_filename,
@@ -1549,7 +1561,10 @@
         self.update_trials( self.best_param,
                             None, test_stats, train_stats )
         self.write_results( self.best_param,
-                            self.valid_stats, self.test_stats, self.train_stats )
+                            self.valid_stats, self.test_stats, self.train_stats,
+                            ntrain = (trainset &lt;&gt; None and trainset.length or 0),
+                            nvalid = (validset &lt;&gt; None and validset.length or 0),
+                            ntest = (testset &lt;&gt; None and testset.length or 0) )
         return dataspec
 
     &quot;&quot;&quot; THE interesting function of the class.
@@ -1559,6 +1574,7 @@
         cf. train_inputspec(), valid_inputspec(), and test_inputspec().
     &quot;&quot;&quot;
     def run(self, dataspec, param = None, L0 = None):
+        random.seed(17)
         assert self.testlevel &gt;= 0
         assert self.max_ntrials &gt; 0
         trainset = self.train_inputspec(dataspec)
@@ -1599,7 +1615,11 @@
 
                 # We reject the model (to avoid testing on it)
                 self.model = None
-                self.write_results( param, valid_stats, None, None, self.testlevel &lt; 2  )
+                self.write_results( param, valid_stats, None, None,
+                                    ntrain = (trainset &lt;&gt; None and trainset.length or 0),
+                                    nvalid = (validset &lt;&gt; None and validset.length or 0),
+                                    ntest = (testset &lt;&gt; None and testset.length or 0),
+                                    only_stdout = self.testlevel &lt; 2  )
 
             # Better valid cost is obtained!
             else:
@@ -1610,7 +1630,11 @@
                 if self.testlevel &gt; 0:
                     self.retrain_and_writeresults(dataspec)
                 else:
-                    self.write_results( param, valid_stats, None, None, True  )
+                    self.write_results( param, valid_stats, None, None,
+                                        ntrain = (trainset &lt;&gt; None and trainset.length or 0),
+                                        nvalid = (validset &lt;&gt; None and validset.length or 0),
+                                        ntest = (testset &lt;&gt; None and testset.length or 0),
+                                        only_stdout = True  )
 
             if( len(expert.trials_param_list)-L0 &gt;= self.max_ntrials
             or  ( self.min_cost &lt;&gt; None and expert.best_cost &lt;= self.min_cost ) ):


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002571.html">[Plearn-commits] r9123 - trunk/python_modules/plearn/gui_tools
</A></li>
	<LI>Next message: <A HREF="002573.html">[Plearn-commits] r9125 - trunk/python_modules/plearn/utilities
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2572">[ date ]</a>
              <a href="thread.html#2572">[ thread ]</a>
              <a href="subject.html#2572">[ subject ]</a>
              <a href="author.html#2572">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
