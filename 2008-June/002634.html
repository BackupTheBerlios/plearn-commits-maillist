<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9186 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9186%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806271512.m5RFCmiM015198%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002633.html">
   <LINK REL="Next"  HREF="002635.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9186 - trunk/plearn_learners_experimental</H1>
    <B>plearner at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9186%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806271512.m5RFCmiM015198%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9186 - trunk/plearn_learners_experimental">plearner at mail.berlios.de
       </A><BR>
    <I>Fri Jun 27 17:12:48 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002633.html">[Plearn-commits] r9185 - trunk/plearn_learners_experimental
</A></li>
        <LI>Next message: <A HREF="002635.html">[Plearn-commits] r9187 - in trunk: plearn/var plearn/vmat	plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2634">[ date ]</a>
              <a href="thread.html#2634">[ thread ]</a>
              <a href="subject.html#2634">[ subject ]</a>
              <a href="author.html#2634">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: plearner
Date: 2008-06-27 17:12:48 +0200 (Fri, 27 Jun 2008)
New Revision: 9186

Modified:
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
Log:
Development in progress on DenoisingRecurrentNet


Modified: trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2008-06-26 22:23:34 UTC (rev 9185)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2008-06-27 15:12:48 UTC (rev 9186)
@@ -460,9 +460,7 @@
     // reserve memory for sequences
     seq.resize(5000,2); // contains the current sequence
 
-    Vec input( inputsize() );
-    Vec target( targetsize() );
-    real weight = 0; // Unused
+    // real weight = 0; // Unused
     Vec train_costs( getTrainCostNames().length() );
     train_costs.clear();
     Vec train_n_items( getTrainCostNames().length() );
@@ -547,22 +545,21 @@
 
 
 //! does encoding if needed and populates the list.
-void DenoisingRecurrentNet::encodeSequenceAndPopulateLists(Mat seq)
+void DenoisingRecurrentNet::encodeSequenceAndPopulateLists(Mat seq) const
 {
     if(encoding==&quot;raw_masked_supervised&quot;) // old already encoded format (for backward testing)
         splitRawMaskedSupervisedSequence(seq);
     else
         encodeAndCreateSupervisedSequence(seq);
-    resize_lists();
 }
 
 // TO DO: penser a gestion des prepended dans ce cas
 // encodes sequ, then populates: inputslist, targets_list, masks_list
-void DenoisingRecurrentNet::encodeAndCreateSupervisedSequence(Mat seq)
+void DenoisingRecurrentNet::encodeAndCreateSupervisedSequence(Mat seq) const
 {
     encodeSequence(seq, encoded_seq);
     // now work with encoded_seq
-    int l = encoded_seq;
+    int l = encoded_seq.length();
     resize_lists(l);
 
     // TO DO: populate lists
@@ -576,7 +573,7 @@
 // TO DO: penser a prepend dans ce cas
 
 // For the (backward testing) raw_masked_supervised case. Populates: input_list, targets_list, masks_list
-void DenoisingRecurrentNet::splitRawMaskedSupervisedSequence(Mat seq)
+void DenoisingRecurrentNet::splitRawMaskedSupervisedSequence(Mat seq) const
 {
     int l = seq.length();
     resize_lists(l);
@@ -589,7 +586,7 @@
         input_list[i] = input_part(i);
 
     int ntargets = target_layers.length();
-    targets_list.resize(ntagets);
+    targets_list.resize(ntargets);
     masks_list.resize(ntargets);
     int startcol = 0; // starting column of next target in target_part and mask_part
     for(int k=0; k&lt;ntargets; k++)
@@ -602,7 +599,7 @@
 }
 
 
-void DenoisingRecurrentNet::resize_lists(int l)
+void DenoisingRecurrentNet::resize_lists(int l) const
 {
     input_list.resize(l);
     hidden_list.resize(l, hidden_layer-&gt;size);
@@ -620,7 +617,7 @@
 
     for( int tar=0; tar &lt; ntargets; tar++ )
     {
-        int targsize = target_layers[k]-&gt;size;
+        int targsize = target_layers[tar]-&gt;size;
         target_prediction_list[tar].resize(l, targsize);
         target_prediction_act_no_bias_list[tar].resize(l, targsize);
     }
@@ -631,12 +628,12 @@
 // TODO: think properly about prepended stuff
 
 // fprop accumulates costs in costs and counts in n_items
-void DenoisingRecurrentNet::fprop(Vec train_costs, Vec train_n_items)
+void DenoisingRecurrentNet::fprop(Vec train_costs, Vec train_n_items) const
 {
     int l = input_list.length();
     int ntargets = target_layers.length();
 
-    for(int i=0; i&lt;input_list.length(); i++ )
+    for(int i=0; i&lt;l; i++ )
     {
         Vec hidden_act_no_bias_i = hidden_act_no_bias_list(i);
         input_connections-&gt;fprop( input_list[i], hidden_act_no_bias_i);
@@ -671,8 +668,8 @@
             {
                 Vec target_prediction_i = target_prediction_list[tar](i);
                 Vec target_prediction_act_no_bias_i = target_prediction_act_no_bias_i;
-                target_connections[tar]-&gt;fprop(last_hidden, target_prediction_act_no_bias_list_i);
-                target_layers[tar]-&gt;fprop(target_prediction_act_no_bias_i, target_prediction_list_i);
+                target_connections[tar]-&gt;fprop(last_hidden, target_prediction_act_no_bias_i);
+                target_layers[tar]-&gt;fprop(target_prediction_act_no_bias_i, target_prediction_i);
                 if( use_target_layers_masks )
                     target_prediction_i *= masks_list[tar](i);
             }
@@ -798,14 +795,14 @@
                 hidden_temporal_gradient, hidden_gradient);
                 
             dynamic_connections-&gt;bpropUpdate(
-                hidden_list[i-1],
+                hidden_list(i-1),
                 hidden_act_no_bias_list(i), // Here, it should be cond_bias, but doesn't matter
                 hidden_gradient, hidden_temporal_gradient);
                 
             hidden_temporal_gradient &lt;&lt; hidden_gradient;
                 
             input_connections-&gt;bpropUpdate(
-                input_list(i),
+                input_list[i],
                 hidden_act_no_bias_list(i), 
                 visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
                 
@@ -816,7 +813,7 @@
                 hidden_act_no_bias_list(i), hidden_list(i),
                 hidden_temporal_gradient, hidden_gradient); // Not really temporal gradient, but this is the final iteration...
             input_connections-&gt;bpropUpdate(
-                input_list(i),
+                input_list[i],
                 hidden_act_no_bias_list(i), 
                 visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
 
@@ -1254,7 +1251,7 @@
 
  */
 
-void DenoisingRecurrentNet::encodeSequence(Mat sequence, Mat&amp; encoded_seq)
+void DenoisingRecurrentNet::encodeSequence(Mat sequence, Mat&amp; encoded_seq) const
 {
     //! Possibilities: &quot;timeframe&quot;, &quot;note_duration&quot;, &quot;note_octav_duration&quot;, &quot;generic&quot;
     int prepend_zero_rows = input_window_size;
@@ -1263,11 +1260,11 @@
     encoded_seq.resize(5000, 4);
 
     if(encoding==&quot;timeframe&quot;)
-        encode_onehot_timeframe(sequence, encoded_sequence, prepend_zero_rows);
+        encode_onehot_timeframe(sequence, encoded_seq, prepend_zero_rows);
     else if(encoding==&quot;note_duration&quot;)
-        encode_onehot_note_octav_duration(sequence, encoded_sequence, prepend_zero_rows);
+        encode_onehot_note_octav_duration(sequence, encoded_seq, prepend_zero_rows);
     else if(encoding==&quot;note_octav_duration&quot;)
-        encode_onehot_note_octav_duration(sequence, encoded_sequence, prepend_zero_rows, true, 4);    
+        encode_onehot_note_octav_duration(sequence, encoded_seq, prepend_zero_rows, true, 4);    
     else if(encoding==&quot;raw_masked_supervised&quot;)
         PLERROR(&quot;raw_masked_supervised encoding not yet implemented&quot;);
     else if(encoding==&quot;generic&quot;)
@@ -1298,6 +1295,7 @@
 
 void DenoisingRecurrentNet::locateSequenceBoundaries(VMat dataset, TVec&lt;int&gt;&amp; boundaries, real end_of_sequence_symbol)
 {
+    boundaries.resize(10000);
     boundaries.resize(0);
     int l = dataset-&gt;length();
     for(int i=0; i&lt;l; i++)
@@ -1328,16 +1326,16 @@
  */
 
 void DenoisingRecurrentNet::encode_onehot_note_octav_duration(Mat sequence, Mat&amp; encoded_sequence, int prepend_zero_rows,
-                                                              bool use_silence, in octav_nbits, int duration_nbits)
+                                                              bool use_silence, int octav_nbits, int duration_nbits)
 {
     int l = sequence.length();
+    int note_nbits = use_silence ?13 :12;
+
     encoded_sequence.resize(prepend_zero_rows+l,note_nbits+octav_nbits+duration_nbits);
     encoded_sequence.clear();
     int octav_min = 10000;
     int octav_max = -10000;
 
-    int note_nbits = use_silence ?13 :12;
-
     if(octav_nbits&gt;0)
     {
         for(int i=0; i&lt;l; i++)
@@ -1429,10 +1427,10 @@
     
 
 // input noise injection
-void inject_zero_forcing_noise(Mat sequence, double noise_prob)
+void DenoisingRecurrentNet::inject_zero_forcing_noise(Mat sequence, double noise_prob)
 {
     if(!sequence.isCompact())
-        PLEERROR(&quot;Expected a compact sequence&quot;);
+        PLERROR(&quot;Expected a compact sequence&quot;);
     real* p = sequence.data();
     int n = sequence.size();
     while(n--)
@@ -1542,13 +1540,10 @@
                   VMat testoutputs, VMat testcosts)const
 {
     int len = testset.length();
-    Vec input;
-    Vec target;
-    real weight;
 
+    //Vec output(outputsize());
+    //output.clear();
 
-    Vec output(outputsize());
-    output.clear();
     Vec costs(nTestCosts());
     costs.clear();
     Vec n_items(nTestCosts());
@@ -1583,7 +1578,7 @@
         seq.resize(seqlen, w);
         testset-&gt;getMat(start,0,seq);
         encodeSequenceAndPopulateLists(seq);
-        fprop(test_costs, test_n_items);
+        fprop(costs, n_items);
 
         if (testoutputs)
         {
@@ -1609,9 +1604,6 @@
             pb-&gt;update(pos);
     }
 
-
-    }
-
     for(int i=0; i&lt;costs.length(); i++)
     {
         if( !fast_exact_is_equal(target_layers_weights[i],0) )
@@ -1928,8 +1920,16 @@
     return getTestCostNames();
 }
 
+
 void DenoisingRecurrentNet::generate(int t, int n)
 {
+    PLERROR(&quot;generate not yet implemented&quot;);
+}
+
+
+/*
+void DenoisingRecurrentNet::oldgenerate(int t, int n)
+{
     //PPath* the_filename = &quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/generate/scoreGen.amat&quot;;
     data = new AutoVMatrix();
     //data-&gt;filename = &quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/listData/target_tm12_input_t_tm12_tp12/scoreGen_tar_tm12__in_tm12_tp12.amat&quot;;
@@ -1955,10 +1955,10 @@
 
     Vec output(outputsize());
     output.clear();
-    /*Vec costs(nTestCosts());
-    costs.clear();
-    Vec n_items(nTestCosts());
-    n_items.clear();*/
+//     Vec costs(nTestCosts());
+//     costs.clear();
+//     Vec n_items(nTestCosts());
+//     n_items.clear();
 
     int r,r2;
     
@@ -1987,32 +1987,32 @@
             }       
         }
     
-/*
-        for (int k = 1; k &lt;= t; k++)
-        {
-            partTarSize = outputsize();
-            for( int tar=0; tar &lt; target_layers.length(); tar++ )
-            {
-                if(i&gt;=t){
-                    input.subVec(inputsize_without_masks-(tarSize*(t-k))-partTarSize-1,target_layers[tar]-&gt;size) &lt;&lt; target_prediction_list[tar][ith_sample_in_sequence-k];
-                    partTarSize -= target_layers[tar]-&gt;size;
-                }
-            }
-        }
-*/
+
+//         for (int k = 1; k &lt;= t; k++)
+//         {
+//             partTarSize = outputsize();
+//             for( int tar=0; tar &lt; target_layers.length(); tar++ )
+//             {
+//                 if(i&gt;=t){
+//                     input.subVec(inputsize_without_masks-(tarSize*(t-k))-partTarSize-1,target_layers[tar]-&gt;size) &lt;&lt; target_prediction_list[tar][ith_sample_in_sequence-k];
+//                     partTarSize -= target_layers[tar]-&gt;size;
+//                 }
+//             }
+//         }
+
         if( fast_exact_is_equal(input[0],end_of_sequence_symbol) )
         {
-            /*  ith_sample_in_sequence = 0;
-            hidden_list.resize(0);
-            hidden_act_no_bias_list.resize(0);
-            hidden2_list.resize(0);
-            hidden2_act_no_bias_list.resize(0);
-            target_prediction_list.resize(0);
-            target_prediction_act_no_bias_list.resize(0);
-            input_list.resize(0);
-            targets_list.resize(0);
-            nll_list.resize(0,0);
-            masks_list.resize(0);*/
+//             ith_sample_in_sequence = 0;
+//             hidden_list.resize(0);
+//             hidden_act_no_bias_list.resize(0);
+//             hidden2_list.resize(0);
+//             hidden2_act_no_bias_list.resize(0);
+//             target_prediction_list.resize(0);
+//             target_prediction_act_no_bias_list.resize(0);
+//             input_list.resize(0);
+//             targets_list.resize(0);
+//             nll_list.resize(0,0);
+//             masks_list.resize(0);
 
             
 
@@ -2186,18 +2186,18 @@
                 nll_list(ith_sample_in_sequence,tar) = 
                     target_layers[tar]-&gt;fpropNLL( 
                         targets_list[tar][ith_sample_in_sequence] ); 
-                /*costs[tar] += nll_list(ith_sample_in_sequence,tar);
+//                 costs[tar] += nll_list(ith_sample_in_sequence,tar);
                 
-                // Normalize by the number of things to predict
-                if( use_target_layers_masks )
-                {
-                    n_items[tar] += sum(
-                        input.subVec( inputsize_without_masks 
-                                      + sum_target_elements, 
-                                      target_layers_n_of_target_elements[tar]) );
-                }
-                else
-                n_items[tar]++;*/
+//                 // Normalize by the number of things to predict
+//                 if( use_target_layers_masks )
+//                 {
+//                     n_items[tar] += sum(
+//                         input.subVec( inputsize_without_masks 
+//                                       + sum_target_elements, 
+//                                       target_layers_n_of_target_elements[tar]) );
+//                 }
+//                 else
+//                 n_items[tar]++;
             }
             if( use_target_layers_masks )
                 sum_target_elements += 
@@ -2209,30 +2209,18 @@
 
     }
 
-    /*  
-    ith_sample_in_sequence = 0;
-    hidden_list.resize(0);
-    hidden_act_no_bias_list.resize(0);
-    hidden2_list.resize(0);
-    hidden2_act_no_bias_list.resize(0);
-    target_prediction_list.resize(0);
-    target_prediction_act_no_bias_list.resize(0);
-    input_list.resize(0);
-    targets_list.resize(0);
-    nll_list.resize(0,0);
-    masks_list.resize(0);   
+//     ith_sample_in_sequence = 0;
+//     hidden_list.resize(0);
+//     hidden_act_no_bias_list.resize(0);
+//     hidden2_list.resize(0);
+//     hidden2_act_no_bias_list.resize(0);
+//     target_prediction_list.resize(0);
+//     target_prediction_act_no_bias_list.resize(0);
+//     input_list.resize(0);
+//     targets_list.resize(0);
+//     nll_list.resize(0,0);
+//     masks_list.resize(0);   
 
-
-    */
-
-
-
-
-
-
-
-
-
     
     //Vec tempo;
     //TVec&lt;real&gt; tempo;
@@ -2264,6 +2252,9 @@
      myfile.close();
 
 }
+
+*/
+
 /*
 void DenoisingRecurrentNet::gen()
 {

Modified: trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2008-06-26 22:23:34 UTC (rev 9185)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2008-06-27 15:12:48 UTC (rev 9186)
@@ -153,7 +153,8 @@
     // encodings
 
     //! encodes sequence according to specified encoding option
-    void encodeSequence(Mat sequence, Mat&amp; encoded_seq);
+    //! (declared const because it needs to be called in test)
+    void encodeSequence(Mat sequence, Mat&amp; encoded_seq) const;
 
     static void encode_onehot_note_octav_duration(Mat sequence, Mat&amp; encoded_sequence, int prepend_zero_rows,
                                                   bool use_silence=true, int octav_nbits=0, int duration_nbits=8);
@@ -221,7 +222,7 @@
 
     //! Returns the number of sequences in the training_set
     int nSequences() const
-    { return boundaries.length(); }
+    { return trainset_boundaries.length(); }
 
     //! Returns the ith sequence
     void getSequence(int i, Mat&amp; seq) const;
@@ -340,10 +341,10 @@
     mutable Vec dynamic_act_no_bias_contribution;
 
     TVec&lt;int&gt; trainset_boundaries;
-    TVec&lt;int&gt; testset_boundaries;
+    mutable TVec&lt;int&gt; testset_boundaries;
 
-    Mat seq; // contains the current train or test sequence
-    Mat encoded_seq; // contains encoded version of current train or test sequence
+    mutable Mat seq; // contains the current train or test sequence
+    mutable Mat encoded_seq; // contains encoded version of current train or test sequence
 
 protected:
     //#####  Protected Member Functions  ######################################
@@ -357,15 +358,21 @@
     //! This does the actual building.
     void build_();
 
+    // note: the following functions are declared const because they have
+    // to be called by test (which is const). Similarly, the members they 
+    // manipulate are all declared mutable.
+    void fprop(Vec train_costs, Vec train_n_items) const;
+
     //! does encoding if needed and populates the list.
-    void encodeSequenceAndPopulateLists(Mat seq);
+    void encodeSequenceAndPopulateLists(Mat seq) const;
 
     //! encodes seq, then populates: inputslist, targets_list, masks_list
-    void encodeAndCreateSupervisedSequence(Mat seq);
+    void encodeAndCreateSupervisedSequence(Mat seq) const;
 
     //! For the (backward testing) raw_masked_supervised case. Populates: input_list, targets_list, masks_list
-    void splitRawMaskedSupervisedSequence(Mat seq);
+    void splitRawMaskedSupervisedSequence(Mat seq) const;
 
+    void resize_lists(int l) const;
 
 private:
     //#####  Private Data Members  ############################################


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002633.html">[Plearn-commits] r9185 - trunk/plearn_learners_experimental
</A></li>
	<LI>Next message: <A HREF="002635.html">[Plearn-commits] r9187 - in trunk: plearn/var plearn/vmat	plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2634">[ date ]</a>
              <a href="thread.html#2634">[ thread ]</a>
              <a href="subject.html#2634">[ subject ]</a>
              <a href="author.html#2634">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
