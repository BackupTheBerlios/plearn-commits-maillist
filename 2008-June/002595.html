<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9147 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9147%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806182054.m5IKs1Mi003278%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002594.html">
   <LINK REL="Next"  HREF="002596.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9147 - trunk/plearn_learners_experimental</H1>
    <B>larocheh at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9147%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806182054.m5IKs1Mi003278%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9147 - trunk/plearn_learners_experimental">larocheh at mail.berlios.de
       </A><BR>
    <I>Wed Jun 18 22:54:01 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002594.html">[Plearn-commits] r9146 - trunk/plearn/base
</A></li>
        <LI>Next message: <A HREF="002596.html">[Plearn-commits] r9148 - trunk/python_modules/plearn/gui_tools
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2595">[ date ]</a>
              <a href="thread.html#2595">[ thread ]</a>
              <a href="subject.html#2595">[ subject ]</a>
              <a href="author.html#2595">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: larocheh
Date: 2008-06-18 22:54:00 +0200 (Wed, 18 Jun 2008)
New Revision: 9147

Modified:
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
Log:
Added the Test-Centric NLMP variant


Modified: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2008-06-18 20:46:01 UTC (rev 9146)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2008-06-18 20:54:00 UTC (rev 9147)
@@ -197,6 +197,13 @@
                   OptionBase::buildoption,
                   &quot;Indication that the value of sigma noise should not be learned.\n&quot;);
 
+    declareOption(ol, &quot;use_test_centric_nlmp&quot;, 
+                  &amp;DeepNonLocalManifoldParzen::use_test_centric_nlmp,
+                  OptionBase::buildoption,
+                  &quot;Indication that the Test-Centric NLMP variant should &quot;
+		  &quot;be used.\n&quot;
+		  &quot;In this case, train_one_network_per_class must be true.\n&quot;);
+
     declareOption(ol, &quot;greedy_stages&quot;, 
                   &amp;DeepNonLocalManifoldParzen::greedy_stages,
                   OptionBase::learntoption,
@@ -275,6 +282,17 @@
             PLERROR(&quot;DeepNonLocalManifoldParzen::build_() - \n&quot;
                     &quot;min_sigma_noise should be &gt; or = to 0.\n&quot;);
 
+	if( use_test_centric_nlmp &amp;&amp; !train_one_network_per_class )
+	    PLERROR(&quot;DeepNonLocalManifoldParzen::build_() - \n&quot;
+                    &quot;train_one_network_per_class must be true for &quot;
+		    &quot;Test-Centric NLMP variant.\n&quot;);
+	  
+	if( use_test_centric_nlmp &amp;&amp; n_classes &gt; 1)
+	    PLERROR(&quot;DeepNonLocalManifoldParzen::build_() - \n&quot;
+                    &quot;n_classes must be &gt; 1 for &quot;
+		    &quot;Test-Centric NLMP variant.\n&quot;);
+	  
+
         if(greedy_stages.length() == 0)
         {
             greedy_stages.resize(n_layers-1);
@@ -1137,115 +1155,145 @@
     Vec target(targetsize());
     real weight;
 
-    if( save_manifold_parzen_parameters )
+    if( use_test_centric_nlmp )
     {
-        updateManifoldParzenParameters();
-
-        int input_j_index;
         for( int i=0; i&lt;n_classes; i++ )
+	{
+	    computeManifoldParzenParameters( input, F, mu, 
+					     pre_sigma_noise, U, sm_svd,
+					     i);
+                    
+	    sigma_noise = pre_sigma_noise[0]*pre_sigma_noise[0] 
+	        + min_sigma_noise;
+                    
+	    mahal = -0.5*pownorm(mu)/sigma_noise;      
+	    norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*
+	        pl_log(sigma_noise);
+        
+	    for(int k=0; k&lt;n_components; k++)
+	    { 
+		uk = U(k);
+		dotp = dot(mu,uk);
+		coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
+		mahal -= dotp*dotp*0.5*coef;
+		norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
+	    }
+	    
+	    log_p_x_g_y = norm_term + mahal;
+	    test_votes[i] = log_p_x_g_y ;
+	}        
+    }
+    else
+    {
+        if( save_manifold_parzen_parameters )
         {
-            for( int j=0; 
-                 j&lt;(n_classes &gt; 1 ? 
-                    class_datasets[i]-&gt;length() 
-                    : train_set-&gt;length()); 
-                 j++ )
+            updateManifoldParzenParameters();
+        
+            int input_j_index;
+            for( int i=0; i&lt;n_classes; i++ )
             {
-                if( n_classes &gt; 1 )
+                for( int j=0; 
+                     j&lt;(n_classes &gt; 1 ? 
+                        class_datasets[i]-&gt;length() 
+                        : train_set-&gt;length()); 
+                     j++ )
                 {
-                    class_datasets[i]-&gt;getExample(j,input_j,target,weight);
-                    input_j_index = class_datasets[i]-&gt;indices[j];
-                }
-                else
-                {
-                    train_set-&gt;getExample(j,input_j,target,weight);
-                    input_j_index = j;
-                }
-
-                U &lt;&lt; eigenvectors[input_j_index];
-                sm_svd &lt;&lt; eigenvalues(input_j_index);
-                sigma_noise = sigma_noises[input_j_index];
-                mu &lt;&lt; mus(input_j_index);
-
-                substract(input,input_j,diff_neighbor_input); 
-                substract(diff_neighbor_input,mu,diff); 
+                    if( n_classes &gt; 1 )
+                    {
+                        class_datasets[i]-&gt;getExample(j,input_j,target,weight);
+                        input_j_index = class_datasets[i]-&gt;indices[j];
+                    }
+                    else
+                    {
+                        train_set-&gt;getExample(j,input_j,target,weight);
+                        input_j_index = j;
+                    }
+        
+                    U &lt;&lt; eigenvectors[input_j_index];
+                    sm_svd &lt;&lt; eigenvalues(input_j_index);
+                    sigma_noise = sigma_noises[input_j_index];
+                    mu &lt;&lt; mus(input_j_index);
+        
+                    substract(input,input_j,diff_neighbor_input); 
+                    substract(diff_neighbor_input,mu,diff); 
+                        
+                    mahal = -0.5*pownorm(diff)/sigma_noise;      
+                    norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*
+                        pl_log(sigma_noise);
+        
+                    for(int k=0; k&lt;n_components; k++)
+                    { 
+                        uk = U(k);
+                        dotp = dot(diff,uk);
+                        coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
+                        mahal -= dotp*dotp*0.5*coef;
+                        norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
+                    }
                     
-                mahal = -0.5*pownorm(diff)/sigma_noise;      
-                norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*
-                    pl_log(sigma_noise);
-
-                for(int k=0; k&lt;n_components; k++)
-                { 
-                    uk = U(k);
-                    dotp = dot(diff,uk);
-                    coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
-                    mahal -= dotp*dotp*0.5*coef;
-                    norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
+                    if( j==0 )
+                        log_p_x_g_y = norm_term + mahal;
+                    else
+                        log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
                 }
-                
-                if( j==0 )
-                    log_p_x_g_y = norm_term + mahal;
-                else
-                    log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
+        
+                test_votes[i] = log_p_x_g_y;
             }
-
-            test_votes[i] = log_p_x_g_y;
         }
-    }
-    else
-    {
-
-        for( int i=0; i&lt;n_classes; i++ )
+        else
         {
-            for( int j=0; 
-                 j&lt;(n_classes &gt; 1 ? 
-                    class_datasets[i]-&gt;length() 
-                    : train_set-&gt;length()); 
-                 j++ )
+        
+            for( int i=0; i&lt;n_classes; i++ )
             {
-                if( n_classes &gt; 1 )
+                for( int j=0; 
+                     j&lt;(n_classes &gt; 1 ? 
+                        class_datasets[i]-&gt;length() 
+                        : train_set-&gt;length()); 
+                     j++ )
                 {
-                    class_datasets[i]-&gt;getExample(j,input_j,target,weight);
-                    computeManifoldParzenParameters( input_j, F, mu, 
-                                                     pre_sigma_noise, U, sm_svd,
-                                                     (int) target[0]);
-                }
-                else
-                {
-                    train_set-&gt;getExample(j,input_j,target,weight);
-                    computeManifoldParzenParameters( input_j, F, mu, 
-                                                     pre_sigma_noise, U, sm_svd );
-                }
-
-                
-                sigma_noise = pre_sigma_noise[0]*pre_sigma_noise[0] 
-                    + min_sigma_noise;
-                
-                substract(input,input_j,diff_neighbor_input); 
-                substract(diff_neighbor_input,mu,diff); 
+                    if( n_classes &gt; 1 )
+                    {
+                        class_datasets[i]-&gt;getExample(j,input_j,target,weight);
+                        computeManifoldParzenParameters( input_j, F, mu, 
+                                                         pre_sigma_noise, U, sm_svd,
+                                                         (int) target[0]);
+                    }
+                    else
+                    {
+                        train_set-&gt;getExample(j,input_j,target,weight);
+                        computeManifoldParzenParameters( input_j, F, mu, 
+                                                         pre_sigma_noise, U, sm_svd );
+                    }
+        
                     
-                mahal = -0.5*pownorm(diff)/sigma_noise;      
-                norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*
-                    pl_log(sigma_noise);
-
-                for(int k=0; k&lt;n_components; k++)
-                { 
-                    uk = U(k);
-                    dotp = dot(diff,uk);
-                    coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
-                    mahal -= dotp*dotp*0.5*coef;
-                    norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
+                    sigma_noise = pre_sigma_noise[0]*pre_sigma_noise[0] 
+                        + min_sigma_noise;
+                    
+                    substract(input,input_j,diff_neighbor_input); 
+                    substract(diff_neighbor_input,mu,diff); 
+                        
+                    mahal = -0.5*pownorm(diff)/sigma_noise;      
+                    norm_term = - n/2.0 * Log2Pi - 0.5*(n-n_components)*
+                        pl_log(sigma_noise);
+        
+                    for(int k=0; k&lt;n_components; k++)
+                    { 
+                        uk = U(k);
+                        dotp = dot(diff,uk);
+                        coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
+                        mahal -= dotp*dotp*0.5*coef;
+                        norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
+                    }
+                    
+                    if( j==0 )
+                        log_p_x_g_y = norm_term + mahal;
+                    else
+                        log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
                 }
-                
-                if( j==0 )
-                    log_p_x_g_y = norm_term + mahal;
-                else
-                    log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
+        
+                test_votes[i] = log_p_x_g_y;
             }
-
-            test_votes[i] = log_p_x_g_y;
         }
     }
-
     if( n_classes &gt; 1 )
         output[0] = argmax(test_votes);
     else
@@ -1297,8 +1345,9 @@
                 costs[n_layers-1] = 0;
             else
                 costs[n_layers-1] = 1;
-            costs[n_layers] = - test_votes[target_class]
-                +pl_log(class_datasets[target_class]-&gt;length()); // Must take into account the 1/n normalization
+	    if( !use_test_centric_nlmp )
+	        costs[n_layers] = - test_votes[target_class]
+                    +pl_log(class_datasets[target_class]-&gt;length()); // Must take into account the 1/n normalization
         }
         else
         {

Modified: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2008-06-18 20:46:01 UTC (rev 9146)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2008-06-18 20:54:00 UTC (rev 9147)
@@ -127,6 +127,10 @@
     //! Indication that the value of sigma noise should not be learned.
     bool do_not_learn_sigma_noise;
 
+    //! Indication that the Test-Centric NLMP variant should be used.
+    //! In this case, train_one_network_per_class must be true.
+    bool use_test_centric_nlmp;
+
     //#####  Public Learnt Options  ###########################################
 
     //! Number of layers


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002594.html">[Plearn-commits] r9146 - trunk/plearn/base
</A></li>
	<LI>Next message: <A HREF="002596.html">[Plearn-commits] r9148 - trunk/python_modules/plearn/gui_tools
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2595">[ date ]</a>
              <a href="thread.html#2595">[ thread ]</a>
              <a href="subject.html#2595">[ subject ]</a>
              <a href="author.html#2595">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
