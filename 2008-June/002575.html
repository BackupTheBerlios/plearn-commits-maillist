<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9127 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9127%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806161743.m5GHh4aN032565%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002574.html">
   <LINK REL="Next"  HREF="002576.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9127 - trunk/plearn_learners_experimental</H1>
    <B>larocheh at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9127%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806161743.m5GHh4aN032565%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9127 - trunk/plearn_learners_experimental">larocheh at mail.berlios.de
       </A><BR>
    <I>Mon Jun 16 19:43:04 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002574.html">[Plearn-commits] r9126 - trunk/plearn_learners_experimental
</A></li>
        <LI>Next message: <A HREF="002576.html">[Plearn-commits] r9128 - trunk/plearn/python
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2575">[ date ]</a>
              <a href="thread.html#2575">[ thread ]</a>
              <a href="subject.html#2575">[ subject ]</a>
              <a href="author.html#2575">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: larocheh
Date: 2008-06-16 19:43:03 +0200 (Mon, 16 Jun 2008)
New Revision: 9127

Modified:
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
Log:
Corrected a bug which made the density estimator not integrate to one...



Modified: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2008-06-16 16:39:23 UTC (rev 9126)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2008-06-16 17:43:03 UTC (rev 9127)
@@ -66,6 +66,7 @@
     n_components( 1 ),
     min_sigma_noise( 0 ),
     n_classes( -1 ),
+    train_one_network_per_class( false ),
     output_connections_l1_penalty_factor( 0 ),
     output_connections_l2_penalty_factor( 0 ),
     save_manifold_parzen_parameters( false ),
@@ -85,7 +86,7 @@
                   &amp;DeepNonLocalManifoldParzen::cd_learning_rate,
                   OptionBase::buildoption,
                   &quot;The learning rate used during the RBM &quot;
-                  &quot;contrastive divergence training&quot;);
+                  &quot;contrastive divergence training.\n&quot;);
 
     declareOption(ol, &quot;cd_decrease_ct&quot;, 
                   &amp;DeepNonLocalManifoldParzen::cd_decrease_ct,
@@ -100,7 +101,7 @@
                   &amp;DeepNonLocalManifoldParzen::greedy_learning_rate,
                   OptionBase::buildoption,
                   &quot;The learning rate used during the autoassociator &quot;
-                  &quot;gradient descent training&quot;);
+                  &quot;gradient descent training.\n&quot;);
 
     declareOption(ol, &quot;greedy_decrease_ct&quot;, 
                   &amp;DeepNonLocalManifoldParzen::greedy_decrease_ct,
@@ -114,7 +115,7 @@
     declareOption(ol, &quot;fine_tuning_learning_rate&quot;, 
                   &amp;DeepNonLocalManifoldParzen::fine_tuning_learning_rate,
                   OptionBase::buildoption,
-                  &quot;The learning rate used during the fine tuning gradient descent&quot;);
+                  &quot;The learning rate used during the fine tuning gradient descent.\n&quot;);
 
     declareOption(ol, &quot;fine_tuning_decrease_ct&quot;, 
                   &amp;DeepNonLocalManifoldParzen::fine_tuning_decrease_ct,
@@ -139,50 +140,57 @@
 
     declareOption(ol, &quot;connections&quot;, &amp;DeepNonLocalManifoldParzen::connections,
                   OptionBase::buildoption,
-                  &quot;The weights of the connections between the layers&quot;);
+                  &quot;The weights of the connections between the layers.\n&quot;);
 
     declareOption(ol, &quot;reconstruction_connections&quot;, 
                   &amp;DeepNonLocalManifoldParzen::reconstruction_connections,
                   OptionBase::buildoption,
-                  &quot;The reconstruction weights of the autoassociators&quot;);
+                  &quot;The reconstruction weights of the autoassociators.\n&quot;);
 
     declareOption(ol, &quot;k_neighbors&quot;, 
                   &amp;DeepNonLocalManifoldParzen::k_neighbors,
                   OptionBase::buildoption,
                   &quot;Number of good nearest neighbors to attract and bad nearest &quot;
-                  &quot;neighbors to repel.&quot;);
+                  &quot;neighbors to repel.\n&quot;);
 
     declareOption(ol, &quot;n_components&quot;, 
                   &amp;DeepNonLocalManifoldParzen::n_components,
                   OptionBase::buildoption,
-                  &quot;Dimensionality of the manifold&quot;);
+                  &quot;Dimensionality of the manifold.\n&quot;);
 
     declareOption(ol, &quot;min_sigma_noise&quot;, 
                   &amp;DeepNonLocalManifoldParzen::min_sigma_noise,
                   OptionBase::buildoption,
-                  &quot;Minimum value for the noise variance&quot;);
+                  &quot;Minimum value for the noise variance.\n&quot;);
 
     declareOption(ol, &quot;n_classes&quot;, 
                   &amp;DeepNonLocalManifoldParzen::n_classes,
                   OptionBase::buildoption,
-                  &quot;Number of classes.&quot;);
+                  &quot;Number of classes. If n_classes = 1, learner will output\n&quot;
+                  &quot;log likelihood of a given input. If n_classes &gt; 1,\n&quot;
+                  &quot;classification will be performed.\n&quot;);
 
+    declareOption(ol, &quot;train_one_network_per_class&quot;, 
+                  &amp;DeepNonLocalManifoldParzen::train_one_network_per_class,
+                  OptionBase::buildoption,
+                  &quot;Indication that one network per class should be trained.\n&quot;);
+
     declareOption(ol, &quot;output_connections_l1_penalty_factor&quot;, 
                   &amp;DeepNonLocalManifoldParzen::output_connections_l1_penalty_factor,
                   OptionBase::buildoption,
-                  &quot;Output weights L1 penalty factor&quot;);
+                  &quot;Output weights L1 penalty factor.\n&quot;);
 
     declareOption(ol, &quot;output_connections_l2_penalty_factor&quot;, 
                   &amp;DeepNonLocalManifoldParzen::output_connections_l2_penalty_factor,
                   OptionBase::buildoption,
-                  &quot;Output weights L2 penalty factor&quot;);
+                  &quot;Output weights L2 penalty factor.\n&quot;);
 
     declareOption(ol, &quot;save_manifold_parzen_parameters&quot;, 
                   &amp;DeepNonLocalManifoldParzen::save_manifold_parzen_parameters,
                   OptionBase::buildoption,
                   &quot;Indication that the parameters for the manifold parzen\n&quot;
                   &quot;windows estimator should be saved during test, to speed up &quot;
-                  &quot;testing.&quot;);
+                  &quot;testing.\n&quot;);
 
     declareOption(ol, &quot;do_not_learn_sigma_noise&quot;, 
                   &amp;DeepNonLocalManifoldParzen::do_not_learn_sigma_noise,
@@ -198,19 +206,19 @@
 
     declareOption(ol, &quot;n_layers&quot;, &amp;DeepNonLocalManifoldParzen::n_layers,
                   OptionBase::learntoption,
-                  &quot;Number of layers&quot;
+                  &quot;Number of layers.\n&quot;
         );
 
     declareOption(ol, &quot;output_connections&quot;, 
                   &amp;DeepNonLocalManifoldParzen::output_connections,
                   OptionBase::learntoption,
-                  &quot;Output weights&quot;
+                  &quot;Output weights.\n&quot;
         );
 
     declareOption(ol, &quot;train_set&quot;, 
                   &amp;DeepNonLocalManifoldParzen::train_set,
                   OptionBase::learntoption,
-                  &quot;Training set&quot;
+                  &quot;Training set.\n&quot;
         );
 
     // Now call the parent class' declareOptions
@@ -232,7 +240,7 @@
 
     MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
 
-    if(inputsize_ &gt; 0 &amp;&amp; targetsize_ &gt; 0)
+    if(inputsize_ &gt; 0 )
     {
         // Initialize some learnt variables
         n_layers = layers.length();
@@ -284,6 +292,52 @@
         }
 
         build_layers_and_connections();
+
+        if( train_one_network_per_class )
+        {
+            if( n_classes == 1 )
+                PLERROR(&quot;DeepNonLocalManifoldParzen::build_() - \n&quot;
+                        &quot;train_one_network_per_class is useless for\n&quot;
+                        &quot;n_classes == 1.\n&quot;);
+            if( all_layers.length() != n_classes )
+            {
+                all_layers.resize( n_classes);
+                for( int i=0; i&lt;all_layers.length(); i++ )
+                {
+                    CopiesMap copies;
+                    all_layers[i] = layers-&gt;deepCopy(copies);
+                }
+            }
+            if( all_connections.length() != n_classes )
+            {
+                all_connections.resize( n_classes);
+                for( int i=0; i&lt;all_connections.length(); i++ )
+                {
+                    CopiesMap copies;
+                    all_connections[i] = connections-&gt;deepCopy(copies);
+                }
+            }
+            if( all_reconstruction_connections.length() != n_classes )
+            {
+                all_reconstruction_connections.resize( n_classes);
+                for( int i=0; i&lt;all_reconstruction_connections.length(); i++ )
+                {
+                    CopiesMap copies;
+                    all_reconstruction_connections[i] = 
+                        reconstruction_connections-&gt;deepCopy(copies);
+                }
+            }
+            if( all_output_connections.length() != n_classes )
+            {
+                all_output_connections.resize( n_classes);
+                for( int i=0; i&lt;all_output_connections.length(); i++ )
+                {
+                    CopiesMap copies;
+                    all_output_connections[i] = 
+                        output_connections-&gt;deepCopy(copies);
+                }
+            }
+        }
     }
 }
 
@@ -419,6 +473,10 @@
     deepCopyField(reconstruction_activation_gradients, copies);
     deepCopyField(reconstruction_expectation_gradients, copies);
     deepCopyField(output_connections, copies);
+    deepCopyField(all_layers, copies);
+    deepCopyField(all_connections, copies);
+    deepCopyField(all_reconstruction_connections, copies);
+    deepCopyField(all_output_connections, copies);
     deepCopyField(input_representation, copies);
     deepCopyField(previous_input_representation, copies);
     deepCopyField(all_outputs, copies);
@@ -463,7 +521,7 @@
     //if(currently_trained_layer &lt; n_layers)
     //    return layers[currently_trained_layer]-&gt;size;
     //return layers[n_layers-1]-&gt;size;
-    return n_classes;
+    return 1;
 }
 
 void DeepNonLocalManifoldParzen::forget()
@@ -482,17 +540,38 @@
 
     manifold_parzen_parameters_are_up_to_date = false;
 
-    for( int i=0 ; i&lt;n_layers-1 ; i++ )
-        connections[i]-&gt;forget();
-    
-    for( int i=0 ; i&lt;n_layers ; i++ )
-        layers[i]-&gt;forget();
-    
-    for( int i=0; i&lt;reconstruction_connections.length(); i++)
-        reconstruction_connections[i]-&gt;forget();
+    if( train_one_network_per_class )
+    {
+        for(int c = 0; c&lt;n_classes; c++ )
+        {
+            for( int i=0 ; i&lt;n_layers-1 ; i++ )
+                all_connections[c][i]-&gt;forget();
+            
+            for( int i=0 ; i&lt;n_layers ; i++ )
+                all_layers[c][i]-&gt;forget();
+            
+            for( int i=0; i&lt;all_reconstruction_connections[c].length(); i++)
+                all_reconstruction_connections[c][i]-&gt;forget();
+            
+            if( all_output_connections[c] )
+                all_output_connections[c]-&gt;forget();
+        }
+    }
+    else
+    {
+        for( int i=0 ; i&lt;n_layers-1 ; i++ )
+            connections[i]-&gt;forget();
+        
+        for( int i=0 ; i&lt;n_layers ; i++ )
+            layers[i]-&gt;forget();
+        
+        for( int i=0; i&lt;reconstruction_connections.length(); i++)
+            reconstruction_connections[i]-&gt;forget();
+        
+        if( output_connections )
+            output_connections-&gt;forget();
 
-    if( output_connections )
-        output_connections-&gt;forget();
+    }
 
     stage = 0;
     greedy_stages.clear();
@@ -558,6 +637,15 @@
         {
             sample = *this_stage % nsamples;
             train_set-&gt;getExample(sample, input, target, weight);
+
+            if( train_one_network_per_class )
+            {
+                int c = (int) target[0];
+                layers = all_layers[c];
+                connections = all_connections[c];
+                reconstruction_connections = all_reconstruction_connections[c];
+                output_connections = all_output_connections[c];
+            }
             greedyStep( input, target, i, train_costs, *this_stage);
             train_stats-&gt;update( train_costs );
 
@@ -576,19 +664,32 @@
             // Find training nearest neighbors
             TVec&lt;int&gt; nearest_neighbors_indices_row;
             nearest_neighbors_indices.resize(train_set-&gt;length(), k_neighbors);
-            for(int k=0; k&lt;n_classes; k++)
-            {
-                for(int i=0; i&lt;class_datasets[k]-&gt;length(); i++)
+            if( n_classes &gt; 1 )
+                for(int k=0; k&lt;n_classes; k++)
                 {
-                    class_datasets[k]-&gt;getExample(i,input,target,weight);
-                    nearest_neighbors_indices_row = nearest_neighbors_indices(
-                        class_datasets[k]-&gt;indices[i]);
+                    for(int i=0; i&lt;class_datasets[k]-&gt;length(); i++)
+                    {
+                        class_datasets[k]-&gt;getExample(i,input,target,weight);
+                        nearest_neighbors_indices_row = nearest_neighbors_indices(
+                            class_datasets[k]-&gt;indices[i]);
+                        
+                        computeNearestNeighbors(
+                            new GetInputVMatrix((VMatrix *)class_datasets[k]),input,
+                            nearest_neighbors_indices_row,
+                            i);
+                    }
+                }
+            else
+                for(int i=0; i&lt;train_set-&gt;length(); i++)
+                {
+                    train_set-&gt;getExample(i,input,target,weight);
+                    nearest_neighbors_indices_row = nearest_neighbors_indices(i);
                     computeNearestNeighbors(
-                        new GetInputVMatrix((VMatrix *)class_datasets[k]),input,
+                        train_set,input,
                         nearest_neighbors_indices_row,
                         i);
                 }
-            }
+                
         }
 
         MODULE_LOG &lt;&lt; &quot;Fine-tuning all parameters, by gradient descent&quot; &lt;&lt; endl;
@@ -603,31 +704,50 @@
                                   + classname(),
                                   nstages - init_stage );
 
-        setLearningRate( fine_tuning_learning_rate );
         train_costs.fill(MISSING_VALUE);
 
         for( ; stage&lt;nstages ; stage++ )
         {
             sample = stage % nsamples;
-            if( !fast_exact_is_equal( fine_tuning_decrease_ct, 0. ) )
-                setLearningRate( fine_tuning_learning_rate
-                                 / (1. + fine_tuning_decrease_ct * stage ) );
-
             train_set-&gt;getExample( sample, input, target, weight );
 
             // Find nearest neighbors
-            for( int k=0; k&lt;k_neighbors; k++ )
+            if( n_classes &gt; 1 )
+                for( int k=0; k&lt;k_neighbors; k++ )
+                {
+                    class_datasets[(int)round(target[0])]-&gt;getExample(
+                        nearest_neighbors_indices(sample,k),
+                        nearest_neighbor, target2, weight2);
+                    
+                    if(round(target[0]) != round(target2[0]))
+                        PLERROR(&quot;DeepNonLocalManifoldParzen::train(): similar&quot;
+                                &quot; example is not from same class!&quot;);
+                    nearest_neighbors(k) &lt;&lt; nearest_neighbor;
+                }
+            else
+                for( int k=0; k&lt;k_neighbors; k++ )
+                {
+                    train_set-&gt;getExample(
+                        nearest_neighbors_indices(sample,k),
+                        nearest_neighbor, target2, weight2);
+                    nearest_neighbors(k) &lt;&lt; nearest_neighbor;
+                }
+                
+
+            if( train_one_network_per_class )
             {
-                class_datasets[(int)round(target[0])]-&gt;getExample(
-                    nearest_neighbors_indices(sample,k),
-                    nearest_neighbor, target2, weight2);
-
-                if(round(target[0]) != round(target2[0]))
-                    PLERROR(&quot;DeepNonLocalManifoldParzen::train(): similar&quot;
-                            &quot; example is not from same class!&quot;);
-                nearest_neighbors(k) &lt;&lt; nearest_neighbor;
+                int c = (int) target[0];
+                layers = all_layers[c];
+                connections = all_connections[c];
+                reconstruction_connections = all_reconstruction_connections[c];
+                output_connections = all_output_connections[c];
             }
 
+            if( !fast_exact_is_equal( fine_tuning_decrease_ct, 0. ) )
+                setLearningRate( fine_tuning_learning_rate
+                                 / (1. + fine_tuning_decrease_ct * stage ) );
+            else
+                setLearningRate( fine_tuning_learning_rate );
 
             fineTuningStep( input, target, train_costs, 
                             nearest_neighbors);
@@ -775,8 +895,17 @@
 
 void DeepNonLocalManifoldParzen::computeManifoldParzenParameters( 
     const Vec&amp; input, Mat&amp; F, Vec&amp; mu, 
-    Vec&amp; pre_sigma_noise, Mat&amp; U, Vec&amp; sm_svd) const
+    Vec&amp; pre_sigma_noise, Mat&amp; U, Vec&amp; sm_svd, int target_class) const
 {
+    if( train_one_network_per_class )
+    {
+        PLASSERT( target_class &gt;= 0 );
+        layers = all_layers[target_class];
+        connections = all_connections[target_class];
+        reconstruction_connections = all_reconstruction_connections[target_class];
+        output_connections = all_output_connections[target_class];
+    }
+
     // Get example representation
     computeRepresentation(input, input_representation, 
                           n_layers-1);
@@ -816,7 +945,11 @@
 {
     manifold_parzen_parameters_are_up_to_date = false;
 
-    computeManifoldParzenParameters( input, F, mu, pre_sigma_noise, U, sm_svd );
+    if( n_classes &gt; 1 )
+        computeManifoldParzenParameters( input, F, mu, pre_sigma_noise, U, sm_svd,
+                                         (int)target[0]);
+    else
+        computeManifoldParzenParameters( input, F, mu, pre_sigma_noise, U, sm_svd);
 
     real sigma_noise = pre_sigma_noise[0]* pre_sigma_noise[0] + min_sigma_noise;
 
@@ -1011,11 +1144,23 @@
         int input_j_index;
         for( int i=0; i&lt;n_classes; i++ )
         {
-            for( int j=0; j&lt;class_datasets[i]-&gt;length(); j++ )
+            for( int j=0; 
+                 j&lt;(n_classes &gt; 1 ? 
+                    class_datasets[i]-&gt;length() 
+                    : train_set-&gt;length()); 
+                 j++ )
             {
-                class_datasets[i]-&gt;getExample(j,input_j,target,weight);
+                if( n_classes &gt; 1 )
+                {
+                    class_datasets[i]-&gt;getExample(j,input_j,target,weight);
+                    input_j_index = class_datasets[i]-&gt;indices[j];
+                }
+                else
+                {
+                    train_set-&gt;getExample(j,input_j,target,weight);
+                    input_j_index = j;
+                }
 
-                input_j_index = class_datasets[i]-&gt;indices[j];
                 U &lt;&lt; eigenvectors[input_j_index];
                 sm_svd &lt;&lt; eigenvalues(input_j_index);
                 sigma_noise = sigma_noises[input_j_index];
@@ -1034,7 +1179,7 @@
                     dotp = dot(diff,uk);
                     coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
                     mahal -= dotp*dotp*0.5*coef;
-                    norm_term -= 0.5*pl_log(sm_svd[k]);
+                    norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
                 }
                 
                 if( j==0 )
@@ -1051,12 +1196,26 @@
 
         for( int i=0; i&lt;n_classes; i++ )
         {
-            for( int j=0; j&lt;class_datasets[i]-&gt;length(); j++ )
+            for( int j=0; 
+                 j&lt;(n_classes &gt; 1 ? 
+                    class_datasets[i]-&gt;length() 
+                    : train_set-&gt;length()); 
+                 j++ )
             {
-                class_datasets[i]-&gt;getExample(j,input_j,target,weight);
+                if( n_classes &gt; 1 )
+                {
+                    class_datasets[i]-&gt;getExample(j,input_j,target,weight);
+                    computeManifoldParzenParameters( input_j, F, mu, 
+                                                     pre_sigma_noise, U, sm_svd,
+                                                     (int) target[0]);
+                }
+                else
+                {
+                    train_set-&gt;getExample(j,input_j,target,weight);
+                    computeManifoldParzenParameters( input_j, F, mu, 
+                                                     pre_sigma_noise, U, sm_svd );
+                }
 
-                computeManifoldParzenParameters( input_j, F, mu, 
-                                                 pre_sigma_noise, U, sm_svd );
                 
                 sigma_noise = pre_sigma_noise[0]*pre_sigma_noise[0] 
                     + min_sigma_noise;
@@ -1074,7 +1233,7 @@
                     dotp = dot(diff,uk);
                     coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
                     mahal -= dotp*dotp*0.5*coef;
-                    norm_term -= 0.5*pl_log(sm_svd[k]);
+                    norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
                 }
                 
                 if( j==0 )
@@ -1087,8 +1246,10 @@
         }
     }
 
-
-    output[0] = argmax(test_votes);
+    if( n_classes &gt; 1 )
+        output[0] = argmax(test_votes);
+    else
+        output[0] = test_votes[0]-pl_log(train_set-&gt;length());
 }
 
 void DeepNonLocalManifoldParzen::computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
@@ -1100,6 +1261,15 @@
     costs.resize( getTestCostNames().length() );
     costs.fill( MISSING_VALUE );
 
+    if( train_one_network_per_class )
+    {
+        int c = (int) target[0];
+        layers = all_layers[c];
+        connections = all_connections[c];
+        reconstruction_connections = all_reconstruction_connections[c];
+        output_connections = all_output_connections[c];
+    }
+
     if( currently_trained_layer&lt;n_layers 
         &amp;&amp; reconstruction_connections.length() != 0 )
     {
@@ -1120,12 +1290,20 @@
     }
     else
     {
-        int target_class = ((int)round(target[0]));
-        if( ((int)round(output[0])) == target_class )
-            costs[n_layers-1] = 0;
+        if( n_classes &gt; 1 )
+        {
+            int target_class = ((int)round(target[0]));
+            if( ((int)round(output[0])) == target_class )
+                costs[n_layers-1] = 0;
+            else
+                costs[n_layers-1] = 1;
+            costs[n_layers] = - test_votes[target_class]
+                +pl_log(class_datasets[target_class]-&gt;length()); // Must take into account the 1/n normalization
+        }
         else
-            costs[n_layers-1] = 1;
-        costs[n_layers] = - test_votes[target_class]+pl_log(class_datasets[target_class]-&gt;length());
+        {
+            costs[n_layers] = - output[0]; // 1/n normalization already accounted for
+        }
     }
 }
 
@@ -1151,8 +1329,13 @@
         {
             train_set-&gt;getExample(i,input,target,weight);
 
-            computeManifoldParzenParameters( input, F, mu, 
-                                             pre_sigma_noise, U, sm_svd );
+            if( n_classes &gt; 1 )
+                computeManifoldParzenParameters( input, F, mu, 
+                                                 pre_sigma_noise, U, sm_svd,
+                                                 (int) target[0]);
+            else
+                computeManifoldParzenParameters( input, F, mu, 
+                                                 pre_sigma_noise, U, sm_svd);
             
             sigma_noise = pre_sigma_noise[0]*pre_sigma_noise[0] + min_sigma_noise;
 
@@ -1198,16 +1381,19 @@
     manifold_parzen_parameters_are_up_to_date = false;
 
     // Separate classes
-    class_datasets.resize(n_classes);
-    for(int k=0; k&lt;n_classes; k++)
+    if( n_classes &gt; 1 )
     {
-        class_datasets[k] = new ClassSubsetVMatrix();
-        class_datasets[k]-&gt;classes.resize(1);
-        class_datasets[k]-&gt;classes[0] = k;
-        class_datasets[k]-&gt;source = training_set;
-        class_datasets[k]-&gt;build();
+        class_datasets.resize(n_classes);
+        for(int k=0; k&lt;n_classes; k++)
+        {
+            class_datasets[k] = new ClassSubsetVMatrix();
+            class_datasets[k]-&gt;classes.resize(1);
+            class_datasets[k]-&gt;classes[0] = k;
+            class_datasets[k]-&gt;source = training_set;
+            class_datasets[k]-&gt;build();
+        }
     }
-    
+
     //// Find other classes proportions
     //class_proportions.resize(n_classes);
     //class_proportions.fill(0);

Modified: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2008-06-16 16:39:23 UTC (rev 9126)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.h	2008-06-16 17:43:03 UTC (rev 9127)
@@ -90,13 +90,13 @@
     TVec&lt;int&gt; training_schedule;
 
     //! The layers of units in the network
-    TVec&lt; PP&lt;RBMLayer&gt; &gt; layers;
+    mutable TVec&lt; PP&lt;RBMLayer&gt; &gt; layers;
 
     //! The weights of the connections between the layers
-    TVec&lt; PP&lt;RBMConnection&gt; &gt; connections;
+    mutable TVec&lt; PP&lt;RBMConnection&gt; &gt; connections;
 
     //! The reconstruction weights of the autoassociators
-    TVec&lt; PP&lt;RBMConnection&gt; &gt; reconstruction_connections;
+    mutable TVec&lt; PP&lt;RBMConnection&gt; &gt; reconstruction_connections;
 
     //! Number of nearest neighbors to use to learn
     //! the manifold structure.
@@ -111,6 +111,9 @@
     //! Number of classes
     int n_classes;
 
+    //! Indication that one network per class should be trained
+    bool train_one_network_per_class;
+
     //! Output weights L1 penalty factor
     real output_connections_l1_penalty_factor;
 
@@ -192,7 +195,8 @@
 
     void computeManifoldParzenParameters( const Vec&amp; input, 
                                           Mat&amp; F, Vec&amp; mu, Vec&amp; pre_sigma_noise,
-                                          Mat&amp; U, Vec&amp; sm_svd) const;
+                                          Mat&amp; U, Vec&amp; sm_svd, 
+                                          int target_class = -1) const;
                                           
 
     //#####  PLearn::Object Protocol  #########################################
@@ -242,6 +246,12 @@
     //! Output weights
     mutable PP&lt;OnlineLearningModule&gt; output_connections;
     
+    //! Parameters for all networks, when training one network per class
+    mutable TVec&lt; TVec&lt; PP&lt;RBMLayer&gt; &gt; &gt; all_layers;
+    mutable TVec&lt; TVec&lt;PP&lt;RBMConnection&gt; &gt; &gt; all_connections;
+    mutable TVec&lt; TVec&lt;PP&lt;RBMConnection&gt; &gt; &gt; all_reconstruction_connections;
+    mutable TVec&lt; PP&lt;OnlineLearningModule&gt; &gt; all_output_connections;
+
     //! Example representation
     mutable Vec input_representation;
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002574.html">[Plearn-commits] r9126 - trunk/plearn_learners_experimental
</A></li>
	<LI>Next message: <A HREF="002576.html">[Plearn-commits] r9128 - trunk/plearn/python
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2575">[ date ]</a>
              <a href="thread.html#2575">[ thread ]</a>
              <a href="subject.html#2575">[ subject ]</a>
              <a href="author.html#2575">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
