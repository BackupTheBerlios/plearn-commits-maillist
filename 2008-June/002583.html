<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9135 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9135%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806171710.m5HHA2Nl029635%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002582.html">
   <LINK REL="Next"  HREF="002584.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9135 - trunk/plearn_learners_experimental</H1>
    <B>laulysta at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9135%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806171710.m5HHA2Nl029635%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9135 - trunk/plearn_learners_experimental">laulysta at mail.berlios.de
       </A><BR>
    <I>Tue Jun 17 19:10:02 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002582.html">[Plearn-commits] r9134 - trunk/python_modules/plearn/utilities
</A></li>
        <LI>Next message: <A HREF="002584.html">[Plearn-commits] r9136 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2583">[ date ]</a>
              <a href="thread.html#2583">[ thread ]</a>
              <a href="subject.html#2583">[ subject ]</a>
              <a href="author.html#2583">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: laulysta
Date: 2008-06-17 19:10:00 +0200 (Tue, 17 Jun 2008)
New Revision: 9135

Added:
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
   trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
Log:


Added: trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2008-06-17 15:51:53 UTC (rev 9134)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.cc	2008-06-17 17:10:00 UTC (rev 9135)
@@ -0,0 +1,1864 @@
+// -*- C++ -*-
+
+// DenoisingRecurrentNet.cc
+//
+// Copyright (C) 2006 Stanislas Lauly
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Stanislas Lauly
+
+/*! \file DenoisingRecurrentNet.cc */
+
+
+#define PL_LOG_MODULE_NAME &quot;DenoisingRecurrentNet&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;DenoisingRecurrentNet.h&quot;
+#include &quot;plearn/math/plapack.h&quot;
+
+// - commiter mse
+// - ajouter denoising recurrent net. Deux possibilit&#233;s:
+//   1) on ajoute du bruit &#224; l'input, et on reconstruit les targets avec des poids
+//      possiblement diff&#233;rents
+//     * option denoising_target_layers_weights (c'est l&#224; qu'on met l'input)
+//     * version de clamp_units qui ajoute le bruit
+//   2) on reconstruit l'input directement (sans 2e couche cach&#233;e)
+//     * toujours clamp_units qui ajoute le bruit
+//     * une option qui dit quelle partie de l'input reconstruire et du code 
+//       pour bloquer le gradient qui ne doit pas passer (pas tr&#232;s propre, 
+//       mais bon...)
+//     * une option donnant les connections de reconstruction
+//     * du code pour entra&#238;ner s&#233;par&#233;ment les hidden_connections (si pr&#233;sentes)
+// - pourrait avoir le gradient du denoising recurrent net en m&#234;me temps que
+//   celui du &quot;fine-tuning&quot;
+// - add dynamic_activations_list and use it in recurrent_update
+
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    DenoisingRecurrentNet,
+    &quot;Model made of RBMs linked through time&quot;,
+    &quot;&quot;
+    );
+
+
+DenoisingRecurrentNet::DenoisingRecurrentNet() :
+    //rbm_learning_rate( 0.01 ),
+    recurrent_net_learning_rate( 0.01),
+    use_target_layers_masks( false ),
+    end_of_sequence_symbol( -1000 )
+    //rbm_nstages( 0 ),
+{
+    random_gen = new PRandom();
+}
+
+void DenoisingRecurrentNet::declareOptions(OptionList&amp; ol)
+{
+//    declareOption(ol, &quot;rbm_learning_rate&quot;, &amp;DenoisingRecurrentNet::rbm_learning_rate,
+//                  OptionBase::buildoption,
+//                  &quot;The learning rate used during RBM contrastive &quot;
+//                  &quot;divergence learning phase.\n&quot;);
+
+    declareOption(ol, &quot;recurrent_net_learning_rate&quot;, 
+                  &amp;DenoisingRecurrentNet::recurrent_net_learning_rate,
+                  OptionBase::buildoption,
+                  &quot;The learning rate used during the recurrent phase.\n&quot;);
+
+//    declareOption(ol, &quot;rbm_nstages&quot;, &amp;DenoisingRecurrentNet::rbm_nstages,
+//                  OptionBase::buildoption,
+//                  &quot;Number of epochs for rbm phase.\n&quot;);
+
+
+    declareOption(ol, &quot;target_layers_weights&quot;, 
+                  &amp;DenoisingRecurrentNet::target_layers_weights,
+                  OptionBase::buildoption,
+                  &quot;The training weights of each target layers.\n&quot;);
+
+    declareOption(ol, &quot;use_target_layers_masks&quot;, 
+                  &amp;DenoisingRecurrentNet::use_target_layers_masks,
+                  OptionBase::buildoption,
+                  &quot;Indication that a mask indicating which target to predict\n&quot;
+                  &quot;is present in the input part of the VMatrix dataset.\n&quot;);
+
+    declareOption(ol, &quot;end_of_sequence_symbol&quot;, 
+                  &amp;DenoisingRecurrentNet::end_of_sequence_symbol,
+                  OptionBase::buildoption,
+                  &quot;Value of the first input component for end-of-sequence &quot;
+                  &quot;delimiter.\n&quot;);
+
+    declareOption(ol, &quot;input_layer&quot;, &amp;DenoisingRecurrentNet::input_layer,
+                  OptionBase::buildoption,
+                  &quot;The input layer of the model.\n&quot;);
+
+    declareOption(ol, &quot;target_layers&quot;, &amp;DenoisingRecurrentNet::target_layers,
+                  OptionBase::buildoption,
+                  &quot;The target layers of the model.\n&quot;);
+
+    declareOption(ol, &quot;hidden_layer&quot;, &amp;DenoisingRecurrentNet::hidden_layer,
+                  OptionBase::buildoption,
+                  &quot;The hidden layer of the model.\n&quot;);
+
+    declareOption(ol, &quot;hidden_layer2&quot;, &amp;DenoisingRecurrentNet::hidden_layer2,
+                  OptionBase::buildoption,
+                  &quot;The second hidden layer of the model (optional).\n&quot;);
+
+    declareOption(ol, &quot;dynamic_connections&quot;, 
+                  &amp;DenoisingRecurrentNet::dynamic_connections,
+                  OptionBase::buildoption,
+                  &quot;The RBMConnection between the first hidden layers, &quot;
+                  &quot;through time (optional).\n&quot;);
+
+    declareOption(ol, &quot;hidden_connections&quot;, 
+                  &amp;DenoisingRecurrentNet::hidden_connections,
+                  OptionBase::buildoption,
+                  &quot;The RBMConnection between the first and second &quot;
+                  &quot;hidden layers (optional).\n&quot;);
+
+    declareOption(ol, &quot;input_connections&quot;, 
+                  &amp;DenoisingRecurrentNet::input_connections,
+                  OptionBase::buildoption,
+                  &quot;The RBMConnection from input_layer to hidden_layer.\n&quot;);
+
+    declareOption(ol, &quot;target_connections&quot;, 
+                  &amp;DenoisingRecurrentNet::target_connections,
+                  OptionBase::buildoption,
+                  &quot;The RBMConnection from input_layer to hidden_layer.\n&quot;);
+
+    /*
+    declareOption(ol, &quot;&quot;, 
+                  &amp;DenoisingRecurrentNet::,
+                  OptionBase::buildoption,
+                  &quot;&quot;);
+    */
+
+
+    declareOption(ol, &quot;target_layers_n_of_target_elements&quot;, 
+                  &amp;DenoisingRecurrentNet::target_layers_n_of_target_elements,
+                  OptionBase::learntoption,
+                  &quot;Number of elements in the target part of a VMatrix associated\n&quot;
+                  &quot;to each target layer.\n&quot;);
+
+    declareOption(ol, &quot;input_symbol_sizes&quot;, 
+                  &amp;DenoisingRecurrentNet::input_symbol_sizes,
+                  OptionBase::learntoption,
+                  &quot;Number of symbols for each symbolic field of train_set.\n&quot;);
+
+    declareOption(ol, &quot;target_symbol_sizes&quot;, 
+                  &amp;DenoisingRecurrentNet::target_symbol_sizes,
+                  OptionBase::learntoption,
+                  &quot;Number of symbols for each symbolic field of train_set.\n&quot;);
+
+    /*
+    declareOption(ol, &quot;&quot;, &amp;DenoisingRecurrentNet::,
+                  OptionBase::learntoption,
+                  &quot;&quot;);
+     */
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void DenoisingRecurrentNet::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a &quot;reloaded&quot; object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or &quot;re-building&quot; of an object after a few &quot;tuning&quot;
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+
+    if(train_set)
+    {
+        PLASSERT( target_layers_weights.length() == target_layers.length() );
+        PLASSERT( target_connections.length() == target_layers.length() );
+        PLASSERT( target_layers.length() &gt; 0 );
+        PLASSERT( input_layer );
+        PLASSERT( hidden_layer );
+        PLASSERT( input_connections );
+
+        // Parsing symbols in input
+        int input_layer_size = 0;
+        input_symbol_sizes.resize(0);
+        PP&lt;Dictionary&gt; dict;
+        int inputsize_without_masks = inputsize() 
+            - ( use_target_layers_masks ? targetsize() : 0 );
+        for(int i=0; i&lt;inputsize_without_masks; i++)
+        {
+            dict = train_set-&gt;getDictionary(i);
+            if(dict)
+            {
+                if( dict-&gt;size() == 0 )
+                    PLERROR(&quot;DenoisingRecurrentNet::build_(): dictionary &quot;
+                        &quot;of field %d is empty&quot;, i);
+                input_symbol_sizes.push_back(dict-&gt;size());
+                // Adjust size to include one-hot vector
+                input_layer_size += dict-&gt;size();
+            }
+            else
+            {
+                input_symbol_sizes.push_back(-1);
+                input_layer_size++;
+            }
+        }
+
+        if( input_layer-&gt;size != input_layer_size )
+            PLERROR(&quot;DenoisingRecurrentNet::build_(): input_layer-&gt;size %d &quot;
+                    &quot;should be %d&quot;, input_layer-&gt;size, input_layer_size);
+
+        // Parsing symbols in target
+        int tar_layer = 0;
+        int tar_layer_size = 0;
+        target_symbol_sizes.resize(target_layers.length());
+        for( int tar_layer=0; tar_layer&lt;target_layers.length(); 
+             tar_layer++ )
+            target_symbol_sizes[tar_layer].resize(0);
+        target_layers_n_of_target_elements.resize( targetsize() );
+        target_layers_n_of_target_elements.clear();
+
+        for( int tar=0; tar&lt;targetsize(); tar++)
+        {
+            if( tar_layer &gt; target_layers.length() )
+                PLERROR(&quot;DenoisingRecurrentNet::build_(): target layers &quot;
+                        &quot;does not cover all targets.&quot;);            
+
+            dict = train_set-&gt;getDictionary(tar+inputsize());
+            if(dict)
+            {
+                if( use_target_layers_masks )
+                    PLERROR(&quot;DenoisingRecurrentNet::build_(): masks for &quot;
+                            &quot;symbolic targets is not implemented.&quot;);
+                if( dict-&gt;size() == 0 )
+                    PLERROR(&quot;DenoisingRecurrentNet::build_(): dictionary &quot;
+                            &quot;of field %d is empty&quot;, tar);
+
+                target_symbol_sizes[tar_layer].push_back(dict-&gt;size());
+                target_layers_n_of_target_elements[tar_layer]++;
+                tar_layer_size += dict-&gt;size();
+            }
+            else
+            {
+                target_symbol_sizes[tar_layer].push_back(-1);
+                target_layers_n_of_target_elements[tar_layer]++;
+                tar_layer_size++;
+            }
+
+            if( target_layers[tar_layer]-&gt;size == tar_layer_size )
+            {
+                tar_layer++;
+                tar_layer_size = 0;
+            }
+        }
+
+        if( tar_layer != target_layers.length() )
+            PLERROR(&quot;DenoisingRecurrentNet::build_(): target layers &quot;
+                    &quot;does not cover all targets.&quot;);
+
+
+        // Building weights and layers
+        if( !input_layer-&gt;random_gen )
+        {
+            input_layer-&gt;random_gen = random_gen;
+            input_layer-&gt;forget();
+        }
+
+        if( !hidden_layer-&gt;random_gen )
+        {
+            hidden_layer-&gt;random_gen = random_gen;
+            hidden_layer-&gt;forget();
+        }
+
+        input_connections-&gt;down_size = input_layer-&gt;size;
+        input_connections-&gt;up_size = hidden_layer-&gt;size;
+        if( !input_connections-&gt;random_gen )
+        {
+            input_connections-&gt;random_gen = random_gen;
+            input_connections-&gt;forget();
+        }
+        input_connections-&gt;build();
+
+
+        if( dynamic_connections )
+        {
+            dynamic_connections-&gt;down_size = hidden_layer-&gt;size;
+            dynamic_connections-&gt;up_size = hidden_layer-&gt;size;
+            if( !dynamic_connections-&gt;random_gen )
+            {
+                dynamic_connections-&gt;random_gen = random_gen;
+                dynamic_connections-&gt;forget();
+            }
+            dynamic_connections-&gt;build();
+        }
+
+        if( hidden_layer2 )
+        {
+            if( !hidden_layer2-&gt;random_gen )
+            {
+                hidden_layer2-&gt;random_gen = random_gen;
+                hidden_layer2-&gt;forget();
+            }
+
+            PLASSERT( hidden_connections );
+
+            hidden_connections-&gt;down_size = hidden_layer-&gt;size;
+            hidden_connections-&gt;up_size = hidden_layer2-&gt;size;
+            if( !hidden_connections-&gt;random_gen )
+            {
+                hidden_connections-&gt;random_gen = random_gen;
+                hidden_connections-&gt;forget();
+            }
+            hidden_connections-&gt;build();
+        }
+
+        for( int tar_layer = 0; tar_layer &lt; target_layers.length(); tar_layer++ )
+        {
+            PLASSERT( target_layers[tar_layer] );
+            PLASSERT( target_connections[tar_layer] );
+
+            if( !target_layers[tar_layer]-&gt;random_gen )
+            {
+                target_layers[tar_layer]-&gt;random_gen = random_gen;
+                target_layers[tar_layer]-&gt;forget();
+            }
+
+            if( hidden_layer2 )
+                target_connections[tar_layer]-&gt;down_size = hidden_layer2-&gt;size;
+            else
+                target_connections[tar_layer]-&gt;down_size = hidden_layer-&gt;size;
+
+            target_connections[tar_layer]-&gt;up_size = target_layers[tar_layer]-&gt;size;
+            if( !target_connections[tar_layer]-&gt;random_gen )
+            {
+                target_connections[tar_layer]-&gt;random_gen = random_gen;
+                target_connections[tar_layer]-&gt;forget();
+            }
+            target_connections[tar_layer]-&gt;build();
+        }
+
+    }
+}
+
+// ### Nothing to add here, simply calls build_
+void DenoisingRecurrentNet::build()
+{
+    inherited::build();
+    build_();
+}
+
+
+void DenoisingRecurrentNet::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField( input_layer, copies);
+    deepCopyField( target_layers , copies);
+    deepCopyField( hidden_layer, copies);
+    deepCopyField( hidden_layer2 , copies);
+    deepCopyField( dynamic_connections , copies);
+    deepCopyField( hidden_connections , copies);
+    deepCopyField( input_connections , copies);
+    deepCopyField( target_connections , copies);
+    deepCopyField( target_layers_n_of_target_elements, copies);
+    deepCopyField( input_symbol_sizes, copies);
+    deepCopyField( target_symbol_sizes, copies);
+    
+
+    deepCopyField( bias_gradient , copies);
+    deepCopyField( visi_bias_gradient , copies);
+    deepCopyField( hidden_gradient , copies);
+    deepCopyField( hidden_temporal_gradient , copies);
+    deepCopyField( hidden_list , copies);
+    deepCopyField( hidden_act_no_bias_list , copies);
+    deepCopyField( hidden2_list , copies);
+    deepCopyField( hidden2_act_no_bias_list , copies);
+    deepCopyField( target_prediction_list , copies);
+    deepCopyField( target_prediction_act_no_bias_list , copies);
+    deepCopyField( input_list , copies);
+    deepCopyField( targets_list , copies);
+    deepCopyField( nll_list , copies);
+    deepCopyField( masks_list , copies);
+    deepCopyField( dynamic_act_no_bias_contribution, copies);
+
+
+    // deepCopyField(, copies);
+
+    //PLERROR(&quot;DenoisingRecurrentNet::makeDeepCopyFromShallowCopy(): &quot;
+    //&quot;not implemented yet&quot;);
+}
+
+
+int DenoisingRecurrentNet::outputsize() const
+{
+    int out_size = 0;
+    for( int i=0; i&lt;target_layers.length(); i++ )
+        out_size += target_layers[i]-&gt;size;
+    return out_size;
+}
+
+void DenoisingRecurrentNet::forget()
+{
+    inherited::forget();
+
+    input_layer-&gt;forget();
+    hidden_layer-&gt;forget();
+    input_connections-&gt;forget();
+    if( dynamic_connections )
+        dynamic_connections-&gt;forget();
+    if( hidden_layer2 )
+    {
+        hidden_layer2-&gt;forget();
+        hidden_connections-&gt;forget();
+    }
+
+    for( int i=0; i&lt;target_layers.length(); i++ )
+    {
+        target_layers[i]-&gt;forget();
+        target_connections[i]-&gt;forget();
+    }
+
+    stage = 0;
+}
+
+void DenoisingRecurrentNet::train()
+{
+    MODULE_LOG &lt;&lt; &quot;train() called &quot; &lt;&lt; endl;
+
+    Vec input( inputsize() );
+    Vec target( targetsize() );
+    real weight = 0; // Unused
+    Vec train_costs( getTrainCostNames().length() );
+    train_costs.clear();
+    Vec train_n_items( getTrainCostNames().length() );
+
+    if( !initTrain() )
+    {
+        MODULE_LOG &lt;&lt; &quot;train() aborted&quot; &lt;&lt; endl;
+        return;
+    }
+
+    ProgressBar* pb = 0;
+
+    // clear stats of previous epoch
+    train_stats-&gt;forget();
+
+
+    /***** RBM training phase *****/
+//    if(rbm_stage &lt; rbm_nstages)
+//    {
+//    }
+
+
+    /***** Recurrent phase *****/
+    if( stage &gt;= nstages )
+        return;
+
+    if( stage &lt; nstages )
+    {        
+
+        MODULE_LOG &lt;&lt; &quot;Training the whole model&quot; &lt;&lt; endl;
+
+        int init_stage = stage;
+        //int end_stage = max(0,nstages-(rbm_nstages + dynamic_nstages));
+        int end_stage = nstages;
+
+        MODULE_LOG &lt;&lt; &quot;  stage = &quot; &lt;&lt; stage &lt;&lt; endl;
+        MODULE_LOG &lt;&lt; &quot;  end_stage = &quot; &lt;&lt; end_stage &lt;&lt; endl;
+        MODULE_LOG &lt;&lt; &quot;  recurrent_net_learning_rate = &quot; &lt;&lt; recurrent_net_learning_rate &lt;&lt; endl;
+
+        if( report_progress &amp;&amp; stage &lt; end_stage )
+            pb = new ProgressBar( &quot;Recurrent training phase of &quot;+classname(),
+                                  end_stage - init_stage );
+
+        setLearningRate( recurrent_net_learning_rate );
+
+        int ith_sample_in_sequence = 0;
+        int inputsize_without_masks = inputsize() 
+            - ( use_target_layers_masks ? targetsize() : 0 );
+        int sum_target_elements = 0;
+        while(stage &lt; end_stage)
+        {
+/*
+                TMat&lt;real&gt; U,V;//////////crap James
+                TVec&lt;real&gt; S;
+                U.resize(hidden_layer-&gt;size,hidden_layer-&gt;size);
+                V.resize(hidden_layer-&gt;size,hidden_layer-&gt;size);
+                S.resize(hidden_layer-&gt;size);
+                U &lt;&lt; dynamic_connections-&gt;weights;
+                
+                SVD(U,dynamic_connections-&gt;weights,S,V);
+                S.fill(-0.5);
+                productScaleAcc(dynamic_connections-&gt;bias,dynamic_connections-&gt;weights,S,1,0);
+*/
+            train_costs.clear();
+            train_n_items.clear();
+            for(int sample=0 ; sample&lt;train_set-&gt;length() ; sample++ )
+            {
+                train_set-&gt;getExample(sample, input, target, weight);
+
+                if( fast_exact_is_equal(input[0],end_of_sequence_symbol) )
+                {
+                    //update
+                    recurrent_update();
+                    
+                    ith_sample_in_sequence = 0;
+                    hidden_list.resize(0);
+                    hidden_act_no_bias_list.resize(0);
+                    hidden2_list.resize(0);
+                    hidden2_act_no_bias_list.resize(0);
+                    target_prediction_list.resize(0);
+                    target_prediction_act_no_bias_list.resize(0);
+                    input_list.resize(0);
+                    targets_list.resize(0);
+                    nll_list.resize(0,0);
+                    masks_list.resize(0);
+                    continue;
+                }
+
+                // Resize internal variables
+                hidden_list.resize(ith_sample_in_sequence+1);
+                hidden_act_no_bias_list.resize(ith_sample_in_sequence+1);
+                if( hidden_layer2 )
+                {
+                    hidden2_list.resize(ith_sample_in_sequence+1);
+                    hidden2_act_no_bias_list.resize(ith_sample_in_sequence+1);
+                }
+                 
+                input_list.resize(ith_sample_in_sequence+1);
+                input_list[ith_sample_in_sequence].resize(input_layer-&gt;size);
+
+                targets_list.resize( target_layers.length() );
+                target_prediction_list.resize( target_layers.length() );
+                target_prediction_act_no_bias_list.resize( target_layers.length() );
+                for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                {
+                    if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                    {                        
+                        targets_list[tar].resize( ith_sample_in_sequence+1);
+                        targets_list[tar][ith_sample_in_sequence].resize( 
+                            target_layers[tar]-&gt;size);
+                        target_prediction_list[tar].resize(
+                            ith_sample_in_sequence+1);
+                        target_prediction_act_no_bias_list[tar].resize(
+                            ith_sample_in_sequence+1);
+                    }
+                }
+                nll_list.resize(ith_sample_in_sequence+1,target_layers.length());
+                if( use_target_layers_masks )
+                {
+                    masks_list.resize( target_layers.length() );
+                    for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                        if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                            masks_list[tar].resize( ith_sample_in_sequence+1 );
+                }
+
+                // Forward propagation
+
+                // Fetch right representation for input
+                clamp_units(input.subVec(0,inputsize_without_masks),
+                            input_layer,
+                            input_symbol_sizes);                
+                input_list[ith_sample_in_sequence] &lt;&lt; input_layer-&gt;expectation;
+
+                // Fetch right representation for target
+                sum_target_elements = 0;
+                for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                {
+                    if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                    {
+                        if( use_target_layers_masks )
+                        {
+                            clamp_units(target.subVec(
+                                            sum_target_elements,
+                                            target_layers_n_of_target_elements[tar]),
+                                        target_layers[tar],
+                                        target_symbol_sizes[tar],
+                                        input.subVec(
+                                            inputsize_without_masks 
+                                            + sum_target_elements, 
+                                            target_layers_n_of_target_elements[tar]),
+                                        masks_list[tar][ith_sample_in_sequence]
+                                );
+                            
+                        }
+                        else
+                        {
+                            clamp_units(target.subVec(
+                                            sum_target_elements,
+                                            target_layers_n_of_target_elements[tar]),
+                                        target_layers[tar],
+                                        target_symbol_sizes[tar]);
+                        }
+                        targets_list[tar][ith_sample_in_sequence] &lt;&lt; 
+                            target_layers[tar]-&gt;expectation;
+                    }
+                    sum_target_elements += target_layers_n_of_target_elements[tar];
+                }
+                
+                input_connections-&gt;fprop( input_list[ith_sample_in_sequence], 
+                                          hidden_act_no_bias_list[ith_sample_in_sequence]);
+                
+                if( ith_sample_in_sequence &gt; 0 &amp;&amp; dynamic_connections )
+                {
+                    dynamic_connections-&gt;fprop( 
+                        hidden_list[ith_sample_in_sequence-1],
+                        dynamic_act_no_bias_contribution );
+
+                    hidden_act_no_bias_list[ith_sample_in_sequence] += 
+                        dynamic_act_no_bias_contribution;
+                }
+                 
+                hidden_layer-&gt;fprop( hidden_act_no_bias_list[ith_sample_in_sequence], 
+                                     hidden_list[ith_sample_in_sequence] );
+                 
+                if( hidden_layer2 )
+                {
+                    hidden_connections-&gt;fprop( 
+                        hidden_list[ith_sample_in_sequence],
+                        hidden2_act_no_bias_list[ith_sample_in_sequence]);
+
+                    hidden_layer2-&gt;fprop( 
+                        hidden2_act_no_bias_list[ith_sample_in_sequence],
+                        hidden2_list[ith_sample_in_sequence] 
+                        );
+
+                    for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                    {
+                        if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                        {
+                            target_connections[tar]-&gt;fprop(
+                                hidden2_list[ith_sample_in_sequence],
+                                target_prediction_act_no_bias_list[tar][
+                                    ith_sample_in_sequence]
+                                );
+                            target_layers[tar]-&gt;fprop(
+                                target_prediction_act_no_bias_list[tar][
+                                    ith_sample_in_sequence],
+                                target_prediction_list[tar][
+                                    ith_sample_in_sequence] );
+                            if( use_target_layers_masks )
+                                target_prediction_list[tar][ ith_sample_in_sequence] *= 
+                                    masks_list[tar][ith_sample_in_sequence];
+                        }
+                    }
+                }
+                else
+                {
+                    for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                    {
+                        if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                        {
+                            target_connections[tar]-&gt;fprop(
+                                hidden_list[ith_sample_in_sequence],
+                                target_prediction_act_no_bias_list[tar][
+                                    ith_sample_in_sequence]
+                                );
+                            target_layers[tar]-&gt;fprop(
+                                target_prediction_act_no_bias_list[tar][
+                                    ith_sample_in_sequence],
+                                target_prediction_list[tar][
+                                    ith_sample_in_sequence] );
+                            if( use_target_layers_masks )
+                                target_prediction_list[tar][ ith_sample_in_sequence] *= 
+                                    masks_list[tar][ith_sample_in_sequence];
+                        }
+                    }
+                }
+
+                sum_target_elements = 0;
+                for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                {
+                    if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                    {
+                        target_layers[tar]-&gt;activation &lt;&lt; 
+                            target_prediction_act_no_bias_list[tar][
+                                ith_sample_in_sequence];
+                        target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                        target_layers[tar]-&gt;setExpectation(
+                            target_prediction_list[tar][
+                                ith_sample_in_sequence]);
+                        nll_list(ith_sample_in_sequence,tar) = 
+                            target_layers[tar]-&gt;fpropNLL( 
+                                targets_list[tar][ith_sample_in_sequence] ); 
+                        train_costs[tar] += nll_list(ith_sample_in_sequence,tar);
+                        
+                        // Normalize by the number of things to predict
+                        if( use_target_layers_masks )
+                        {
+                            train_n_items[tar] += sum(
+                                input.subVec( inputsize_without_masks 
+                                              + sum_target_elements, 
+                                              target_layers_n_of_target_elements[tar]) );
+                        }
+                        else
+                            train_n_items[tar]++;
+                    }
+                    if( use_target_layers_masks )
+                        sum_target_elements += 
+                            target_layers_n_of_target_elements[tar];
+                    
+                }
+                ith_sample_in_sequence++;
+            }
+            if( pb )
+                pb-&gt;update( stage + 1 - init_stage);
+            
+            for(int i=0; i&lt;train_costs.length(); i++)
+            {
+                if( !fast_exact_is_equal(target_layers_weights[i],0) )
+                    train_costs[i] /= train_n_items[i];
+                else
+                    train_costs[i] = MISSING_VALUE;
+            }
+
+            if(verbosity&gt;0)
+                cout &lt;&lt; &quot;mean costs at stage &quot; &lt;&lt; stage &lt;&lt; 
+                    &quot; = &quot; &lt;&lt; train_costs &lt;&lt; endl;
+            stage++;
+            train_stats-&gt;update(train_costs);
+        }    
+        if( pb )
+        {
+            delete pb;
+            pb = 0;
+        }
+
+    }
+
+
+    train_stats-&gt;finalize();
+}
+
+
+
+void DenoisingRecurrentNet::clamp_units(const Vec layer_vector,
+                                             PP&lt;RBMLayer&gt; layer,
+                                             TVec&lt;int&gt; symbol_sizes) const
+{
+    int it = 0;
+    int ss = -1;
+    for(int i=0; i&lt;layer_vector.length(); i++)
+    {
+        ss = symbol_sizes[i];
+        // If input is a real ...
+        if(ss &lt; 0) 
+        {
+            layer-&gt;expectation[it++] = layer_vector[i];
+        }
+        else // ... or a symbol
+        {
+            // Convert to one-hot vector
+            layer-&gt;expectation.subVec(it,ss).clear();
+            layer-&gt;expectation[it+(int)layer_vector[i]] = 1;
+            it += ss;
+        }
+    }
+    layer-&gt;setExpectation( layer-&gt;expectation );
+}
+
+void DenoisingRecurrentNet::clamp_units(const Vec layer_vector,
+                                             PP&lt;RBMLayer&gt; layer,
+                                             TVec&lt;int&gt; symbol_sizes,
+                                             const Vec original_mask,
+                                             Vec&amp; formated_mask) const
+{
+    int it = 0;
+    int ss = -1;
+    PLASSERT( original_mask.length() == layer_vector.length() );
+    formated_mask.resize(layer-&gt;size);
+    for(int i=0; i&lt;layer_vector.length(); i++)
+    {
+        ss = symbol_sizes[i];
+        // If input is a real ...
+        if(ss &lt; 0) 
+        {
+            formated_mask[it] = original_mask[i];
+            layer-&gt;expectation[it++] = layer_vector[i];
+        }
+        else // ... or a symbol
+        {
+            // Convert to one-hot vector
+            layer-&gt;expectation.subVec(it,ss).clear();
+            formated_mask.subVec(it,ss).fill(original_mask[i]);
+            layer-&gt;expectation[it+(int)layer_vector[i]] = 1;
+            it += ss;
+        }
+    }
+    layer-&gt;setExpectation( layer-&gt;expectation );
+}
+
+void DenoisingRecurrentNet::setLearningRate( real the_learning_rate )
+{
+    input_layer-&gt;setLearningRate( the_learning_rate );
+    hidden_layer-&gt;setLearningRate( the_learning_rate );
+    input_connections-&gt;setLearningRate( the_learning_rate );
+    if( dynamic_connections )
+        dynamic_connections-&gt;setLearningRate( the_learning_rate ); //HUGO: multiply by dynamic_connections_learning_weight;
+    if( hidden_layer2 )
+    {
+        hidden_layer2-&gt;setLearningRate( the_learning_rate );
+        hidden_connections-&gt;setLearningRate( the_learning_rate );
+    }
+
+    for( int i=0; i&lt;target_layers.length(); i++ )
+    {
+        target_layers[i]-&gt;setLearningRate( the_learning_rate );
+        target_connections[i]-&gt;setLearningRate( the_learning_rate );
+    }
+}
+
+void DenoisingRecurrentNet::recurrent_update()
+{
+        hidden_temporal_gradient.resize(hidden_layer-&gt;size);
+        hidden_temporal_gradient.clear();
+        for(int i=hidden_list.length()-1; i&gt;=0; i--){   
+
+            if( hidden_layer2 )
+                hidden_gradient.resize(hidden_layer2-&gt;size);
+            else
+                hidden_gradient.resize(hidden_layer-&gt;size);
+            hidden_gradient.clear();
+            if(use_target_layers_masks)
+            {
+                for( int tar=0; tar&lt;target_layers.length(); tar++)
+                {
+                    if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                    {
+                        target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar][i];
+                        target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                        target_layers[tar]-&gt;setExpectation(target_prediction_list[tar][i]);
+                        target_layers[tar]-&gt;bpropNLL(targets_list[tar][i],nll_list(i,tar),bias_gradient);
+                        bias_gradient *= target_layers_weights[tar];
+                        bias_gradient *= masks_list[tar][i];
+                        target_layers[tar]-&gt;update(bias_gradient);
+                        if( hidden_layer2 )
+                            target_connections[tar]-&gt;bpropUpdate(hidden2_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                                 hidden_gradient, bias_gradient,true);
+                        else
+                            target_connections[tar]-&gt;bpropUpdate(hidden_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                                 hidden_gradient, bias_gradient,true);
+                    }
+                }
+            }
+            else
+            {
+                for( int tar=0; tar&lt;target_layers.length(); tar++)
+                {
+                    if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                    {
+                        target_layers[tar]-&gt;activation &lt;&lt; target_prediction_act_no_bias_list[tar][i];
+                        target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                        target_layers[tar]-&gt;setExpectation(target_prediction_list[tar][i]);
+                        target_layers[tar]-&gt;bpropNLL(targets_list[tar][i],nll_list(i,tar),bias_gradient);
+                        bias_gradient *= target_layers_weights[tar];
+                        target_layers[tar]-&gt;update(bias_gradient);
+                        if( hidden_layer2 )
+                            target_connections[tar]-&gt;bpropUpdate(hidden2_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                                 hidden_gradient, bias_gradient,true); 
+                        else
+                            target_connections[tar]-&gt;bpropUpdate(hidden_list[i],target_prediction_act_no_bias_list[tar][i],
+                                                                 hidden_gradient, bias_gradient,true); 
+                        
+                    }
+                }
+            }
+
+            if (hidden_layer2)
+            {
+                hidden_layer2-&gt;bpropUpdate(
+                    hidden2_act_no_bias_list[i], hidden2_list[i],
+                    bias_gradient, hidden_gradient);
+                
+                hidden_connections-&gt;bpropUpdate(
+                    hidden_list[i],
+                    hidden2_act_no_bias_list[i], 
+                    hidden_gradient, bias_gradient);
+            }
+            
+            if(i!=0 &amp;&amp; dynamic_connections )
+            {   
+                hidden_gradient += hidden_temporal_gradient;
+                
+                hidden_layer-&gt;bpropUpdate(
+                    hidden_act_no_bias_list[i], hidden_list[i],
+                    hidden_temporal_gradient, hidden_gradient);
+                
+                dynamic_connections-&gt;bpropUpdate(
+                    hidden_list[i-1],
+                    hidden_act_no_bias_list[i], // Here, it should be cond_bias, but doesn't matter
+                    hidden_gradient, hidden_temporal_gradient);
+                
+                hidden_temporal_gradient &lt;&lt; hidden_gradient;
+                
+                input_connections-&gt;bpropUpdate(
+                    input_list[i],
+                    hidden_act_no_bias_list[i], 
+                    visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
+                
+            }
+            else
+            {
+                hidden_layer-&gt;bpropUpdate(
+                    hidden_act_no_bias_list[i], hidden_list[i],
+                    hidden_temporal_gradient, hidden_gradient); // Not really temporal gradient, but this is the final iteration...
+                input_connections-&gt;bpropUpdate(
+                    input_list[i],
+                    hidden_act_no_bias_list[i], 
+                    visi_bias_gradient, hidden_temporal_gradient);// Here, it should be activations - cond_bias, but doesn't matter
+
+            }
+        }
+    
+}
+
+void DenoisingRecurrentNet::computeOutput(const Vec&amp; input, Vec&amp; output) const
+{
+    PLERROR(&quot;DenoisingRecurrentNet::computeOutput(): this is a dynamic, &quot;
+            &quot;generative model, that can only compute negative log-likelihood &quot;
+            &quot;costs for a whole VMat&quot;);
+}
+
+void DenoisingRecurrentNet::computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
+                                           const Vec&amp; target, Vec&amp; costs) const
+{
+    PLERROR(&quot;DenoisingRecurrentNet::computeCostsFromOutputs(): this is a &quot;
+            &quot;dynamic, generative model, that can only compute negative &quot;
+            &quot;log-likelihooh costs for a whole VMat&quot;);
+}
+
+void DenoisingRecurrentNet::test(VMat testset, PP&lt;VecStatsCollector&gt; test_stats,
+                  VMat testoutputs, VMat testcosts)const
+{ 
+
+    int len = testset.length();
+    Vec input;
+    Vec target;
+    real weight;
+
+    Vec output(outputsize());
+    output.clear();
+    Vec costs(nTestCosts());
+    costs.clear();
+    Vec n_items(nTestCosts());
+    n_items.clear();
+
+    PP&lt;ProgressBar&gt; pb;
+    if (report_progress) 
+        pb = new ProgressBar(&quot;Testing learner&quot;, len);
+
+    if (len == 0) {
+        // Empty test set: we give -1 cost arbitrarily.
+        costs.fill(-1);
+        test_stats-&gt;update(costs);
+    }
+    
+    int ith_sample_in_sequence = 0;
+    int inputsize_without_masks = inputsize() 
+        - ( use_target_layers_masks ? targetsize() : 0 );
+    int sum_target_elements = 0;
+    for (int i = 0; i &lt; len; i++)
+    {
+        testset.getExample(i, input, target, weight);
+
+        if( fast_exact_is_equal(input[0],end_of_sequence_symbol) )
+        {
+            ith_sample_in_sequence = 0;
+            hidden_list.resize(0);
+            hidden_act_no_bias_list.resize(0);
+            hidden2_list.resize(0);
+            hidden2_act_no_bias_list.resize(0);
+            target_prediction_list.resize(0);
+            target_prediction_act_no_bias_list.resize(0);
+            input_list.resize(0);
+            targets_list.resize(0);
+            nll_list.resize(0,0);
+            masks_list.resize(0);
+
+            if (testoutputs)
+            {
+                output.fill(end_of_sequence_symbol);
+                testoutputs-&gt;putOrAppendRow(i, output);
+            }
+
+            continue;
+        }
+
+        // Resize internal variables
+        hidden_list.resize(ith_sample_in_sequence+1);
+        hidden_act_no_bias_list.resize(ith_sample_in_sequence+1);
+        if( hidden_layer2 )
+        {
+            hidden2_list.resize(ith_sample_in_sequence+1);
+            hidden2_act_no_bias_list.resize(ith_sample_in_sequence+1);
+        }
+                 
+        input_list.resize(ith_sample_in_sequence+1);
+        input_list[ith_sample_in_sequence].resize(input_layer-&gt;size);
+
+        targets_list.resize( target_layers.length() );
+        target_prediction_list.resize( target_layers.length() );
+        target_prediction_act_no_bias_list.resize( target_layers.length() );
+        for( int tar=0; tar &lt; target_layers.length(); tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                targets_list[tar].resize( ith_sample_in_sequence+1);
+                targets_list[tar][ith_sample_in_sequence].resize( 
+                    target_layers[tar]-&gt;size);
+                target_prediction_list[tar].resize(
+                    ith_sample_in_sequence+1);
+                target_prediction_act_no_bias_list[tar].resize(
+                    ith_sample_in_sequence+1);
+            }
+        }
+        nll_list.resize(ith_sample_in_sequence+1,target_layers.length());
+        if( use_target_layers_masks )
+        {
+            masks_list.resize( target_layers.length() );
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                    masks_list[tar].resize( ith_sample_in_sequence+1 );
+        }
+
+        // Forward propagation
+
+        // Fetch right representation for input
+        clamp_units(input.subVec(0,inputsize_without_masks),
+                    input_layer,
+                    input_symbol_sizes);                
+        input_list[ith_sample_in_sequence] &lt;&lt; input_layer-&gt;expectation;
+
+        // Fetch right representation for target
+        sum_target_elements = 0;
+        for( int tar=0; tar &lt; target_layers.length(); tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                if( use_target_layers_masks )
+                {
+                    clamp_units(target.subVec(
+                                    sum_target_elements,
+                                    target_layers_n_of_target_elements[tar]),
+                                target_layers[tar],
+                                target_symbol_sizes[tar],
+                                input.subVec(
+                                    inputsize_without_masks 
+                                    + sum_target_elements, 
+                                    target_layers_n_of_target_elements[tar]),
+                                masks_list[tar][ith_sample_in_sequence]
+                        );
+                    
+                }
+                else
+                {
+                    clamp_units(target.subVec(
+                                    sum_target_elements,
+                                    target_layers_n_of_target_elements[tar]),
+                                target_layers[tar],
+                                target_symbol_sizes[tar]);
+                }
+                targets_list[tar][ith_sample_in_sequence] &lt;&lt; 
+                    target_layers[tar]-&gt;expectation;
+            }
+            sum_target_elements += target_layers_n_of_target_elements[tar];
+        }
+                
+        input_connections-&gt;fprop( input_list[ith_sample_in_sequence], 
+                                  hidden_act_no_bias_list[ith_sample_in_sequence]);
+                
+        if( ith_sample_in_sequence &gt; 0 &amp;&amp; dynamic_connections )
+        {
+            dynamic_connections-&gt;fprop( 
+                hidden_list[ith_sample_in_sequence-1],
+                dynamic_act_no_bias_contribution );
+
+            hidden_act_no_bias_list[ith_sample_in_sequence] += 
+                dynamic_act_no_bias_contribution;
+        }
+                 
+        hidden_layer-&gt;fprop( hidden_act_no_bias_list[ith_sample_in_sequence], 
+                             hidden_list[ith_sample_in_sequence] );
+                 
+        if( hidden_layer2 )
+        {
+            hidden_connections-&gt;fprop( 
+                hidden_list[ith_sample_in_sequence],
+                hidden2_act_no_bias_list[ith_sample_in_sequence]);
+
+            hidden_layer2-&gt;fprop( 
+                hidden2_act_no_bias_list[ith_sample_in_sequence],
+                hidden2_list[ith_sample_in_sequence] 
+                );
+
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_connections[tar]-&gt;fprop(
+                        hidden2_list[ith_sample_in_sequence],
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence]
+                        );
+                    target_layers[tar]-&gt;fprop(
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence],
+                        target_prediction_list[tar][
+                            ith_sample_in_sequence] );
+                    if( use_target_layers_masks )
+                        target_prediction_list[tar][ ith_sample_in_sequence] *= 
+                            masks_list[tar][ith_sample_in_sequence];
+                }
+            }
+        }
+        else
+        {
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_connections[tar]-&gt;fprop(
+                        hidden_list[ith_sample_in_sequence],
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence]
+                        );
+                    target_layers[tar]-&gt;fprop(
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence],
+                        target_prediction_list[tar][
+                            ith_sample_in_sequence] );
+                    if( use_target_layers_masks )
+                        target_prediction_list[tar][ ith_sample_in_sequence] *= 
+                            masks_list[tar][ith_sample_in_sequence];
+                }
+            }
+        }
+
+        if (testoutputs)
+        {
+            int sum_target_layers_size = 0;
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    output.subVec(sum_target_layers_size,target_layers[tar]-&gt;size)
+                        &lt;&lt; target_prediction_list[tar][ ith_sample_in_sequence ];
+                }
+                sum_target_layers_size += target_layers[tar]-&gt;size;
+            }
+            testoutputs-&gt;putOrAppendRow(i, output);
+        }
+
+        sum_target_elements = 0;
+        for( int tar=0; tar &lt; target_layers.length(); tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                target_layers[tar]-&gt;activation &lt;&lt; 
+                    target_prediction_act_no_bias_list[tar][
+                        ith_sample_in_sequence];
+                target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                target_layers[tar]-&gt;setExpectation(
+                    target_prediction_list[tar][
+                        ith_sample_in_sequence]);
+                nll_list(ith_sample_in_sequence,tar) = 
+                    target_layers[tar]-&gt;fpropNLL( 
+                        targets_list[tar][ith_sample_in_sequence] ); 
+                costs[tar] += nll_list(ith_sample_in_sequence,tar);
+                
+                // Normalize by the number of things to predict
+                if( use_target_layers_masks )
+                {
+                    n_items[tar] += sum(
+                        input.subVec( inputsize_without_masks 
+                                      + sum_target_elements, 
+                                      target_layers_n_of_target_elements[tar]) );
+                }
+                else
+                    n_items[tar]++;
+            }
+            if( use_target_layers_masks )
+                sum_target_elements += 
+                    target_layers_n_of_target_elements[tar];
+        }
+        ith_sample_in_sequence++;
+
+        if (report_progress)
+            pb-&gt;update(i);
+
+    }
+
+    for(int i=0; i&lt;costs.length(); i++)
+    {
+        if( !fast_exact_is_equal(target_layers_weights[i],0) )
+            costs[i] /= n_items[i];
+        else
+            costs[i] = MISSING_VALUE;
+    }
+    if (testcosts)
+        testcosts-&gt;putOrAppendRow(0, costs);
+    
+    if (test_stats)
+        test_stats-&gt;update(costs, weight);
+    
+    ith_sample_in_sequence = 0;
+    hidden_list.resize(0);
+    hidden_act_no_bias_list.resize(0);
+    hidden2_list.resize(0);
+    hidden2_act_no_bias_list.resize(0);
+    target_prediction_list.resize(0);
+    target_prediction_act_no_bias_list.resize(0);
+    input_list.resize(0);
+    targets_list.resize(0);
+    nll_list.resize(0,0);
+    masks_list.resize(0);   
+}
+
+
+TVec&lt;string&gt; DenoisingRecurrentNet::getTestCostNames() const
+{
+    TVec&lt;string&gt; cost_names(0);
+    for( int i=0; i&lt;target_layers.length(); i++ )
+        cost_names.append(&quot;target&quot; + tostring(i) + &quot;.NLL&quot;);
+    return cost_names;
+}
+
+TVec&lt;string&gt; DenoisingRecurrentNet::getTrainCostNames() const
+{
+    return getTestCostNames();
+}
+
+void DenoisingRecurrentNet::generate(int t, int n)
+{
+    //PPath* the_filename = &quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/generate/scoreGen.amat&quot;;
+    data = new AutoVMatrix();
+    //data-&gt;filename = &quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/listData/target_tm12_input_t_tm12_tp12/scoreGen_tar_tm12__in_tm12_tp12.amat&quot;;
+    data-&gt;filename = &quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/create_data/scoreGenSuitePerf.amat&quot;;
+
+    data-&gt;defineSizes(208,16,0);
+    //data-&gt;inputsize = 21;
+    //data-&gt;targetsize = 0;
+    //data-&gt;weightsize = 0;
+    data-&gt;build();
+
+    
+    
+   
+   
+
+    int len = data-&gt;length();
+    int tarSize = outputsize();
+    int partTarSize;
+    Vec input;
+    Vec target;
+    real weight;
+
+    Vec output(outputsize());
+    output.clear();
+    /*Vec costs(nTestCosts());
+    costs.clear();
+    Vec n_items(nTestCosts());
+    n_items.clear();*/
+
+    int r,r2;
+    
+    int ith_sample_in_sequence = 0;
+    int inputsize_without_masks = inputsize() 
+        - ( use_target_layers_masks ? targetsize() : 0 );
+    int sum_target_elements = 0;
+    for (int i = 0; i &lt; len; i++)
+    {
+        data-&gt;getExample(i, input, target, weight);
+        if(i&gt;n)
+        {
+            for (int k = 1; k &lt;= t; k++)
+            {
+                if(k&lt;=i){
+                    partTarSize = outputsize();
+                    for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                    {
+                        
+                        input.subVec(inputsize_without_masks-(tarSize*(t-k))-partTarSize-1,target_layers[tar]-&gt;size) &lt;&lt; target_prediction_list[tar][ith_sample_in_sequence-k];
+                        partTarSize -= target_layers[tar]-&gt;size;
+                        
+                        
+                    }
+                }
+            }       
+        }
+    
+/*
+        for (int k = 1; k &lt;= t; k++)
+        {
+            partTarSize = outputsize();
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+            {
+                if(i&gt;=t){
+                    input.subVec(inputsize_without_masks-(tarSize*(t-k))-partTarSize-1,target_layers[tar]-&gt;size) &lt;&lt; target_prediction_list[tar][ith_sample_in_sequence-k];
+                    partTarSize -= target_layers[tar]-&gt;size;
+                }
+            }
+        }
+*/
+        if( fast_exact_is_equal(input[0],end_of_sequence_symbol) )
+        {
+            /*  ith_sample_in_sequence = 0;
+            hidden_list.resize(0);
+            hidden_act_no_bias_list.resize(0);
+            hidden2_list.resize(0);
+            hidden2_act_no_bias_list.resize(0);
+            target_prediction_list.resize(0);
+            target_prediction_act_no_bias_list.resize(0);
+            input_list.resize(0);
+            targets_list.resize(0);
+            nll_list.resize(0,0);
+            masks_list.resize(0);*/
+
+            
+
+            continue;
+        }
+
+        // Resize internal variables
+        hidden_list.resize(ith_sample_in_sequence+1);
+        hidden_act_no_bias_list.resize(ith_sample_in_sequence+1);
+        if( hidden_layer2 )
+        {
+            hidden2_list.resize(ith_sample_in_sequence+1);
+            hidden2_act_no_bias_list.resize(ith_sample_in_sequence+1);
+        }
+                 
+        input_list.resize(ith_sample_in_sequence+1);
+        input_list[ith_sample_in_sequence].resize(input_layer-&gt;size);
+
+        targets_list.resize( target_layers.length() );
+        target_prediction_list.resize( target_layers.length() );
+        target_prediction_act_no_bias_list.resize( target_layers.length() );
+        for( int tar=0; tar &lt; target_layers.length(); tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                targets_list[tar].resize( ith_sample_in_sequence+1);
+                targets_list[tar][ith_sample_in_sequence].resize( 
+                    target_layers[tar]-&gt;size);
+                target_prediction_list[tar].resize(
+                    ith_sample_in_sequence+1);
+                target_prediction_act_no_bias_list[tar].resize(
+                    ith_sample_in_sequence+1);
+            }
+        }
+        nll_list.resize(ith_sample_in_sequence+1,target_layers.length());
+        if( use_target_layers_masks )
+        {
+            masks_list.resize( target_layers.length() );
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                    masks_list[tar].resize( ith_sample_in_sequence+1 );
+        }
+
+        // Forward propagation
+
+        // Fetch right representation for input
+        clamp_units(input.subVec(0,inputsize_without_masks),
+                    input_layer,
+                    input_symbol_sizes);                
+        input_list[ith_sample_in_sequence] &lt;&lt; input_layer-&gt;expectation;
+
+        // Fetch right representation for target
+        sum_target_elements = 0;
+        for( int tar=0; tar &lt; target_layers.length(); tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                if( use_target_layers_masks )
+                {
+                    clamp_units(target.subVec(
+                                    sum_target_elements,
+                                    target_layers_n_of_target_elements[tar]),
+                                target_layers[tar],
+                                target_symbol_sizes[tar],
+                                input.subVec(
+                                    inputsize_without_masks 
+                                    + sum_target_elements, 
+                                    target_layers_n_of_target_elements[tar]),
+                                masks_list[tar][ith_sample_in_sequence]
+                        );
+                    
+                }
+                else
+                {
+                    clamp_units(target.subVec(
+                                    sum_target_elements,
+                                    target_layers_n_of_target_elements[tar]),
+                                target_layers[tar],
+                                target_symbol_sizes[tar]);
+                }
+                targets_list[tar][ith_sample_in_sequence] &lt;&lt; 
+                    target_layers[tar]-&gt;expectation;
+            }
+            sum_target_elements += target_layers_n_of_target_elements[tar];
+        }
+                
+        input_connections-&gt;fprop( input_list[ith_sample_in_sequence], 
+                                  hidden_act_no_bias_list[ith_sample_in_sequence]);
+                
+        if( ith_sample_in_sequence &gt; 0 &amp;&amp; dynamic_connections )
+        {
+            dynamic_connections-&gt;fprop( 
+                hidden_list[ith_sample_in_sequence-1],
+                dynamic_act_no_bias_contribution );
+
+            hidden_act_no_bias_list[ith_sample_in_sequence] += 
+                dynamic_act_no_bias_contribution;
+        }
+                 
+        hidden_layer-&gt;fprop( hidden_act_no_bias_list[ith_sample_in_sequence], 
+                             hidden_list[ith_sample_in_sequence] );
+                 
+        if( hidden_layer2 )
+        {
+            hidden_connections-&gt;fprop( 
+                hidden_list[ith_sample_in_sequence],
+                hidden2_act_no_bias_list[ith_sample_in_sequence]);
+
+            hidden_layer2-&gt;fprop( 
+                hidden2_act_no_bias_list[ith_sample_in_sequence],
+                hidden2_list[ith_sample_in_sequence] 
+                );
+
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_connections[tar]-&gt;fprop(
+                        hidden2_list[ith_sample_in_sequence],
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence]
+                        );
+                    target_layers[tar]-&gt;fprop(
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence],
+                        target_prediction_list[tar][
+                            ith_sample_in_sequence] );
+                    if( use_target_layers_masks )
+                        target_prediction_list[tar][ ith_sample_in_sequence] *= 
+                            masks_list[tar][ith_sample_in_sequence];
+                }
+            }
+        }
+        else
+        {
+            for( int tar=0; tar &lt; target_layers.length(); tar++ )
+            {
+                if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+                {
+                    target_connections[tar]-&gt;fprop(
+                        hidden_list[ith_sample_in_sequence],
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence]
+                        );
+                    target_layers[tar]-&gt;fprop(
+                        target_prediction_act_no_bias_list[tar][
+                            ith_sample_in_sequence],
+                        target_prediction_list[tar][
+                            ith_sample_in_sequence] );
+                    if( use_target_layers_masks )
+                        target_prediction_list[tar][ ith_sample_in_sequence] *= 
+                            masks_list[tar][ith_sample_in_sequence];
+                }
+            }
+        }
+
+        
+
+        sum_target_elements = 0;
+        for( int tar=0; tar &lt; target_layers.length(); tar++ )
+        {
+            if( !fast_exact_is_equal(target_layers_weights[tar],0) )
+            {
+                target_layers[tar]-&gt;activation &lt;&lt; 
+                    target_prediction_act_no_bias_list[tar][
+                        ith_sample_in_sequence];
+                target_layers[tar]-&gt;activation += target_layers[tar]-&gt;bias;
+                target_layers[tar]-&gt;setExpectation(
+                    target_prediction_list[tar][
+                        ith_sample_in_sequence]);
+                nll_list(ith_sample_in_sequence,tar) = 
+                    target_layers[tar]-&gt;fpropNLL( 
+                        targets_list[tar][ith_sample_in_sequence] ); 
+                /*costs[tar] += nll_list(ith_sample_in_sequence,tar);
+                
+                // Normalize by the number of things to predict
+                if( use_target_layers_masks )
+                {
+                    n_items[tar] += sum(
+                        input.subVec( inputsize_without_masks 
+                                      + sum_target_elements, 
+                                      target_layers_n_of_target_elements[tar]) );
+                }
+                else
+                n_items[tar]++;*/
+            }
+            if( use_target_layers_masks )
+                sum_target_elements += 
+                    target_layers_n_of_target_elements[tar];
+        }
+        ith_sample_in_sequence++;
+
+        
+
+    }
+
+    /*  
+    ith_sample_in_sequence = 0;
+    hidden_list.resize(0);
+    hidden_act_no_bias_list.resize(0);
+    hidden2_list.resize(0);
+    hidden2_act_no_bias_list.resize(0);
+    target_prediction_list.resize(0);
+    target_prediction_act_no_bias_list.resize(0);
+    input_list.resize(0);
+    targets_list.resize(0);
+    nll_list.resize(0,0);
+    masks_list.resize(0);   
+
+
+    */
+
+
+
+
+
+
+
+
+
+    
+    //Vec tempo;
+    //TVec&lt;real&gt; tempo;
+    //tempo.resize(visible_layer-&gt;size);
+    ofstream myfile;
+    myfile.open (&quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/generate/test.txt&quot;);
+    
+    for (int i = 0; i &lt; target_prediction_list[0].length() ; i++ ){
+       
+       
+        for( int tar=0; tar &lt; target_layers.length(); tar++ )
+        {
+            for (int j = 0; j &lt; target_prediction_list[tar][i].length() ; j++ ){
+                
+                if(i&gt;n){
+                    myfile &lt;&lt; target_prediction_list[tar][i][j] &lt;&lt; &quot; &quot;;
+                }
+                else{
+                    myfile &lt;&lt; targets_list[tar][i][j] &lt;&lt; &quot; &quot;;
+                }
+                       
+           
+            }
+        }
+        myfile &lt;&lt; &quot;\n&quot;;
+    }
+     
+
+     myfile.close();
+
+}
+/*
+void DenoisingRecurrentNet::gen()
+{
+    //PPath* the_filename = &quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/generate/scoreGen.amat&quot;;
+    data = new AutoVMatrix();
+    data-&gt;filename = &quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/generate/scoreGen.amat&quot;;
+    data-&gt;defineSizes(21,0,0);
+    //data-&gt;inputsize = 21;
+    //data-&gt;targetsize = 0;
+    //data-&gt;weightsize = 0;
+    data-&gt;build();
+
+    
+    int len = data-&gt;length();
+    Vec score;
+    Vec target;
+    real weight;
+    Vec bias_tempo;
+    Vec visi_bias_tempo;
+   
+   
+    
+    previous_hidden_layer.resize(hidden_layer-&gt;size);
+    connections_idem = connections;
+
+    for (int ith_sample = 0; ith_sample &lt; len ; ith_sample++ ){
+        
+        data-&gt;getExample(ith_sample, score, target, weight);
+        //score &lt;&lt; data(ith_sample);
+        input_prediction_list.resize(
+            ith_sample+1,visible_layer-&gt;size);
+        if(ith_sample &gt; 0)
+        {
+            
+            //input_list(ith_sample_in_sequence) &lt;&lt; previous_input;
+            //h*_{t-1}
+            //////////////////////////////////
+            dynamic_connections-&gt;fprop(previous_hidden_layer, cond_bias);
+            hidden_layer-&gt;setAllBias(cond_bias); 
+            
+            
+            
+            //up phase
+            connections-&gt;setAsDownInput( input_prediction_list(ith_sample-1) );
+            hidden_layer-&gt;getAllActivations( connections_idem );
+            hidden_layer-&gt;computeExpectation();
+            //////////////////////////////////
+            
+            //previous_hidden_layer &lt;&lt; hidden_layer-&gt;expectation;//h_{t-2} au prochain tour
+            //previous_hidden_layer_act_no_bias &lt;&lt; hidden_layer-&gt;activation;
+            
+            
+            //h*_{t}
+            ////////////
+            if(dynamic_connections_copy)
+                dynamic_connections_copy-&gt;fprop( hidden_layer-&gt;expectation ,hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+            else
+                dynamic_connections-&gt;fprop( hidden_layer-&gt;expectation ,hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+            //dynamic_connections_copy-&gt;fprop( hidden_layer-&gt;expectation ,hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+            hidden_layer-&gt;expectation_is_not_up_to_date();
+            hidden_layer-&gt;computeExpectation();//h_{t}
+            ///////////
+            
+            //previous_input &lt;&lt; visible_layer-&gt;expectation;//v_{t-1}
+            
+        }
+        else
+        {
+            
+            previous_hidden_layer.clear();//h_{t-1}
+            if(dynamic_connections_copy)
+                dynamic_connections_copy-&gt;fprop( previous_hidden_layer ,
+                                                 hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+            else
+                dynamic_connections-&gt;fprop(previous_hidden_layer,
+                                           hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+            
+            hidden_layer-&gt;expectation_is_not_up_to_date();
+            hidden_layer-&gt;computeExpectation();//h_{t}
+            //previous_input.resize(data-&gt;inputsize);
+            //previous_input &lt;&lt; data(ith_sample);
+            
+        }
+        
+        //connections_transpose-&gt;setAsDownInput( hidden_layer-&gt;expectation );
+        //visible_layer-&gt;getAllActivations( connections_idem_t );
+        
+        connections-&gt;setAsUpInput( hidden_layer-&gt;expectation );
+        visible_layer-&gt;getAllActivations( connections_idem );
+        
+        visible_layer-&gt;computeExpectation();
+        //visible_layer-&gt;generateSample();
+        partition(score.subVec(14,taillePart), visible_layer-&gt;activation.subVec(14+taillePart,taillePart), visible_layer-&gt;activation.subVec(14+(taillePart*2),taillePart));
+        partition(score.subVec(14,taillePart), visible_layer-&gt;expectation.subVec(14+taillePart,taillePart), visible_layer-&gt;expectation.subVec(14+(taillePart*2),taillePart));
+
+
+        visible_layer-&gt;activation.subVec(0,14+taillePart) &lt;&lt; score;
+        visible_layer-&gt;expectation.subVec(0,14+taillePart) &lt;&lt; score;
+
+        input_prediction_list(ith_sample) &lt;&lt; visible_layer-&gt;expectation;
+        
+    }
+    
+    //Vec tempo;
+    TVec&lt;real&gt; tempo;
+    tempo.resize(visible_layer-&gt;size);
+    ofstream myfile;
+    myfile.open (&quot;/home/stan/Documents/recherche_maitrise/DDBN_bosendorfer/data/generate/test.txt&quot;);
+    
+    for (int i = 0; i &lt; len ; i++ ){
+        tempo &lt;&lt; input_prediction_list(i);
+        
+        //cout &lt;&lt; tempo[2] &lt;&lt; endl;
+       
+        for (int j = 0; j &lt; tempo.length() ; j++ ){
+            
+            
+                
+                
+               myfile &lt;&lt; tempo[j] &lt;&lt; &quot; &quot;;
+               
+
+               
+           
+        }
+        myfile &lt;&lt; &quot;\n&quot;;
+    }
+     
+
+     myfile.close();
+
+}*/
+//void DenoisingRecurrentNet::generate(int nbNotes)
+//{
+//    
+//    previous_hidden_layer.resize(hidden_layer-&gt;size);
+//    connections_idem = connections;
+//
+//    for (int ith_sample = 0; ith_sample &lt; nbNotes ; ith_sample++ ){
+//        
+//        input_prediction_list.resize(
+//            ith_sample+1,visible_layer-&gt;size);
+//        if(ith_sample &gt; 0)
+//        {
+//            
+//            //input_list(ith_sample_in_sequence) &lt;&lt; previous_input;
+//            //h*_{t-1}
+//            //////////////////////////////////
+//            dynamic_connections-&gt;fprop(previous_hidden_layer, cond_bias);
+//            hidden_layer-&gt;setAllBias(cond_bias); //**************************
+//            
+//            
+//            
+//            //up phase
+//            connections-&gt;setAsDownInput( input_prediction_list(ith_sample-1) );
+//            hidden_layer-&gt;getAllActivations( connections_idem );
+//            hidden_layer-&gt;computeExpectation();
+//            //////////////////////////////////
+//            
+//            //previous_hidden_layer &lt;&lt; hidden_layer-&gt;expectation;//h_{t-2} au prochain tour//******************************
+//            //previous_hidden_layer_act_no_bias &lt;&lt; hidden_layer-&gt;activation;
+//            
+//            
+//            //h*_{t}
+//            ////////////
+//            if(dynamic_connections_copy)
+//                dynamic_connections_copy-&gt;fprop( hidden_layer-&gt;expectation ,hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+//            else
+//                dynamic_connections-&gt;fprop( hidden_layer-&gt;expectation ,hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+//            //dynamic_connections_copy-&gt;fprop( hidden_layer-&gt;expectation ,hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+//            hidden_layer-&gt;expectation_is_not_up_to_date();
+//            hidden_layer-&gt;computeExpectation();//h_{t}
+//            ///////////
+//            
+//            //previous_input &lt;&lt; visible_layer-&gt;expectation;//v_{t-1}
+//            
+//        }
+//        else
+//        {
+//            
+//            previous_hidden_layer.clear();//h_{t-1}
+//            if(dynamic_connections_copy)
+//                dynamic_connections_copy-&gt;fprop( previous_hidden_layer ,
+//                                                 hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+//            else
+//                dynamic_connections-&gt;fprop(previous_hidden_layer,
+//                                           hidden_layer-&gt;activation);//conection entre h_{t-1} et h_{t}
+//            
+//            hidden_layer-&gt;expectation_is_not_up_to_date();
+//            hidden_layer-&gt;computeExpectation();//h_{t}
+//            
+//            
+//        }
+//        
+//        //connections_transpose-&gt;setAsDownInput( hidden_layer-&gt;expectation );
+//        //visible_layer-&gt;getAllActivations( connections_idem_t );
+//        
+//        connections-&gt;setAsUpInput( hidden_layer-&gt;expectation );
+//        visible_layer-&gt;getAllActivations( connections_idem );
+//        
+//        visible_layer-&gt;computeExpectation();
+//        visible_layer-&gt;generateSample();
+//        
+//        input_prediction_list(ith_sample) &lt;&lt; visible_layer-&gt;sample;
+//        
+//    }
+//    
+//    //Vec tempo;
+//    TVec&lt;int&gt; tempo;
+//    tempo.resize(visible_layer-&gt;size);
+//    int theNote;
+//    //int nbNoteVisiLayer = input_prediction_list(1).length()/13;
+//    ofstream myfile;
+//    int theLayer;
+//    myfile.open (&quot;/home/stan/Documents/recherche_maitrise/DDBN_musicGeneration/data/generate/test.txt&quot;);
+//    
+//    for (int i = 0; i &lt; nbNotes ; i++ ){
+//        tempo &lt;&lt; input_prediction_list(i);
+//        
+//        //cout &lt;&lt; tempo[2] &lt;&lt; endl;
+//       
+//        for (int j = 0; j &lt; tempo.length() ; j++ ){
+//            
+//            if (tempo[j] == 1){
+//                theLayer = (j/13);
+//                
+//                theNote = j - (13*theLayer);
+//               
+//
+//                if (theNote&lt;=11){
+//                    //print theNote
+//                    //cout &lt;&lt; theNote+50 &lt;&lt; &quot; &quot;;
+//                    myfile &lt;&lt; theNote &lt;&lt; &quot; &quot;;
+//                }
+//                else{
+//                    //print #
+//                    //cout &lt;&lt; &quot;# &quot;;
+//                    myfile &lt;&lt; &quot;# &quot;;
+//                    
+//                }
+//     
+//            }
+//           
+//        }
+//        myfile &lt;&lt; &quot;\n&quot;;
+//    }
+//     myfile &lt;&lt; &quot;&lt;oov&gt; &lt;oov&gt; \n&quot;;
+//
+//     myfile.close();
+//
+//}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners_experimental/DenoisingRecurrentNet.h
===================================================================
--- trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2008-06-17 15:51:53 UTC (rev 9134)
+++ trunk/plearn_learners_experimental/DenoisingRecurrentNet.h	2008-06-17 17:10:00 UTC (rev 9135)
@@ -0,0 +1,308 @@
+// -*- C++ -*-
+
+// DenoisingRecurrentNet.h
+//
+// Copyright (C) 2006 Stanislas Lauly
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Stanislas Lauly
+
+/*! \file DenoisingRecurrentNet.h */
+
+
+
+#ifndef DenoisingRecurrentNet_INC
+#define DenoisingRecurrentNet_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/online/OnlineLearningModule.h&gt;
+#include &lt;plearn_learners/online/RBMClassificationModule.h&gt;
+#include &lt;plearn_learners/online/RBMLayer.h&gt;
+#include &lt;plearn_learners/online/RBMMixedLayer.h&gt;
+#include &lt;plearn_learners/online/RBMConnection.h&gt;
+#include &lt;plearn_learners/online/RBMMatrixConnection.h&gt;
+#include &lt;plearn/vmat/AutoVMatrix.h&gt;
+#include &lt;plearn_learners/online/RBMMatrixTransposeConnection.h&gt;
+
+#include &lt;plearn_learners/online/GradNNetLayerModule.h&gt;
+
+namespace PLearn {
+
+/**
+ * Model made of RBMs linked through time.
+ */
+class DenoisingRecurrentNet : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    ////! The learning rate used during RBM contrastive divergence learning phase
+    //real rbm_learning_rate;
+
+    //! The learning rate used during the recurrent phase
+    real recurrent_net_learning_rate;
+
+    ////! Number of epochs for rbm phase
+    //int rbm_nstages;
+
+    //! The training weights of each target layers
+    Vec target_layers_weights;
+    
+    //! Indication that a mask indicating which target to predict
+    //! is present in the input part of the VMatrix dataset.
+    bool use_target_layers_masks;
+
+    //! Value of the first input component for end-of-sequence delimiter
+    real end_of_sequence_symbol;
+
+    //! The input layer of the model
+    PP&lt;RBMLayer&gt; input_layer;
+
+    //! The target layers of the model
+    TVec&lt; PP&lt;RBMLayer&gt; &gt; target_layers;
+
+    //! The hidden layer of the model
+    PP&lt;RBMLayer&gt; hidden_layer;
+
+    //! The second hidden layer of the model (optional) 
+    PP&lt;RBMLayer&gt; hidden_layer2;
+
+    //! The RBMConnection between the first hidden layers, through time
+    PP&lt;RBMConnection&gt; dynamic_connections;
+
+    //! The RBMConnection between the first and second hidden layers (optional)
+    PP&lt;RBMConnection&gt; hidden_connections;
+
+    //! The RBMConnection from input_layer to hidden_layer
+    PP&lt;RBMConnection&gt; input_connections;
+
+    //! The RBMConnection from input_layer to hidden_layer
+    TVec&lt; PP&lt;RBMConnection&gt; &gt; target_connections;
+
+    //#####  Public Learnt Options  ###########################################
+
+    //! Number of elements in the target part of a VMatrix associated
+    //! to each target layer
+    TVec&lt;int&gt; target_layers_n_of_target_elements;
+
+    //! Number of symbols for each symbolic field of train_set
+    TVec&lt;int&gt; input_symbol_sizes;
+    
+    //! Number of symbols for each symbolic field of train_set
+    TVec&lt; TVec&lt;int&gt; &gt; target_symbol_sizes;
+
+    
+    
+    //#####  Not Options  #####################################################
+
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    DenoisingRecurrentNet();
+
+
+    //#####  PLearner Member Functions  #######################################
+
+    //! Returns the size of this learner's output, (which typically
+    //! may depend on its inputsize(), targetsize() and set options).
+    virtual int outputsize() const;
+
+    //! (Re-)initializes the PLearner in its fresh state (that state may depend
+    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
+    //! a fresh learner!).
+    virtual void forget();
+
+    //! The role of the train method is to bring the learner up to
+    //! stage==nstages, updating the train_stats collector with training costs
+    //! measured on-line in the process.
+    virtual void train();
+
+    //! Sets the learning of all layers and connections
+    void setLearningRate( real the_learning_rate );
+
+    //! Computes the output from the input.
+    virtual void computeOutput(const Vec&amp; input, Vec&amp; output) const;
+
+    //! Computes the costs from already computed output.
+    virtual void computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
+                                         const Vec&amp; target, Vec&amp; costs) const;
+
+    //! Returns the names of the costs computed by computeCostsFromOutpus (and
+    //! thus the test method).
+    virtual TVec&lt;std::string&gt; getTestCostNames() const;
+
+    
+
+//    //! Generate music in a folder
+    void generate(int t, int n);
+//
+//    //! Generate a part of the data in a folder
+//    void gen();
+
+    //! Returns the names of the objective costs that the train method computes
+    //! and  for which it updates the VecStatsCollector train_stats.
+    virtual TVec&lt;std::string&gt; getTrainCostNames() const;
+
+    //! Use the partition
+    void partition(TVec&lt;double&gt; part, TVec&lt;double&gt; periode, TVec&lt;double&gt; vel ) const;
+    
+    //! Clamps the layer units based on a layer vector
+    void clamp_units(const Vec layer_vector, PP&lt;RBMLayer&gt; layer,
+                     TVec&lt;int&gt; symbol_sizes) const;
+
+    //! Clamps the layer units based on a layer vector
+    //! and provides the associated mask in the correct format.
+    void clamp_units(const Vec layer_vector, PP&lt;RBMLayer&gt; layer,
+                     TVec&lt;int&gt; symbol_sizes, const Vec original_mask,
+                     Vec &amp;formated_mask) const;
+    
+    //! Updates both the RBM parameters and the 
+    //! dynamic connections in the recurrent tuning phase,
+    //! after the visible units have been clamped
+    void recurrent_update();
+
+    virtual void test(VMat testset, PP&lt;VecStatsCollector&gt; test_stats,
+                      VMat testoutputs=0, VMat testcosts=0) const;
+
+    
+
+
+    // *** SUBCLASS WRITING: ***
+    // While in general not necessary, in case of particular needs
+    // (efficiency concerns for ex) you may also want to overload
+    // some of the following methods:
+    // virtual void computeOutputAndCosts(const Vec&amp; input, const Vec&amp; target,
+    //                                    Vec&amp; output, Vec&amp; costs) const;
+    // virtual void computeCostsOnly(const Vec&amp; input, const Vec&amp; target,
+    //                               Vec&amp; costs) const;
+    // virtual int nTestCosts() const;
+    // virtual int nTrainCosts() const;
+    // virtual void resetInternalState();
+    // virtual bool isStatefulLearner() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    PLEARN_DECLARE_OBJECT(DenoisingRecurrentNet);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    //#####  Not Options  #####################################################
+
+
+    //! Store external data;
+    AutoVMatrix*  data;
+   
+    //! Stores bias gradient
+    mutable Vec bias_gradient;
+    
+     //! Stores bias gradient
+    mutable Vec visi_bias_gradient;
+
+    //! Stores hidden gradient of dynamic connections
+    mutable Vec hidden_gradient;
+    
+    //! Stores hidden gradient of dynamic connections coming from time t+1
+    mutable Vec hidden_temporal_gradient;
+        
+    //! List of hidden layers values
+    mutable TVec&lt; Vec &gt; hidden_list;
+    mutable TVec&lt; Vec &gt; hidden_act_no_bias_list;
+
+    //! List of second hidden layers values
+    mutable TVec&lt; Vec &gt; hidden2_list;
+    mutable TVec&lt; Vec &gt; hidden2_act_no_bias_list;
+
+    //! List of target prediction values
+    mutable TVec&lt; TVec&lt; Vec &gt; &gt; target_prediction_list;
+    mutable TVec&lt; TVec&lt; Vec &gt; &gt; target_prediction_act_no_bias_list;
+
+    //! List of inputs values
+    mutable TVec&lt; Vec &gt; input_list;
+
+    //! List of inputs values
+    mutable TVec&lt; TVec&lt; Vec &gt; &gt; targets_list;
+
+    //! List of the nll of the input samples in a sequence
+    mutable Mat nll_list;
+
+    //! List of all targets' masks
+    mutable TVec&lt; TVec&lt; Vec &gt; &gt; masks_list;
+
+    //! Contribution of dynamic weights to hidden layer activation
+    mutable Vec dynamic_act_no_bias_contribution;
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(DenoisingRecurrentNet);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002582.html">[Plearn-commits] r9134 - trunk/python_modules/plearn/utilities
</A></li>
	<LI>Next message: <A HREF="002584.html">[Plearn-commits] r9136 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2583">[ date ]</a>
              <a href="thread.html#2583">[ thread ]</a>
              <a href="subject.html#2583">[ subject ]</a>
              <a href="author.html#2583">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
