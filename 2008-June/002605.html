<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9157 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9157%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806201927.m5KJRONo007284%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002604.html">
   <LINK REL="Next"  HREF="002606.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9157 - trunk/plearn_learners_experimental</H1>
    <B>larocheh at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9157%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200806201927.m5KJRONo007284%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9157 - trunk/plearn_learners_experimental">larocheh at mail.berlios.de
       </A><BR>
    <I>Fri Jun 20 21:27:24 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002604.html">[Plearn-commits] r9156 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="002606.html">[Plearn-commits] r9158 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2605">[ date ]</a>
              <a href="thread.html#2605">[ thread ]</a>
              <a href="subject.html#2605">[ subject ]</a>
              <a href="author.html#2605">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: larocheh
Date: 2008-06-20 21:27:24 +0200 (Fri, 20 Jun 2008)
New Revision: 9157

Modified:
   trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
   trunk/plearn_learners_experimental/ManifoldParzen.cc
Log:
Corrected indentation...



Modified: trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc
===================================================================
--- trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2008-06-20 16:12:42 UTC (rev 9156)
+++ trunk/plearn_learners_experimental/DeepNonLocalManifoldParzen.cc	2008-06-20 19:27:24 UTC (rev 9157)
@@ -550,7 +550,7 @@
     /*!
       A typical forget() method should do the following:
       - call inherited::forget() to initialize its random number generator
-        with the 'seed' option
+      with the 'seed' option
       - initialize the learner's parameters, using this random generator
       - stage = 0
     */
@@ -626,7 +626,7 @@
     for( int i=0 ; i&lt;n_layers-1 ; i++ )
     {
         MODULE_LOG &lt;&lt; &quot;Training connection weights between layers &quot; &lt;&lt; i
-            &lt;&lt; &quot; and &quot; &lt;&lt; i+1 &lt;&lt; endl;
+                   &lt;&lt; &quot; and &quot; &lt;&lt; i+1 &lt;&lt; endl;
 
         int end_stage = training_schedule[i];
         int* this_stage = greedy_stages.subVec(i,1).data();
@@ -804,7 +804,7 @@
     computeRepresentation(input, previous_input_representation, 
                           index);
     connections[index]-&gt;fprop(previous_input_representation,
-                                     activations[index+1]);
+                              activations[index+1]);
     layers[index+1]-&gt;fprop(activations[index+1],
                            expectations[index+1]);
 
@@ -896,7 +896,7 @@
     {
         if( !fast_exact_is_equal( cd_decrease_ct , 0 ) )
             lr = cd_learning_rate/(1 + cd_decrease_ct 
-                                       * this_stage); 
+                                   * this_stage); 
         else
             lr = cd_learning_rate;
 
@@ -1005,7 +1005,7 @@
             coef = (1.0/(sm_svd[k]+sigma_noise) - 1.0/sigma_noise);
             multiplyAcc(inv_sigma_zj,uk,dotp*coef);
             mahal -= dotp*dotp*0.5*coef;
-            norm_term -= 0.5*pl_log(sm_svd[k]);
+            norm_term -= 0.5*pl_log(sm_svd[k]+sigma_noise);
             if(j==0)
                 tr_inv_Sigma += coef;
         }
@@ -1107,8 +1107,8 @@
 
 
 void DeepNonLocalManifoldParzen::computeRepresentation(const Vec&amp; input,
-                                                             Vec&amp; representation,
-                                                             int layer) const
+                                                       Vec&amp; representation,
+                                                       int layer) const
 {
     if(layer == 0)
     {
@@ -1301,7 +1301,7 @@
 }
 
 void DeepNonLocalManifoldParzen::computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
-                                           const Vec&amp; target, Vec&amp; costs) const
+                                                         const Vec&amp; target, Vec&amp; costs) const
 {
 
     //Assumes that computeOutput has been called

Modified: trunk/plearn_learners_experimental/ManifoldParzen.cc
===================================================================
--- trunk/plearn_learners_experimental/ManifoldParzen.cc	2008-06-20 16:12:42 UTC (rev 9156)
+++ trunk/plearn_learners_experimental/ManifoldParzen.cc	2008-06-20 19:27:24 UTC (rev 9157)
@@ -212,14 +212,14 @@
     /*!
       A typical forget() method should do the following:
       - call inherited::forget() to initialize its random number generator
-        with the 'seed' option
+      with the 'seed' option
       - initialize the learner's parameters, using this random generator
       - stage = 0
     */
     inherited::forget();
 
     for(int i=0; i &lt; eigenvectors.length(); i++)
-      eigenvectors[i].clear();
+        eigenvectors[i].clear();
     eigenvalues.clear();
     sigma_noises.clear();
     mus.clear();
@@ -249,43 +249,43 @@
     train_stats-&gt;forget();
 
     if( stage &lt; 1 &amp;&amp; nstages &gt; 0 )
-      {
+    {
 	stage = 1;
 	MODULE_LOG &lt;&lt; &quot;Finding the nearest neighbors&quot; &lt;&lt; endl;
 	// Find training nearest neighbors
 	TVec&lt;int&gt; nearest_neighbors_indices_row;
 	nearest_neighbors_indices.resize(train_set-&gt;length(), nneighbors);
 	if( nclasses &gt; 1 )
-	  for(int k=0; k&lt;nclasses; k++)
+            for(int k=0; k&lt;nclasses; k++)
 	    {
-	      for(int i=0; i&lt;class_datasets[k]-&gt;length(); i++)
+                for(int i=0; i&lt;class_datasets[k]-&gt;length(); i++)
 		{
-		  class_datasets[k]-&gt;getExample(i,input,target,weight);
-		  nearest_neighbors_indices_row = nearest_neighbors_indices(
-									    class_datasets[k]-&gt;indices[i]);
+                    class_datasets[k]-&gt;getExample(i,input,target,weight);
+                    nearest_neighbors_indices_row = nearest_neighbors_indices(
+                        class_datasets[k]-&gt;indices[i]);
 		
-		  computeNearestNeighbors(
-					  new GetInputVMatrix((VMatrix *)class_datasets[k]),input,
-					  nearest_neighbors_indices_row,
-					  i);
+                    computeNearestNeighbors(
+                        new GetInputVMatrix((VMatrix *)class_datasets[k]),input,
+                        nearest_neighbors_indices_row,
+                        i);
 		}
 	    }
 	else
-	  for(int i=0; i&lt;train_set-&gt;length(); i++)
+            for(int i=0; i&lt;train_set-&gt;length(); i++)
 	    {
-	      train_set-&gt;getExample(i,input,target,weight);
-	      nearest_neighbors_indices_row = nearest_neighbors_indices(i);
-	      computeNearestNeighbors(
-				      train_set,input,
-				      nearest_neighbors_indices_row,
-				      i);
+                train_set-&gt;getExample(i,input,target,weight);
+                nearest_neighbors_indices_row = nearest_neighbors_indices(i);
+                computeNearestNeighbors(
+                    train_set,input,
+                    nearest_neighbors_indices_row,
+                    i);
 	    }
       
         train_costs.fill(MISSING_VALUE);
 
         if( report_progress )
-	  pb = new ProgressBar( &quot;Training ManifoldParzen&quot;,
-				train_set-&gt;length() );
+            pb = new ProgressBar( &quot;Training ManifoldParzen&quot;,
+                                  train_set-&gt;length() );
 
 	eigenvectors.resize( train_set-&gt;length() );
 	eigenvalues.resize( train_set-&gt;length(), ncomponents );
@@ -293,54 +293,54 @@
 	mus.resize( train_set-&gt;length(), inputsize() );
 	mus.clear();
         for( sample = 0; sample &lt; train_set-&gt;length() ; sample++ )
-	  { 
+        { 
             train_set-&gt;getExample( sample, input, target, weight );
 	    
             // Find nearest neighbors
             if( nclasses &gt; 1 )
-	      for( int k=0; k&lt;nneighbors; k++ )
+                for( int k=0; k&lt;nneighbors; k++ )
                 {
-		  class_datasets[(int)round(target[0])]-&gt;getExample(
-								    nearest_neighbors_indices(sample,k),
-								    nearest_neighbor, target2, weight2);
+                    class_datasets[(int)round(target[0])]-&gt;getExample(
+                        nearest_neighbors_indices(sample,k),
+                        nearest_neighbor, target2, weight2);
 		  
-		  if(round(target[0]) != round(target2[0]))
-		    PLERROR(&quot;ManifoldParzen::train(): similar&quot;
-			    &quot; example is not from same class!&quot;);
-		  nearest_neighbors(k) &lt;&lt; nearest_neighbor;
+                    if(round(target[0]) != round(target2[0]))
+                        PLERROR(&quot;ManifoldParzen::train(): similar&quot;
+                                &quot; example is not from same class!&quot;);
+                    nearest_neighbors(k) &lt;&lt; nearest_neighbor;
                 }
             else
-	      for( int k=0; k&lt;nneighbors; k++ )
+                for( int k=0; k&lt;nneighbors; k++ )
                 {
-		  train_set-&gt;getExample(
-					nearest_neighbors_indices(sample,k),
-					nearest_neighbor, target2, weight2);
-		  nearest_neighbors(k) &lt;&lt; nearest_neighbor;
+                    train_set-&gt;getExample(
+                        nearest_neighbors_indices(sample,k),
+                        nearest_neighbor, target2, weight2);
+                    nearest_neighbors(k) &lt;&lt; nearest_neighbor;
                 }
 	    
 	    if( learn_mu )
-	      {
+            {
 		mu.resize(inputsize());
 		columnMean( nearest_neighbors, mu );
 		mus(sample) &lt;&lt; mu;
 		mus(sample) -= input;
-	      }
+            }
 	    substractFromRows(nearest_neighbors, input, false); // Boolean is somehow unused???
 	    lapackSVD(nearest_neighbors, Ut, S, V,'A',1.5);
 	    eigenvectors[sample].resize(ncomponents,inputsize());
 	    for (int k=0;k&lt;ncomponents;k++)
-	      {
-		eigenvalues(sample,k) = mypow(S[k],2);
+            {
+		eigenvalues(sample,k) = mypow(S[k],2)/nneighbors;
 		eigenvectors[sample](k) &lt;&lt; Ut(k);
-	      }
+            }
 	    sigma_noises[sample] = 0; // HUGO: Seems stupid for now, but I keep 
 	                              //       this variable in case I want to use
 	                              //       the last eigen value or something...
 
             if( pb )
-	      pb-&gt;update( sample + 1 );
-	  }
-      }
+                pb-&gt;update( sample + 1 );
+        }
+    }
     
     train_stats-&gt;finalize();
     MODULE_LOG &lt;&lt; &quot;  train costs = &quot; &lt;&lt; train_stats-&gt;getMean() &lt;&lt; endl;
@@ -372,23 +372,23 @@
 
     int input_j_index;
     for( int i=0; i&lt;nclasses; i++ )
-      {
+    {
 	for( int j=0; 
 	     j&lt;(nclasses &gt; 1 ? 
 		class_datasets[i]-&gt;length() 
 		: train_set-&gt;length()); 
 	     j++ )
-	  {
+        {
 	    if( nclasses &gt; 1 )
-	      {
+            {
 		class_datasets[i]-&gt;getExample(j,input_j,target,weight);
 		input_j_index = class_datasets[i]-&gt;indices[j];
-	      }
+            }
 	    else
-	      {
+            {
 		train_set-&gt;getExample(j,input_j,target,weight);
 		input_j_index = j;
-	      }
+            }
 	    
 	    U &lt;&lt; eigenvectors[input_j_index];
 	    sm_svd &lt;&lt; eigenvalues(input_j_index);
@@ -400,25 +400,25 @@
             
 	    mahal = -0.5*pownorm(diff)/sigma_noise;      
 	    norm_term = - n/2.0 * Log2Pi - 0.5*(n-ncomponents)*
-	      pl_log(sigma_noise);
+                pl_log(sigma_noise);
 	    
 	    for(int k=0; k&lt;ncomponents; k++)
-	      { 
+            { 
 		uk = U(k);
 		dotp = dot(diff,uk);
 		coef = (1.0/(sm_svd[k]+global_lambda0) - 1.0/sigma_noise);
 		mahal -= dotp*dotp*0.5*coef;
 		norm_term -= 0.5*pl_log(sm_svd[k]+global_lambda0);
-	      }
+            }
 	    
 	    if( j==0 )
-	      log_p_x_g_y = norm_term + mahal;
+                log_p_x_g_y = norm_term + mahal;
 	    else
-	      log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
-	  }
+                log_p_x_g_y = logadd(norm_term + mahal, log_p_x_g_y);
+        }
         
 	test_votes[i] = log_p_x_g_y;
-      }
+    }
 
     if( nclasses &gt; 1 )
         output[0] = argmax(test_votes);
@@ -427,7 +427,7 @@
 }
 
 void ManifoldParzen::computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
-                                           const Vec&amp; target, Vec&amp; costs) const
+                                             const Vec&amp; target, Vec&amp; costs) const
 {
 
     //Assumes that computeOutput has been called
@@ -436,19 +436,19 @@
     costs.fill( MISSING_VALUE );
 
     if( nclasses &gt; 1 )
-      {
+    {
 	int target_class = ((int)round(target[0]));
 	if( ((int)round(output[0])) == target_class )
-	  costs[0] = 0;
+            costs[0] = 0;
 	else
-	  costs[0] = 1;
+            costs[0] = 1;
 	costs[1] = - test_votes[target_class]
-	  +pl_log(class_datasets[target_class]-&gt;length()); // Must take into account the 1/n normalization
-      }
+            +pl_log(class_datasets[target_class]-&gt;length()); // Must take into account the 1/n normalization
+    }
     else
-      {
+    {
 	costs[1] = - output[0]; // 1/n normalization already accounted for
-      }
+    }
 }
 
 TVec&lt;string&gt; ManifoldParzen::getTestCostNames() const


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002604.html">[Plearn-commits] r9156 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="002606.html">[Plearn-commits] r9158 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2605">[ date ]</a>
              <a href="thread.html#2605">[ thread ]</a>
              <a href="subject.html#2605">[ subject ]</a>
              <a href="author.html#2605">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
