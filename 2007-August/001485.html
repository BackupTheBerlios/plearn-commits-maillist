<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8037 - trunk/plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-August/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8037%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200708301820.l7UIK9Ao011209%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001484.html">
   <LINK REL="Next"  HREF="001486.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8037 - trunk/plearn_learners/generic/EXPERIMENTAL</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8037%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200708301820.l7UIK9Ao011209%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8037 - trunk/plearn_learners/generic/EXPERIMENTAL">tihocan at mail.berlios.de
       </A><BR>
    <I>Thu Aug 30 20:20:09 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001484.html">[Plearn-commits] r8036 - trunk/plearn_learners/online/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="001486.html">[Plearn-commits] r8038 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1485">[ date ]</a>
              <a href="thread.html#1485">[ thread ]</a>
              <a href="subject.html#1485">[ subject ]</a>
              <a href="author.html#1485">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2007-08-30 20:20:09 +0200 (Thu, 30 Aug 2007)
New Revision: 8037

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.h
Log:
Put back the decrease constant mechanism. Now it does not use the semaphore anymore, but instead uses shared memory: this overcomes the issue of a max value for semaphores.

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-08-29 18:53:09 UTC (rev 8036)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-08-30 18:20:09 UTC (rev 8037)
@@ -99,12 +99,17 @@
       cumulative_training_time(0),
       params_ptr(NULL),
       params_id(-1),
+      params_int_ptr(NULL),
+      params_int_id(-1),
       nsteps(0),
       semaphore_id(-1)
 {
     random_gen = new PRandom();
 }
 
+////////////////////
+// declareOptions //
+////////////////////
 void NatGradSMPNNet::declareOptions(OptionList&amp; ol)
 {
     declareOption(ol, &quot;delayed_update&quot;, &amp;NatGradSMPNNet::delayed_update,
@@ -349,6 +354,9 @@
     inherited::declareOptions(ol);
 }
 
+////////////
+// build_ //
+////////////
 void NatGradSMPNNet::build_()
 {
     if (!train_set)
@@ -410,16 +418,17 @@
     }
 
     // Allocate shared memory for parameters.
-    // First deallocate memory if needed.
-    if (params_ptr) {
-        shmctl(params_id, IPC_RMID, 0);
-        params_ptr = NULL;
-    }
+    freeSharedMemory(); // First deallocate memory if needed.
     long total_memory_needed = long(n_params) * sizeof(real);
     params_id = shmget(IPC_PRIVATE, total_memory_needed, 0666 | IPC_CREAT);
     PLCHECK( params_id != -1 );
     params_ptr = (real*) shmat(params_id, 0, 0);
-    assert( params_ptr );
+    PLCHECK( params_ptr );
+    long total_int_memory_needed = 1 * sizeof(int);
+    params_int_id = shmget(IPC_PRIVATE, total_int_memory_needed, 0666 | IPC_CREAT);
+    PLCHECK( params_int_id != -1 );
+    params_int_ptr = (int*) shmat(params_int_id, 0, 0);
+    PLCHECK( params_int_ptr );
     // We should have copied data from 'all_params' first if there were some!
     PLCHECK_MSG( all_params.isEmpty(), &quot;Multiple builds not implemented yet&quot; );
     all_params = Vec(n_params, params_ptr);
@@ -552,14 +561,36 @@
 
 }
 
-// ### Nothing to add here, simply calls build_
+///////////
+// build //
+///////////
 void NatGradSMPNNet::build()
 {
     inherited::build();
     build_();
 }
 
+//////////////////////
+// freeSharedMemory //
+//////////////////////
+void NatGradSMPNNet::freeSharedMemory()
+{
+    if (params_ptr) {
+        shmctl(params_id, IPC_RMID, 0);
+        params_ptr = NULL;
+        params_id = -1;
+    }
+    if (params_int_ptr) {
+        shmctl(params_int_id, IPC_RMID, 0);
+        params_int_ptr = NULL;
+        params_int_id = -1;
+    }
+}
 
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
 void NatGradSMPNNet::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
@@ -604,8 +635,12 @@
     if (params_ptr)
         PLERROR(&quot;In NatGradSMPNNet::makeDeepCopyFromShallowCopy - Deep copy of&quot;
                 &quot; 'params_ptr' not implemented&quot;);
+    if (params_int_ptr)
+        PLERROR(&quot;In NatGradSMPNNet::makeDeepCopyFromShallowCopy - Deep copy of&quot;
+                &quot; 'params_int_ptr' not implemented&quot;);
 
 
+
 /*
     deepCopyField(, copies);
 */
@@ -708,7 +743,7 @@
     // period.
     // Finally, the last value is the current stage, i.e. the number of samples
     // with which the network has been updated so far.
-    semaphore_id = semget(IPC_PRIVATE, ncpus + 2, 0666 | IPC_CREAT);
+    semaphore_id = semget(IPC_PRIVATE, ncpus + 1, 0666 | IPC_CREAT);
     if (semaphore_id == -1)
         PLERROR(&quot;In NatGradSMPNNet::train - Could not create semaphore &quot;
                 &quot;(errno = %d)&quot;, errno);
@@ -721,13 +756,11 @@
             PLERROR(&quot;In NatGradSMPNNet::train - Could not initialize semaphore&quot;
                     &quot; value (errno = %d)&quot;, errno);
     }
-    semun_v.val = stage;
-    semun_v.val = 0; // TODO Fix (pb with max semaphore value)
-    int success = semctl(semaphore_id, ncpus + 1, SETVAL, semun_v);
-    if (success != 0)
-        PLERROR(&quot;In NatGradSMPNNet::train - Could not initialize semaphore&quot;
-                &quot; value to store the stage (errno = %d)&quot;, errno);
 
+    // Initialize current stage, stored in integer shared memory.
+    int stage_idx = 0;
+    params_int_ptr[stage_idx] = stage;
+
     // Fork one process/cpu.
     int iam = 0;
     for (int cpu = 1; cpu &lt; ncpus ; cpu++)
@@ -762,7 +795,7 @@
         {
             // Read the current stage value (will be used to compute the
             // current learning rate).
-            int cur_stage = semctl(semaphore_id, ncpus + 1, GETVAL);
+            int cur_stage = params_int_ptr[stage_idx];
             PLASSERT( cur_stage &gt;= 0 );
             onlineStep(cur_stage, targets, train_costs, example_weights );
             nsteps++;
@@ -782,20 +815,14 @@
                     params_update.clear();
                 }
                 // Update the current stage.
-                cur_stage = semctl(semaphore_id, ncpus + 1, GETVAL);
+                cur_stage = params_int_ptr[stage_idx];
                 PLASSERT( cur_stage &gt;= 0 );
-                semun_v.val = cur_stage + nsteps * minibatch_size;
-                semun_v.val = 0; // TODO Fix: pb with max semaphore value.
-                success = semctl(semaphore_id, ncpus + 1, SETVAL, semun_v);
-                if (success != 0)
-                    PLERROR(&quot;In NatGradSMPNNet::train - Could not update &quot;
-                            &quot;stage value for semaphore (errno = %d, returned &quot;
-                            &quot;value = %d, set value = %d)&quot;, errno, success,
-                            semun_v.val);
+                int new_stage = cur_stage + nsteps * minibatch_size;
+                params_int_ptr[stage_idx] = new_stage;
                 // Give update token to next CPU.
                 sem_value = (sem_value + 1) % ncpus;
                 semun_v.val = sem_value;
-                success = semctl(semaphore_id, 0, SETVAL, semun_v);
+                int success = semctl(semaphore_id, 0, SETVAL, semun_v);
                 if (success != 0)
                     PLERROR(&quot;In NatGradSMPNNet::train - Could not update &quot;
                             &quot;semaphore with next CPU (errno = %d, returned &quot;
@@ -912,7 +939,7 @@
     */
 
     // Get current stage (for debug purpose).
-    int cur_stage = semctl(semaphore_id, ncpus + 1, GETVAL);
+    int cur_stage = params_int_ptr[stage_idx];
     PLASSERT( cur_stage &gt;= 0 );
 
     // Free semaphore's ressources.
@@ -1402,10 +1429,7 @@
 
 NatGradSMPNNet::~NatGradSMPNNet()
 {
-    if (params_ptr) {
-        shmctl(params_id, IPC_RMID, 0);
-        params_ptr = NULL;
-    }
+    freeSharedMemory();
     if (semaphore_id &gt;= 0) {
         int success = semctl(semaphore_id, 0, IPC_RMID);
         if (success &lt; 0)

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.h	2007-08-29 18:53:09 UTC (rev 8036)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.h	2007-08-30 18:20:09 UTC (rev 8037)
@@ -329,8 +329,10 @@
     Vec example_weights; // one element per example in a minibatch
     Mat train_costs; // one row per example in a minibatch
 
-    real* params_ptr; // Raw pointer to the (shared) parameters.
-    int params_id; // Shared memory id for parameters.
+    real* params_ptr;       // Raw pointer to the (shared) parameters.
+    int params_id;          // Shared memory id for parameters.
+    int* params_int_ptr;    // Raw pointer to the (shared) integer parameters.
+    int params_int_id;      // Shared memory id for integer parameters.
 
     //! Number of online steps performed since the last global parameter update.
     int nsteps;
@@ -347,6 +349,9 @@
     TVec&lt;Mat&gt; layer_params_update;
 
     //PP&lt;CorrelationProfiler&gt; g_corrprof, ng_corrprof;    // for optional gradient correlation profiling
+
+    //! Free shared memory that may still be allocated.
+    void freeSharedMemory();
 };
 
 // Declares a few other classes and functions related to this class


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001484.html">[Plearn-commits] r8036 - trunk/plearn_learners/online/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="001486.html">[Plearn-commits] r8038 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1485">[ date ]</a>
              <a href="thread.html#1485">[ thread ]</a>
              <a href="subject.html#1485">[ subject ]</a>
              <a href="author.html#1485">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
