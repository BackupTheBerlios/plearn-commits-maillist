<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7993 - trunk/python_modules/plearn/learners
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-August/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7993%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200708141916.l7EJGeFd006659%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001440.html">
   <LINK REL="Next"  HREF="001442.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7993 - trunk/python_modules/plearn/learners</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7993%20-%20trunk/python_modules/plearn/learners&In-Reply-To=%3C200708141916.l7EJGeFd006659%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7993 - trunk/python_modules/plearn/learners">nouiz at mail.berlios.de
       </A><BR>
    <I>Tue Aug 14 21:16:40 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001440.html">[Plearn-commits] r7992 - in trunk: . plearn/base plearn/python
</A></li>
        <LI>Next message: <A HREF="001442.html">[Plearn-commits] r7994 - trunk/plearn/math
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1441">[ date ]</a>
              <a href="thread.html#1441">[ thread ]</a>
              <a href="subject.html#1441">[ subject ]</a>
              <a href="author.html#1441">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2007-08-14 21:16:40 +0200 (Tue, 14 Aug 2007)
New Revision: 7993

Added:
   trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py
Log:
Added a new learner that generate do a boosting on 3 classes with 2 standard adaboost

Added: trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py
===================================================================
--- trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py	2007-08-14 18:22:44 UTC (rev 7992)
+++ trunk/python_modules/plearn/learners/AdaBoostMultiClasses.py	2007-08-14 19:16:40 UTC (rev 7993)
@@ -0,0 +1,122 @@
+from plearn.pyext import *
+from plearn.pyplearn.plargs import *
+
+
+class AdaBoostMultiClasses:
+#class AdaBoost3PLearner(pl.PLearner):
+    def __init__(self,trainSet1,trainSet2):
+        self.trainSet1=trainSet1
+        self.trainSet2=trainSet2
+        self.learner1 = self.myAdaBoostLearner(self.weakLearner(),trainSet1)
+        self.learner1.expdir=plargs.expdirr+&quot;/learner1&quot;
+        self.learner1.setTrainingSet(trainSet1,True)
+        
+        self.learner2 = self.myAdaBoostLearner(self.weakLearner(),trainSet2)
+        self.learner2.expdir=plargs.expdirr+&quot;/learner2&quot;
+        self.learner2.setTrainingSet(trainSet2,True)
+        self.nstages = 0
+        self.stage = 0
+#        self.confusion_target=plargs.confusion_target
+        
+    def weakLearner(self):
+        &quot;&quot;&quot; Return a new instance of the weak learner to use&quot;&quot;&quot;
+        return pl.RegressionTree(
+            nstages = plargs.subnstages
+            ,loss_function_weight = 1
+            ,missing_is_valid = plargs.missing_is_valid
+            ,multiclass_outputs = plargs.multiclass_output
+            ,maximum_number_of_nodes = 500
+            ,compute_train_stats = 0
+            ,complexity_penalty_factor = 0.0
+            ,verbosity = 0
+            ,report_progress = 1
+            ,forget_when_training_set_changes = 1
+            ,leave_template = pl.RegressionTreeLeave( )
+            )
+    
+    def myAdaBoostLearner(self,sublearner,trainSet):
+        l = pl.AdaBoost()
+        l.weak_learner_template=sublearner
+        l.pseudo_loss_adaboost=True
+        l.weight_by_resampling=plargs.weight_by_resampling
+        l.setTrainingSet(trainSet,True)
+        l.setTrainStatsCollector(VecStatsCollector())
+        return l
+
+    def train(self):
+        self.learner1.nstages = self.nstages
+        self.learner1.train()
+        self.learner2.nstages = self.nstages
+        self.learner2.train()
+        self.stage=self.learner1.stage
+
+    def getTestCostNames(self):
+        costnames = [&quot;class_error&quot;,&quot;linear_class_error&quot;,&quot;square_class_error&quot;]
+        #    for i in range(len(conf_matrix)):
+        #        for j in range(len(conf_matrix[i])):
+        for i in range(4):
+            for j in range(3):
+                costnames.append(&quot;conf_matrix_%d_%d&quot;%(i,j))
+        return costnames
+
+    def computeOutput(self,example):
+        &quot;&quot;&quot; compute the output for the example in the parameter
+        
+        return a tuple: (predicted result, output of sub learner1,output of sub learner2)
+        &quot;&quot;&quot;
+        out1=self.learner1.computeOutput(example)[0]
+        out2=self.learner2.computeOutput(example)[0]
+        ind1=int(round(out1))
+        ind2=int(round(out2))
+        if ind1==ind2==0:
+            ind=0
+        elif ind1==1 and ind2==0:
+            ind=1
+        elif ind1==ind2==1:
+            ind=2
+        else:
+            ind=3
+        return (ind,out1,out2)
+    
+    def computeCostsFromOutput(self,input,output,target,costs=[]):
+        del costs[:]
+        class_error=int(output[0] != target)
+        linear_class_error=abs(output[0]-target)
+        square_class_error=pow(abs(output[0]-target),2)
+        costs.append(class_error)
+        costs.append(linear_class_error)
+        costs.append(square_class_error)
+        for i in range(4):
+            for j in range(3):
+                costs.append(0)
+        costs[output[0]*3+target+3]=1  
+        return costs
+        
+    def outputsize(self):
+        return len(self.getTestCostNames())
+
+    def save(self,path=&quot;&quot;,encoding=&quot;plearn_ascii&quot;):
+        if not os.path.exists(path):
+            os.mkdir(path)
+        if path:
+            path+=&quot;/&quot;
+        else:
+            print &quot;WARNING: AdaBoost3PLearner - no path for saving the learner, we use the current directory&quot;
+        self.learner1.save(path+&quot;learner1_stage#&quot;+str(self.stage)+&quot;.psave&quot;,encoding)
+        self.learner2.save(path+&quot;learner2_stage#&quot;+str(self.stage)+&quot;.psave&quot;,encoding)
+    
+    def load_old_learner(self,filepath,stage,trainSet1,trainSet2):
+        print &quot;load_old_learner&quot;
+        self.old_learner1=self.learner1
+        self.old_learner2=self.learner2
+        self.learner1=loadObject(filepath+&quot;/learner1_stage#&quot;+str(stage)+&quot;.psave&quot;)
+        self.learner2=loadObject(filepath+&quot;/learner2_stage#&quot;+str(stage)+&quot;.psave&quot;)
+        assert(self.learner1.stage==self.learner2.stage)
+        self.stage=self.learner1.stage
+        self.nstages=self.learner1.nstages
+#        self.learner1.expdir=plargs.expdirr+&quot;/learner1&quot;
+        self.learner1.setTrainingSet(trainSet1,False)
+        self.learner2.setTrainingSet(trainSet2,False)
+        print self.stage
+        print self.stage
+        


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001440.html">[Plearn-commits] r7992 - in trunk: . plearn/base plearn/python
</A></li>
	<LI>Next message: <A HREF="001442.html">[Plearn-commits] r7994 - trunk/plearn/math
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1441">[ date ]</a>
              <a href="thread.html#1441">[ thread ]</a>
              <a href="subject.html#1441">[ subject ]</a>
              <a href="author.html#1441">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
