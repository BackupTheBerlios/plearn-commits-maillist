<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7941 - trunk/python_modules/plearn/parallel
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-August/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7941%20-%20trunk/python_modules/plearn/parallel&In-Reply-To=%3C200708071746.l77HkODn009010%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001388.html">
   <LINK REL="Next"  HREF="001390.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7941 - trunk/python_modules/plearn/parallel</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7941%20-%20trunk/python_modules/plearn/parallel&In-Reply-To=%3C200708071746.l77HkODn009010%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7941 - trunk/python_modules/plearn/parallel">nouiz at mail.berlios.de
       </A><BR>
    <I>Tue Aug  7 19:46:24 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001388.html">[Plearn-commits] r7940 - trunk/scripts
</A></li>
        <LI>Next message: <A HREF="001390.html">[Plearn-commits] r7942 - in trunk: python_modules/plearn/parallel	scripts
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1389">[ date ]</a>
              <a href="thread.html#1389">[ thread ]</a>
              <a href="subject.html#1389">[ subject ]</a>
              <a href="author.html#1389">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2007-08-07 19:46:24 +0200 (Tue, 07 Aug 2007)
New Revision: 7941

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
Log:
-new try for condor with all computer (32 and 64 bits)
-cluster with 32,64 or both computer
-redirect stdout, stderr
-new fct add_command()
-new fct exec_pre_batch()
-new fct exec_post_batch()


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2007-08-07 17:22:26 UTC (rev 7940)
+++ trunk/python_modules/plearn/parallel/dbi.py	2007-08-07 17:46:24 UTC (rev 7941)
@@ -48,28 +48,29 @@
         self.post_batch = []
 
         # the default directory where to keep all the log files
-        self.log_dir = 'LOGS'
-        self.log_file = os.path.join( self.log_dir, self.unique_id )
+        self.log_dir = os.path.join( 'LOGS', self.unique_id )
+        self.log_file = os.path.join( self.log_dir, 'log' )
 
         # the default directory where file generated by dbi will be stored
         # It should not take the &quot;&quot; or &quot; &quot; value. Use &quot;.&quot; instead.
         self.tmp_dir = 'TMP_DBI'
-
         #
-        self.file_redirect_stdout = False
-        self.file_redirect_stderr = False
+        self.file_redirect_stdout = True
+        self.file_redirect_stderr = True
 
         # Initialize the namespace
         self.requirements = ''
         self.test = False
         self.dolog = False
         self.temp_files = []
+        self.arch = 0 # TODO, we should put the local arch: 32,64 or 3264 bits
         for key in args.keys():
             self.__dict__[key] = args[key]
 
         # check if log directory exists, if not create it
-        if self.dolog and not os.path.exists(self.log_dir):
-            os.mkdir(self.log_dir)
+#        if (not os.path.exists(self.log_dir)):
+#            if self.dolog or self.file_redirect_stdout or self.file_redirect_stderr:
+        os.mkdir(self.log_dir)
 
         # If some arguments aren't lists, put them in a list
         if not isinstance(commands, list):
@@ -84,7 +85,35 @@
             self.post_batch = [self.post_batch]
 
     def n_avail_machines(self): raise NotImplementedError, &quot;DBIBase.n_avail_machines()&quot;
-
+    def add_command(self,command): raise NotImplementedError, &quot;DBIBase.add_command()&quot;
+    def exec_pre_batch(self):
+        # Execute pre-batch
+        output = PIPE
+        error = PIPE
+        pre_batch_command = ';'.join( self.pre_batch )
+        if int(self.file_redirect_stdout):
+            output = file(self.log_file + '.pre_batch.out', 'w')
+        if int(self.file_redirect_stderr):
+            error = file(self.log_file + '.pre_batch.err', 'w')
+        if not self.test:
+            self.pre = Popen(pre_batch_command, shell=True, stdout=output, stderr=error)
+        else:
+            print &quot;[DBI] pre_batch_command:&quot;,pre_batch_command
+            
+    def exec_post_batch(self):
+        # Execute post-batch
+        output = PIPE
+        error = PIPE
+        post_batch_command = ';'.join( self.post_batch )
+        if int(self.file_redirect_stdout):
+            output = file(self.log_file + '.post_batch.out', 'w')
+        if int(self.file_redirect_stderr):
+            error = file(self.log_file + '.post_batch.err', 'w')
+        if not self.test:
+            self.post = Popen(post_batch_command, shell=True, stdout=output, stderr=error)
+        else:
+            print &quot;[DBI] post_batch_command:&quot;,post_batch_command
+            
     def clean(self):
         pass
 
@@ -208,8 +237,16 @@
 
     def run_one_job(self, task):
         DBIBase.run(self)
-
-        command = &quot;cluster --execute '&quot; + string.join(task.commands,';') + &quot;'&quot;
+        
+        command = &quot;cluster --execute&quot; 
+        if self.arch == 32:
+            command += &quot;--typecpu 32bits&quot;
+        elif self.arch == 64:
+            command += &quot;--typecpu 64bits&quot;
+        if self.arch==3264:
+            command += &quot;--typecpu all&quot;
+        command += &quot; '&quot;+string.join(task.commands,';') + &quot;'&quot;
+        
         print command
 
         task.launch_time = time.time()
@@ -228,33 +265,18 @@
         if self.test:
             print &quot;Test mode, we only print the command to be executed, we don't execute them&quot;
         # Execute pre-batch
-        pre_batch_command = ';'.join( self.pre_batch )
-        output = PIPE
-        error = PIPE
-        if int(self.file_redirect_stdout):
-            output = file(self.log_file + '.pre_batch.out', 'w')
-        if int(self.file_redirect_stderr):
-            error = file(self.log_file + '.pre_batch.err', 'w')
-        if self.test:
-            print pre_batch_command
-        else:
-            self.pre = Popen(pre_batch_command, shell=True, stdout=output, stderr=error)
+        if len(self.pre_batch)&gt;0:
+            exec_pre_batch()
 
         # Execute all Tasks (including pre_tasks and post_tasks if any)
         for task in self.tasks:
             self.run_one_job(task)
 
         # Execute post-batchs
-        post_batch_command = &quot;;&quot;.join( self.post_batch );
-        if int(self.file_redirect_stdout):
-            output = file(self.log_file + '.post_batch.out', 'w')
-        if int(self.file_redirect_stderr):
-            error = file(self.log_file + '.post_batch.err', 'w')
-        if self.test:
-            print post_batch_command
-        else:
-            self.post = Popen(post_batch_command, shell=True, stdout=output, stderr=error)
-            
+        if len(self.post_batch)&gt;0:
+            exec_post_batch()
+
+        print &quot;The Log file are under %s&quot;%self.log_dir
     def clean(self):
         #TODO: delete all log files for the current batch
         pass
@@ -397,12 +419,13 @@
                 self.targetcondorplatform='BOTH'
                 self.targetplatform='linux-i386'
                 #newcommand=c+&quot;.32&quot;+c2
-                newcommand='if [ $1 == &quot;INTEL&quot; ]; then\n'
-                newcommand+='  '+c+'.32'+c2+'\n'
-                newcommand+='else\n'
-                newcommand+='  '+c+&quot;.64&quot;+c2+'\nfi'
+                newcommand='if [ $CPUTYPE == \'x86_64\' ]; then'
+                newcommand+='  '+c+'.64'+c2
+                newcommand+='; else '
+                newcommand+=c+&quot;.32&quot;+c2+'; fi'
                 if not os.access(c+&quot;.64&quot;, os.X_OK):
                     raise Exception(&quot;The command '&quot;+c+&quot;.64' do not have execution permission!&quot;)
+#                newcommand=command
                 c+=&quot;.32&quot;
             elif self.cplat==&quot;INTEL&quot; and os.path.exists(c+&quot;.32&quot;):
                 self.targetcondorplatform='INTEL'
@@ -438,7 +461,10 @@
             return #no task to run
         # create the bqsubmit.dat, with
         condor_datas = []
-        if len(self.tasks)&gt;1:
+
+        #we supose that each task in tasks have the same number of commands
+        #it should be true.
+        if len(self.tasks[0].commands)&gt;1:
             for task in self.tasks:
                 condor_data = os.path.join(self.tmp_dir,self.unique_id +'.'+ task.unique_id + '.data')
                 condor_datas.append(condor_data)
@@ -483,7 +509,7 @@
 #                preBatch = ''' + pre_batch_command + '''
 #                postBatch = ''' + post_batch_command +'''
 
-        if len(condor_datas)==0:
+        if len(condor_datas)!=0:
             for i in condor_datas:
                 condor_dat.write(&quot;arguments      = sh &quot;+i+&quot; $$(Arch) \nqueue\n&quot;)
         else:
@@ -567,7 +593,11 @@
 
 
     def run(self):
+        if len(self.pre_batch)&gt;0):
+            exec_pre_batch()
         self.run_all_job()
+        if len(self.post_batch)&gt;0):
+            exec_post_batch()
 
 
 
@@ -581,33 +611,36 @@
         DBIBase.__init__(self, commands, **args)
 
         for command in commands:
-            pos = string.find(command,' ')
-            if pos&gt;=0:
-                c = command[0:pos]
-                c2 = command[pos:]
-            else:
-                c=command
-                c2=&quot;&quot;
-
-        # We use the absolute path so that we don't have corner case as with ./ 
-            c = os.path.normpath(os.path.join(os.getcwd(), c))
-            command = c + c2
+            addjobs(command)
             
-            # We will execute the command on the specified architecture
-            # if it is specified. If the executable exist for both
-            # architecture we execute on both. Otherwise we execute on the
-            # same architecture as the architecture of the launch computer
+    def add_command(self,command):
+        pos = string.find(command,' ')
+        if pos&gt;=0:
+            c = command[0:pos]
+            c2 = command[pos:]
+        else:
+            c=command
+            c2=&quot;&quot;
             
-            if not os.path.exists(c):
-                raise Exception(&quot;The command '&quot;+c+&quot;' do not exist!&quot;)
-            elif not os.access(c, os.X_OK):
-                raise Exception(&quot;The command '&quot;+c+&quot;' do not have execution permission!&quot;)
-            self.tasks.append(Task(command, self.tmp_dir, self.log_dir,
-                                   self.time_format, self.pre_tasks,
-                                   self.post_tasks,self.dolog,args))
+        # We use the absolute path so that we don't have corner case as with ./ 
+        c = os.path.normpath(os.path.join(os.getcwd(), c))
+        command = c + c2
+        
+        # We will execute the command on the specified architecture
+        # if it is specified. If the executable exist for both
+        # architecture we execute on both. Otherwise we execute on the
+        # same architecture as the architecture of the launch computer
+        
+        if not os.path.exists(c):
+            raise Exception(&quot;The command '&quot;+c+&quot;' do not exist!&quot;)
+        elif not os.access(c, os.X_OK):
+            raise Exception(&quot;The command '&quot;+c+&quot;' do not have execution permission!&quot;)
+        self.tasks.append(Task(command, self.tmp_dir, self.log_dir,
+                               self.time_format, self.pre_tasks,
+                               self.post_tasks,self.dolog,args))
+        
+        #keeps a list of the temporary files created, so that they can be deleted at will            
 
-            #keeps a list of the temporary files created, so that they can be deleted at will            
-
     def run_one_job(self,task):
         launch_file = os.path.join(self.tmp_dir, 'launch.sh')
 
@@ -623,7 +656,6 @@
         if self.test == False:
             print c
             os.system(c)
-
         else:
             print c
             
@@ -641,9 +673,24 @@
     def run(self):
         if self.test:
             print &quot;Test mode, we only print the command to be executed, we don't execute them&quot;
+        for (task,ind) in zip(self.tasks,range(len(self.tasks))):
+            print &quot;Will execute command %d/%d&quot;%(ind+1,len(self.tasks))
+            self.run_one_job(task)
+
+        # Execute pre-batch
+        output = PIPE
+        error = PIPE
+        if len(self.pre_batch)&gt;0:
+            exec_pre_batch()
+
+        # Execute all Tasks (including pre_tasks and post_tasks if any)
         for task in self.tasks:
             self.run_one_job(task)
 
+        # Execute post-batchs
+        if len(self.post_batch)&gt;0:
+            exec_post_batch()
+            
     def clean(self):
         pass
 
@@ -742,15 +789,8 @@
 
     def run(self):
         # Execute pre-batch
-        pre_batch_command = ';'.join( self.pre_batch )
-        output = PIPE
-        error = PIPE
-        if int(self.file_redirect_stdout):
-            output = file(self.log_file + '.pre_batch.out', 'w')
-        if int(self.file_redirect_stderr):
-            error = file(self.log_file + '.pre_batch.err', 'w')
-        self.pre = Popen(pre_batch_command, shell=True, stdout=output, stderr=error)
-        print 'pre_batch_command =', pre_batch_command
+        if len(self.pre_batch)&gt;0:
+            exec_pre_batch()
 
         # Execute all Tasks (including pre_tasks and post_tasks if any)
         print &quot;tasks= &quot;, self.tasks
@@ -758,13 +798,8 @@
             self.run_one_job(task)
 
         # Execute post-batchs
-        post_batch_command = &quot;;&quot;.join( self.post_batch );
-        if int(self.file_redirect_stdout):
-            output = file(self.log_file + '.post_batch.out', 'w')
-        if int(self.file_redirect_stderr):
-            error = file(self.log_file + '.post_batch.err', 'w')
-        self.post = Popen(post_batch_command, shell=True, stdout=output, stderr=error)
-        print 'post_batch_command =', post_batch_command
+        if len(self.post_batch)&gt;0:
+            exec_post_batch()
 
     def clean(self):
         #TODO: delete all log files for the current batch


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001388.html">[Plearn-commits] r7940 - trunk/scripts
</A></li>
	<LI>Next message: <A HREF="001390.html">[Plearn-commits] r7942 - in trunk: python_modules/plearn/parallel	scripts
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1389">[ date ]</a>
              <a href="thread.html#1389">[ thread ]</a>
              <a href="subject.html#1389">[ subject ]</a>
              <a href="author.html#1389">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
