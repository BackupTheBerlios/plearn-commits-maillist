<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7990 - trunk/python_modules/plearn/learners/autolr
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-August/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7990%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200708141748.l7EHm7ZN030630%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001437.html">
   <LINK REL="Next"  HREF="001439.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7990 - trunk/python_modules/plearn/learners/autolr</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7990%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200708141748.l7EHm7ZN030630%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7990 - trunk/python_modules/plearn/learners/autolr">nouiz at mail.berlios.de
       </A><BR>
    <I>Tue Aug 14 19:48:07 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001437.html">[Plearn-commits] r7989 - trunk/python_modules/plearn/parallel
</A></li>
        <LI>Next message: <A HREF="001439.html">[Plearn-commits] r7991 - trunk/python_modules/plearn/parallel
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1438">[ date ]</a>
              <a href="thread.html#1438">[ thread ]</a>
              <a href="subject.html#1438">[ subject ]</a>
              <a href="author.html#1438">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2007-08-14 19:48:07 +0200 (Tue, 14 Aug 2007)
New Revision: 7990

Modified:
   trunk/python_modules/plearn/learners/autolr/__init__.py
Log:
bugfix and more agressive deletion of candidate

now we also delete all candidate with a learning rate bellow the one for the best candidate


Modified: trunk/python_modules/plearn/learners/autolr/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/autolr/__init__.py	2007-08-14 17:46:26 UTC (rev 7989)
+++ trunk/python_modules/plearn/learners/autolr/__init__.py	2007-08-14 17:48:07 UTC (rev 7990)
@@ -426,8 +426,17 @@
         start_t = max(all_start[c1],all_start[c2])
         curve1 = error_curve(c1,start_t,t)#[valid_error]
         curve2 = error_curve(c2,start_t,t)
+        
         if curve2.shape[0]-1&lt;min_epochs_to_delete:
             return False
+
+        #If the best have a higher lr then the current one, we remove this one
+        #This one can't be better then the next one we will create
+        #as the next one we will create won't have a lower lr than this one
+        #and it start with a lower error rate
+        if all_lr[c1]&gt;c2lr:
+            return True
+        
         for a in actives:
             if a!=c2 and all_lr[a]==c2lr and all_last_err[a]&lt;=c2err:
                 # throw it away if worse than other actives of same lr
@@ -506,7 +515,7 @@
             print &gt;&gt;logfile, &quot;Before epoch&quot;,t+1
             print &gt;&gt;logfile, &quot;Actives now: &quot;,actives
             print &gt;&gt;logfile, &quot; with lr=&quot;, array(all_lr)[actives]
-        print &quot;Before epoch %d/%d&quot;%(t,n_train),&quot;actives now: &quot;,actives, &quot; with lr=&quot;, array(all_lr)[actives]
+        print &quot;Before epoch %d/%d&quot;%(t+1,n_train),&quot;actives now: &quot;,actives, &quot; with lr=&quot;, array(all_lr)[actives]
         print &quot;current best actives:&quot;,best_active,&quot;best_error:&quot;,all_last_err[best_active],&quot;lr:&quot;,all_lr[best_active]
 
         threads = []
@@ -639,7 +648,7 @@
                         print &gt;&gt;logfile,&quot;REMOVE candidate &quot;,a
                     release_server(all_candidates[a], use_threads)
                     # hopefully this destroys the candidate
-                    all_end[a]=t
+                    all_end[a]=t+1 # so that all_end[i]-all_start[i]=nb of epoch executed by this learner
                     all_candidates[a]=None
                     del actives[j-ndeleted]
                     ndeleted+=1
@@ -656,7 +665,7 @@
                 all_candidates.append(new_candidate)
                 all_results.append(all_results[best_active].copy())
                 all_last_err.append(best_last)
-                all_start.append(t)
+                all_start.append(t+1)#start at the next epoch
                 all_end.append(-1)
                 if logfile:
                     print &gt;&gt;logfile,&quot;CREATE candidate &quot;, new_a, &quot; from &quot;,best_active,&quot;at stage &quot;,learner.stage,&quot; with lr=&quot;,all_lr[new_a]
@@ -670,14 +679,13 @@
     if logfile and best_err &lt; all_last_err[best_active]:
         print &gt;&gt;logfile, &quot;WARNING: best performing model would have stopped early at stage &quot;,best_early_stop
     if logfile:
-        print &gt;&gt;logfile,&quot;When then learner started&quot;,all_start
-        print &gt;&gt;logfile,&quot;When then learner ended&quot;,all_end
+        print &gt;&gt;logfile,&quot;We created %d learner&quot;%len(all_start)
+        print &gt;&gt;logfile,&quot;When the learners started:&quot;,all_start
+        all_end2=[ ifthenelse(x==-1,t+1,x) for x in all_end ]
+        print &gt;&gt;logfile,&quot;When the learners ended:&quot;,all_end2
         l=[]
         for i in range(len(all_start)):
-            if all_end[i]==-1:
-                l.append(abs(all_start[i]-n_train))
-            else:
-                l.append(abs(all_start[i]-all_end[i]+1))
+            l.append(all_end2[i]-all_start[i])
         print &gt;&gt;logfile,&quot;Duration of all learner in number of epoch:&quot;,l
         sum=reduce(lambda x,y:x+y, l)
         print &gt;&gt;logfile,&quot;Their was a total of %d epoch executed for %d asked(%fx more)&quot;%(sum,n_train,float(sum)/n_train)


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001437.html">[Plearn-commits] r7989 - trunk/python_modules/plearn/parallel
</A></li>
	<LI>Next message: <A HREF="001439.html">[Plearn-commits] r7991 - trunk/python_modules/plearn/parallel
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1438">[ date ]</a>
              <a href="thread.html#1438">[ thread ]</a>
              <a href="subject.html#1438">[ subject ]</a>
              <a href="author.html#1438">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
