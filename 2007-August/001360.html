<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7915 - trunk/plearn_learners/regressors
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-August/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7915%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200708021953.l72Jr5N7013920%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001362.html">
   <LINK REL="Next"  HREF="001364.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7915 - trunk/plearn_learners/regressors</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7915%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200708021953.l72Jr5N7013920%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7915 - trunk/plearn_learners/regressors">nouiz at mail.berlios.de
       </A><BR>
    <I>Thu Aug  2 21:53:05 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001362.html">[Plearn-commits] r7914 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="001364.html">[Plearn-commits] r7916 - trunk/plearn/io
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1360">[ date ]</a>
              <a href="thread.html#1360">[ thread ]</a>
              <a href="subject.html#1360">[ subject ]</a>
              <a href="author.html#1360">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2007-08-02 21:53:04 +0200 (Thu, 02 Aug 2007)
New Revision: 7915

Modified:
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
   trunk/plearn_learners/regressors/RegressionTreeRegisters.h
Log:
-Made RegressionTreeRegisters look more like a VMatrix for its functions and variable name
-Added VMatrix function to RegressionTreeRegisters
-put global variable name local


Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-08-02 19:37:12 UTC (rev 7914)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2007-08-02 19:53:04 UTC (rev 7915)
@@ -182,8 +182,8 @@
     missing_leave_id = train_set-&gt;getNextId();
     left_leave_id =  train_set-&gt;getNextId();
     right_leave_id =  train_set-&gt;getNextId();
-    length = train_set-&gt;getLength();
-    inputsize = train_set-&gt;getInputsize();
+    length = train_set-&gt;length();
+    inputsize = train_set-&gt;inputsize();
     missing_leave = ::PLearn::deepCopy(leave_template);
     missing_leave-&gt;setOption(&quot;id&quot;, tostring(missing_leave_id));
     if (missing_is_valid &gt; 0) missing_leave-&gt;setOption(&quot;missing_leave&quot;, &quot;0&quot;);

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-08-02 19:37:12 UTC (rev 7914)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.cc	2007-08-02 19:53:04 UTC (rev 7915)
@@ -73,15 +73,15 @@
       
     declareOption(ol, &quot;next_id&quot;, &amp;RegressionTreeRegisters::next_id, OptionBase::learntoption,
                   &quot;The next id for creating a new leave\n&quot;);
-    declareOption(ol, &quot;length&quot;, &amp;RegressionTreeRegisters::length, OptionBase::learntoption,
+    declareOption(ol, &quot;length&quot;, &amp;RegressionTreeRegisters::length_, OptionBase::learntoption,
                   &quot;The length of the train set\n&quot;);
-    declareOption(ol, &quot;width&quot;, &amp;RegressionTreeRegisters::width, OptionBase::learntoption,
+    declareOption(ol, &quot;width&quot;, &amp;RegressionTreeRegisters::width_, OptionBase::learntoption,
                   &quot;The width of the train set\n&quot;);
-    declareOption(ol, &quot;inputsize&quot;, &amp;RegressionTreeRegisters::inputsize, OptionBase::learntoption,
+    declareOption(ol, &quot;inputsize&quot;, &amp;RegressionTreeRegisters::inputsize_, OptionBase::learntoption,
                   &quot;The input size of the train set\n&quot;);
-    declareOption(ol, &quot;targetsize&quot;, &amp;RegressionTreeRegisters::targetsize, OptionBase::learntoption,
+    declareOption(ol, &quot;targetsize&quot;, &amp;RegressionTreeRegisters::targetsize_, OptionBase::learntoption,
                   &quot;The target size of the train set\n&quot;);
-    declareOption(ol, &quot;weightsize&quot;, &amp;RegressionTreeRegisters::weightsize, OptionBase::learntoption,
+    declareOption(ol, &quot;weightsize&quot;, &amp;RegressionTreeRegisters::weightsize_, OptionBase::learntoption,
                   &quot;The weight of each sample in the train set\n&quot;);
     declareOption(ol, &quot;sorted_row&quot;, &amp;RegressionTreeRegisters::sorted_row, OptionBase::learntoption,
                   &quot;The matrix holding the sequence of samples in ascending value order for each dimension\n&quot;);
@@ -97,15 +97,7 @@
 void RegressionTreeRegisters::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
-    deepCopyField(report_progress, copies);
-    deepCopyField(verbosity, copies);
     deepCopyField(train_set, copies);
-    deepCopyField(next_id, copies);
-    deepCopyField(length, copies);
-    deepCopyField(width, copies);
-    deepCopyField(inputsize, copies);
-    deepCopyField(targetsize, copies);
-    deepCopyField(weightsize, copies);
     deepCopyField(sorted_row, copies);
     deepCopyField(inverted_sorted_row, copies);
     deepCopyField(leave_register, copies);
@@ -125,13 +117,13 @@
 void RegressionTreeRegisters::initRegisters(VMat the_train_set)
 {
     train_set = the_train_set;
-    length = train_set-&gt;length();
-    width = train_set-&gt;width();
-    inputsize = train_set-&gt;inputsize();
-    targetsize = train_set-&gt;targetsize();
-    weightsize = train_set-&gt;weightsize();
-    leave_register.resize(length);
-    leave_candidate.resize(length);
+    length_ = train_set-&gt;length();
+    width_ = train_set-&gt;width();
+    inputsize_ = train_set-&gt;inputsize();
+    targetsize_ = train_set-&gt;targetsize();
+    weightsize_ = train_set-&gt;weightsize();
+    leave_register.resize(length());
+    leave_candidate.resize(length());
     sortRows();
 }
 
@@ -157,18 +149,19 @@
 
 real RegressionTreeRegisters::getTarget(int row)
 {
-    return train_set-&gt;get(row, inputsize);
+    return train_set-&gt;get(row, inputsize());
 }
 
 real RegressionTreeRegisters::getWeight(int row)
 {
-    if (weightsize &lt;= 0) return 1.0 / length;
-    else return train_set-&gt;get(row, inputsize + 1);
+    if (weightsize() &lt;= 0) return 1.0 / length();
+    else return train_set-&gt;get(row, inputsize() + targetsize() );
 }
 
-int RegressionTreeRegisters::getLength()
+void RegressionTreeRegisters::setWeight(int row, real val)
 {
-    return length;
+    PLASSERT(weightsize() &gt; 0);
+    train_set-&gt;put(row, inputsize() + targetsize(), val );
 }
 
 int RegressionTreeRegisters::getNextId()
@@ -177,19 +170,15 @@
     return next_id;
 }
 
-int RegressionTreeRegisters::getInputsize()
-{
-    return inputsize;
-}
-
 int RegressionTreeRegisters::getNextRegisteredRow(int leave_id, int col, int previous_row)
 {
-    if (previous_row &gt;= length) return length;
+    if (previous_row &gt;= length()) return length();
+    int each_train_sample_index;
     if (previous_row &lt; 0) each_train_sample_index = 0;
     else each_train_sample_index = inverted_sorted_row(previous_row, col) + 1;
     while (true)
     {
-        if (each_train_sample_index &gt;= length) return length;
+        if (each_train_sample_index &gt;= length()) return length();
         if (leave_register[sorted_row(each_train_sample_index, col)] == leave_id) break;
         each_train_sample_index += 1;
     }
@@ -198,12 +187,13 @@
 
 int RegressionTreeRegisters::getNextCandidateRow(int leave_id, int col, int previous_row)
 {
-    if (previous_row &gt;= length) return length;
+    if (previous_row &gt;= length()) return length();
+    int each_train_sample_index;
     if (previous_row &lt; 0) each_train_sample_index = 0;
     else each_train_sample_index = inverted_sorted_row(previous_row, col) + 1;
     while (true)
     {
-        if (each_train_sample_index &gt;= length) return length;
+        if (each_train_sample_index &gt;= length()) return length();
         if (leave_candidate[sorted_row(each_train_sample_index, col)] == leave_id) break;
         each_train_sample_index += 1;
     }
@@ -213,34 +203,34 @@
 void RegressionTreeRegisters::sortRows()
 {
     next_id = 0;
-    if (sorted_row.length() == length &amp;&amp; sorted_row.width() == inputsize)
+    if (sorted_row.length() == length() &amp;&amp; sorted_row.width() == inputsize())
     {
         verbose(&quot;RegressionTreeRegisters: Sorted train set indices are present, no sort required&quot;, 3);
         return;
     }
     verbose(&quot;RegressionTreeRegisters: The train set is being sorted&quot;, 3);
-    sorted_row.resize(length, inputsize);
+    sorted_row.resize(length(), inputsize());
     PP&lt;ProgressBar&gt; pb;
     if (report_progress)
     {
-        pb = new ProgressBar(&quot;RegressionTreeRegisters : sorting the train set on input dimensions: &quot;, inputsize);
+        pb = new ProgressBar(&quot;RegressionTreeRegisters : sorting the train set on input dimensions: &quot;, inputsize());
     }
-    for (each_train_sample_index = 0; each_train_sample_index &lt; length; each_train_sample_index++)
+    for (int each_train_sample_index = 0; each_train_sample_index &lt; length(); each_train_sample_index++)
     {
-        for (sample_dim = 0; sample_dim &lt; inputsize; sample_dim++)
+        for (int sample_dim = 0; sample_dim &lt; inputsize(); sample_dim++)
         {
             sorted_row(each_train_sample_index, sample_dim) = each_train_sample_index;
         }
     }
-    for (sample_dim = 0; sample_dim &lt; inputsize; sample_dim++)
+    for (int sample_dim = 0; sample_dim &lt; inputsize(); sample_dim++)
     {
         sortEachDim(sample_dim);
         if (report_progress) pb-&gt;update(sample_dim);
     }
-    inverted_sorted_row.resize(length, inputsize);
-    for (each_train_sample_index = 0; each_train_sample_index &lt; length; each_train_sample_index++)
+    inverted_sorted_row.resize(length(), inputsize());
+    for (int each_train_sample_index = 0; each_train_sample_index &lt; length(); each_train_sample_index++)
     {
-        for (sample_dim = 0; sample_dim &lt; inputsize; sample_dim++)
+        for (int sample_dim = 0; sample_dim &lt; inputsize(); sample_dim++)
         {
             inverted_sorted_row(sorted_row(each_train_sample_index, sample_dim), sample_dim) = each_train_sample_index;
         }
@@ -250,7 +240,7 @@
 void RegressionTreeRegisters::sortEachDim(int dim)
 {
     int start_index = 0;
-    int end_index = length - 1;
+    int end_index = length() - 1;
     int forward_index;
     int backward_index;
     int stack_index = -1;
@@ -284,7 +274,7 @@
                 swapIndex(start_index, start_index + 1, dim);
             forward_index = start_index + 1;
             backward_index = end_index;
-            sample_feature = train_set-&gt;get(sorted_row(start_index + 1, dim), dim);
+            real sample_feature = train_set-&gt;get(sorted_row(start_index + 1, dim), dim);
             for (;;)
             {
                 do forward_index++; while (compare(train_set-&gt;get(sorted_row(forward_index, dim), dim), sample_feature) &lt; 0.0);
@@ -317,12 +307,13 @@
   
 void RegressionTreeRegisters::sortSmallSubArray(int the_start_index, int the_end_index, int dim)
 {
-    for (next_train_sample_index = the_start_index + 1;
+    for (int next_train_sample_index = the_start_index + 1;
          next_train_sample_index &lt;= the_end_index;
          next_train_sample_index++)
     {
-        saved_index = sorted_row(next_train_sample_index, dim);
-        sample_feature = train_set-&gt;get(saved_index, dim);
+        int saved_index = sorted_row(next_train_sample_index, dim);
+        real sample_feature = train_set-&gt;get(saved_index, dim);
+        int each_train_sample_index;
         for (each_train_sample_index = next_train_sample_index - 1;
              each_train_sample_index &gt;= the_start_index;
              each_train_sample_index--)
@@ -339,7 +330,7 @@
 
 void RegressionTreeRegisters::swapIndex(int index_i, int index_j, int dim)
 {
-    saved_index = sorted_row(index_i, dim);
+    int saved_index = sorted_row(index_i, dim);
     sorted_row(index_i, dim) = sorted_row(index_j, dim);
     sorted_row(index_j, dim) = saved_index;
 }
@@ -355,9 +346,9 @@
 void RegressionTreeRegisters::printRegisters()
 {
     cout &lt;&lt; &quot;candidate: &quot;;
-    for (int ii = 0; ii &lt; length; ii++) cout &lt;&lt; &quot; &quot; &lt;&lt; tostring(leave_candidate[ii]);
+    for (int ii = 0; ii &lt; length(); ii++) cout &lt;&lt; &quot; &quot; &lt;&lt; tostring(leave_candidate[ii]);
     cout &lt;&lt; &quot; register:  &quot;;
-    for (int ii = 0; ii &lt; length; ii++) cout &lt;&lt; &quot; &quot; &lt;&lt; tostring(leave_register[ii]);
+    for (int ii = 0; ii &lt; length(); ii++) cout &lt;&lt; &quot; &quot; &lt;&lt; tostring(leave_register[ii]);
     cout &lt;&lt; endl;
 }
 
@@ -367,6 +358,30 @@
         cout &lt;&lt; the_msg &lt;&lt; endl;
 }
 
+void RegressionTreeRegisters::getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight)
+{
+    if(inputsize_&lt;0)
+        PLERROR(&quot;In VMatrix::getExample, inputsize_ not defined for this vmat&quot;);
+    input.resize(inputsize_);
+    train_set-&gt;getSubRow(i,0,input);
+    if(targetsize_&lt;0)
+        PLERROR(&quot;In VMatrix::getExample, targetsize_ not defined for this vmat&quot;);
+    target.resize(targetsize_);
+    if (targetsize_ &gt; 0) {
+        train_set-&gt;getSubRow(i,inputsize_,target);
+    }
+
+    if(weightsize()==0)
+        weight = 1;
+    else if(weightsize()&lt;0)
+        PLERROR(&quot;In VMatrix::getExample, weightsize_ not defined for this vmat&quot;);
+    else if(weightsize()&gt;1)
+        PLERROR(&quot;In VMatrix::getExample, weightsize_ &gt;1 not supported by this call&quot;);
+    else
+        weight = train_set-&gt;get(i,inputsize()+targetsize());
+}
+
+
 } // end of namespace PLearn
 
 

Modified: trunk/plearn_learners/regressors/RegressionTreeRegisters.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-08-02 19:37:12 UTC (rev 7914)
+++ trunk/plearn_learners/regressors/RegressionTreeRegisters.h	2007-08-02 19:53:04 UTC (rev 7915)
@@ -69,26 +69,16 @@
 */
 
     int       next_id;
-    int       length;
-    int       width;
-    int       inputsize;
-    int       targetsize;
-    int       weightsize;  
+    int       length_;
+    int       width_;
+    int       inputsize_;
+    int       targetsize_;
+    int       weightsize_;  
     TMat&lt;int&gt; sorted_row;
     TMat&lt;int&gt; inverted_sorted_row;
     TVec&lt;int&gt; leave_register;
     TVec&lt;int&gt; leave_candidate;
  
-/*
-  Work fields: they are sized and initialized if need be, at buid time
-*/  
- 
-    int  each_train_sample_index;
-    int  next_train_sample_index;
-    int  saved_index;
-    int  sample_dim;
-    real sample_feature;
-  
 public:
     RegressionTreeRegisters();
     virtual              ~RegressionTreeRegisters();
@@ -105,13 +95,18 @@
     real         getFeature(int row, int col);
     real         getTarget(int row);
     real         getWeight(int row);
-    int          getLength();
+    void         setWeight(int row,real val);
+    int          length(){return length_;}
     int          getNextId();
-    int          getInputsize();
+    int          inputsize(){return inputsize_;}
+    int          targetsize(){return targetsize_;}
+    int          weightsize(){return weightsize_;}
     int          getNextRegisteredRow(int leave_id, int col, int previous_row);
     int          getNextCandidateRow(int leave_id, int col, int previous_row);
     void         sortRows();
     void         printRegisters();
+    void         getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight);
+
 private:
     void         build_();
     void         sortEachDim(int dim);


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001362.html">[Plearn-commits] r7914 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="001364.html">[Plearn-commits] r7916 - trunk/plearn/io
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1360">[ date ]</a>
              <a href="thread.html#1360">[ thread ]</a>
              <a href="subject.html#1360">[ subject ]</a>
              <a href="author.html#1360">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
