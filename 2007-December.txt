From saintmlx at mail.berlios.de  Tue Dec  4 23:09:00 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:09:00 +0100
Subject: [Plearn-commits] r8329 - trunk/plearn/python
Message-ID: <200712042209.lB4M90Nc026422@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:09:00 +0100 (Tue, 04 Dec 2007)
New Revision: 8329

Modified:
   trunk/plearn/python/PythonObjectWrapper.cc
   trunk/plearn/python/PythonObjectWrapper.h
Log:
- allow wrapping of VMats in python (#ifdef PL_PYTHON_VMAT_AS_PTR)
- keep wrappedObjectsSet



Modified: trunk/plearn/python/PythonObjectWrapper.cc
===================================================================
--- trunk/plearn/python/PythonObjectWrapper.cc	2007-11-29 21:50:10 UTC (rev 8328)
+++ trunk/plearn/python/PythonObjectWrapper.cc	2007-12-04 22:09:00 UTC (rev 8329)
@@ -183,6 +183,7 @@
     return obj;
 }
 
+
 void ConvertFromPyObject<Vec>::convert(PyObject* pyobj, Vec& v,
                                        bool print_traceback)
 {
@@ -478,7 +479,7 @@
     PythonObjectWrapper::m_wrapped_objects[o]= pyo;
     //perr << "refCPPObj: " << (void*)o << " : " << (void*)pyo << endl;
 
-    Py_INCREF(pyo);
+    addToWrappedObjectsSet(pyo);//Py_INCREF(pyo);
     //printWrappedObjects();
 
     return newPyObject();//None
@@ -494,7 +495,8 @@
         ++m_gc_next_object;
         if(it->first->usage() == 1 && it->second->ob_refcnt == 1)
         {
-            Py_DECREF(it->second);
+            //Py_DECREF(it->second);
+            removeFromWrappedObjectsSet(it->second);
             gc_collect1();
         }
     }
@@ -526,9 +528,6 @@
 
 PyObject* ConvertToPyObject<Object*>::newPyObject(const Object* x)
 {
-    //perr << "in ConvertToPyObject<Object*>::newPyObject : "
-    //     << x->classname() << ' ' << (void*)x << endl;
-
     // void ptr becomes None
     if(!x) return PythonObjectWrapper::newPyObject();
 
@@ -542,12 +541,6 @@
     if(objit != PythonObjectWrapper::m_wrapped_objects.end())
     {
         PyObject* o= objit->second;
-
-//         perr << "NEW REF TO " << objit->first->classname() << ' ' << (void*)objit->first 
-//              << ' ' << objit->first->usage() << " : " 
-//              << (void*)objit->second << ' ' << objit->second->ob_refcnt << endl;
-
-//        printWrappedObjects();
         Py_INCREF(o);//new ref
         return o;//return ptr to already created pyobj
     }
@@ -585,7 +578,7 @@
 
 //    perr << "newPyObject: " << (void*)x << " : " << (void*)the_obj << endl;
 
-    Py_INCREF(the_obj);
+    addToWrappedObjectsSet(the_obj);//Py_INCREF(the_obj);
     //printWrappedObjects();
 
     return the_obj;
@@ -684,8 +677,11 @@
     if (vm.isNull())
         return ConvertToPyObject<Mat>::newPyObject(Mat());
     else
-        return ConvertToPyObject<Mat>::newPyObject(vm->toMat());
-    //return ConvertToPyObject<Object*>::newPyObject(static_cast<Object*>(vm));
+#ifdef PL_PYTHON_VMAT_AS_PTR
+        return ConvertToPyObject<Object*>::newPyObject(static_cast<Object*>(vm));
+#else
+        return ConvertToPyObject<Mat>::newPyObject(vm->toMat());// as a numpy array
+#endif
 }
 
 PyObject* ConvertToPyObject<PythonObjectWrapper>::newPyObject(const PythonObjectWrapper& pow)
@@ -795,6 +791,28 @@
     return out; // shut up compiler
 }
 
+
+PStream& operator>>(PStream& in, PyObject* v)
+{
+    PLERROR("operator>>(PStream& in, PyObject* v) not supported yet");
+    return in;
+}
+
+PStream& operator<<(PStream& out, const PyObject* v)
+{
+    PyObject* pystr= PyObject_Str(const_cast<PyObject*>(v));
+    if(!pystr)
+    {
+        if (PyErr_Occurred()) PyErr_Print();
+        PLERROR("in PythonTableVMatrix::build_ : "
+                "access to underlying table's 'weightsize' failed.");
+    }
+    out << PythonObjectWrapper(pystr).as<string>();
+    Py_DECREF(pystr);
+    return out;
+}
+
+
 //! debug
 void printWrappedObjects()
 {
@@ -820,7 +838,7 @@
             PythonObjectWrapper::wrapped_objects_t::iterator jt= it;
             ++it;
             if(jt->second->ob_refcnt == 1 && jt->first->usage() == 1)
-                Py_DECREF(jt->second);
+                removeFromWrappedObjectsSet(jt->second);
         }
     }
 }

Modified: trunk/plearn/python/PythonObjectWrapper.h
===================================================================
--- trunk/plearn/python/PythonObjectWrapper.h	2007-11-29 21:50:10 UTC (rev 8328)
+++ trunk/plearn/python/PythonObjectWrapper.h	2007-12-04 22:09:00 UTC (rev 8329)
@@ -331,7 +331,6 @@
     static Object* convert(PyObject*, bool print_traceback);
 };
 
-
 ///***///***
 // PARTIAL specialisation from T*.  Assume Object*.
 // todo: fix this assumption
@@ -1397,6 +1396,8 @@
 
 PStream& operator>>(PStream& in, PythonObjectWrapper& v);
 PStream& operator<<(PStream& out, const PythonObjectWrapper& v);
+PStream& operator>>(PStream& in, PyObject* v);
+PStream& operator<<(PStream& out, const PyObject* v);
 DECLARE_TYPE_TRAITS(PythonObjectWrapper);
 
 //! for debug purposes



From saintmlx at mail.berlios.de  Tue Dec  4 23:10:06 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:10:06 +0100
Subject: [Plearn-commits] r8330 - trunk/plearn/python
Message-ID: <200712042210.lB4MA6fZ026534@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:10:05 +0100 (Tue, 04 Dec 2007)
New Revision: 8330

Modified:
   trunk/plearn/python/PythonExtension.cc
   trunk/plearn/python/PythonExtension.h
Log:
- keep wrappedObjectsSet



Modified: trunk/plearn/python/PythonExtension.cc
===================================================================
--- trunk/plearn/python/PythonExtension.cc	2007-12-04 22:09:00 UTC (rev 8329)
+++ trunk/plearn/python/PythonExtension.cc	2007-12-04 22:10:05 UTC (rev 8330)
@@ -375,6 +375,58 @@
     }
 }
 
+void createWrappedObjectsSet(PyObject* module)
+{
+    string code= "";
+#if PL_PYTHON_VERSION <= 230
+    code+= "\nfrom sets import Set as set\n";
+#endif // PL_PYTHON_VERSION <= 230
+    code+= "\nwrapped_PLearn_instances= set()\n";
+    PyObject* res= PyRun_String(code.c_str(), Py_file_input, 
+                                PyModule_GetDict(module), PyModule_GetDict(module));
+    if(!res)
+    {
+        if(PyErr_Occurred()) PyErr_Print();
+        PLERROR("in createWrappedObjectsSet : cannot create set.");
+    }
+    Py_DECREF(res);
+ }
+
+void addToWrappedObjectsSet(PyObject* o)
+{
+    PLASSERT(the_PLearn_python_module);
+    if(-1 == PyObject_SetAttrString(the_PLearn_python_module, "_tmp_wrapped_instance", o))
+        PLERROR("in addToWrappedObjectsSet : cannot add wrapped object to module.");
+    PyObject* res= PyRun_String("\nwrapped_PLearn_instances.add(_tmp_wrapped_instance)"
+                                "\ndel _tmp_wrapped_instance\n", 
+                                Py_file_input, 
+                                PyModule_GetDict(the_PLearn_python_module), 
+                                PyModule_GetDict(the_PLearn_python_module));
+    if(!res)
+    {
+        if(PyErr_Occurred()) PyErr_Print();
+        PLERROR("in addToWrappedObjectsSet : cannot add wrapped object to set.");
+    }
+    Py_DECREF(res);
+}
+void removeFromWrappedObjectsSet(PyObject* o)
+{
+    PLASSERT(the_PLearn_python_module);
+    if(-1 == PyObject_SetAttrString(the_PLearn_python_module, "_tmp_wrapped_instance", o))
+        PLERROR("in addToWrappedObjectsSet : cannot add wrapped object to module.");
+    PyObject* res= PyRun_String("\nwrapped_PLearn_instances.remove(_tmp_wrapped_instance)"
+                                "\ndel _tmp_wrapped_instance\n", 
+                                Py_file_input, 
+                                PyModule_GetDict(the_PLearn_python_module), 
+                                PyModule_GetDict(the_PLearn_python_module));
+    if(!res)
+    {
+        if(PyErr_Occurred()) PyErr_Print();
+        PLERROR("in addToWrappedObjectsSet : cannot add wrapped object to set.");
+    }
+    Py_DECREF(res);
+}
+
 // Init func for python module.
 // init module, then inject global funcs
 void initPythonExtensionModule(char* module_name)
@@ -388,7 +440,9 @@
 {
     injectPLearnGlobalFunctions(module);
     injectPLearnClasses(module);
+    createWrappedObjectsSet(module);
     the_PLearn_python_module= module;
+    
 }
 
 PyObject* the_PLearn_python_module= 0;

Modified: trunk/plearn/python/PythonExtension.h
===================================================================
--- trunk/plearn/python/PythonExtension.h	2007-12-04 22:09:00 UTC (rev 8329)
+++ trunk/plearn/python/PythonExtension.h	2007-12-04 22:10:05 UTC (rev 8330)
@@ -53,6 +53,11 @@
 // inject funcs. and classes, set global module.
 void setPythonModuleAndInject(PyObject* module);
 
+// manage wrapped objects set
+void addToWrappedObjectsSet(PyObject* o);
+void removeFromWrappedObjectsSet(PyObject* o);
+
+
 extern PyObject* the_PLearn_python_module;
 
 } // end of namespace PLearn



From saintmlx at mail.berlios.de  Tue Dec  4 23:11:59 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:11:59 +0100
Subject: [Plearn-commits] r8331 - trunk/plearn_learners/generic
Message-ID: <200712042211.lB4MBxBR026623@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:11:59 +0100 (Tue, 04 Dec 2007)
New Revision: 8331

Modified:
   trunk/plearn_learners/generic/NNet.cc
Log:
- allow saving train costs at each epoch



Modified: trunk/plearn_learners/generic/NNet.cc
===================================================================
--- trunk/plearn_learners/generic/NNet.cc	2007-12-04 22:10:05 UTC (rev 8330)
+++ trunk/plearn_learners/generic/NNet.cc	2007-12-04 22:11:59 UTC (rev 8331)
@@ -77,6 +77,7 @@
 #include "NNet.h"
 // #include <plearn/math/random.h>
 #include <plearn/vmat/SubVMatrix.h>
+#include <plearn/vmat/FileVMatrix.h>
 
 namespace PLearn {
 using namespace std;
@@ -1059,6 +1060,22 @@
     if(report_progress)
         pb = new ProgressBar("Training " + classname() + " from stage " + tostring(stage) + " to " + tostring(nstages), nstages-stage);
 
+
+    //Open/create vmat to save train costs at each epoch
+    VMat costs_per_epoch= 0;
+    if(expdir != "")
+    {
+        PPath cpe_path= expdir / "NNet_train_costs.pmat";
+        if(isfile(cpe_path))
+            costs_per_epoch= new FileVMatrix(cpe_path, true);
+        else
+        {
+            TVec<string> fieldnames(1, "epoch");
+            fieldnames.append(train_stats->getFieldNames());
+            costs_per_epoch= new FileVMatrix(cpe_path, 0, fieldnames);
+        }
+    }
+
     int initial_stage = stage;
     bool early_stop=false;
     while(stage<nstages && !early_stop)
@@ -1071,6 +1088,12 @@
         train_stats->finalize();
         if(verbosity>2)
             pout << "Epoch " << stage << " train objective: " << train_stats->getMean() << endl;
+        if(costs_per_epoch)
+        {
+            Vec v(1, stage);
+            v.append(train_stats->getMean());
+            costs_per_epoch->appendRow(v);
+        }
         ++stage;
         if(pb)
             pb->update(stage-initial_stage);



From saintmlx at mail.berlios.de  Tue Dec  4 23:13:15 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:13:15 +0100
Subject: [Plearn-commits] r8332 - trunk/plearn/math
Message-ID: <200712042213.lB4MDFqt026715@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:13:14 +0100 (Tue, 04 Dec 2007)
New Revision: 8332

Modified:
   trunk/plearn/math/ObservationWindow.cc
Log:
- don't realloc. for each append



Modified: trunk/plearn/math/ObservationWindow.cc
===================================================================
--- trunk/plearn/math/ObservationWindow.cc	2007-12-04 22:11:59 UTC (rev 8331)
+++ trunk/plearn/math/ObservationWindow.cc	2007-12-04 22:13:14 UTC (rev 8332)
@@ -164,8 +164,10 @@
     
     ++m_nobs;
     if(unlimited_size) m_window= m_nobs;
-    m_observations.resize(MIN(m_nobs,m_window), obs.size());
-    m_obs_weights.resize(MIN(m_nobs,m_window));
+    int new_size= MIN(m_nobs,m_window);
+    int extra= unlimited_size? new_size : 0;//extra rows to alloc. when resizing
+    m_observations.resize(new_size, obs.size(), extra*obs.size());
+    m_obs_weights.resize(new_size, extra);
     if (m_nobs > m_window)
     {
         outdated.resize(obs.size());



From saintmlx at mail.berlios.de  Tue Dec  4 23:17:32 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:17:32 +0100
Subject: [Plearn-commits] r8333 - trunk/plearn/vmat
Message-ID: <200712042217.lB4MHW9Z027088@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:17:32 +0100 (Tue, 04 Dec 2007)
New Revision: 8333

Modified:
   trunk/plearn/vmat/Splitter.cc
   trunk/plearn/vmat/VMatrix.cc
Log:
- remote declare methods



Modified: trunk/plearn/vmat/Splitter.cc
===================================================================
--- trunk/plearn/vmat/Splitter.cc	2007-12-04 22:13:14 UTC (rev 8332)
+++ trunk/plearn/vmat/Splitter.cc	2007-12-04 22:17:32 UTC (rev 8333)
@@ -77,6 +77,10 @@
     rmm.inherited(inherited::_getRemoteMethodMap_());
 
     declareMethod(
+        rmm, "setDataSet", &Splitter::setDataSet,
+        (BodyDoc("Set this splitter's dataset\n"),
+         ArgDoc ("the_dataset","The dataset to split")));
+    declareMethod(
         rmm, "nSetsPerSplit", &Splitter::nSetsPerSplit,
         (BodyDoc("Returns the number of sets per split\n"),
          RetDoc ("the numer of sets per split")));
@@ -84,6 +88,11 @@
         rmm, "nsplits", &Splitter::nsplits,
         (BodyDoc(" Returns the number of available different 'splits'\n"),
          RetDoc (" the numer of available splits")));
+    declareMethod(
+        rmm, "getSplit", &Splitter::getSplit,
+        (BodyDoc("Get one of the splits\n"),
+         ArgDoc ("i","The split to get"),
+         RetDoc ("The ith split (vec. of N sets)")));
 
 
 ///TODO export    virtual TVec<VMat> getSplit(int i=0) = 0;

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-12-04 22:13:14 UTC (rev 8332)
+++ trunk/plearn/vmat/VMatrix.cc	2007-12-04 22:17:32 UTC (rev 8333)
@@ -239,6 +239,14 @@
         (BodyDoc("Returns the unconditonal statistics for all fields\n"),
          RetDoc ("Stats vector")));
 
+    declareMethod(
+        rmm, "defineSizes", &VMatrix::defineSizes,
+        (BodyDoc("Define this vmatrix's sizes\n"),
+         ArgDoc ("inputsize", "inputsize"),
+         ArgDoc ("targetsize", "targetsize"),
+         ArgDoc ("weightsize", "weightsize"),
+         ArgDoc ("extrasize", "extrasize")));
+
 }
 
 



From saintmlx at mail.berlios.de  Tue Dec  4 23:18:24 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:18:24 +0100
Subject: [Plearn-commits] r8334 - trunk/plearn/io
Message-ID: <200712042218.lB4MIOVO027170@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:18:24 +0100 (Tue, 04 Dec 2007)
New Revision: 8334

Modified:
   trunk/plearn/io/BufferedIntVecFile.cc
Log:
- more efficient 'flush'



Modified: trunk/plearn/io/BufferedIntVecFile.cc
===================================================================
--- trunk/plearn/io/BufferedIntVecFile.cc	2007-12-04 22:17:32 UTC (rev 8333)
+++ trunk/plearn/io/BufferedIntVecFile.cc	2007-12-04 22:18:24 UTC (rev 8334)
@@ -97,9 +97,29 @@
 
 void BufferedIntVecFile::flush()
 {
+/*
     if(bufmod)
         for(int i= 0; i < buflen && i+bufstart < length(); ++i)
             inherited::put(i+bufstart, buf[i]);
+*/
+
+    if(bufmod)
+    {
+        int len= min(buflen, length()-bufstart);
+        seek_to_index(bufstart);
+        if (byte_order() != endianness_) 
+        {
+            TVec<int> new_vec(len);
+            new_vec.copyFrom(buf, len);
+            endianswap(new_vec.data(), new_vec.length());
+            fwrite(new_vec.data(), sizeof(int), new_vec.length(), f);
+        }
+        else 
+        {
+            fwrite(buf, sizeof(int), len, f);
+        }
+    }
+
     bufmod= false;
 }
 



From saintmlx at mail.berlios.de  Tue Dec  4 23:20:27 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:20:27 +0100
Subject: [Plearn-commits] r8335 - trunk/python_modules/plearn/pybridge
Message-ID: <200712042220.lB4MKRX8027451@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:20:27 +0100 (Tue, 04 Dec 2007)
New Revision: 8335

Modified:
   trunk/python_modules/plearn/pybridge/wrapped_plearn_object.py
Log:
- added __getstate__ and __setstate__ for pickling



Modified: trunk/python_modules/plearn/pybridge/wrapped_plearn_object.py
===================================================================
--- trunk/python_modules/plearn/pybridge/wrapped_plearn_object.py	2007-12-04 22:18:24 UTC (rev 8334)
+++ trunk/python_modules/plearn/pybridge/wrapped_plearn_object.py	2007-12-04 22:20:27 UTC (rev 8335)
@@ -31,6 +31,9 @@
 #  This file is part of the PLearn library. For more information on the PLearn
 #  library, go to the PLearn Web site at www.plearn.org
 
+global plearn_module
+plearn_module= None
+
 class WrappedPLearnObject(object):
 
     def __init__(self, **kwargs):
@@ -91,7 +94,21 @@
                     copy.deepcopy(self.__dict__[k], memo)
         return newone
 
+    def __getstate__(self):
+        d= self.__dict__.copy()
+        d['_cptr']= self.asString()
+        return d
+    
+    def __setstate__(self, dict):
+        newone= plearn_module.newObject(dict['_cptr'])
+        self._cptr= newone._cptr
+        self._refCPPObj(self, False)
+        for k in dict:
+            if k != '_cptr':
+                self.__setattr__(k, dict[k])
+        return dict
 
+
 from numpy.numarray import *
 
 class WrappedPLearnVMat(WrappedPLearnObject):



From saintmlx at mail.berlios.de  Tue Dec  4 23:21:23 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:21:23 +0100
Subject: [Plearn-commits] r8336 - trunk/plearn_learners/generic
Message-ID: <200712042221.lB4MLNxr027539@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:21:23 +0100 (Tue, 04 Dec 2007)
New Revision: 8336

Modified:
   trunk/plearn_learners/generic/PLearner.cc
   trunk/plearn_learners/generic/PLearner.h
Log:
- remote declare methods



Modified: trunk/plearn_learners/generic/PLearner.cc
===================================================================
--- trunk/plearn_learners/generic/PLearner.cc	2007-12-04 22:20:27 UTC (rev 8335)
+++ trunk/plearn_learners/generic/PLearner.cc	2007-12-04 22:21:23 UTC (rev 8336)
@@ -343,7 +343,17 @@
 
 
     declareMethod(
-        rmm, "test", &PLearner::rtest,
+        rmm, "sub_test", &PLearner::sub_test,
+        (BodyDoc("Test on a given (chunk of a) testset and return stats, outputs and costs.  "
+                 "Used by parallel test"),
+         ArgDoc("testset","test set"),
+         ArgDoc("test_stats","VecStatsCollector to use"),
+         ArgDoc("rtestoutputs","wether to return outputs"),
+         ArgDoc("rtestcosts","wether to return costs"),
+         RetDoc ("tuple of (stats, outputs, costs)")));
+
+    declareMethod(
+        rmm, "test", &PLearner::remote_test,
         (BodyDoc("Test on a given testset and return stats, outputs and costs."),
          ArgDoc("testset","test set"),
          ArgDoc("test_stats","VecStatsCollector to use"),
@@ -387,6 +397,12 @@
          RetDoc ("Matrix holding the computed outputs")));
 
     declareMethod(
+        rmm, "useOnTrain", &PLearner::remote_useOnTrain,
+        (BodyDoc("Compute the output of a trained learner on every row of \n"
+                 "the trainset.  The outputs are returned as a matrix.\n"),
+         RetDoc ("Matrix holding the computed outputs")));
+
+    declareMethod(
         rmm, "computeInputOutputMat", &PLearner::computeInputOutputMat,
         (BodyDoc("Returns a matrix which is a (horizontal) concatenation\n"
                  "and the computed outputs.\n"),
@@ -869,6 +885,13 @@
     use(train_set, train_output);
 }
 
+Mat PLearner::remote_useOnTrain() const 
+{
+    Mat outputs;
+    useOnTrain(outputs);
+    return outputs;
+}
+
 //////////
 // test //
 //////////
@@ -960,7 +983,7 @@
                         s->link(tsid, testset);
                     }
                     curpos+= clen;
-                    s->callMethod(id, "test", sts, template_vsc, 
+                    s->callMethod(id, "sub_test", sts, template_vsc, 
                                   static_cast<bool>(testoutputs), static_cast<bool>(testcosts));
                     chunknums[s]= chunks_called;
                     ++chunks_called;
@@ -994,7 +1017,7 @@
                     if(master_sends_testset_rows)
                         sts= new MemoryVMatrix(sts.toMat());
                     curpos+= clen;
-                    s->callMethod(learners_ids[s], "test", sts, template_vsc, 
+                    s->callMethod(learners_ids[s], "sub_test", sts, template_vsc, 
                                   static_cast<bool>(testoutputs), static_cast<bool>(testcosts));
                     chunknums[s]= chunks_called;
                     ++chunks_called;
@@ -1126,10 +1149,10 @@
 }
 
 
-////////////////////////////////////////////////////////////////
-// test ('remote' version which returns a tuple w/ results.) //
-//////////////////////////////////////////////////////////////
-tuple<PP<VecStatsCollector>, VMat, VMat> PLearner::rtest(VMat testset, PP<VecStatsCollector> test_stats, bool rtestoutputs, bool rtestcosts) const
+//////////////////////////////////////////////////////////////////////////////////////////
+// sub-test, used by parallel test ('remote' version which returns a tuple w/ results.) //
+//////////////////////////////////////////////////////////////////////////////////////////
+tuple<PP<VecStatsCollector>, VMat, VMat> PLearner::sub_test(VMat testset, PP<VecStatsCollector> test_stats, bool rtestoutputs, bool rtestcosts) const
 {
     VMat testoutputs= 0;
     VMat testcosts= 0;
@@ -1149,6 +1172,21 @@
 }
 
 
+//////////////////////////////////////////////////////////////////////////////////////////
+// remote interface for test                                                            //
+//////////////////////////////////////////////////////////////////////////////////////////
+tuple<PP<VecStatsCollector>, VMat, VMat> PLearner::remote_test(VMat testset, PP<VecStatsCollector> test_stats, bool rtestoutputs, bool rtestcosts) const
+{
+    VMat testoutputs= 0;
+    VMat testcosts= 0;
+    int outsize= outputsize();
+    int costsize= nTestCosts();
+    int len= testset.length();
+    if(rtestoutputs) testoutputs= new MemoryVMatrix(len, outsize);
+    if(rtestcosts) testcosts= new MemoryVMatrix(len, costsize);
+    test(testset, test_stats, testoutputs, testcosts);
+    return make_tuple(test_stats, testoutputs, testcosts);
+}
 
 ///////////////
 // initTrain //

Modified: trunk/plearn_learners/generic/PLearner.h
===================================================================
--- trunk/plearn_learners/generic/PLearner.h	2007-12-04 22:20:27 UTC (rev 8335)
+++ trunk/plearn_learners/generic/PLearner.h	2007-12-04 22:21:23 UTC (rev 8336)
@@ -559,6 +559,11 @@
     virtual void useOnTrain(Mat& outputs) const;
 
     /**
+     * 'remote' version of useOnTrain
+     */
+    virtual Mat remote_useOnTrain() const;
+
+    /**
      *  Performs test on testset, updating test cost statistics, and optionally
      *  filling testoutputs and testcosts.  The default version repeatedly
      *  calls computeOutputAndCosts or computeCostsOnly.  Note that neither
@@ -570,12 +575,20 @@
                       VMat testoutputs=0, VMat testcosts=0) const;
 
     /**
-     *  "remote" test:
+     *  sub-test:
+     *  Called by parallel test on chunks of the testset.
      *  Performs test on testset, returns stats and optionally testoutputs and testcosts
      */
-    virtual tuple<PP<VecStatsCollector>, VMat, VMat> rtest(VMat testset, PP<VecStatsCollector> test_stats,
+    virtual tuple<PP<VecStatsCollector>, VMat, VMat> sub_test(VMat testset, PP<VecStatsCollector> test_stats,
                                                       bool rtestoutputs, bool rtestcosts) const;
     
+    /**
+     * 'remote' interface for test
+     */
+    virtual tuple<PP<VecStatsCollector>, VMat, VMat> remote_test(VMat testset, PP<VecStatsCollector> test_stats,
+                                                      bool rtestoutputs, bool rtestcosts) const;
+    
+    
 
     /**
      * Process a full dataset (possibly containing input,target,weight,extra



From saintmlx at mail.berlios.de  Tue Dec  4 23:24:41 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 4 Dec 2007 23:24:41 +0100
Subject: [Plearn-commits] r8337 - in trunk: . plearn/base plearn/var
	plearn/vmat python_modules/plearn/pyplearn
	python_modules/plearn/utilities
Message-ID: <200712042224.lB4MOfA2027716@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-04 23:24:41 +0100 (Tue, 04 Dec 2007)
New Revision: 8337

Modified:
   trunk/plearn/base/plerror.cc
   trunk/plearn/var/ColumnIndexVariable.h
   trunk/plearn/vmat/SelectRowsFileIndexVMatrix.cc
   trunk/pymake.config.model
   trunk/python_modules/plearn/pyplearn/plargs.py
   trunk/python_modules/plearn/utilities/options_dialog.py
Log:
- minor changes (err. msgs, comments, etc.)



Modified: trunk/plearn/base/plerror.cc
===================================================================
--- trunk/plearn/base/plerror.cc	2007-12-04 22:21:23 UTC (rev 8336)
+++ trunk/plearn/base/plerror.cc	2007-12-04 22:24:41 UTC (rev 8337)
@@ -55,7 +55,7 @@
 
 ostream* error_stream = &cerr;
 
-#define ERROR_MSG_SIZE 1024
+#define ERROR_MSG_SIZE 4096
 #ifndef USER_SUPPLIED_ERROR
 void errormsg2(const char* filename,const int linenumber,const char* msg, ...){
     va_list args;

Modified: trunk/plearn/var/ColumnIndexVariable.h
===================================================================
--- trunk/plearn/var/ColumnIndexVariable.h	2007-12-04 22:21:23 UTC (rev 8336)
+++ trunk/plearn/var/ColumnIndexVariable.h	2007-12-04 22:24:41 UTC (rev 8337)
@@ -77,7 +77,7 @@
 inline Var matrixIndex(Var mat, Var index)
 {
     if(index->size()!=mat->width())
-        PLERROR("matrixIndex: index->size() should be equal to mat->width()");
+        PLERROR("matrixIndex: index->size() should be equal to mat->width() (%d!=%d x %d)",index->size(),mat->width(),mat->length());
     return new ColumnIndexVariable(mat,index);  
 }
 

Modified: trunk/plearn/vmat/SelectRowsFileIndexVMatrix.cc
===================================================================
--- trunk/plearn/vmat/SelectRowsFileIndexVMatrix.cc	2007-12-04 22:21:23 UTC (rev 8336)
+++ trunk/plearn/vmat/SelectRowsFileIndexVMatrix.cc	2007-12-04 22:24:41 UTC (rev 8337)
@@ -74,6 +74,7 @@
             indices.open(index_file);
             length_ = indices.length();
         }
+        width_= distr->width();
         defineSizes(distr->inputsize(), distr->targetsize(), distr->weightsize());
     }
 }

Modified: trunk/pymake.config.model
===================================================================
--- trunk/pymake.config.model	2007-12-04 22:21:23 UTC (rev 8336)
+++ trunk/pymake.config.model	2007-12-04 22:24:41 UTC (rev 8337)
@@ -266,7 +266,7 @@
   
   [ 'blas', 'noblas' ],
   [ 'defblas', 'nolibblas', 'p3blas','p4blas','athlonblas','pentiumblas',
-    'mammouthblas', 'veclib', 'scs', 'goto', 'lisa' ],
+    'mammouthblas', 'apintelblas', 'veclib', 'scs', 'goto', 'lisa' ],
   
   [ 'logging=dbg', 'logging=mand', 'logging=imp', 'logging=normal',
     'logging=extreme', 'logging=dbg-profile' ],
@@ -345,7 +345,7 @@
             python_version = '2.5'
         else:
             python_version = pyver
-
+            
         python_lib_root = '/usr/lib'
         numpy_site_packages = '-L/usr/lib/python'+python_version+'/site-packages/numarray'
         python_includedirs   = [ '/usr/include/python'+python_version]
@@ -789,6 +789,10 @@
               description = 'linking BLAS for P4 Mammouth-Serie cluster',
               linkeroptions = '-L/opt/mkl/lib/32 -lmkl_p4 -lmkl_vml_p4 -lpthread -lmkl_lapack' )
 
+pymakeLinkOption( name = 'apintelblas',
+              description = 'Intel BLAS+LAPACK for generic install in /usr/local/lib (incl. ApSTAT)',
+              linkeroptions = '-L/home/chrish/mkl/install/lib/32 -lmkl_lapack -lmkl -lguide -lpthread' )
+
 pymakeLinkOption( name = 'veclib',
               description = "Apple's vecLib library, a version of the BLAS library for the G4 and G5 under OS X",
               linkeroptions = '-framework vecLib' )

Modified: trunk/python_modules/plearn/pyplearn/plargs.py
===================================================================
--- trunk/python_modules/plearn/pyplearn/plargs.py	2007-12-04 22:21:23 UTC (rev 8336)
+++ trunk/python_modules/plearn/pyplearn/plargs.py	2007-12-04 22:24:41 UTC (rev 8337)
@@ -430,6 +430,9 @@
     def getType(self):
         return self._type
 
+    def getDoc(self):
+        return self._doc
+
     def getGui(self):
         return self._gui
 
@@ -456,6 +459,9 @@
     def setDefault(self, default):
         self.__default_value = default
 
+    def setDoc(self, doc):
+        self._doc= doc
+
     #######  Static methods  ######################################################
 
     def addCmdLineOverride(holder_name, optname, value):
@@ -595,9 +601,26 @@
     iterator = staticmethod(iterator)
 
     def optdict(holder):
+        """
+        returns a dict of {plopt_name: plopt_value} for all options in holder
+        """
         return dict([ (opt.getName(), opt.get()) for opt in plopt.iterator(holder) ])
     optdict = staticmethod(optdict)
 
+    def optdict2(holder):
+        """
+        returns a dict of {plopt_name, plopt} for all options in holder
+        """
+        return dict([ (opt.getName(), opt) for opt in plopt.iterator(holder) ])
+    optdict2 = staticmethod(optdict2)
+
+    def copyOptionFrom(holder, option):
+        """
+        returns a [deep] copy of holder's option 'option'
+        """
+        return copy.deepcopy(plopt.optdict2(holder)[option])
+    copyOptionFrom= staticmethod(copyOptionFrom)
+
     def override(holder, option, value):
         """Typical pattern to override the value of an existing plopt instance."""
         plopt_instance = type.__getattribute__(holder, option)

Modified: trunk/python_modules/plearn/utilities/options_dialog.py
===================================================================
--- trunk/python_modules/plearn/utilities/options_dialog.py	2007-12-04 22:21:23 UTC (rev 8336)
+++ trunk/python_modules/plearn/utilities/options_dialog.py	2007-12-04 22:24:41 UTC (rev 8337)
@@ -85,7 +85,8 @@
     return verb, logs, namespaces, pos>=0
 
 def gladeFile():
-    import plearn.plide.plide
+    #import plearn.plide.plide
+    import plearn
     return os.path.join(os.path.dirname(plearn.utilities.options_dialog.__file__),
                         "resources", "options_dialog.glade")
 



From saintmlx at mail.berlios.de  Wed Dec  5 17:27:19 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Wed, 5 Dec 2007 17:27:19 +0100
Subject: [Plearn-commits] r8338 - trunk/plearn/vmat
Message-ID: <200712051627.lB5GRJXK015060@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-05 17:27:19 +0100 (Wed, 05 Dec 2007)
New Revision: 8338

Added:
   trunk/plearn/vmat/PythonTableVMatrix.cc
   trunk/plearn/vmat/PythonTableVMatrix.h
Log:
- VMatrix that wraps an underlying python table.



Added: trunk/plearn/vmat/PythonTableVMatrix.cc
===================================================================
--- trunk/plearn/vmat/PythonTableVMatrix.cc	2007-12-04 22:24:41 UTC (rev 8337)
+++ trunk/plearn/vmat/PythonTableVMatrix.cc	2007-12-05 16:27:19 UTC (rev 8338)
@@ -0,0 +1,178 @@
+// -*- C++ -*-
+
+// PythonTableVMatrix.cc
+//
+// Copyright (C) 2007 Xavier Saint-Mleux, ApSTAT Technologies inc.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Xavier Saint-Mleux
+
+/*! \file PythonTableVMatrix.cc */
+
+
+#include "PythonTableVMatrix.h"
+
+namespace PLearn {
+using namespace std;
+
+
+PLEARN_IMPLEMENT_OBJECT(
+    PythonTableVMatrix,
+    "VMatrix wrapper for a python table (module apstat.data.table)",
+    "VMatrix wrapper for a python table (module apstat.data.table).\n"
+    "The underlying table must be numeric.\n"
+    );
+
+PythonTableVMatrix::PythonTableVMatrix(PyObject* table)
+    :the_table(table)
+{
+}
+
+void PythonTableVMatrix::getNewRow(int i, const Vec& v) const
+{
+    PLASSERT(the_table);
+    PyObject* row= PyObject_CallMethod(the_table, "getRow", "i", i);
+    if(!row)
+    {
+        if (PyErr_Occurred()) PyErr_Print();
+        PLERROR("in PythonTableVMatrix::getNewRow : "
+                "call to underlying table's 'getRow' failed.");
+    }
+    v << PythonObjectWrapper(row).as<Vec>();
+    Py_DECREF(row);
+}
+
+void PythonTableVMatrix::declareOptions(OptionList& ol)
+{
+
+    declareOption(ol, "table", &PythonTableVMatrix::the_table,
+                  OptionBase::buildoption,
+                  "underlying table");
+
+    inherited::declareOptions(ol);
+}
+
+void PythonTableVMatrix::build_()
+{
+    if(!the_table) return;
+    PyObject* pywidth= PyObject_CallMethod(the_table, "width", 0);
+    if(!pywidth)
+    {
+        if (PyErr_Occurred()) PyErr_Print();
+        PLERROR("in PythonTableVMatrix::build_ : "
+                "call to underlying table's 'width' failed.");
+    }
+    width_= PythonObjectWrapper(pywidth);
+    Py_DECREF(pywidth);
+    PyObject* pylength= PyObject_CallMethod(the_table, "length", 0);
+    if(!pylength)
+    {
+        if (PyErr_Occurred()) PyErr_Print();
+        PLERROR("in PythonTableVMatrix::build_ : "
+                "call to underlying table's 'length' failed.");
+    }
+    length_= PythonObjectWrapper(pylength);
+    Py_DECREF(pylength);
+    PyObject* pyfieldnames= PyObject_GetAttrString(the_table, "fieldnames");
+    if(!pyfieldnames)
+    {
+        if (PyErr_Occurred()) PyErr_Print();
+        PLERROR("in PythonTableVMatrix::build_ : "
+                "access to underlying table's 'fieldnames' failed.");
+    }
+    declareFieldNames(PythonObjectWrapper(pyfieldnames));
+    Py_DECREF(pyfieldnames);
+
+    if(PyObject_HasAttrString(the_table, "inputsize"))
+    {
+        PyObject* inpsz= PyObject_GetAttrString(the_table, "inputsize");
+        if(!inpsz)
+        {
+            if (PyErr_Occurred()) PyErr_Print();
+            PLERROR("in PythonTableVMatrix::build_ : "
+                    "access to underlying table's 'inputsize' failed.");
+        }
+        inputsize_= PythonObjectWrapper(inpsz).as<int>();
+    }
+    if(PyObject_HasAttrString(the_table, "targetsize"))
+    {
+        PyObject* targsz= PyObject_GetAttrString(the_table, "targetsize");
+        if(!targsz)
+        {
+            if (PyErr_Occurred()) PyErr_Print();
+            PLERROR("in PythonTableVMatrix::build_ : "
+                    "access to underlying table's 'targetsize' failed.");
+        }
+        targetsize_= PythonObjectWrapper(targsz).as<int>();
+    }
+    if(PyObject_HasAttrString(the_table, "weightsize"))
+    {
+        PyObject* wgtsz= PyObject_GetAttrString(the_table, "weightsize");
+        if(!wgtsz)
+        {
+            if (PyErr_Occurred()) PyErr_Print();
+            PLERROR("in PythonTableVMatrix::build_ : "
+                    "access to underlying table's 'weightsize' failed.");
+        }
+        weightsize_= PythonObjectWrapper(wgtsz).as<int>();
+    }
+
+
+}
+
+void PythonTableVMatrix::build()
+{
+    inherited::build();
+    build_();
+}
+
+void PythonTableVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // deepCopyField(trainvec, copies);
+
+    PLERROR("PythonTableVMatrix::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!");
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/vmat/PythonTableVMatrix.h
===================================================================
--- trunk/plearn/vmat/PythonTableVMatrix.h	2007-12-04 22:24:41 UTC (rev 8337)
+++ trunk/plearn/vmat/PythonTableVMatrix.h	2007-12-05 16:27:19 UTC (rev 8338)
@@ -0,0 +1,108 @@
+// -*- C++ -*-
+
+// PythonTableVMatrix.h
+//
+// Copyright (C) 2007 Xavier Saint-Mleux, ApSTAT Technologies inc.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Xavier Saint-Mleux
+
+/*! \file PythonTableVMatrix.h */
+
+
+#ifndef PythonTableVMatrix_INC
+#define PythonTableVMatrix_INC
+
+#include <plearn/vmat/RowBufferedVMatrix.h>
+
+namespace PLearn {
+
+class PythonTableVMatrix : public RowBufferedVMatrix
+{
+    typedef RowBufferedVMatrix inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    PyObject* the_table;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    PythonTableVMatrix(PyObject* table= 0);
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    PLEARN_DECLARE_OBJECT(PythonTableVMatrix);
+
+    virtual void build();
+
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    static void declareOptions(OptionList& ol);
+
+    //! Fill the vector 'v' with the content of the i-th row.
+    //! 'v' is assumed to be the right size.
+    virtual void getNewRow(int i, const Vec& v) const;
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+};
+
+DECLARE_OBJECT_PTR(PythonTableVMatrix);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From saintmlx at mail.berlios.de  Fri Dec  7 22:08:14 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Fri, 7 Dec 2007 22:08:14 +0100
Subject: [Plearn-commits] r8339 - trunk/plearn/ker
Message-ID: <200712072108.lB7L8EVK004850@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-07 22:08:14 +0100 (Fri, 07 Dec 2007)
New Revision: 8339

Added:
   trunk/plearn/ker/DTWKernel.cc
   trunk/plearn/ker/DTWKernel.h
Log:
- new kernel for Dynamic Time Warping (DTW)



Added: trunk/plearn/ker/DTWKernel.cc
===================================================================
--- trunk/plearn/ker/DTWKernel.cc	2007-12-05 16:27:19 UTC (rev 8338)
+++ trunk/plearn/ker/DTWKernel.cc	2007-12-07 21:08:14 UTC (rev 8339)
@@ -0,0 +1,256 @@
+// -*- C++ -*-
+
+// DTWKernel.cc
+//
+// Copyright (C) 2007 Xavier Saint-Mleux, ApSTAT Technologies inc.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Xavier Saint-Mleux
+
+/*! \file DTWKernel.cc */
+
+
+#include "DTWKernel.h"
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    DTWKernel,
+    "Kernel for Dynamic Time Warping",
+    "Kernel for Dynamic Time Warping\n"
+    "(see sect.4.7 of Rabiner, L. and Juang, B. 1993 'Fundamentals of Speech Recognition'. Prentice-Hall, Inc.)\n"
+    "TODO: Add global path constraints and other goodies...\n"
+    );
+
+//////////////////
+// DTWKernel //
+//////////////////
+DTWKernel::DTWKernel()
+    :subvec_length(-1), local_paths(), distance_type("euclidean")
+{
+    /*
+     * default local paths: 
+     * (0,1) or (1,0) cost 1.
+     * (1,1) costs 2.
+     */
+    local_paths.push_back(TVec<LocalStep>(1,make_pair(make_pair(0,1),1.)));
+    local_paths.push_back(TVec<LocalStep>(1,make_pair(make_pair(1,0),1.)));
+    local_paths.push_back(TVec<LocalStep>(1,make_pair(make_pair(1,1),2.)));
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void DTWKernel::declareOptions(OptionList& ol)
+{
+    declareOption(ol, "subvec_length", &DTWKernel::subvec_length,
+                  OptionBase::buildoption,
+                  "length of each sub-vec within an example");
+
+    declareOption(ol, "local_paths", &DTWKernel::local_paths,
+                  OptionBase::buildoption,
+                  "Specifies local path constraints.");
+
+    declareOption(ol, "distance_type", &DTWKernel::distance_type,
+                  OptionBase::buildoption,
+                  "Name of the 'distance' function to use "
+                  "when comparing features (sub-vecs).");
+
+    inherited::declareOptions(ol);
+}
+
+void DTWKernel::declareMethods(RemoteMethodMap& rmm)
+{
+    rmm.inherited(inherited::_getRemoteMethodMap_());
+
+    declareMethod(
+        rmm, "dtw", &DTWKernel::remote_dtw,
+        (BodyDoc("Calc. DTW on two feature vectors\n"),
+         ArgDoc("x1","first vector"),
+         ArgDoc("x2","second vector"),
+         RetDoc ("dpoint, dpath, bptrs")));
+}
+
+
+
+///////////
+// build //
+///////////
+void DTWKernel::build()
+{
+    // ### Nothing to add here, simply calls build_
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void DTWKernel::build_()
+{
+    if(subvec_length <= 0)
+        PLERROR("In DTWKernel::build_() : "
+                "subvec_length must be specified before build "
+                "(%d is not a valid value).", subvec_length);
+
+    if(distance_type == "euclidean")
+        dist_fn= powdistance;
+    else
+        PLERROR("In DTWKernel::build_() : "
+                "only 'euclidean' distance_type is supported for now "
+                "('%s' is not a valid value).", distance_type.c_str());
+}
+
+//////////////
+//   dtw    //
+//////////////
+void DTWKernel::dtw(const Vec& x1, const Vec& x2) const
+{
+    PLASSERT(x1.length() % subvec_length == 0);
+    PLASSERT(x2.length() % subvec_length == 0);
+
+    int n1= x1.length() / subvec_length;// n1 features
+    TVec<Vec> subvecs1(n1);
+    for(int i= 0; i < n1; ++i)
+        subvecs1[i]= x1.subVec(i*subvec_length, subvec_length);
+    int n2= x2.length() / subvec_length;// n2 features
+    TVec<Vec> subvecs2(n2);
+    for(int j= 0; j < n2; ++j)
+        subvecs2[j]= x2.subVec(j*subvec_length, subvec_length);
+
+    //init: calc. point-to-point distances
+    dpoint.resize(n1,n2);
+    for(int i= 0; i < n1; ++i)
+        for(int j= 0; j < n2; ++j)
+            dpoint(i,j)= dist_fn(subvecs1[i], subvecs2[j]);
+
+    //recurs: calc. path distances
+    dpath.resize(n1,n2);
+    bptrs.resize(n1,n2);
+    dpath(0,0)= dpoint(0,0); //starting point
+    
+    int i,j;
+    real mn; //min. found at each step
+    int ai, aj; //'actual' coords when following a local path
+    pair<int,int> scoords; //coords for a step
+    real dist; //'distance' to a given point
+    TVec<LocalPath>::iterator it;
+    TVec<LocalPath>::iterator itbeg= local_paths.begin();
+    TVec<LocalPath>::iterator itend= local_paths.end();
+    TVec<LocalStep>::iterator jt;
+    TVec<LocalStep>::iterator jtend;
+    bool path_ok; //is this path valid?
+    bool some_path_ok; //is there any valid path to those coords?
+
+    for(i= 0; i < n1; ++i)
+        for(j= 0; j < n2; ++j)
+        {
+            if(i==0 && j==0)
+                continue; //starting point already calc.
+            some_path_ok= false;
+            mn= REAL_MAX;
+            for(it= itbeg; it != itend; ++it)
+            {// for all local paths
+                path_ok= true;
+                ai= i; aj= j;
+                dist= 0.;
+                jtend= it->end();
+                for(jt= it->begin(); jt != jtend; ++jt)
+                {// for each step from a local path
+                    dist+= dpoint(ai,aj) * jt->second;
+                    scoords= jt->first;
+                    ai-= scoords.first;
+                    aj-= scoords.second;
+                    if(ai < 0 || aj < 0)//invalid path
+                    {
+                        path_ok= false;
+                        break;
+                    }
+                }
+                if(path_ok)
+                {
+                    dist+= dpath(ai,aj);//add dist. to beg. of path
+                    if(dist < mn || !some_path_ok)
+                    {
+                        mn= dist;
+                        bptrs(i,j)= make_pair(ai,aj);
+                        some_path_ok= true;
+                    }
+                }
+            }
+            dpath(i,j)= mn;//will be REAL_MAX if no path
+        }
+}
+
+////////////////
+// remote dtw //
+////////////////
+tuple<Mat, Mat, TMat<pair<int, int> > > DTWKernel::remote_dtw(const Vec& x1, const Vec& x2) const
+{
+    dtw(x1,x2);
+    return make_tuple(dpath, dpoint, bptrs);
+
+}
+//////////////
+// evaluate //
+//////////////
+real DTWKernel::evaluate(const Vec& x1, const Vec& x2) const 
+{
+    dtw(x1, x2);
+    return dpath.lastElement();
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void DTWKernel::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField(dpoint, copies);
+    deepCopyField(dpath, copies);
+    deepCopyField(bptrs, copies);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/ker/DTWKernel.h
===================================================================
--- trunk/plearn/ker/DTWKernel.h	2007-12-05 16:27:19 UTC (rev 8338)
+++ trunk/plearn/ker/DTWKernel.h	2007-12-07 21:08:14 UTC (rev 8339)
@@ -0,0 +1,161 @@
+// -*- C++ -*-
+
+// DTWKernel.h
+//
+// Copyright (C) 2007 Xavier Saint-Mleux, ApSTAT Technologies inc.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Xavier Saint-Mleux
+
+/*! \file DTWKernel.h */
+
+
+#ifndef DTWKernel_INC
+#define DTWKernel_INC
+
+#include <plearn/ker/Kernel.h>
+
+namespace PLearn {
+
+/**
+ * Kernel for Dynamic Time Warping
+ * see sect.4.7 of Rabiner, L. and Juang, B. 1993 'Fundamentals of Speech Recognition'. Prentice-Hall, Inc.
+ *
+ * WARNING: THIS CLASS IS *NOT* THREAD-SAFE (has mutable pre-allocated data members)
+ * 
+ * TODO: Add global path constraints and other goodies
+ */
+
+class DTWKernel : public Kernel
+{
+    typedef Kernel inherited;
+
+public:
+
+    //#####  Typedefs  ########################################################
+
+    // ** Local path constraints:
+
+    //! LocalStep specifies an (x,y) offset and associated cost (weight)
+    typedef pair<pair<int, int>, real> LocalStep;
+
+    //! LocalPath is a series of LocalSteps taken in one iteration
+    typedef TVec<LocalStep> LocalPath;
+
+    //#####  Public Build Options  ############################################
+
+    //! length of each sub-vec within an example
+    int subvec_length;
+
+    //! allowed local paths (incl. associated costs)
+    TVec<LocalPath> local_paths;
+
+    //! name of the 'distance' function to use when comparing features (sub-vecs)
+    string distance_type;
+    
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    DTWKernel();
+
+    //#####  Kernel Member Functions  #########################################
+
+    //! Compute all distances and paths (to mutalbe vars)
+    void dtw(const Vec& x1, const Vec& x2) const;
+    tuple<Mat, Mat, TMat<pair<int, int> > > remote_dtw(const Vec& x1, const Vec& x2) const;
+
+    //! Compute K(x1,x2).
+    virtual real evaluate(const Vec& x1, const Vec& x2) const;
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    PLEARN_DECLARE_OBJECT(DTWKernel);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList& ol);
+
+    //! Declare the methods that are remote-callable
+    static void declareMethods(RemoteMethodMap& rmm);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    //! point-to-point distances (pre-alloc'd)
+    mutable Mat dpoint;
+
+    //! path length from (0,0) to (i,j) (pre-alloc'd)
+    mutable Mat dpath;
+
+    //! back-pointers of optimal paths (pre-alloc'd)
+    mutable TMat<pair<int,int> > bptrs;
+
+    //! actual pointer to distance function
+    real (*dist_fn)(const Vec&,const Vec&);
+
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(DTWKernel);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From saintmlx at mail.berlios.de  Fri Dec  7 22:09:25 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Fri, 7 Dec 2007 22:09:25 +0100
Subject: [Plearn-commits] r8340 - trunk/plearn/python
Message-ID: <200712072109.lB7L9PCv004890@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-07 22:09:25 +0100 (Fri, 07 Dec 2007)
New Revision: 8340

Modified:
   trunk/plearn/python/PythonObjectWrapper.cc
   trunk/plearn/python/PythonObjectWrapper.h
Log:
- fixed conversion of VMat to Python



Modified: trunk/plearn/python/PythonObjectWrapper.cc
===================================================================
--- trunk/plearn/python/PythonObjectWrapper.cc	2007-12-07 21:08:14 UTC (rev 8339)
+++ trunk/plearn/python/PythonObjectWrapper.cc	2007-12-07 21:09:25 UTC (rev 8340)
@@ -288,6 +288,7 @@
 }
 
 //#####  Constructors+Destructors  ############################################
+
 PythonObjectWrapper::PythonObjectWrapper(OwnershipMode o,
                                          // unused in this overload
                                          bool acquire_gil)
@@ -671,17 +672,19 @@
     return (PyObject*)pyarr;
 }
 
+
+bool PythonObjectWrapper::VMatAsPtr= false;//numpy array by default
+
 //PyObject* ConvertToPyObject<VMat>::newPyObject(const VMat& vm)
 PyObject* ConvertToPyObject<PP<VMatrix> >::newPyObject(const PP<VMatrix>& vm)
 {
-    if (vm.isNull())
-        return ConvertToPyObject<Mat>::newPyObject(Mat());
-    else
-#ifdef PL_PYTHON_VMAT_AS_PTR
+    if(PythonObjectWrapper::VMatAsPtr)
         return ConvertToPyObject<Object*>::newPyObject(static_cast<Object*>(vm));
-#else
-        return ConvertToPyObject<Mat>::newPyObject(vm->toMat());// as a numpy array
-#endif
+    else// as a numpy array
+        if (vm.isNull())
+            return ConvertToPyObject<Mat>::newPyObject(Mat());
+        else
+            return ConvertToPyObject<Mat>::newPyObject(vm->toMat());
 }
 
 PyObject* ConvertToPyObject<PythonObjectWrapper>::newPyObject(const PythonObjectWrapper& pow)

Modified: trunk/plearn/python/PythonObjectWrapper.h
===================================================================
--- trunk/plearn/python/PythonObjectWrapper.h	2007-12-07 21:08:14 UTC (rev 8339)
+++ trunk/plearn/python/PythonObjectWrapper.h	2007-12-07 21:09:25 UTC (rev 8340)
@@ -753,6 +753,8 @@
         transfer_ownership
     };
 
+    static bool VMatAsPtr;//Object* or numpy array?
+
 public:
     //#####  Construction and Utility  ########################################
 
@@ -881,6 +883,7 @@
     friend PStream& operator<<(PStream& out, const PythonObjectWrapper& v);
 };
 
+
 // Specialization for General T*.  Attempt to cast into Object*.  If that works
 // we're all set; for specific pointer types (e.g.  map<U,V>* and vector<T>*),
 // above, since they are more specialized they should kick in before this one.



From saintmlx at mail.berlios.de  Fri Dec  7 22:10:22 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Fri, 7 Dec 2007 22:10:22 +0100
Subject: [Plearn-commits] r8341 - trunk/plearn/ker
Message-ID: <200712072110.lB7LAMBo004951@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-07 22:10:22 +0100 (Fri, 07 Dec 2007)
New Revision: 8341

Modified:
   trunk/plearn/ker/Kernel.cc
Log:
- remote declare method evaluate



Modified: trunk/plearn/ker/Kernel.cc
===================================================================
--- trunk/plearn/ker/Kernel.cc	2007-12-07 21:09:25 UTC (rev 8340)
+++ trunk/plearn/ker/Kernel.cc	2007-12-07 21:10:22 UTC (rev 8341)
@@ -125,6 +125,13 @@
         rmm, "returnComputedGramMatrix", &Kernel::returnComputedGramMatrix,
         (BodyDoc("\n"),
          RetDoc ("Returns the Gram Matrix")));
+
+    declareMethod(
+        rmm, "evaluate", &Kernel::evaluate,
+        (BodyDoc("evaluate the kernel on two vectors\n"),
+         ArgDoc("x1","first vector"),
+         ArgDoc("x2","second vector"),
+         RetDoc ("K(x1,x2)")));
 }
 
 ///////////



From saintmlx at mail.berlios.de  Fri Dec  7 22:11:46 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Fri, 7 Dec 2007 22:11:46 +0100
Subject: [Plearn-commits] r8342 - trunk/plearn/math
Message-ID: <200712072111.lB7LBkk4005121@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-07 22:11:46 +0100 (Fri, 07 Dec 2007)
New Revision: 8342

Modified:
   trunk/plearn/math/TMat_decl.h
Log:
- fixed  TMat<T>::lastElement



Modified: trunk/plearn/math/TMat_decl.h
===================================================================
--- trunk/plearn/math/TMat_decl.h	2007-12-07 21:10:22 UTC (rev 8341)
+++ trunk/plearn/math/TMat_decl.h	2007-12-07 21:11:46 UTC (rev 8342)
@@ -573,7 +573,7 @@
     { return subMatRows(row, 1); }
 
     inline T& firstElement() const { return *data(); }
-    inline T& lastElement() const { return operator()(length-1,width-1); }
+    inline T& lastElement() const { return operator()(length_-1,width_-1); }
 
     inline TVec<T> firstRow() const { return operator()(0); } 
     inline TVec<T> lastRow() const { return operator()(length_ - 1); }



From saintmlx at mail.berlios.de  Fri Dec  7 22:13:13 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Fri, 7 Dec 2007 22:13:13 +0100
Subject: [Plearn-commits] r8343 - in trunk: commands
	python_modules/plearn/pyext
Message-ID: <200712072113.lB7LDDL2005176@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-07 22:13:13 +0100 (Fri, 07 Dec 2007)
New Revision: 8343

Modified:
   trunk/commands/plearn_full.cc
   trunk/commands/plearn_noblas_inc.h
   trunk/python_modules/plearn/pyext/plext.cc
Log:
- Python: wrap VMats instead of converting to numpy
- added DTWKernel to includes



Modified: trunk/commands/plearn_full.cc
===================================================================
--- trunk/commands/plearn_full.cc	2007-12-07 21:11:46 UTC (rev 8342)
+++ trunk/commands/plearn_full.cc	2007-12-07 21:13:13 UTC (rev 8343)
@@ -44,6 +44,7 @@
 
 int main(int argc, char** argv)
 {
+    PythonObjectWrapper::VMatAsPtr= true;
     return plearn_main( argc, argv, 
                         PLEARN_MAJOR_VERSION, 
                         PLEARN_MINOR_VERSION, 

Modified: trunk/commands/plearn_noblas_inc.h
===================================================================
--- trunk/commands/plearn_noblas_inc.h	2007-12-07 21:11:46 UTC (rev 8342)
+++ trunk/commands/plearn_noblas_inc.h	2007-12-07 21:13:13 UTC (rev 8343)
@@ -120,6 +120,7 @@
 #include <plearn/ker/SummationKernel.h>
 #include <plearn/ker/ThresholdedKernel.h>
 #include <plearn/ker/VMatKernel.h>
+#include <plearn/ker/DTWKernel.h>
 
 /*************
  * Optimizer *

Modified: trunk/python_modules/plearn/pyext/plext.cc
===================================================================
--- trunk/python_modules/plearn/pyext/plext.cc	2007-12-07 21:11:46 UTC (rev 8342)
+++ trunk/python_modules/plearn/pyext/plext.cc	2007-12-07 21:13:13 UTC (rev 8343)
@@ -40,6 +40,7 @@
 
 PyMODINIT_FUNC initplext()
 {
+    PythonObjectWrapper::VMatAsPtr= true;
     setVersion(0,92,0);
     initPythonExtensionModule("plext");
 }



From saintmlx at mail.berlios.de  Fri Dec  7 23:37:57 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Fri, 7 Dec 2007 23:37:57 +0100
Subject: [Plearn-commits] r8344 - trunk/plearn/python
Message-ID: <200712072237.lB7MbvJ5008761@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-07 23:37:57 +0100 (Fri, 07 Dec 2007)
New Revision: 8344

Modified:
   trunk/plearn/python/PythonObjectWrapper.cc
   trunk/plearn/python/PythonObjectWrapper.h
Log:
- allow setting PythonObjectWrapper::VMatAsPtr from python



Modified: trunk/plearn/python/PythonObjectWrapper.cc
===================================================================
--- trunk/plearn/python/PythonObjectWrapper.cc	2007-12-07 21:13:13 UTC (rev 8343)
+++ trunk/plearn/python/PythonObjectWrapper.cc	2007-12-07 22:37:57 UTC (rev 8344)
@@ -846,11 +846,34 @@
     }
 }
 
+
+bool getVMatAsPtr()
+{
+    return PythonObjectWrapper::VMatAsPtr;
+}
+bool setVMatAsPtr(bool vmat_as_ptr)
+{
+    bool prev= PythonObjectWrapper::VMatAsPtr;
+    PythonObjectWrapper::VMatAsPtr= vmat_as_ptr;
+    return prev;
+}
+
+
 BEGIN_DECLARE_REMOTE_FUNCTIONS
     declareFunction("printWrappedObjects", &printWrappedObjects,
                     (BodyDoc("Prints PLearn objects wrapped into python.\n")));
     declareFunction("ramassePoubelles", &ramassePoubelles,
                     (BodyDoc("GC for wrapped objects.\n")));
+
+    declareFunction("getVMatAsPtr", &getVMatAsPtr,
+                    (BodyDoc("Returns current setting of 'VMatAsPtr'.\n"
+                             "true= wrapped VMat; false= numpy array.\n"),
+                     RetDoc("current VMatAsPtr")));
+    declareFunction("setVMatAsPtr", &setVMatAsPtr,
+                    (BodyDoc("Sets 'VMatAsPtr', returns previous setting.\n"
+                             "true= wrapped VMat; false= numpy array.\n"),
+                     ArgDoc("vmat_as_ptr","wrap VMats instead of converting to numpy?"),
+                     RetDoc("Previous setting")));
 END_DECLARE_REMOTE_FUNCTIONS
 
 

Modified: trunk/plearn/python/PythonObjectWrapper.h
===================================================================
--- trunk/plearn/python/PythonObjectWrapper.h	2007-12-07 21:13:13 UTC (rev 8343)
+++ trunk/plearn/python/PythonObjectWrapper.h	2007-12-07 22:37:57 UTC (rev 8344)
@@ -1407,6 +1407,9 @@
 void printWrappedObjects();
 void ramassePoubelles();
 
+bool getVMatAsPtr();
+bool setVMatAsPtr(bool vmat_as_ptr= true);
+
 } // end of namespace PLearn
 
 #endif



From tihocan at mail.berlios.de  Mon Dec 10 17:05:30 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Mon, 10 Dec 2007 17:05:30 +0100
Subject: [Plearn-commits] r8345 - trunk/plearn_learners/generic/EXPERIMENTAL
Message-ID: <200712101605.lBAG5ULa015991@sheep.berlios.de>

Author: tihocan
Date: 2007-12-10 17:05:29 +0100 (Mon, 10 Dec 2007)
New Revision: 8345

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
Log:
Added new cost to make sure timing works fine

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-12-07 22:37:57 UTC (rev 8344)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-12-10 16:05:29 UTC (rev 8345)
@@ -40,6 +40,7 @@
 #include "NatGradSMPNNet.h"
 #include <plearn/io/openFile.h>
 #include <plearn/math/pl_erf.h>
+#include <plearn/misc/PTimer.h>
 
 #include <sys/ipc.h>
 #include <sys/sem.h>
@@ -867,11 +868,14 @@
     int my_stage_incr = iam >= stage_incr_left ? stage_incr_per_cpu
                                                : stage_incr_per_cpu + 1;
 
+    PP<PTimer> ptimer;
     if (iam == 0) {
         //tmp_log << "Starting loop" << endl;
         //tmp_log.flush();
+        ptimer = new PTimer();
         Profiler::reset("big_loop");
         Profiler::start("big_loop");
+        ptimer->startTimer("big_loop");
     }
 
     //pout << "CPU " << iam << ": my_stage_incr = " << my_stage_incr << endl;
@@ -996,6 +1000,7 @@
         //tmp_log << "Loop ended" << endl;
         //tmp_log.flush();
         Profiler::end("big_loop");
+        ptimer->stopTimer("big_loop");
     }
 
     if (!wait_for_final_update) {
@@ -1132,6 +1137,7 @@
     costs_plus_time[train_costs.width()+2] =
         (big_loop_stats.user_duration + big_loop_stats.system_duration) /
         ticksPerSec;
+    costs_plus_time[train_costs.width() + 3] = ptimer->getTimer("big_loop");
     train_stats->update( costs_plus_time );
     train_stats->finalize(); // finalize statistics for this epoch
 
@@ -1575,7 +1581,8 @@
     TVec<string> costs = getTestCostNames();
     costs.append("train_seconds");
     costs.append("cum_train_seconds");
-    costs.append("big_loop_seconds");
+    costs.append("big_loop_seconds_1");
+    costs.append("big_loop_seconds_2");
     return costs;
 }
 



From saintmlx at mail.berlios.de  Tue Dec 11 21:43:50 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Tue, 11 Dec 2007 21:43:50 +0100
Subject: [Plearn-commits] r8346 - trunk/plearn/ker
Message-ID: <200712112043.lBBKhoqj025456@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-11 21:43:50 +0100 (Tue, 11 Dec 2007)
New Revision: 8346

Modified:
   trunk/plearn/ker/DTWKernel.cc
   trunk/plearn/ker/DTWKernel.h
Log:
- more generic DTW



Modified: trunk/plearn/ker/DTWKernel.cc
===================================================================
--- trunk/plearn/ker/DTWKernel.cc	2007-12-10 16:05:29 UTC (rev 8345)
+++ trunk/plearn/ker/DTWKernel.cc	2007-12-11 20:43:50 UTC (rev 8346)
@@ -47,14 +47,16 @@
     "Kernel for Dynamic Time Warping",
     "Kernel for Dynamic Time Warping\n"
     "(see sect.4.7 of Rabiner, L. and Juang, B. 1993 'Fundamentals of Speech Recognition'. Prentice-Hall, Inc.)\n"
-    "TODO: Add global path constraints and other goodies...\n"
     );
 
 //////////////////
 // DTWKernel //
 //////////////////
 DTWKernel::DTWKernel()
-    :subvec_length(-1), local_paths(), distance_type("euclidean")
+    :subvec_length(-1), 
+     local_paths(), 
+     distance_type("L2"), 
+     max_time_deviation(-1)
 {
     /*
      * default local paths: 
@@ -77,13 +79,26 @@
 
     declareOption(ol, "local_paths", &DTWKernel::local_paths,
                   OptionBase::buildoption,
-                  "Specifies local path constraints.");
+                  "Specifies local path constraints and weights. "
+                  "In each path, steps should be listed from "
+                  "the ending point to the starting point."
+                  "e.g. if a path can start at (0,0), go to (1,1) "
+                  "and then end at (2,1), it should be listed as: "
+                  "[((1,0),0.5), ((1,1),0.5)] where '0.5' are weights");
 
     declareOption(ol, "distance_type", &DTWKernel::distance_type,
                   OptionBase::buildoption,
                   "Name of the 'distance' function to use "
-                  "when comparing features (sub-vecs).");
+                  "when comparing features (sub-vecs). "
+                  "one of: 'L2'  : sqrt{sum{(x-y)^2}}"
+                  "        'L1'  : sum{|x-y|}"
+                  "        'pow2': sum{(x-y)^2}");
 
+    declareOption(ol, "max_time_deviation", &DTWKernel::max_time_deviation,
+                  OptionBase::buildoption,
+                  "Maximum allowed difference between i and j; "
+                  "negative means no limit.");
+
     inherited::declareOptions(ol);
 }
 
@@ -121,12 +136,46 @@
                 "subvec_length must be specified before build "
                 "(%d is not a valid value).", subvec_length);
 
-    if(distance_type == "euclidean")
+    //distance function
+    if(distance_type == "L2")
+        dist_fn= L2distance;
+    else if(distance_type == "L1")
+        dist_fn= L1distance;
+    else if(distance_type == "pow2")
         dist_fn= powdistance;
     else
         PLERROR("In DTWKernel::build_() : "
-                "only 'euclidean' distance_type is supported for now "
+                "distance_type should be one of: " 
+                "'L2', 'L1' or 'pow2' "
                 "('%s' is not a valid value).", distance_type.c_str());
+
+    //calc. valid region from local_paths (min/max slope)
+    TVec<LocalPath>::iterator it;
+    TVec<LocalPath>::iterator itbeg= local_paths.begin();
+    TVec<LocalPath>::iterator itend= local_paths.end();
+    TVec<LocalStep>::iterator jt;
+    TVec<LocalStep>::iterator jtend;
+    bool first= true;
+    for(it= itbeg; it != itend; ++it)
+    {
+        int i= 0, j= 0;
+        jtend= it->end();
+        for(jt= it->begin(); jt != jtend; ++jt)
+        {
+            i+= jt->first.first;
+            j+= jt->first.second;
+        }
+        real rij= i;
+        rij/= j;
+        if(rij < slope_ij_min || first)
+            slope_ij_min= rij;
+        real rji= j;
+        rji/= i;
+        if(rji < slope_ji_min || first)
+            slope_ji_min= rji;
+        first= false;
+    }
+
 }
 
 //////////////
@@ -147,17 +196,43 @@
         subvecs2[j]= x2.subVec(j*subvec_length, subvec_length);
 
     //init: calc. point-to-point distances
+    // also pre-calc. bounds on j for each i
+    int i,j,jmin,jmax;
+    real jmin0, jmax0;
     dpoint.resize(n1,n2);
-    for(int i= 0; i < n1; ++i)
-        for(int j= 0; j < n2; ++j)
+    jbounds.resize(n1,2);
+    for(i= 0; i < n1; ++i)
+    {
+        if(slope_ij_min == 0.)
+        {
+            jmin0= 0.;
+            jmax0= n2;
+        }
+        else
+        {
+            jmin0= static_cast<real>(i+1-n1)/slope_ij_min + n2 - 1;
+            jmax0= static_cast<real>(i)/slope_ij_min;
+        }
+        jmin= static_cast<int>(ceil(max(jmin0, slope_ji_min * i)));
+        jmax= static_cast<int>(
+            floor(min(jmax0, slope_ji_min*(i-n1+1) + n2 - 1)));
+        if(max_time_deviation >= 0)
+        {
+            jmin= max(jmin, i - max_time_deviation);
+            jmax= min(jmax, i + max_time_deviation);
+        }
+        jbounds(i,0)= jmin;
+        jbounds(i,1)= jmax;
+
+        for(j= jmin; j <= jmax; ++j)
             dpoint(i,j)= dist_fn(subvecs1[i], subvecs2[j]);
+    }
 
     //recurs: calc. path distances
     dpath.resize(n1,n2);
     bptrs.resize(n1,n2);
     dpath(0,0)= dpoint(0,0); //starting point
     
-    int i,j;
     real mn; //min. found at each step
     int ai, aj; //'actual' coords when following a local path
     pair<int,int> scoords; //coords for a step
@@ -171,10 +246,13 @@
     bool some_path_ok; //is there any valid path to those coords?
 
     for(i= 0; i < n1; ++i)
-        for(j= 0; j < n2; ++j)
+    {
+        jmin= jbounds(i,0);
+        if(i==0)
+            jmin= max(1,jmin);//skip (0,0), already calc.
+        jmax= jbounds(i,1);
+        for(j= jmin; j <= jmax; ++j)
         {
-            if(i==0 && j==0)
-                continue; //starting point already calc.
             some_path_ok= false;
             mn= REAL_MAX;
             for(it= itbeg; it != itend; ++it)
@@ -184,17 +262,19 @@
                 dist= 0.;
                 jtend= it->end();
                 for(jt= it->begin(); jt != jtend; ++jt)
-                {// for each step from a local path
+                {// for each step in the local path
                     dist+= dpoint(ai,aj) * jt->second;
                     scoords= jt->first;
                     ai-= scoords.first;
                     aj-= scoords.second;
-                    if(ai < 0 || aj < 0)//invalid path
+                    if(ai < 0 || aj < 0)
                     {
                         path_ok= false;
                         break;
                     }
                 }
+                if(ai < 0 || aj < jbounds(ai,0) || aj > jbounds(ai,1))
+                    path_ok= false;
                 if(path_ok)
                 {
                     dist+= dpath(ai,aj);//add dist. to beg. of path
@@ -206,8 +286,12 @@
                     }
                 }
             }
-            dpath(i,j)= mn;//will be REAL_MAX if no path
+            dpath(i,j)= mn;//will be REAL_MAX if no path... but should not happen
+            if(!some_path_ok && i==n1-1 && j==n2-1)
+                PLERROR("In DTWKernel::dtw : can't reach end of path! "
+                        "Check your local_paths, they may be inconsistent.");
         }
+    }
 }
 
 ////////////////

Modified: trunk/plearn/ker/DTWKernel.h
===================================================================
--- trunk/plearn/ker/DTWKernel.h	2007-12-10 16:05:29 UTC (rev 8345)
+++ trunk/plearn/ker/DTWKernel.h	2007-12-11 20:43:50 UTC (rev 8346)
@@ -50,7 +50,6 @@
  *
  * WARNING: THIS CLASS IS *NOT* THREAD-SAFE (has mutable pre-allocated data members)
  * 
- * TODO: Add global path constraints and other goodies
  */
 
 class DTWKernel : public Kernel
@@ -79,6 +78,9 @@
 
     //! name of the 'distance' function to use when comparing features (sub-vecs)
     string distance_type;
+
+    //! Maximum allowed difference between i and j.
+    int max_time_deviation;
     
 public:
     //#####  Public Member Functions  #########################################
@@ -135,9 +137,18 @@
     //! back-pointers of optimal paths (pre-alloc'd)
     mutable TMat<pair<int,int> > bptrs;
 
+    //! bounds on j for each i
+    mutable TMat<int> jbounds;
+
     //! actual pointer to distance function
     real (*dist_fn)(const Vec&,const Vec&);
 
+    //! global path constraints calc. from local_paths
+    //! min. and max. slope
+    real slope_ij_min;
+    real slope_ji_min;
+
+
 };
 
 // Declares a few other classes and functions related to this class



From saintmlx at mail.berlios.de  Thu Dec 13 19:06:56 2007
From: saintmlx at mail.berlios.de (saintmlx at BerliOS)
Date: Thu, 13 Dec 2007 19:06:56 +0100
Subject: [Plearn-commits] r8347 - trunk/plearn/ker
Message-ID: <200712131806.lBDI6uxG020473@sheep.berlios.de>

Author: saintmlx
Date: 2007-12-13 19:06:55 +0100 (Thu, 13 Dec 2007)
New Revision: 8347

Modified:
   trunk/plearn/ker/DTWKernel.cc
   trunk/plearn/ker/DTWKernel.h
Log:
- minor fixes, comments, etc.



Modified: trunk/plearn/ker/DTWKernel.cc
===================================================================
--- trunk/plearn/ker/DTWKernel.cc	2007-12-11 20:43:50 UTC (rev 8346)
+++ trunk/plearn/ker/DTWKernel.cc	2007-12-13 18:06:55 UTC (rev 8347)
@@ -89,10 +89,10 @@
     declareOption(ol, "distance_type", &DTWKernel::distance_type,
                   OptionBase::buildoption,
                   "Name of the 'distance' function to use "
-                  "when comparing features (sub-vecs). "
-                  "one of: 'L2'  : sqrt{sum{(x-y)^2}}"
-                  "        'L1'  : sum{|x-y|}"
-                  "        'pow2': sum{(x-y)^2}");
+                  "when comparing features (sub-vecs).\n"
+                  "one of: 'L2'  : sqrt{sum{(x-y)^2}}\n"
+                  "        'L1'  : sum{|x-y|}\n"
+                  "        'pow2': sum{(x-y)^2}\n");
 
     declareOption(ol, "max_time_deviation", &DTWKernel::max_time_deviation,
                   OptionBase::buildoption,
@@ -111,7 +111,7 @@
         (BodyDoc("Calc. DTW on two feature vectors\n"),
          ArgDoc("x1","first vector"),
          ArgDoc("x2","second vector"),
-         RetDoc ("dpoint, dpath, bptrs")));
+         RetDoc ("dpath, dpoint, bptrs")));
 }
 
 
@@ -204,7 +204,7 @@
     for(i= 0; i < n1; ++i)
     {
         if(slope_ij_min == 0.)
-        {
+        {// avoid div by zero... especially if 0/0
             jmin0= 0.;
             jmax0= n2;
         }
@@ -217,13 +217,18 @@
         jmax= static_cast<int>(
             floor(min(jmax0, slope_ji_min*(i-n1+1) + n2 - 1)));
         if(max_time_deviation >= 0)
-        {
+        {// max abs. delta time (if >= 0)
             jmin= max(jmin, i - max_time_deviation);
             jmax= min(jmax, i + max_time_deviation);
         }
         jbounds(i,0)= jmin;
         jbounds(i,1)= jmax;
-
+        ///***///***///***///
+        /*
+         * TODO: make sure this is OK for exotic local_paths
+         *       (also see: option desc. for local_paths)
+         */
+        ///***///***///***///
         for(j= jmin; j <= jmax; ++j)
             dpoint(i,j)= dist_fn(subvecs1[i], subvecs2[j]);
     }
@@ -319,9 +324,11 @@
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
 
+    deepCopyField(local_paths, copies);
     deepCopyField(dpoint, copies);
     deepCopyField(dpath, copies);
     deepCopyField(bptrs, copies);
+    deepCopyField(jbounds, copies);
 }
 
 } // end of namespace PLearn

Modified: trunk/plearn/ker/DTWKernel.h
===================================================================
--- trunk/plearn/ker/DTWKernel.h	2007-12-11 20:43:50 UTC (rev 8346)
+++ trunk/plearn/ker/DTWKernel.h	2007-12-13 18:06:55 UTC (rev 8347)
@@ -148,7 +148,6 @@
     real slope_ij_min;
     real slope_ji_min;
 
-
 };
 
 // Declares a few other classes and functions related to this class



From tihocan at mail.berlios.de  Thu Dec 13 21:25:46 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Thu, 13 Dec 2007 21:25:46 +0100
Subject: [Plearn-commits] r8348 - trunk/plearn/vmat
Message-ID: <200712132025.lBDKPk4L026549@sheep.berlios.de>

Author: tihocan
Date: 2007-12-13 21:25:45 +0100 (Thu, 13 Dec 2007)
New Revision: 8348

Modified:
   trunk/plearn/vmat/VMatrix.cc
Log:
Typo fix in help

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-12-13 18:06:55 UTC (rev 8347)
+++ trunk/plearn/vmat/VMatrix.cc	2007-12-13 20:25:45 UTC (rev 8348)
@@ -169,7 +169,7 @@
     declareMethod(
         rmm, "getMat", &VMatrix::toMat,
         (BodyDoc("Returns the content of the vmat as a Mat\n"),
-         RetDoc ("The conent of this VMatrix as a Mat")));
+         RetDoc ("The content of this VMatrix as a Mat")));
 
     declareMethod(
         rmm, "declareFieldNames", &VMatrix::declareFieldNames,



From tihocan at mail.berlios.de  Fri Dec 14 16:42:27 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 16:42:27 +0100
Subject: [Plearn-commits] r8349 - trunk/plearn/vmat
Message-ID: <200712141542.lBEFgRfq021189@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 16:42:26 +0100 (Fri, 14 Dec 2007)
New Revision: 8349

Modified:
   trunk/plearn/vmat/SortRowsVMatrix.cc
   trunk/plearn/vmat/SortRowsVMatrix.h
Log:
Added a new option in order to be able to sort by column names rather than by numerical indices only

Modified: trunk/plearn/vmat/SortRowsVMatrix.cc
===================================================================
--- trunk/plearn/vmat/SortRowsVMatrix.cc	2007-12-13 20:25:45 UTC (rev 8348)
+++ trunk/plearn/vmat/SortRowsVMatrix.cc	2007-12-14 15:42:26 UTC (rev 8349)
@@ -48,37 +48,56 @@
 
 /** SortRowsVMatrix **/
 
-PLEARN_IMPLEMENT_OBJECT(SortRowsVMatrix,
-                        "Sort the samples of a VMatrix according to one (or more) given columns.",
-                        "The implementation is not efficient at all, feel free to improve it !"
-    );
+PLEARN_IMPLEMENT_OBJECT(
+    SortRowsVMatrix,
+    "Sort the samples of a VMatrix according to one (or more) given columns.",
+    "The implementation is not efficient at all, feel free to improve it !"
+);
 
-SortRowsVMatrix::SortRowsVMatrix()
-    : increasing_order(true)
-{
-    // Default = no sorting.
-    sort_columns.resize(0);
-}
+/////////////////////
+// SortRowsVMatrix //
+/////////////////////
+SortRowsVMatrix::SortRowsVMatrix():
+    increasing_order(true)
+{}
 
+////////////////////
+// declareOptions //
+////////////////////
 void SortRowsVMatrix::declareOptions(OptionList &ol)
 {
-    declareOption(ol, "sort_columns", &SortRowsVMatrix::sort_columns, OptionBase::buildoption,
-                  "    the column(s) that must be sorted (the first one is the first criterion)");
+    declareOption(ol, "sort_columns", &SortRowsVMatrix::sort_columns,
+                                      OptionBase::buildoption,
+        "Indices of the column(s) that must be sorted (the first one is the\n"
+        "first criterion).");
 
+    declareOption(ol, "sort_columns_by_name",
+                  &SortRowsVMatrix::sort_columns_by_name,
+                  OptionBase::buildoption,
+        "Names of the column(s) that must be sorted (the first one is the\n"
+        "first criterion). This option is optional and, if provided, the\n"
+        "'sort_columns' option will be ignored.");
+
     declareOption(ol, "increasing_order", &SortRowsVMatrix::increasing_order, OptionBase::buildoption,
                   "    if set to 1, the data will be sorted in increasing order");
 
     inherited::declareOptions(ol);
 
+    // Hide unused options.
+
     redeclareOption(ol, "indices", &SortRowsVMatrix::indices, OptionBase::nosave,
                     "The indices are computed at build time.");
     redeclareOption(ol, "indices_vmat", &SortRowsVMatrix::indices_vmat, OptionBase::nosave,
                     "Unused.");
 }
 
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
 void SortRowsVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
 {
-    deepCopyField(sort_columns, copies);
+    deepCopyField(sort_columns,         copies);
+    deepCopyField(sort_columns_by_name, copies);
     inherited::makeDeepCopyFromShallowCopy(copies);
 }
 
@@ -96,6 +115,12 @@
 ////////////
 void SortRowsVMatrix::build_()
 {
+    if (sort_columns_by_name.isNotEmpty() && source) {
+        // Convert column names into column indices.
+        sort_columns.resize(sort_columns_by_name.length());
+        for (int i = 0; i < sort_columns_by_name.length(); i++)
+            sort_columns[i] = source->getFieldIndex(sort_columns_by_name[i]);
+    }
     // Check we don't try to sort twice by the same column (this can be confusing).
     if (sort_columns.isNotEmpty()) {
         for (int i = 0; i < sort_columns.length(); i++) {

Modified: trunk/plearn/vmat/SortRowsVMatrix.h
===================================================================
--- trunk/plearn/vmat/SortRowsVMatrix.h	2007-12-13 20:25:45 UTC (rev 8348)
+++ trunk/plearn/vmat/SortRowsVMatrix.h	2007-12-14 15:42:26 UTC (rev 8349)
@@ -61,6 +61,7 @@
     //! Public build options.
     bool increasing_order;
     TVec<int> sort_columns;
+    TVec<string> sort_columns_by_name;
 
 public:
 
@@ -68,11 +69,14 @@
 
     PLEARN_DECLARE_OBJECT(SortRowsVMatrix);
 
-    static void declareOptions(OptionList &ol);
 
     virtual void build();
     virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
 
+protected:
+
+    static void declareOptions(OptionList &ol);
+
 private:
 
     void build_();



From tihocan at mail.berlios.de  Fri Dec 14 18:27:23 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 18:27:23 +0100
Subject: [Plearn-commits] r8350 - trunk/plearn/python/test
Message-ID: <200712141727.lBEHRNpc027339@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 18:27:22 +0100 (Fri, 14 Dec 2007)
New Revision: 8350

Modified:
   trunk/plearn/python/test/InterfunctionXchgTest.cc
Log:
Removed potentially system-dependent python path from test output

Modified: trunk/plearn/python/test/InterfunctionXchgTest.cc
===================================================================
--- trunk/plearn/python/test/InterfunctionXchgTest.cc	2007-12-14 15:42:26 UTC (rev 8349)
+++ trunk/plearn/python/test/InterfunctionXchgTest.cc	2007-12-14 17:27:22 UTC (rev 8350)
@@ -187,6 +187,12 @@
             regex_replace(msg_without_sys_dependent_data, python_ver,
                     "Python 2.X.Y");
 
+        boost::regex python_path(": /(.)+/python",
+                                 boost::regex::perl|boost::regex::icase);
+        msg_without_sys_dependent_data =
+            regex_replace(msg_without_sys_dependent_data, python_path,
+                    ": /path/python");
+
         boost::regex except_display("<type 'exceptions.([a-z]+)'>",
                                     boost::regex::perl|boost::regex::icase);
         msg_without_sys_dependent_data =



From tihocan at mail.berlios.de  Fri Dec 14 18:30:34 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 18:30:34 +0100
Subject: [Plearn-commits] r8351 -
	trunk/plearn/python/test/.pytest/EmbeddedPython_InterfunctionXchg/expected_results
Message-ID: <200712141730.lBEHUYnj029332@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 18:30:32 +0100 (Fri, 14 Dec 2007)
New Revision: 8351

Modified:
   trunk/plearn/python/test/.pytest/EmbeddedPython_InterfunctionXchg/expected_results/RUN.log
Log:
Updated test result following recent commit

Modified: trunk/plearn/python/test/.pytest/EmbeddedPython_InterfunctionXchg/expected_results/RUN.log
===================================================================
--- trunk/plearn/python/test/.pytest/EmbeddedPython_InterfunctionXchg/expected_results/RUN.log	2007-12-14 17:27:22 UTC (rev 8350)
+++ trunk/plearn/python/test/.pytest/EmbeddedPython_InterfunctionXchg/expected_results/RUN.log	2007-12-14 17:30:32 UTC (rev 8351)
@@ -17,7 +17,7 @@
 Read back the string: 'This string should survive within the Python environment'
 Trying to read back from second snippet:
 Caught Python Exception: 'NameError
-Python 2.X.Y: /usr/bin/python
+Python 2.X.Y: /path/python
 
 
 A problem occurred in a Python script.  Here is the sequence of



From tihocan at mail.berlios.de  Fri Dec 14 18:31:57 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 18:31:57 +0100
Subject: [Plearn-commits] r8352 - trunk/plearn/base
Message-ID: <200712141731.lBEHVvED000066@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 18:31:57 +0100 (Fri, 14 Dec 2007)
New Revision: 8352

Modified:
   trunk/plearn/base/ms_hash_wrapper.h
Log:
Fix for ICC 10.0 that uses GNU includes instead of Intel includes

Modified: trunk/plearn/base/ms_hash_wrapper.h
===================================================================
--- trunk/plearn/base/ms_hash_wrapper.h	2007-12-14 17:30:32 UTC (rev 8351)
+++ trunk/plearn/base/ms_hash_wrapper.h	2007-12-14 17:31:57 UTC (rev 8352)
@@ -49,7 +49,8 @@
 #  include <ext/hash_set> //to get stl_hash_fun.h ... (template<> class hash)
 #  include <ext/hash_map> //to get stl_hash_fun.h ... (template<> class hash)
 
-#	if (__GNUC__ == 3 && __GNUC_MINOR__ == 0) || defined(__INTEL_COMPILER) // GCC 3.0 or ICC
+#	if (__GNUC__ == 3 && __GNUC_MINOR__ == 0) || (defined(__INTEL_COMPILER) && __INTEL_COMPILER < 1000)
+//              GCC 3.0 or ICC < 10.0
 #		define __NMSPACE__ std
 #  else                                            // GCC 3.1 or later
 using namespace __gnu_cxx;



From tihocan at mail.berlios.de  Fri Dec 14 19:08:44 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 19:08:44 +0100
Subject: [Plearn-commits] r8353 - in trunk/plearn/base/test: .
	.pytest/PL_check/expected_results
Message-ID: <200712141808.lBEI8iK7016048@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 19:08:44 +0100 (Fri, 14 Dec 2007)
New Revision: 8353

Modified:
   trunk/plearn/base/test/.pytest/PL_check/expected_results/RUN.log
   trunk/plearn/base/test/PLCheckTest.cc
Log:
Removed virtual from output (ICC does not display it)

Modified: trunk/plearn/base/test/.pytest/PL_check/expected_results/RUN.log
===================================================================
--- trunk/plearn/base/test/.pytest/PL_check/expected_results/RUN.log	2007-12-14 17:31:57 UTC (rev 8352)
+++ trunk/plearn/base/test/.pytest/PL_check/expected_results/RUN.log	2007-12-14 18:08:44 UTC (rev 8353)
@@ -1,5 +1,5 @@
 FATAL ERROR: Check failed: ein == stein
-Function: virtual void PLearn::PLCheckTest::perform()
+Function: void PLearn::PLCheckTest::perform()
     File: PLCheckTest.cc
-    Line: 108
+    Line: 116
  Message: ein != stein

Modified: trunk/plearn/base/test/PLCheckTest.cc
===================================================================
--- trunk/plearn/base/test/PLCheckTest.cc	2007-12-14 17:31:57 UTC (rev 8352)
+++ trunk/plearn/base/test/PLCheckTest.cc	2007-12-14 18:08:44 UTC (rev 8353)
@@ -38,6 +38,7 @@
 
 
 #include "PLCheckTest.h"
+#include <plearn/base/stringutils.h>
 
 namespace PLearn {
 using namespace std;
@@ -104,6 +105,13 @@
 #undef __FILE__
 #define __FILE__ "PLCheckTest.cc"
 
+// Similarly, PLCHECK uses __PRETTY_FUNCTION__, but we want the test to have
+// the same output regardless of small variations in the function display.
+// In particular, GCC displays the 'virtual' keyword, but not ICC.
+    string pl_assert_func = PL_ASSERT_FUNCTION;
+    search_replace(pl_assert_func, "virtual", "");
+#undef PL_ASSERT_FUNCTION
+#define PL_ASSERT_FUNCTION (pl_assert_func.c_str())
     PLCHECK( one == ein );
     PLCHECK_MSG( ein == stein, "ein != stein" );
 }



From tihocan at mail.berlios.de  Fri Dec 14 19:43:44 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 19:43:44 +0100
Subject: [Plearn-commits] r8354 - trunk/plearn/base
Message-ID: <200712141843.lBEIhibP018133@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 19:43:44 +0100 (Fri, 14 Dec 2007)
New Revision: 8354

Modified:
   trunk/plearn/base/pl_hash_fun.h
Log:
Fix for ICC 10

Modified: trunk/plearn/base/pl_hash_fun.h
===================================================================
--- trunk/plearn/base/pl_hash_fun.h	2007-12-14 18:08:44 UTC (rev 8353)
+++ trunk/plearn/base/pl_hash_fun.h	2007-12-14 18:43:44 UTC (rev 8354)
@@ -79,10 +79,11 @@
 
 ///////////////////////////////////////////////////////////////////////////
 
-#if defined(__GNUC__) && defined(__INTEL_COMPILER)
-// Intel Compiler on Linux: we need to define a hash function for const char*.
+#if defined(__GNUC__) && defined(__INTEL_COMPILER) && __INTEL_COMPILER < 1000
+// Intel Compiler (before 10.0) on Linux: we need to define a hash function for
+// const char*.
 SET_HASH_WITH_FUNCTION_NOCONSTREF(const char*, _s, PLearn::hashval(_s))
-#endif // __GNUC__
+#endif
 
     SET_HASH_WITH_INHERITANCE(std::string, const char*, __s, __s.c_str())
 



From tihocan at mail.berlios.de  Fri Dec 14 19:46:35 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 19:46:35 +0100
Subject: [Plearn-commits] r8355 - trunk
Message-ID: <200712141846.lBEIkZJk018297@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 19:46:34 +0100 (Fri, 14 Dec 2007)
New Revision: 8355

Modified:
   trunk/pymake.config.model
Log:
Fixes for compilation on mammouth

Modified: trunk/pymake.config.model
===================================================================
--- trunk/pymake.config.model	2007-12-14 18:43:44 UTC (rev 8354)
+++ trunk/pymake.config.model	2007-12-14 18:46:34 UTC (rev 8355)
@@ -253,7 +253,7 @@
 # First option that appears in each group is the default, and is assumed if you
 # do not specify any option from that group.
 options_choices = [
-  [ 'g++', 'g++3', 'g++no-cygwin', 'icc', 'icc8', 'icc9', 'mpi',
+  [ 'g++', 'g++3', 'g++no-cygwin', 'icc', 'icc8', 'icc9', 'icc10', 'mpi',
     'purify', 'quantify', 'vc++', 'condor' ],
   
   [ 'dbg', 'opt', 'pintel', 'gprof', 'optdbggprof', 'safegprof',
@@ -299,6 +299,7 @@
 if not 'nopython' in optionargs:
     # First find which version of python is installed.
     python_includedirs=[]
+    numpy_includedirs = []
     if domain_name.endswith('iro.umontreal.ca'):
         optionargs += [ pyoption ]
         python_version = pyver
@@ -312,16 +313,15 @@
             numpy_site_packages = []
             numpy_includedirs = []
         else:
-            numpy_includedirs = [ '/u/lisa/local/' + target_platform + '/include/', '/usr/include/python'+python_version ]
+          nothing_to_do = True
+          #numpy_includedirs = [ '/u/lisa/local/' + target_platform + '/include/', '/usr/include/python'+python_version ]
             ### NB: The '-lutil' is necessary on i386 LISA computers.
-            numpy_site_packages = '/u/lisa/local/' + target_platform + '/lib/python%s/site-packages/numarray -lutil' % pyver
-    elif domain_name.endswith('.ms'):
-        numpy_includedirs = []
-        numpy_site_packages = join(homedir, '../delallea/local/lib/python2.5/site-packages/numarray -lutil')
-        optionargs += [ 'python25' ]
+            #numpy_site_packages = '/u/lisa/local/' + target_platform + '/lib/python%s/site-packages/numarray -lutil' % pyver
+    elif domain_name.endswith('.m'):
+        #numpy_site_packages = join(homedir, '../delallea/local/lib/python2.5/site-packages/numarray -lutil')
         python_version = '2.5'
+        optionargs += [ 'python%s' % python_version.replace('.', '') ]
         python_lib_root = '/home/delallea/local/lib'
-        linkeroptions_tail += '-lunwind -lcprts' # -lgcc_eh
     elif domain_name.endswith('.rqchp.qc.ca'):
         numpy_includedirs   = [ '/usr/network.ALTIX/python-2.4.1/include' ]
         numpy_site_packages = join(homedir, '../delallea/local/lib/python2.4/site-packages/numarray -lutil')
@@ -393,9 +393,9 @@
                   ' or compile using another version of python.'
             sys.exit(100)
 
-    numpy_lib= ' -lnumarray '
-    if 'numpy' in optionargs:
-        numpy_lib= '/_capi.so -lutil '
+    #numpy_lib= ' -lnumarray '
+    #if 'numpy' in optionargs:
+      #numpy_lib= '/_capi.so -lutil '
 
     if platform == 'darwin':
         optionalLibrary( name = 'python',
@@ -416,11 +416,9 @@
         optionalLibrary( name = 'python',
                      triggers = '[Pp]ython*',
                      includedirs = numpy_includedirs,
-                     linkeroptions = ( '%s%s ' % (numpy_site_packages, numpy_lib) + 
-                                       '-L%s/python%s/config -lpython%s ' % (python_lib_root, python_version, python_version) +
-                                       '-Xlinker -export-dynamic ' + 
-                                       '-Xlinker -rpath -Xlinker %s' % numpy_site_packages )
-                     )
+                     linkeroptions = ( '-L%s/python%s/config -lpython%s ' % \
+                         (python_lib_root, python_version, python_version ) +
+                         ' -Xlinker -export-dynamic -lutil '))
 else:
     python_version = '' # should not be used anyway
 
@@ -588,6 +586,17 @@
               linker = icc9_exec + ' '
               )
 
+pymakeOption( name = 'icc10',   # For C++, it is actually icpc
+              description = 'compiling with Intel Compiler (version 10.x), with no MPI support',
+              # Disable some warnings:
+              # remark #981: operands are evaluated in unspecified order
+              # remark #383: value copied to temporary, reference to temporary used
+              # remark #1418: external function definition with no prior declaration
+              compiler = 'icpc -wd981 -wd383 -wd1418',
+              cpp_definitions = ['USING_MPI=0'],
+              linker = 'icpc  '
+              )
+
 pymakeOption( name = 'mpi',
               description = 'compiling and linking with MPI support (and USING_MPI=1)',
               compiler = 'mpiCC',
@@ -787,7 +796,7 @@
 
 pymakeLinkOption( name = 'mammouthblas',
               description = 'linking BLAS for P4 Mammouth-Serie cluster',
-              linkeroptions = '-L/opt/mkl/lib/32 -lmkl_p4 -lmkl_vml_p4 -lpthread -lmkl_lapack' )
+              linkeroptions = '-L/opt/intel/mkl/10.0.011/lib/32 -lmkl -openmp' ) #-lmkl_lapack -lmkl_p4 -lmkl_vml_p4 -lpthread ' )
 
 pymakeLinkOption( name = 'apintelblas',
               description = 'Intel BLAS+LAPACK for generic install in /usr/local/lib (incl. ApSTAT)',



From tihocan at mail.berlios.de  Fri Dec 14 20:47:47 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 14 Dec 2007 20:47:47 +0100
Subject: [Plearn-commits] r8356 - trunk/plearn/base/test
Message-ID: <200712141947.lBEJllv3021261@sheep.berlios.de>

Author: tihocan
Date: 2007-12-14 20:47:46 +0100 (Fri, 14 Dec 2007)
New Revision: 8356

Modified:
   trunk/plearn/base/test/PLCheckTest.cc
Log:
Fixed test with GCC (error introduced in recent commit)

Modified: trunk/plearn/base/test/PLCheckTest.cc
===================================================================
--- trunk/plearn/base/test/PLCheckTest.cc	2007-12-14 18:46:34 UTC (rev 8355)
+++ trunk/plearn/base/test/PLCheckTest.cc	2007-12-14 19:47:46 UTC (rev 8356)
@@ -109,7 +109,7 @@
 // the same output regardless of small variations in the function display.
 // In particular, GCC displays the 'virtual' keyword, but not ICC.
     string pl_assert_func = PL_ASSERT_FUNCTION;
-    search_replace(pl_assert_func, "virtual", "");
+    search_replace(pl_assert_func, "virtual ", "");
 #undef PL_ASSERT_FUNCTION
 #define PL_ASSERT_FUNCTION (pl_assert_func.c_str())
     PLCHECK( one == ein );



From dumitruerhan at mail.berlios.de  Fri Dec 14 21:14:06 2007
From: dumitruerhan at mail.berlios.de (dumitruerhan at BerliOS)
Date: Fri, 14 Dec 2007 21:14:06 +0100
Subject: [Plearn-commits] r8357 - trunk/plearn_learners/online
Message-ID: <200712142014.lBEKE6P7022653@sheep.berlios.de>

Author: dumitruerhan
Date: 2007-12-14 21:14:05 +0100 (Fri, 14 Dec 2007)
New Revision: 8357

Modified:
   trunk/plearn_learners/online/RBMModule.cc
Log:
We want this error when compiling in -opt too

Modified: trunk/plearn_learners/online/RBMModule.cc
===================================================================
--- trunk/plearn_learners/online/RBMModule.cc	2007-12-14 19:47:46 UTC (rev 8356)
+++ trunk/plearn_learners/online/RBMModule.cc	2007-12-14 20:14:05 UTC (rev 8357)
@@ -1457,7 +1457,7 @@
         connection->accumulatePosStats(*visible,*hidden);
 
         // negative phase
-        PLASSERT_MSG(hidden_layer->size<32 || visible_layer->size<32,
+        PLCHECK_MSG(hidden_layer->size<32 || visible_layer->size<32,
                      "To minimize exact log-likelihood of an RBM, hidden_layer->size "
                      "or visible_layer->size must be <32");
         // gradient of partition function



From dumitruerhan at mail.berlios.de  Fri Dec 14 21:15:35 2007
From: dumitruerhan at mail.berlios.de (dumitruerhan at BerliOS)
Date: Fri, 14 Dec 2007 21:15:35 +0100
Subject: [Plearn-commits] r8358 - trunk/plearn_learners/online
Message-ID: <200712142015.lBEKFZ91022767@sheep.berlios.de>

Author: dumitruerhan
Date: 2007-12-14 21:15:34 +0100 (Fri, 14 Dec 2007)
New Revision: 8358

Modified:
   trunk/plearn_learners/online/RBMLayer.cc
   trunk/plearn_learners/online/RBMLayer.h
Log:
Added an option to decay biases in an RBM layer. Use with caution. Default is no decay (like before)

Modified: trunk/plearn_learners/online/RBMLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMLayer.cc	2007-12-14 20:14:05 UTC (rev 8357)
+++ trunk/plearn_learners/online/RBMLayer.cc	2007-12-14 20:15:34 UTC (rev 8358)
@@ -55,6 +55,8 @@
     learning_rate(the_learning_rate),
     momentum(0.),
     size(-1),
+    bias_decay_type("none"),
+    bias_decay_parameter(0),
     gibbs_ma_increment(0.1),
     gibbs_initial_ma_coefficient(0.1),
     batch_size(0),
@@ -109,6 +111,17 @@
                   OptionBase::buildoption,
                   "Momentum.");
 
+    declareOption(ol, "bias_decay_type", &RBMLayer::bias_decay_type,
+                  OptionBase::buildoption,
+                  "Bias decay type:\n"
+                  " - none: no decay applied\n"
+                  " - negative: pushes the biases towards -\\infty\n"
+                  " - l2: applies an l2 penalty");
+
+    declareOption(ol, "bias_decay_parameter", &RBMLayer::bias_decay_parameter,
+                  OptionBase::buildoption,
+                  "Bias decay parameter.");
+
     declareOption(ol, "gibbs_ma_schedule", &RBMLayer::gibbs_ma_schedule,
                   OptionBase::buildoption,
                   "Each element of this vector is a number of updates after which\n"
@@ -394,6 +407,8 @@
         }
     }
 
+    applyBiasDecay();
+    
     clearStats();
 }
 
@@ -419,6 +434,8 @@
             b[i] += binc[i];
         }
     }
+
+    applyBiasDecay();
 }
 
 void RBMLayer::update( const Vec& pos_values, const Vec& neg_values)
@@ -443,6 +460,9 @@
             b[i] += binc[i];
         }
     }
+
+    applyBiasDecay();
+
 }
 
 void RBMLayer::update( const Mat& pos_values, const Mat& neg_values)
@@ -480,6 +500,9 @@
         }
         */
     }
+
+    applyBiasDecay();
+
 }
 
 //////////////////////
@@ -522,6 +545,9 @@
     columnSum(cd_neg_values, tmp);
     multiplyAcc(bias, tmp,
                 -learning_rate*(1-background_gibbs_update_ratio)*normalize_factor);
+
+    applyBiasDecay();
+
 }
 
 /////////////////
@@ -564,6 +590,9 @@
     columnSum(pos_values,tmp);
     multiplyAcc(bias, tmp, learning_rate*normalize_factor);
     multiplyAcc(bias, bias_neg_stats, -learning_rate);
+
+    applyBiasDecay();
+
 }
 
 ////////////////
@@ -628,6 +657,9 @@
 
     for( int i=0 ; i<size ; i++ )
         bg[i] = -bps[i]/pos_count + bns[i]/neg_count;
+
+    addBiasDecay(bias_gradient);
+
 }
 
 void RBMLayer::bpropCD(const Vec& pos_values, const Vec& neg_values,
@@ -641,6 +673,9 @@
 
     for( int i=0 ; i<size ; i++ )
         bg[i] = -bps[i] + bns[i];
+    
+    addBiasDecay(bias_gradient);
+
 }
 
 real RBMLayer::energy(const Vec& unit_values) const
@@ -666,6 +701,49 @@
     PLERROR("RBMLayer::getConfiguration(int, Vec) not implemented in subclass %s\n",classname().c_str());
 }
 
+
+void RBMLayer::addBiasDecay(Vec& bias_gradient)
+{
+    PLASSERT(bias_gradient.size()==size);
+
+    real *bg = bias_gradient.data();
+    real *b = bias.data();
+    bias_decay_type = lowerstring(bias_decay_type);
+
+    if (bias_decay_type=="none")
+        {}
+    else if (bias_decay_type=="negative")  // Pushes the biases towards -\infty
+        for( int i=0 ; i<size ; i++ )
+            bg[i] += learning_rate * bias_decay_parameter;
+    else if (bias_decay_type=="l2")  // L2 penalty on the biases
+        for (int i=0 ; i<size ; i++ )
+            bg[i] += learning_rate * bias_decay_parameter * b[i];
+    else
+        PLERROR("RBMLayer::addBiasDecay(string) bias_decay_type %s is not in"
+                " the list, in subclass %s\n",bias_decay_type.c_str(),classname().c_str());
+
+}
+
+void RBMLayer::applyBiasDecay()
+{
+    
+    PLASSERT(bias.size()==size);
+
+    real* b = bias.data();
+    bias_decay_type = lowerstring(bias_decay_type);
+
+    if (bias_decay_type=="none")
+        {}
+    else if (bias_decay_type=="negative") // Pushes the biases towards -\infty
+        for( int i=0 ; i<size ; i++ )
+            b[i] -= learning_rate * bias_decay_parameter;
+    else if (bias_decay_type=="l2") // L2 penalty on the biases
+        bias *= (1 - learning_rate * bias_decay_parameter);
+    else 
+        PLERROR("RBMLayer::applyBiasDecay(string) bias_decay_type %s is not in"
+                " the list, in subclass %s\n",bias_decay_type.c_str(),classname().c_str());
+
+}   
 } // end of namespace PLearn
 
 

Modified: trunk/plearn_learners/online/RBMLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMLayer.h	2007-12-14 20:14:05 UTC (rev 8357)
+++ trunk/plearn_learners/online/RBMLayer.h	2007-12-14 20:15:34 UTC (rev 8358)
@@ -72,6 +72,12 @@
     //! Obsolete option, still here for script compatibility
     string units_types;
 
+    //! Type of decay applied to the biases
+    string bias_decay_type;
+
+    //! Bias decay parameter
+    real bias_decay_parameter;
+
     //! background gibbs chain options
     //! each element of this vector is a number of updates after which
     //! the moving average coefficient is incremented (by incrementing
@@ -285,6 +291,12 @@
     //! Computes the conf_index configuration of the layer.
     virtual void getConfiguration(int conf_index, Vec& output);
 
+    //! Applies the bias decay
+    virtual void applyBiasDecay();
+
+    //! Adds the bias decay to the bias gradients
+    virtual void addBiasDecay(Vec& bias_gradient);
+
     //#####  PLearn::Object Protocol  #########################################
 
     // Declares other standard object methods.



From plearner at mail.berlios.de  Mon Dec 17 23:39:48 2007
From: plearner at mail.berlios.de (plearner at BerliOS)
Date: Mon, 17 Dec 2007 23:39:48 +0100
Subject: [Plearn-commits] r8359 - in trunk: commands/EXPERIMENTAL
	plearn/display plearn/math plearn/var plearn/var/EXPERIMENTAL
	plearn_learners/generic/EXPERIMENTAL python_modules/plearn/var
Message-ID: <200712172239.lBHMdmtf009979@sheep.berlios.de>

Author: plearner
Date: 2007-12-17 23:39:46 +0100 (Mon, 17 Dec 2007)
New Revision: 8359

Added:
   trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.cc
   trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.h
   trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.cc
   trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.h
   trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.cc
   trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.h
Modified:
   trunk/commands/EXPERIMENTAL/plearn_exp.cc
   trunk/plearn/display/DisplayUtils.cc
   trunk/plearn/math/TMat_decl.h
   trunk/plearn/var/EXPERIMENTAL/MultiSampleVariable.cc
   trunk/plearn/var/NegCrossEntropySigmoidVariable.cc
   trunk/plearn/var/UnaryVariable.cc
   trunk/plearn/var/UnaryVariable.h
   trunk/plearn/var/Variable.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
   trunk/python_modules/plearn/var/Var.py
Log:
- New var classes to be used within DeepReconstructorNet
- Minor fixes to a few existing classes (mostly doc fixes or warning removal)


Modified: trunk/commands/EXPERIMENTAL/plearn_exp.cc
===================================================================
--- trunk/commands/EXPERIMENTAL/plearn_exp.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/commands/EXPERIMENTAL/plearn_exp.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -370,13 +370,18 @@
 #include <plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.h>
 #include <plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h>
 #include <plearn/var/SourceVariable.h>
+#include <plearn/var/ConcatColumnsVariable.h>
+#include <plearn/var/ConcatRowsVariable.h>
 #include <plearn/var/ExpVariable.h>
 #include <plearn/var/SigmoidVariable.h>
 #include <plearn/var/ProductTransposeVariable.h>
 #include <plearn/var/NegCrossEntropySigmoidVariable.h>
 #include <plearn/var/LogSoftmaxVariable.h>
 #include <plearn/var/ClassificationLossVariable.h>
-// #include <plearn/var/EXPERIMENTAL/MultiSampleVariable.h>
+#include <plearn/var/EXPERIMENTAL/MultiSampleVariable.h>
+#include <plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.h>
+#include <plearn/var/EXPERIMENTAL/BernoulliSampleVariable.h>
+#include <plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.h>
 
 // Stuff used for transformationLearner experiments
 #include <plearn_learners/distributions/EXPERIMENTAL/TransformationLearner.h>

Modified: trunk/plearn/display/DisplayUtils.cc
===================================================================
--- trunk/plearn/display/DisplayUtils.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/display/DisplayUtils.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -89,7 +89,7 @@
 
   real color_luminance_to_rgbreal(int colornum, real luminance)
   {
-    real r,g,b;
+    real r=0, g=0, b=0;
     color_luminance_to_rgb(colornum, luminance, r, g, b);
     return rgb2real(r,g,b);
   }

Modified: trunk/plearn/math/TMat_decl.h
===================================================================
--- trunk/plearn/math/TMat_decl.h	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/math/TMat_decl.h	2007-12-17 22:39:46 UTC (rev 8359)
@@ -253,6 +253,16 @@
     inline int mod() const
     { return mod_; }
 
+    //! returns true if matrix elements are contiguous in memory
+    //! (i.e. no gap between last element of a row and first element of next row).
+    inline bool isContiguous() const
+    { return mod_==width_; }
+
+    //! returns true if matrix elements are not contiguous in memory
+    //! (i.e. there is a gap between last element of a row and first element of next row).
+    inline bool isNotContiguous() const
+    { return mod_!=width_; }
+
     //! Set a new value for 'mod'. The content of the matrix will be destroyed
     //! (i.e. moved around). In addition, if the new mod is strictly less than
     //! the width, the width will be set to this new mod (in order to ensure it

Added: trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -0,0 +1,164 @@
+// -*- C++ -*-
+
+// BernoulliSampleVariable.cc
+//
+// Copyright (C) 2007 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file BernoulliSampleVariable.cc */
+
+
+#include "BernoulliSampleVariable.h"
+
+namespace PLearn {
+using namespace std;
+
+/** BernoulliSampleVariable **/
+
+PLEARN_IMPLEMENT_OBJECT(
+    BernoulliSampleVariable,
+    "Input gives a vector of parameters, each of which is the probability parameter of a Bernoulli. Output is sample from those." ,
+    "\n"
+    );
+
+
+//! Constructor
+
+BernoulliSampleVariable::BernoulliSampleVariable(Variable* input)
+    : inherited(input, input->length(), input->width()),
+      random_gen(0)
+{
+    build_();
+}
+
+void BernoulliSampleVariable::recomputeSize(int& l, int& w) const
+{
+    if (input) {
+        l = input->length();
+        w = input->width() ;
+    } else
+        l = w = 0;
+}
+
+// ### computes value from input's value
+void BernoulliSampleVariable::fprop()
+{
+    checkContiguity();
+
+    if(random_gen.isNull())
+        random_gen = PRandom::common(false);
+
+    int l = nelems();
+    real* valueptr = valuedata;
+    real* inputvalueptr = input->valuedata;
+    for(int i=0; i<l; i++)
+        *valueptr++ = random_gen->binomial_sample(*inputvalueptr++);
+}
+
+// ### computes input's gradient from gradient
+void BernoulliSampleVariable::bprop()
+{}    
+
+// ### You can implement these methods:
+// void BernoulliSampleVariable::bbprop() {}
+// void BernoulliSampleVariable::symbolicBprop() {}
+// void BernoulliSampleVariable::rfprop() {}
+
+
+// ### Nothing to add here, simply calls build_
+void BernoulliSampleVariable::build()
+{
+    inherited::build();
+    build_();
+}
+
+void BernoulliSampleVariable::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all "pointer-like" fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    deepCopyField(random_gen, copies);
+    // ### If you want to deepCopy a Var field:
+    // varDeepCopyField(somevariable, copies);   
+}
+
+void BernoulliSampleVariable::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    // ### ex:
+    declareOption(ol, "random_gen", &BernoulliSampleVariable::random_gen,
+                  OptionBase::buildoption,
+                  "Random number generator. If null, the PRandom::common(false) generator will be used.");
+            
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void BernoulliSampleVariable::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.h	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/EXPERIMENTAL/BernoulliSampleVariable.h	2007-12-17 22:39:46 UTC (rev 8359)
@@ -0,0 +1,154 @@
+// -*- C++ -*-
+
+// BernoulliSampleVariable.h
+//
+// Copyright (C) 2007 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file BernoulliSampleVariable.h */
+
+
+#ifndef BernoulliSampleVariable_INC
+#define BernoulliSampleVariable_INC
+
+#include <plearn/var/UnaryVariable.h>
+#include <plearn/math/PRandom.h>
+
+namespace PLearn {
+using namespace std;
+
+/*! * BernoulliSampleVariable * */
+
+/**
+ * 
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class BernoulliSampleVariable : public UnaryVariable
+{
+    typedef UnaryVariable inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    PP<PRandom> random_gen;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor, usually does nothing
+    BernoulliSampleVariable()
+    {}
+
+
+    // ### If your class has parameters, you probably want a constructor that
+    // ### initializes them
+    BernoulliSampleVariable(Variable* input);
+
+    // Your other public member functions go here
+
+    //#####  PLearn::Variable methods #########################################
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void recomputeSize(int& l, int& w) const;
+    virtual void fprop();
+    virtual void bprop();
+
+    // ### These ones are not always implemented
+    // virtual void bbprop();
+    // virtual void symbolicBprop();
+    // virtual void rfprop();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(BernoulliSampleVariable);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(BernoulliSampleVariable);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Modified: trunk/plearn/var/EXPERIMENTAL/MultiSampleVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/MultiSampleVariable.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/EXPERIMENTAL/MultiSampleVariable.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -75,6 +75,9 @@
 // ### computes value from input's value
 void MultiSampleVariable::fprop()
 {
+    if(random_gen.isNull())
+        random_gen = PRandom::common(false);
+
     int k;
     Mat inputValue = input->matValue;
 
@@ -149,7 +152,7 @@
 
     declareOption(ol, "random_gen", &MultiSampleVariable::random_gen,
                   OptionBase::buildoption,
-                  "random generator");
+                  "Random number generator. If null, the PRandom::common(false) generator will be used.");
             
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
@@ -172,11 +175,6 @@
         PLERROR("Groupsize(s) not specified or invalid in MultiSampleVariable");    
     if (input->width() % groupsize != 0)
         PLERROR("Invalid groupsize in MultiSampleVariable (%i does not divide %i)", groupsize, input->width());
-
-    
-    if(random_gen == NULL)
-        random_gen = new PRandom();
-    
 }
 
 

Added: trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -0,0 +1,203 @@
+// -*- C++ -*-
+
+// RandomForcedValuesVariable.cc
+//
+// Copyright (C) 2007 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file RandomForcedValuesVariable.cc */
+
+
+#include "RandomForcedValuesVariable.h"
+
+namespace PLearn {
+using namespace std;
+
+/** RandomForcedValuesVariable **/
+
+PLEARN_IMPLEMENT_OBJECT(
+    RandomForcedValuesVariable,
+    "ONE LINE USER DESCRIPTION",
+    "MULTI LINE\nHELP FOR USERS"
+    );
+
+RandomForcedValuesVariable::RandomForcedValuesVariable()
+    :forcing_prob(0),
+     forcing_value(0)
+
+    /* ### Initialize all fields to their default value */
+{
+    // ### You may (or not) want to call build_() to finish building the object
+    // ### (doing so assumes the parent classes' build_() have been called too
+    // ### in the parent classes' constructors, something that you must ensure)
+}
+
+// constructor from input variable and parameters
+// RandomForcedValuesVariable::RandomForcedValuesVariable(Variable* input, param_type the_parameter,...)
+// ### replace with actual parameters
+//  : inherited(input, this_variable_length, this_variable_width),
+//    parameter(the_parameter),
+//    ...
+//{
+//    // ### You may (or not) want to call build_() to finish building the
+//    // ### object
+//}
+
+void RandomForcedValuesVariable::recomputeSize(int& l, int& w) const
+{
+    if (input) 
+    {
+        l = input.length();
+        w = input.width(); // the computed width
+    } 
+    else
+        l = w = 0;
+}
+
+// ### computes value from input's value
+void RandomForcedValuesVariable::fprop()
+{
+    checkContiguity();
+
+    if(random_gen.isNull())
+        random_gen = PRandom::common(false);
+
+
+    int n = value.length();
+    forced.resize(n);
+
+    for(int i=0; i<n; i++)
+    {
+        if(random_gen->uniform_sample()<forcing_prob)
+        {
+            valuedata[i] = forcing_value;
+            forced[i] = true;
+        }
+        else
+        {
+            valuedata[i] = input->valuedata[i];
+            forced[i] = false;
+        }
+    }
+}
+
+// ### computes input's gradient from gradient
+void RandomForcedValuesVariable::bprop()
+{
+    int n = gradient.length();
+    for(int i=0; i<n; i++)
+    {
+        if(!forced[i])
+            input->gradientdata[i] += gradientdata[i];
+    }
+}
+
+// ### You can implement these methods:
+// void RandomForcedValuesVariable::bbprop() {}
+// void RandomForcedValuesVariable::symbolicBprop() {}
+// void RandomForcedValuesVariable::rfprop() {}
+
+
+// ### Nothing to add here, simply calls build_
+void RandomForcedValuesVariable::build()
+{
+    inherited::build();
+    build_();
+}
+
+void RandomForcedValuesVariable::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all "pointer-like" fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    deepCopyField(random_gen, copies);
+
+    // ### If you want to deepCopy a Var field:
+    // varDeepCopyField(somevariable, copies);
+}
+
+void RandomForcedValuesVariable::declareOptions(OptionList& ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the "flags" of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    declareOption(ol, "forcing_prob", &RandomForcedValuesVariable::forcing_prob,
+                  OptionBase::buildoption,
+                  "The probability of forcing each input to forcing_value");
+    declareOption(ol, "forcing_value", &RandomForcedValuesVariable::forcing_value,
+                  OptionBase::buildoption,
+                  "The value to which to set all inputs that have been elected to be forced.");
+    declareOption(ol, "random_gen", &RandomForcedValuesVariable::random_gen,
+                  OptionBase::buildoption,
+                  "Random number generator. If null, the PRandom::common(false) generator will be used.");
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void RandomForcedValuesVariable::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a "reloaded" object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or "re-building" of an object after a few "tuning"
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.h	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/EXPERIMENTAL/RandomForcedValuesVariable.h	2007-12-17 22:39:46 UTC (rev 8359)
@@ -0,0 +1,164 @@
+// -*- C++ -*-
+
+// RandomForcedValuesVariable.h
+//
+// Copyright (C) 2007 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Vincent
+
+/*! \file RandomForcedValuesVariable.h */
+
+
+#ifndef RandomForcedValuesVariable_INC
+#define RandomForcedValuesVariable_INC
+
+#include <plearn/var/UnaryVariable.h>
+#include <plearn/math/PRandom.h>
+
+namespace PLearn {
+using namespace std;
+
+/*! * RandomForcedValuesVariable * */
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class RandomForcedValuesVariable : public UnaryVariable
+{
+    typedef UnaryVariable inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    PP<PRandom> random_gen;
+    real forcing_prob;
+    real forcing_value;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor, usually does nothing
+    RandomForcedValuesVariable();
+
+    // ### If your class has parameters, you probably want a constructor that
+    // ### initializes them
+    // RandomForcedValuesVariable(Variable* input, param_type the_parameter, ...);
+
+    // Your other public member functions go here
+
+    //#####  PLearn::Variable methods #########################################
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void recomputeSize(int& l, int& w) const;
+    virtual void fprop();
+    virtual void bprop();
+
+    // ### These ones are not always implemented
+    // virtual void bbprop();
+    // virtual void symbolicBprop();
+    // virtual void rfprop();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(RandomForcedValuesVariable);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+    
+    // will contain true where features have been forced to forcing_value
+    TVec<bool> forced;
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(RandomForcedValuesVariable);
+
+// ### Put here a convenient method for building your variable.
+// ### e.g., if your class is TotoVariable, with two parameters foo_type foo
+// ### and bar_type bar, you could write:
+// inline Var toto(Var v, foo_type foo=default_foo, bar_type bar=default_bar)
+// { return new TotoVariable(v, foo, bar); }
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -0,0 +1,131 @@
+// -*- C++ -*-
+
+// TimesConstantScalarVariable2.cc
+//
+// Copyright (C) 2007 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************      
+ * $Id: TimesConstantScalarVariable2.cc 3994 2005-08-25 13:35:03Z chapados $
+ * This file is part of the PLearn library.
+ ******************************************************* */
+
+#include "TimesConstantScalarVariable2.h"
+#include <plearn/var/Var_operators.h>
+
+
+
+namespace PLearn {
+using namespace std;
+
+/** TimesConstantScalarVariable2 **/
+
+PLEARN_IMPLEMENT_OBJECT(TimesConstantScalarVariable2,
+                        "Multiplies the first var V1 by a scalar second var V2. The second var is assumed constant, and no gradient is backpropagated to it.",
+                        "NO HELP");
+
+TimesConstantScalarVariable2::TimesConstantScalarVariable2(Variable* input1, Variable* input2)
+    : inherited(input1, input2, input1->length(), input1->width())
+{
+    build_();
+}
+
+void
+TimesConstantScalarVariable2::build()
+{
+    inherited::build();
+    build_();
+}
+
+void
+TimesConstantScalarVariable2::build_()
+{
+    if (input2 && !input2->isScalar())
+        PLERROR("IN TimesConstantScalarVariable2: input2 is not a scalar");
+}
+
+void TimesConstantScalarVariable2::recomputeSize(int& l, int& w) const
+{
+    if (input1) {
+        l = input1->length();
+        w = input1->width();
+    } else
+        l = w = 0;
+}
+
+void TimesConstantScalarVariable2::fprop()
+{
+    real scal = input2->valuedata[0];
+    for(int k=0; k<nelems(); k++)
+        valuedata[k] = input1->valuedata[k] * scal;
+}
+
+
+void TimesConstantScalarVariable2::bprop()
+{
+    real scal = input2->valuedata[0];
+    for(int k=0; k<nelems(); k++)
+        input1->gradientdata[k] += scal*gradientdata[k];
+}
+
+
+void TimesConstantScalarVariable2::symbolicBprop()
+{
+    input1->accg(g*input2);
+}
+
+
+//R(x1x2)=R(x1)x2+x1R(x2)
+void TimesConstantScalarVariable2::rfprop()
+{
+    if (rValue.length()==0) resizeRValue();
+    real scal = input2->valuedata[0];
+    real rscal = input2->rvaluedata[0];
+    for(int k=0; k<nelems(); k++)
+        rvaluedata[k] = input1->rvaluedata[k] * scal + input1->valuedata[k] * rscal;
+}
+
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.h	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/EXPERIMENTAL/TimesConstantScalarVariable2.h	2007-12-17 22:39:46 UTC (rev 8359)
@@ -0,0 +1,96 @@
+// -*- C++ -*-
+
+// TimesConstantScalarVariable2.h
+//
+// Copyright (C) 2007 Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************      
+ * $Id: TimesConstantScalarVariable2.h 3994 2005-08-25 13:35:03Z chapados $
+ * This file is part of the PLearn library.
+ ******************************************************* */
+
+#ifndef TimesConstantScalarVariable2_INC
+#define TimesConstantScalarVariable2_INC
+
+#include <plearn/var/BinaryVariable.h>
+
+namespace PLearn {
+using namespace std;
+
+
+//!  multiplies a matrix var by a scalar var
+class TimesConstantScalarVariable2: public BinaryVariable
+{
+    typedef BinaryVariable inherited;
+
+public:
+    //!  Default constructor for persistence
+    TimesConstantScalarVariable2() {}
+    TimesConstantScalarVariable2(Variable* input1, Variable* input2);
+
+    PLEARN_DECLARE_OBJECT(TimesConstantScalarVariable2);
+
+    virtual void build();
+
+    virtual void recomputeSize(int& l, int& w) const;
+    virtual void fprop();
+    virtual void bprop();
+    virtual void symbolicBprop();
+    virtual void rfprop();
+
+protected:
+    void build_();
+};
+
+DECLARE_OBJECT_PTR(TimesConstantScalarVariable2);
+
+inline Var timesConstantScalar2(Var v, Var scalar) {
+    return new TimesConstantScalarVariable2(v, scalar);
+}
+
+
+} // end of namespace PLearn
+
+#endif 
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Modified: trunk/plearn/var/NegCrossEntropySigmoidVariable.cc
===================================================================
--- trunk/plearn/var/NegCrossEntropySigmoidVariable.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/NegCrossEntropySigmoidVariable.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -51,7 +51,8 @@
 PLEARN_IMPLEMENT_OBJECT(NegCrossEntropySigmoidVariable,
                         "Compute sigmoid of its first input, and then computes the negative "
                         "cross-entropy cost",
-                        "NO HELP");
+                        "Let o the first input ant t te second input, this computes\n"
+                        "result = - \sum_i t_i*log(o_i) + (1-t_i)*log(1-o_i)");
 
 ////////////////////////////////////
 // NegCrossEntropySigmoidVariable //

Modified: trunk/plearn/var/UnaryVariable.cc
===================================================================
--- trunk/plearn/var/UnaryVariable.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/UnaryVariable.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -101,6 +101,14 @@
     }
 }
 
+void UnaryVariable::checkContiguity() const
+{
+    if(matValue.isNotContiguous() 
+       || input->matValue.isNotContiguous()
+       || matGradient.isNotContiguous() 
+       || input->matGradient.isNotContiguous())
+        PLERROR("operation not currently implemented for non-contiguous matrix data");
+}
 
 VarArray UnaryVariable::sources() 
 { 
@@ -110,7 +118,6 @@
     return input->sources(); 
 }
 
-
 VarArray UnaryVariable::random_sources() 
 { 
     if (marked)

Modified: trunk/plearn/var/UnaryVariable.h
===================================================================
--- trunk/plearn/var/UnaryVariable.h	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/UnaryVariable.h	2007-12-17 22:39:46 UTC (rev 8359)
@@ -93,6 +93,10 @@
         pout << endl; 
     }
     virtual void resizeRValue();
+
+    //! will issue a PLERROR if any of the input or current value or gradient matrices are not contiguous.
+    void checkContiguity() const;
+
 };
 
 // Declares a few other classes and functions related to this class.

Modified: trunk/plearn/var/Variable.cc
===================================================================
--- trunk/plearn/var/Variable.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn/var/Variable.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -317,7 +317,7 @@
     else
         gradientdata = 0;
 }
-  
+
 //////////////
 // sizeprop //
 //////////////

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2007-12-17 22:39:46 UTC (rev 8359)
@@ -251,14 +251,14 @@
 
     supervised_costvec = hconcat(supervised_costs);
 
-
-    fullcost = supervised_costs[0];
+    if(supervised_costs.length()>0)
+        fullcost += supervised_costs[0];
     for(int i=1; i<supervised_costs.length(); i++)
-        fullcost = fullcost + supervised_costs[i];
+        fullcost += supervised_costs[i];
     
     int n_rec_costs = reconstruction_costs.length();
     for(int k=0; k<n_rec_costs; k++)
-        fullcost = fullcost + reconstruction_costs[k];
+        fullcost += reconstruction_costs[k];
     //displayVarGraph(fullcost);
     Var input = layers[0];
     Func f(input&target, fullcost);

Modified: trunk/python_modules/plearn/var/Var.py
===================================================================
--- trunk/python_modules/plearn/var/Var.py	2007-12-14 20:15:34 UTC (rev 8358)
+++ trunk/python_modules/plearn/var/Var.py	2007-12-17 22:39:46 UTC (rev 8359)
@@ -147,6 +147,12 @@
     def multiSample(self, gs):
         return Var(pl.MultiSampleVariable(input=self.v, groupsize=gs))
 
+    def bernoulliSample(self):
+        return Var(pl.BernoulliSampleVariable(input=self.v))
+
+    def timesConstantScalarVariable2(self, v2):
+        return Var(pl.TimesConstantScalarVariable2(input1=self.v, input2=v2.v))
+
     def transposeDoubleProduct(self, W, M):
         return Var(pl.TransposedDoubleProductVariable(varray=[self.v, W, M]))
 
@@ -170,6 +176,16 @@
 
     def __neg__(self):
         return self.neg()
+
+####################################################
+# Operations implemented as functions
+
+
+def hconcatVars(varlist):
+    return Var(pl.ConcatColumnsVariable(varray=varlist))
+
+def vconcatVars(varlist):
+    return Var(pl.ConcatRowsVariable(varray=varlist))
     
 
 ###################################################    



From nouiz at mail.berlios.de  Tue Dec 18 17:30:52 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Tue, 18 Dec 2007 17:30:52 +0100
Subject: [Plearn-commits] r8360 - trunk/plearn/math
Message-ID: <200712181630.lBIGUqNc010022@sheep.berlios.de>

Author: nouiz
Date: 2007-12-18 17:30:52 +0100 (Tue, 18 Dec 2007)
New Revision: 8360

Modified:
   trunk/plearn/math/RowMapSparseMatrix.h
Log:
corrected comment for doxygen


Modified: trunk/plearn/math/RowMapSparseMatrix.h
===================================================================
--- trunk/plearn/math/RowMapSparseMatrix.h	2007-12-17 22:39:46 UTC (rev 8359)
+++ trunk/plearn/math/RowMapSparseMatrix.h	2007-12-18 16:30:52 UTC (rev 8360)
@@ -828,7 +828,7 @@
         return MAX(end1->first, end2->first);
     }
 
-/*!       Export as matlab readable [i, j , v] format to file <out>
+/*!       Export as matlab readable [i, j , v] format to file 'filename'
   Matlab : (1) load <out> (2) A = spconvert(out)
   (note: the file extension must be '.dat')
 */



From dorionc at mail.berlios.de  Tue Dec 18 20:22:18 2007
From: dorionc at mail.berlios.de (dorionc at BerliOS)
Date: Tue, 18 Dec 2007 20:22:18 +0100
Subject: [Plearn-commits] r8361 - trunk/python_modules/plearn/parallel
Message-ID: <200712181922.lBIJMIGD008875@sheep.berlios.de>

Author: dorionc
Date: 2007-12-18 20:22:18 +0100 (Tue, 18 Dec 2007)
New Revision: 8361

Modified:
   trunk/python_modules/plearn/parallel/dispatch.py
Log:
Modified to facilitate its use for non-plearn program


Modified: trunk/python_modules/plearn/parallel/dispatch.py
===================================================================
--- trunk/python_modules/plearn/parallel/dispatch.py	2007-12-18 16:30:52 UTC (rev 8360)
+++ trunk/python_modules/plearn/parallel/dispatch.py	2007-12-18 19:22:18 UTC (rev 8361)
@@ -70,6 +70,12 @@
 LOGDIR        = None  # May be set by set_logdir()
 DOMAIN_NAME   = get_domain_name()
 
+# Configurables
+NICE          = 'nice'
+ARG_VALUE_FMT = "%s=%s"
+QUOTED_ARGS   = lambda L: ['"%s"'%elem for elem in L]
+
+
 #######  To be assigned to a subclass of TaskType when these will be declared
 Task = None
 
@@ -355,26 +361,45 @@
     listAvailableMachines = classmethod(listAvailableMachines)
 
     def nextAvailableMachine(cls):
-        # If a StopIteration exception is encountered on an already began
-        # loop, we simply have queried each machine once and shall start
-        # over. If such an exception is raise on a new loop, then no
-        # machines are currently available and we raise an
-        # EmptyTaskListError so as to wait a little while before querying
-        # again...
-        new_loop = False
-        if cls._available_machines is None:
-            cls._available_machines = cls.listAvailableMachines()            
-            new_loop = True
-
-        try:
-            return cls._available_machines.next()
-        except StopIteration:
-            cls._available_machines = None
-            if new_loop:
-                time.sleep(SLEEP_TIME)
-            return cls.nextAvailableMachine()
+        # If a StopIteration exception is encountered on an iteration
+        # already begun, we simply have queried each machine once and shall
+        # start over. If such an exception is raised on a fresh iterator,
+        # then no machines are currently available and we have to wait a
+        # little before querying again...
+        next = None
+        fresh_iterator = False
+        while next is None:
+            try:
+                next = cls._available_machines.next()
+            except (StopIteration, AttributeError), err:
+                if fresh_iterator:
+                    time.sleep(SLEEP_TIME)
+                cls._available_machines = cls.listAvailableMachines()
+                fresh_iterator = True
+        return next
     nextAvailableMachine = classmethod(nextAvailableMachine)
 
+    #TBR: def nextAvailableMachine(cls):
+    #TBR:     # If a StopIteration exception is encountered on an already began
+    #TBR:     # loop, we simply have queried each machine once and shall start
+    #TBR:     # over. If such an exception is raise on a new loop, then no
+    #TBR:     # machines are currently available and we raise an
+    #TBR:     # EmptyTaskListError so as to wait a little while before querying
+    #TBR:     # again...
+    #TBR:     new_loop = False
+    #TBR:     if cls._available_machines is None:
+    #TBR:         cls._available_machines = cls.listAvailableMachines()            
+    #TBR:         new_loop = True
+    #TBR:     
+    #TBR:     try:
+    #TBR:         return cls._available_machines.next()
+    #TBR:     except StopIteration:
+    #TBR:         cls._available_machines = None
+    #TBR:         if new_loop:
+    #TBR:             time.sleep(SLEEP_TIME)
+    #TBR:         return cls.nextAvailableMachine()
+    #TBR: nextAvailableMachine = classmethod(nextAvailableMachine)
+
     #
     # Instance methods
     #
@@ -382,7 +407,7 @@
     def getLaunchCommand(self):
         # Get the first available machine
         self.host = self.nextAvailableMachine()
-        actual_command = ' '.join(['cd', os.getcwd(), ';', 'nice'] + self.argv)
+        actual_command = ' '.join(['cd', os.getcwd(), ';', NICE] + self.argv)
         actual_command = actual_command.replace('"', r'\"')
         return 'ssh %s %s "%s"'%(self.host, self.Xopt, actual_command)
 
@@ -430,8 +455,6 @@
 
 class RejectedByPredicate( Exception ): pass
 
-## Under Development
-_quoted = lambda L: ['"%s"'%elem for elem in L]
 class Dispatch( PyPLearnObject ):
     # The name of the program to invoke
     program                  = PLOption(None)
@@ -489,7 +512,7 @@
 
           4) expdir_root      -> Experiments are cached.
 
-        Keys and values are joined using an equal sign ('=').
+        Keys and values are joined using the ARG_VALUE_FMT string.
         """
         self.program       = argument_bindings.pop( "_program_",       self.program )
         self.script        = argument_bindings.pop( "_script_",        self.script )
@@ -503,9 +526,9 @@
                 Experiment.cache_experiments( self.expdir_root )
         
         if self.protocol=="expkey":            
-            expkey = [ "%s=%s"%(k,v) for (k,v) in argument_bindings.iteritems() ]
+            expkey = [ ARG_VALUE_FMT%(k,v) for (k,v) in argument_bindings.iteritems() ]
             if not self._predicate( expkey ):
-                raise RejectedByPredicate( ' '.join(_quoted(expkey)) )
+                raise RejectedByPredicate( ' '.join(QUOTED_ARGS(expkey)) )
             return expkey
         elif self.protocol=="named_args":
             return [ arg%argument_bindings for arg in self.constant_args ]
@@ -523,7 +546,7 @@
             task_sum = 0
             delayed_tasks = 0
             for arguments_oracle in oracles:
-                assert isinstance( arguments_oracle, ArgumentsOracle ), TypeError(type(argumentsoracle))
+                assert isinstance( arguments_oracle, ArgumentsOracle ), TypeError(type(arguments_oracle))
                 done, delayed = self.__start( arguments_oracle )
                 task_sum += done
                 delayed_tasks += delayed
@@ -552,12 +575,14 @@
                 continue
 
             assert self.program
-            prepend = [ "echo", "$HOST;", 'nice', self.program ]
+            prepend = [ "echo", "$HOST;", NICE, self.program ]
             if self.script:
                 prepend.append( self.script )
             if self.protocol=="expkey":
                 prepend.extend( self.constant_args )
 
+            # No expdir is created if there is no script or if the script
+            # is not a pyplearn script
             if self.script.find( '.pyplearn' ) != -1:
                 expdir = None
                 for arg in arguments:
@@ -573,19 +598,19 @@
                     arguments.append( "expdir=%s" % expdir )
 
             # # Module function defined above
-            # launch_task( prepend+_quoted(arguments) )
+            # launch_task( prepend+QUOTED_ARGS(arguments) )
             assert Task is not None
-            ##TBM?: task = Task(prepend+_quoted(arguments)+[";", "echo", "'Task Done.'"])
+            ##TBM?: task = Task(prepend+QUOTED_ARGS(arguments)+[";", "echo", "'Task Done.'"])
             if self.delay:
                 ##TBM?: 
-                cmd = ' '.join(prepend+_quoted(arguments))
+                cmd = ' '.join(prepend+QUOTED_ARGS(arguments))
                 logging.info('Delayed: %s'%cmd)
                 ##TBM?: logging.info('Delayed: %s'%task.getLaunchCommand())
                 delayed += 1
                 ##TBM?: task.free() # Since it won't be launch, free the resources...
                 continue
             ##TBM?: 
-            task = Task(prepend+_quoted(arguments)+[";", "echo", "'Task Done.'"])
+            task = Task(prepend+QUOTED_ARGS(arguments)+[";", "echo", "'Task Done.'"])
             
             task.launch()
             if Task.count( ) == self.max_nmachines:



From dorionc at mail.berlios.de  Tue Dec 18 21:38:15 2007
From: dorionc at mail.berlios.de (dorionc at BerliOS)
Date: Tue, 18 Dec 2007 21:38:15 +0100
Subject: [Plearn-commits] r8362 - trunk/python_modules/plearn/parallel
Message-ID: <200712182038.lBIKcFGg017613@sheep.berlios.de>

Author: dorionc
Date: 2007-12-18 21:38:15 +0100 (Tue, 18 Dec 2007)
New Revision: 8362

Modified:
   trunk/python_modules/plearn/parallel/dispatch.py
Log:
Add OnHostTask support for unknown domains

Modified: trunk/python_modules/plearn/parallel/dispatch.py
===================================================================
--- trunk/python_modules/plearn/parallel/dispatch.py	2007-12-18 19:22:18 UTC (rev 8361)
+++ trunk/python_modules/plearn/parallel/dispatch.py	2007-12-18 20:38:15 UTC (rev 8362)
@@ -35,8 +35,9 @@
 #  These could be moved in a config file...
 #  ( cluster.config in .plearn )
 #
-TASK_TYPE_MAP    = { 'apstat.com':       'SshTask',
-                     'iro.umontreal.ca': 'ClusterTask'
+TASK_TYPE_MAP    = { 'apstat.com':            'SshTask',
+                     'iro.umontreal.ca':      'ClusterTask',
+                     '## UNKNOWN DOMAINE ##': 'OnHostTask'
                      }
 
 # Used only for clusters of type 'ssh'. Do not enter the same machine more
@@ -55,7 +56,9 @@
                      'iro.umontreal.ca' : [ 'lhmm',    'lknn',    'lmfa',      'lmlp',
                                             'lsom',    'lsvm',    'currie',    'dirac',
                                             'fermi',   'plank',   'einstein'
-                                            ]                         
+                                            ],
+
+                     '## UNKNOWN DOMAINE ##': [ 'host' ]
                      }
 
 # To override the default of 1
@@ -68,7 +71,10 @@
 BUFSIZE       = 4096
 SLEEP_TIME    = 15
 LOGDIR        = None  # May be set by set_logdir()
-DOMAIN_NAME   = get_domain_name()
+try:
+    DOMAIN_NAME = get_domain_name()
+except Exception, e:
+    DOMAIN_NAME = "## UNKNOWN DOMAINE ##"
 
 # Configurables
 NICE          = 'nice'
@@ -229,7 +235,8 @@
             for fromchild in iwtd:
                 ready = cls._child_processes[fromchild]
                 read_str = ready.process.fromchild.read()
-                #read_str = ready.process.fromchild.read(BUFSIZE)
+                logging.debug("* Read \n%s"% read_str)
+                #print("* Read \n%s"% read_str)
                 if hasattr(ready, 'logfile'):
                     ready.logfile.write(read_str)
 
@@ -247,7 +254,9 @@
             # the task is still running.
             running_tasks = cls._child_processes.values()
             for task in running_tasks:
-                if task.process.poll() >= 0:
+                poll_value = task.process.poll()
+                logging.debug("* Poll returned %s" % poll_value)
+                if poll_value >= 0:
                     task.free()
                     completed.append(task)
 
@@ -323,7 +332,8 @@
     _available_machines = None
     _max_load= 1.0
     
-    def getLoadAvg(cls, machine):
+    def getLoadAvg(cls, machine,
+                   command = lambda host: 'ssh -x %s cat /proc/loadavg' % host):
         #print "\nQuery to", machine
         if machine in cls._loadavg:
             # For typical PLearn/FinLearn tasks, the process begins by
@@ -337,7 +347,7 @@
 
         # Query for the load average
         #print "NEW QUERY!"
-        p = os.popen('ssh -x %s cat /proc/loadavg' % machine)
+        p = os.popen( command(machine) )
         line = p.readline()
         return float(line.split()[0]) # Take the last minute average
     getLoadAvg = classmethod(getLoadAvg)
@@ -379,27 +389,6 @@
         return next
     nextAvailableMachine = classmethod(nextAvailableMachine)
 
-    #TBR: def nextAvailableMachine(cls):
-    #TBR:     # If a StopIteration exception is encountered on an already began
-    #TBR:     # loop, we simply have queried each machine once and shall start
-    #TBR:     # over. If such an exception is raise on a new loop, then no
-    #TBR:     # machines are currently available and we raise an
-    #TBR:     # EmptyTaskListError so as to wait a little while before querying
-    #TBR:     # again...
-    #TBR:     new_loop = False
-    #TBR:     if cls._available_machines is None:
-    #TBR:         cls._available_machines = cls.listAvailableMachines()            
-    #TBR:         new_loop = True
-    #TBR:     
-    #TBR:     try:
-    #TBR:         return cls._available_machines.next()
-    #TBR:     except StopIteration:
-    #TBR:         cls._available_machines = None
-    #TBR:         if new_loop:
-    #TBR:             time.sleep(SLEEP_TIME)
-    #TBR:         return cls.nextAvailableMachine()
-    #TBR: nextAvailableMachine = classmethod(nextAvailableMachine)
-
     #
     # Instance methods
     #
@@ -418,6 +407,50 @@
         #KNOWN ISSUE: self._machines.append( self.host )
         TaskType.free(self)
 
+
+class OnHostTask( SshTask ):
+
+    def getLoadAvg(cls, machine,
+                   command = lambda host: 'cat /proc/loadavg'):
+        return SshTask.getLoadAvg(machine, command)
+    getLoadAvg = classmethod(getLoadAvg)
+    
+    def listAvailableMachines(cls):
+        for m in cls._machines:
+            loadavg = cls.getLoadAvg(m)
+            max_loadavg = cls._max_load
+
+            print "Load %f / %f"%(loadavg, max_loadavg)
+            if loadavg < max_loadavg:
+                # Register the load average *plus* one, taking in account
+                # the process we are about to launch
+                cls._loadavg[m] = datetime(*time.localtime()[:6]), loadavg+1
+                print "At %s Saving %f"%cls._loadavg[m]
+                print
+                yield m
+    listAvailableMachines = classmethod(listAvailableMachines)
+
+    #
+    # Instance methods
+    #
+
+    def getLaunchCommand(self):
+        # Get the first available machine
+        self.host = self.nextAvailableMachine()
+        assert self.host == 'host', self.host
+        return ' '.join(self.argv)
+
+    def getLogFileBaseName(self):
+        raise NotImplementedError('OnHostTask::getLogFileBaseName')
+
+    # def free(self):
+    #     TaskType.free(self)
+    # 
+    #     cls = self.__class__
+    #     time, loadavg = cls._loadavg['host'] 
+    #     cls._loadavg['host'] = time, loadavg-1
+
+
 class ClusterTask( TaskType ):
     def listAvailableMachines( cls ):
         p = os.popen('cluster --charge')



From nouiz at mail.berlios.de  Wed Dec 19 22:57:28 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 19 Dec 2007 22:57:28 +0100
Subject: [Plearn-commits] r8363 - trunk/plearn/vmat
Message-ID: <200712192157.lBJLvSUf025114@sheep.berlios.de>

Author: nouiz
Date: 2007-12-19 22:57:28 +0100 (Wed, 19 Dec 2007)
New Revision: 8363

Modified:
   trunk/plearn/vmat/ImputationVMatrix.h
Log:
better import


Modified: trunk/plearn/vmat/ImputationVMatrix.h
===================================================================
--- trunk/plearn/vmat/ImputationVMatrix.h	2007-12-18 20:38:15 UTC (rev 8362)
+++ trunk/plearn/vmat/ImputationVMatrix.h	2007-12-19 21:57:28 UTC (rev 8363)
@@ -44,8 +44,8 @@
 #ifndef ImputationVMatrix_INC
 #define ImputationVMatrix_INC
 
-#include <plearn/vmat/SourceVMatrix.h>
-#include <plearn/vmat/FileVMatrix.h>
+#include <plearn/vmat/VMatrix.h>
+#include <plearn/vmat/VMat.h>
 #include <plearn/io/fileutils.h>                     //!<  For isfile()
 #include <plearn/math/BottomNI.h>
 



From nouiz at mail.berlios.de  Wed Dec 19 23:43:58 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 19 Dec 2007 23:43:58 +0100
Subject: [Plearn-commits] r8364 - trunk/plearn/vmat
Message-ID: <200712192243.lBJMhwqO027953@sheep.berlios.de>

Author: nouiz
Date: 2007-12-19 23:43:58 +0100 (Wed, 19 Dec 2007)
New Revision: 8364

Modified:
   trunk/plearn/vmat/SelectColumnsVMatrix.cc
Log:
better error msg


Modified: trunk/plearn/vmat/SelectColumnsVMatrix.cc
===================================================================
--- trunk/plearn/vmat/SelectColumnsVMatrix.cc	2007-12-19 21:57:28 UTC (rev 8363)
+++ trunk/plearn/vmat/SelectColumnsVMatrix.cc	2007-12-19 22:43:58 UTC (rev 8364)
@@ -256,6 +256,10 @@
         width_ = indices.length();
         length_ = source->length();
 
+        if(inputsize_ + targetsize_ + weightsize_ + extrasize_ != width_)
+            PLWARNING("In SelectColumnsVMatrix::build_() - inputsize_(%d) +"
+                      " targetsize_(%d) + weightsize_(%d) + extrasize_(%d) != width_(%d) !",
+                      inputsize_, targetsize_, weightsize_, extrasize_, width_);
 #if 0
         // Disabled for now, since it gives way too many false positives in
         // some cases. Todo: figure out a way to warn in a useful way when



From nouiz at mail.berlios.de  Wed Dec 19 23:50:38 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Wed, 19 Dec 2007 23:50:38 +0100
Subject: [Plearn-commits] r8365 - in trunk: commands/PLearnCommands
	plearn/misc plearn/vmat
Message-ID: <200712192250.lBJMocNL028261@sheep.berlios.de>

Author: nouiz
Date: 2007-12-19 23:50:37 +0100 (Wed, 19 Dec 2007)
New Revision: 8365

Modified:
   trunk/commands/PLearnCommands/VMatCommand.cc
   trunk/plearn/misc/vmatmain.cc
   trunk/plearn/vmat/VMatrix.cc
   trunk/plearn/vmat/VMatrix.h
Log:
Added a a command
pl vmat compare_stats <dataset1> <dataset2> [stderror threshold] [missing threshold]
that can be used to check that the test set is similar to the train set


Modified: trunk/commands/PLearnCommands/VMatCommand.cc
===================================================================
--- trunk/commands/PLearnCommands/VMatCommand.cc	2007-12-19 22:43:58 UTC (rev 8364)
+++ trunk/commands/PLearnCommands/VMatCommand.cc	2007-12-19 22:50:37 UTC (rev 8365)
@@ -113,7 +113,10 @@
         "       field (column) number, starting at 0. Those files contain the plearn\n"
         "       scripts of the Dictionary objets for each field.\n"
         "   or: vmat catstr <dataset>\n"
-        "       Will output the content of <dataset>, using its string mappings\n\n"
+        "       Will output the content of <dataset>, using its string mappings\n"
+        "   or: vmat compare_stats <dataset1> <dataset2> [stdev threshold] [missing threshold]\n"
+        "       Will compare stats from dataset1 to dataset2\n\n"
+
         "<dataset> is a parameter understandable by getDataSet: \n"
         + getDataSetHelp()
         ) 

Modified: trunk/plearn/misc/vmatmain.cc
===================================================================
--- trunk/plearn/misc/vmatmain.cc	2007-12-19 22:43:58 UTC (rev 8364)
+++ trunk/plearn/misc/vmatmain.cc	2007-12-19 22:50:37 UTC (rev 8365)
@@ -486,7 +486,9 @@
             "       between two consecutive input points \n"
             "   or: vmat catstr <dataset> [separator]\n"
             "       Will output the content of <dataset>, using its string mappings.\n"
-            "       A column separator can be provided. By default, \"\t\" is used.\n\n"
+            "       A column separator can be provided. By default, \"\t\" is used.\n"
+            "   or: vmat compare_stats <dataset1> <dataset2> [stdev threshold] [missing threshold]\n"
+            "       Will compare stats from dataset1 to dataset2\n\n"
             "<dataset> is a parameter understandable by getDataSet. This includes \n"
             "all matrix file formats. Type 'vmat help dataset' to see what other\n"
             "<dataset> strings are available." << endl;
@@ -943,6 +945,22 @@
     {
         pout << getDataSetHelp() << endl;
     }
+    else if(command=="compare_stats")
+    {
+        if(!(argc==4||argc==5||argc==6))
+            PLERROR("vmat compare_stats must be used that way: vmat compare_stats <dataset1> <dataset2> [stderror threshold] [missing threshold]");
+        VMat m1 = getDataSet(argv[2]);
+        VMat m2 = getDataSet(argv[3]);
+        real stderror_threshold = 1;
+        real missing_threshold = 10;
+        if(argc>4)
+            stderror_threshold=toreal(argv[4]);
+        if(argc>5)
+            missing_threshold=toreal(argv[5]);
+        int diff = m1->compareStats(m2, stderror_threshold, missing_threshold);
+        cout<<"Their is "<<diff<<" fields that have different stats"<<endl;
+
+    }
     else
         PLERROR("Unknown command : %s",command.c_str());
     return 0;

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-12-19 22:43:58 UTC (rev 8364)
+++ trunk/plearn/vmat/VMatrix.cc	2007-12-19 22:50:37 UTC (rev 8365)
@@ -1886,6 +1886,45 @@
         appendRow(rows(i));
 }
 
+
+int VMatrix:: compareStats(const VMat& target,
+                           const real stderror_threshold,
+                           const real missing_threshold) const
+{
+#ifdef BOUNDCHECK
+    if(target->width()!=width())
+        PLERROR("In VecStatsCollector:: compareStats() - this vmatris have width %d witch differ from the target width of %d", width(), target->width());
+#endif
+    int diff = 0;
+
+    for(int i=0;i<width();i++)
+    {
+        const StatsCollector tstats = target->getStats(i);
+        const StatsCollector lstats = getStats(i);
+
+        real tmissing = tstats.nmissing()/tstats.n();
+        real lmissing = lstats.nmissing()/lstats.n();
+        if(lmissing<(tmissing-missing_threshold/100) || lmissing>(tmissing+missing_threshold/100))
+        {
+            PLWARNING("In VMatrix::compareStats - field %d(%s) have %f missing while target stats have %f",
+                      i, fieldName(i).c_str(), lmissing, tmissing);
+            diff++;
+        }
+        real tmean = tstats.mean();
+        real lmean = lstats.mean();
+        real tstderror = tstats.stderror();
+        real  th = (lmean-tmean)/tstderror;
+
+        if(th>stderror_threshold)
+        {
+            PLWARNING("In VMatrix::compareStats - field %d(%s) have mean %f"
+                      " while target mean is %f and target stderror is %f. They differ by %f stderror",
+                      i, fieldName(i).c_str(), lmean, tmean, tstderror, th);
+            diff++;
+        }
+    }
+     return diff;
+}
 } // end of namespace PLearn
 
 

Modified: trunk/plearn/vmat/VMatrix.h
===================================================================
--- trunk/plearn/vmat/VMatrix.h	2007-12-19 22:43:58 UTC (rev 8364)
+++ trunk/plearn/vmat/VMatrix.h	2007-12-19 22:50:37 UTC (rev 8365)
@@ -596,6 +596,18 @@
     StatsCollector& getStats(int fieldnum) const
     { return getStats()[fieldnum]; }
 
+    
+    //! Compare the stats of this VecStatsCollector with the target one.
+    //! @param target the VecStatsCollector we compare again
+    //! @param stderror_threshold The threshold alowed for the standard error
+    //! @param missing_threshold The threshold alowed for the % of missing
+    //! @return If they are comparable with respect to the gived threshold,
+    //! we return true. Otherwise false
+    int compareStats(const VMat& target,
+                     const real stderror_threshold = 2,
+                     const real missing_threshold = 10) const;
+
+
     /**
      *  Returns the bounding box of the data, as a vector of min:max pairs.  If
      *  extra_percent is non 0, then the box is enlarged in both ends of every



From nouiz at mail.berlios.de  Thu Dec 20 16:18:05 2007
From: nouiz at mail.berlios.de (nouiz at BerliOS)
Date: Thu, 20 Dec 2007 16:18:05 +0100
Subject: [Plearn-commits] r8366 - trunk/doc
Message-ID: <200712201518.lBKFI5T2025273@sheep.berlios.de>

Author: nouiz
Date: 2007-12-20 16:18:05 +0100 (Thu, 20 Dec 2007)
New Revision: 8366

Modified:
   trunk/doc/Doxyfile
   trunk/doc/Doxyfile2
   trunk/doc/Doxyfile3
Log:
Corrected Dorectory outupt


Modified: trunk/doc/Doxyfile
===================================================================
--- trunk/doc/Doxyfile	2007-12-19 22:50:37 UTC (rev 8365)
+++ trunk/doc/Doxyfile	2007-12-20 15:18:05 UTC (rev 8366)
@@ -38,7 +38,7 @@
 # If a relative path is entered, it will be relative to the location 
 # where doxygen was started. If left blank the current directory will be used.
 
-OUTPUT_DIRECTORY       = LibraryReference.joseph
+OUTPUT_DIRECTORY       = LibraryReference
 
 # If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
 # 4096 sub-directories (in 2 levels) under the output directory of each output 

Modified: trunk/doc/Doxyfile2
===================================================================
--- trunk/doc/Doxyfile2	2007-12-19 22:50:37 UTC (rev 8365)
+++ trunk/doc/Doxyfile2	2007-12-20 15:18:05 UTC (rev 8366)
@@ -38,7 +38,7 @@
 # If a relative path is entered, it will be relative to the location 
 # where doxygen was started. If left blank the current directory will be used.
 
-OUTPUT_DIRECTORY       = LibraryReference.joseph
+OUTPUT_DIRECTORY       = LibraryReference-No-Dot
 
 # If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
 # 4096 sub-directories (in 2 levels) under the output directory of each output 

Modified: trunk/doc/Doxyfile3
===================================================================
--- trunk/doc/Doxyfile3	2007-12-19 22:50:37 UTC (rev 8365)
+++ trunk/doc/Doxyfile3	2007-12-20 15:18:05 UTC (rev 8366)
@@ -38,7 +38,7 @@
 # If a relative path is entered, it will be relative to the location 
 # where doxygen was started. If left blank the current directory will be used.
 
-OUTPUT_DIRECTORY       = LibraryReference.joseph
+OUTPUT_DIRECTORY       = LibraryReference-No-Source
 
 # If the CREATE_SUBDIRS tag is set to YES, then doxygen will create 
 # 4096 sub-directories (in 2 levels) under the output directory of each output 



From tihocan at mail.berlios.de  Thu Dec 20 17:20:15 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Thu, 20 Dec 2007 17:20:15 +0100
Subject: [Plearn-commits] r8367 - trunk/plearn/vmat
Message-ID: <200712201620.lBKGKFLF029070@sheep.berlios.de>

Author: tihocan
Date: 2007-12-20 17:20:15 +0100 (Thu, 20 Dec 2007)
New Revision: 8367

Modified:
   trunk/plearn/vmat/VMatrix.cc
Log:
Added getString as a remote method

Modified: trunk/plearn/vmat/VMatrix.cc
===================================================================
--- trunk/plearn/vmat/VMatrix.cc	2007-12-20 15:18:05 UTC (rev 8366)
+++ trunk/plearn/vmat/VMatrix.cc	2007-12-20 16:20:15 UTC (rev 8367)
@@ -167,6 +167,13 @@
          RetDoc ("row i vector")));
 
     declareMethod(
+        rmm, "getString", &VMatrix::getString,
+        (BodyDoc("Returns an element of a matrix as a string\n"),
+         ArgDoc ("i", "Position of the row to get.\n"),
+         ArgDoc ("j", "Position of the column to get.\n"),
+         RetDoc ("string value")));
+
+    declareMethod(
         rmm, "getMat", &VMatrix::toMat,
         (BodyDoc("Returns the content of the vmat as a Mat\n"),
          RetDoc ("The content of this VMatrix as a Mat")));



From tihocan at mail.berlios.de  Thu Dec 20 17:43:57 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Thu, 20 Dec 2007 17:43:57 +0100
Subject: [Plearn-commits] r8368 - trunk/plearn/vmat
Message-ID: <200712201643.lBKGhvW8030845@sheep.berlios.de>

Author: tihocan
Date: 2007-12-20 17:43:57 +0100 (Thu, 20 Dec 2007)
New Revision: 8368

Modified:
   trunk/plearn/vmat/SelectColumnsVMatrix.cc
Log:
Remove unnecessary warning when sizes are not defined

Modified: trunk/plearn/vmat/SelectColumnsVMatrix.cc
===================================================================
--- trunk/plearn/vmat/SelectColumnsVMatrix.cc	2007-12-20 16:20:15 UTC (rev 8367)
+++ trunk/plearn/vmat/SelectColumnsVMatrix.cc	2007-12-20 16:43:57 UTC (rev 8368)
@@ -256,10 +256,15 @@
         width_ = indices.length();
         length_ = source->length();
 
-        if(inputsize_ + targetsize_ + weightsize_ + extrasize_ != width_)
+        // Check sizes are consistent with width.
+        if(inputsize_ >= 0 && targetsize_ >= 0 && weightsize_ >= 0 &&
+           extrasize_ >= 0  &&
+           (inputsize_ + targetsize_ + weightsize_ + extrasize_ != width_))
+        {
             PLWARNING("In SelectColumnsVMatrix::build_() - inputsize_(%d) +"
                       " targetsize_(%d) + weightsize_(%d) + extrasize_(%d) != width_(%d) !",
                       inputsize_, targetsize_, weightsize_, extrasize_, width_);
+        }
 #if 0
         // Disabled for now, since it gives way too many false positives in
         // some cases. Todo: figure out a way to warn in a useful way when



From dorionc at mail.berlios.de  Thu Dec 27 13:29:22 2007
From: dorionc at mail.berlios.de (dorionc at BerliOS)
Date: Thu, 27 Dec 2007 13:29:22 +0100
Subject: [Plearn-commits] r8369 - trunk/python_modules/plearn/parallel
Message-ID: <200712271229.lBRCTMvL014801@sheep.berlios.de>

Author: dorionc
Date: 2007-12-27 13:29:21 +0100 (Thu, 27 Dec 2007)
New Revision: 8369

Modified:
   trunk/python_modules/plearn/parallel/dispatch.py
Log:
Removed some debug prints...


Modified: trunk/python_modules/plearn/parallel/dispatch.py
===================================================================
--- trunk/python_modules/plearn/parallel/dispatch.py	2007-12-20 16:43:57 UTC (rev 8368)
+++ trunk/python_modules/plearn/parallel/dispatch.py	2007-12-27 12:29:21 UTC (rev 8369)
@@ -420,13 +420,8 @@
             loadavg = cls.getLoadAvg(m)
             max_loadavg = cls._max_load
 
-            print "Load %f / %f"%(loadavg, max_loadavg)
             if loadavg < max_loadavg:
-                # Register the load average *plus* one, taking in account
-                # the process we are about to launch
                 cls._loadavg[m] = datetime(*time.localtime()[:6]), loadavg+1
-                print "At %s Saving %f"%cls._loadavg[m]
-                print
                 yield m
     listAvailableMachines = classmethod(listAvailableMachines)
 
@@ -443,14 +438,7 @@
     def getLogFileBaseName(self):
         raise NotImplementedError('OnHostTask::getLogFileBaseName')
 
-    # def free(self):
-    #     TaskType.free(self)
-    # 
-    #     cls = self.__class__
-    #     time, loadavg = cls._loadavg['host'] 
-    #     cls._loadavg['host'] = time, loadavg-1
 
-
 class ClusterTask( TaskType ):
     def listAvailableMachines( cls ):
         p = os.popen('cluster --charge')



From tihocan at mail.berlios.de  Fri Dec 28 21:51:40 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 28 Dec 2007 21:51:40 +0100
Subject: [Plearn-commits] r8370 - trunk/plearn/vmat
Message-ID: <200712282051.lBSKpefb021100@sheep.berlios.de>

Author: tihocan
Date: 2007-12-28 21:51:40 +0100 (Fri, 28 Dec 2007)
New Revision: 8370

Modified:
   trunk/plearn/vmat/BootstrapVMatrix.cc
   trunk/plearn/vmat/BootstrapVMatrix.h
Log:
Added an option to operate on bags

Modified: trunk/plearn/vmat/BootstrapVMatrix.cc
===================================================================
--- trunk/plearn/vmat/BootstrapVMatrix.cc	2007-12-27 12:29:21 UTC (rev 8369)
+++ trunk/plearn/vmat/BootstrapVMatrix.cc	2007-12-28 20:51:40 UTC (rev 8370)
@@ -49,7 +49,7 @@
         "A VMatrix that sees a bootstrap subset of its parent VMatrix.",
         "It means that a random sample of the source will be taken. Samples\n"
         "may or may not be repeated depending on the value of the option\n"
-        "'allow_repetitions'"
+        "'allow_repetitions' (the default behavior is not to repeat samples)."
 );
 
 //////////////////////
@@ -59,6 +59,7 @@
     rgen(new PRandom()),
     frac(0.6667),
     n_elems(-1),
+    operate_on_bags(false),
     own_seed(-3), // Temporary hack value to detect use of deprecated option.
     seed(1827),   // Default fixed seed value (safer than time-dependent).
     shuffle(false),
@@ -70,6 +71,7 @@
     rgen(new PRandom()),
     frac(the_frac),
     n_elems(-1),
+    operate_on_bags(false),
     own_seed(-3),
     seed(the_seed),
     shuffle(the_shuffle),
@@ -86,6 +88,7 @@
     rgen(the_rgen),
     frac(the_frac),
     n_elems(-1),
+    operate_on_bags(false),
     own_seed(-3),
     shuffle(the_shuffle),
     allow_repetitions(allow_rep)
@@ -121,6 +124,12 @@
                   "Wether examples should be allowed to appear each more than once.",
                   OptionBase::advanced_level);
 
+    declareOption(ol, "operate_on_bags", &BootstrapVMatrix::operate_on_bags, 
+                  OptionBase::buildoption,
+        "Wether to operate on bags rather than individual samples (see help\n"
+        "of SumOverBagsVariable for details on bags).",
+        OptionBase::advanced_level);
+
     declareOption(ol, "own_seed", &BootstrapVMatrix::own_seed,
                   (OptionBase::learntoption | OptionBase::nosave),
                   "DEPRECATED: old random generator seed",
@@ -163,7 +172,31 @@
 
         // Create bootstrap sample.
         int l= source.length();
+
+        TVec< TVec<int> > bag_to_indices;
+        if (operate_on_bags) {
+            // Analyze bags in the source.
+            Vec input, target;
+            real weight;
+            for (int i = 0; i < l; i++) {
+                source->getExample(i, input, target, weight);
+#ifdef BOUNDCHECK
+                // Safety checks on bag information.
+                real bi = target.lastElement();
+                PLASSERT( is_equal(round(bi), bi) );
+                int bii = int(round(bi));
+                PLASSERT( bii >= 0 && bii <= 3 );
+#endif
+                int bag_info = int(round(target.lastElement()));
+                if (bag_info % 2 == 1)
+                    bag_to_indices.append(TVec<int>());
+                bag_to_indices.lastElement().append(i);
+            }
+            l = bag_to_indices.length();
+        }
+
         int nsamp= (n_elems >= 0) ? n_elems : int(round(frac*l));
+
         if(allow_repetitions)
         {
             indices.resize(nsamp);
@@ -179,6 +212,14 @@
         if (!shuffle)
             sortElements(indices);
 
+        if (operate_on_bags) {
+            // Convert bag indices back to sample indices.
+            TVec<int> bag_indices = indices.copy();
+            indices.resize(0);
+            for (int i = 0; i < bag_indices.length(); i++)
+                indices.append(bag_to_indices[bag_indices[i]]);
+        }
+
         // Because we changed the indices, a rebuild may be needed.
         inherited::build();
     }

Modified: trunk/plearn/vmat/BootstrapVMatrix.h
===================================================================
--- trunk/plearn/vmat/BootstrapVMatrix.h	2007-12-27 12:29:21 UTC (rev 8369)
+++ trunk/plearn/vmat/BootstrapVMatrix.h	2007-12-28 20:51:40 UTC (rev 8370)
@@ -61,6 +61,7 @@
 
     real frac;
     int n_elems;
+    bool operate_on_bags;
     int32_t own_seed;
     int32_t seed;
     bool shuffle;



From tihocan at mail.berlios.de  Fri Dec 28 21:52:08 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 28 Dec 2007 21:52:08 +0100
Subject: [Plearn-commits] r8371 - trunk/plearn/vmat
Message-ID: <200712282052.lBSKq8bF021130@sheep.berlios.de>

Author: tihocan
Date: 2007-12-28 21:52:08 +0100 (Fri, 28 Dec 2007)
New Revision: 8371

Added:
   trunk/plearn/vmat/AddBagInformationVMatrix.cc
   trunk/plearn/vmat/AddBagInformationVMatrix.h
Log:
VMat that adds the bag target information to its source

Added: trunk/plearn/vmat/AddBagInformationVMatrix.cc
===================================================================
--- trunk/plearn/vmat/AddBagInformationVMatrix.cc	2007-12-28 20:51:40 UTC (rev 8370)
+++ trunk/plearn/vmat/AddBagInformationVMatrix.cc	2007-12-28 20:52:08 UTC (rev 8371)
@@ -0,0 +1,169 @@
+// -*- C++ -*-
+
+// AddBagInformationVMatrix.cc
+//
+// Copyright (C) 2007 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Olivier Delalleau
+
+/*! \file AddBagInformationVMatrix.cc */
+
+
+#include "AddBagInformationVMatrix.h"
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    AddBagInformationVMatrix,
+    "Add bag information to an existing VMat.",
+    "This VMatrix adds an extra target column to its source VMat, that\n"
+    "contains bag information as follows:\n"
+    "   - 1 = beginning of bag\n"
+    "   - 2 = end of bag\n"
+    "   - 0 = middle of bag\n"
+    "   - 3 = single-row bag (both beginning and end)\n"
+    "Bags are found by looking at a specific column of the source (given by\n"
+    "the 'bag_info_column' option): a new bag is started when this column's\n"
+    "value changes between two consecutive samples.\n"
+);
+
+//////////////////////////////
+// AddBagInformationVMatrix //
+//////////////////////////////
+AddBagInformationVMatrix::AddBagInformationVMatrix():
+    bag_info_idx(-1)
+{
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void AddBagInformationVMatrix::declareOptions(OptionList& ol)
+{
+    declareOption(ol, "bag_info_column",
+                  &AddBagInformationVMatrix::bag_info_column,
+                  OptionBase::buildoption,
+        "The source's column that is used to find bags in the data. It can\n"
+        "be either a number or a column's name.");
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+///////////
+// build //
+///////////
+void AddBagInformationVMatrix::build()
+{
+    // ### Nothing to add here, simply calls build_
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void AddBagInformationVMatrix::build_()
+{
+    if (source) {
+        bag_info_idx = source->getFieldIndex(bag_info_column);
+        sourcerow.resize(source->width());
+        width_ = source->width() + 1;
+        int st = source->targetsize();
+        if (st >= 0)
+            targetsize_ = st + 1;
+
+        // Set field infos.
+        Array<VMField> fields = source->getFieldInfos().copy();
+        fields.append(VMField("bag_info"));
+        setFieldInfos(fields);
+
+        setMetaInfoFromSource();
+    }
+}
+
+///////////////
+// getNewRow //
+///////////////
+void AddBagInformationVMatrix::getNewRow(int i, const Vec& v) const
+{
+    bool is_beg = false;
+    bool is_end = false;
+    // Obtain current bag information.
+    source->getRow(i, sourcerow);
+    real cur = sourcerow[bag_info_idx];
+    if (i == 0)
+        is_beg = true;
+    else {
+        // Compare with previous sample.
+        real prev = source->get(i - 1, bag_info_idx);
+        if (!is_equal(cur, prev))
+            is_beg = true;
+    }
+    if (i == length_ - 1)
+        is_end = true;
+    else {
+        // Compare with next sample.
+        real next = source->get(i + 1, bag_info_idx);
+        if (!is_equal(cur, next))
+            is_end = true;
+    }
+    real bag_info = is_beg ? is_end ? 3
+                                    : 1
+                           : is_end ? 2
+                                    : 0;
+    v.subVec(0, sourcerow.length()) << sourcerow;
+    v.lastElement() = bag_info;
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void AddBagInformationVMatrix::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/vmat/AddBagInformationVMatrix.h
===================================================================
--- trunk/plearn/vmat/AddBagInformationVMatrix.h	2007-12-28 20:51:40 UTC (rev 8370)
+++ trunk/plearn/vmat/AddBagInformationVMatrix.h	2007-12-28 20:52:08 UTC (rev 8371)
@@ -0,0 +1,142 @@
+// -*- C++ -*-
+
+// AddBagInformationVMatrix.h
+//
+// Copyright (C) 2007 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Olivier Delalleau
+
+/*! \file AddBagInformationVMatrix.h */
+
+
+#ifndef AddBagInformationVMatrix_INC
+#define AddBagInformationVMatrix_INC
+
+#include <plearn/vmat/SourceVMatrix.h>
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class AddBagInformationVMatrix : public SourceVMatrix
+{
+    typedef SourceVMatrix inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    string bag_info_column;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    AddBagInformationVMatrix();
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(AddBagInformationVMatrix);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+
+    //! The index of 'bag_info_column' in the source VMat.
+    int bag_info_idx;
+    
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+    //! Fill the vector 'v' with the content of the i-th row.
+    //! v is assumed to be the right size.
+    //! ### This function must be overridden in your class
+    virtual void getNewRow(int i, const Vec& v) const;
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(AddBagInformationVMatrix);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From tihocan at mail.berlios.de  Fri Dec 28 21:53:01 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 28 Dec 2007 21:53:01 +0100
Subject: [Plearn-commits] r8372 - trunk/plearn_learners/classifiers
Message-ID: <200712282053.lBSKr1ZY021171@sheep.berlios.de>

Author: tihocan
Date: 2007-12-28 21:53:01 +0100 (Fri, 28 Dec 2007)
New Revision: 8372

Added:
   trunk/plearn_learners/classifiers/ToBagClassifier.cc
   trunk/plearn_learners/classifiers/ToBagClassifier.h
Log:
Generic classifier to make an underlying classifier operate on bags

Added: trunk/plearn_learners/classifiers/ToBagClassifier.cc
===================================================================
--- trunk/plearn_learners/classifiers/ToBagClassifier.cc	2007-12-28 20:52:08 UTC (rev 8371)
+++ trunk/plearn_learners/classifiers/ToBagClassifier.cc	2007-12-28 20:53:01 UTC (rev 8372)
@@ -0,0 +1,190 @@
+// -*- C++ -*-
+
+// ToBagClassifier.cc
+//
+// Copyright (C) 2007 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Olivier Delalleau
+
+/*! \file ToBagClassifier.cc */
+
+
+#include "ToBagClassifier.h"
+#include <plearn/vmat/SubVMatrix.h>
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    ToBagClassifier,
+    "Makes an existing classifier operate on bags.",
+    "Training is performed by simply removing bag information.\n"
+    "For testing, a majority vote is performed on each bag: assuming the\n"
+    "inner learner's output is made of the probabilities for each class,\n"
+    "these probabilities are summed over a full bag, and the class with\n"
+    "highest sum is taken as prediction.");
+
+/////////////////////
+// ToBagClassifier //
+/////////////////////
+ToBagClassifier::ToBagClassifier()
+{
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void ToBagClassifier::declareOptions(OptionList& ol)
+{
+    // ### ex:
+    // declareOption(ol, "myoption", &ToBagClassifier::myoption,
+    //               OptionBase::buildoption,
+    //               "Help text describing this option");
+    // ...
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+////////////
+// build_ //
+////////////
+void ToBagClassifier::build_()
+{
+}
+
+///////////
+// build //
+///////////
+void ToBagClassifier::build()
+{
+    inherited::build();
+    build_();
+}
+
+/////////////////////////////
+// computeCostsFromOutputs //
+/////////////////////////////
+void ToBagClassifier::computeCostsFromOutputs(const Vec& input,
+                                              const Vec& output,
+                                              const Vec& target,
+                                              Vec& costs) const
+{
+    sub_target.resize(target.length() - 1);
+    sub_target << target.subVec(0, sub_target.length());
+    inherited::computeCostsFromOutputs(input, output, sub_target, costs);
+    int bag_info = int(round(target.lastElement()));
+    if (bag_info % 2 == 1)
+        bag_output.resize(0, 0);
+    bag_output.appendRow(output);
+    costs.resize(1);
+    if (bag_info >= 2) {
+        // Perform majority vote.
+        votes.resize(bag_output.width());
+        columnSum(bag_output, votes);
+        int target_class = int(round(target[0]));
+        if (argmax(votes) == target_class)
+            costs[0] = 0;
+        else
+            costs[0] = 1;
+    } else
+        costs.fill(MISSING_VALUE);
+}
+
+//////////////////////
+// getTestCostNames //
+//////////////////////
+TVec<string> ToBagClassifier::getTestCostNames() const
+{
+    static TVec<string> costs;
+    if (costs.isEmpty())
+        costs.append("class_error");
+    return costs;
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void ToBagClassifier::makeDeepCopyFromShallowCopy(CopiesMap& copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all "pointer-like" fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+
+    // ### Remove this line when you have fully implemented this method.
+    PLERROR("ToBagClassifier::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!");
+}
+
+////////////////////
+// setTrainingSet //
+////////////////////
+void ToBagClassifier::setTrainingSet(VMat training_set, bool call_forget)
+{
+    // Remove bag information (last target).
+    PLCHECK( training_set->weightsize() == 0 &&
+             training_set->extrasize() == 0 ); // Not compatible yet.
+    PP<SubVMatrix> sub_train_set = new SubVMatrix(training_set, 0, 0, 
+                                                  training_set->length(),
+                                                  training_set->width() - 1);
+    sub_train_set->defineSizes(training_set->inputsize(),
+                               training_set->targetsize() - 1,
+                               training_set->weightsize(),
+                               training_set->extrasize());
+    setInnerLearnerTrainingSet(get_pointer(sub_train_set), call_forget);
+    PLearner::setTrainingSet(training_set, call_forget);
+}
+
+////////////////
+// targetsize //
+////////////////
+int ToBagClassifier::targetsize() const
+{
+    return learner_->targetsize() + 1;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners/classifiers/ToBagClassifier.h
===================================================================
--- trunk/plearn_learners/classifiers/ToBagClassifier.h	2007-12-28 20:52:08 UTC (rev 8371)
+++ trunk/plearn_learners/classifiers/ToBagClassifier.h	2007-12-28 20:53:01 UTC (rev 8372)
@@ -0,0 +1,172 @@
+// -*- C++ -*-
+
+// ToBagClassifier.h
+//
+// Copyright (C) 2007 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Olivier Delalleau
+
+/*! \file ToBagClassifier.h */
+
+
+#ifndef ToBagClassifier_INC
+#define ToBagClassifier_INC
+
+#include <plearn_learners/generic/EmbeddedLearner.h>
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See http://www.doxygen.org/manual.html
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class ToBagClassifier : public EmbeddedLearner
+{
+    typedef EmbeddedLearner inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    ToBagClassifier();
+
+    //#####  PLearner Member Functions  #######################################
+
+    //! Set training set.
+    virtual void setTrainingSet(VMat training_set, bool call_forget=true);
+
+    //! Targetsize is one more than the inner learner's targetsize.
+    virtual int targetsize() const;
+
+    //! Compute costs.
+    virtual void computeCostsFromOutputs(const Vec& input, const Vec& output,
+                                         const Vec& target, Vec& costs) const;
+
+    //! Currently using PLearner's simple version for code simplicity.
+    virtual void computeOutputAndCosts(const Vec& input, const Vec& target,
+                                       Vec& output, Vec& costs) const
+    {
+        PLearner::computeOutputAndCosts(input, target, output, costs);
+    }
+
+    //! Currently using PLearner's simple version for code simplicity.
+    virtual void computeOutputsAndCosts(const Mat& input, const Mat& target,
+                                        Mat& output, Mat& costs) const
+    {
+        PLearner::computeOutputsAndCosts(input, target, output, costs);
+    }
+
+    //! Currently only compute classification error.
+    virtual TVec<string> getTestCostNames() const;
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(ToBagClassifier);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap& copies);
+
+protected:
+
+    //! Used to store the target forwarded to the inner learner.
+    mutable Vec sub_target;
+
+    //! Used to store outputs on a bag.
+    mutable Mat bag_output;
+
+    //! Used to store votes.
+    mutable Vec votes;
+
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList& ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(ToBagClassifier);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:"stroustrup"
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :



From tihocan at mail.berlios.de  Fri Dec 28 21:54:07 2007
From: tihocan at mail.berlios.de (tihocan at BerliOS)
Date: Fri, 28 Dec 2007 21:54:07 +0100
Subject: [Plearn-commits] r8373 - trunk/plearn_learners/generic
Message-ID: <200712282054.lBSKs7dI021265@sheep.berlios.de>

Author: tihocan
Date: 2007-12-28 21:54:06 +0100 (Fri, 28 Dec 2007)
New Revision: 8373

Modified:
   trunk/plearn_learners/generic/EmbeddedLearner.cc
   trunk/plearn_learners/generic/EmbeddedLearner.h
Log:
Factorized some code to reuse in subclasses

Modified: trunk/plearn_learners/generic/EmbeddedLearner.cc
===================================================================
--- trunk/plearn_learners/generic/EmbeddedLearner.cc	2007-12-28 20:53:01 UTC (rev 8372)
+++ trunk/plearn_learners/generic/EmbeddedLearner.cc	2007-12-28 20:54:06 UTC (rev 8373)
@@ -100,20 +100,27 @@
 {
     if (!learner_)
         PLERROR("EmbeddedLearner::_build() - learner_ attribute is NULL");
-
-    //learner_->build();
 }
 
+///////////
+// build //
+///////////
 void EmbeddedLearner::build()
 {
     inherited::build();
     build_();
 }
 
-void EmbeddedLearner::setTrainingSet(VMat training_set, bool call_forget)
+
+////////////////////////////////
+// setInnerLearnerTrainingSet //
+////////////////////////////////
+void EmbeddedLearner::setInnerLearnerTrainingSet(VMat training_set,
+                                                 bool call_forget)
 {
     PLASSERT( learner_ );
-    bool training_set_has_changed = !train_set || !(train_set->looksTheSameAs(training_set));
+    VMat ts = learner_->getTrainingSet();
+    bool training_set_has_changed = !ts || !(ts->looksTheSameAs(training_set));
     // If 'call_forget' is true, learner_->forget() will be called
     // in this->forget() (called by PLearner::setTrainingSet a few lines below),
     // so we don't need to call it here.
@@ -122,9 +129,20 @@
         // In this case, learner_->build() will not have been called, which may
         // cause trouble if it updates data from the training set.
         learner_->build();
+}
+
+////////////////////
+// setTrainingSet //
+////////////////////
+void EmbeddedLearner::setTrainingSet(VMat training_set, bool call_forget)
+{
+    setInnerLearnerTrainingSet(training_set, call_forget);
     inherited::setTrainingSet(training_set, call_forget);
 }
 
+//////////////////////
+// setValidationSet //
+//////////////////////
 void EmbeddedLearner::setValidationSet(VMat validset)
 {
     PLASSERT( learner_ );

Modified: trunk/plearn_learners/generic/EmbeddedLearner.h
===================================================================
--- trunk/plearn_learners/generic/EmbeddedLearner.h	2007-12-28 20:53:01 UTC (rev 8372)
+++ trunk/plearn_learners/generic/EmbeddedLearner.h	2007-12-28 20:54:06 UTC (rev 8373)
@@ -78,13 +78,16 @@
 
 private: 
     //! This does the actual building. 
-    // (Please implement in .cc)
     void build_();
 
 protected: 
+
     //! Declares this class' options
-    // (Please implement in .cc)
     static void declareOptions(OptionList& ol);
+
+    //! Set training set of the inner learner.
+    void setInnerLearnerTrainingSet(VMat training_set, bool call_forget);
+    
 public:
     // simply calls inherited::build() then build_() 
     virtual void build();



