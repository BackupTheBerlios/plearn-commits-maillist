<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6941 - in trunk/plearn_learners_experimental: .	netflix
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-April/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6941%20-%20in%20trunk/plearn_learners_experimental%3A%20.%0A%09netflix&In-Reply-To=%3C200704252128.l3PLSx67015809%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000389.html">
   <LINK REL="Next"  HREF="000391.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6941 - in trunk/plearn_learners_experimental: .	netflix</H1>
    <B>manzagop at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6941%20-%20in%20trunk/plearn_learners_experimental%3A%20.%0A%09netflix&In-Reply-To=%3C200704252128.l3PLSx67015809%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6941 - in trunk/plearn_learners_experimental: .	netflix">manzagop at mail.berlios.de
       </A><BR>
    <I>Wed Apr 25 23:28:59 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000389.html">[Plearn-commits] r6940 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000391.html">[Plearn-commits] r6942 - trunk/plearn_learners_experimental/netflix
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#390">[ date ]</a>
              <a href="thread.html#390">[ thread ]</a>
              <a href="subject.html#390">[ subject ]</a>
              <a href="author.html#390">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: manzagop
Date: 2007-04-25 23:28:58 +0200 (Wed, 25 Apr 2007)
New Revision: 6941

Added:
   trunk/plearn_learners_experimental/netflix/
   trunk/plearn_learners_experimental/netflix/NxProfileLearner.cc
   trunk/plearn_learners_experimental/netflix/NxProfileLearner.h
Log:
Implements an idea for netflix. See the twiki section Neurones/DeepNetsRecommandationSystems about this.


Added: trunk/plearn_learners_experimental/netflix/NxProfileLearner.cc
===================================================================
--- trunk/plearn_learners_experimental/netflix/NxProfileLearner.cc	2007-04-25 15:00:42 UTC (rev 6940)
+++ trunk/plearn_learners_experimental/netflix/NxProfileLearner.cc	2007-04-25 21:28:58 UTC (rev 6941)
@@ -0,0 +1,297 @@
+// -*- C++ -*-
+
+// NxProfileLearner.cc
+//
+// Copyright (C) 2007 Pierre-Antoine Manzagol
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pierre-Antoine Manzagol
+
+/*! \file NxProfileLearner.cc */
+
+
+#include &quot;NxProfileLearner.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    NxProfileLearner,
+    &quot;ONE LINE DESCRIPTION&quot;,
+    &quot;MULTI-LINE \nHELP&quot;);
+
+NxProfileLearner::NxProfileLearner()    :   profile_dim(1),
+                                            slr(0.0),
+                                            dc(0.0),
+                                            n_films(17770),
+                                            n_users(480189)
+/* ### Initialize all fields to their default value here */
+{
+    // ...
+
+    // ### You may (or not) want to call build_() to finish building the object
+    // ### (doing so assumes the parent classes' build_() have been called too
+    // ### in the parent classes' constructors, something that you must ensure)
+
+    // ### If this learner needs to generate random numbers, uncomment the
+    // ### line below to enable the use of the inherited PRandom object.
+    // random_gen = new PRandom();
+    if( !random_gen)
+        random_gen = new PRandom;
+}
+
+void NxProfileLearner::declareOptions(OptionList&amp; ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the &quot;flags&quot; of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    declareOption(ol, &quot;profile_dim&quot;, &amp;NxProfileLearner::profile_dim,
+                  OptionBase::buildoption,
+                  &quot;Dimension of the profiles to learn.&quot;);
+    declareOption(ol, &quot;slr&quot;, &amp;NxProfileLearner::slr,
+                  OptionBase::buildoption,
+                  &quot;Starting learning rate.&quot;);
+    declareOption(ol, &quot;dc&quot;, &amp;NxProfileLearner::dc,
+                  OptionBase::buildoption,
+                  &quot;Learning rate decrease constant.&quot;);
+
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void NxProfileLearner::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a &quot;reloaded&quot; object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or &quot;re-building&quot; of an object after a few &quot;tuning&quot;
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+
+    if( !train_set )
+        return;
+
+    cout &lt;&lt; &quot;build()&quot; &lt;&lt; endl;
+
+    f_profiles.resize(n_films, profile_dim);     //! matrix of film profiles (n_films*profile_dim)
+    u_profiles.resize(n_users, profile_dim);     //! matrix of user profiles (n_users*profile_dim)
+
+    forget();
+}
+
+// ### Nothing to add here, simply calls build_
+void NxProfileLearner::build()
+{
+    inherited::build();
+    build_();
+}
+
+
+void NxProfileLearner::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField(f_profiles, copies);
+    deepCopyField(u_profiles, copies);
+
+    // ### Remove this line when you have fully implemented this method.
+    //PLERROR(&quot;NxProfileLearner::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!&quot;);
+}
+
+
+int NxProfileLearner::outputsize() const
+{
+    // Compute and return the size of this learner's output (which typically
+    // may depend on its inputsize(), targetsize() and set options).
+    return 1;
+}
+
+void NxProfileLearner::forget()
+{
+    //! (Re-)initialize the PLearner in its fresh state (that state may depend
+    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
+    //! a fresh learner!)
+    /*!
+      A typical forget() method should do the following:
+      - call inherited::forget() to initialize its random number generator
+        with the 'seed' option
+      - initialize the learner's parameters, using this random generator
+      - stage = 0
+    */
+    inherited::forget();
+
+    cout &lt;&lt; &quot;forget&quot; &lt;&lt; endl;
+
+    //real delta = 1/sqrt(real(layer_sizes[i]));
+    real delta =  1.0/sqrt(real(profile_dim));;
+    random_gen-&gt;fill_random_uniform(u_profiles,-delta,delta);
+    random_gen-&gt;fill_random_uniform(f_profiles,-delta,delta);
+    stage = 0;
+
+}
+
+void NxProfileLearner::train()
+{
+    // The role of the train method is to bring the learner up to
+    // stage==nstages, updating train_stats with training costs measured
+    // on-line in the process.
+
+    static Vec input;  // static so we don't reallocate memory each time...
+    static Vec target; // (but be careful that static means shared!)
+    input.resize(inputsize());    // the train_set's inputsize()
+    target.resize(targetsize());  // the train_set's targetsize()
+    real weight, error, lr;
+
+    // This generic PLearner method does a number of standard stuff useful for
+    // (almost) any learner, and return 'false' if no training should take
+    // place. See PLearner.h for more details.
+    if (!initTrain())
+        return;
+
+    int nsamples = train_set-&gt;length();
+    // clear statistics of previous epoch
+    train_stats-&gt;forget();
+
+    PP&lt;ProgressBar&gt; pb;
+    if( report_progress &amp;&amp; stage &lt; nstages )
+        pb = new ProgressBar( &quot;Training &quot;+classname(), nstages-stage);
+
+    while(stage&lt;nstages)
+    {
+        train_set-&gt;getExample(stage%nsamples, input, target, weight);
+
+        PLASSERT( (input[0]&gt;=0) &amp;&amp; (input[0]&lt;n_films) &amp;&amp; (input[1]&gt;=0) &amp;&amp; (input[1]&lt;n_users) );
+
+        // save a function call by not using the functions
+        // We're using squared error cost, but dropping the 2 and taking the
+        // negative already
+        error = target[0] - dot( f_profiles((int)input[0]), u_profiles((int)input[1]) );
+
+    /*cout &lt;&lt; &quot; f &quot; &lt;&lt; filmProfileID &lt;&lt; &quot; &quot; &lt;&lt; f_profiles(filmProfileID) &lt;&lt; endl;
+    cout &lt;&lt; &quot; u &quot; &lt;&lt; userProfileID &lt;&lt; &quot; &quot; &lt;&lt; u_profiles(userProfileID) &lt;&lt; endl;
+    cout &lt;&lt; &quot;error &quot; &lt;&lt; error &lt;&lt; endl;*/
+
+        lr = slr/(1.0 + stage*dc);
+        // Not quite exact. Should do exact (copy the f_profiles entry)? 
+        // Or perhaps alternate based on stage parity?
+        f_profiles((int)input[0]) += lr * error * u_profiles((int)input[1]);
+        u_profiles((int)input[1]) += lr * error * f_profiles((int)input[0]);
+
+        // TODO add regularization
+/*        real delta_L2 = learning_rate * L2_penalty_factor;
+        if( delta_L2 &gt; 1 )
+            PLWARNING(&quot;GradNNetLayerModule::bpropUpdate:\n&quot;
+                      &quot;learning rate = %f is too large!\n&quot;, learning_rate);
+
+          if( delta_L2 &gt; 0. )
+                w_[j] *= (1 - delta_L2);
+
+
+*/
+        //train_stats-&gt;update(train_costs)
+        ++stage;
+        if( pb )
+            pb-&gt;update( stage );
+    }
+
+    train_stats-&gt;finalize(); // finalize statistics for this epoch
+
+}
+
+// Compute the output from the input.
+void NxProfileLearner::computeOutput(const Vec&amp; input, Vec&amp; output) const
+{
+    int nout = outputsize();
+    output.resize(nout);
+
+    PLASSERT( (input[0]&gt;=0) &amp;&amp; (input[0]&lt;n_films) &amp;&amp; (input[1]&gt;=0) &amp;&amp; (input[1]&lt;n_users) );
+
+    output[0] = dot( f_profiles((int)input[0]), u_profiles((int)input[1]) );
+
+/*    cout &lt;&lt; &quot; f &quot; &lt;&lt; filmProfileID &lt;&lt; &quot; &quot; &lt;&lt; f_profiles(filmProfileID) &lt;&lt; endl;
+    cout &lt;&lt; &quot; u &quot; &lt;&lt; userProfileID &lt;&lt; &quot; &quot; &lt;&lt; u_profiles(userProfileID) &lt;&lt; endl;
+    cout &lt;&lt; &quot;output[0] &quot; &lt;&lt; output[0];*/
+}
+
+// Compute the costs from *already* computed output.
+void NxProfileLearner::computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
+                                           const Vec&amp; target, Vec&amp; costs) const
+{
+    real error = target[0] - output[0];
+    // the 16 is to put the error on the 1-5 rating basis
+    costs[0] = 16.0 * error * error;
+//cout &lt;&lt; &quot; error &quot; &lt;&lt; error &lt;&lt; &quot; cost[0] &quot; &lt;&lt; costs[0] &lt;&lt; endl;
+}
+
+TVec&lt;string&gt; NxProfileLearner::getTestCostNames() const
+{
+    // Return the names of the costs computed by computeCostsFromOutputs
+    // (these may or may not be exactly the same as what's returned by
+    // getTrainCostNames).
+    return getTrainCostNames();
+}
+
+TVec&lt;string&gt; NxProfileLearner::getTrainCostNames() const
+{
+    // Return the names of the objective costs that the train method computes
+    // and for which it updates the VecStatsCollector train_stats
+    // (these may or may not be exactly the same as what's returned by
+    // getTestCostNames).
+    TVec&lt;string&gt; costs;
+    costs.resize(1);
+    costs[0]=&quot;MSE&quot;;
+    return costs;
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners_experimental/netflix/NxProfileLearner.h
===================================================================
--- trunk/plearn_learners_experimental/netflix/NxProfileLearner.h	2007-04-25 15:00:42 UTC (rev 6940)
+++ trunk/plearn_learners_experimental/netflix/NxProfileLearner.h	2007-04-25 21:28:58 UTC (rev 6941)
@@ -0,0 +1,207 @@
+// -*- C++ -*-
+
+// NxProfileLearner.h
+//
+// Copyright (C) 2007 Pierre-Antoine Manzagol
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pierre-Antoine Manzagol
+
+/*! \file NxProfileLearner.h */
+
+
+#ifndef NxProfileLearner_INC
+#define NxProfileLearner_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See <A HREF="http://www.doxygen.org/manual.html">http://www.doxygen.org/manual.html</A>
+ *
+ * @todo Think about sorting the profiles by frequency to save access time.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class NxProfileLearner : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    int profile_dim;    //! dimension of the profiles to be learnt
+    real slr;           //! start learning rate
+    real dc;            //! learning rate decrease constant
+
+    //#####  Public NOT Options  ##############################################
+
+    int n_films;
+    int n_users;
+
+    //map&lt;int, int&gt; u_map;  //! userID to userProfileID
+    // We are already using modified IDs... see about this
+    //map&lt;int, int&gt; f_map;  //! filmID to filmProfileID
+
+    // The rest of the private stuff goes here
+    Mat f_profiles;     //! matrix of film profiles (n_films*profile_dim)
+    Mat u_profiles;     //! matrix of user profiles (n_users*profile_dim)
+
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    NxProfileLearner();
+
+
+    //#####  PLearner Member Functions  #######################################
+
+    //! Returns the size of this learner's output, (which typically
+    //! may depend on its inputsize(), targetsize() and set options).
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual int outputsize() const;
+
+    //! (Re-)initializes the PLearner in its fresh state (that state may depend
+    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
+    //! a fresh learner!).
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void forget();
+
+    //! The role of the train method is to bring the learner up to
+    //! stage==nstages, updating the train_stats collector with training costs
+    //! measured on-line in the process.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void train();
+
+    //! Computes the output from the input.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void computeOutput(const Vec&amp; input, Vec&amp; output) const;
+
+    //! Computes the costs from already computed output.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output,
+                                         const Vec&amp; target, Vec&amp; costs) const;
+
+    //! Returns the names of the costs computed by computeCostsFromOutpus (and
+    //! thus the test method).
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual TVec&lt;std::string&gt; getTestCostNames() const;
+
+    //! Returns the names of the objective costs that the train method computes
+    //! and  for which it updates the VecStatsCollector train_stats.
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual TVec&lt;std::string&gt; getTrainCostNames() const;
+
+
+    // *** SUBCLASS WRITING: ***
+    // While in general not necessary, in case of particular needs
+    // (efficiency concerns for ex) you may also want to overload
+    // some of the following methods:
+    // virtual void computeOutputAndCosts(const Vec&amp; input, const Vec&amp; target,
+    //                                    Vec&amp; output, Vec&amp; costs) const;
+    // virtual void computeCostsOnly(const Vec&amp; input, const Vec&amp; target,
+    //                               Vec&amp; costs) const;
+    // virtual void test(VMat testset, PP&lt;VecStatsCollector&gt; test_stats,
+    //                   VMat testoutputs=0, VMat testcosts=0) const;
+    // virtual int nTestCosts() const;
+    // virtual int nTrainCosts() const;
+    // virtual void resetInternalState();
+    // virtual bool isStatefulLearner() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(NxProfileLearner);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(NxProfileLearner);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000389.html">[Plearn-commits] r6940 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000391.html">[Plearn-commits] r6942 - trunk/plearn_learners_experimental/netflix
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#390">[ date ]</a>
              <a href="thread.html#390">[ thread ]</a>
              <a href="subject.html#390">[ subject ]</a>
              <a href="author.html#390">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
