<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8251 - trunk/plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-November/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8251%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200711131745.lADHjKX6023325%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001698.html">
   <LINK REL="Next"  HREF="001700.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8251 - trunk/plearn_learners/generic/EXPERIMENTAL</H1>
    <B>manzagop at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8251%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200711131745.lADHjKX6023325%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8251 - trunk/plearn_learners/generic/EXPERIMENTAL">manzagop at mail.berlios.de
       </A><BR>
    <I>Tue Nov 13 18:45:20 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001698.html">[Plearn-commits] r8250 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="001700.html">[Plearn-commits] r8252 -	branches/cgi-desjardin/plearn_learners/second_iteration
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1699">[ date ]</a>
              <a href="thread.html#1699">[ thread ]</a>
              <a href="subject.html#1699">[ subject ]</a>
              <a href="author.html#1699">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: manzagop
Date: 2007-11-13 18:45:16 +0100 (Tue, 13 Nov 2007)
New Revision: 8251

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h
Log:
- introduced an option for varying the required confidence 
- optimized the pvgrad() function


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc	2007-11-13 17:41:53 UTC (rev 8250)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.cc	2007-11-13 17:45:16 UTC (rev 8251)
@@ -57,12 +57,15 @@
       pv_deceleration(0.5),
       pv_min_samples(2),
       pv_required_confidence(0.80),
+      pv_conf_ct(0.0),
       pv_strategy(1),
       pv_random_sample_step(false),
       pv_self_discount(0.5),
       pv_other_discount(0.95),
       pv_within_neuron_discount(0.95),
-      n_updates(0)
+      n_updates(0),
+      limit_ratio(0.0),
+      n_small_ratios(0.0)
 {
     random_gen = new PRandom();
 }
@@ -105,6 +108,11 @@
                   OptionBase::buildoption,
                   &quot;Minimum required confidence (probability of being positive or negative) for taking a step.&quot;);
 
+    declareOption(ol, &quot;pv_conf_ct&quot;,
+                  &amp;PvGradNNet::pv_conf_ct,
+                  OptionBase::buildoption,
+                  &quot;Used for confidence adaptation.&quot;);
+
     declareOption(ol, &quot;pv_strategy&quot;,
                   &amp;PvGradNNet::pv_strategy,
                   OptionBase::buildoption,
@@ -215,6 +223,8 @@
     n_small_ratios=0.0;
     n_neuron_updates.fill(0);    
 //    pv_gradstats-&gt;forget();
+
+    limit_ratio = gauss_01_quantile(pv_required_confidence);
 }
 
 //! Performs the backprop update. Must be called after the fbpropNet.
@@ -249,12 +259,17 @@
         
 }
 
-void PvGradNNet::pvGrad()   
+void PvGradNNet::pvGrad()  
 {
     int np = all_params.length();
     real m, e;//, prob_pos, prob_neg;
-    real ratio;
-    real limit_ratio = gauss_01_quantile(pv_required_confidence);
+    //real ratio;
+    // move this stuff to a train function to avoid repeated computations
+    if( pv_conf_ct != 0.0 ) {     
+        real conf = pv_required_confidence; 
+        conf += (1.0-pv_required_confidence) * (stage/stage+pv_conf_ct);
+        limit_ratio = gauss_01_quantile(conf);
+    }
 
     for(int k=0; k&lt;np; k++) {
         // update stats
@@ -263,13 +278,16 @@
         pv_all_sumsquare[k] += all_params_gradient[k] * all_params_gradient[k];
 
         if(pv_all_nsamples[k]&gt;pv_min_samples)   {
-            m = pv_all_sum[k] / pv_all_nsamples[k];
+            real inv_pv_all_nsamples_k = 1./pv_all_nsamples[k];
+            real pv_all_sum_k = pv_all_sum[k];
+            m = pv_all_sum_k * inv_pv_all_nsamples_k;
             // e is the standard error
-            //e = sqrt( (pv_all_sumsquare[k] - (pv_all_sum[k]*pv_all_sum[k])/pv_all_nsamples[k]) / (real)(pv_all_nsamples[k]*(pv_all_nsamples[k]-1)) );
             // variance
-            e = real((pv_all_sumsquare[k] - square(pv_all_sum[k])/pv_all_nsamples[k])/(pv_all_nsamples[k]-1));
+            //e = real((pv_all_sumsquare[k] - square(pv_all_sum[k])/pv_all_nsamples[k])/(pv_all_nsamples[k]-1));
             // standard error 
-            e = sqrt(e/pv_all_nsamples[k]);
+            //e = sqrt(e*inv_pv_all_nsamples_k);
+            // This is an approxiamtion where we've raplaced a (nsamples-1) by nsamples
+            e = sqrt(pv_all_sumsquare[k]-pv_all_sum_k*m)*inv_pv_all_nsamples_k;
 
             // test to see if numerical problems
             if( fabs(m) &lt; 1e-15 || e &lt; 1e-15 )  {
@@ -282,14 +300,15 @@
             // Comparing the ratio would be sufficient.
             //prob_pos = gauss_01_cum(m/e);
             //prob_neg = 1.-prob_pos;
-            ratio = m/e;
+            //ratio = m/e;
 
             if(!pv_random_sample_step)  {
-    
+                real threshold = limit_ratio*e;
                 // We adapt the stepsize before taking the step
                 // gradient is positive
                 //if(prob_pos&gt;=pv_required_confidence)    {
-                if(ratio&gt;=limit_ratio)  {
+                //if(ratio&gt;=limit_ratio)  {
+                if(m&gt;=threshold)  {
                     //pv_all_stepsizes[k] *= (pv_all_stepsigns[k]?pv_acceleration:pv_deceleration);
                     if(pv_all_stepsigns[k]&gt;0)   {
                         pv_all_stepsizes[k]*=pv_acceleration;
@@ -309,7 +328,7 @@
                 }
                 // gradient is negative
                 //else if(prob_neg&gt;=pv_required_confidence)   {
-                if(ratio&lt;=-limit_ratio) {
+                else if(m&lt;=-threshold) {
                     //pv_all_stepsizes[k] *= ((!pv_all_stepsigns[k])?pv_acceleration:pv_deceleration);
                     if(pv_all_stepsigns[k]&lt;0)   {
                         pv_all_stepsizes[k]*=pv_acceleration;
@@ -356,8 +375,13 @@
     real m, e;//, prob_pos, prob_neg;
     int stepsign;
 
+    // TODO bring the confidenca treatment up to date (see pvGrad)
     real ratio;
-    real limit_ratio = gauss_01_quantile(pv_required_confidence);
+    real conf = pv_required_confidence;
+    if( pv_conf_ct != 0.0 ) {
+        conf += (1.0-pv_required_confidence) * (stage/stage+pv_conf_ct);
+    }
+    real limit_ratio = gauss_01_quantile(conf);
 
     // 
     real discount = pow(pv_other_discount,n_updates);
@@ -444,8 +468,13 @@
     real m, e;//, prob_pos, prob_neg;
     int stepsign;
 
+    // TODO bring the confidenca treatment up to date (see pvGrad)
     real ratio;
-    real limit_ratio = gauss_01_quantile(pv_required_confidence);
+    real conf = pv_required_confidence;
+    if( pv_conf_ct != 0.0 ) {
+        conf += (1.0-pv_required_confidence) * (stage/stage+pv_conf_ct);
+    }
+    real limit_ratio = gauss_01_quantile(conf);
 
     //
     real discount = pow(pv_other_discount,n_updates);

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h	2007-11-13 17:41:53 UTC (rev 8250)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/PvGradNNet.h	2007-11-13 17:45:16 UTC (rev 8251)
@@ -68,6 +68,7 @@
     //! Minimum required confidence (probability of being positive or negative)
     //! for taking a step.
     real pv_required_confidence;
+    real pv_conf_ct;
 
     int pv_strategy;
 
@@ -162,6 +163,7 @@
     //! accumulated statistics of gradients on each parameter.
     //PP&lt;VecStatsCollector&gt; pv_gradstats;
 
+    real limit_ratio;
     real n_small_ratios;
 };
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001698.html">[Plearn-commits] r8250 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="001700.html">[Plearn-commits] r8252 -	branches/cgi-desjardin/plearn_learners/second_iteration
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1699">[ date ]</a>
              <a href="thread.html#1699">[ thread ]</a>
              <a href="subject.html#1699">[ subject ]</a>
              <a href="author.html#1699">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
