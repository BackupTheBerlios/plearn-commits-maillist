<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8314 - trunk/plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-November/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8314%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200711281536.lASFa9FW029242%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001761.html">
   <LINK REL="Next"  HREF="001763.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8314 - trunk/plearn_learners/generic/EXPERIMENTAL</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8314%20-%20trunk/plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200711281536.lASFa9FW029242%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8314 - trunk/plearn_learners/generic/EXPERIMENTAL">tihocan at mail.berlios.de
       </A><BR>
    <I>Wed Nov 28 16:36:09 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001761.html">[Plearn-commits] r8313 - trunk/plearn_learners/regressors
</A></li>
        <LI>Next message: <A HREF="001763.html">[Plearn-commits] r8315 - trunk/doc
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1762">[ date ]</a>
              <a href="thread.html#1762">[ thread ]</a>
              <a href="subject.html#1762">[ subject ]</a>
              <a href="author.html#1762">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2007-11-28 16:36:09 +0100 (Wed, 28 Nov 2007)
New Revision: 8314

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
Log:
Added a new debug cost

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-11-27 18:34:24 UTC (rev 8313)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradSMPNNet.cc	2007-11-28 15:36:09 UTC (rev 8314)
@@ -560,8 +560,7 @@
             neuron_gradients.subMatColumns(k,layer_sizes[i]);
     }
     example_weights.resize(minibatch_size);
-    TVec&lt;string&gt; train_cost_names = getTrainCostNames() ;
-    train_costs.resize(minibatch_size,train_cost_names.length()-2 );
+    train_costs.resize(minibatch_size, nTestCosts());
 
     Profiler::activate();
 
@@ -763,15 +762,13 @@
 
     Profiler::reset(&quot;training&quot;);
     Profiler::start(&quot;training&quot;);
-    Profiler::pl_profile_start(&quot;Totaltraining&quot;);
+    //Profiler::pl_profile_start(&quot;Totaltraining&quot;);
     if( report_progress &amp;&amp; stage &lt; nstages )
         pb = new ProgressBar( &quot;Training &quot;+classname(),
                               nstages - stage );
 
-    Vec costs_plus_time(train_costs.width()+2);
-    costs_plus_time[train_costs.width()] = MISSING_VALUE;
-    costs_plus_time[train_costs.width()+1] = MISSING_VALUE;
-    Vec costs = costs_plus_time.subVec(0,train_costs.width());
+    Vec costs_plus_time(nTrainCosts(), MISSING_VALUE);
+    Vec costs = costs_plus_time.subVec(0, train_costs.width());
     int nsamples = train_set-&gt;length();
 
     // Obtain the number of CPUs we want to use.
@@ -873,8 +870,11 @@
     if (iam == 0) {
         //tmp_log &lt;&lt; &quot;Starting loop&quot; &lt;&lt; endl;
         //tmp_log.flush();
+        Profiler::reset(&quot;big_loop&quot;);
+        Profiler::start(&quot;big_loop&quot;);
     }
 
+    //pout &lt;&lt; &quot;CPU &quot; &lt;&lt; iam &lt;&lt; &quot;: my_stage_incr = &quot; &lt;&lt; my_stage_incr &lt;&lt; endl;
     for(int i = 0; i &lt; my_stage_incr; i++)
     {
         int sample = start + i % my_n_samples;
@@ -991,9 +991,11 @@
         */
     }
 
+
     if (iam == 0) {
         //tmp_log &lt;&lt; &quot;Loop ended&quot; &lt;&lt; endl;
         //tmp_log.flush();
+        Profiler::end(&quot;big_loop&quot;);
     }
 
     if (!wait_for_final_update) {
@@ -1018,8 +1020,8 @@
         }
     }
 
-    Profiler::reset(&quot;Synchronization&quot;);
-    Profiler::start(&quot;Synchronization&quot;);
+    //Profiler::reset(&quot;Synchronization&quot;);
+    //Profiler::start(&quot;Synchronization&quot;);
 
     //tmp_log &lt;&lt; &quot;Synchronization&quot; &lt;&lt; endl;
     //tmp_log.flush();
@@ -1083,7 +1085,7 @@
 
     //tmp_log &lt;&lt; &quot;Synchronized&quot; &lt;&lt; endl;
     //tmp_log.flush();
-    Profiler::end(&quot;Synchronization&quot;);
+    //Profiler::end(&quot;Synchronization&quot;);
     /*
     const Profiler::Stats&amp; synch_stats = Profiler::getStats(&quot;Synchronization&quot;);
     real synch_time = (synch_stats.user_duration + synch_stats.system_duration)
@@ -1114,16 +1116,22 @@
                 &quot;stage: %d)&quot;, stage, cur_stage);
 
     Profiler::end(&quot;training&quot;);
-    Profiler::pl_profile_end(&quot;Totaltraining&quot;);
+    //Profiler::pl_profile_end(&quot;Totaltraining&quot;);
+    /*
     if (verbosity&gt;0)
         Profiler::report(cout);
+        */
     const Profiler::Stats&amp; stats = Profiler::getStats(&quot;training&quot;);
+    const Profiler::Stats&amp; big_loop_stats = Profiler::getStats(&quot;big_loop&quot;);
     costs.fill(MISSING_VALUE);
     real ticksPerSec = Profiler::ticksPerSecond();
     real cpu_time = (stats.user_duration+stats.system_duration)/ticksPerSec;
     cumulative_training_time += cpu_time;
     costs_plus_time[train_costs.width()] = cpu_time;
     costs_plus_time[train_costs.width()+1] = cumulative_training_time;
+    costs_plus_time[train_costs.width()+2] =
+        (big_loop_stats.user_duration + big_loop_stats.system_duration) /
+        ticksPerSec;
     train_stats-&gt;update( costs_plus_time );
     train_stats-&gt;finalize(); // finalize statistics for this epoch
 
@@ -1218,17 +1226,13 @@
 //alternate
             PLERROR(&quot;No, I just want stochastic gradient!&quot;);
             if( params_natgrad_per_input_template &amp;&amp; i==1 ){ // parameters are transposed
-                Profiler::pl_profile_start(&quot;ProducScaleAccOnlineStep&quot;);
                 productScaleAcc(layer_params_gradient[i-1],
                             neuron_extended_outputs_per_layer[i-1], true,
                             next_neurons_gradient, false, 
                             1, 0);
-                Profiler::pl_profile_end(&quot;ProducScaleAccOnlineStep&quot;);
             }else{
-                Profiler::pl_profile_start(&quot;ProducScaleAccOnlineStep&quot;);
                 productScaleAcc(layer_params_gradient[i-1],next_neurons_gradient,true,
                             neuron_extended_outputs_per_layer[i-1],false,1,0);
-                Profiler::pl_profile_end(&quot;ProducScaleAccOnlineStep&quot;);
             }
             layer_params_gradient[i-1] *= 1.0/minibatch_size; // use the MEAN gradient
         } else {// just regular stochastic gradient
@@ -1372,11 +1376,11 @@
     out_log_file &lt;&lt; &quot;Starting to compute output on &quot; &lt;&lt; input &lt;&lt; endl;
     out_log_file.flush();
     */
-    Profiler::pl_profile_start(&quot;computeOutput&quot;);
+    //Profiler::pl_profile_start(&quot;computeOutput&quot;);
     neuron_outputs_per_layer[0](0) &lt;&lt; input;
     fpropNet(1,false);
     output &lt;&lt; neuron_outputs_per_layer[n_layers-1](0);
-    Profiler::pl_profile_end(&quot;computeOutput&quot;);
+    //Profiler::pl_profile_end(&quot;computeOutput&quot;);
     /*
     out_log_file &lt;&lt; &quot;Output computed&quot; &lt;&lt; endl;
     out_log_file.flush();
@@ -1405,31 +1409,15 @@
 
         // try to use BLAS for the expensive operation
         if (self_adjusted_scaling_and_bias &amp;&amp; i+1&lt;n_layers-1){
-            if (during_training)
-                Profiler::pl_profile_start(&quot;ProducScaleAccFpropTrain&quot;);
-            else
-                Profiler::pl_profile_start(&quot;ProducScaleAccFpropNoTrain&quot;);
             productScaleAcc(next_layer, prev_layer, false, 
                             (during_training || params_averaging_coeff==1.0)?
                             weights[i]:mweights[i], 
                             tw, 1, 0);
-            if (during_training)
-                Profiler::pl_profile_end(&quot;ProducScaleAccFpropTrain&quot;);
-            else
-                Profiler::pl_profile_end(&quot;ProducScaleAcccFpropNoTrain&quot;);
         }else{
-            if (during_training)
-                Profiler::pl_profile_start(&quot;ProducScaleAccFpropTrain&quot;);
-            else
-                Profiler::pl_profile_start(&quot;ProducScaleAcccFpropNoTrain&quot;);
             productScaleAcc(next_layer, prev_layer, false, 
                             (during_training || params_averaging_coeff==1.0)?
                             layer_params[i]:layer_mparams[i], 
                             tw, 1, 0);
-            if (during_training)
-                Profiler::pl_profile_end(&quot;ProducScaleAccFpropTrain&quot;);
-            else
-                Profiler::pl_profile_end(&quot;ProducScaleAcccFpropNoTrain&quot;);
         }
         // compute layer's output non-linearity
         if (i+1&lt;n_layers-1)
@@ -1467,32 +1455,24 @@
                                 *v *= rescale_factor*rescale_factor;
                             }
                         }
-                        Profiler::pl_profile_start(&quot;activation function&quot;);
                         *a = tanh((*a + *b) * *s);
-                        Profiler::pl_profile_end(&quot;activation function&quot;);
                     }
                 }
                 else{
-                    Profiler::pl_profile_start(&quot;activation function&quot;);
                     compute_tanh(L,L);
-                    Profiler::pl_profile_end(&quot;activation function&quot;);
                 }
             }
         else if (output_type==&quot;NLL&quot;)
             for (int k=0;k&lt;n_examples;k++)
             {
                 Vec L=next_layer(k);
-                Profiler::pl_profile_start(&quot;activation function&quot;);
                 log_softmax(L,L);
-                Profiler::pl_profile_end(&quot;activation function&quot;);
             }
         else if (output_type==&quot;cross_entropy&quot;)  {
             for (int k=0;k&lt;n_examples;k++)
             {
                 Vec L=next_layer(k);
-                Profiler::pl_profile_start(&quot;activation function&quot;);
                 log_sigmoid(L,L);
-                Profiler::pl_profile_end(&quot;activation function&quot;);
             }
          }
     }
@@ -1595,6 +1575,7 @@
     TVec&lt;string&gt; costs = getTestCostNames();
     costs.append(&quot;train_seconds&quot;);
     costs.append(&quot;cum_train_seconds&quot;);
+    costs.append(&quot;big_loop_seconds&quot;);
     return costs;
 }
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001761.html">[Plearn-commits] r8313 - trunk/plearn_learners/regressors
</A></li>
	<LI>Next message: <A HREF="001763.html">[Plearn-commits] r8315 - trunk/doc
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1762">[ date ]</a>
              <a href="thread.html#1762">[ thread ]</a>
              <a href="subject.html#1762">[ subject ]</a>
              <a href="author.html#1762">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
