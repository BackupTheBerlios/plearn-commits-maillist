<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7220 - in trunk/plearn_learners/generic: .	EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7220%20-%20in%20trunk/plearn_learners/generic%3A%20.%0A%09EXPERIMENTAL&In-Reply-To=%3C200705212114.l4LLESNT003200%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000668.html">
   <LINK REL="Next"  HREF="000670.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7220 - in trunk/plearn_learners/generic: .	EXPERIMENTAL</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7220%20-%20in%20trunk/plearn_learners/generic%3A%20.%0A%09EXPERIMENTAL&In-Reply-To=%3C200705212114.l4LLESNT003200%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7220 - in trunk/plearn_learners/generic: .	EXPERIMENTAL">yoshua at mail.berlios.de
       </A><BR>
    <I>Mon May 21 23:14:28 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000668.html">[Plearn-commits] r7219 - trunk/python_modules/plearn/pymake
</A></li>
        <LI>Next message: <A HREF="000670.html">[Plearn-commits] r7221 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#669">[ date ]</a>
              <a href="thread.html#669">[ thread ]</a>
              <a href="subject.html#669">[ subject ]</a>
              <a href="author.html#669">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-05-21 23:14:28 +0200 (Mon, 21 May 2007)
New Revision: 7220

Modified:
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h
   trunk/plearn_learners/generic/NatGradEstimator.cc
   trunk/plearn_learners/generic/NatGradEstimator.h
Log:
Generalized NatGradEstimator to GradientCorrector


Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-05-21 21:12:55 UTC (rev 7219)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-05-21 21:14:28 UTC (rev 7220)
@@ -49,7 +49,7 @@
     &quot;A separate covariance matrix is estimated for the gradients associated with the\n&quot;
     &quot;the input weights of each neuron, and a covariance matrix between the gradients\n&quot;
     &quot;on the neurons is also computed. These are combined to obtained an adjusted gradient\n&quot;
-    &quot;on all the parameters. The class NatGradEstimator embodies the adjustment algorithm.\n&quot;
+    &quot;on all the parameters. The class GradientCorrector embodies the adjustment algorithm.\n&quot;
     &quot;Users may specify different options for the estimator that is used for correcting\n&quot;
     &quot;the neurons gradients and for the estimator that is used for correcting the\n&quot;
     &quot;parameters gradients (separately for each neuron).\n&quot;
@@ -165,42 +165,42 @@
 
     declareOption(ol, &quot;neurons_natgrad_template&quot;, &amp;NatGradNNet::neurons_natgrad_template,
                   OptionBase::buildoption,
-                  &quot;Optional template NatGradEstimator for the neurons gradient.\n&quot;
+                  &quot;Optional template GradientCorrector for the neurons gradient.\n&quot;
                   &quot;If not provided, then the natural gradient correction\n&quot;
                   &quot;on the neurons gradient is not performed.\n&quot;);
 
     declareOption(ol, &quot;neurons_natgrad_per_layer&quot;, 
                   &amp;NatGradNNet::neurons_natgrad_per_layer,
                   OptionBase::learntoption,
-                  &quot;Vector of NatGradEstimator objects for the gradient on the neurons of each layer.\n&quot;
+                  &quot;Vector of GradientCorrector objects for the gradient on the neurons of each layer.\n&quot;
                   &quot;They are copies of the neuron_natgrad_template provided by the user.\n&quot;);
 
     declareOption(ol, &quot;params_natgrad_template&quot;, 
                   &amp;NatGradNNet::params_natgrad_template,
                   OptionBase::buildoption,
-                  &quot;Optional template NatGradEstimator object for the gradient of the parameters inside each neuron\n&quot;
+                  &quot;Optional template GradientCorrector object for the gradient of the parameters inside each neuron\n&quot;
                   &quot;It is replicated in the params_natgrad vector, for each neuron\n&quot;
                   &quot;If not provided, then the neuron-specific natural gradient estimator is not used.\n&quot;);
 
     declareOption(ol, &quot;params_natgrad_per_input_template&quot;,
                   &amp;NatGradNNet::params_natgrad_per_input_template,
                   OptionBase::buildoption,
-                  &quot;Optional template NatGradEstimator object for the gradient of the parameters of the first layer\n&quot;
+                  &quot;Optional template GradientCorrector object for the gradient of the parameters of the first layer\n&quot;
                   &quot;grouped based upon their input. It is replicated in the params_natgrad_per_group vector, for each group.\n&quot;
                   &quot;If provided, overides the params_natgrad_template for the parameters of the first layer.\n&quot;);
 
     declareOption(ol, &quot;params_natgrad_per_group&quot;, 
                     &amp;NatGradNNet::params_natgrad_per_group,
                     OptionBase::learntoption,
-                    &quot;Vector of NatGradEstimator objects for the gradient inside groups of parameters.\n&quot;
+                    &quot;Vector of GradientCorrector objects for the gradient inside groups of parameters.\n&quot;
                     &quot;They are copies of the params_natgrad_template and params_natgrad_per_input_template\n&quot;
                     &quot;templates provided by the user.\n&quot;);
 
     declareOption(ol, &quot;full_natgrad&quot;, &amp;NatGradNNet::full_natgrad,
                   OptionBase::buildoption,
-                  &quot;NatGradEstimator for all the parameter gradients simultaneously.\n&quot;
+                  &quot;GradientCorrector for all the parameter gradients simultaneously.\n&quot;
                   &quot;This should not be set if neurons_natgrad or params_natgrad_template\n&quot;
-                  &quot;is provided. If none of the NatGradEstimators is provided, then\n&quot;
+                  &quot;is provided. If none of the GradientCorrectors is provided, then\n&quot;
                   &quot;regular stochastic gradient is performed.\n&quot;);
 
     declareOption(ol, &quot;output_type&quot;, 
@@ -338,7 +338,7 @@
     if(use_pvgrad &amp;&amp; minibatch_size!=1)
         PLERROR(&quot;PV's gradient technique (triggered by use_pvgrad): support for minibatch not yet implemented (must have minibatch_size=1)&quot;);
     
-    while (hidden_layer_sizes[hidden_layer_sizes.length()-1]==0)
+    while (hidden_layer_sizes.length()&gt;0 &amp;&amp; hidden_layer_sizes[hidden_layer_sizes.length()-1]==0)
         hidden_layer_sizes.resize(hidden_layer_sizes.length()-1);
     n_layers = hidden_layer_sizes.length()+2;
     layer_sizes.resize(n_layers);
@@ -775,7 +775,7 @@
     {
         for (int i=0;i&lt;params_natgrad_per_group.length();i++)
         {
-            NatGradEstimator&amp; neuron_natgrad = *(params_natgrad_per_group[i]);
+            GradientCorrector&amp; neuron_natgrad = *(params_natgrad_per_group[i]);
             neuron_natgrad(t/minibatch_size,group_params_gradient[i],group_params_delta[i]); // compute update direction by natural gradient
         }
 //alternate

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h	2007-05-21 21:12:55 UTC (rev 7219)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.h	2007-05-21 21:14:28 UTC (rev 7220)
@@ -41,7 +41,7 @@
 #define NatGradNNet_INC
 
 #include &lt;plearn_learners/generic/PLearner.h&gt;
-#include &lt;plearn_learners/generic/NatGradEstimator.h&gt;
+#include &lt;plearn_learners/generic/GradientCorrector.h&gt;
 #include &lt;plearn/sys/Profiler.h&gt;
 //#include &quot;CorrelationProfiler.h&quot;
 
@@ -87,12 +87,12 @@
 
     //! natural gradient estimator for neurons
     //! (if 0 then do not correct the gradient on neurons)
-    PP&lt;NatGradEstimator&gt; neurons_natgrad_template;
-    TVec&lt;PP&lt;NatGradEstimator&gt; &gt; neurons_natgrad_per_layer;
+    PP&lt;GradientCorrector&gt; neurons_natgrad_template;
+    TVec&lt;PP&lt;GradientCorrector&gt; &gt; neurons_natgrad_per_layer;
 
     //! natural gradient estimator for the parameters within each neuron
     //! (if 0 then do not correct the gradient on each neuron weight)
-    PP&lt;NatGradEstimator&gt; params_natgrad_template;
+    PP&lt;GradientCorrector&gt; params_natgrad_template;
     //! natural gradient estimator solely for the parameters of the first
     //! layer. If present, performs over groups of parameters related to the
     //! same input (this includes the additional bias input).
@@ -100,15 +100,15 @@
     //! no natural gradient performed on the groups of a neuron's parameters:
     //! params_natgrad_template is not applied for the first hidden layer's
     //! parameters). 
-    PP&lt;NatGradEstimator&gt; params_natgrad_per_input_template;
+    PP&lt;GradientCorrector&gt; params_natgrad_per_input_template;
 
     //! the above templates are used by the user to specifiy all the elements of the vector below
-    TVec&lt;PP&lt;NatGradEstimator&gt; &gt; params_natgrad_per_group;
+    TVec&lt;PP&lt;GradientCorrector&gt; &gt; params_natgrad_per_group;
 
     //! optionally, if neurons_natgrad==0 and params_natgrad_template==0, one can
     //! have regular stochastic gradient descent, or full-covariance natural gradient
     //! using the natural gradient estimator below
-    PP&lt;NatGradEstimator&gt; full_natgrad;
+    PP&lt;GradientCorrector&gt; full_natgrad;
 
     //! type of output cost: &quot;NLL&quot; for classification problems, &quot;MSE&quot; for regression
     string output_type;

Modified: trunk/plearn_learners/generic/NatGradEstimator.cc
===================================================================
--- trunk/plearn_learners/generic/NatGradEstimator.cc	2007-05-21 21:12:55 UTC (rev 7219)
+++ trunk/plearn_learners/generic/NatGradEstimator.cc	2007-05-21 21:14:28 UTC (rev 7220)
@@ -2,7 +2,7 @@
 
 // NatGradEstimator.cc
 //
-// Copyright (C) 2007 yoshua Bengio
+// Copyright (C) 2007 Yoshua Bengio
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: yoshua Bengio
+// Authors: Yoshua Bengio
 
 /*! \file NatGradEstimator.cc */
 
@@ -48,7 +48,8 @@
 
 PLEARN_IMPLEMENT_OBJECT(
     NatGradEstimator,
-    &quot;Convert a sequence of gradients into covariance-corrected (natural gradient) directions.\n&quot;,
+    &quot;Subclass of GradientCorrector that computes an online natural gradient update direction.\n&quot;,
+    &quot;Convert a sequence of gradients into covariance-corrected (natural gradient) directions.\n&quot;
     &quot;The algorithm used for converting a sequence of n-dimensional gradients g_t\n&quot;
     &quot;into covariance-corrected update directions v_t is the following:\n\n&quot;
     &quot;operator(int t, Vec g, Vec v): (reads g and writes v)\n&quot;
@@ -72,8 +73,6 @@
       lambda(1),
       n_eigen(10),
       gamma(0.99),
-      n_dim(-1),
-      verbosity(0),
       renormalize(true),
       previous_t(-1),
       first_t(-1)
@@ -85,17 +84,13 @@
 void NatGradEstimator::build()
 {
     inherited::build();
-    build_();
+    init();
 }
 
 void NatGradEstimator::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
 
-    // ### Call deepCopyField on all &quot;pointer-like&quot; fields
-    // ### that you wish to be deepCopied rather than
-    // ### shallow-copied.
-    // ### ex:
     deepCopyField(Ut, copies);
     deepCopyField(D, copies);
     deepCopyField(Xt, copies);
@@ -149,9 +144,6 @@
                   OptionBase::buildoption,
                   &quot;Whether to renormalize z wrt scaling that gamma produces\n&quot;);
 
-    declareOption(ol, &quot;n_dim&quot;, &amp;NatGradEstimator::n_dim,
-                  OptionBase::learntoption,
-                  &quot;Number of dimensions of the gradient vectors\n&quot;);
     declareOption(ol, &quot;Ut&quot;, &amp;NatGradEstimator::Ut,
                   OptionBase::learntoption,
                   &quot;Estimated scaled principal eigenvectors of the gradients covariance matrix\n&quot;
@@ -174,11 +166,6 @@
     inherited::declareOptions(ol);
 }
 
-void NatGradEstimator::build_()
-{
-    init();
-}
-
 void NatGradEstimator::init()
 {
     if (n_dim&gt;=0)

Modified: trunk/plearn_learners/generic/NatGradEstimator.h
===================================================================
--- trunk/plearn_learners/generic/NatGradEstimator.h	2007-05-21 21:12:55 UTC (rev 7219)
+++ trunk/plearn_learners/generic/NatGradEstimator.h	2007-05-21 21:14:28 UTC (rev 7220)
@@ -2,7 +2,7 @@
 
 // NatGradEstimator.h
 //
-// Copyright (C) 2007 yoshua Bengio
+// Copyright (C) 2007 Yoshua Bengio
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: yoshua Bengio
+// Authors: Yoshua Bengio
 
 /*! \file NatGradEstimator.h */
 
@@ -42,21 +42,20 @@
 
 #include &lt;plearn/base/Object.h&gt;
 #include &lt;plearn/math/TMat_impl.h&gt;
+#include &lt;plearn_learners/generic/GradientCorrector.h&gt;
 
 namespace PLearn {
 
 /**
- * Class used for converting a sequence of n-dimensional gradients g_t
+ * GradientCorrector subclass used for converting a sequence of n-dimensional gradients g_t
  * into covariance-corrected update directions v_t, approximating
  *     v_t = inv(C_t) g_t,
  * with C_t = gamma C_{t-1} + g_t g_t'.
  * 
- * There is a main method, the operator(), which takes a g_t and fills v_t.
- * The process can be initialized by init(). 
  */
-class NatGradEstimator : public Object
+class NatGradEstimator : public GradientCorrector
 {
-    typedef Object inherited;
+    typedef GradientCorrector inherited;
 
 public:
     //#####  Public Build Options  ############################################
@@ -75,12 +74,6 @@
     //! forgetting factor in moving average estimator of covariance
     real gamma;
 
-    //! number of input dimensions (size of g_t or v_t)
-    int n_dim;
-
-    //! verbosity level, track improvement, spectrum, etgc.
-    int verbosity;
-
     bool renormalize;
 
     //! use the formula Ginv &lt;-- (1+eps) Ginv - eps Ginv g g' Ginv
@@ -95,17 +88,19 @@
     // ### initializes all fields to reasonable default values.
     NatGradEstimator();
 
+    virtual void build();
+
     // Your other public member functions go here
 
     //! initialize the object to start collecting covariance statistics from fresh
-    void init();
+    virtual void init();
 
     //! main method of this class: reads from the gradient &quot;g&quot; field
     //! and writes into the &quot;v&quot; field an estimator of inv(cov) g.
     //! The argument is an index over examples, which is used to
     //! know when cycling through a minibatch. The statistics on
     //! the covariance are updated.
-    void operator()(int t, const Vec&amp; g, Vec v);
+    virtual void operator()(int t, const Vec&amp; g, Vec v);
 
     //#####  PLearn::Object Protocol  #########################################
 
@@ -114,9 +109,6 @@
     // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
     PLEARN_DECLARE_OBJECT(NatGradEstimator);
 
-    // Simply calls inherited::build() then build_()
-    virtual void build();
-
     //! Transforms a shallow copy into a deep copy
     // (PLEASE IMPLEMENT IN .cc)
     virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
@@ -152,10 +144,6 @@
 private:
     //#####  Private Member Functions  ########################################
 
-    //! This does the actual building.
-    // (PLEASE IMPLEMENT IN .cc)
-    void build_();
-
 private:
     //#####  Private Data Members  ############################################
 
@@ -166,17 +154,6 @@
     Mat Vkt; //! sub-matrix of Vt with first n_eigen eigen-vectors
     Mat A; // matrix for linear system solving
     TVec&lt;int&gt; pivots; // pivots for linear system solving
-    /*
-    //! temporary buffer
-    Vec tmp_v;
-    //! Gram matrix, of dimension (k + minibatch_size, k + minibatch_size)
-    //! and its sub-matrices
-    Mat M, M11, M12, M21, M22;
-    //! k+1 eigenvectors of the Gram matrix (in the rows)
-    Mat Vbt; //! sub-matrix of Vt with last cov_minibatch_size elements of each eigen-vector
-    //! temp for new value of Ut
-    Mat newUt;
-    */
 };
 
 // Declares a few other classes and functions related to this class


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000668.html">[Plearn-commits] r7219 - trunk/python_modules/plearn/pymake
</A></li>
	<LI>Next message: <A HREF="000670.html">[Plearn-commits] r7221 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#669">[ date ]</a>
              <a href="thread.html#669">[ thread ]</a>
              <a href="subject.html#669">[ subject ]</a>
              <a href="author.html#669">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
