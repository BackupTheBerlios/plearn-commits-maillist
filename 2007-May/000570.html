<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7121 - in trunk/plearn_learners/distributions: .	EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7121%20-%20in%20trunk/plearn_learners/distributions%3A%20.%0A%09EXPERIMENTAL&In-Reply-To=%3C200705161448.l4GEm3SI017057%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000569.html">
   <LINK REL="Next"  HREF="000571.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7121 - in trunk/plearn_learners/distributions: .	EXPERIMENTAL</H1>
    <B>plearner at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7121%20-%20in%20trunk/plearn_learners/distributions%3A%20.%0A%09EXPERIMENTAL&In-Reply-To=%3C200705161448.l4GEm3SI017057%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7121 - in trunk/plearn_learners/distributions: .	EXPERIMENTAL">plearner at mail.berlios.de
       </A><BR>
    <I>Wed May 16 16:48:03 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000569.html">[Plearn-commits] r7120 - trunk/scripts/Skeletons
</A></li>
        <LI>Next message: <A HREF="000571.html">[Plearn-commits] r7122 - in trunk/plearn_learners/online: .	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1/Split0	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-1	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-1/Split0
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#570">[ date ]</a>
              <a href="thread.html#570">[ thread ]</a>
              <a href="subject.html#570">[ subject ]</a>
              <a href="author.html#570">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: plearner
Date: 2007-05-16 16:48:03 +0200 (Wed, 16 May 2007)
New Revision: 7121

Added:
   trunk/plearn_learners/distributions/EXPERIMENTAL/LocallyMagnifiedDistribution.cc
   trunk/plearn_learners/distributions/EXPERIMENTAL/LocallyMagnifiedDistribution.h
   trunk/plearn_learners/distributions/EXPERIMENTAL/NeighborhoodBoxVolumeDensityEstimator.cc
   trunk/plearn_learners/distributions/EXPERIMENTAL/NeighborhoodBoxVolumeDensityEstimator.h
Removed:
   trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.cc
   trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.h
   trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.cc
   trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.h
Log:
Moved a couple of distributions to EXPERIMENTAL


Copied: trunk/plearn_learners/distributions/EXPERIMENTAL/LocallyMagnifiedDistribution.cc (from rev 7120, trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.cc)

Copied: trunk/plearn_learners/distributions/EXPERIMENTAL/LocallyMagnifiedDistribution.h (from rev 7120, trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.h)

Copied: trunk/plearn_learners/distributions/EXPERIMENTAL/NeighborhoodBoxVolumeDensityEstimator.cc (from rev 7120, trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.cc)

Copied: trunk/plearn_learners/distributions/EXPERIMENTAL/NeighborhoodBoxVolumeDensityEstimator.h (from rev 7120, trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.h)

Deleted: trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.cc
===================================================================
--- trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.cc	2007-05-16 02:27:01 UTC (rev 7120)
+++ trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.cc	2007-05-16 14:48:03 UTC (rev 7121)
@@ -1,389 +0,0 @@
-// -*- C++ -*-
-
-// LocallyMagnifiedDistribution.cc
-//
-// Copyright (C) 2005 Pascal Vincent
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-//
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-//
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-//
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-//
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-/* *******************************************************
- * $Id$
- ******************************************************* */
-
-// Authors: Pascal Vincent
-
-/*! \file LocallyMagnifiedDistribution.cc */
-
-
-#include &quot;LocallyMagnifiedDistribution.h&quot;
-#include &lt;plearn/vmat/ConcatColumnsVMatrix.h&gt;
-#include &lt;plearn/vmat/MemoryVMatrix.h&gt;
-#include &lt;plearn_learners/nearest_neighbors/ExhaustiveNearestNeighbors.h&gt;
-#include &lt;plearn/base/tostring.h&gt;
-
-namespace PLearn {
-using namespace std;
-
-//////////////////
-// LocallyMagnifiedDistribution //
-//////////////////
-LocallyMagnifiedDistribution::LocallyMagnifiedDistribution()
-    :mode(0),
-     nneighbors(-1),
-     use_rank_weighting(false),
-     width_neighbor(0),
-     width_factor(1.0),
-     width_optionname(&quot;sigma&quot;)
-{
-}
-
-PLEARN_IMPLEMENT_OBJECT(LocallyMagnifiedDistribution,
-                        &quot;Density estimation by fitting a local model (localdistr) to a view of the training samples, magnified locally around the test point.&quot;,
-                        &quot;&quot;
-    );
-
-////////////////////
-// declareOptions //
-////////////////////
-void LocallyMagnifiedDistribution::declareOptions(OptionList&amp; ol)
-{
-    // ### Declare all of this object's options here
-    // ### For the &quot;flags&quot; of each option, you should typically specify
-    // ### one of OptionBase::buildoption, OptionBase::learntoption or
-    // ### OptionBase::tuningoption. Another possible flag to be combined with
-    // ### is OptionBase::nosave
-
-    declareOption(ol, &quot;mode&quot;, &amp;LocallyMagnifiedDistribution::mode, OptionBase::buildoption,
-                  &quot;Output computation mode&quot;);
-
-    declareOption(ol, &quot;nneighbors&quot;, &amp;LocallyMagnifiedDistribution::nneighbors, OptionBase::buildoption,
-                  &quot;If &lt;=0 we use all training points (with an appropriate weight).\n&quot;
-                  &quot;If &gt;0 we consider only that many neighbors of the test point;\n&quot;
-                  &quot;(it's equivalent to giving all other data points a weight of 0)\n&quot;);
-
-    declareOption(ol, &quot;use_rank_weighting&quot;, &amp;LocallyMagnifiedDistribution::use_rank_weighting, OptionBase::buildoption,
-                  &quot;If true, then we ignore the weighting_kernel, and ascribe weight 1/k to the neighbors\n&quot;
-                  &quot;where k is the index of the neighbor from 1 to nneighbors&quot;);
-
-    declareOption(ol, &quot;weighting_kernel&quot;, &amp;LocallyMagnifiedDistribution::weighting_kernel, OptionBase::buildoption,
-                  &quot;The magnifying kernel that will be used to locally weigh the samples.\n&quot;
-                  &quot;If it is left null, and use_rank_weighting is false, then all \n&quot;
-                  &quot;nneighbors will receive a weight of 1\n&quot;);
-
-    declareOption(ol, &quot;width_neighbor&quot;, &amp;LocallyMagnifiedDistribution::width_neighbor, OptionBase::buildoption,
-                  &quot;If width_neighbor&gt;0, kernel width is set to be the distance to the \n&quot;
-                  &quot;width_neighbor'th neighbor times the width_factor (Euclidean distance neighbors for now)\n&quot;
-                  &quot;If width_neighbor==0, kernel is left as specified upon construction&quot;);
-
-    declareOption(ol, &quot;width_factor&quot;, &amp;LocallyMagnifiedDistribution::width_factor, OptionBase::buildoption,
-                  &quot;Only used if width_neighbor&gt;0 (see width_neighbor)&quot;);
-
-    declareOption(ol, &quot;width_optionname&quot;, &amp;LocallyMagnifiedDistribution::width_optionname, OptionBase::buildoption,
-                  &quot;Only used if width_neighbor&gt;0. The name of the option in the weighting kernel that should be used to set or modifiy its width&quot;);
-
-    declareOption(ol, &quot;localdistr&quot;, &amp;LocallyMagnifiedDistribution::localdistr, OptionBase::buildoption,
-                  &quot;The distribution that will be trained with local weights obtained from the magnifying kernel&quot;);
-
-    declareOption(ol, &quot;train_set&quot;, &amp;LocallyMagnifiedDistribution::train_set, OptionBase::learntoption,
-                  &quot;We need to store the training set, as this learner is memory-based...&quot;);
-
-    // declareOption(ol, &quot;NN&quot;, &amp;LocallyMagnifiedDistribution::NN, OptionBase::learntoption,
-    //              &quot;The nearest neighbor algorithm used to find nearest neighbors&quot;);
-
-    // Now call the parent class' declareOptions().
-    inherited::declareOptions(ol);
-}
-
-///////////
-// build //
-///////////
-void LocallyMagnifiedDistribution::build()
-{
-    // ### Nothing to add here, simply calls build_().
-    inherited::build();
-    build_();
-}
-
-////////////
-// build_ //
-////////////
-void LocallyMagnifiedDistribution::build_()
-{
-    // ### This method should do the real building of the object,
-    // ### according to set 'options', in *any* situation.
-    // ### Typical situations include:
-    // ###  - Initial building of an object from a few user-specified options
-    // ###  - Building of a &quot;reloaded&quot; object: i.e. from the complete set of all serialised options.
-    // ###  - Updating or &quot;re-building&quot; of an object after a few &quot;tuning&quot; options have been modified.
-    // ### You should assume that the parent class' build_() has already been called.
-
-    int actual_nneighbors = max(nneighbors, width_neighbor);
-    if(train_set.isNotNull())
-        actual_nneighbors = min(actual_nneighbors, train_set.length());
-
-    if(actual_nneighbors&gt;0)
-    {
-        NN = new ExhaustiveNearestNeighbors(); // for now use Exhaustive search and default Euclidean distance
-        NN-&gt;num_neighbors = actual_nneighbors;
-        NN-&gt;copy_input = false;
-        NN-&gt;copy_target = false;
-        NN-&gt;copy_weight = false;
-        NN-&gt;copy_index = true;
-        NN-&gt;build();
-        NN_outputs.resize(actual_nneighbors);
-        NN_costs.resize(actual_nneighbors);
-        if(train_set.isNotNull())
-        {
-            NN-&gt;setTrainingSet(train_set);
-            NN-&gt;train();
-        }
-    }
-
-
-    // ### If the distribution is conditional, you should finish build_() by:
-    // PDistribution::finishConditionalBuild();
-
-}
-
-/////////////////
-// log_density //
-/////////////////
-real LocallyMagnifiedDistribution::log_density(const Vec&amp; y) const
-{
-    int l = train_set.length();
-    int w = inputsize();
-    int ws = train_set-&gt;weightsize();
-    trainsample.resize(w+ws);
-    Vec input = trainsample.subVec(0,w);
-
-    PLASSERT(targetsize()==0);
-
-    int actual_nneighbors = max(nneighbors, width_neighbor);
-    if(actual_nneighbors&gt;l)
-        actual_nneighbors = l;
-
-    if(actual_nneighbors&gt;0)
-        NN-&gt;computeOutputAndCosts(y, emptyvec, NN_outputs, NN_costs);
-
-    if(width_neighbor&gt;0 &amp;&amp; weighting_kernel.isNotNull()) // adapt weighting kernel width
-    {
-        // Find distance d to width_neighbor neighbour
-        real d = NN_costs[width_neighbor-1];
-        // Now set new kernel width:
-        real newwidth = d*width_factor;
-        weighting_kernel-&gt;setOption(width_optionname,tostring(newwidth));
-        weighting_kernel-&gt;build(); // rebuild to adapt to width change
-    }
-
-    double weightsum = 0;
-
-    VMat local_trainset;
-    if(nneighbors&gt;0) // we'll use only the neighbors
-    {
-        int n = NN_outputs.length();
-        Mat neighbors(n, w+1);
-        neighbors.lastColumn().fill(1.0); // default weight 1.0
-        for(int k=0; k&lt;n; k++)
-        {
-            Vec neighbors_k = neighbors(k);
-            Vec neighbors_row = neighbors_k.subVec(0,w+ws);
-            Vec neighbors_input = neighbors_row.subVec(0,w);
-            train_set-&gt;getRow(int(NN_outputs[k]),neighbors_row);
-            real weight = 1.;
-            if(use_rank_weighting)
-                weight = 1./(1+k); 
-            else if(weighting_kernel.isNotNull())
-                weight = weighting_kernel(y,neighbors_input);
-            weightsum += weight;
-            neighbors_k[w] *= weight;
-        }
-        local_trainset = new MemoryVMatrix(neighbors);
-        local_trainset-&gt;defineSizes(w,0,1); 
-    }
-    else // we'll use all the points
-    {
-        // 'weights' will contain the &quot;localization&quot; weights for the current test point.
-        weights.resize(l);
-        for(int i=0; i&lt;l; i++)
-        {
-            train_set-&gt;getRow(i,trainsample);
-            real weight = 1.;
-            if(use_rank_weighting)
-                PLERROR(&quot;use_rank_weighting=true, but nneigbors&lt;=0. rank weighting requires specifying a number of neighbors (as it's this that will give the ranking&quot;);
-            else if(weighting_kernel.isNotNull())
-                weight = weighting_kernel(y,input);
-            if(ws==1)
-                weight *= trainsample[w];
-            weightsum += weight;
-            weights[i] = weight;
-        }
-
-        VMat weight_column(columnmatrix(weights));
-        if(ws==0) // append weight column
-            local_trainset = hconcat(train_set, weight_column);
-        else // replace last column by weight column
-            local_trainset = hconcat(train_set.subMatColumns(0,w), weight_column);
-        local_trainset-&gt;defineSizes(w,0,1);        
-    }
-
-    // perr &lt;&lt; &quot;local_trainset =&quot; &lt;&lt; endl &lt;&lt; local_trainset-&gt;toMat() &lt;&lt; endl;
-
-
-#if 0
-// OLD CODE
-    if(use_rank_weighting)  // use only the neighbors with rank weighting
-    {
-        Mat neighbors(actual_nneighbors, w+1);
-        for(int k=0; k&lt;actual_nneighbors; k++)
-        {
-            train_set-&gt;getSubRow(int(NN_outputs[k]),0,neighbors(k).subVec(0,w));
-            real weight = 1./(1+k); 
-            neighbors(k,w) = weight;
-            weightsum += weight;
-        }
-        local_trainset = new MemoryVMatrix(neighbors);
-        local_trainset-&gt;defineSizes(w,0,1); 
-    }
-    else if(weighting_kernel.isNotNull()) // build a weighted local_trainset
-    {
-        for(int i=0; i&lt;l; i++)
-        {
-            train_set-&gt;getRow(i,trainsample);
-            real weight = weighting_kernel(y,input);
-            if(ws==1)
-                weight *= trainsample[w];
-            weights[i] = weight;
-            weightsum += weight;
-        }
-
-        VMat weight_column(columnmatrix(weights));
-
-        if(ws==0) // append weight column
-            local_trainset = hconcat(train_set, weight_column);
-        else // replace last column by weight column
-            local_trainset = hconcat(train_set.subMatColumns(0,inputsize()), weight_column);
-        local_trainset-&gt;defineSizes(w,0,1);        
-    }
-    else // no weighting kernel, we just use the neighbors
-    {
-        Mat neighbors_input(actual_nneighbors, w);
-        for(int k=0; k&lt;actual_nneighbors; k++)
-            train_set-&gt;getSubRow(int(NN_outputs[k]),0,neighbors_input(k));
-        local_trainset = new MemoryVMatrix(neighbors_input);
-        local_trainset-&gt;defineSizes(w,0,0);
-    }
-#endif
-
-
-    localdistr-&gt;forget();
-    localdistr-&gt;setTrainingSet(local_trainset);
-    localdistr-&gt;train();
-    double log_local_p = localdistr-&gt;log_density(y);
-
-    switch(mode)
-    {
-    case 0:
-        return log_local_p + pl_log((double)weightsum) - pl_log((double)l) - pl_log((double)weighting_kernel(input,input));
-    case 1:
-        return log_local_p;
-    case 2:
-        return pl_log((double)weightsum) - pl_log((double)l);
-    case 3:
-        return pl_log((double)weightsum);
-    case 4:
-        return log_local_p+pl_log((double)actual_nneighbors)-pl_log((double)l);
-    default:
-        PLERROR(&quot;Invalid mode %d&quot;, mode);
-        return 0; 
-    }
-
-}
-
-/////////////////////////////////
-// makeDeepCopyFromShallowCopy //
-/////////////////////////////////
-void LocallyMagnifiedDistribution::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
-{
-    inherited::makeDeepCopyFromShallowCopy(copies);
-
-    // ### Call deepCopyField on all &quot;pointer-like&quot; fields
-    // ### that you wish to be deepCopied rather than
-    // ### shallow-copied.
-    // ### ex:
-    // deepCopyField(trainvec, copies);
-    deepCopyField(weighting_kernel, copies);
-    deepCopyField(localdistr, copies);
-    deepCopyField(NN, copies);
-}
-
-
-// ### Remove this method, if your distribution does not implement it.
-///////////
-// train //
-///////////
-void LocallyMagnifiedDistribution::train()
-{
-    int actual_nneighbors = max(nneighbors, width_neighbor);
-    if(actual_nneighbors&gt;0) // train nearest neighbor searcher
-    {
-        actual_nneighbors = min(actual_nneighbors, train_set.length());
-        if(NN-&gt;num_neighbors!=actual_nneighbors)
-        {
-            NN-&gt;num_neighbors = actual_nneighbors;
-            NN-&gt;build();
-            NN_outputs.resize(actual_nneighbors);
-            NN_costs.resize(actual_nneighbors);
-        }
-        NN-&gt;setTrainingSet(train_set);
-        NN-&gt;train();
-    }
-}
-
-
-void LocallyMagnifiedDistribution::forget()
-{
-    if(NN.isNotNull())
-        NN-&gt;forget();
-}
-
-
-}
-
-
-/*
-  Local Variables:
-  mode:c++
-  c-basic-offset:4
-  c-file-style:&quot;stroustrup&quot;
-  c-file-offsets:((innamespace . 0)(inline-open . 0))
-  indent-tabs-mode:nil
-  fill-column:79
-  End:
-*/
-// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Deleted: trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.h
===================================================================
--- trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.h	2007-05-16 02:27:01 UTC (rev 7120)
+++ trunk/plearn_learners/distributions/LocallyMagnifiedDistribution.h	2007-05-16 14:48:03 UTC (rev 7121)
@@ -1,172 +0,0 @@
-// -*- C++ -*-
-
-// LocallyMagnifiedDistribution.h
-//
-// Copyright (C) 2005 Pascal Vincent
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-//
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-//
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-//
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-//
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-/* *******************************************************
- * $Id$
- ******************************************************* */
-
-// Authors: Pascal Vincent
-
-/*! \file LocallyMagnifiedDistribution.h */
-
-
-#ifndef LocallyMagnifiedDistribution_INC
-#define LocallyMagnifiedDistribution_INC
-
-#include &lt;plearn_learners/distributions/PDistribution.h&gt;
-#include &lt;plearn/ker/Kernel.h&gt;
-#include &lt;plearn_learners/nearest_neighbors/GenericNearestNeighbors.h&gt;
-
-namespace PLearn {
-
-class LocallyMagnifiedDistribution: public PDistribution
-{
-
-private:
-
-    typedef PDistribution inherited;
-
-    //! Global storage to save memory allocations.
-    mutable Vec trainsample, weights;
-
-protected:
-
-    Vec emptyvec;
-    mutable Vec NN_outputs;
-    mutable Vec NN_costs;
-
-    // *********************
-    // * protected options *
-    // *********************
-
-    PP&lt;GenericNearestNeighbors&gt; NN;
-
-public:
-
-    // ************************
-    // * public build options *
-    // ************************
-    int mode;
-    int nneighbors;
-
-    bool use_rank_weighting;
-    //! The kernel that will be used to locally weigh the samples
-    Ker weighting_kernel;
-
-    //! The distribution that will be trained with local weights
-    PP&lt;PDistribution&gt; localdistr;
-
-    int width_neighbor;
-    real width_factor;
-    string width_optionname;
-
-    // ****************
-    // * Constructors *
-    // ****************
-
-    //! Default constructor.
-    LocallyMagnifiedDistribution();
-
-    // *************************
-    // * PDistribution methods *
-    // *************************
-
-private:
-
-    //! This does the actual building.
-    // ### Please implement in .cc.
-    void build_();
-
-protected:
-
-    //! Declare this class' options.
-    // ### Please implement in .cc.
-    static void declareOptions(OptionList&amp; ol);
-
-public:
-
-    // ************************
-    // **** Object methods ****
-    // ************************
-
-    //! Simply call inherited::build() then build_().
-    virtual void build();
-
-    //! Transform a shallow copy into a deep copy.
-    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
-
-    // Declare other standard object methods.
-    // ### If your class is not instantiatable (it has pure virtual methods)
-    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS.
-    PLEARN_DECLARE_OBJECT(LocallyMagnifiedDistribution);
-
-    // *******************************
-    // **** PDistribution methods ****
-    // *******************************
-
-    //! Return log of probability density log(p(y | x)).
-    virtual real log_density(const Vec&amp; x) const;
-
-    // **************************
-    // **** PLearner methods ****
-    // **************************
-
-    //! The role of the train method is to bring the learner up to stage == nstages,
-    //! updating the train_stats collector with training costs measured on-line in the process.
-    // ### You may remove this method if your distribution does not implement it.
-    virtual void train();
-
-    virtual void forget();
-
-};
-
-// Declare a few other classes and functions related to this class.
-DECLARE_OBJECT_PTR(LocallyMagnifiedDistribution);
-
-} // end of namespace PLearn
-
-#endif
-
-
-/*
-  Local Variables:
-  mode:c++
-  c-basic-offset:4
-  c-file-style:&quot;stroustrup&quot;
-  c-file-offsets:((innamespace . 0)(inline-open . 0))
-  indent-tabs-mode:nil
-  fill-column:79
-  End:
-*/
-// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Deleted: trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.cc
===================================================================
--- trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.cc	2007-05-16 02:27:01 UTC (rev 7120)
+++ trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.cc	2007-05-16 14:48:03 UTC (rev 7121)
@@ -1,234 +0,0 @@
-// -*- C++ -*-
-
-// NeighborhoodBoxVolumeDensityEstimator.cc
-//
-// Copyright (C) 2006 Pascal Vincent
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-//
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-//
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-//
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-//
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-/* *******************************************************
- * $Id: NeighborhoodBoxVolumeDensityEstimator.cc 5668 2006-05-25 17:50:24Z plearner $
- ******************************************************* */
-
-// Authors: Pascal Vincent
-
-/*! \file NeighborhoodBoxVolumeDensityEstimator.cc */
-
-
-#include &quot;NeighborhoodBoxVolumeDensityEstimator.h&quot;
-#include &lt;plearn/vmat/ConcatColumnsVMatrix.h&gt;
-#include &lt;plearn/vmat/MemoryVMatrix.h&gt;
-#include &lt;plearn_learners/nearest_neighbors/ExhaustiveNearestNeighbors.h&gt;
-#include &lt;plearn/base/tostring.h&gt;
-
-namespace PLearn {
-using namespace std;
-
-//////////////////
-// NeighborhoodBoxVolumeDensityEstimator //
-//////////////////
-NeighborhoodBoxVolumeDensityEstimator::NeighborhoodBoxVolumeDensityEstimator()
-    :nneighbors(1),
-     min_radius(1e-6)
-{
-    // for default use Exhaustive search and default Euclidean distance
-    NN = new ExhaustiveNearestNeighbors(); 
-}
-
-PLEARN_IMPLEMENT_OBJECT(NeighborhoodBoxVolumeDensityEstimator,
-                        &quot;Simple density estimation based on the volume of the smallest symmetic box, &quot;
-                        &quot;centered on the test point, and containing its k neighbors.&quot;,
-                        &quot;This estimator is not guaranteed to sum to 1.&quot;
-    );
-
-////////////////////
-// declareOptions //
-////////////////////
-void NeighborhoodBoxVolumeDensityEstimator::declareOptions(OptionList&amp; ol)
-{
-    // ### Declare all of this object's options here
-    // ### For the &quot;flags&quot; of each option, you should typically specify
-    // ### one of OptionBase::buildoption, OptionBase::learntoption or
-    // ### OptionBase::tuningoption. Another possible flag to be combined with
-    // ### is OptionBase::nosave
-
-    declareOption(ol, &quot;nneighbors&quot;, &amp;NeighborhoodBoxVolumeDensityEstimator::nneighbors, OptionBase::buildoption,
-                  &quot;Number of neighbors to consider to determine the boxed region centered on the test point&quot;);
-
-    declareOption(ol, &quot;min_radius&quot;, &amp;NeighborhoodBoxVolumeDensityEstimator::min_radius, OptionBase::buildoption,
-                  &quot;This is added to each dimension of the found box (as some dimensions may be initially 0)&quot;);
-
-    declareOption(ol, &quot;train_set&quot;, &amp;NeighborhoodBoxVolumeDensityEstimator::train_set, OptionBase::learntoption,
-                  &quot;We need to store the training set, as this learner is memory-based...&quot;);
-
-    declareOption(ol, &quot;NN&quot;, &amp;NeighborhoodBoxVolumeDensityEstimator::NN, OptionBase::buildoption,
-                  &quot;The nearest neighbor search method to use (default uses ehaustive search with Euclidean distance)&quot;);
-
-    // Now call the parent class' declareOptions().
-    inherited::declareOptions(ol);
-}
-
-///////////
-// build //
-///////////
-void NeighborhoodBoxVolumeDensityEstimator::build()
-{
-    // ### Nothing to add here, simply calls build_().
-    inherited::build();
-    build_();
-}
-
-////////////
-// build_ //
-////////////
-void NeighborhoodBoxVolumeDensityEstimator::build_()
-{
-    // ### This method should do the real building of the object,
-    // ### according to set 'options', in *any* situation.
-    // ### Typical situations include:
-    // ###  - Initial building of an object from a few user-specified options
-    // ###  - Building of a &quot;reloaded&quot; object: i.e. from the complete set of all serialised options.
-    // ###  - Updating or &quot;re-building&quot; of an object after a few &quot;tuning&quot; options have been modified.
-    // ### You should assume that the parent class' build_() has already been called.
-
-    // ### If the distribution is conditional, you should finish build_() by:
-    // PDistribution::finishConditionalBuild();
-
-    NN-&gt;num_neighbors = nneighbors;
-    NN-&gt;copy_input = false;
-    NN-&gt;copy_target = false;
-    NN-&gt;copy_weight = false;
-    NN-&gt;copy_index = true;
-    NN-&gt;build();
-    if(!train_set.isNull())
-    {
-        NN-&gt;setTrainingSet(train_set);
-        NN-&gt;train();
-    }
-    NN_outputs.resize(nneighbors);
-}
-
-/////////////////
-// log_density //
-/////////////////
-bool NeighborhoodBoxVolumeDensityEstimator::box_contains(const Vec&amp; center, const Vec&amp; radius, const Vec&amp; input) const
-{
-    int w = center.length();
-    for(int j=0; j&lt;w; j++)
-        if(fabs(input[j]-center[j])&gt;radius[j])
-            return false;
-    return true;
-}
-
-
-real NeighborhoodBoxVolumeDensityEstimator::log_density(const Vec&amp; y) const
-{
-    int l = train_set.length();
-    int w = inputsize();
-    int ws = train_set-&gt;weightsize();
-    trainsample.resize(w+ws);
-    Vec input = trainsample.subVec(0,w);
-
-    // Find distance d to width_neighbor neighbour
-    NN-&gt;computeOutput(y, NN_outputs);
-
-    Vec radius(w);
-    for(int k=0; k&lt;NN_outputs.length(); k++)
-    {
-        train_set-&gt;getRow((int)NN_outputs[k],trainsample);
-        for(int j=0; j&lt;w; j++)
-        {
-            real d = fabs(y[j]-input[j]);
-            radius[j] = max(radius[j],d);
-        }
-    }
-    radius += min_radius;
-    
-    int region_count = 0;
-    for(int i=0; i&lt;l; i++)
-    {
-        train_set-&gt;getRow(i,trainsample);
-        if(box_contains(y,radius,input))
-            region_count++;
-    }
-    
-    double log_region_volume = 0;
-    for(int j=0; j&lt;w; j++)
-        log_region_volume += pl_log(radius[j]);
-
-    return pl_log(double(region_count))-log_region_volume-pl_log(double(l));
-}
-
-/////////////////////////////////
-// makeDeepCopyFromShallowCopy //
-/////////////////////////////////
-void NeighborhoodBoxVolumeDensityEstimator::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
-{
-    inherited::makeDeepCopyFromShallowCopy(copies);
-
-    // ### Call deepCopyField on all &quot;pointer-like&quot; fields
-    // ### that you wish to be deepCopied rather than
-    // ### shallow-copied.
-    // ### ex:
-    // deepCopyField(trainvec, copies);
-    deepCopyField(NN, copies);
-}
-
-
-// ### Remove this method, if your distribution does not implement it.
-///////////
-// train //
-///////////
-void NeighborhoodBoxVolumeDensityEstimator::train()
-{
-    NN-&gt;setTrainingSet(train_set);
-    NN-&gt;train();
-}
-
-
-void NeighborhoodBoxVolumeDensityEstimator::forget()
-{
-    NN-&gt;forget();
-}
-
-
-}
-
-
-/*
-  Local Variables:
-  mode:c++
-  c-basic-offset:4
-  c-file-style:&quot;stroustrup&quot;
-  c-file-offsets:((innamespace . 0)(inline-open . 0))
-  indent-tabs-mode:nil
-  fill-column:79
-  End:
-*/
-// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Deleted: trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.h
===================================================================
--- trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.h	2007-05-16 02:27:01 UTC (rev 7120)
+++ trunk/plearn_learners/distributions/NeighborhoodBoxVolumeDensityEstimator.h	2007-05-16 14:48:03 UTC (rev 7121)
@@ -1,164 +0,0 @@
-// -*- C++ -*-
-
-// NeighborhoodBoxVolumeDensityEstimator.h
-//
-// Copyright (C) 2006 Pascal Vincent
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-//
-//  1. Redistributions of source code must retain the above copyright
-//     notice, this list of conditions and the following disclaimer.
-//
-//  2. Redistributions in binary form must reproduce the above copyright
-//     notice, this list of conditions and the following disclaimer in the
-//     documentation and/or other materials provided with the distribution.
-//
-//  3. The name of the authors may not be used to endorse or promote
-//     products derived from this software without specific prior written
-//     permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
-// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
-// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
-// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
-// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
-// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
-// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
-// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-//
-// This file is part of the PLearn library. For more information on the PLearn
-// library, go to the PLearn Web site at www.plearn.org
-
-/* *******************************************************
- * $Id: NeighborhoodBoxVolumeDensityEstimator.h 5388 2006-04-13 21:28:14Z lamblin $
- ******************************************************* */
-
-// Authors: Pascal Vincent
-
-/*! \file NeighborhoodBoxVolumeDensityEstimator.h */
-
-
-#ifndef NeighborhoodBoxVolumeDensityEstimator_INC
-#define NeighborhoodBoxVolumeDensityEstimator_INC
-
-#include &lt;plearn_learners/distributions/UnconditionalDistribution.h&gt;
-#include &lt;plearn/ker/Kernel.h&gt;
-#include &lt;plearn_learners/nearest_neighbors/GenericNearestNeighbors.h&gt;
-
-namespace PLearn {
-
-class NeighborhoodBoxVolumeDensityEstimator: public UnconditionalDistribution
-{
-
-private:
-
-    typedef UnconditionalDistribution inherited;
-
-    //! Global storage to save memory allocations.
-    mutable Vec trainsample;
-
-protected:
-
-    // *********************
-    // * protected options *
-    // *********************
-
-    PP&lt;GenericNearestNeighbors&gt; NN;
-    mutable Vec NN_outputs;
-
-
-public:
-
-    // ************************
-    // * public build options *
-    // ************************
-
-    int nneighbors;
-    real min_radius;
-
-    // ****************
-    // * Constructors *
-    // ****************
-
-    //! Default constructor.
-    NeighborhoodBoxVolumeDensityEstimator();
-
-    // *************************
-    // * PDistribution methods *
-    // *************************
-
-private:
-
-    //! This does the actual building.
-    // ### Please implement in .cc.
-    void build_();
-
-protected:
-
-    //! Returns true if input is contained in the box specified by center and radius
-    bool box_contains(const Vec&amp; center, const Vec&amp; radius, const Vec&amp; input) const;
-
-
-    //! Declare this class' options.
-    // ### Please implement in .cc.
-    static void declareOptions(OptionList&amp; ol);
-
-public:
-
-    // ************************
-    // **** Object methods ****
-    // ************************
-
-    //! Simply call inherited::build() then build_().
-    virtual void build();
-
-    //! Transform a shallow copy into a deep copy.
-    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
-
-    // Declare other standard object methods.
-    // ### If your class is not instantiatable (it has pure virtual methods)
-    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS.
-    PLEARN_DECLARE_OBJECT(NeighborhoodBoxVolumeDensityEstimator);
-
-    // *******************************
-    // **** PDistribution methods ****
-    // *******************************
-
-    //! Return log of probability density log(p(y | x)).
-    virtual real log_density(const Vec&amp; x) const;
-
-    // **************************
-    // **** PLearner methods ****
-    // **************************
-
-    //! The role of the train method is to bring the learner up to stage == nstages,
-    //! updating the train_stats collector with training costs measured on-line in the process.
-    // ### You may remove this method if your distribution does not implement it.
-    virtual void train();
-
-    virtual void forget();
-
-};
-
-// Declare a few other classes and functions related to this class.
-DECLARE_OBJECT_PTR(NeighborhoodBoxVolumeDensityEstimator);
-
-} // end of namespace PLearn
-
-#endif
-
-
-/*
-  Local Variables:
-  mode:c++
-  c-basic-offset:4
-  c-file-style:&quot;stroustrup&quot;
-  c-file-offsets:((innamespace . 0)(inline-open . 0))
-  indent-tabs-mode:nil
-  fill-column:79
-  End:
-*/
-// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000569.html">[Plearn-commits] r7120 - trunk/scripts/Skeletons
</A></li>
	<LI>Next message: <A HREF="000571.html">[Plearn-commits] r7122 - in trunk/plearn_learners/online: .	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1/Split0	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-1	test/DeepBeliefNet/.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-1/Split0
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#570">[ date ]</a>
              <a href="thread.html#570">[ thread ]</a>
              <a href="subject.html#570">[ subject ]</a>
              <a href="author.html#570">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
