<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7473 - trunk/python_modules/plearn/learners/autolr
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7473%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200705311949.l4VJnjEM008455%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000921.html">
   <LINK REL="Next"  HREF="000923.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7473 - trunk/python_modules/plearn/learners/autolr</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7473%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200705311949.l4VJnjEM008455%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7473 - trunk/python_modules/plearn/learners/autolr">yoshua at mail.berlios.de
       </A><BR>
    <I>Thu May 31 21:49:45 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000921.html">[Plearn-commits] r7472 - trunk/plearn_learners/hyper
</A></li>
        <LI>Next message: <A HREF="000923.html">[Plearn-commits] r7474 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#922">[ date ]</a>
              <a href="thread.html#922">[ thread ]</a>
              <a href="subject.html#922">[ subject ]</a>
              <a href="author.html#922">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-05-31 21:49:44 +0200 (Thu, 31 May 2007)
New Revision: 7473

Modified:
   trunk/python_modules/plearn/learners/autolr/__init__.py
Log:
improved train_with_schedule


Modified: trunk/python_modules/plearn/learners/autolr/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/autolr/__init__.py	2007-05-31 19:05:57 UTC (rev 7472)
+++ trunk/python_modules/plearn/learners/autolr/__init__.py	2007-05-31 19:49:44 UTC (rev 7473)
@@ -35,18 +35,19 @@
     n_train = len(learning_rates)
     n_tests = len(testsets)
     n_costs = len(costnames)
-    results = zeros([n_train,1+n_tests*n_costs],Float32)
+    results = zeros([n_train,2+n_tests*n_costs],Float32)
     best_err = 1e10
     if plearn.bridgemode.interactive:
         clf()
     colors=&quot;bgrcmyk&quot;
     styles=['-', '--', '-.', ':', '.', ',', 'o', '^', 'v', '&lt;', '&gt;', 's', '+', 'x', 'D']
     for i in range(n_train):
-        learner.nstages = stages[i]
+        learner.nstages = int(stages[i])
         for lr_option in lr_options:
             learner.changeOptions({lr_option:str(learning_rates[i])})
         learner.train()
         results[i,0] = learner.stage
+        results[i,1] = learning_rates[i]
         for j in range(0,n_tests):
             ts = pl.VecStatsCollector()
             learner.test(testsets[j],ts,0,0)
@@ -54,7 +55,7 @@
                 print &gt;&gt;logfile, &quot;At stage &quot;,learner.stage,&quot; test&quot; + str(j+1),&quot;: &quot;,
             for k in range(0,n_costs):
                 err = ts.getStat(&quot;E[&quot;+str(k)+&quot;]&quot;)
-                results[i,j*n_costs+k+1]=err
+                results[i,j*n_costs+k+2]=err
                 costname = costnames[cost_indices[k]]
                 if logfile:
                     print &gt;&gt;logfile, costname, &quot;=&quot;, err,
@@ -63,7 +64,7 @@
                     learner.save(expdir+&quot;/&quot;+&quot;best_learner.psave&quot;,&quot;plearn_ascii&quot;)
                 if plearn.bridgemode.interactive:
                     plot(results[0:i+1,0],results[0:i+1,
-                         j*n_costs+k+1],colors[k%7]+styles[j%15],
+                         j*n_costs+k+2],colors[k%7]+styles[j%15],
                          label='test'+str(j+1)+':'+costname)
             if logfile:
                 print &gt;&gt;logfile
@@ -72,26 +73,52 @@
     return (['stage']+selected_costnames,results)
 
 
-def choose_initial_lr(learner,trainset,testset,lr_option,
+def choose_initial_lr(initial_learner,trainset,testset,lr_options,
                       nstages=10000,
                       cost_to_select_best=0,
                       initial_lr=0.01,
+                      call_forget=True,
                       lr_steps=exp(log(10)/2)):
-
+    &quot;&quot;&quot;
+Optimize initial learning rate by exploring greedily from a given initial learning rate
+If call_forget then the provided initial_learner is changed (and not necessarily the
+optimal one) upon return. But if not call_forget then the initial_learner is unchanged
+(we make deep copies internally).
+&quot;&quot;&quot;
     log_initial_lr=log(initial_lr)
     log_steps=log(lr_steps)
+    global best_err
+    global best_learner
+    global initial_stage
+    best_learner=initial_learner
+    initial_stage=initial_learner.stage
+    best_err=1e20
 
     def lr(i):
         return exp(log_initial_lr+i*log_steps)
 
     def perf(i):
-        learner.setTrainingSet(trainset,True) # call forget()
-        learner.changeOptions({lr_option:str(lr(i))})
-        learner.nstages = nstages
+        global best_err
+        global best_learner
+        
+        if call_forget:
+            learner = initial_learner
+        else:
+            learner = deepcopy(initial_learner)
+        learner.setTrainingSet(trainset,call_forget)
+        options = {}
+        for lr_option in lr_options:
+            options[lr_option]=str(lr(i))
+        learner.changeOptions(options)
+        learner.nstages = int(nstages+initial_stage)
         learner.train()
         ts = pl.VecStatsCollector()
         learner.test(testset,ts,0,0)
-        return ts.getStat(&quot;E[&quot;+str(cost_to_select_best)+&quot;]&quot;)
+        err=ts.getStat(&quot;E[&quot;+str(cost_to_select_best)+&quot;]&quot;)
+        if err&lt;best_err:
+            best_learner=learner
+            best_err=err
+        return err
 
     perfs = {}
     top = 1
@@ -114,7 +141,7 @@
             perfs[bottom]=perf(bottom)
             if perfs[bottom]&lt;perfs[best]:
                 best=bottom
-    return (lr(best),perfs)
+    return (lr(best),perfs,best_learner)
 
 def train_adapting_lr(learner,
                       epoch,nstages,
@@ -194,7 +221,7 @@
         for active in actives:
             candidate = all_candidates[active]
             results = all_results[active]
-            candidate.nstages = initial_stage+s
+            candidate.nstages = int(initial_stage+s)
             for lr_option in lr_options:
                 candidate.changeOptions({lr_option:str(all_lr[active])})
             candidate.setTrainingSet(trainset,False)


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000921.html">[Plearn-commits] r7472 - trunk/plearn_learners/hyper
</A></li>
	<LI>Next message: <A HREF="000923.html">[Plearn-commits] r7474 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#922">[ date ]</a>
              <a href="thread.html#922">[ thread ]</a>
              <a href="subject.html#922">[ subject ]</a>
              <a href="author.html#922">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
