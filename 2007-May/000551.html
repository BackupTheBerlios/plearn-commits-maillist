<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7102 - in trunk: plearn/sys	plearn_learners/generic/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7102%20-%20in%20trunk%3A%20plearn/sys%0A%09plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200705151753.l4FHrXjv013987%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000550.html">
   <LINK REL="Next"  HREF="000552.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7102 - in trunk: plearn/sys	plearn_learners/generic/EXPERIMENTAL</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7102%20-%20in%20trunk%3A%20plearn/sys%0A%09plearn_learners/generic/EXPERIMENTAL&In-Reply-To=%3C200705151753.l4FHrXjv013987%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7102 - in trunk: plearn/sys	plearn_learners/generic/EXPERIMENTAL">nouiz at mail.berlios.de
       </A><BR>
    <I>Tue May 15 19:53:33 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000550.html">[Plearn-commits] r7101 - in trunk: commands/PLearnCommands	plearn/misc plearn_learners/generic plearn_learners/online	plearn_learners/testers
</A></li>
        <LI>Next message: <A HREF="000552.html">[Plearn-commits] r7103 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#551">[ date ]</a>
              <a href="thread.html#551">[ thread ]</a>
              <a href="subject.html#551">[ subject ]</a>
              <a href="author.html#551">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2007-05-15 19:53:33 +0200 (Tue, 15 May 2007)
New Revision: 7102

Modified:
   trunk/plearn/sys/Profiler.cc
   trunk/plearn/sys/Profiler.h
   trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
Log:
Added 2 functions (Profiler::pl_profile_start and Profiler::pl_profile_end) that generate profile only when the macro PL_PROFILE is set.
Used those functions to profile NatGradNNet


Modified: trunk/plearn/sys/Profiler.cc
===================================================================
--- trunk/plearn/sys/Profiler.cc	2007-05-15 15:23:13 UTC (rev 7101)
+++ trunk/plearn/sys/Profiler.cc	2007-05-15 17:53:33 UTC (rev 7102)
@@ -112,9 +112,27 @@
         stats.system_duration += system_duration;
     }
 }
+
+// start recording time for named piece of code if PL_PROFILE is set
+#ifdef PL_PROFILE  
+void Profiler::pl_profile_start(const string&amp; name_of_piece_of_code){
+        Profiler::start(name_of_piece_of_code);}
+#else
+void inline Profiler::pl_profile_start(const string&amp; name_of_piece_of_code){}
 #endif
 
+// end recording time for named piece of code, and increment
+// frequency of occurence and total duration of this piece of code.
+// if PL_PROFILE is set
+#ifdef PL_PROFILE  
+void Profiler::pl_profile_end(const string&amp; name_of_piece_of_code){
+        Profiler::end(name_of_piece_of_code);}
+#else
+void inline Profiler::pl_profile_start(const string&amp; name_of_piece_of_code){}
+#endif
 
+#endif
+
 //! Return the statistics related to a piece of code.  This is useful
 //! for aggregators that collect and report a number of statistics
 const Profiler::Stats&amp; Profiler::getStats(const string&amp; name_of_piece_of_code)

Modified: trunk/plearn/sys/Profiler.h
===================================================================
--- trunk/plearn/sys/Profiler.h	2007-05-15 15:23:13 UTC (rev 7101)
+++ trunk/plearn/sys/Profiler.h	2007-05-15 17:53:33 UTC (rev 7102)
@@ -154,6 +154,22 @@
     static inline void end(const string&amp; name_of_piece_of_code) { } 
 #endif
 
+    //!  Start recording time for named piece of code if PL_PROFILE is set
+#ifdef PROFILE
+    static void pl_profile_start(const string&amp; name_of_piece_of_code);
+#else
+    static inline void pl_profile_start(const string&amp; name_of_piece_of_code) {}
+#endif
+
+    //!  End recording time for named piece of code, and increment
+    //!  frequency of occurence and total duration of this piece of code.
+    //!  if PL_PROFILE is set
+#ifdef PROFILE
+    static void pl_profile_end(const string&amp; name_of_piece_of_code);
+#else
+    static inline void pl_profile_end(const string&amp; name_of_piece_of_code) { } 
+#endif
+
     //! Return the number of clock ticks per second on this computer.
 #ifdef PROFILE
     static long ticksPerSecond() { return sysconf(_SC_CLK_TCK); }

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-05-15 15:23:13 UTC (rev 7101)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/NatGradNNet.cc	2007-05-15 17:53:33 UTC (rev 7102)
@@ -596,6 +596,7 @@
 
     Profiler::reset(&quot;training&quot;);
     Profiler::start(&quot;training&quot;);
+    Profiler::pl_profile_start(&quot;Totaltraining&quot;);
     if( report_progress &amp;&amp; stage &lt; nstages )
         pb = new ProgressBar( &quot;Training &quot;+classname(),
                               nstages - stage );
@@ -612,9 +613,9 @@
         int b = stage % minibatch_size;
         Vec input = neuron_outputs_per_layer[0](b);
         Vec target = targets(b);
-        Profiler::start(&quot;getting_data&quot;);
+        Profiler::pl_profile_start(&quot;getting_data&quot;);
         train_set-&gt;getExample(sample, input, target, example_weights[b]);
-        Profiler::end(&quot;getting_data&quot;);
+        Profiler::pl_profile_end(&quot;getting_data&quot;);
         if (b+1==minibatch_size) // do also special end-case || stage+1==nstages)
         {
             onlineStep(stage, targets, train_costs, example_weights );
@@ -634,6 +635,7 @@
             pb-&gt;update( stage + 1 );
     }
     Profiler::end(&quot;training&quot;);
+    Profiler::pl_profile_end(&quot;Totaltraining&quot;);
     if (verbosity&gt;0)
         Profiler::report(cout);
     const Profiler::Stats&amp; stats = Profiler::getStats(&quot;training&quot;);
@@ -706,8 +708,10 @@
         if (i&gt;1) // compute gradient on previous layer
         {
             // propagate gradients
+            Profiler::pl_profile_start(&quot;ProducScaleAccOnlineStep&quot;);
             productScaleAcc(previous_neurons_gradient,next_neurons_gradient,false,
                             weights[i-1],false,1,0);
+            Profiler::pl_profile_end(&quot;ProducScaleAccOnlineStep&quot;);
             // propagate through tanh non-linearity
             for (int j=0;j&lt;previous_neurons_gradient.length();j++)
             {
@@ -726,21 +730,29 @@
         else if (full_natgrad || params_natgrad_template || params_natgrad_per_input_template) 
         {
 //alternate
-            if( params_natgrad_per_input_template &amp;&amp; i==1 ) // parameters are transposed
+            if( params_natgrad_per_input_template &amp;&amp; i==1 ){ // parameters are transposed
+                Profiler::pl_profile_start(&quot;ProducScaleAccOnlineStep&quot;);
                 productScaleAcc(layer_params_gradient[i-1],
                             neuron_extended_outputs_per_layer[i-1], true,
                             next_neurons_gradient, false, 
                             1, 0);
-            else
+                Profiler::pl_profile_end(&quot;ProducScaleAccOnlineStep&quot;);
+            }else{
+                Profiler::pl_profile_start(&quot;ProducScaleAccOnlineStep&quot;);
                 productScaleAcc(layer_params_gradient[i-1],next_neurons_gradient,true,
                             neuron_extended_outputs_per_layer[i-1],false,1,0);
+                Profiler::pl_profile_end(&quot;ProducScaleAccOnlineStep&quot;);
+            }
             layer_params_gradient[i-1] *= 1.0/minibatch_size; // use the MEAN gradient
-        } else // just regular stochastic gradient
+        } else {// just regular stochastic gradient
             // compute gradient on weights and update them in one go (more efficient)
             // mean gradient has less variance, can afford larger learning rate
+            Profiler::pl_profile_start(&quot;ProducScaleAccOnlineStep&quot;);
             productScaleAcc(layer_params[i-1],next_neurons_gradient,true,
                             neuron_extended_outputs_per_layer[i-1],false,
                             -layer_lrate_factor*lrate/minibatch_size,1);
+            Profiler::pl_profile_end(&quot;ProducScaleAccOnlineStep&quot;);
+        }
     }
     if (use_pvgrad)
     {
@@ -835,9 +847,11 @@
 
 void NatGradNNet::computeOutput(const Vec&amp; input, Vec&amp; output) const
 {
+    Profiler::pl_profile_start(&quot;computeOutput&quot;);
     neuron_outputs_per_layer[0](0) &lt;&lt; input;
     fpropNet(1,false);
     output &lt;&lt; neuron_outputs_per_layer[n_layers-1](0);
+    Profiler::pl_profile_end(&quot;computeOutput&quot;);
 }
 
 //! compute (pre-final-non-linearity) network top-layer output given input
@@ -861,16 +875,33 @@
             tw = false;
 
         // try to use BLAS for the expensive operation
-        if (self_adjusted_scaling_and_bias &amp;&amp; i+1&lt;n_layers-1)
+        if (self_adjusted_scaling_and_bias &amp;&amp; i+1&lt;n_layers-1){
+            if (during_training)
+                Profiler::pl_profile_start(&quot;ProducScaleAccFpropTrain&quot;);
+            else
+                Profiler::pl_profile_start(&quot;ProducScaleAccFpropNoTrain&quot;);
             productScaleAcc(next_layer, prev_layer, false, 
                             (during_training || params_averaging_coeff==1.0)?
                             weights[i]:mweights[i], 
                             tw, 1, 0);
-        else
+            if (during_training)
+                Profiler::pl_profile_end(&quot;ProducScaleAccFpropTrain&quot;);
+            else
+                Profiler::pl_profile_end(&quot;ProducScaleAcccFpropNoTrain&quot;);
+        }else{
+            if (during_training)
+                Profiler::pl_profile_start(&quot;ProducScaleAccFpropTrain&quot;);
+            else
+                Profiler::pl_profile_start(&quot;ProducScaleAcccFpropNoTrain&quot;);
             productScaleAcc(next_layer, prev_layer, false, 
                             (during_training || params_averaging_coeff==1.0)?
                             layer_params[i]:layer_mparams[i], 
                             tw, 1, 0);
+            if (during_training)
+                Profiler::pl_profile_end(&quot;ProducScaleAccFpropTrain&quot;);
+            else
+                Profiler::pl_profile_end(&quot;ProducScaleAcccFpropNoTrain&quot;);
+        }
         // compute layer's output non-linearity
         if (i+1&lt;n_layers-1)
             for (int k=0;k&lt;n_examples;k++)
@@ -907,17 +938,24 @@
                                 *v *= rescale_factor*rescale_factor;
                             }
                         }
+                        Profiler::pl_profile_start(&quot;activation function&quot;);
                         *a = tanh((*a + *b) * *s);
+                        Profiler::pl_profile_end(&quot;activation function&quot;);
                     }
                 }
-                else
+                else{
+                    Profiler::pl_profile_start(&quot;activation function&quot;);
                     compute_tanh(L,L);
+                    Profiler::pl_profile_end(&quot;activation function&quot;);
+                }
             }
         else if (output_type==&quot;NLL&quot;)
             for (int k=0;k&lt;n_examples;k++)
             {
                 Vec L=next_layer(k);
+                Profiler::pl_profile_start(&quot;activation function&quot;);
                 log_softmax(L,L);
+                Profiler::pl_profile_end(&quot;activation function&quot;);
             }
     }
 }


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000550.html">[Plearn-commits] r7101 - in trunk: commands/PLearnCommands	plearn/misc plearn_learners/generic plearn_learners/online	plearn_learners/testers
</A></li>
	<LI>Next message: <A HREF="000552.html">[Plearn-commits] r7103 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#551">[ date ]</a>
              <a href="thread.html#551">[ thread ]</a>
              <a href="subject.html#551">[ subject ]</a>
              <a href="author.html#551">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
