<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7412 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7412%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200705291529.l4TFTIfl021865%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000860.html">
   <LINK REL="Next"  HREF="000862.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7412 - trunk/plearn_learners/online</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7412%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200705291529.l4TFTIfl021865%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7412 - trunk/plearn_learners/online">tihocan at mail.berlios.de
       </A><BR>
    <I>Tue May 29 17:29:18 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000860.html">[Plearn-commits] r7411 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000862.html">[Plearn-commits] r7413 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#861">[ date ]</a>
              <a href="thread.html#861">[ thread ]</a>
              <a href="subject.html#861">[ subject ]</a>
              <a href="author.html#861">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2007-05-29 17:29:17 +0200 (Tue, 29 May 2007)
New Revision: 7412

Modified:
   trunk/plearn_learners/online/RBMModule.cc
   trunk/plearn_learners/online/RBMModule.h
Log:
- Moved getPortIndex from protected to public
- Renamed addportname to addPortName to follow PLearn naming conventions
- Moved code from .h to .cc
- Added comments in .h


Modified: trunk/plearn_learners/online/RBMModule.cc
===================================================================
--- trunk/plearn_learners/online/RBMModule.cc	2007-05-29 14:58:43 UTC (rev 7411)
+++ trunk/plearn_learners/online/RBMModule.cc	2007-05-29 15:29:17 UTC (rev 7412)
@@ -236,25 +236,25 @@
     // buid ports and port_sizes
 
     ports.resize(0);
-    addportname(&quot;visible&quot;);
-    addportname(&quot;hidden.state&quot;);
-    addportname(&quot;hidden_activations.state&quot;);
-    addportname(&quot;visible_sample&quot;);
-    addportname(&quot;hidden_sample&quot;);
-    addportname(&quot;energy&quot;);
-    addportname(&quot;hidden_bias&quot;); 
-    addportname(&quot;neg_log_likelihood&quot;);
+    addPortName(&quot;visible&quot;);
+    addPortName(&quot;hidden.state&quot;);
+    addPortName(&quot;hidden_activations.state&quot;);
+    addPortName(&quot;visible_sample&quot;);
+    addPortName(&quot;hidden_sample&quot;);
+    addPortName(&quot;energy&quot;);
+    addPortName(&quot;hidden_bias&quot;); 
+    addPortName(&quot;neg_log_likelihood&quot;);
     if(reconstruction_connection)
     {
-        addportname(&quot;visible_reconstruction.state&quot;);
-        addportname(&quot;visible_reconstruction_activations.state&quot;);
-        addportname(&quot;reconstruction_error.state&quot;);
+        addPortName(&quot;visible_reconstruction.state&quot;);
+        addPortName(&quot;visible_reconstruction_activations.state&quot;);
+        addPortName(&quot;reconstruction_error.state&quot;);
     }
     if (compute_contrastive_divergence)
     {
-        addportname(&quot;contrastive_divergence&quot;);
-        addportname(&quot;negative_phase_visible_samples.state&quot;);
-        addportname(&quot;negative_phase_hidden_expectations.state&quot;);
+        addPortName(&quot;contrastive_divergence&quot;);
+        addPortName(&quot;negative_phase_visible_samples.state&quot;);
+        addPortName(&quot;negative_phase_hidden_expectations.state&quot;);
     }
 
     port_sizes.resize(nPorts(), 2);
@@ -300,7 +300,141 @@
     build_();
 }
 
+/////////////////
+// addPortName //
+/////////////////
+void RBMModule::addPortName(const string&amp; name)
+{
+    PLASSERT( portname_to_index.find(name) == portname_to_index.end() );
+    portname_to_index[name] = ports.length();
+    ports.append(name);
+}
 
+///////////////////
+// computeEnergy //
+///////////////////
+void RBMModule::computeEnergy(const Mat&amp; visible, const Mat&amp; hidden,
+                              Mat&amp; energy, bool positive_phase)
+{
+    int mbs=hidden.length();
+    energy.resize(mbs, 1);
+    Mat* hidden_activations = NULL;
+    if (positive_phase) {
+        computePositivePhaseHiddenActivations(visible);
+        hidden_activations = hidden_act;
+    } else {
+        computeHiddenActivations(visible);
+        hidden_activations = &amp; hidden_layer-&gt;activations;
+    }
+    PLASSERT( hidden_activations );
+    for (int i=0;i&lt;mbs;i++)
+        energy(i,0) = visible_layer-&gt;energy(visible(i)) + 
+            hidden_layer-&gt;energy(hidden(i)) + 
+            dot(hidden(i), (*hidden_activations)(i));
+}
+
+///////////////////////////////
+// computeFreeEnergyOfHidden //
+///////////////////////////////
+void RBMModule::computeFreeEnergyOfHidden(const Mat&amp; hidden, Mat&amp; energy)
+{
+    int mbs=hidden.length();
+    if (energy.isEmpty())
+        energy.resize(mbs,1);
+    else {
+        PLASSERT( energy.length() == mbs &amp;&amp; energy.width() == 1 );
+    }
+    PLASSERT(visible_layer-&gt;classname()==&quot;RBMBinomialLayer&quot;);
+    computeVisibleActivations(hidden, false);
+    for (int i=0;i&lt;mbs;i++)
+    {
+        energy(i,0) = hidden_layer-&gt;energy(hidden(i));
+        for (int j=0;j&lt;visible_layer-&gt;size;j++)
+            energy(i,0) += softplus(visible_layer-&gt;activations(i,j));
+    }
+}
+
+////////////////////////////////
+// computeFreeEnergyOfVisible //
+////////////////////////////////
+void RBMModule::computeFreeEnergyOfVisible(const Mat&amp; visible, Mat&amp; energy,
+                                           bool positive_phase)
+{
+    int mbs=visible.length();
+    if (energy.isEmpty())
+        energy.resize(mbs,1);
+    else {
+        PLASSERT( energy.length() == mbs &amp;&amp; energy.width() == 1 );
+    }
+    PLASSERT(hidden_layer-&gt;classname()==&quot;RBMBinomialLayer&quot;);
+    Mat* hidden_activations = NULL;
+    if (positive_phase) {
+        computePositivePhaseHiddenActivations(visible);
+        hidden_activations = hidden_act;
+    }
+    else {
+        computeHiddenActivations(visible);
+        hidden_activations = &amp; hidden_layer-&gt;activations;
+    }
+    PLASSERT( hidden_activations &amp;&amp; hidden_activations-&gt;length() == mbs
+            &amp;&amp; hidden_activations-&gt;width() == hidden_layer-&gt;size );
+    for (int i=0;i&lt;mbs;i++)
+    {
+        energy(i,0) = visible_layer-&gt;energy(visible(i));
+        for (int j=0;j&lt;hidden_layer-&gt;size;j++)
+            energy(i,0) += softplus((*hidden_activations)(i,j));
+    }
+}
+
+//////////////////////////////
+// computeHiddenActivations //
+//////////////////////////////
+void RBMModule::computeHiddenActivations(const Mat&amp; visible)
+{
+    connection-&gt;setAsDownInputs(visible);
+    hidden_layer-&gt;getAllActivations(connection, 0, true);
+    if (hidden_bias &amp;&amp; !hidden_bias-&gt;isEmpty())
+        hidden_layer-&gt;activations += *hidden_bias;
+}
+
+///////////////////////////////////////////
+// computePositivePhaseHiddenActivations //
+///////////////////////////////////////////
+void RBMModule::computePositivePhaseHiddenActivations(const Mat&amp; visible)
+{
+    if (hidden_activations_are_computed) {
+        // Nothing to do.
+        PLASSERT( !hidden_act || !hidden_act-&gt;isEmpty() );
+        return;
+    }
+    computeHiddenActivations(visible);
+    if (hidden_act &amp;&amp; hidden_act-&gt;isEmpty())
+    {
+        hidden_act-&gt;resize(visible.length(),hidden_layer-&gt;size);
+        *hidden_act &lt;&lt; hidden_layer-&gt;activations;
+    }
+    hidden_activations_are_computed = true;
+}
+
+///////////////////////////////
+// computeVisibleActivations //
+///////////////////////////////
+void RBMModule::computeVisibleActivations(const Mat&amp; hidden,
+                                          bool using_reconstruction_connection)
+{
+    if (using_reconstruction_connection)
+    {
+        PLASSERT( reconstruction_connection );
+        reconstruction_connection-&gt;setAsDownInputs(hidden);
+        visible_layer-&gt;getAllActivations(reconstruction_connection, 0, true);
+    }
+    else
+    {
+        connection-&gt;setAsUpInputs(hidden);
+        visible_layer-&gt;getAllActivations(connection, 0, true);
+    }
+}
+
 /////////////////////////////////
 // makeDeepCopyFromShallowCopy //
 /////////////////////////////////
@@ -980,6 +1114,24 @@
         reconstruction_connection-&gt;setLearningRate(lr);
 }
 
+//////////////////////////////
+// sampleHiddenGivenVisible //
+//////////////////////////////
+void RBMModule::sampleHiddenGivenVisible(const Mat&amp; visible)
+{
+    computeHiddenActivations(visible);
+    hidden_layer-&gt;generateSamples();
+}
+
+//////////////////////////////
+// sampleVisibleGivenHidden //
+//////////////////////////////
+void RBMModule::sampleVisibleGivenHidden(const Mat&amp; hidden)
+{
+    computeVisibleActivations(hidden);
+    visible_layer-&gt;generateSamples();
+}
+
 /////////////////////
 // setLearningRate //
 /////////////////////

Modified: trunk/plearn_learners/online/RBMModule.h
===================================================================
--- trunk/plearn_learners/online/RBMModule.h	2007-05-29 14:58:43 UTC (rev 7411)
+++ trunk/plearn_learners/online/RBMModule.h	2007-05-29 15:29:17 UTC (rev 7412)
@@ -193,6 +193,11 @@
     //! The ports' sizes are given by the corresponding RBM layers.
     virtual const TMat&lt;int&gt;&amp; getPortSizes();
 
+    //! Return the index (as in the list of ports returned by getPorts()) of
+    //! a given port.
+    //! If 'port' does not exist, -1 is returned.
+    virtual int getPortIndex(const string&amp; port);
+
     //#####  PLearn::Object Protocol  #########################################
 
     // Declares other standard object methods.
@@ -238,124 +243,62 @@
     //! Map from a port name to its index in the 'ports' vector.
     map&lt;string, int&gt; portname_to_index;
 
-    //! Return the index (as in the list of ports returned by getPorts()) of
-    //! a given port.
-    //! If 'port' does not exist, -1 is returned.
-    virtual int getPortIndex(const string&amp; port);
-
-    void addportname(string name) { ports.append(name); portname_to_index[name]=ports.length()-1; }
-
     //#####  Protected Member Functions  ######################################
 
+    //! Add a new port to the 'portname_to_index' map and 'ports' vector.
+    void addPortName(const string&amp; name);
+
     //! Forward the given learning rate to all elements of this module.
     void setAllLearningRates(real lr);
 
     //! Declares the class options.
     static void declareOptions(OptionList&amp; ol);
 
-    void computeHiddenActivations(const Mat&amp; visible) {
-        connection-&gt;setAsDownInputs(visible);
-        hidden_layer-&gt;getAllActivations(connection, 0, true);
-        if (hidden_bias &amp;&amp; !hidden_bias-&gt;isEmpty())
-            hidden_layer-&gt;activations += *hidden_bias;
-    }
+    //! Compute activations on the hidden layer based on the provided
+    //! visible input.
+    //! If 'hidden_bias' is not null nor empty, then it is used as an
+    //! additional bias for hidden activations.
+    void computeHiddenActivations(const Mat&amp; visible);
 
-    void computePositivePhaseHiddenActivations(const Mat&amp; visible) {
-        if (hidden_activations_are_computed) {
-            // Nothing to do.
-            PLASSERT( !hidden_act || !hidden_act-&gt;isEmpty() );
-            return;
-        }
-        computeHiddenActivations(visible);
-        if (hidden_act &amp;&amp; hidden_act-&gt;isEmpty())
-        {
-            hidden_act-&gt;resize(visible.length(),hidden_layer-&gt;size);
-            *hidden_act &lt;&lt; hidden_layer-&gt;activations;
-        }
-        hidden_activations_are_computed=true;
-    }
+    //! Compute activations on the visible layer.
+    //! If 'using_reconstruction_connection' is true, then we use the
+    //! reconstruction connection to compute these activations. Otherwise, we
+    //! use the normal connection, in a 'top-&gt;down' fashion.
+    void computeVisibleActivations(const Mat&amp; hidden,
+                                   bool using_reconstruction_connection=false);
 
-    void sampleHiddenGivenVisible(const Mat&amp; visible) {
-        computeHiddenActivations(visible);
-        hidden_layer-&gt;generateSamples();
-    }
-    void computeVisibleActivations(const Mat&amp; hidden, bool using_reconstruction_connection=false) {
-        if (using_reconstruction_connection)
-        {
-            reconstruction_connection-&gt;setAsDownInputs(hidden);
-            visible_layer-&gt;getAllActivations(reconstruction_connection, 0, true);
-        }
-        else
-        {
-            connection-&gt;setAsUpInputs(hidden);
-            visible_layer-&gt;getAllActivations(connection, 0, true);
-        }
-    }
-    void sampleVisibleGivenHidden(const Mat&amp; hidden) {
-        computeVisibleActivations(hidden);
-        visible_layer-&gt;generateSamples();
-    }
+    //! Compute activations on the hidden layer based on the provided visible
+    //! input during positive phase. This method is called to ensure hidden
+    //! hidden activations are computed only once, and during a fprop it should
+    //! always be called with the same 'visible' input.
+    //! If 'hidden_act' is not null, it is filled with the computed hidden
+    //! activations.
+    void computePositivePhaseHiddenActivations(const Mat&amp; visible);
 
-    void computeFreeEnergyOfVisible(const Mat&amp; visible, Mat&amp; energy, bool positive_phase=true) {
-        int mbs=visible.length();
-        if (energy.isEmpty())
-            energy.resize(mbs,1);
-        else {
-            PLASSERT( energy.length() == mbs &amp;&amp; energy.width() == 1 );
-        }
-        PLASSERT(hidden_layer-&gt;classname()==&quot;RBMBinomialLayer&quot;);
-        Mat* hidden_activations = NULL;
-        if (positive_phase) {
-            computePositivePhaseHiddenActivations(visible);
-            hidden_activations = hidden_act;
-        }
-        else {
-            computeHiddenActivations(visible);
-            hidden_activations = &amp; hidden_layer-&gt;activations;
-        }
-        PLASSERT( hidden_activations &amp;&amp; hidden_activations-&gt;length() == mbs
-                  &amp;&amp; hidden_activations-&gt;width() == hidden_layer-&gt;size );
-        for (int i=0;i&lt;mbs;i++)
-        {
-            energy(i,0) = visible_layer-&gt;energy(visible(i));
-            for (int j=0;j&lt;hidden_layer-&gt;size;j++)
-                energy(i,0) += softplus((*hidden_activations)(i,j));
-        }
-    }
+    //! Sample hidden layer data based on the provided 'visible' inputs.
+    void sampleHiddenGivenVisible(const Mat&amp; visible);
 
-    void computeFreeEnergyOfHidden(const Mat&amp; hidden, Mat&amp; energy) {
-        int mbs=hidden.length();
-        if (energy.isEmpty())
-            energy.resize(mbs,1);
-        PLASSERT(visible_layer-&gt;classname()==&quot;RBMBinomialLayer&quot;);
-        computeVisibleActivations(hidden);
-        for (int i=0;i&lt;mbs;i++)
-        {
-            energy(i,0) = hidden_layer-&gt;energy(hidden(i));
-            for (int j=0;j&lt;visible_layer-&gt;size;j++)
-                energy(i,0) += softplus(visible_layer-&gt;activations(i,j));
-        }
-    }
+    //! Sample visible layer data based on the provided 'hidden' inputs.
+    void sampleVisibleGivenHidden(const Mat&amp; hidden);
 
+    //! Compute free energy on the visible layer and store it in the 'energy'
+    //! matrix.
+    //! The 'positive_phase' boolean is used to save computations when we know
+    //! we are in the positive phase of fprop.
+    void computeFreeEnergyOfVisible(const Mat&amp; visible, Mat&amp; energy,
+                                    bool positive_phase = true);
+
+    //! Compute free energy on the hidden layer and store it in the 'energy'
+    //! matrix.
+    void computeFreeEnergyOfHidden(const Mat&amp; hidden, Mat&amp; energy);
+
+    //! Compute energy of the joint (visible, hidden) configuration and store
+    //! it in the 'energy' matrix.
+    //! The 'positive_phase' boolean is used to save computations when we know
+    //! we are in the positive phase of fprop.
     void computeEnergy(const Mat&amp; visible, const Mat&amp; hidden, Mat&amp; energy, 
-                       bool positive_phase=true) 
-    {
-        int mbs=hidden.length();
-        energy.resize(mbs,1);
-        Mat* hidden_activations = NULL;
-        if (positive_phase) {
-            computePositivePhaseHiddenActivations(visible);
-            hidden_activations = hidden_act;
-        } else {
-            computeHiddenActivations(visible);
-            hidden_activations = &amp; hidden_layer-&gt;activations;
-        }
-        PLASSERT( hidden_activations );
-        for (int i=0;i&lt;mbs;i++)
-            energy(i,0) = visible_layer-&gt;energy(visible(i)) + 
-                hidden_layer-&gt;energy(hidden(i)) + 
-                dot(hidden(i), (*hidden_activations)(i));
-    }
+                       bool positive_phase = true);
+
 private:
     //#####  Private Member Functions  ########################################
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000860.html">[Plearn-commits] r7411 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000862.html">[Plearn-commits] r7413 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#861">[ date ]</a>
              <a href="thread.html#861">[ thread ]</a>
              <a href="subject.html#861">[ subject ]</a>
              <a href="author.html#861">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
