<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7043 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7043%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200705092359.l49NxR4S011344%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000491.html">
   <LINK REL="Next"  HREF="000493.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7043 - trunk/plearn_learners/online</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7043%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200705092359.l49NxR4S011344%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7043 - trunk/plearn_learners/online">yoshua at mail.berlios.de
       </A><BR>
    <I>Thu May 10 01:59:27 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000491.html">[Plearn-commits] r7042 - in trunk: . commands	commands/PLearnCommands plearn/base plearn/db plearn/display	plearn/io plearn/ker plearn/math plearn/misc plearn/opt	plearn/python plearn/python/test plearn/python/test/.pytest	plearn/python/test/.pytest/EmbeddedPython_Instances	plearn/python/test/.pytest/EmbeddedPython_Instances/expected_results	plearn/python/test/.pytest/EmbeddedPython_InterfunctionXchg/expected_results	plearn/var plearn/vmat plearn_learners/generic	plearn_learners/hyper plearn_learners/regressors	plearn_learners/testers python_modules/plearn	python_modules/plearn/pybridge
</A></li>
        <LI>Next message: <A HREF="000493.html">[Plearn-commits] r7044 - in trunk/plearn/python: . test	test/.pytest/EmbeddedPython_Instances/expected_results
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#492">[ date ]</a>
              <a href="thread.html#492">[ thread ]</a>
              <a href="subject.html#492">[ subject ]</a>
              <a href="author.html#492">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-05-10 01:59:26 +0200 (Thu, 10 May 2007)
New Revision: 7043

Modified:
   trunk/plearn_learners/online/Convolution2DModule.cc
   trunk/plearn_learners/online/DeepBeliefNet.cc
   trunk/plearn_learners/online/DeepBeliefNet.h
   trunk/plearn_learners/online/GradNNetLayerModule.cc
   trunk/plearn_learners/online/ModulesLearner.cc
   trunk/plearn_learners/online/RBMConnection.cc
   trunk/plearn_learners/online/RBMConnection.h
   trunk/plearn_learners/online/RBMLayer.cc
   trunk/plearn_learners/online/RBMLayer.h
   trunk/plearn_learners/online/RBMMatrixConnection.cc
   trunk/plearn_learners/online/RBMMatrixConnection.h
Log:
Added code for adaptive estimation of the non-stationarity in negative statistics from Gibbs chain


Modified: trunk/plearn_learners/online/Convolution2DModule.cc
===================================================================
--- trunk/plearn_learners/online/Convolution2DModule.cc	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/Convolution2DModule.cc	2007-05-09 23:59:26 UTC (rev 7043)
@@ -428,7 +428,7 @@
                                     kernel_step1, kernel_step2, accumulate );
 
                 // kernel(i,j) -= learning_rate * kernel_gradient
-                multiplyAcc( kernels(i,j), kernel_gradient, -learning_rate );
+                multiplyAcc( kernels(i,j), kernel_gradient, -learning_rate ); // could be more efficiently done within the convolve2Dbackprop
             }
         bias[j] -= learning_rate * sum( output_gradients[j] );
     }

Modified: trunk/plearn_learners/online/DeepBeliefNet.cc
===================================================================
--- trunk/plearn_learners/online/DeepBeliefNet.cc	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/DeepBeliefNet.cc	2007-05-09 23:59:26 UTC (rev 7043)
@@ -68,7 +68,6 @@
     n_layers( 0 ),
     online ( false ),
     background_gibbs_update_ratio(0),
-    gibbs_chain_statistics_forgetting_factor(0.999),
     gibbs_chain_reinit_freq( INT_MAX ),
     minibatch_size( 0 ),
     initialize_gibbs_chain( false ),
@@ -220,13 +219,6 @@
                   &quot;negative phase statistics). If = 1, then do not perform any contrastive\n&quot;
                   &quot;divergence negative phase (use only the Gibbs chain statistics).\n&quot;);
 
-    declareOption(ol, &quot;gibbs_chain_statistics_forgetting_factor&quot;,
-                  &amp;DeepBeliefNet::gibbs_chain_statistics_forgetting_factor,
-                  OptionBase::buildoption,
-                  &quot;Negative chain statistics are forgotten at this rate (a value of 0\n&quot;
-                  &quot;would only use the current sample, a value of .99 would use 1% of\n&quot;
-                  &quot;the current sample and 99% of the old statistics).\n&quot;);
-
     declareOption(ol, &quot;gibbs_chain_reinit_freq&quot;,
                   &amp;DeepBeliefNet::gibbs_chain_reinit_freq,
                   OptionBase::buildoption,
@@ -1848,28 +1840,22 @@
             {
                 down_layer-&gt;updateCDandGibbs(pos_down_vals,cd_neg_down_vals,
                                              down_state,
-                                             background_gibbs_update_ratio,
-                                             gibbs_chain_statistics_forgetting_factor);
+                                             background_gibbs_update_ratio);
                 connection-&gt;updateCDandGibbs(pos_down_vals,pos_up_vals,
                                              cd_neg_down_vals, cd_neg_up_vals,
                                              down_state,
                                              up_layer-&gt;getExpectations(),
-                                             background_gibbs_update_ratio,
-                                             gibbs_chain_statistics_forgetting_factor);
+                                             background_gibbs_update_ratio);
                 up_layer-&gt;updateCDandGibbs(pos_up_vals,cd_neg_up_vals,
                                            up_layer-&gt;getExpectations(),
-                                           background_gibbs_update_ratio,
-                                           gibbs_chain_statistics_forgetting_factor);
+                                           background_gibbs_update_ratio);
             }
             else
             {
-                down_layer-&gt;updateGibbs(pos_down_vals,down_state,
-                                        gibbs_chain_statistics_forgetting_factor);
+                down_layer-&gt;updateGibbs(pos_down_vals,down_state);
                 connection-&gt;updateGibbs(pos_down_vals,pos_up_vals,down_state,
-                                        up_layer-&gt;getExpectations(),
-                                        gibbs_chain_statistics_forgetting_factor);
-                up_layer-&gt;updateGibbs(pos_up_vals,up_layer-&gt;getExpectations(),
-                                        gibbs_chain_statistics_forgetting_factor);
+                                        up_layer-&gt;getExpectations());
+                up_layer-&gt;updateGibbs(pos_up_vals,up_layer-&gt;getExpectations());
             }
 
             // Save Gibbs chain's state.

Modified: trunk/plearn_learners/online/DeepBeliefNet.h
===================================================================
--- trunk/plearn_learners/online/DeepBeliefNet.h	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/DeepBeliefNet.h	2007-05-09 23:59:26 UTC (rev 7043)
@@ -157,11 +157,6 @@
     // statistics).
     real background_gibbs_update_ratio;
 
-    // negative chain statistics are forgotten at this rate (a value of 0
-    // would only use the current sample, a value of .99 would use 1% of
-    // the new sample and 99% of the old statistics).
-    real gibbs_chain_statistics_forgetting_factor;
-
     //! Wether we do a step of joint contrastive divergence on top-layer
     //! Only used if online for the moment
     bool top_layer_joint_cd;

Modified: trunk/plearn_learners/online/GradNNetLayerModule.cc
===================================================================
--- trunk/plearn_learners/online/GradNNetLayerModule.cc	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/GradNNetLayerModule.cc	2007-05-09 23:59:26 UTC (rev 7043)
@@ -95,7 +95,7 @@
 
     // Add bias.
     resizeOnes(n);
-    externalProductScaleAcc(outputs, ones, bias, 1.);
+    externalProductScaleAcc(outputs, ones, bias, 1.); // could be more efficient, but not critical 
 }
 
 /////////////////

Modified: trunk/plearn_learners/online/ModulesLearner.cc
===================================================================
--- trunk/plearn_learners/online/ModulesLearner.cc	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/ModulesLearner.cc	2007-05-09 23:59:26 UTC (rev 7043)
@@ -47,7 +47,7 @@
     &quot;Trains an OnlineLearningModule wrt the cost of a CostModule.&quot;,
     &quot;The CostModule provides the output gradient to train the\n&quot;
     &quot;OnlineLearningModule.\n&quot;
-    &quot;In order to stack layers, you can use StackedModulesModule,\n&quot;
+    &quot;In order to stack layers, you can use ModuleStackModule,\n&quot;
     &quot;and in order to compute several costs, you can use CombinedCostsModule.\n&quot;
     );
 

Modified: trunk/plearn_learners/online/RBMConnection.cc
===================================================================
--- trunk/plearn_learners/online/RBMConnection.cc	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/RBMConnection.cc	2007-05-09 23:59:26 UTC (rev 7043)
@@ -253,8 +253,7 @@
                                       const Mat&amp; cd_neg_up_values,
                                       const Mat&amp; gibbs_neg_down_values,
                                       const Mat&amp; gibbs_neg_up_values,
-                                      real background_gibbs_update_ratio,
-                                      real gibbs_chain_statistics_forgetting_factor)
+                                      real background_gibbs_update_ratio)
 {
     PLASSERT_MSG(false, &quot;Not implemented by subclass!&quot;);
 }
@@ -266,8 +265,7 @@
 void RBMConnection::updateGibbs( const Mat&amp; pos_down_values,
                                  const Mat&amp; pos_up_values,
                                  const Mat&amp; gibbs_neg_down_values,
-                                 const Mat&amp; gibbs_neg_up_values,
-                                 real gibbs_chain_statistics_forgetting_factor)
+                                 const Mat&amp; gibbs_neg_up_values)
 {
     PLASSERT_MSG(false, &quot;Not implemented by subclass!&quot;);
 }

Modified: trunk/plearn_learners/online/RBMConnection.h
===================================================================
--- trunk/plearn_learners/online/RBMConnection.h	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/RBMConnection.h	2007-05-09 23:59:26 UTC (rev 7043)
@@ -159,8 +159,7 @@
                                    const Mat&amp; cd_neg_up_values,
                                    const Mat&amp; gibbs_neg_down_values,
                                    const Mat&amp; gibbs_neg_up_values,
-                                   real background_gibbs_update_ratio,
-                                   real gibbs_chain_statistics_forgetting_factor);
+                                   real background_gibbs_update_ratio);
 
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
@@ -169,8 +168,7 @@
     virtual void updateGibbs( const Mat&amp; pos_down_values,
                               const Mat&amp; pos_up_values,
                               const Mat&amp; gibbs_neg_down_values,
-                              const Mat&amp; gibbs_neg_up_values,
-                              real gibbs_chain_statistics_forgetting_factor);
+                              const Mat&amp; gibbs_neg_up_values);
 
     //! Clear all information accumulated during stats
     virtual void clearStats() = 0;

Modified: trunk/plearn_learners/online/RBMLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMLayer.cc	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/RBMLayer.cc	2007-05-09 23:59:26 UTC (rev 7043)
@@ -55,6 +55,12 @@
     learning_rate(the_learning_rate),
     momentum(0.),
     size(-1),
+    delta_ma_param(0.1),
+    stationarity_statistic_threshold(2),
+    fast_mean(0), slow_mean(0),
+    gibbs_fast_ma_coefficient(0), gibbs_fast_ma_param(0),
+    gibbs_slow_ma_coefficient(0), gibbs_slow_ma_param(0),
+    var_of_value(0),sum_fast2(0),sum_slow2(0),sum_slowfast(0),
     expectation_is_up_to_date(false),
     expectations_are_up_to_date(false),
     pos_count(0),
@@ -78,6 +84,14 @@
     bias_neg_stats.clear();
     pos_count = 0;
     neg_count = 0;
+    gibbs_fast_ma_param = -1;
+    gibbs_slow_ma_param = 0;
+    gibbs_fast_ma_coefficient = sigmoid(gibbs_fast_ma_param);
+    gibbs_slow_ma_coefficient = sigmoid(gibbs_slow_ma_param);
+    var_of_value = 0.25;
+    sum_fast2 = (1 - gibbs_fast_ma_coefficient)*(1 - gibbs_fast_ma_coefficient);
+    sum_slow2 = (1 - gibbs_slow_ma_coefficient)*(1 - gibbs_slow_ma_coefficient);
+    sum_slowfast = (1 - gibbs_slow_ma_coefficient)*(1 - gibbs_fast_ma_coefficient);
 }
 
 void RBMLayer::forget()
@@ -105,6 +119,24 @@
                   OptionBase::buildoption,
                   &quot;Momentum.&quot;);
 
+    declareOption(ol, &quot;delta_ma_param&quot;, &amp;RBMLayer::delta_ma_param,
+                  OptionBase::buildoption,
+                  &quot;This option is used only when the background Gibbs is computed (i.e. update*Gibbs() is called).\n&quot;
+                  &quot;delta_ma_param is the increment in the parameters that control the moving average coefficients\n&quot;
+                  &quot;used to detect non-stationarity in the negative phase activity statistics.\n&quot;
+                  &quot;The moving average coefficient are obtained by sigmoid(parameter).\n&quot;
+                  &quot;Two moving averages are kept, a slow one and a fast one. When their\n&quot;
+                  &quot;difference is statistically significant the moving averages are slowed down.\n&quot;);
+
+    declareOption(ol, &quot;stationarity_statistic_threshold&quot;, &amp;RBMLayer::stationarity_statistic_threshold,
+                  OptionBase::buildoption,
+                  &quot;This option is used only when the background Gibbs is computed (i.e. update*Gibbs() is called).\n&quot;
+                  &quot;When the absolute value of the difference of the slow mean and the fast mean\n&quot;
+                  &quot;divided by the standard deviation of this difference is above this threshold,\n&quot;
+                  &quot;the moving averages are slowed down by increasing their parameter by delta_ma_param.\n&quot;
+                  &quot;When this stastitic is less than half the threshold, the moving averages are accelerated\n&quot;
+                  &quot;by decreasing their parameter by delta_ma_param.\n&quot;);
+
     declareOption(ol, &quot;bias&quot;, &amp;RBMLayer::bias,
                   OptionBase::learntoption,
                   &quot;Biases of the units.&quot;);
@@ -423,8 +455,7 @@
 void RBMLayer::updateCDandGibbs( const Mat&amp; pos_values,
                                  const Mat&amp; cd_neg_values,
                                  const Mat&amp; gibbs_neg_values,
-                                 real background_gibbs_update_ratio,
-                                 real gibbs_chain_statistics_forgetting_factor)
+                                 real background_gibbs_update_ratio )
 {
     PLASSERT(pos_values.width()==size);
     PLASSERT(cd_neg_values.width()==size);
@@ -442,8 +473,8 @@
     if (neg_count==0)
         multiply(tmp,normalize_factor,bias_neg_stats);
     else
-        multiplyScaledAdd(tmp,gibbs_chain_statistics_forgetting_factor,
-                          normalize_factor*(1-gibbs_chain_statistics_forgetting_factor),
+        multiplyScaledAdd(tmp,gibbs_slow_ma_coefficient,
+                          normalize_factor*(1-gibbs_slow_ma_coefficient),
                           bias_neg_stats);
     neg_count++;
 
@@ -462,8 +493,7 @@
 // updateGibbs //
 /////////////////
 void RBMLayer::updateGibbs( const Mat&amp; pos_values,
-                            const Mat&amp; gibbs_neg_values,
-                            real gibbs_chain_statistics_forgetting_factor)
+                            const Mat&amp; gibbs_neg_values)
 {
     int minibatch_size = pos_values.length();
     PLASSERT(pos_values.width()==size);
@@ -479,10 +509,51 @@
         multiply(tmp,normalize_factor,bias_neg_stats);
     else // bias_neg_stats &lt;-- tmp*(1-gibbs_chain_statistics_forgetting_factor)/minibatch_size 
         //                    +gibbs_chain_statistics_forgetting_factor*bias_neg_stats
-        multiplyScaledAdd(tmp,gibbs_chain_statistics_forgetting_factor,
-                          normalize_factor*(1-gibbs_chain_statistics_forgetting_factor),
+        multiplyScaledAdd(tmp,gibbs_slow_ma_coefficient,
+                          normalize_factor*(1-gibbs_slow_ma_coefficient),
                           bias_neg_stats);
     neg_count++;
+
+    // update gibbs chain statistics for checking when to change the ma_coefficient
+
+    // this is the statistic that summarizes what is happening in one minibatch (we could use something else)
+    real value = sum(tmp)*normalize_factor/size; 
+    // fast moving average of the value
+    fast_mean = gibbs_fast_ma_coefficient*fast_mean + (1-gibbs_fast_ma_coefficient)*value;
+    // slow moving average of the value
+    slow_mean = gibbs_slow_ma_coefficient*fast_mean + (1-gibbs_slow_ma_coefficient)*value;
+    // moving average estimator of the variance of the value
+    var_of_value = gibbs_slow_ma_coefficient*var_of_value + (1-gibbs_slow_ma_coefficient)*(value-slow_mean)*(value-slow_mean);
+    // now construct moving sums in order to compute Var(fast_mean-slow_mean)
+    sum_fast2 = gibbs_fast_ma_coefficient*gibbs_fast_ma_coefficient*sum_fast2 + 
+        (1-gibbs_fast_ma_coefficient)*(1-gibbs_fast_ma_coefficient);
+    sum_slow2 = gibbs_slow_ma_coefficient*gibbs_slow_ma_coefficient*sum_slow2 + 
+        (1-gibbs_slow_ma_coefficient)*(1-gibbs_slow_ma_coefficient);
+    sum_slowfast = gibbs_slow_ma_coefficient*gibbs_fast_ma_coefficient*sum_slowfast + 
+        (1-gibbs_slow_ma_coefficient)*(1-gibbs_fast_ma_coefficient);
+    // this is Var(fast_mean-slow_mean):
+    real var_of_mean_difference = var_of_value * (sum_fast2 + sum_slow2 - 2*sum_slowfast);
+    if (var_of_mean_difference&gt;0)
+    {
+        real stationarity_statistic = fabs(fast_mean - slow_mean)/sqrt(var_of_mean_difference);
+        if (stationarity_statistic&gt;stationarity_statistic_threshold) // things are changing too fast
+        {
+            gibbs_fast_ma_param-=delta_ma_param;
+            gibbs_slow_ma_param-=delta_ma_param;
+            gibbs_fast_ma_coefficient = sigmoid(gibbs_fast_ma_param);
+            gibbs_slow_ma_coefficient = sigmoid(gibbs_slow_ma_param);
+        }
+        else if (stationarity_statistic&lt;0.5*stationarity_statistic_threshold // things are not changing fast enough...
+                 &amp;&amp; gibbs_slow_ma_param &lt;10) // but there is not point in going TOO slow
+        {
+            gibbs_fast_ma_param+=delta_ma_param;
+            gibbs_slow_ma_param+=delta_ma_param;
+            gibbs_fast_ma_coefficient = sigmoid(gibbs_fast_ma_param);
+            gibbs_slow_ma_coefficient = sigmoid(gibbs_slow_ma_param);
+        }
+    }
+    else PLWARNING(&quot;non-positive variance?&quot;);
+    
     // delta w = -lrate * ( meanoverrows(pos_values) - neg_stats ) 
     columnSum(pos_values,tmp);
     multiplyAcc(bias, tmp, -learning_rate*normalize_factor);

Modified: trunk/plearn_learners/online/RBMLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMLayer.h	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/RBMLayer.h	2007-05-09 23:59:26 UTC (rev 7043)
@@ -73,11 +73,22 @@
     //! Obsolete option, still here for script compatibility
     string units_types;
 
+    //! gibbs stuff options
+    real delta_ma_param; // by how much to adapt the parameter of the moving average coefficients
+    real stationarity_statistic_threshold; // threshold on the z-statistic for stationarity
+
     //#####  Learnt Options  ##################################################
 
     // stores the bias of the unit
     Vec bias;
 
+    //! stuff used for Gibbs chain methods only
+    real fast_mean, slow_mean;
+    real gibbs_fast_ma_coefficient, gibbs_fast_ma_param; // fast_ma_coefficient = sigmoid(fast_ma_param)
+    real gibbs_slow_ma_coefficient, gibbs_slow_ma_param; // slow_ma_coefficient = sigmoid(slow_ma_param)
+    real var_of_value;
+    real sum_fast2, sum_slow2, sum_slowfast;
+
     //#####  Not Options  #####################################################
 
     //! activation value: \sum Wx + b
@@ -206,18 +217,15 @@
     virtual void updateCDandGibbs( const Mat&amp; pos_values,
                                    const Mat&amp; cd_neg_values,
                                    const Mat&amp; gibbs_neg_values,
-                                   real background_gibbs_update_ratio,
-                                   real gibbs_chain_statistics_forgetting_factor);
+                                   real background_gibbs_update_ratio );
 
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * \sum_i gibbs_neg_values_i / minibatch_size
     // delta bias = -lrate * \sum_i (pos_values_i - neg_stats) / minibatch_size
     virtual void updateGibbs( const Mat&amp; pos_values,
-                              const Mat&amp; gibbs_neg_values,
-                              real gibbs_chain_statistics_forgetting_factor);
+                              const Mat&amp; gibbs_neg_values );
 
-
     //! resets activations, sample and expectation fields
     virtual void reset();
 

Modified: trunk/plearn_learners/online/RBMMatrixConnection.cc
===================================================================
--- trunk/plearn_learners/online/RBMMatrixConnection.cc	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/RBMMatrixConnection.cc	2007-05-09 23:59:26 UTC (rev 7043)
@@ -50,7 +50,13 @@
     &quot;&quot;);
 
 RBMMatrixConnection::RBMMatrixConnection( real the_learning_rate ) :
-    inherited(the_learning_rate)
+    inherited(the_learning_rate),
+    delta_ma_param(0.1),
+    stationarity_statistic_threshold(2),
+    fast_mean(0), slow_mean(0),
+    gibbs_fast_ma_coefficient(0), gibbs_fast_ma_param(0),
+    gibbs_slow_ma_coefficient(0), gibbs_slow_ma_param(0),
+    var_of_value(0),sum_fast2(0),sum_slow2(0),sum_slowfast(0)
 {
 }
 
@@ -61,6 +67,24 @@
                   &quot;Matrix containing unit-to-unit weights (up_size &#215;&quot;
                   &quot; down_size)&quot;);
 
+    declareOption(ol, &quot;delta_ma_param&quot;, &amp;RBMMatrixConnection::delta_ma_param,
+                  OptionBase::buildoption,
+                  &quot;This option is used only when the background Gibbs is computed (i.e. update*Gibbs() is called).\n&quot;
+                  &quot;delta_ma_param is the increment in the parameters that control the moving average coefficients\n&quot;
+                  &quot;used to detect non-stationarity in the negative phase activity statistics.\n&quot;
+                  &quot;The moving average coefficient are obtained by sigmoid(parameter).\n&quot;
+                  &quot;Two moving averages are kept, a slow one and a fast one. When their\n&quot;
+                  &quot;difference is statistically significant the moving averages are slowed down.\n&quot;);
+
+    declareOption(ol, &quot;stationarity_statistic_threshold&quot;, &amp;RBMMatrixConnection::stationarity_statistic_threshold,
+                  OptionBase::buildoption,
+                  &quot;This option is used only when the background Gibbs is computed (i.e. update*Gibbs() is called).\n&quot;
+                  &quot;When the absolute value of the difference of the slow mean and the fast mean\n&quot;
+                  &quot;divided by the standard deviation of this difference is above this threshold,\n&quot;
+                  &quot;the moving averages are slowed down by increasing their parameter by delta_ma_param.\n&quot;
+                  &quot;When this stastitic is less than half the threshold, the moving averages are accelerated\n&quot;
+                  &quot;by decreasing their parameter by delta_ma_param.\n&quot;);
+
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
 }
@@ -294,8 +318,7 @@
                                             const Mat&amp; cd_neg_up_values,
                                             const Mat&amp; gibbs_neg_down_values,
                                             const Mat&amp; gibbs_neg_up_values,
-                                            real background_gibbs_update_ratio,
-                                            real gibbs_chain_statistics_forgetting_factor)
+                                            real background_gibbs_update_ratio)
 {
     real normalize_factor = 1.0/pos_down_values.length();
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
@@ -309,8 +332,8 @@
         productScaleAcc(weights_neg_stats,
                         gibbs_neg_up_values,true,
                         gibbs_neg_down_values,false,
-                        normalize_factor*(1-gibbs_chain_statistics_forgetting_factor),
-                        gibbs_chain_statistics_forgetting_factor);
+                        normalize_factor*(1-gibbs_slow_ma_coefficient),
+                        gibbs_slow_ma_coefficient);
     neg_count++;
 
     // delta w = -lrate * ( pos_up_values'*pos_down_values
@@ -331,25 +354,65 @@
 void RBMMatrixConnection::updateGibbs( const Mat&amp; pos_down_values,
                                        const Mat&amp; pos_up_values,
                                        const Mat&amp; gibbs_neg_down_values,
-                                       const Mat&amp; gibbs_neg_up_values,
-                                       real gibbs_chain_statistics_forgetting_factor)
+                                       const Mat&amp; gibbs_neg_up_values)
 {
     real normalize_factor = 1.0/pos_down_values.length();
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * gibbs_neg_up_values'*gibbs_neg_down_values
+    static Mat tmp;
+    tmp.resize(weights.length(),weights.width());
+    productScaleAcc(tmp,gibbs_neg_up_values,true,gibbs_neg_down_values,false,1,0);
     if (neg_count==0)
-        productScaleAcc(weights_neg_stats,
-                        gibbs_neg_up_values,true,
-                        gibbs_neg_down_values,false,normalize_factor,0);
+        multiply(weights_neg_stats,tmp,normalize_factor);
     else
-        productScaleAcc(weights_neg_stats,
-                        gibbs_neg_up_values,true,
-                        gibbs_neg_down_values,false,
-                        normalize_factor*(1-gibbs_chain_statistics_forgetting_factor),
-                        gibbs_chain_statistics_forgetting_factor);
+        multiplyScaledAdd(tmp,gibbs_slow_ma_coefficient,
+                          normalize_factor*(1-gibbs_slow_ma_coefficient),
+                          weights_neg_stats);
+
     neg_count++;
 
+    // update gibbs chain statistics for checking when to change the ma_coefficient
+
+    // this is the statistic that summarizes what is happening in one minibatch (we could use something else)
+    real value = sum(tmp)*normalize_factor/tmp.size();
+    // fast moving average of the value
+    fast_mean = gibbs_fast_ma_coefficient*fast_mean + (1-gibbs_fast_ma_coefficient)*value;
+    // slow moving average of the value
+    slow_mean = gibbs_slow_ma_coefficient*fast_mean + (1-gibbs_slow_ma_coefficient)*value;
+    // moving average estimator of the variance of the value
+    var_of_value = gibbs_slow_ma_coefficient*var_of_value + (1-gibbs_slow_ma_coefficient)*(value-slow_mean)*(value-slow_mean);
+    // now construct moving sums in order to compute Var(fast_mean-slow_mean)
+    sum_fast2 = gibbs_fast_ma_coefficient*gibbs_fast_ma_coefficient*sum_fast2 + 
+        (1-gibbs_fast_ma_coefficient)*(1-gibbs_fast_ma_coefficient);
+    sum_slow2 = gibbs_slow_ma_coefficient*gibbs_slow_ma_coefficient*sum_slow2 + 
+        (1-gibbs_slow_ma_coefficient)*(1-gibbs_slow_ma_coefficient);
+    sum_slowfast = gibbs_slow_ma_coefficient*gibbs_fast_ma_coefficient*sum_slowfast + 
+        (1-gibbs_slow_ma_coefficient)*(1-gibbs_fast_ma_coefficient);
+    // this is Var(fast_mean-slow_mean):
+    real var_of_mean_difference = var_of_value * (sum_fast2 + sum_slow2 - 2*sum_slowfast);
+    if (var_of_mean_difference&gt;0)
+    {
+        real stationarity_statistic = fabs(fast_mean - slow_mean)/sqrt(var_of_mean_difference);
+        if (stationarity_statistic&gt;stationarity_statistic_threshold) // things are changing too fast
+        {
+            gibbs_fast_ma_param-=delta_ma_param;
+            gibbs_slow_ma_param-=2*delta_ma_param;
+            gibbs_fast_ma_coefficient = sigmoid(gibbs_fast_ma_param);
+            gibbs_slow_ma_coefficient = sigmoid(gibbs_slow_ma_param);
+        }
+        else if (stationarity_statistic&lt;0.5*stationarity_statistic_threshold // things are not changing fast enough...
+                 &amp;&amp; gibbs_slow_ma_param &lt;10) // but there is not point in going TOO slow
+        {
+            gibbs_fast_ma_param+=delta_ma_param;
+            gibbs_slow_ma_param+=2*delta_ma_param;
+            gibbs_fast_ma_coefficient = sigmoid(gibbs_fast_ma_param);
+            gibbs_slow_ma_coefficient = sigmoid(gibbs_slow_ma_param);
+        }
+    }
+    else PLWARNING(&quot;non-positive variance?&quot;);
+
+
     // delta w = -lrate * ( pos_up_values'*pos_down_values/minibatch_size - neg_stats )
     productScaleAcc(weights,
                     pos_up_values, true,
@@ -367,6 +430,15 @@
 
     pos_count = 0;
     neg_count = 0;
+
+    gibbs_fast_ma_param = -1;
+    gibbs_slow_ma_param = 0;
+    gibbs_fast_ma_coefficient = sigmoid(gibbs_fast_ma_param);
+    gibbs_slow_ma_coefficient = sigmoid(gibbs_slow_ma_param);
+    var_of_value = 0.25;
+    sum_fast2 = (1 - gibbs_fast_ma_coefficient)*(1 - gibbs_fast_ma_coefficient);
+    sum_slow2 = (1 - gibbs_slow_ma_coefficient)*(1 - gibbs_slow_ma_coefficient);
+    sum_slowfast = (1 - gibbs_slow_ma_coefficient)*(1 - gibbs_fast_ma_coefficient);
 }
 
 ////////////////////

Modified: trunk/plearn_learners/online/RBMMatrixConnection.h
===================================================================
--- trunk/plearn_learners/online/RBMMatrixConnection.h	2007-05-09 23:44:20 UTC (rev 7042)
+++ trunk/plearn_learners/online/RBMMatrixConnection.h	2007-05-09 23:59:26 UTC (rev 7043)
@@ -57,11 +57,22 @@
 public:
     //#####  Public Build Options  ############################################
 
+    //! gibbs stuff options
+    real delta_ma_param; // by how much to adapt the parameter of the moving average coefficients
+    real stationarity_statistic_threshold; // threshold on the z-statistic for stationarity
+
     //#####  Learned Options  #################################################
 
     //! Matrix containing unit-to-unit weights (output_size &#215; input_size)
     Mat weights;
 
+    //! stuff used for Gibbs chain methods only
+    real fast_mean, slow_mean;
+    real gibbs_fast_ma_coefficient, gibbs_fast_ma_param; // fast_ma_coefficient = sigmoid(fast_ma_param)
+    real gibbs_slow_ma_coefficient, gibbs_slow_ma_param; // slow_ma_coefficient = sigmoid(slow_ma_param)
+    real var_of_value;
+    real sum_fast2, sum_slow2, sum_slowfast;
+
     //#####  Not Options  #####################################################
 
     //! Accumulates positive contribution to the weights' gradient
@@ -130,8 +141,7 @@
                                    const Mat&amp; cd_neg_up_values,
                                    const Mat&amp; gibbs_neg_down_values,
                                    const Mat&amp; gibbs_neg_up_values,
-                                   real background_gibbs_update_ratio,
-                                   real gibbs_chain_statistics_forgetting_factor);
+                                   real background_gibbs_update_ratio);
 
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
@@ -140,8 +150,7 @@
     virtual void updateGibbs( const Mat&amp; pos_down_values,
                               const Mat&amp; pos_up_values,
                               const Mat&amp; gibbs_neg_down_values,
-                              const Mat&amp; gibbs_neg_up_values,
-                              real gibbs_chain_statistics_forgetting_factor);
+                              const Mat&amp; gibbs_neg_up_values );
 
     //! Clear all information accumulated during stats
     virtual void clearStats();


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000491.html">[Plearn-commits] r7042 - in trunk: . commands	commands/PLearnCommands plearn/base plearn/db plearn/display	plearn/io plearn/ker plearn/math plearn/misc plearn/opt	plearn/python plearn/python/test plearn/python/test/.pytest	plearn/python/test/.pytest/EmbeddedPython_Instances	plearn/python/test/.pytest/EmbeddedPython_Instances/expected_results	plearn/python/test/.pytest/EmbeddedPython_InterfunctionXchg/expected_results	plearn/var plearn/vmat plearn_learners/generic	plearn_learners/hyper plearn_learners/regressors	plearn_learners/testers python_modules/plearn	python_modules/plearn/pybridge
</A></li>
	<LI>Next message: <A HREF="000493.html">[Plearn-commits] r7044 - in trunk/plearn/python: . test	test/.pytest/EmbeddedPython_Instances/expected_results
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#492">[ date ]</a>
              <a href="thread.html#492">[ thread ]</a>
              <a href="subject.html#492">[ subject ]</a>
              <a href="author.html#492">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
