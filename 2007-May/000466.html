<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7017 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7017%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200705061647.l46GlSD1005374%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000465.html">
   <LINK REL="Next"  HREF="000467.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7017 - trunk/plearn_learners/online</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7017%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200705061647.l46GlSD1005374%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7017 - trunk/plearn_learners/online">yoshua at mail.berlios.de
       </A><BR>
    <I>Sun May  6 18:47:28 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000465.html">[Plearn-commits] r7016 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000467.html">[Plearn-commits] r7018 - trunk/python_modules/plearn/pymake
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#466">[ date ]</a>
              <a href="thread.html#466">[ thread ]</a>
              <a href="subject.html#466">[ subject ]</a>
              <a href="author.html#466">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-05-06 18:47:26 +0200 (Sun, 06 May 2007)
New Revision: 7017

Modified:
   trunk/plearn_learners/online/DeepBeliefNet.cc
   trunk/plearn_learners/online/RBMConnection.h
   trunk/plearn_learners/online/RBMLayer.cc
   trunk/plearn_learners/online/RBMLayer.h
   trunk/plearn_learners/online/RBMMatrixConnection.cc
   trunk/plearn_learners/online/RBMMatrixConnection.h
Log:
Finished changes to make layerwise_reconstruction work, and 
continue implementing background Gibbs chain


Modified: trunk/plearn_learners/online/DeepBeliefNet.cc
===================================================================
--- trunk/plearn_learners/online/DeepBeliefNet.cc	2007-05-05 15:38:49 UTC (rev 7016)
+++ trunk/plearn_learners/online/DeepBeliefNet.cc	2007-05-06 16:47:26 UTC (rev 7017)
@@ -705,7 +705,7 @@
             activations_gradients[i].resize(minibatch_size, layers[i]-&gt;size);
             expectations_gradients[i].resize(minibatch_size, layers[i]-&gt;size);
 
-            if (background_gibbs_update_ratio&gt;0)
+            if (background_gibbs_update_ratio&gt;0 &amp;&amp; i&lt;n_layers-1)
                 gibbs_down_state[i].resize(minibatch_size, layers[i]-&gt;size);
         }
         if (final_cost)
@@ -748,6 +748,7 @@
 
         for( ; stage&lt;nstages; stage++)
         {
+            initialize_gibbs_chain=(stage%gibbs_chain_reinit_freq==0);
             // Do a step every 'minibatch_size' examples.
             if (stage % minibatch_size == 0) {
                 int sample_start = stage % nsamples;
@@ -793,6 +794,7 @@
 
             for( ; stage&lt;end_stage ; stage++ )
             {
+                initialize_gibbs_chain=(stage%gibbs_chain_reinit_freq==0);
                 // Do a step every 'minibatch_size' examples.
                 if (stage % minibatch_size == 0) {
                     int sample_start = stage % nsamples;
@@ -841,6 +843,7 @@
             int previous_stage = cumulative_schedule[n_layers-2];
             for( ; stage&lt;end_stage ; stage++ )
             {
+                initialize_gibbs_chain=(stage%gibbs_chain_reinit_freq==0);
                 int sample = stage % nsamples;
                 train_set-&gt;getExample( sample, input, target, weight );
                 jointGreedyStep( input, target );
@@ -872,7 +875,7 @@
         bool update_stats = false;
         for( ; stage&lt;end_stage ; stage++ )
         {
-            initialize_gibbs_chain=(stage%gibbs_chain_reinit_freq==0);
+
             // Update every 'minibatch_size' samples.
             if (stage % minibatch_size == 0) {
                 int sample_start = stage % nsamples;
@@ -1423,7 +1426,7 @@
         layer_inputs &lt;&lt; layers[index]-&gt;getExpectations(); // we will perturb these, so save them
         connections[index]-&gt;setAsUpInputs(layers[index+1]-&gt;getExpectations());
         layers[index]-&gt;getAllActivations(connections[index], 0, true);
-        layers[index]-&gt;fpropNLL(inputs, train_costs_m.column(reconstruction_cost_index+index+1));
+        layers[index]-&gt;fpropNLL(layer_inputs, train_costs_m.column(reconstruction_cost_index+index+1));
         Mat rc = train_costs_m.column(reconstruction_cost_index);
         rc += train_costs_m.column(reconstruction_cost_index+index+1);
         layers[index]-&gt;setExpectations(layer_inputs); // and restore them here

Modified: trunk/plearn_learners/online/RBMConnection.h
===================================================================
--- trunk/plearn_learners/online/RBMConnection.h	2007-05-05 15:38:49 UTC (rev 7016)
+++ trunk/plearn_learners/online/RBMConnection.h	2007-05-06 16:47:26 UTC (rev 7017)
@@ -149,10 +149,10 @@
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * gibbs_neg_up_values'*gibbs_neg_down_values
-    // delta w = lrate * ( pos_up_values'*pos_down_values
-    //                  - ( background_gibbs_update_ratio*neg_stats
-    //                     +(1-background_gibbs_update_ratio)
-    //                      * cd_neg_up_values'*cd_neg_down_values))
+    // delta w = -lrate * ( pos_up_values'*pos_down_values
+    //                   - ( background_gibbs_update_ratio*neg_stats
+    //                      +(1-background_gibbs_update_ratio)
+    //                       * cd_neg_up_values'*cd_neg_down_values))
     virtual void updateCDandGibbs( const Mat&amp; pos_down_values,
                                    const Mat&amp; pos_up_values,
                                    const Mat&amp; cd_neg_down_values,
@@ -165,7 +165,7 @@
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * gibbs_neg_up_values'*gibbs_neg_down_values
-    // delta w = lrate * ( pos_up_values'*pos_down_values - neg_stats )
+    // delta w = -lrate * ( pos_up_values'*pos_down_values - neg_stats )
     virtual void updateGibbs( const Mat&amp; pos_down_values,
                               const Mat&amp; pos_up_values,
                               const Mat&amp; gibbs_neg_down_values,

Modified: trunk/plearn_learners/online/RBMLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMLayer.cc	2007-05-05 15:38:49 UTC (rev 7016)
+++ trunk/plearn_learners/online/RBMLayer.cc	2007-05-06 16:47:26 UTC (rev 7017)
@@ -419,34 +419,58 @@
 //////////////////////
 // updateCDandGibbs //
 //////////////////////
-// neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
-//              +(1-gibbs_chain_statistics_forgetting_factor)
-//               * gibbs_neg_values
-// delta w = lrate * ( pos_values
-//                  - ( background_gibbs_update_ratio*neg_stats
-//                     +(1-background_gibbs_update_ratio)
-//                      * cd_neg_values ) )
 void RBMLayer::updateCDandGibbs( const Mat&amp; pos_values,
                                  const Mat&amp; cd_neg_values,
                                  const Mat&amp; gibbs_neg_values,
                                  real background_gibbs_update_ratio,
                                  real gibbs_chain_statistics_forgetting_factor)
 {
-    PLASSERT_MSG(false, &quot;Not implemented by subclass!&quot;);
+    PLASSERT(pos_values.width()==size);
+    PLASSERT(cd_neg_values.width()==size);
+    PLASSERT(gibbs_neg_values.width()==size);
+    int minibatch_size=gibbs_neg_values.length();
+    PLASSERT(pos_values.length()==minibatch_size);
+    PLASSERT(cd_neg_values.length()==minibatch_size);
+
+    // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
+    //              +(1-gibbs_chain_statistics_forgetting_factor)
+    //               * sumoverrows(gibbs_neg_values)
+    tmp.resize(size);
+    columnSum(gibbs_neg_values,tmp);
+    multiplyScaledAdd(tmp,gibbs_chain_statistics_forgetting_factor,
+                      (1-gibbs_chain_statistics_forgetting_factor),bias_neg_stats);
+    // delta w = -lrate * ( sumoverrows(pos_values)
+    //                   - ( background_gibbs_update_ratio*neg_stats
+    //                      +(1-background_gibbs_update_ratio)
+    //                       * sumoverrows(cd_neg_values) ) )
+    columnSum(pos_values,tmp);
+    multiplyAcc(bias, tmp, -learning_rate);
+    multiplyAcc(bias,bias_neg_stats,learning_rate*background_gibbs_update_ratio);
+    columnSum(cd_neg_values, tmp);
+    multiplyAcc(bias, tmp, -learning_rate*(1-background_gibbs_update_ratio));
 }
 
 /////////////////
 // updateGibbs //
 /////////////////
-// neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
-//              +(1-gibbs_chain_statistics_forgetting_factor)
-//               * gibbs_neg_values
-// delta w = lrate * ( pos_values - neg_stats )
 void RBMLayer::updateGibbs( const Mat&amp; pos_values,
                             const Mat&amp; gibbs_neg_values,
                             real gibbs_chain_statistics_forgetting_factor)
 {
-    PLASSERT_MSG(false, &quot;Not implemented by subclass!&quot;);
+    PLASSERT(pos_values.width()==size);
+    PLASSERT(gibbs_neg_values.width()==size);
+    PLASSERT(pos_values.length()==gibbs_neg_values.length());
+    // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
+    //              +(1-gibbs_chain_statistics_forgetting_factor)
+    //               * sumoverrows(gibbs_neg_values)
+    tmp.resize(size);
+    columnSum(gibbs_neg_values,tmp);
+    multiplyScaledAdd(tmp,gibbs_chain_statistics_forgetting_factor,
+                      (1-gibbs_chain_statistics_forgetting_factor),bias_neg_stats);
+    // delta w = -lrate * ( sumoverrows(pos_values - neg_stats ) )
+    columnSum(pos_values,tmp);
+    multiplyAcc(bias, tmp, -learning_rate);
+    multiplyAcc(bias,bias_neg_stats,learning_rate);
 }
 
 ////////////////

Modified: trunk/plearn_learners/online/RBMLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMLayer.h	2007-05-05 15:38:49 UTC (rev 7016)
+++ trunk/plearn_learners/online/RBMLayer.h	2007-05-06 16:47:26 UTC (rev 7017)
@@ -199,7 +199,7 @@
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * gibbs_neg_values
-    // delta w = lrate * ( pos_values
+    // delta w = -lrate * ( pos_values
     //                  - ( background_gibbs_update_ratio*neg_stats
     //                     +(1-background_gibbs_update_ratio)
     //                      * cd_neg_values ) )
@@ -212,7 +212,7 @@
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * gibbs_neg_values
-    // delta w = lrate * ( pos_values - neg_stats )
+    // delta w = -lrate * ( pos_values - neg_stats )
     virtual void updateGibbs( const Mat&amp; pos_values,
                               const Mat&amp; gibbs_neg_values,
                               real gibbs_chain_statistics_forgetting_factor);
@@ -275,6 +275,8 @@
     //! It is protected to encourage the use of accessors.
     Mat expectations;
 
+    Vec tmp;
+
 protected:
     //#####  Protected Member Functions  ######################################
 

Modified: trunk/plearn_learners/online/RBMMatrixConnection.cc
===================================================================
--- trunk/plearn_learners/online/RBMMatrixConnection.cc	2007-05-05 15:38:49 UTC (rev 7016)
+++ trunk/plearn_learners/online/RBMMatrixConnection.cc	2007-05-06 16:47:26 UTC (rev 7017)
@@ -318,7 +318,7 @@
     productScaleAcc(weights,
                     cd_neg_up_values, true,
                     cd_neg_down_values, false,
-                    learning_rate*(1-background_gibbs_update_ratio),1.);
+                    -learning_rate*(1-background_gibbs_update_ratio),1.);
 }
 
 void RBMMatrixConnection::updateGibbs( const Mat&amp; pos_down_values,

Modified: trunk/plearn_learners/online/RBMMatrixConnection.h
===================================================================
--- trunk/plearn_learners/online/RBMMatrixConnection.h	2007-05-05 15:38:49 UTC (rev 7016)
+++ trunk/plearn_learners/online/RBMMatrixConnection.h	2007-05-06 16:47:26 UTC (rev 7017)
@@ -120,10 +120,10 @@
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * gibbs_neg_up_values'*gibbs_neg_down_values
-    // delta w = lrate * ( pos_up_values'*pos_down_values
-    //                  - ( background_gibbs_update_ratio*neg_stats
-    //                     +(1-background_gibbs_update_ratio)
-    //                      * cd_neg_up_values'*cd_neg_down_values))
+    // delta w = -lrate * ( pos_up_values'*pos_down_values
+    //                   - ( background_gibbs_update_ratio*neg_stats
+    //                      +(1-background_gibbs_update_ratio)
+    //                       * cd_neg_up_values'*cd_neg_down_values))
     virtual void updateCDandGibbs( const Mat&amp; pos_down_values,
                                    const Mat&amp; pos_up_values,
                                    const Mat&amp; cd_neg_down_values,
@@ -136,7 +136,7 @@
     // neg_stats &lt;-- gibbs_chain_statistics_forgetting_factor * neg_stats
     //              +(1-gibbs_chain_statistics_forgetting_factor)
     //               * gibbs_neg_up_values'*gibbs_neg_down_values
-    // delta w = lrate * ( pos_up_values'*pos_down_values - neg_stats )
+    // delta w = -lrate * ( pos_up_values'*pos_down_values - neg_stats )
     virtual void updateGibbs( const Mat&amp; pos_down_values,
                               const Mat&amp; pos_up_values,
                               const Mat&amp; gibbs_neg_down_values,


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000465.html">[Plearn-commits] r7016 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000467.html">[Plearn-commits] r7018 - trunk/python_modules/plearn/pymake
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#466">[ date ]</a>
              <a href="thread.html#466">[ thread ]</a>
              <a href="subject.html#466">[ subject ]</a>
              <a href="author.html#466">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
