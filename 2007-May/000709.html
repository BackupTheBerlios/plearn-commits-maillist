<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7260 - in trunk: commands plearn_learners/online	plearn_learners/online/test	plearn_learners/online/test/MaxSubsampling2DModule	plearn_learners/online/test/MaxSubsampling2DModule/.pytest	plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling	plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7260%20-%20in%20trunk%3A%20commands%20plearn_learners/online%0A%09plearn_learners/online/test%0A%09plearn_learners/online/test/MaxSubsampling2DModule%0A%09plearn_learners/online/test/MaxSubsampling2DModule/.pytest%0A%09plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling%0A%09plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results&In-Reply-To=%3C200705231532.l4NFWZMf015888%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000708.html">
   <LINK REL="Next"  HREF="000710.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7260 - in trunk: commands plearn_learners/online	plearn_learners/online/test	plearn_learners/online/test/MaxSubsampling2DModule	plearn_learners/online/test/MaxSubsampling2DModule/.pytest	plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling	plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results</H1>
    <B>lamblin at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7260%20-%20in%20trunk%3A%20commands%20plearn_learners/online%0A%09plearn_learners/online/test%0A%09plearn_learners/online/test/MaxSubsampling2DModule%0A%09plearn_learners/online/test/MaxSubsampling2DModule/.pytest%0A%09plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling%0A%09plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results&In-Reply-To=%3C200705231532.l4NFWZMf015888%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7260 - in trunk: commands plearn_learners/online	plearn_learners/online/test	plearn_learners/online/test/MaxSubsampling2DModule	plearn_learners/online/test/MaxSubsampling2DModule/.pytest	plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling	plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results">lamblin at mail.berlios.de
       </A><BR>
    <I>Wed May 23 17:32:35 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000708.html">[Plearn-commits] r7259 - in trunk: plearn/var/EXPERIMENTAL	plearn_learners/generic/EXPERIMENTAL python_modules/plearn/var
</A></li>
        <LI>Next message: <A HREF="000710.html">[Plearn-commits] r7261 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#709">[ date ]</a>
              <a href="thread.html#709">[ thread ]</a>
              <a href="subject.html#709">[ subject ]</a>
              <a href="author.html#709">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: lamblin
Date: 2007-05-23 17:32:33 +0200 (Wed, 23 May 2007)
New Revision: 7260

Added:
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/RUN.log
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_0.psave
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_1.psave
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_2.psave
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_3.psave
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_4.psave
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_5.psave
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.cc
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.h
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/PL_max_subsampling.pyplearn
   trunk/plearn_learners/online/test/MaxSubsampling2DModule/pytest.config
Modified:
   trunk/commands/plearn_tests_inc.h
   trunk/plearn_learners/online/MaxSubsampling2DModule.cc
   trunk/plearn_learners/online/MaxSubsampling2DModule.h
Log:
New version (with ports interface) of MaxSubsampling2DModule, and a test.


Modified: trunk/commands/plearn_tests_inc.h
===================================================================
--- trunk/commands/plearn_tests_inc.h	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/commands/plearn_tests_inc.h	2007-05-23 15:32:33 UTC (rev 7260)
@@ -75,6 +75,7 @@
 #include &lt;plearn/vmat/test/FileVMatrixTest.h&gt;
 #include &lt;plearn/vmat/test/IndexedVMatrixTest.h&gt;
 #include &lt;plearn/vmat/test/RowBufferedVMatrixTest.h&gt;
+#include &lt;plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.h&gt;
 
 #include &lt;plearn/python/test/InstanceSnippetTest.h&gt;
 // Some other minimal includes to be able to run tests.

Modified: trunk/plearn_learners/online/MaxSubsampling2DModule.cc
===================================================================
--- trunk/plearn_learners/online/MaxSubsampling2DModule.cc	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/MaxSubsampling2DModule.cc	2007-05-23 15:32:33 UTC (rev 7260)
@@ -2,7 +2,7 @@
 
 // MaxSubsampling2DModule.cc
 //
-// Copyright (C) 2006 Pascal Lamblin
+// Copyright (C) 2007 Pascal Lamblin
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -41,18 +41,16 @@
 #include &lt;plearn/io/pl_log.h&gt;
 
 #include &quot;MaxSubsampling2DModule.h&quot;
-#include &lt;plearn/math/convolutions.h&gt;
-#include &lt;plearn/math/TMat_maths.h&gt;
 
 namespace PLearn {
 using namespace std;
 
 PLEARN_IMPLEMENT_OBJECT(
     MaxSubsampling2DModule,
-    &quot;Apply convolution filters on (possibly multiple) 2D inputs (images)&quot;,
+    &quot;Reduce the size of the 2D images by taking the max value of nearby pixels&quot;,
     &quot;&quot;);
 
-MaxSubsampling2DModule::MaxSubsampling2DModule() :
+MaxSubsampling2DModule::MaxSubsampling2DModule():
     n_input_images(1),
     input_images_length(-1),
     input_images_width(-1),
@@ -67,10 +65,6 @@
 
 void MaxSubsampling2DModule::declareOptions(OptionList&amp; ol)
 {
-    // declareOption(ol, &quot;myoption&quot;, &amp;MaxSubsampling2DModule::myoption,
-    //               OptionBase::buildoption,
-    //               &quot;Help text describing this option&quot;);
-
     declareOption(ol, &quot;n_input_images&quot;,
                   &amp;MaxSubsampling2DModule::n_input_images,
                   OptionBase::buildoption,
@@ -89,13 +83,11 @@
 
     declareOption(ol, &quot;kernel_length&quot;, &amp;MaxSubsampling2DModule::kernel_length,
                   OptionBase::buildoption,
-                  &quot;Length of the areas to maximize over&quot;
-                  );
+                  &quot;Length of the areas to maximize over&quot;);
 
     declareOption(ol, &quot;kernel_width&quot;, &amp;MaxSubsampling2DModule::kernel_width,
                   OptionBase::buildoption,
-                  &quot;Width of the areas to maximize over&quot;
-                  );
+                  &quot;Width of the areas to maximize over&quot;);
 
     declareOption(ol, &quot;output_images_length&quot;,
                   &amp;MaxSubsampling2DModule::output_images_length,
@@ -107,78 +99,64 @@
                   OptionBase::learntoption,
                   &quot;Width of the output images&quot;);
 
+    // declareOption(ol, &quot;&quot;, &amp;MaxSubsampling2DModule::,
+    //               OptionBase::buildoption,
+    //               &quot;&quot;);
+
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
 
-    // Redeclare some of the parent's options as learntoptions
+
     redeclareOption(ol, &quot;input_size&quot;, &amp;MaxSubsampling2DModule::input_size,
-                    OptionBase::learntoption,
-                    &quot;Size of the input, computed from n_input_images,\n&quot;
-                    &quot;input_images_length and input_images_width.\n&quot;);
+                  OptionBase::learntoption,
+                  &quot;Size of the input, computed from n_input_images,\n&quot;
+                  &quot;input_images_length and input_images_width.\n&quot;);
 
-    redeclareOption(ol, &quot;output_size&quot;, &amp;MaxSubsampling2DModule::output_size,
-                    OptionBase::learntoption,
-                    &quot;Size of the output, computed from n_input_images,\n&quot;
-                    &quot;output_images_length and output_images_width.\n&quot;);
+    declareOption(ol, &quot;output_size&quot;, &amp;MaxSubsampling2DModule::output_size,
+                  OptionBase::learntoption,
+                  &quot;Size of the output, computed from n_input_images,\n&quot;
+                  &quot;output_images_length and output_images_width.\n&quot;);
+
 }
 
 void MaxSubsampling2DModule::build_()
 {
     MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
 
-    // Verify the parameters
-    if( n_input_images &lt; 1 )
-        PLERROR(&quot;MaxSubsampling2DModule::build_: 'n_input_images' &lt; 1 (%i).\n&quot;,
-                n_input_images);
-
-    if( input_images_length &lt; 0 )
-        PLERROR(&quot;MaxSubsampling2DModule::build_: 'input_images_length'&lt;0 (%i).\n&quot;,
-                input_images_length);
-
-    if( input_images_width &lt; 0 )
-        PLERROR(&quot;MaxSubsampling2DModule::build_: 'input_images_width'&lt;0 (%i).\n&quot;,
-                input_images_width);
-
-    if( kernel_length &lt; 0 )
-        PLERROR(&quot;MaxSubsampling2DModule::build_: 'kernel_length'&lt;0 (%i).\n&quot;,
-                kernel_length);
-
-    if( kernel_width &lt; 0 )
-        PLERROR(&quot;MaxSubsampling2DModule::build_: 'kernel_width'&lt;0 (%i).\n&quot;,
-                kernel_width);
-
-    if( input_images_length % kernel_length != 0 )
-        PLERROR(&quot;MaxSubsampling2DModule::build_: input_images_length (%i)\n&quot;
-                &quot;should be a multiple of kernel_length (%i).\n&quot;,
-                input_images_length, kernel_length);
-
-    if( input_images_width % kernel_width != 0 )
-        PLERROR(&quot;MaxSubsampling2DModule::build_: input_images_width (%i)\n&quot;
-                &quot;should be a multiple of kernel_width (%i).\n&quot;,
-                input_images_width, kernel_width);
-
     // Build the learntoptions from the buildoptions
     input_images_size = input_images_length * input_images_width;
     input_size = n_input_images * input_images_size;
 
+    PLCHECK( n_input_images &gt; 0 );
+    PLCHECK( input_images_length &gt; 0 );
+    PLCHECK( input_images_width &gt; 0 );
+    PLCHECK( kernel_length &gt; 0 );
+    PLCHECK( kernel_width &gt; 0 );
+    PLCHECK_MSG( input_images_length % kernel_length == 0,
+                 &quot;input_images_length should be a multiple of kernel_length&quot; );
+    PLCHECK_MSG( input_images_width % kernel_width == 0,
+                 &quot;input_images_width should be a multiple of kernel_width&quot; );
+
     output_images_length = input_images_length / kernel_length;
     output_images_width = input_images_width / kernel_width;
     output_images_size = output_images_length * output_images_width;
     output_size = n_input_images * output_images_size;
 
-    input_images.resize(n_input_images);
-    output_images.resize(n_input_images);
-    input_gradients.resize(n_input_images);
-    output_gradients.resize(n_input_images);
+    // build ports
+    ports.resize(3);
+    ports[0] = &quot;input&quot;;
+    ports[1] = &quot;output&quot;;
+    ports[2] = &quot;argmax.state&quot;;
 
-    all_max_indices.resize(output_size);
-    max_indices.resize(n_input_images);
-    for( int i = 0; i &lt; n_input_images; i++ )
-        max_indices[i] =
-            all_max_indices.subVec(i*output_images_size, output_images_size)
-                .toMat(output_images_length, output_images_width);
+    // build port_sizes
+    port_sizes.resize(nPorts(), 2);
+    port_sizes.column(0).fill(-1);
+    port_sizes(0, 1) = input_size;
+    port_sizes(1, 1) = output_size;
+    port_sizes(2, 1) = output_size;
 }
 
+// ### Nothing to add here, simply calls build_
 void MaxSubsampling2DModule::build()
 {
     inherited::build();
@@ -190,184 +168,266 @@
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
 
-    deepCopyField(input_images, copies);
-    deepCopyField(output_images, copies);
-    deepCopyField(input_gradients, copies);
-    deepCopyField(output_gradients, copies);
-    deepCopyField(all_max_indices, copies);
-    deepCopyField(max_indices, copies);
+    deepCopyField(ports, copies);
 }
 
-//! given the input, compute the output (possibly resize it  appropriately)
-void MaxSubsampling2DModule::fprop(const Vec&amp; input, Vec&amp; output) const
+///////////
+// fprop //
+///////////
+void MaxSubsampling2DModule::fprop(const TVec&lt;Mat*&gt;&amp; ports_value)
 {
-    // Check size
-    if( input.size() != input_size )
-        PLERROR(&quot;MaxSubsampling2DModule::fprop: input.size() should be equal to\n&quot;
-                &quot;input_size (%i != %i).\n&quot;, input.size(), input_size);
-    output.resize(output_size);
+    PLASSERT( ports_value.length() == nPorts() );
+    // check which ports are input
+    // (ports_value[i] &amp;&amp; !ports_value[i]-&gt;isEmpty())
+    // which ports are output (ports_value[i] &amp;&amp; ports_value[i]-&gt;isEmpty())
+    // and which ports are ignored (!ports_value[i]).
+    // If that combination of (input,output,ignored) is feasible by this class
+    // then perform the corresponding computation. Otherwise launch the error
+    // below. See the comment in the header file for more information.
 
-    // Make input_images and output_images point to the right places
-    for( int l=0 ; l&lt;n_input_images ; l++ )
+    Mat* input = ports_value[0];
+    Mat* output = ports_value[1];
+    Mat* argmax = ports_value[2];
+
+    if( input &amp;&amp; !input-&gt;isEmpty()
+        &amp;&amp; output &amp;&amp; output-&gt;isEmpty()
+        &amp;&amp; argmax &amp;&amp; argmax-&gt;isEmpty() )
     {
-        input_images[l] =
-            input.subVec(l*input_images_size, input_images_size)
-                .toMat( input_images_length, input_images_width );
+        PLASSERT( input-&gt;width() == port_sizes(0,1) );
+        PLASSERT( output-&gt;width() == port_sizes(1,1) );
+        PLASSERT( argmax-&gt;width() == port_sizes(2,1) );
 
-        output_images[l] =
-            output.subVec(l*output_images_size, output_images_size)
-                .toMat( output_images_length, output_images_width );
-    }
+        int batch_size = input-&gt;length();
+        output-&gt;resize(batch_size, port_sizes(1,1));
+        argmax-&gt;resize(batch_size, port_sizes(2,1));
 
-    // Compute the values of the output_images
-    for( int l=0 ; l&lt;n_input_images ; l++ )
-        for( int i=0; i&lt;output_images_length; i++ )
-            for( int j=0; j&lt;output_images_width; j++ )
+        for( int k=0; k&lt;batch_size; k++ )
+            for( int l=0; l&lt;n_input_images; l++ )
             {
-                int min_i, min_j;
-                output_images[l](i,j) = max(
-                    input_images[l].subMat(i*kernel_length, j*kernel_width,
-                                           kernel_length, kernel_width),
-                    min_i, min_j );
-                max_indices[l](i,j) = min_i*input_images_width + min_j;
+                Mat input_image_kl = (*input)(k)
+                    .subVec(l*input_images_size, input_images_size)
+                    .toMat(input_images_length, input_images_width);
+                Mat output_image_kl = (*output)(k)
+                    .subVec(l*output_images_size, output_images_size)
+                    .toMat(output_images_length, output_images_width);
+                Mat argmax_kl = (*argmax)(k)
+                    .subVec(l*output_images_size, output_images_size)
+                    .toMat(output_images_length, output_images_width);
+
+                for( int i=0; i&lt;output_images_length; i++ )
+                    for( int j=0; j&lt;output_images_width; j++ )
+                    {
+                        int argmax_i, argmax_j;
+                        output_image_kl(i,j) = max(
+                            input_image_kl.subMat(i*kernel_length,
+                                                   j*kernel_width,
+                                                   kernel_length,
+                                                   kernel_width),
+                            argmax_i, argmax_j );
+                        argmax_kl(i,j) = argmax_i*input_images_width+argmax_j;
+                    }
             }
+    }
+    else
+        PLCHECK_MSG( false, &quot;Unknown port configuration&quot; );
 }
 
-/* THIS METHOD IS OPTIONAL
-//! Adapt based on the output gradient: this method should only
-//! be called just after a corresponding fprop; it should be
-//! called with the same arguments as fprop for the first two arguments
-//! (and output should not have been modified since then).
-//! Since sub-classes are supposed to learn ONLINE, the object
-//! is 'ready-to-be-used' just after any bpropUpdate.
-//! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS, WHICH
-//! JUST CALLS
-//!     bpropUpdate(input, output, input_gradient, output_gradient)
-//! AND IGNORES INPUT GRADIENT.
-void MaxSubsampling2DModule::bpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                               const Vec&amp; output_gradient)
-{
-}
-*/
+/////////////////
+// bpropUpdate //
+/////////////////
 
-//! this version allows to obtain the input gradient as well
-void MaxSubsampling2DModule::bpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                                         Vec&amp; input_gradient,
-                                         const Vec&amp; output_gradient,
-                                         bool accumulate)
+
+void MaxSubsampling2DModule::bpropAccUpdate(const TVec&lt;Mat*&gt;&amp; ports_value,
+                                            const TVec&lt;Mat*&gt;&amp; ports_gradient)
 {
-    // Check size
-    if( input.size() != input_size )
-        PLERROR(&quot;MaxSubsampling2DModule::bpropUpdate: input.size() should be\n&quot;
-                &quot;equal to input_size (%i != %i).\n&quot;, input.size(), input_size);
-    if( output.size() != output_size )
-        PLERROR(&quot;MaxSubsampling2DModule::bpropUpdate: output.size() should be\n&quot;
-                &quot;equal to output_size (%i != %i).\n&quot;,
-                output.size(), output_size);
-    if( output_gradient.size() != output_size )
-        PLERROR(&quot;MaxSubsampling2DModule::bpropUpdate: output_gradient.size()&quot;
-                &quot; should be\n&quot;
-                &quot;equal to output_size (%i != %i).\n&quot;,
-                output_gradient.size(), output_size);
+    PLASSERT( ports_value.length() == nPorts()
+              &amp;&amp; ports_gradient.length() == nPorts());
+    // check which ports are input
+    // (ports_value[i] &amp;&amp; !ports_value[i]-&gt;isEmpty())
+    // which ports are output (ports_value[i] &amp;&amp; ports_value[i]-&gt;isEmpty())
+    // and which ports are ignored (!ports_value[i]).
+    // A similar logic applies to ports_gradients (to know whether gradient
+    // is coming into the module of coming from the module through a given
+    // ports_gradient[i]).
+    // An input port_value should correspond to an outgoing port_gradient,
+    // an output port_value could either correspond to an incoming
+    // port_gradient (when that gradient is to be propagated inside and to the
+    // input ports) or it should be null (no gradient is propagated from that
+    // output port).
 
-    if( accumulate )
-    {
-        PLASSERT_MSG( input_gradient.size() == input_size,
-                      &quot;Cannot resize input_gradient AND accumulate into it&quot; );
-    }
-    else
-    {
-        input_gradient.resize(input_size);
-        input_gradient.clear();
-    }
+    Mat* input = ports_value[0];
+    Mat* output = ports_value[1];
+    Mat* argmax = ports_value[2];
+    Mat* input_grad = ports_gradient[0];
+    Mat* output_grad = ports_gradient[1];
+    Mat* argmax_grad = ports_gradient[2];
 
-    // Since fprop() has just been called, we assume that input_images,
-    // output_images and gradient are up-to-date
-    // Make input_gradients and output_gradients point to the right places
-    for( int l=0 ; l&lt;n_input_images ; l++ )
+    // If we want input_grad and we have output_grad
+    if( input_grad &amp;&amp; input_grad-&gt;isEmpty()
+        &amp;&amp; output_grad &amp;&amp; !output_grad-&gt;isEmpty() )
     {
-        input_gradients[l] =
-            input_gradient.subVec(l*input_images_size, input_images_size)
-                .toMat( input_images_length, input_images_width );
+        PLASSERT( !argmax_grad );
 
-        output_gradients[l] =
-            output_gradient.subVec(l*output_images_size, output_images_size)
-                .toMat( output_images_length, output_images_width );
-    }
+        PLASSERT( input-&gt;width() == port_sizes(0,1) );
+        PLASSERT( output-&gt;width() == port_sizes(1,1) );
+        PLASSERT( argmax-&gt;width() == port_sizes(2,1) );
+        PLASSERT( input_grad-&gt;width() == port_sizes(0,1) );
+        PLASSERT( output_grad-&gt;width() == port_sizes(1,1) );
 
-    // Do the actual bprop and update
-    for( int l=0 ; l&lt;n_input_images ; l++ )
-        for( int i=0; i&lt;output_images_length; i++ )
-            for( int j=0; j&lt;output_images_width; j++ )
+        int batch_size = input-&gt;length();
+        PLASSERT( output-&gt;length() == batch_size );
+        PLASSERT( argmax-&gt;length() == batch_size );
+        PLASSERT( output_grad-&gt;length() == batch_size );
+
+        input_grad-&gt;resize(batch_size, port_sizes(0,1));
+
+        for( int k=0; k&lt;batch_size; k++ )
+            for( int l=0; l&lt;n_input_images; l++ )
             {
-                Mat input_grad_zone =
-                    input_gradients[l].subMat(i*kernel_length, j*kernel_width,
-                                              kernel_length, kernel_width);
-                input_grad_zone.data()[ max_indices[l](i,j) ] =
-                    output_gradients[l](i,j);
+                Mat input_grad_image_kl = (*input_grad)(k)
+                    .subVec(l*input_images_size, input_images_size)
+                    .toMat(input_images_length, input_images_width);
+                Mat output_grad_image_kl = (*output_grad)(k)
+                    .subVec(l*output_images_size, output_images_size)
+                    .toMat(output_images_length, output_images_width);
+                Mat argmax_kl = (*argmax)(k)
+                    .subVec(l*output_images_size, output_images_size)
+                    .toMat(output_images_length, output_images_width);
+
+                for( int i=0; i&lt;output_images_length; i++ )
+                    for( int j=0; j&lt;output_images_width; j++ )
+                    {
+                        Mat input_grad_zone = input_grad_image_kl
+                            .subMat(i*kernel_length, j*kernel_width,
+                                    kernel_length, kernel_width);
+
+                        int argmax = (int) round(argmax_kl(i,j));
+                        input_grad_zone.data()[argmax] =
+                            output_grad_image_kl(i,j);
+                    }
             }
+    }
+    else
+        PLERROR(&quot;In MaxSubsampling2DModule::bpropAccUpdate - this configuration of ports not implemented for class &quot;
+            &quot;'%s'&quot;, classname().c_str());
 }
 
-//! reset the parameters to the state they would be BEFORE starting training.
-//! Note that this method is necessarily called from build().
+
+////////////
+// forget //
+////////////
 void MaxSubsampling2DModule::forget()
 {
-    all_max_indices.clear();
 }
 
+//////////////
+// finalize //
+//////////////
 /* THIS METHOD IS OPTIONAL
-//! reset the parameters to the state they would be BEFORE starting training.
-//! Note that this method is necessarily called from build().
-//! THE DEFAULT IMPLEMENTATION PROVIDED IN THE SUPER-CLASS DOES NOT DO
-//! ANYTHING.
 void MaxSubsampling2DModule::finalize()
 {
 }
 */
 
+//////////////////////
+// bpropDoesNothing //
+//////////////////////
 /* THIS METHOD IS OPTIONAL
-//! in case bpropUpdate does not do anything, make it known
-//! THE DEFAULT IMPLEMENTATION PROVIDED IN THE SUPER-CLASS RETURNS false;
+// the default implementation returns false
 bool MaxSubsampling2DModule::bpropDoesNothing()
 {
 }
 */
 
-/* THIS METHOD IS OPTIONAL
-//! Similar to bpropUpdate, but adapt based also on the estimation
-//! of the diagonal of the Hessian matrix, and propagates this
-//! back. If these methods are defined, you can use them INSTEAD of
-//! bpropUpdate(...)
-//! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS, WHICH
-//! JUST CALLS
-//!     bbpropUpdate(input, output, input_gradient, output_gradient,
-//!                  in_hess, out_hess)
-//! AND IGNORES INPUT HESSIAN AND INPUT GRADIENT.
-void MaxSubsampling2DModule::bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                                const Vec&amp; output_gradient,
-                                const Vec&amp; output_diag_hessian)
+/////////////////////
+// setLearningRate //
+/////////////////////
+void MaxSubsampling2DModule::setLearningRate(real dynamic_learning_rate)
 {
+    // Do nothing.
 }
+
+////////////////////////
+// getPortDescription //
+////////////////////////
+/* OPTIONAL
+// The default implementation is probably appropriate
+TVec&lt;string&gt; MaxSubsampling2DModule::getPortDescription(const string&amp; port)
+{
+}
 */
 
-/* NOT IMPLEMENTED
-//! Similar to bpropUpdate, but adapt based also on the estimation
-//! of the diagonal of the Hessian matrix, and propagates this
-//! back. If these methods are defined, you can use them INSTEAD of
-//! bpropUpdate(...)
-void MaxSubsampling2DModule::bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                                       Vec&amp; input_gradient,
-                                       const Vec&amp; output_gradient,
-                                       Vec&amp; input_diag_hessian,
-                                       const Vec&amp; output_diag_hessian,
-                                       bool accumulate)
+//////////////////
+// getPortIndex //
+//////////////////
+/* OPTIONAL
+// The default implementation is probably appropriate
+int MaxSubsampling2DModule::getPortIndex(const string&amp; port)
 {
 }
 */
 
+/////////////////
+// getPortName //
+/////////////////
+/* OPTIONAL
+// The default implementation is probably appropriate
+string MaxSubsampling2DModule::getPortName(int i)
+{
+}
+*/
 
-} // end of namespace PLearn
+//////////////
+// getPorts //
+//////////////
+const TVec&lt;string&gt;&amp; MaxSubsampling2DModule::getPorts()
+{
+    return ports;
+}
 
+//////////////////
+// getPortSizes //
+//////////////////
+const TMat&lt;int&gt;&amp; MaxSubsampling2DModule::getPortSizes()
+{
+    return port_sizes;
+}
+
+///////////////////
+// getPortLength //
+///////////////////
+/* OPTIONAL
+// The default implementation is probably appropriate
+int MaxSubsampling2DModule::getPortLength(const string&amp; port)
+{
+    PLASSERT( getPortIndex(port) &gt;= 0 );
+    return getPortSizes()(getPortIndex(port), 0);
+}
+*/
+
+//////////////////
+// getPortWidth //
+//////////////////
+/* OPTIONAL
+// The default implementation is probably appropriate
+int MaxSubsampling2DModule::getPortWidth(const string&amp; port)
+{
+}
+*/
+
+////////////
+// nPorts //
+////////////
+/* OPTIONAL
+// The default implementation is probably appropriate
+int MaxSubsampling2DModule::nPorts()
+{
+}
+*/
+
+}
+// end of namespace PLearn
+
 
 /*
   Local Variables:

Modified: trunk/plearn_learners/online/MaxSubsampling2DModule.h
===================================================================
--- trunk/plearn_learners/online/MaxSubsampling2DModule.h	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/MaxSubsampling2DModule.h	2007-05-23 15:32:33 UTC (rev 7260)
@@ -2,7 +2,7 @@
 
 // MaxSubsampling2DModule.h
 //
-// Copyright (C) 2006 Pascal Lamblin
+// Copyright (C) 2007 Pascal Lamblin
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -87,6 +87,7 @@
     int output_images_size;
 
 
+
 public:
     //#####  Public Member Functions  #########################################
 
@@ -97,68 +98,98 @@
 
     // Your other public member functions go here
 
-    //! given the input, compute the output (possibly resize it  appropriately)
-    virtual void fprop(const Vec&amp; input, Vec&amp; output) const;
+    //! Perform a fprop step.
+    //! Each Mat* pointer in the 'ports_value' vector can be one of:
+    //! - a full matrix: this is data that is provided to the module, and can
+    //!                  be used to compute other ports' values
+    //! - an empty matrix: this is what we want to compute
+    //! - a NULL pointer: this is data that is not available, but whose value
+    //!                   does not need to be returned (or even computed)
+    //! The default version will either:
+    //! - call the mini-batch versions of standard fprop if 'ports_value' has
+    //!   size 2, with the first value being provided (and the second being
+    //!   the desired output)
+    //! - crash otherwise
+    void fprop(const TVec&lt;Mat*&gt;&amp; ports_value);
 
-    //! Adapt based on the output gradient: this method should only
-    //! be called just after a corresponding fprop; it should be
-    //! called with the same arguments as fprop for the first two arguments
-    //! (and output should not have been modified since then).
-    //! Since sub-classes are supposed to learn ONLINE, the object
-    //! is 'ready-to-be-used' just after any bpropUpdate.
-    //! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS, WHICH
-    //! JUST CALLS
-    //!     bpropUpdate(input, output, input_gradient, output_gradient)
-    //! AND IGNORES INPUT GRADIENT.
-    // virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
-    //                          const Vec&amp; output_gradient);
+    //! Perform a back propagation step (also updating parameters according to
+    //! the provided gradient).
+    //! The matrices in 'ports_value' must be the same as the ones given in a
+    //! previous call to 'fprop' (and thus they should in particular contain
+    //! the result of the fprop computation). However, they are not necessarily
+    //! the same as the ones given in the LAST call to 'fprop': if there is a
+    //! need to store an internal module state, this should be done using a
+    //! specific port to store this state.
+    //! Each Mat* pointer in the 'ports_gradient' vector can be one of:
+    //! - a full matrix  : this is the gradient that is provided to the module,
+    //!                    and can be used to compute other ports' gradient.
+    //! - an empty matrix: this is a gradient we want to compute and accumulate
+    //!                    into. This matrix must have length 0 and a width
+    //!                    equal to the width of the corresponding matrix in
+    //!                    the 'ports_value' vector (we can thus accumulate
+    //!                    gradients using PLearn's ability to keep intact
+    //!                    stored values when resizing a matrix' length).
+    //! - a NULL pointer : this is a gradient that is not available, but does
+    //!                    not need to be returned (or even computed).
+    //! The default version tries to use the standard mini-batch bpropUpdate
+    //! method, when possible.
+    virtual void bpropAccUpdate(const TVec&lt;Mat*&gt;&amp; ports_value,
+                                const TVec&lt;Mat*&gt;&amp; ports_gradient);
 
-    //! this version allows to obtain the input gradient as well
-    //! N.B. THE DEFAULT IMPLEMENTATION IN SUPER-CLASS JUST RAISES A PLERROR.
-    virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                             Vec&amp; input_gradient,
-                             const Vec&amp; output_gradient,
-                             bool accumulate=false);
 
-    //! Similar to bpropUpdate, but adapt based also on the estimation
-    //! of the diagonal of the Hessian matrix, and propagates this
-    //! back. If these methods are defined, you can use them INSTEAD of
-    //! bpropUpdate(...)
-    //! N.B. A DEFAULT IMPLEMENTATION IS PROVIDED IN THE SUPER-CLASS,
-    //! WHICH JUST CALLS
-    //!     bbpropUpdate(input, output, input_gradient, output_gradient,
-    //!                  out_hess, in_hess)
-    //! AND IGNORES INPUT HESSIAN AND INPUT GRADIENT.
-    // virtual void bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
-    //                           const Vec&amp; output_gradient,
-    //                           const Vec&amp; output_diag_hessian);
-
-    /*
-    //! this version allows to obtain the input gradient and diag_hessian
-    virtual void bbpropUpdate(const Vec&amp; input, const Vec&amp; output,
-                              Vec&amp; input_gradient,
-                              const Vec&amp; output_gradient,
-                              Vec&amp; input_diag_hessian,
-                              const Vec&amp; output_diag_hessian,
-                              bool accumulate=false);
-    */
-
-    //! reset the parameters to the state they would be BEFORE starting
+    //! Reset the parameters to the state they would be BEFORE starting
     //! training.  Note that this method is necessarily called from
     //! build().
     virtual void forget();
 
+    //! If this class has a learning rate (or something close to it), set it.
+    //! If not, you can redefine this method to get rid of the warning.
+    virtual void setLearningRate(real dynamic_learning_rate);
 
-    //! optionally perform some processing after training, or after a
-    //! series of fprop/bpropUpdate calls to prepare the model for truly
-    //! out-of-sample operation.  THE DEFAULT IMPLEMENTATION PROVIDED IN
-    //! THE SUPER-CLASS DOES NOT DO ANYTHING.
-    // virtual void finalize();
+    //! Return the list of ports in the module.
+    //! The default implementation returns a pair (&quot;input&quot;, &quot;output&quot;) to handle
+    //! the most common case.
+    virtual const TVec&lt;string&gt;&amp; getPorts();
 
-    //! in case bpropUpdate does not do anything, make it known
-    //! THE DEFAULT IMPLEMENTATION PROVIDED IN THE SUPER-CLASS RETURNS false;
-    // virtual bool bpropDoesNothing();
+    //! Return the size of all ports, in the form of a two-column matrix, where
+    //! each row represents a port, and the two numbers on a row are
+    //! respectively its length and its width (with -1 representing an
+    //! undefined or variable value).
+    //! The default value fills this matrix with:
+    //!     - in the first column (lengths): -1
+    //!     - in the second column (widths):
+    //!         - -1 if nPorts() != 2
+    //!         - 'input_size' for the first row and 'output_size' for the
+    //!           second row if nPorts() == 2 (also assuming the port names
+    //!           are respectively 'input' and 'output')
+    virtual const TMat&lt;int&gt;&amp; getPortSizes();
 
+    /* Optional
+    //! Return the width of a specific port.
+    int getPortWidth(const string&amp; port);
+
+    //! Return the length of a specific port.
+    int getPortLength(const string&amp; port);
+
+    //! Return the number of ports in the module.
+    int nPorts();
+
+    //! Return the index (as in the list of ports returned by getPorts()) of
+    //! a given port.
+    //! If 'port' does not exist, -1 is returned.
+    int getPortIndex(const string&amp; port);
+
+    //! Return name of the i-th port.
+    string getPortName(int i);
+
+    //! Return a list of strings, that represents the description of the values
+    //! taken by a given port: the i-th string is the name for the i-th column
+    //! value computed in 'port'.
+    //! The default version returns [ &quot;port_name_1&quot;, ..., &quot;port_name_n&quot; ] where
+    //! 'port_name' is the name of the port, and 'n' its size.
+    virtual TVec&lt;string&gt; getPortDescription(const string&amp; port);
+    */
+
     //#####  PLearn::Object Protocol  #########################################
 
     // Declares other standard object methods.
@@ -188,19 +219,10 @@
 private:
     //#####  Private Data Members  ############################################
 
-    // The Mat they contain will point to sub-parts of input and output vectors
-    // and gradients, for more convenience
-    TVec&lt;Mat&gt; input_images;
-    TVec&lt;Mat&gt; output_images;
-    TVec&lt;Mat&gt; input_gradients;
-    TVec&lt;Mat&gt; output_gradients;
-    TVec&lt;Mat&gt; input_diag_hessians;
-    TVec&lt;Mat&gt; output_diag_hessians;
+    // The rest of the private stuff goes here
 
-    // Stores the index of the max within the pooling zone (i*mod + j)
-    TVec&lt;int&gt; all_max_indices;
-    TVec&lt; TMat&lt;int&gt; &gt; max_indices;
-
+    //! The name of the ports
+    TVec&lt;string&gt; ports;
 };
 
 // Declares a few other classes and functions related to this class


Property changes on: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest
___________________________________________________________________
Name: svn:ignore
   + *.compilation_log



Property changes on: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling
___________________________________________________________________
Name: svn:ignore
   + .plearn
run_results


Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/RUN.log
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/RUN.log	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/RUN.log	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,338 @@
+in(0,0) = 
+0.571326846722513437	
+
+out(0,0) = 
+0.571326846722513437	
+
+argmax(0,0) = 
+0	
+
+in_grad(0,0) = 
+1	
+
+in(0,0) = 
+0.571326846722513437	-0.550624472554773092	
+0.608788561541587114	-0.477692046202719212	
+
+out(0,0) = 
+0.608788561541587114	
+
+argmax(0,0) = 
+2	
+
+in_grad(0,0) = 
+0	0	
+1	0	
+
+in(0,0) = 
+0.571326846722513437	-0.550624472554773092	0.608788561541587114	-0.477692046202719212	
+0.355168055277317762	-0.663885291200131178	-0.578607434406876564	0.948888262268155813	
+0.0751642072573304176	-0.637551446910947561	0.597350681200623512	0.465034858789294958	
+0.695156253408640623	-0.535273394081741571	-0.482424828689545393	0.325693489052355289	
+
+out(0,0) = 
+0.571326846722513437	0.948888262268155813	
+0.695156253408640623	0.597350681200623512	
+
+argmax(0,0) = 
+0	5	
+4	0	
+
+in_grad(0,0) = 
+1	0	0	0	
+0	0	0	1	
+0	0	1	0	
+1	0	0	0	
+
+in(0,0) = 
+0.571326846722513437	-0.550624472554773092	0.608788561541587114	-0.477692046202719212	0.355168055277317762	-0.663885291200131178	
+-0.578607434406876564	0.948888262268155813	0.0751642072573304176	-0.637551446910947561	0.597350681200623512	0.465034858789294958	
+0.695156253408640623	-0.535273394081741571	-0.482424828689545393	0.325693489052355289	0.339111538603901863	-0.367646996397525072	
+-0.950825333595275879	0.0142417014576494694	0.313384936191141605	-0.130194013472646475	0.589585374109447002	-0.635994510259479284	
+
+out(0,0) = 
+0.948888262268155813	0.608788561541587114	0.597350681200623512	
+0.695156253408640623	0.325693489052355289	0.589585374109447002	
+
+argmax(0,0) = 
+7	0	6	
+0	1	6	
+
+in_grad(0,0) = 
+0	0	1	0	0	0	
+0	1	0	0	1	0	
+1	0	0	1	0	0	
+0	0	0	0	1	0	
+
+in(0,0) = 
+0.571326846722513437	-0.550624472554773092	0.608788561541587114	-0.477692046202719212	0.355168055277317762	-0.663885291200131178	
+-0.578607434406876564	0.948888262268155813	0.0751642072573304176	-0.637551446910947561	0.597350681200623512	0.465034858789294958	
+0.695156253408640623	-0.535273394081741571	-0.482424828689545393	0.325693489052355289	0.339111538603901863	-0.367646996397525072	
+-0.950825333595275879	0.0142417014576494694	0.313384936191141605	-0.130194013472646475	0.589585374109447002	-0.635994510259479284	
+
+out(0,0) = 
+0.948888262268155813	0.597350681200623512	
+0.695156253408640623	0.589585374109447002	
+
+argmax(0,0) = 
+7	7	
+0	7	
+
+in_grad(0,0) = 
+0	0	0	0	0	0	
+0	1	0	0	1	0	
+1	0	0	0	0	0	
+0	0	0	0	1	0	
+
+in(0,1) = 
+-0.956723117269575596	-0.271381198428571224	0.015802550595253706	0.228985379450023174	0.244860945269465446	0.291733738034963608	
+-0.384619461838155985	-0.53015851741656661	-0.204196315724402666	-0.212734253145754337	0.686032896395772696	0.443961090873926878	
+-0.590117036364972591	-0.3476050547324121	-0.681061949580907822	0.823367457371205091	-0.821575027424842119	0.0181499738246202469	
+-0.0198183669708669186	0.515492677222937346	-0.548446270637214184	-0.216243199538439512	-0.638110734988003969	-0.0777672920376062393	
+
+out(0,1) = 
+0.015802550595253706	0.686032896395772696	
+0.515492677222937346	0.823367457371205091	
+
+argmax(0,1) = 
+2	7	
+7	0	
+
+in_grad(0,1) = 
+0	0	1	0	0	0	
+0	0	0	0	1	0	
+0	0	0	1	0	0	
+0	1	0	0	0	0	
+
+in(1,0) = 
+0.646286267787218094	0.512002706527709961	0.376393313985317945	0.754204463679343462	0.696149583440274	-0.217543072532862425	
+-0.549941702280193567	0.56771835358813405	-0.817558882758021355	0.865787100978195667	0.128220072947442532	-0.740110177546739578	
+0.0536648905836045742	-0.258133819792419672	0.906170420348644257	0.91196447191759944	-0.51761457696557045	0.0407517999410629272	
+-0.925520627293735743	0.0505637023597955704	-0.709694980643689632	0.982084857765585184	-0.976217687595635653	0.423902397975325584	
+
+out(1,0) = 
+0.646286267787218094	0.865787100978195667	
+0.906170420348644257	0.982084857765585184	
+
+argmax(1,0) = 
+0	6	
+2	6	
+
+in_grad(1,0) = 
+1	0	0	0	0	0	
+0	0	0	1	0	0	
+0	0	1	0	0	0	
+0	0	0	1	0	0	
+
+in(1,1) = 
+-0.297947391401976347	0.806114098988473415	0.655256930738687515	0.475033317226916552	-0.441493467427790165	-0.164894609246402979	
+0.867289803922176361	0.695263925474137068	0.795250971335917711	-0.888961348216980696	-0.502931285183876753	-0.457339916843920946	
+0.746990945190191269	-0.764961786568164825	-0.31189091457054019	0.260067802388221025	-0.103939638938754797	0.154285140335559845	
+0.318781671114265919	0.178770334925502539	-0.00328331161290407181	0.0251420335844159126	0.851010150741785765	0.862215745262801647	
+
+out(1,1) = 
+0.867289803922176361	0.475033317226916552	
+0.746990945190191269	0.862215745262801647	
+
+argmax(1,1) = 
+6	0	
+0	8	
+
+in_grad(1,1) = 
+0	0	0	1	0	0	
+1	0	0	0	0	0	
+1	0	0	0	0	0	
+0	0	0	0	0	1	
+
+in(0,0) = 
+0.571326846722513437	-0.550624472554773092	0.608788561541587114	-0.477692046202719212	0.355168055277317762	-0.663885291200131178	-0.578607434406876564	0.948888262268155813	0.0751642072573304176	
+-0.637551446910947561	0.597350681200623512	0.465034858789294958	0.695156253408640623	-0.535273394081741571	-0.482424828689545393	0.325693489052355289	0.339111538603901863	-0.367646996397525072	
+-0.950825333595275879	0.0142417014576494694	0.313384936191141605	-0.130194013472646475	0.589585374109447002	-0.635994510259479284	-0.956723117269575596	-0.271381198428571224	0.015802550595253706	
+0.228985379450023174	0.244860945269465446	0.291733738034963608	-0.384619461838155985	-0.53015851741656661	-0.204196315724402666	-0.212734253145754337	0.686032896395772696	0.443961090873926878	
+-0.590117036364972591	-0.3476050547324121	-0.681061949580907822	0.823367457371205091	-0.821575027424842119	0.0181499738246202469	-0.0198183669708669186	0.515492677222937346	-0.548446270637214184	
+-0.216243199538439512	-0.638110734988003969	-0.0777672920376062393	0.646286267787218094	0.512002706527709961	0.376393313985317945	0.754204463679343462	0.696149583440274	-0.217543072532862425	
+-0.549941702280193567	0.56771835358813405	-0.817558882758021355	0.865787100978195667	0.128220072947442532	-0.740110177546739578	0.0536648905836045742	-0.258133819792419672	0.906170420348644257	
+0.91196447191759944	-0.51761457696557045	0.0407517999410629272	-0.925520627293735743	0.0505637023597955704	-0.709694980643689632	0.982084857765585184	-0.976217687595635653	0.423902397975325584	
+
+out(0,0) = 
+0.608788561541587114	0.695156253408640623	0.948888262268155813	
+0.313384936191141605	0.589585374109447002	0.686032896395772696	
+-0.0777672920376062393	0.823367457371205091	0.754204463679343462	
+0.91196447191759944	0.865787100978195667	0.982084857765585184	
+
+argmax(0,0) = 
+2	9	1	
+2	1	10	
+11	0	9	
+9	0	9	
+
+in_grad(0,0) = 
+0	0	1	0	0	0	0	1	0	
+0	0	0	1	0	0	0	0	0	
+0	0	1	0	1	0	0	0	0	
+0	0	0	0	0	0	0	1	0	
+0	0	0	1	0	0	0	0	0	
+0	0	1	0	0	0	1	0	0	
+0	0	0	1	0	0	0	0	0	
+1	0	0	0	0	0	1	0	0	
+
+in(0,1) = 
+-0.297947391401976347	0.806114098988473415	0.655256930738687515	0.475033317226916552	-0.441493467427790165	-0.164894609246402979	0.867289803922176361	0.695263925474137068	0.795250971335917711	
+-0.888961348216980696	-0.502931285183876753	-0.457339916843920946	0.746990945190191269	-0.764961786568164825	-0.31189091457054019	0.260067802388221025	-0.103939638938754797	0.154285140335559845	
+0.318781671114265919	0.178770334925502539	-0.00328331161290407181	0.0251420335844159126	0.851010150741785765	0.862215745262801647	0.830306585878133774	0.199107083957642317	-0.524740696419030428	
+-0.843397119548171759	0.227271720767021179	0.705192922614514828	-0.780793830286711454	-0.360368281602859497	-0.699946817476302385	0.37047756789252162	-0.0186068224720656872	-0.289045078679919243	
+0.529622823931276798	0.461395638063549995	-0.216189119033515453	0.56683295825496316	0.656894176732748747	0.414181752596050501	-0.728953968733549118	0.69680509902536869	-0.31371064018458128	
+0.0276385452598333359	0.599551916122436523	0.821352297440171242	-0.611164216883480549	0.0443695774301886559	0.268772690091282129	0.270312429405748844	-0.370683836285024881	-0.165102168917655945	
+0.778291610069572926	-0.879311913158744574	0.285094562452286482	0.479851304553449154	-0.461524561513215303	0.697461313102394342	0.813971135299652815	-0.507007838692516088	0.749897083733230829	
+-0.685909315012395382	0.63549605431035161	-0.876462335232645273	0.535131368786096573	0.785372436977922916	0.740887172054499388	-0.938765168655663729	0.535506801214069128	-0.543675530236214399	
+
+out(0,1) = 
+0.806114098988473415	0.746990945190191269	0.867289803922176361	
+0.705192922614514828	0.862215745262801647	0.830306585878133774	
+0.821352297440171242	0.656894176732748747	0.69680509902536869	
+0.778291610069572926	0.785372436977922916	0.813971135299652815	
+
+argmax(0,1) = 
+1	9	0	
+11	2	0	
+11	1	1	
+0	10	0	
+
+in_grad(0,1) = 
+0	1	0	0	0	0	1	0	0	
+0	0	0	1	0	0	0	0	0	
+0	0	0	0	0	1	1	0	0	
+0	0	1	0	0	0	0	0	0	
+0	0	0	0	1	0	0	1	0	
+0	0	1	0	0	0	0	0	0	
+1	0	0	0	0	0	1	0	0	
+0	0	0	0	1	0	0	0	0	
+
+in(1,0) = 
+-0.755344613920897245	-0.393051613122224808	-0.687121164985001087	-0.962993938475847244	-0.0955118830315768719	0.933977600652724504	-0.0370173612609505653	-0.976382689084857702	-0.154836560599505901	
+-0.243761579040437937	-0.279245186597108841	0.4250230947509408	-0.724119691643863916	-0.828008556738495827	-0.702050714753568172	0.201835400890558958	0.604263714514672756	0.333568504080176353	
+-0.75061694672331214	0.654334078077226877	0.271133680362254381	-0.0625479849986732006	-0.873768972232937813	0.391690145246684551	0.287336778827011585	-0.466696632094681263	-0.929326991084963083	
+-0.515656690113246441	0.557777666952461004	-0.0345322093926370144	0.669763568323105574	0.214102389290928841	-0.0652437200769782066	-0.847295900341123343	-0.202720282133668661	-0.963177159428596497	
+0.730358208995312452	-0.096455384511500597	0.106090763583779335	0.687722341623157263	-0.64360488299280405	-0.312377617694437504	-0.0190618583001196384	0.0452512013725936413	0.0976039301604032516	
+-0.884401315823197365	-0.686241064686328173	0.636225741356611252	-0.517111004795879126	-0.0372242135927081108	-0.643954774364829063	-0.588138274848461151	-0.568130447994917631	-0.790880403947085142	
+0.264362832996994257	0.256328245159238577	0.561468489933758974	-0.252742551732808352	0.341283001471310854	0.630701709538698196	0.979142906609922647	-0.829384967684745789	0.040753544308245182	
+0.544261562172323465	0.0113788959570229053	-0.287360015325248241	0.23905809223651886	0.229240103624761105	-0.332921466324478388	0.874992931261658669	-0.716977030970156193	0.708054920192807913	
+
+out(1,0) = 
+0.4250230947509408	0.933977600652724504	0.604263714514672756	
+0.654334078077226877	0.669763568323105574	0.287336778827011585	
+0.730358208995312452	0.687722341623157263	0.0976039301604032516	
+0.561468489933758974	0.630701709538698196	0.979142906609922647	
+
+argmax(1,0) = 
+11	2	10	
+1	9	0	
+0	0	2	
+2	2	0	
+
+in_grad(1,0) = 
+0	0	0	0	0	1	0	0	0	
+0	0	1	0	0	0	0	1	0	
+0	1	0	0	0	0	1	0	0	
+0	0	0	1	0	0	0	0	0	
+1	0	0	1	0	0	0	0	1	
+0	0	0	0	0	0	0	0	0	
+0	0	1	0	0	1	1	0	0	
+0	0	0	0	0	0	0	0	0	
+
+in(1,1) = 
+-0.938628851436078548	-0.269241021014750004	-0.594286998268216848	0.299565569963306189	-0.143737125210464001	0.14594197366386652	-0.185718911234289408	-0.926968766842037439	-0.719217754900455475	
+-0.693857750855386257	0.281010459177196026	0.684511712286621332	-0.0396721218712627888	-0.354658268857747316	0.42193468427285552	-0.0400427663698792458	-0.104158622678369284	0.823569628410041332	
+0.72455522371456027	0.722601148299872875	0.0144090983085334301	0.849128606263548136	-0.913421934004873037	0.584830904379487038	-0.176237258594483137	-0.863306947983801365	-0.721231872215867043	
+-0.859459508210420609	0.448102036491036415	0.0816276348195970058	-0.981384512968361378	0.0615152348764240742	0.0769725046120584011	0.453298950102180243	0.267717594280838966	-0.740899860858917236	
+-0.743943261913955212	-0.334591051563620567	0.487573413178324699	-0.454338779207319021	-0.652354483027011156	-0.910603183787316084	0.468275381717830896	-0.720956706441938877	-0.713868721388280392	
+-0.539852520916610956	0.915742420125752687	0.683820731937885284	0.130990934558212757	0.0761357322335243225	0.233760896138846874	-0.509316393174231052	-0.0343938199803233147	0.767118279356509447	
+0.574448753148317337	-0.767061630263924599	0.581202478148043156	-0.910781679209321737	-0.625704724341630936	0.421665451023727655	0.183285312727093697	0.682652499061077833	-0.0801949761807918549	
+0.0250438465736806393	-0.402028783224523067	0.897043769247829914	0.61242325184866786	-0.934452060144394636	-0.647561328019946814	-0.753529454581439495	-0.153364272788167	-0.770104783121496439	
+
+out(1,1) = 
+0.684511712286621332	0.42193468427285552	0.823569628410041332	
+0.72455522371456027	0.849128606263548136	0.453298950102180243	
+0.915742420125752687	0.233760896138846874	0.767118279356509447	
+0.897043769247829914	0.61242325184866786	0.682652499061077833	
+
+argmax(1,1) = 
+11	11	11	
+0	0	9	
+10	11	11	
+11	9	1	
+
+in_grad(1,1) = 
+0	0	0	0	0	0	0	0	0	
+0	0	1	0	0	1	0	0	1	
+1	0	0	1	0	0	0	0	0	
+0	0	0	0	0	0	1	0	0	
+0	0	0	0	0	0	0	0	0	
+0	1	0	0	0	1	0	0	1	
+0	0	0	0	0	0	0	1	0	
+0	0	1	1	0	0	0	0	0	
+
+in(2,0) = 
+-0.890055653639137745	0.287453474011272192	-0.655440897680819035	0.905010147020220757	0.0537269017659127712	-0.110203962773084641	-0.909325978253036737	0.880283167120069265	-0.956694527994841337	
+0.887084122747182846	-0.813556892797350883	-0.696523032616823912	-0.654647601302713156	0.414035465102642775	-0.916271085385233164	-0.643515811767429113	-0.623071747832000256	0.146038418635725975	
+-0.112721335608512163	-0.512047830503433943	-0.0738867395557463169	0.0553026534616947174	0.753282325342297554	-0.0435635163448750973	-0.0955849355086684227	0.326459934003651142	-0.60305265337228775	
+0.89340380160138011	0.942606566939502954	0.597291520331054926	0.597525130491703749	-0.170118831563740969	-0.674715345725417137	0.468547443859279156	-0.282911969814449549	-0.68318235082551837	
+0.941749637946486473	-0.283705959096550941	0.395635352935642004	-0.200152359902858734	-0.00180571340024471283	-0.493696716148406267	0.790636275429278612	-0.0283253099769353867	-0.401146629825234413	
+0.690326664596796036	0.473645797930657864	-0.0512562091462314129	0.238830635324120522	0.622223143931478262	0.608401739038527012	0.405333616770803928	0.0490465234033763409	0.500435053836554289	
+-0.018231536727398634	0.415528562385588884	0.583769787102937698	0.0540795209817588329	-0.247392232064157724	-0.0299137481488287449	0.858878015074878931	0.593805938959121704	0.294548793695867062	
+0.884298227727413177	-0.59345990652218461	0.83607357507571578	0.553381056524813175	0.476989970542490482	-0.618070585653185844	0.39125065878033638	-0.520521380938589573	-0.160860335454344749	
+
+out(2,0) = 
+0.887084122747182846	0.905010147020220757	0.880283167120069265	
+0.942606566939502954	0.753282325342297554	0.468547443859279156	
+0.941749637946486473	0.622223143931478262	0.790636275429278612	
+0.884298227727413177	0.553381056524813175	0.858878015074878931	
+
+argmax(2,0) = 
+9	0	1	
+10	1	9	
+0	10	0	
+9	9	0	
+
+in_grad(2,0) = 
+0	0	0	1	0	0	0	1	0	
+1	0	0	0	0	0	0	0	0	
+0	0	0	0	1	0	0	0	0	
+0	1	0	0	0	0	1	0	0	
+1	0	0	0	0	0	1	0	0	
+0	0	0	0	1	0	0	0	0	
+0	0	0	0	0	0	1	0	0	
+1	0	0	1	0	0	0	0	0	
+
+in(2,1) = 
+-0.749015794135630131	-0.349699351936578751	-0.641539500560611486	0.0138297886587679386	0.063070767093449831	-0.947923564352095127	0.771255760453641415	-0.757229115813970566	0.926343504805117846	
+-0.364798226859420538	0.295570539776235819	-0.673065460752695799	-0.116214605513960123	0.530218476429581642	-0.719410167075693607	0.280772914178669453	-0.489925960544496775	0.55708160437643528	
+0.643587098922580481	0.254525111522525549	0.777592013590037823	-0.62061991123482585	-0.949346481822431087	0.133687897585332394	0.00695815123617649078	-0.0231872373260557652	0.15213604923337698	
+-0.363684321753680706	-0.582700469065457582	0.0718550635501742363	-0.368921313900500536	0.631066549569368362	0.325047091580927372	-0.719764448702335358	-0.197854017838835716	0.0476941680535674095	
+-0.702443660702556372	-0.858990040607750416	0.944962318055331707	-0.369296548888087273	0.452246352564543486	0.207664524205029011	-0.686109459958970547	0.353912363294512033	0.0435376213863492012	
+0.10044220881536603	0.684590333141386509	0.0322081302292644978	0.0578017150983214378	0.651162354741245508	-0.59985532658174634	0.105445236433297396	0.509505088906735182	0.186710843816399574	
+0.370430746581405401	-0.513987528625875711	-0.370630988851189613	-0.636249630246311426	0.844203201122581959	0.684649956412613392	-0.409037624020129442	-0.161302005406469107	0.241920999716967344	
+0.596968461759388447	-0.986156462226063013	-0.204723549541085958	-0.224706951063126326	0.26855435548350215	0.79631987027823925	-0.284639174584299326	0.0340899988077580929	0.046419195830821991	
+
+out(2,1) = 
+0.295570539776235819	0.530218476429581642	0.926343504805117846	
+0.777592013590037823	0.631066549569368362	0.15213604923337698	
+0.944962318055331707	0.651162354741245508	0.509505088906735182	
+0.596968461759388447	0.844203201122581959	0.241920999716967344	
+
+argmax(2,1) = 
+10	10	2	
+2	10	2	
+2	10	10	
+9	1	2	
+
+in_grad(2,1) = 
+0	0	0	0	0	0	0	0	1	
+0	1	0	0	1	0	0	0	0	
+0	0	1	0	0	0	0	0	1	
+0	0	0	0	1	0	0	0	0	
+0	0	1	0	0	0	0	0	0	
+0	0	0	0	1	0	0	1	0	
+0	0	0	0	1	0	0	0	1	
+1	0	0	0	0	0	0	0	0	
+

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_0.psave
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_0.psave	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_0.psave	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,31 @@
+*1 -&gt;MaxSubsamplingTest(
+batch_size = 1 ;
+n_input_images = 1 ;
+input_images_length = 1 ;
+input_images_width = 1 ;
+kernel_length = 1 ;
+kernel_width = 1 ;
+output_images_length = 1 ;
+output_images_width = 1 ;
+input_images_size = 1 ;
+output_images_size = 1 ;
+input_size = 1 ;
+output_size = 1 ;
+max_module = *2 -&gt;MaxSubsampling2DModule(
+n_input_images = 1 ;
+input_images_length = 1 ;
+input_images_width = 1 ;
+kernel_length = 1 ;
+kernel_width = 1 ;
+output_images_length = 1 ;
+output_images_width = 1 ;
+input_size = 1 ;
+output_size = 1 ;
+name = &quot;MaxSubsampling2DModule&quot; ;
+estimate_simpler_diag_hessian = 0 ;
+expdir = &quot;&quot; ;
+random_gen = *0 ;
+output_size = 1  )
+;
+save = 1 ;
+save_path = &quot;test_0.psave&quot;  )

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_1.psave
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_1.psave	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_1.psave	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,31 @@
+*1 -&gt;MaxSubsamplingTest(
+batch_size = 1 ;
+n_input_images = 1 ;
+input_images_length = 2 ;
+input_images_width = 2 ;
+kernel_length = 2 ;
+kernel_width = 2 ;
+output_images_length = 1 ;
+output_images_width = 1 ;
+input_images_size = 4 ;
+output_images_size = 1 ;
+input_size = 4 ;
+output_size = 1 ;
+max_module = *2 -&gt;MaxSubsampling2DModule(
+n_input_images = 1 ;
+input_images_length = 2 ;
+input_images_width = 2 ;
+kernel_length = 2 ;
+kernel_width = 2 ;
+output_images_length = 1 ;
+output_images_width = 1 ;
+input_size = 4 ;
+output_size = 1 ;
+name = &quot;MaxSubsampling2DModule&quot; ;
+estimate_simpler_diag_hessian = 0 ;
+expdir = &quot;&quot; ;
+random_gen = *0 ;
+output_size = 1  )
+;
+save = 1 ;
+save_path = &quot;test_1.psave&quot;  )

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_2.psave
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_2.psave	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_2.psave	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,31 @@
+*1 -&gt;MaxSubsamplingTest(
+batch_size = 1 ;
+n_input_images = 1 ;
+input_images_length = 4 ;
+input_images_width = 4 ;
+kernel_length = 2 ;
+kernel_width = 2 ;
+output_images_length = 2 ;
+output_images_width = 2 ;
+input_images_size = 16 ;
+output_images_size = 4 ;
+input_size = 16 ;
+output_size = 4 ;
+max_module = *2 -&gt;MaxSubsampling2DModule(
+n_input_images = 1 ;
+input_images_length = 4 ;
+input_images_width = 4 ;
+kernel_length = 2 ;
+kernel_width = 2 ;
+output_images_length = 2 ;
+output_images_width = 2 ;
+input_size = 16 ;
+output_size = 4 ;
+name = &quot;MaxSubsampling2DModule&quot; ;
+estimate_simpler_diag_hessian = 0 ;
+expdir = &quot;&quot; ;
+random_gen = *0 ;
+output_size = 4  )
+;
+save = 1 ;
+save_path = &quot;test_2.psave&quot;  )

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_3.psave
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_3.psave	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_3.psave	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,31 @@
+*1 -&gt;MaxSubsamplingTest(
+batch_size = 1 ;
+n_input_images = 1 ;
+input_images_length = 4 ;
+input_images_width = 6 ;
+kernel_length = 2 ;
+kernel_width = 2 ;
+output_images_length = 2 ;
+output_images_width = 3 ;
+input_images_size = 24 ;
+output_images_size = 6 ;
+input_size = 24 ;
+output_size = 6 ;
+max_module = *2 -&gt;MaxSubsampling2DModule(
+n_input_images = 1 ;
+input_images_length = 4 ;
+input_images_width = 6 ;
+kernel_length = 2 ;
+kernel_width = 2 ;
+output_images_length = 2 ;
+output_images_width = 3 ;
+input_size = 24 ;
+output_size = 6 ;
+name = &quot;MaxSubsampling2DModule&quot; ;
+estimate_simpler_diag_hessian = 0 ;
+expdir = &quot;&quot; ;
+random_gen = *0 ;
+output_size = 6  )
+;
+save = 1 ;
+save_path = &quot;test_3.psave&quot;  )

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_4.psave
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_4.psave	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_4.psave	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,31 @@
+*1 -&gt;MaxSubsamplingTest(
+batch_size = 2 ;
+n_input_images = 2 ;
+input_images_length = 4 ;
+input_images_width = 6 ;
+kernel_length = 2 ;
+kernel_width = 3 ;
+output_images_length = 2 ;
+output_images_width = 2 ;
+input_images_size = 24 ;
+output_images_size = 4 ;
+input_size = 48 ;
+output_size = 8 ;
+max_module = *2 -&gt;MaxSubsampling2DModule(
+n_input_images = 2 ;
+input_images_length = 4 ;
+input_images_width = 6 ;
+kernel_length = 2 ;
+kernel_width = 3 ;
+output_images_length = 2 ;
+output_images_width = 2 ;
+input_size = 48 ;
+output_size = 8 ;
+name = &quot;MaxSubsampling2DModule&quot; ;
+estimate_simpler_diag_hessian = 0 ;
+expdir = &quot;&quot; ;
+random_gen = *0 ;
+output_size = 8  )
+;
+save = 1 ;
+save_path = &quot;test_4.psave&quot;  )

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_5.psave
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_5.psave	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/.pytest/PL_max_subsampling/expected_results/test_5.psave	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,31 @@
+*1 -&gt;MaxSubsamplingTest(
+batch_size = 3 ;
+n_input_images = 2 ;
+input_images_length = 8 ;
+input_images_width = 9 ;
+kernel_length = 2 ;
+kernel_width = 3 ;
+output_images_length = 4 ;
+output_images_width = 3 ;
+input_images_size = 72 ;
+output_images_size = 12 ;
+input_size = 144 ;
+output_size = 24 ;
+max_module = *2 -&gt;MaxSubsampling2DModule(
+n_input_images = 2 ;
+input_images_length = 8 ;
+input_images_width = 9 ;
+kernel_length = 2 ;
+kernel_width = 3 ;
+output_images_length = 4 ;
+output_images_width = 3 ;
+input_size = 144 ;
+output_size = 24 ;
+name = &quot;MaxSubsampling2DModule&quot; ;
+estimate_simpler_diag_hessian = 0 ;
+expdir = &quot;&quot; ;
+random_gen = *0 ;
+output_size = 24  )
+;
+save = 1 ;
+save_path = &quot;test_5.psave&quot;  )

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.cc
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.cc	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.cc	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,270 @@
+// -*- C++ -*-
+
+// MaxSubsamplingTest.cc
+//
+// Copyright (C) 2007 Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Lamblin
+
+/*! \file MaxSubsamplingTest.cc */
+
+
+#include &quot;MaxSubsamplingTest.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    MaxSubsamplingTest,
+    &quot;Tests MaxSubsampling2DModule&quot;,
+    &quot;&quot;
+);
+
+//////////////////
+// MaxSubsamplingTest //
+//////////////////
+MaxSubsamplingTest::MaxSubsamplingTest()
+{
+}
+
+///////////
+// build //
+///////////
+void MaxSubsamplingTest::build()
+{
+    inherited::build();
+    build_();
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void MaxSubsamplingTest::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField(max_module, copies);
+    deepCopyField(random_gen, copies);
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void MaxSubsamplingTest::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;batch_size&quot;, &amp;MaxSubsamplingTest::batch_size,
+                  OptionBase::buildoption,
+                  &quot;Size of batch&quot;);
+
+    declareOption(ol, &quot;n_input_images&quot;, &amp;MaxSubsamplingTest::n_input_images,
+                  OptionBase::buildoption,
+                  &quot;Number of images in each input vector&quot;);
+
+    declareOption(ol, &quot;input_images_length&quot;,
+                  &amp;MaxSubsamplingTest::input_images_length,
+                  OptionBase::buildoption,
+                  &quot;Length of input images&quot;);
+
+    declareOption(ol, &quot;input_images_width&quot;,
+                  &amp;MaxSubsamplingTest::input_images_width,
+                  OptionBase::buildoption,
+                  &quot;Width of input images&quot;);
+
+    declareOption(ol, &quot;kernel_length&quot;, &amp;MaxSubsamplingTest::kernel_length,
+                  OptionBase::buildoption,
+                  &quot;Length of the subsampling zone&quot;);
+
+    declareOption(ol, &quot;kernel_width&quot;, &amp;MaxSubsamplingTest::kernel_width,
+                  OptionBase::buildoption,
+                  &quot;Width of the subsampling zone&quot;);
+
+    declareOption(ol, &quot;output_images_length&quot;,
+                  &amp;MaxSubsamplingTest::output_images_length,
+                  OptionBase::learntoption,
+                  &quot;Length of output images&quot;);
+
+    declareOption(ol, &quot;output_images_width&quot;,
+                  &amp;MaxSubsamplingTest::output_images_width,
+                  OptionBase::learntoption,
+                  &quot;Width of output images&quot;);
+
+    declareOption(ol, &quot;input_images_size&quot;,
+                  &amp;MaxSubsamplingTest::input_images_size,
+                  OptionBase::learntoption,
+                  &quot;input_images_length*input_images_width&quot;);
+
+    declareOption(ol, &quot;output_images_size&quot;,
+                  &amp;MaxSubsamplingTest::output_images_size,
+                  OptionBase::learntoption,
+                  &quot;output_images_length*output_images_width&quot;);
+
+    declareOption(ol, &quot;input_size&quot;,
+                  &amp;MaxSubsamplingTest::input_size,
+                  OptionBase::learntoption,
+                  &quot;n_input_images*input_images_size&quot;);
+
+    declareOption(ol, &quot;output_size&quot;,
+                  &amp;MaxSubsamplingTest::output_size,
+                  OptionBase::learntoption,
+                  &quot;n_input_images*output_images_size&quot;);
+
+    declareOption(ol, &quot;max_module&quot;, &amp;MaxSubsamplingTest::max_module,
+                  OptionBase::learntoption,
+                  &quot;The MaxSubsampling2DModule we build and test&quot;);
+    /*
+    declareOption(ol, &quot;&quot;, &amp;MaxSubsamplingTest::,
+                  OptionBase::buildoption,
+                  &quot;&quot;);
+    */
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+////////////
+// build_ //
+////////////
+void MaxSubsamplingTest::build_()
+{
+    PLCHECK( input_images_length % kernel_length == 0 );
+    PLCHECK( input_images_width % kernel_width == 0 );
+
+    output_images_length = input_images_length / kernel_length;
+    output_images_width = input_images_width / kernel_width;
+
+    input_images_size = input_images_length * input_images_width;
+    output_images_size = output_images_length * output_images_width;
+
+    input_size = n_input_images * input_images_size;
+    output_size = n_input_images * output_images_size;
+
+    if( !max_module )
+    {
+        max_module = new MaxSubsampling2DModule();
+        max_module-&gt;n_input_images = n_input_images;
+        max_module-&gt;input_images_length = input_images_length;
+        max_module-&gt;input_images_width = input_images_width;
+        max_module-&gt;kernel_length = kernel_length;
+        max_module-&gt;kernel_width = kernel_width;
+        max_module-&gt;build();
+    }
+
+    if (!random_gen)
+        random_gen = new PRandom();
+    random_gen-&gt;manual_seed(42);
+}
+
+/////////////
+// perform //
+/////////////
+void MaxSubsamplingTest::perform()
+{
+    Mat in_(batch_size, input_size);
+    Mat out_(batch_size, output_size);
+    Mat argmax_(batch_size, output_size);
+
+    TMat&lt;Mat&gt; in(batch_size, n_input_images);
+    TMat&lt;Mat&gt; out(batch_size, n_input_images);
+    TMat&lt;Mat&gt; argmax(batch_size, n_input_images);
+
+    for( int k=0; k&lt;batch_size; k++ )
+        for( int i=0; i&lt;n_input_images; i++ )
+        {
+            in(k,i) = in_(k).subVec(i*input_images_size, input_images_size)
+                .toMat(input_images_length, input_images_width);
+            random_gen-&gt;fill_random_uniform(in(k,i), -1, 1);
+
+            out(k,i) = out_(k)
+                .subVec(i*output_images_size, output_images_size)
+                .toMat(output_images_length, output_images_width);
+
+            argmax(k,i) = argmax_(k)
+                .subVec( i*output_images_size, output_images_size)
+                .toMat(output_images_length, output_images_width);
+        }
+
+    TVec&lt;Mat*&gt; ports_values(3);
+    ports_values[0] = &amp;in_;
+    ports_values[1] = &amp;out_;
+    ports_values[2] = &amp;argmax_;
+
+    out_.resize(0, output_size);
+    argmax_.resize(0, output_size);
+    max_module-&gt;fprop(ports_values);
+
+
+    Mat out_grad_(batch_size, output_size, 1.);
+    Mat in_grad_(batch_size, input_size);
+    TMat&lt;Mat&gt; in_grad(batch_size, n_input_images);
+
+    for( int k=0; k&lt;batch_size; k++ )
+        for( int i=0; i&lt;n_input_images; i++ )
+        {
+            in_grad(k,i) = in_grad_(k)
+                .subVec(i*input_images_size, input_images_size)
+                .toMat(input_images_length, input_images_width);
+        }
+
+    TVec&lt;Mat*&gt; ports_grad(3);
+    ports_grad[0] = &amp;in_grad_;
+    ports_grad[1] = &amp;out_grad_;
+    ports_grad[2] = NULL;
+
+    in_grad_.resize(0, input_size);
+    max_module-&gt;bpropAccUpdate( ports_values, ports_grad );
+
+    for( int k=0; k&lt;batch_size; k++ )
+        for( int i=0; i&lt;n_input_images; i++ )
+        {
+            pout &lt;&lt; &quot;in(&quot;&lt;&lt;k&lt;&lt;&quot;,&quot;&lt;&lt;i&lt;&lt;&quot;) = &quot; &lt;&lt; endl &lt;&lt; in(k,i) &lt;&lt; endl;
+            pout &lt;&lt; &quot;out(&quot;&lt;&lt;k&lt;&lt;&quot;,&quot;&lt;&lt;i&lt;&lt;&quot;) = &quot; &lt;&lt; endl &lt;&lt; out(k,i) &lt;&lt; endl;
+            pout &lt;&lt; &quot;argmax(&quot;&lt;&lt;k&lt;&lt;&quot;,&quot;&lt;&lt;i&lt;&lt;&quot;) = &quot; &lt;&lt; endl
+                &lt;&lt; argmax(k,i) &lt;&lt; endl;
+            pout &lt;&lt; &quot;in_grad(&quot;&lt;&lt;k&lt;&lt;&quot;,&quot;&lt;&lt;i&lt;&lt;&quot;) = &quot; &lt;&lt; endl
+                &lt;&lt; in_grad(k,i) &lt;&lt; endl;
+        }
+
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.h
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.h	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/MaxSubsamplingTest.h	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,153 @@
+// -*- C++ -*-
+
+// MaxSubsamplingTest.h
+//
+// Copyright (C) 2007 Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Pascal Lamblin
+
+/*! \file MaxSubsamplingTest.h */
+
+
+#ifndef MaxSubsamplingTest_INC
+#define MaxSubsamplingTest_INC
+
+#include &lt;plearn/misc/PTest.h&gt;
+#include &lt;plearn/math/PRandom.h&gt;
+#include &lt;plearn_learners/online/MaxSubsampling2DModule.h&gt;
+
+namespace PLearn {
+
+/**
+ * Tests MaxSubsampling2DModule.
+ */
+class MaxSubsamplingTest : public PTest
+{
+    typedef PTest inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    // ### declare public option fields (such as build options) here
+    // Start your comments with Doxygen-compatible comments such as //!
+    // ### Typically, a PTest options are used to store the test results.
+
+    int batch_size;
+    int n_input_images;
+    int input_images_length;
+    int input_images_width;
+    int kernel_length;
+    int kernel_width;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    MaxSubsamplingTest();
+
+    // Your other public member functions go here
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(MaxSubsamplingTest);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+    //#####  PLearn::PTest Protocol  ##########################################
+
+    //! The method performing the test. A typical test consists in some output
+    //! (to pout and / or perr), and updates of this object's options.
+    virtual void perform();
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    int output_images_length;
+    int output_images_width;
+    int input_images_size;
+    int output_images_size;
+    int input_size;
+    int output_size;
+
+    PP&lt;MaxSubsampling2DModule&gt; max_module;
+    PP&lt;PRandom&gt; random_gen;
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(MaxSubsamplingTest);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/PL_max_subsampling.pyplearn
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/PL_max_subsampling.pyplearn	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/PL_max_subsampling.pyplearn	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,32 @@
+from plearn.pyplearn import *
+
+test_parameters = [
+    #(batch_size, n_input_images, ii_length, ii_width, k_length, k_width)
+    (1, 1, 1, 1, 1, 1),
+    (1, 1, 2, 2, 2, 2),
+    (1, 1, 4, 4, 2, 2),
+    (1, 1, 6, 4, 2, 2),
+    (2, 2, 6, 4, 3, 2),
+    (3, 2, 9, 8, 3, 2)
+    ]
+
+tests = [
+    pl.MaxSubsamplingTest(
+            batch_size = batch_size,
+            n_input_images = n_input_images,
+            input_images_width = input_images_width,
+            input_images_length = input_images_length,
+            kernel_length = kernel_length,
+            kernel_width = kernel_width,
+            save_path = 'test_' + str(i) + '.psave'
+            )
+    for (batch_size, n_input_images, input_images_width, input_images_length, \
+            kernel_width, kernel_length), i
+    in zip(test_parameters, range(len(test_parameters)))
+    ]
+
+def main():
+    return pl.RunObject(
+            objects = tests,
+            run_objects = True
+            )

Added: trunk/plearn_learners/online/test/MaxSubsampling2DModule/pytest.config
===================================================================
--- trunk/plearn_learners/online/test/MaxSubsampling2DModule/pytest.config	2007-05-23 15:08:43 UTC (rev 7259)
+++ trunk/plearn_learners/online/test/MaxSubsampling2DModule/pytest.config	2007-05-23 15:32:33 UTC (rev 7260)
@@ -0,0 +1,108 @@
+&quot;&quot;&quot;Pytest config file.
+
+Test is a class regrouping the elements that define a test for PyTest.
+    
+    For each Test instance you declare in a config file, a test will be ran
+    by PyTest.
+    
+      @ivar(name):
+    The name of the Test must uniquely determine the
+    test. Among others, it will be used to identify the test's results
+    (.PyTest/name/*_results/) and to report test informations.
+      @type(name):
+    String
+    
+      @ivar(description):
+    The description must provide other users an
+    insight of what exactly is the Test testing. You are encouraged
+    to used triple quoted strings for indented multi-lines
+    descriptions.
+      @type(description):
+    String
+    
+      @ivar(category):
+    The category to which this test belongs. By default, a
+    test is considered a 'General' test.
+    
+    It is not desirable to let an extensive and lengthy test as 'General',
+    while one shall refrain abusive use of categories since it is likely
+    that only 'General' tests will be ran before most commits...
+    
+      @type(category):
+    string
+    
+      @ivar(program):
+    The program to be run by the Test. The program's name
+    PRGNAME is used to lookup for the program in the following manner:
+    
+    1) Look for a local program named PRGNAME
+    2) Look for a plearn-like command (plearn, plearn_tests, ...) named 
+PRGNAME
+    3) Call 'which PRGNAME'
+    4) Fail
+    
+    Compilable program should provide the keyword argument 'compiler'
+    mapping to a string interpreted as the compiler name (e.g.
+    &quot;compiler = 'pymake'&quot;). If no compiler is provided while the program is
+    believed to be compilable, 'pymake' will be assigned by
+    default. Arguments to be forwarded to the compiler can be provided as a
+    string through the 'compile_options' keyword argument. @type program:
+    Program
+    
+      @ivar(arguments):
+    The command line arguments to be passed to the program
+    for the test to proceed.
+      @type(arguments):
+    String
+    
+      @ivar(resources):
+    A list of resources that are used by your program
+    either in the command line or directly in the code (plearn or pyplearn
+    files, databases, ...). The elements of the list must be string
+    representations of the path, absolute or relative, to the resource.
+      @type(resources):
+    List of Strings
+    
+      @ivar(precision):
+    The precision (absolute and relative) used when comparing
+    floating numbers in the test output (default = 1e-6)
+      @type(precision):
+    float
+    
+      @ivar(pfileprg):
+    The program to be used for comparing files of psave &amp;
+    vmat formats. It can be either:
+      - &quot;__program__&quot;: maps to this test's program if its compilable;
+    maps to 'plearn_tests' otherwise (default);
+      - &quot;__plearn__&quot;: always maps to 'plearn_tests' (for when the program
+    under test is not a version of PLearn);
+      - A Program (see 'program' option) instance
+      - None: if you are sure no files are to be compared.
+    
+      @ivar(ignored_files_re):
+    Default behaviour of a test is to compare all
+    files created by running the test. In some case, one may prefer some of
+    these files to be ignored.
+      @type(ignored_files_re):
+    list of regular expressions
+    
+      @ivar(disabled):
+    If true, the test will not be ran.
+      @type(disabled):
+    bool
+    
+&quot;&quot;&quot;
+Test(
+    name = &quot;PL_max_subsampling&quot;,
+    description = &quot;MaxSubsampling2DModule&quot;,
+    category = &quot;General&quot;,
+    program = Program(
+        name = &quot;plearn_tests&quot;,
+        compiler = &quot;pymake&quot;
+        ),
+    arguments = &quot;PL_max_subsampling.pyplearn&quot;,
+    resources = [ &quot;PL_max_subsampling.pyplearn&quot; ],
+    precision = 1e-06,
+    pfileprg = &quot;__program__&quot;,
+    disabled = False
+    )


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000708.html">[Plearn-commits] r7259 - in trunk: plearn/var/EXPERIMENTAL	plearn_learners/generic/EXPERIMENTAL python_modules/plearn/var
</A></li>
	<LI>Next message: <A HREF="000710.html">[Plearn-commits] r7261 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#709">[ date ]</a>
              <a href="thread.html#709">[ thread ]</a>
              <a href="subject.html#709">[ subject ]</a>
              <a href="author.html#709">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
