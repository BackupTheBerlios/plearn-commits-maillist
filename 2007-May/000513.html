<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7064 - in trunk: plearn/var	plearn/var/EXPERIMENTAL python_modules/plearn/var
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7064%20-%20in%20trunk%3A%20plearn/var%0A%09plearn/var/EXPERIMENTAL%20python_modules/plearn/var&In-Reply-To=%3C200705111803.l4BI3lqH019822%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000512.html">
   <LINK REL="Next"  HREF="000514.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7064 - in trunk: plearn/var	plearn/var/EXPERIMENTAL python_modules/plearn/var</H1>
    <B>simonl at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7064%20-%20in%20trunk%3A%20plearn/var%0A%09plearn/var/EXPERIMENTAL%20python_modules/plearn/var&In-Reply-To=%3C200705111803.l4BI3lqH019822%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7064 - in trunk: plearn/var	plearn/var/EXPERIMENTAL python_modules/plearn/var">simonl at mail.berlios.de
       </A><BR>
    <I>Fri May 11 20:03:47 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000512.html">[Plearn-commits] r7063 - trunk/python_modules/plearn/pyplearn
</A></li>
        <LI>Next message: <A HREF="000514.html">[Plearn-commits] r7065 - trunk/scripts
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#513">[ date ]</a>
              <a href="thread.html#513">[ thread ]</a>
              <a href="subject.html#513">[ subject ]</a>
              <a href="author.html#513">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: simonl
Date: 2007-05-11 20:03:46 +0200 (Fri, 11 May 2007)
New Revision: 7064

Modified:
   trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc
   trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h
   trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc
   trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.h
   trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc
   trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h
   trunk/plearn/var/SourceVariable.cc
   trunk/plearn/var/SourceVariable.h
   trunk/python_modules/plearn/var/Var.py
Log:
Improved experimental var stuff


Modified: trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc	2007-05-11 18:03:46 UTC (rev 7064)
@@ -2,7 +2,7 @@
 
 // DoubleProductVariable.cc
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file DoubleProductVariable.cc */
 

Modified: trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h	2007-05-11 18:03:46 UTC (rev 7064)
@@ -2,7 +2,7 @@
 
 // DoubleProductVariable.h
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file DoubleProductVariable.h */
 

Modified: trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc	2007-05-11 18:03:46 UTC (rev 7064)
@@ -2,7 +2,7 @@
 
 // MultiMaxVariable.cc
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file MultiMaxVariable.cc */
 
@@ -51,49 +51,31 @@
     );
 
 
-// constructor from input variable and parameters
+//! Constructor
 MultiMaxVariable::MultiMaxVariable(Variable* input, TVec&lt;int&gt; groupsizes, char computation_type)
-// ### replace with actual parameters
     : inherited(input, input-&gt;length(), input-&gt;width()),
       groupsizes(groupsizes),
       computation_type(computation_type)
-
-//    parameter(the_parameter),
-//    ...
 {
-//TODO : enlever les deux lignes suivantes
-//     this-&gt;groupsizes = groupsizes;
-//     this-&gt;computation_type = computation_type;
+    build_();
+}
 
-   // ### You may (or not) want to call build_() to finish building the
-   // ### object
 
-    int sum =0;
-    for(int i=0; i&lt;groupsizes.length(); i++)
-        sum += groupsizes[i];
 
-    if(sum != input-&gt;width())
-        PLERROR(&quot;invalid groupsizes in MultiMaxVariable&quot;);
-}
 
-
-MultiMaxVariable::MultiMaxVariable(Variable* input, int groupsizes, char computation_type)
+MultiMaxVariable::MultiMaxVariable(Variable* input, int groupsize, char computation_type)
     : inherited(input, input-&gt;length(), input-&gt;width()),
-      computation_type(computation_type)
+      computation_type(computation_type),
+      groupsize(groupsize)
 {
-    if(input-&gt;width()%groupsizes !=0)
-        PLERROR(&quot;invalid groupsizes in MultiMaxVariable&quot;);    
-
-    TVec&lt;int&gt; vec(input-&gt;width()/groupsizes, groupsizes);
-    this-&gt;groupsizes = vec;
+    build_();
 }
 
 void MultiMaxVariable::recomputeSize(int&amp; l, int&amp; w) const
 {
-    // ### usual code to put here is:
         if (input) {
-            l = input-&gt;length(); // the computed length of this Var
-            w = input-&gt;width() ; // the computed width
+            l = input-&gt;length();
+            w = input-&gt;width() ;
         } else
             l = w = 0;
 }
@@ -251,6 +233,10 @@
                   OptionBase::buildoption,
                   &quot;this telles how to \&quot;divide\&quot; our diffrents inputs\nex: groupsizes = [1,2,3] says we divide our output like this :\n[x1],[x2,x3],[x4,x5,x6] and apply a maximum algorithm on each group separately&quot;);
 
+    declareOption(ol, &quot;groupsize&quot;, &amp;MultiMaxVariable::groupsize,
+                  OptionBase::buildoption,
+                  &quot;&quot;);
+
     declareOption(ol, &quot;computation_type&quot;, &amp;MultiMaxVariable::computation_type,
                   OptionBase::buildoption,
                   &quot;specifies what maximum algorithm should be used on our groups\n\'S\' = Softmax\n\'L\' = Log(Softmax)\n\'H\' = Hardmax*value\n\'h\' = hardmax\n\'R\' = random_Softmax*value\n\'r\' = random_Softmax&quot;);
@@ -271,14 +257,32 @@
     // ###    options have been modified.
     // ### You should assume that the parent class' build_() has already been
     // ### called.
+    
+    if (groupsizes.length() &lt;= 0)
+    {
+        if (groupsize &lt;= 0)
+            PLERROR(&quot;Groupsize(s) not specified or invalid in MultiMaxVariable&quot;);    
+        if (input-&gt;width() % groupsize != 0)
+            PLERROR(&quot;Invalid groupsize in MultiMaxVariable&quot;);
+
+        TVec&lt;int&gt; vec(input-&gt;width()/groupsize, groupsize);
+        groupsizes = vec;
+    }
+    else
+    {
+        int sum = 0;
+        for(int i=0; i&lt;groupsizes.length(); i++)
+            sum += groupsizes[i];       
+        if(sum != input-&gt;width())
+            PLERROR(&quot;Invalid groupsizes in MultiMaxVariable&quot;);    
+    }
 }
 
+
 ////////////////
 // some utils //
 ////////////////
 
-
-
 void MultiMaxVariable::softmax_range(Vec &amp;x, Vec &amp;y, int start, int length)
 {
     real somme=0;

Modified: trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.h	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.h	2007-05-11 18:03:46 UTC (rev 7064)
@@ -2,7 +2,7 @@
 
 // MultiMaxVariable.h
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file MultiMaxVariable.h */
 
@@ -48,10 +48,15 @@
 /*! * MultiMaxVariable * */
 
 /**
- * The first sentence should be a BRIEF DESCRIPTION of what the class does.
- * Place the rest of the class programmer documentation here.  Doxygen supports
- * Javadoc-style comments.  See <A HREF="http://www.doxygen.org/manual.html">http://www.doxygen.org/manual.html</A>
+ * This variables computes a max functions (softmax, log-softmax, hardmax, etc., determined by the field computation_type) 
+ * on subvectors of the input, which lenght is defined by the field groupsizes.
+ * 
+ * ex :
+ * if groupsizes = [1,2,3], and computation_type = 'S' (for softmax), and the input vector [1,2,3,4,5,6],
+ * the result will be [softmax([1]), softmax([2,3]), softmax([4,5,6])]
  *
+ *  note : in that example matValue.width() of the variable must be 1+2+3=6
+ * 
  * @todo Write class to-do's here if there are any.
  *
  * @deprecated Write deprecated stuff here if there is any.  Indicate what else
@@ -72,18 +77,16 @@
 // les sizes ont du sens... ou sinon valider qqpart ailleurs que la somme des
 // groupsize's donne bien le width de la variable
     TVec&lt;int&gt; groupsizes;
-    /*computation type :
-      'H' = ...
-      'h' = ...
-      ...
-    */
     char computation_type;
+    int groupsize;
+
 public:
     //#####  Public Member Functions  #########################################
 
     //! Default constructor, usually does nothing
     MultiMaxVariable()
-        :computation_type('S') 
+        :computation_type('S'),
+         groupsize(-1)
     {}
 
 

Modified: trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc	2007-05-11 18:03:46 UTC (rev 7064)
@@ -2,7 +2,7 @@
 
 // TransposedDoubleProductVariable.cc
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file TransposedDoubleProductVariable.cc */
 

Modified: trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h	2007-05-11 18:03:46 UTC (rev 7064)
@@ -2,7 +2,7 @@
 
 // TransposedDoubleProductVariable.h
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file TransposedDoubleProductVariable.h */
 

Modified: trunk/plearn/var/SourceVariable.cc
===================================================================
--- trunk/plearn/var/SourceVariable.cc	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/SourceVariable.cc	2007-05-11 18:03:46 UTC (rev 7064)
@@ -54,17 +54,55 @@
 );
 
 SourceVariable::SourceVariable(int thelength, int thewidth)
-    : inherited(thelength,thewidth)
+    : inherited(thelength,thewidth),
+      build_length(thelength),
+      build_width(thewidth)
 {}
 
 SourceVariable::SourceVariable(const Vec&amp; v, bool vertical)
     : inherited(vertical ?v.toMat(v.length(),1) :v.toMat(1,v.length()))
-{}
+{
+    build_length = length();
+    build_width = width();
+}
 
 SourceVariable::SourceVariable(const Mat&amp; m)
-    : inherited(m)
+    : inherited(m),
+      build_length(m.length()),
+      build_width(m.width())
 {}
 
+void SourceVariable::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;build_length&quot;, &amp;SourceVariable::build_length, OptionBase::buildoption, 
+                  &quot;The initial length for the variable&quot;);
+
+    declareOption(ol, &quot;build_width&quot;, &amp;SourceVariable::build_width, OptionBase::buildoption, 
+                  &quot;The initial width for the variable&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+
+////////////
+// build_ //
+////////////
+void SourceVariable::build_()
+{ 
+    if(build_length&gt;0 &amp;&amp; build_width&gt;0)
+        resize(build_length, build_width);
+}
+
+///////////
+// build //
+///////////
+void SourceVariable::build()
+{
+    inherited::build();
+    build_();
+}
+
+
 void SourceVariable::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);

Modified: trunk/plearn/var/SourceVariable.h
===================================================================
--- trunk/plearn/var/SourceVariable.h	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/plearn/var/SourceVariable.h	2007-05-11 18:03:46 UTC (rev 7064)
@@ -53,8 +53,21 @@
     typedef Variable inherited;
 
 public:
+    // build options
+    int build_length;
+    int build_width;
+
+private:
+    void build_();
+public:
+    virtual void build();
+
+protected:
+    static void declareOptions(OptionList &amp; ol);
+
+public:
     //!  Default constructor for persistence
-    SourceVariable() {}
+    SourceVariable(): build_length(-1), build_width(-1) {}
     SourceVariable(int thelength, int thewidth);
     SourceVariable(const Vec&amp; v, bool vertical=true);
     SourceVariable(const Mat&amp; m);

Modified: trunk/python_modules/plearn/var/Var.py
===================================================================
--- trunk/python_modules/plearn/var/Var.py	2007-05-11 17:14:28 UTC (rev 7063)
+++ trunk/python_modules/plearn/var/Var.py	2007-05-11 18:03:46 UTC (rev 7064)
@@ -30,20 +30,58 @@
 ##
 ## Authors: Pascal Vincent
 
+from plearn.pyplearn import *
+from plearn.pyplearn.plearn_repr import plearn_repr, format_list_elements
 
 class Var:
 
-    def __init__(self, plvar):
-        self.v = plvar
+    def __init__(self, l, w=1):
+        if isinstance(l,int):
+            self.v = pl.SourceVariable(build_length=l,
+                                       build_width=w)
+        else: # assume parameter l is a pl. plvar
+            self.v = l
 
     def sigmoid(self):
         return Var(pl.SigmoidVariable(input=self.v))
 
+    def plearn_repr( self, indent_level=0, inner_repr=plearn_repr ):
+        # asking for plearn_repr could be to send specification over
+        # to another prg so that will open the .pmat
+        # So we make sure data is flushed to disk.
+        return self.v.plearn_repr(indent_level, inner_repr)
 
-def reconstructionCost(hidden, input, W):
-    return hidden.matrixTransposeProduct(W).dot(input).neg()
+    def probabilityPairs(self, min, max):
+        return Var(pl.ProbabilityPairsVariable(input=self.v, min=min, max=max))
 
+    def matrixProduct(self, W):
+        pass
+        # return Var(pl.MatrixProductVariable(self.v, W)
 
+    def doubleProduct(self, W, M):
+        return Var(pl.DoubleProductVariable(x=self.v, w=W, m=M))
+
+    def dot(self, input):
+        return Var(pl.DotProductVariable(input1=self, input2=input))
+
+    def multiMax(self, igs, computation_type):        
+        return Var(pl.MultiMaxVariable(input=self.v, groupsize=igs, computation_type=PLChar(computation_type)))
+
+    def multiSoftMax(self, igs):        
+        return self.multiMax(igs, 'S')
+
+    def multiLogSoftMax(self, igs):
+        return self.multiMax(igs, 'L')
+
+    def transposeDoubleProduct(self, W, M):
+        return Var(pl.TranposedDoubleProductVariable(w=W, m=M, h=self.v))
+
+    def __neg__(self):
+        return Var(pl.NegateElementsVariable(input=self.v))
+    
+    
+
+    
 # RLayer stands for reconstruciton hidden layer
 
 def addSigmoidRLayer(input, nh):
@@ -54,7 +92,7 @@
     cost = -hidden.matrixTransposeProduct(W).log_sigmoid().dot(input)
     return (hidden, cost, W)
 
-def addMultiSoftmaxRLayer(input, ing, igs, ong, ogs, tighed=true, use_double_product=false):
+def addMultiSoftmaxRLayer(input, ing, igs, ong, ogs, tighed=True, use_double_product=True):
     &quot;&quot;&quot;ing is the input's number of groups
     igs is the input's group size
     ong is the output's number of groups
@@ -65,54 +103,24 @@
     Returns a triple (hidden, params, reonstruction_cost)&quot;&quot;&quot;
     if not use_double_product:
         W = Var(ing*igs,ong*ogs)
-        hidden = input.matrixProduct(W).multiSoftMax(ong, ogs)
+        hidden = input.matrixProduct(W).multiSoftMax(ogs)
         if tighed:
-            cost = -hidden.matrixTransposeProduct(W).multiLogSoftMax(ing,igs).dot(input)
+            cost = -hidden.matrixTransposeProduct(W).multiLogSoftMax(igs).dot(input)
             return hidden, cost, W
         else:
             Wr = Var(ong*ogs, ing*igs)
-            cost = -hidden.matrixProduct(Wr).multiLogSoftMax(ing,igs)
+            cost = -hidden.matrixProduct(Wr).multiLogSoftMax(igs)
             return hidden, cost, (W, Wr)
 
     else: # use double product
         M = Var(ing*igs, ong)
         W = Var(ing*igs, ogs)
-        hidden = input.doubleProduct(W,M).multiSoftMax(ong, ogs)
+        hidden = input.doubleProduct(W,M).multiSoftMax(ogs)
         if tighed:
-            cost = -hidden.transposeDoubleProduct(W,M).multiLogSoftMax(ing,igs).dot(input)
+            cost = -hidden.transposeDoubleProduct(W,M).multiLogSoftMax(igs).dot(input)
             return hidden, cost, (W,M)
         else:
             Mr = Var()
             Wr = Var()
-n1=100, g1=4
-n2=50, g2=8
-n3=10, g3=25
-n4=1,  g4=10
+            
 
-d=400
-input = Var(1,d)
-W1 = Var(n1*g1,d)
-h1 = input.matrixProduct(W1)
-W2 = Var(n2*g2,n1*g1)
-h2 = h1.matrixProduct(W2)
-W3 = Var(n3*g3,n2*g2)
-h3 = h2.matrixProduct(W3)
-W4 = Var(n4*g4,n3*g3)
-h4 = h3.matrixProduct(W4)
-
-xr = reconstructionCost(h1, x, W1)
-h1r = reconstructionCost(h2, h1, W2)
-h2r = reconstructionCost(h3, h2, W3)
-h3r = reconstructionCost(h4, h3, W4)
-
-
-parameters = [ Var() for ]
-W1 = Var(10,25)
-W2 = Var(3,2)
-
-
-
-
-learner = pl.DeepAutoAssociatorLeanrer(
-    
-    )


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000512.html">[Plearn-commits] r7063 - trunk/python_modules/plearn/pyplearn
</A></li>
	<LI>Next message: <A HREF="000514.html">[Plearn-commits] r7065 - trunk/scripts
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#513">[ date ]</a>
              <a href="thread.html#513">[ thread ]</a>
              <a href="subject.html#513">[ subject ]</a>
              <a href="author.html#513">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
