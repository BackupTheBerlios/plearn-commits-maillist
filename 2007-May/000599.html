<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7150 - trunk/plearn_learners/online/EXPERIMENTAL
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7150%20-%20trunk/plearn_learners/online/EXPERIMENTAL&In-Reply-To=%3C200705171757.l4HHv29f007384%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000598.html">
   <LINK REL="Next"  HREF="000600.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7150 - trunk/plearn_learners/online/EXPERIMENTAL</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7150%20-%20trunk/plearn_learners/online/EXPERIMENTAL&In-Reply-To=%3C200705171757.l4HHv29f007384%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7150 - trunk/plearn_learners/online/EXPERIMENTAL">tihocan at mail.berlios.de
       </A><BR>
    <I>Thu May 17 19:57:02 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000598.html">[Plearn-commits] r7149 - trunk/plearn_learners/online/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="000600.html">[Plearn-commits] r7151 - in trunk/plearn_learners/online: .	EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#599">[ date ]</a>
              <a href="thread.html#599">[ thread ]</a>
              <a href="subject.html#599">[ subject ]</a>
              <a href="author.html#599">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2007-05-17 19:57:01 +0200 (Thu, 17 May 2007)
New Revision: 7150

Modified:
   trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.cc
   trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.h
Log:
Huge rewrite: most of the code is now contained into the NetworkModule module, and thus this class can be greatly simplified

Modified: trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.cc
===================================================================
--- trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.cc	2007-05-17 17:56:04 UTC (rev 7149)
+++ trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.cc	2007-05-17 17:57:01 UTC (rev 7150)
@@ -72,54 +72,11 @@
 ////////////////////
 void LearningNetwork::declareOptions(OptionList&amp; ol)
 {
-    declareOption(ol, &quot;modules&quot;, &amp;LearningNetwork::modules,
+    declareOption(ol, &quot;module&quot;, &amp;LearningNetwork::module,
                   OptionBase::buildoption,
-       &quot;List of modules contained in the network.&quot;);
+       &quot;The module being optimized. This module should typically have some\n&quot;
+       &quot;ports named 'input', 'target', 'weight', 'output' and 'cost'.&quot;);
 
-    declareOption(ol, &quot;connections&quot;, &amp;LearningNetwork::connections,
-                  OptionBase::buildoption,
-       &quot;List of connections between modules.&quot;);
-
-    declareOption(ol, &quot;input_module&quot;, &amp;LearningNetwork::input_module,
-                  OptionBase::buildoption,
-        &quot;Module that uses the samples' inputs.&quot;);
-
-    declareOption(ol, &quot;input_port&quot;, &amp;LearningNetwork::input_port,
-                  OptionBase::buildoption,
-       &quot;Port of 'input_module' that is filled with the samples' inputs.&quot;);
-
-    declareOption(ol, &quot;target_module&quot;, &amp;LearningNetwork::target_module,
-                  OptionBase::buildoption,
-        &quot;Module that uses the samples' targets.&quot;);
-
-    declareOption(ol, &quot;target_port&quot;, &amp;LearningNetwork::target_port,
-                  OptionBase::buildoption,
-       &quot;Port of 'target_module' that is filled with the samples' targets.&quot;);
-
-    declareOption(ol, &quot;weight_module&quot;, &amp;LearningNetwork::weight_module,
-                  OptionBase::buildoption,
-        &quot;Module that uses the samples' weights.&quot;);
-
-    declareOption(ol, &quot;weight_port&quot;, &amp;LearningNetwork::weight_port,
-                  OptionBase::buildoption,
-       &quot;Port of 'weight_module' that is filled with the samples' weights.&quot;);
-
-    declareOption(ol, &quot;output_module&quot;, &amp;LearningNetwork::output_module,
-                  OptionBase::buildoption,
-        &quot;Module that computes the network's output.&quot;);
-
-    declareOption(ol, &quot;output_port&quot;, &amp;LearningNetwork::output_port,
-                  OptionBase::buildoption,
-       &quot;Port of 'output_module' that contains the network's output&quot;);
-
-    declareOption(ol, &quot;cost_module&quot;, &amp;LearningNetwork::cost_module,
-                  OptionBase::buildoption,
-        &quot;Module that computes the network's cost.&quot;);
-
-    declareOption(ol, &quot;cost_port&quot;, &amp;LearningNetwork::cost_port,
-                  OptionBase::buildoption,
-       &quot;Port of 'cost_module' that contains the network's cost&quot;);
-
     declareOption(ol, &quot;batch_size&quot;, &amp;LearningNetwork::batch_size,
                   OptionBase::buildoption,
        &quot;Number of samples fed to the network at each iteration of learning.\n&quot;
@@ -139,223 +96,82 @@
 ////////////
 void LearningNetwork::build_()
 {
-    // Forward random number generator to underlying modules.
-    for (int i = 0; i &lt; modules.length(); i++)
-        if (!modules[i]-&gt;random_gen) {
-            modules[i]-&gt;random_gen = random_gen;
-            // Currently we call forget, since it ensures the module is
-            // correctly initialized and also will propagate the random number
-            // generator to its own sub-modules. However, this is not very
-            // intuitive, and a better solution may be found.
-            modules[i]-&gt;forget();
-        }
+    if (!module)
+        // Cannot do anything without an underlying module.
+        return;
 
-    // Initialize 'all_modules' and 'all_connections' with copies of
-    // respectively 'modules' and 'connections'.
-    all_modules.resize(modules.length());
-    all_modules &lt;&lt; modules;
-    all_connections.resize(connections.length());
-    all_connections &lt;&lt; connections;
-    
-    // Add connections corresponding to the input, target, weight, output and
-    // cost data.
-    if (input_module) {
+    // Forward random number generator to underlying module.
+    if (!module-&gt;random_gen) {
+        module-&gt;random_gen = random_gen;
+        // Currently we call forget, since it ensures the module is
+        // correctly initialized and also will propagate the random number
+        // generator to its own sub-modules. However, this is not very
+        // intuitive, and a better solution may be found.
+        module-&gt;forget();
+    }
+
+    // Create a new NetworkModule that connects the ports of the underlying
+    // module to simple MatrixModules that will provide/store data.
+    const TVec&lt;string&gt;&amp; ports = module-&gt;getPorts();
+    TVec&lt; PP&lt;OnlineLearningModule&gt; &gt; all_modules;
+    all_modules.append(module);
+    TVec&lt; PP&lt;NetworkConnection&gt; &gt; all_connections;
+
+    if (ports.find(&quot;input&quot;) &gt;= 0) {
         store_inputs = new MatrixModule(&quot;store_inputs&quot;, true);
         all_modules.append(get_pointer(store_inputs));
         all_connections.append(new NetworkConnection(
                     get_pointer(store_inputs), &quot;data&quot;,
-                    input_module, input_port, false));
-    }
-    if (target_module) {
+                    module, &quot;input&quot;, false));
+    } else
+        store_inputs = NULL;
+
+    if (ports.find(&quot;target&quot;) &gt;= 0) {
         store_targets = new MatrixModule(&quot;store_targets&quot;, true);
         all_modules.append(get_pointer(store_targets));
         all_connections.append(new NetworkConnection(
                     get_pointer(store_targets), &quot;data&quot;,
-                    target_module, target_port, false));
-    }
-    if (weight_module) {
+                    module, &quot;target&quot;, false));
+    } else
+        store_targets = NULL;
+
+    if (ports.find(&quot;weight&quot;) &gt;= 0) {
         store_weights = new MatrixModule(&quot;store_weights&quot;, true);
         all_modules.append(get_pointer(store_weights));
         all_connections.append(new NetworkConnection(
                     get_pointer(store_weights), &quot;data&quot;,
-                    weight_module, weight_port, false));
-    }
-    if (output_module) {
+                    module, &quot;weight&quot;, false));
+    } else
+        store_weights = NULL;
+
+    if (ports.find(&quot;output&quot;) &gt;= 0) {
         store_outputs = new MatrixModule(&quot;store_outputs&quot;, true);
         all_modules.append(get_pointer(store_outputs));
         all_connections.append(new NetworkConnection(
-                    output_module, output_port,
+                    module, &quot;output&quot;,
                     get_pointer(store_outputs), &quot;data&quot;, false));
-    }
-    if (cost_module) {
+    } else
+        store_outputs = NULL;
+
+    if (ports.find(&quot;cost&quot;) &gt;= 0) {
         store_costs = new MatrixModule(&quot;store_costs&quot;, true);
         all_modules.append(get_pointer(store_costs));
+        // Note that this is the only connection that propagates the gradient.
         all_connections.append(new NetworkConnection(
-                    cost_module, cost_port,
+                    module, &quot;cost&quot;,
                     get_pointer(store_costs), &quot;data&quot;, true));
-    }
+    } else
+        store_costs = NULL;
 
-    // First create a dictionary of all_modules.
-    map&lt;string, PP&lt;OnlineLearningModule&gt; &gt; name_to_module;
-    for (int i = 0; i &lt; all_modules.length(); i++) {
-        string module = all_modules[i]-&gt;name;
-        if (name_to_module.find(module) != name_to_module.end()) {
-            // There is already a module with the same name. For safety
-            // reasons, we make it point to a NULL pointer to ensure we do not
-            // accidentally use the wrong module.
-            name_to_module[module] = NULL;
-        } else
-            name_to_module[module] = all_modules[i];
-    }
+    network = new NetworkModule();
+    network-&gt;modules = all_modules;
+    network-&gt;connections = all_connections;
+    network-&gt;build();
 
-    // Initialize connections.
-    for (int i = 0; i &lt; all_connections.length(); i++)
-        all_connections[i]-&gt;initialize(name_to_module);
-
-    // Construct fprop and bprop paths from the list of modules and
-    // connections.
-    // First preprocess some convenience data structures from the list of
-    // connections.
-    // 'module_to_index' maps module pointers to their corresponding index in
-    // the 'all_modules' list.
-    map&lt;const OnlineLearningModule*, int&gt; module_to_index;
-    for (int i = 0; i &lt; all_modules.length(); i++)
-        module_to_index[all_modules[i]] = i;
-    // The i-th element of 'in_connections' maps each port in the i-th module
-    // to the connection that has it as destination (there may be only one).
-    TVec&lt; map&lt;string, PP&lt;NetworkConnection&gt; &gt; &gt; in_connections;
-    in_connections.resize(all_modules.length());
-    // The i-th element of 'out_connections' maps each port in the i-th module
-    // to the connections that have it as source (there may be many).
-    TVec&lt; map&lt;string, TVec&lt; PP&lt;NetworkConnection&gt; &gt; &gt; &gt; out_connections;
-    out_connections.resize(all_modules.length());
-    // The 'inputs_needed' vector contains the number of inputs that must be
-    // fed to a module before it can compute a fprop.
-    TVec&lt;int&gt; inputs_needed(all_modules.length(), 0);
-    // The 'compute_input_of' list gives, for each module M, the indices of
-    // other modules that take an output of M as input.
-    TVec&lt; TVec&lt;int&gt; &gt; compute_input_of(all_modules.length());
-    for (int i = 0; i &lt; all_connections.length(); i++) {
-        PP&lt;NetworkConnection&gt; connection = all_connections[i];
-        int src = module_to_index[connection-&gt;getSourceModule()];
-        int dest = module_to_index[connection-&gt;getDestinationModule()];
-        inputs_needed[dest]++;
-        compute_input_of[src].append(dest);
-        map&lt;string, PP&lt;NetworkConnection&gt; &gt;&amp; in_conn = in_connections[dest];
-        if (in_conn.find(connection-&gt;getDestinationPort()) != in_conn.end()) {
-            // The port has more than one incoming connection. Currently, we
-            // only allow this to happen if the module is a NullModule (this is
-            // for safety). If in the future we want more modules to allow
-            // multiple incoming connections, we may get rid of this error.
-            NullModule* test = dynamic_cast&lt;NullModule*&gt;(
-                    get_pointer(connection-&gt;getDestinationModule()));
-            if (!test)
-                PLERROR(&quot;In LearningNetwork::build_ - A port may have only one &quot;
-                        &quot;incoming connection&quot;);
-        }
-        in_conn[connection-&gt;getDestinationPort()] = connection;
-        out_connections[src][connection-&gt;getSourcePort()].append(connection);
-    }
-
-    // The fprop and bprop paths can now be computed.
-    fprop_path.resize(0);
-    bprop_path.resize(all_modules.length());
-    bprop_path.fill(-1);
-    TVec&lt;bool&gt; is_done(all_modules.length(), false);
-    fprop_data.resize(0);
-    bprop_data.resize(all_modules.length());
-    all_mats.resize(0);
-    fprop_toresize.resize(0);
-    bprop_toresize.resize(all_modules.length());
-    // A vector that stores the index of a module in the fprop path.
-    TVec&lt;int&gt; module_index_to_path_index(all_modules.length(), -1);
-    while (is_done.find(false) &gt;= 0) {
-        for (int i = 0; i &lt; all_modules.length(); i++) {
-            if (!is_done[i] &amp;&amp; inputs_needed[i] == 0) {
-                for (int j = 0; j &lt; compute_input_of[i].length(); j++)
-                    inputs_needed[compute_input_of[i][j]]--;
-                // Compute the list of matrices that must be provided to this
-                // module when doing a fprop and bprop.
-                TVec&lt;string&gt; ports = all_modules[i]-&gt;getPorts();
-                map&lt;string, PP&lt;NetworkConnection&gt; &gt;&amp; in_conn =
-                    in_connections[i];
-                map&lt;string, TVec&lt; PP&lt;NetworkConnection&gt; &gt; &gt;&amp; out_conn =
-                    out_connections[i];
-                TVec&lt;int&gt; fprop_tores;
-                TVec&lt;int&gt; bprop_tores;
-                TVec&lt;Mat*&gt; fprop_mats;
-                TVec&lt;Mat*&gt; bprop_mats;
-                for (int j = 0; j &lt; ports.length(); j++) {
-                    if (in_conn.find(ports[j]) != in_conn.end()) {
-                        // This port has an incoming connection: it is thus an
-                        // input, and the corresponding matrices for storing
-                        // its value and gradient are found by looking at the
-                        // source port of the connection.
-                        PP&lt;NetworkConnection&gt; conn = in_conn[ports[j]];
-                        int src_mod = module_to_index[conn-&gt;getSourceModule()];
-                        int path_index = module_index_to_path_index[src_mod];
-                        int port_index = conn-&gt;getSourceModule()-&gt;getPortIndex(
-                                conn-&gt;getSourcePort());
-                        fprop_mats.append(fprop_data[path_index][port_index]);
-                        if (!conn-&gt;propagate_gradient)
-                            // This connection does not propagate the gradient,
-                            // and thus we do not want to accumulate it.
-                            bprop_mats.append(NULL);
-                        else {
-                            int b_idx = all_modules.length() - 1 - path_index;
-                            bprop_mats.append(bprop_data[b_idx][port_index]);
-                            bprop_tores.append(j);
-                        }
-                        PLASSERT( out_conn.find(ports[j]) == out_conn.end() );
-                    } else if (out_conn.find(ports[j]) != out_conn.end()) {
-                        // This port has (at least) one outgoing connection: it
-                        // is thus an output, and it must be provided with
-                        // matrices to store its value (and gradient if the
-                        // connection propagates it).
-                        all_mats.append(Mat());
-                        Mat* new_mat = &amp;all_mats.lastElement();
-                        fprop_mats.append(new_mat);
-                        fprop_tores.append(j);
-                        // Ensure there exists a connection propagating the
-                        // gradient to this port.
-                        bool must_store_grad = false;
-                        const TVec&lt; PP&lt;NetworkConnection&gt; &gt;&amp; out_j =
-                            out_conn[ports[j]];
-                        for (int k = 0; k &lt; out_j.length(); k++)
-                            if (out_j[k]-&gt;propagate_gradient) {
-                                must_store_grad = true;
-                                break;
-                            }
-                        if (must_store_grad) {
-                            all_mats.append(Mat());
-                            new_mat = &amp;all_mats.lastElement();
-                            bprop_mats.append(new_mat);
-                        } else
-                            // No connection propagating gradient to this port.
-                            bprop_mats.append(NULL);
-                    } else {
-                        // This port is not used (we do not provide its value,
-                        // and we do not care about obtaining it).
-                        fprop_mats.append(NULL);
-                        bprop_mats.append(NULL);
-                    }
-                }
-                module_index_to_path_index[i] = fprop_path.length();
-                // Update fprop path.
-                fprop_data.append(fprop_mats);
-                fprop_toresize.append(fprop_tores);
-                fprop_path.append(i);
-                // Update bprop path.
-                int bprop_idx = bprop_path.length() - fprop_path.length();
-                bprop_data[bprop_idx] = bprop_mats;
-                bprop_toresize[bprop_idx] = bprop_tores;
-                bprop_path[bprop_idx] = i;
-
-                is_done[i] = true;
-            }
-        }
-    }
-    PLASSERT( module_index_to_path_index.find(-1) == -1 );
+    // Initialize the list of null pointers to provided for forward and
+    // backward propagation.
+    null_pointers.resize(module-&gt;nPorts());
+    null_pointers.fill(NULL);
 }
 
 ///////////
@@ -374,8 +190,6 @@
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
 
-    deepCopyField(output_module, copies);
-
     // ### Remove this line when you have fully implemented this method.
     PLERROR(&quot;LearningNetwork::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!&quot;);
 }
@@ -385,8 +199,8 @@
 ////////////////
 int LearningNetwork::outputsize() const
 {
-    PLASSERT( output_module );
-    return output_module-&gt;getPortWidth(output_port);
+    PLASSERT( module &amp;&amp; store_outputs );
+    return module-&gt;getPortWidth(&quot;output&quot;);
 }
 
 ////////////
@@ -396,9 +210,8 @@
 {
     inherited::forget();
 
-    // All modules should forget too.
-    for (int i = 0; i &lt; modules.length(); i++)
-        modules[i]-&gt;forget();
+    if (module)
+        module-&gt;forget();
 
     mbatch_size = -1;
 }
@@ -417,7 +230,7 @@
             mbatch_size = train_set-&gt;length();
         else
             mbatch_size = batch_size;
-        if (train_set-&gt;weightsize() &gt;= 1 &amp;&amp; !weight_module)
+        if (train_set-&gt;weightsize() &gt;= 1 &amp;&amp; !store_weights)
             PLWARNING(&quot;In LearningNetwork::train - The training set contains &quot;
                     &quot;weights, but the network is not using them&quot;);
     }
@@ -456,73 +269,24 @@
 {
     // Fill in the provided batch values (only if they are actually used by the
     // network).
-    if (input_module)
+    if (store_inputs)
         store_inputs-&gt;setData(inputs);
-    if (target_module)
+    if (store_targets)
         store_targets-&gt;setData(targets);
-    if (weight_module)
+    if (store_weights)
         store_weights-&gt;setData(weights.toMat(weights.length(), 1));
 
-    // Propagate up.
-    for (int i = 0; i &lt; fprop_path.length(); i++) {
-        PP&lt;OnlineLearningModule&gt; module = all_modules[fprop_path[i]];
-        DBG_MODULE_LOG &lt;&lt; &quot;FPROP: &quot; &lt;&lt; module-&gt;classname() &lt;&lt; endl;
-        // First resize some data matrices, so that the outputs are properly
-        // computed.
-        const TVec&lt;int&gt;&amp; toresize = fprop_toresize[i];
-        for (int j = 0; j &lt; toresize.length(); j++) {
-            DBG_MODULE_LOG &lt;&lt; &quot;  out = &quot; &lt;&lt; module-&gt;getPortName(toresize[j])
-                           &lt;&lt; endl;
-            fprop_data[i][toresize[j]]-&gt;resize(0, 0);
-        }
-        module-&gt;fprop(fprop_data[i]);
-    }
+    // Forward propagation.
+    network-&gt;fprop(null_pointers);
 
-    // Clear gradients.
-    PLASSERT( fprop_path.length() == bprop_path.length() );
-    for (int i = 0; i &lt; bprop_path.length(); i++) {
-        const TVec&lt;int&gt;&amp; toresize = bprop_toresize[i];
-        const TVec&lt;Mat*&gt;&amp; f_data = fprop_data[fprop_data.length() - 1 - i];
-        for (int j = 0; j &lt; toresize.length(); j++) {
-            if (j == 0) {
-                DBG_MODULE_LOG &lt;&lt; &quot;CLEAR: &quot; &lt;&lt;
-                    all_modules[bprop_path[i]]-&gt;classname() &lt;&lt; endl;
-            }
-            int mat_idx = toresize[j];
-            DBG_MODULE_LOG &lt;&lt; &quot;  grad = &quot; &lt;&lt;
-                all_modules[bprop_path[i]]-&gt;getPortName(mat_idx) &lt;&lt; endl;
-            Mat* mat_toresize = bprop_data[i][mat_idx];
-            Mat* mat_tpl = f_data[mat_idx];
-            mat_toresize-&gt;resize(mat_tpl-&gt;length(), mat_tpl-&gt;width());
-            mat_toresize-&gt;fill(0);
-        }
-    }
-
     // Initialize cost gradients to 1.
     // Note that we may not need to re-do it at every iteration, but this is so
     // cheap it should not impact performance.
-    if (cost_module)
+    if (store_costs)
         store_costs-&gt;setGradientTo(1);
 
-    // Backpropagate gradient to optimize parameters.
-    for (int i = 0; i &lt; bprop_path.length(); i++) {
-        PP&lt;OnlineLearningModule&gt; module = all_modules[bprop_path[i]];
-        DBG_MODULE_LOG &lt;&lt; &quot;BPROP: &quot; &lt;&lt; module-&gt;classname() &lt;&lt; endl;
-        // First resize some gradient matrices, so that the gradient is
-        // properly computed.
-        const TVec&lt;int&gt;&amp; toresize = bprop_toresize[i];
-        for (int j = 0; j &lt; toresize.length(); j++) {
-            int mat_idx = toresize[j];
-            DBG_MODULE_LOG &lt;&lt; &quot;  grad = &quot; &lt;&lt; module-&gt;getPortName(mat_idx)
-                           &lt;&lt; endl;
-            Mat* mat_toresize = bprop_data[i][mat_idx];
-            PLASSERT( mat_toresize-&gt;width() &gt; 0 );
-            mat_toresize-&gt;resize(0, mat_toresize-&gt;width());
-        }
-        // Then perform the bpropUpdate step.
-        module-&gt;bpropAccUpdate(
-                fprop_data[fprop_data.length() - 1 - i], bprop_data[i]);
-    }
+    // Backpropagation.
+    network-&gt;bpropAccUpdate(null_pointers, null_pointers);
 }
 
 ///////////////////////////
@@ -531,31 +295,22 @@
 void LearningNetwork::computeOutputAndCosts(const Vec&amp; input, const Vec&amp; target,
                                             Vec&amp; output, Vec&amp; costs) const
 {
-    if (input_module)
+    static Mat one;
+    if (store_inputs)
         store_inputs-&gt;setData(input.toMat(1, input.length()));
-    if (target_module)
+    if (store_targets)
         store_targets-&gt;setData(target.toMat(1, target.length()));
-    if (weight_module)
-        // Should fill store_weights with 1, but this is not a priority.
-        PLERROR(&quot;In LearningNetwork::computeOutputAndCosts - Not implemented &quot;
-                &quot;with 'weight_module'&quot;);
-
-    // Propagate up.
-    // TODO Code duplicated with code in train. This is bad!
-    for (int i = 0; i &lt; fprop_path.length(); i++) {
-        PP&lt;OnlineLearningModule&gt; module = all_modules[fprop_path[i]];
-        DBG_MODULE_LOG &lt;&lt; &quot;FPROP: &quot; &lt;&lt; module-&gt;classname() &lt;&lt; endl;
-        // First resize some data matrices, so that the outputs are properly
-        // computed.
-        const TVec&lt;int&gt;&amp; toresize = fprop_toresize[i];
-        for (int j = 0; j &lt; toresize.length(); j++) {
-            DBG_MODULE_LOG &lt;&lt; &quot;  out = &quot; &lt;&lt; module-&gt;getPortName(toresize[j])
-                           &lt;&lt; endl;
-            fprop_data[i][toresize[j]]-&gt;resize(0, 0);
+    if (store_weights) {
+        if (one.isEmpty()) {
+            one.resize(1, 1);
+            one(0, 0) = 1;
         }
-        module-&gt;fprop(fprop_data[i]);
+        store_weights-&gt;setData(one);
     }
 
+    // Forward propagation.
+    network-&gt;fprop(null_pointers);
+
     // Store output.
     PLASSERT( store_outputs );
     const Mat&amp; net_out = store_outputs-&gt;getData();
@@ -606,10 +361,10 @@
 //////////////////////
 TVec&lt;string&gt; LearningNetwork::getTestCostNames() const
 {
-    if (!cost_module)
+    if (!store_costs)
         return TVec&lt;string&gt;();
     else
-        return cost_module-&gt;getPortDescription(cost_port);
+        return module-&gt;getPortDescription(&quot;cost&quot;);
 }
 
 ///////////////////////

Modified: trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.h
===================================================================
--- trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.h	2007-05-17 17:56:04 UTC (rev 7149)
+++ trunk/plearn_learners/online/EXPERIMENTAL/LearningNetwork.h	2007-05-17 17:57:01 UTC (rev 7150)
@@ -44,6 +44,7 @@
 #include &lt;plearn_learners/online/OnlineLearningModule.h&gt;
 #include &lt;plearn_learners/online/EXPERIMENTAL/MatrixModule.h&gt;
 #include &lt;plearn_learners/online/NetworkConnection.h&gt;
+#include &lt;plearn_learners/online/NetworkModule.h&gt;
 
 namespace PLearn {
 
@@ -64,21 +65,8 @@
 public:
     //#####  Public Build Options  ############################################
 
-    TVec&lt; PP&lt;OnlineLearningModule&gt; &gt; modules;
-    TVec&lt; PP&lt;NetworkConnection&gt; &gt; connections;
+    PP&lt;OnlineLearningModule&gt; module;
 
-    PP&lt;OnlineLearningModule&gt; input_module;
-    PP&lt;OnlineLearningModule&gt; target_module;
-    PP&lt;OnlineLearningModule&gt; weight_module;
-    PP&lt;OnlineLearningModule&gt; output_module;
-    PP&lt;OnlineLearningModule&gt; cost_module;
-
-    string input_port;
-    string target_port;
-    string weight_port;
-    string output_port;
-    string cost_port;
-
     int batch_size;
 
 public:
@@ -173,48 +161,14 @@
     //! fprop step.
     PP&lt;MatrixModule&gt; store_costs;
 
-    //! Contains all modules (i.e. those in the 'modules' list, and the modules
-    //! storing the inputs, targets, etc).
-    TVec&lt; PP&lt;OnlineLearningModule&gt; &gt; all_modules;
+    //! The network consisting of the optimized module and the additional
+    //! modules described above.
+    PP&lt;NetworkModule&gt; network;
 
-    //! Contains all connections (i.e. those in the 'connections' list, and
-    //! those added to connect the modules storing the inputs, targets, etc).
-    TVec&lt; PP&lt;NetworkConnection&gt; &gt; all_connections;
+    //! The list of (null) pointers to matrices being given as argument to the
+    //! network's fprop and bpropAccUpdate methods.
+    TVec&lt;Mat*&gt; null_pointers;
 
-    //! Ordered list of modules used when doing a fprop (the integer values
-    //! correspond to indices in 'all_modules').
-    TVec&lt;int&gt; fprop_path;
-
-    //! Ordered list of modules used when doing a bprop (the integer values
-    //! correspond to indices in 'all_modules').
-    TVec&lt;int&gt; bprop_path;
-
-    //! The i-th element is the list of Mat* pointers being provided to the
-    //! i-th module in a fprop step.
-    TVec&lt; TVec&lt;Mat*&gt; &gt; fprop_data;
-
-    //! The i-the elment is the list of matrices that need to be resized to
-    //! empty matrices prior to calling fprop() on the i-th module in a fprop
-    //! step.
-    //! The resizing is needed to ensure we correctly compute the desired
-    //! outputs.
-    TVec&lt; TVec&lt;int&gt; &gt; fprop_toresize;
-    
-    //! The i-th element is the list of Mat* pointers being provided to the
-    //! i-th module in a bprop step.
-    TVec&lt; TVec&lt;Mat*&gt; &gt; bprop_data;
-
-    //! The i-th element is the list of matrices that need to be resized to
-    //! empty matrices prior to calling bpropUpdate() on the i-th module in a
-    //! bprop step.
-    //! The resizing is needed to ensure we correctly compute the desired
-    //! gradients.
-    TVec&lt; TVec&lt;int&gt; &gt; bprop_toresize;
-
-    //! A list of all matrices used to store the various computation results in
-    //! the network (i.e. the outputs of each module).
-    TVec&lt;Mat&gt; all_mats;
-    
     //#####  Protected Options  ###############################################
 
     int mbatch_size;


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000598.html">[Plearn-commits] r7149 - trunk/plearn_learners/online/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="000600.html">[Plearn-commits] r7151 - in trunk/plearn_learners/online: .	EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#599">[ date ]</a>
              <a href="thread.html#599">[ thread ]</a>
              <a href="subject.html#599">[ subject ]</a>
              <a href="author.html#599">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
