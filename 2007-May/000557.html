<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7108 - in trunk: plearn/var/EXPERIMENTAL	python_modules/plearn/var
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7108%20-%20in%20trunk%3A%20plearn/var/EXPERIMENTAL%0A%09python_modules/plearn/var&In-Reply-To=%3C200705151833.l4FIX0xY017283%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000556.html">
   <LINK REL="Next"  HREF="000558.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7108 - in trunk: plearn/var/EXPERIMENTAL	python_modules/plearn/var</H1>
    <B>simonl at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7108%20-%20in%20trunk%3A%20plearn/var/EXPERIMENTAL%0A%09python_modules/plearn/var&In-Reply-To=%3C200705151833.l4FIX0xY017283%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7108 - in trunk: plearn/var/EXPERIMENTAL	python_modules/plearn/var">simonl at mail.berlios.de
       </A><BR>
    <I>Tue May 15 20:33:00 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000556.html">[Plearn-commits] r7107 - trunk/plearn_learners/online/EXPERIMENTAL
</A></li>
        <LI>Next message: <A HREF="000558.html">[Plearn-commits] r7109 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#557">[ date ]</a>
              <a href="thread.html#557">[ thread ]</a>
              <a href="subject.html#557">[ subject ]</a>
              <a href="author.html#557">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: simonl
Date: 2007-05-15 20:32:58 +0200 (Tue, 15 May 2007)
New Revision: 7108

Added:
   trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.cc
   trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.h
   trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.cc
   trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.h
Modified:
   trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc
   trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h
   trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc
   trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc
   trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h
   trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc
   trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h
   trunk/python_modules/plearn/var/Var.py
Log:
Some new variables and improvements in others


Modified: trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.cc	2007-05-15 18:32:58 UTC (rev 7108)
@@ -47,81 +47,23 @@
 PLEARN_IMPLEMENT_OBJECT(
     DoubleProductVariable,
     &quot;ONE LINE USER DESCRIPTION&quot;,
-    &quot;MULTI LINE\nHELP FOR USERS&quot;
-    );
+    &quot;Let X,W and M be the inputs, nw the length of W and d their width (they all have the same width)&quot;
+    &quot; \nThen output(n,i+j*nw) = sum_k{X(n,k)*W(i,k)*M(j,k)}&quot;);
 
-//DoubleProductVariable::DoubleProductVariable()
-    /* ### Initialize all fields to their default value */
-//{
-    // ### You may (or not) want to call build_() to finish building the object
-    // ### (doing so assumes the parent classes' build_() have been called too
-    // ### in the parent classes' constructors, something that you must ensure)
-//}
-
-// constructors from input variables.
-// NaryVariable constructor (inherited) takes a VarArray as argument.
-// You can either construct from a VarArray (if the number of parent Var is not
-// fixed, for instance), or construct a VarArray from Var by operator &amp;:
-// input1 &amp; input2 &amp; input3. You can also do both, uncomment what you prefer.
-
-// DoubleProductVariable::DoubleProductVariable(const VarArray&amp; vararray)
-// ### replace with actual parameters
-//  : inherited(vararray, this_variable_length, this_variable_width),
-//    parameter(default_value),
-//    ...
-// {
-//     // ### You may (or not) want to call build_() to finish building the
-//     // ### object
-// }
-
 DoubleProductVariable::DoubleProductVariable(Var&amp; x, Var&amp; w, Var&amp; m)
-// ### replace with actual parameters
     : inherited(x &amp; w &amp; m, x.length(), w.length()*m.length())
-//    parameter(default_value),
-//    ...
 {
-    // ### You may (or not) want to call build_() to finish building the
-    // ### object
+    build_();
 }
 
-// constructor from input variable and parameters
-// DoubleProductVariable::DoubleProductVariable(const VarArray&amp; vararray
-//                            param_type the_parameter, ...)
-// ### replace with actual parameters
-//  : inherited(vararray, this_variable_length, this_variable_width),
-//    parameter(the_parameter),
-//    ...
-// {
-//     // ### You may (or not) want to call build_() to finish building the
-//     // ### object
-// }
 
-// constructor from input variable and parameters
-// DoubleProductVariable::DoubleProductVariable(Var input1, Var input2,
-//                            Var input3, ...,
-//                            param_type the_parameter, ...)
-// ### replace with actual parameters
-//  : inherited(input1 &amp; input2 &amp; input3 &amp; ...,
-//              this_variable_length, this_variable_width),
-//    parameter(the_parameter),
-//    ...
-// {
-//     // ### You may (or not) want to call build_() to finish building the
-//     // ### object
-// }
-
-
-//TODO : V&#201;RIFIER QUE CEST OK
 void DoubleProductVariable::recomputeSize(int&amp; l, int&amp; w) const
-{
-    // ### usual code to put here is:
-    
+{   
         if (varray.size() &gt; 0) {
             l = varray[0].length() ; // the computed length of this Var
             w = varray[1].length()*varray[2].length(); // the computed width
         } else
-            l = w = 0;
-    
+            l = w = 0;    
 }
 
 // ### computes value from varray values
@@ -141,7 +83,6 @@
         for(int i=0; i&lt;nw; i++)        
             for(int j=0; j&lt;nm; j++)
             {
-//TODO :v&#233;rifier que cest bien nw et pas nm
                 matValue(n,i+j*nw) = 0.;
                 for(int k=0; k&lt;d; k++)
                     matValue(n,i+j*nw) += x(n,k)*w(i,k)*m(j,k);
@@ -168,10 +109,8 @@
         for(int i=0 ;i&lt;nw; i++)
             for(int j=0; j&lt;nm; j++)
             {
-                //on est &#224; S[n, i+j*nw]
                 for(int k=0; k&lt;d; k++)
-                {
-                    //TODO : v&#233;rifier que cest bien nw et pas nw dans la(les) ligne(s) suivante(s)
+                {             
                     x_grad(n,k) += s_grad(n,i+j*nw)*w(i,k)*m(j,k);
                     w_grad(i,k) += s_grad(n,i+j*nw)*x(n,k)*m(j,k);
                     m_grad(j,k) += s_grad(n,i+j*nw)*x(n,k)*w(i,k);
@@ -240,6 +179,9 @@
     // ###    options have been modified.
     // ### You should assume that the parent class' build_() has already been
     // ### called.
+   
+    if (varW().width() != varX().width() || varW().width() != varM().width())
+        PLERROR(&quot;All input matrix widths must be equal in DoubleProductVariable&quot;);
 }
 
 

Modified: trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/DoubleProductVariable.h	2007-05-15 18:32:58 UTC (rev 7108)
@@ -71,31 +71,16 @@
     //#####  Public Member Functions  #########################################
 
     //! Default constructor, usually does nothing
-    DoubleProductVariable(){}
+    DoubleProductVariable() {}
 
     //! Constructor initializing from input variables
-    // NaryVariable constructor (inherited) takes a VarArray as
-    // argument.  You can either construct from a VarArray (if the
-    // number of parent Var is not fixed, for instance), or construct
-    // a VarArray from Var by operator &amp;: input1 &amp; input2 &amp;
-    // input3. You can also do both, uncomment what you prefer.
-
-    // ### Make sure the implementation in the .cc calls inherited constructor
-    // ### and initializes all fields with reasonable default values.
-    // DoubleProductVariable(const VarArray&amp; vararray);
     DoubleProductVariable(Var&amp; input1, Var&amp; input2, Var&amp; input3);
 
-    // ### If your class has parameters, you probably want a constructor that
-    // ### initializes them
-    // DoubleProductVariable(Var input1, Var input2,
-    //              param_type the_parameter, ...);
+    // For clear and easy access
+    Var&amp; varX() { return varray[0]; }
+    Var&amp; varW() { return varray[1]; }
+    Var&amp; varM() { return varray[2]; }
 
-    // ### If your parent variables are a meaning and you want to be able to
-    // ### access them easily, you can add functions like:
-    // Var&amp; First() { return varray[0]; }
-    // Var&amp; Second() { return varray[1]; }
-    // ...
-
     // Your other public member functions go here
 
     //#####  PLearn::Variable methods #########################################

Added: trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.cc	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.cc	2007-05-15 18:32:58 UTC (rev 7108)
@@ -0,0 +1,198 @@
+// -*- C++ -*-
+
+// LogSoftSoftMaxVariable.cc
+//
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Simon Lemieux, Pascal Vincent
+
+/*! \file LogSoftSoftMaxVariable.cc */
+
+
+#include &quot;LogSoftSoftMaxVariable.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+/** LogSoftSoftMaxVariable **/
+
+PLEARN_IMPLEMENT_OBJECT(
+    LogSoftSoftMaxVariable,
+    &quot;Kind of softmax variable&quot;,
+    &quot;Let X:=input1, A:=input2\nThen output(n,k) = X(n,k) - log(sum_j{ exp[ X(n,j) + A(k,j) ] })&quot;
+    );
+
+
+// constructor from input variables.
+LogSoftSoftMaxVariable::LogSoftSoftMaxVariable(Variable* input1, Variable* input2)
+    : inherited(input1, input2, input1-&gt;length(), input1-&gt;width())
+{
+    build_();
+}
+
+
+void LogSoftSoftMaxVariable::recomputeSize(int&amp; l, int&amp; w) const
+{
+        if (input1) {
+            l = input1-&gt;length(); // the computed length of this Var
+            w = input1-&gt;width(); // the computed width
+        } else
+            l = w = 0;
+}
+
+// ### computes value from input1 and input2 values
+void LogSoftSoftMaxVariable::fprop()
+{
+    Mat X = input1-&gt;matValue,
+        A = input2-&gt;matValue;
+
+    real sum;
+
+    for (int n=0; n&lt;X.length(); n++)    
+        for (int k=0; k&lt;X.width(); k++)
+        {
+            sum=0;
+            for (int i=0; i&lt;X.width(); i++)
+                sum += safeexp(X(n,i) + A(k,i));
+            matValue(n,k) = X(n,k) - safelog(sum);
+        }    
+}
+
+// ### computes input1 and input2 gradients from gradient
+void LogSoftSoftMaxVariable::bprop()
+{
+    Mat X = input1-&gt;matValue,
+        A = input2-&gt;matValue,
+        grad_X = input1-&gt;matGradient,
+        grad_A = input2-&gt;matGradient;
+
+    real temp;
+
+    //chacun des exemples de X
+    for (int n=0; n&lt;X.length(); n++)
+        //chaque coordonn&#233; dun exemple //correspond au gradient
+        for (int k=0; k&lt;X.width(); k++)
+            //m&#234;me exemple, coordonn&#233;e aussi // correspond &#224; un exemple
+            for (int j=0; j&lt;X.width(); j++)
+            {
+                temp = matGradient(n,j)*safeexp(matValue(n,j) + X(n,k) + A(j,k) - X(n,j));
+
+                if(k==j)
+                    grad_X(n,k) += matGradient(n,j)*(1.-safeexp(matValue(n,k)));
+                else
+                    grad_X(n,k) -= temp;                    
+                                                                                            
+                grad_A(j,k) -= temp;
+            }
+}
+
+// ### You can implement these methods:
+// void LogSoftSoftMaxVariable::bbprop() {}
+// void LogSoftSoftMaxVariable::symbolicBprop() {}
+// void LogSoftSoftMaxVariable::rfprop() {}
+
+
+// ### Nothing to add here, simply calls build_
+void LogSoftSoftMaxVariable::build()
+{
+    inherited::build();
+    build_();
+}
+
+void LogSoftSoftMaxVariable::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all &quot;pointer-like&quot; fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+
+    // ### If you want to deepCopy a Var field:
+    // varDeepCopyField(somevariable, copies);
+
+    // ### Remove this line when you have fully implemented this method.
+    PLERROR(&quot;LogSoftSoftMaxVariable::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!&quot;);
+}
+
+void LogSoftSoftMaxVariable::declareOptions(OptionList&amp; ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the &quot;flags&quot; of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    // ### ex:
+    // declareOption(ol, &quot;myoption&quot;, &amp;LogSoftSoftMaxVariable::myoption,
+    //               OptionBase::buildoption,
+    //               &quot;Help text describing this option&quot;);
+    // ...
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void LogSoftSoftMaxVariable::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a &quot;reloaded&quot; object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or &quot;re-building&quot; of an object after a few &quot;tuning&quot;
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+
+    if (input2.length() != input1.width() || input2.width() != input1.width())
+        PLERROR(&quot;Length and width of input2 must be equal to width of input1 in LogSoftSoftMaxVariable&quot;);
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.h	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/LogSoftSoftMaxVariable.h	2007-05-15 18:32:58 UTC (rev 7108)
@@ -0,0 +1,157 @@
+// -*- C++ -*-
+
+// LogSoftSoftMaxVariable.h
+//
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Simon Lemieux, Pascal Vincent
+
+/*! \file LogSoftSoftMaxVariable.h */
+
+
+#ifndef LogSoftSoftMaxVariable_INC
+#define LogSoftSoftMaxVariable_INC
+
+#include &lt;plearn/var/BinaryVariable.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+/*! * LogSoftSoftMaxVariable * */
+
+/**
+ * Log of SoftSoftMaxVariable (see SoftSoftMaxVariable for more details)
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class LogSoftSoftMaxVariable : public BinaryVariable
+{
+    typedef BinaryVariable inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor, usually does nothing
+    LogSoftSoftMaxVariable(){}
+
+    //! Constructor initializing from two input variables
+    // ### Make sure the implementation in the .cc calls inherited constructor
+    // ### and initializes all fields with reasonable default values.
+    LogSoftSoftMaxVariable(Variable* input1, Variable* input2);
+
+    // Your other public member functions go here
+
+    //#####  PLearn::Variable methods #########################################
+    virtual void recomputeSize(int&amp; l, int&amp; w) const;
+    virtual void fprop();
+    virtual void bprop();
+
+    // ### These ones are not always implemented
+    // virtual void bbprop();
+    // virtual void symbolicBprop();
+    // virtual void rfprop();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(LogSoftSoftMaxVariable);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(LogSoftSoftMaxVariable);
+
+// ### Put here a convenient method for building your variable from two
+// ### existing ones.
+// ### e.g., if your class is TotoVariable, with two parameters foo_type foo
+// ### and bar_type bar, you could write:
+// inline Var toto(Var v1, Var v2,
+//                 foo_type foo=default_foo, bar_type bar=default_bar)
+// { return new TotoVariable(v1, v2, foo, bar); }
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Modified: trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/MultiMaxVariable.cc	2007-05-15 18:32:58 UTC (rev 7108)
@@ -46,9 +46,15 @@
 
 PLEARN_IMPLEMENT_OBJECT(
     MultiMaxVariable,
-    &quot;ONE LINE USER DESCRIPTION&quot;,
-    &quot;MULTI LINE\nHELP FOR USERS&quot;
-    );
+    &quot;Different max variables done on separate groups of the input&quot;,
+&quot;This variables computes a max functions (softmax, log-softmax, hardmax, etc., determined by the field computation_type)&quot; 
+&quot;\non subvectors of the input, which lengths are defined by the field groupsizes (or groupsize if all the groups will have the same size).&quot; 
+&quot;\n&quot;
+&quot;\nex :&quot;
+&quot;\nif groupsizes = [1,2,3], and computation_type = 'S' (for softmax), and the input vector [1,2,3,4,5,6],&quot;
+&quot;\nthe result will be [softmax([1]), softmax([2,3]), softmax([4,5,6])]&quot;
+&quot;\n&quot;
+&quot;\nnote : in that example matValue.width() of the variable must be 1+2+3=6&quot; );
 
 
 //! Constructor
@@ -61,8 +67,6 @@
 }
 
 
-
-
 MultiMaxVariable::MultiMaxVariable(Variable* input, int groupsize, char computation_type)
     : inherited(input, input-&gt;length(), input-&gt;width()),
       computation_type(computation_type),
@@ -209,13 +213,9 @@
     // ### that you wish to be deepCopied rather than
     // ### shallow-copied.
     // ### ex:
-    // deepCopyField(trainvec, copies);
-
+    deepCopyField(groupsizes, copies);
     // ### If you want to deepCopy a Var field:
-    // varDeepCopyField(somevariable, copies);
-
-    // ### Remove this line when you have fully implemented this method.
-    PLERROR(&quot;MultiMaxVariable::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!&quot;);
+    // varDeepCopyField(somevariable, copies);   
 }
 
 void MultiMaxVariable::declareOptions(OptionList&amp; ol)
@@ -231,11 +231,11 @@
     // ### ex:
     declareOption(ol, &quot;groupsizes&quot;, &amp;MultiMaxVariable::groupsizes,
                   OptionBase::buildoption,
-                  &quot;this telles how to \&quot;divide\&quot; our diffrents inputs\nex: groupsizes = [1,2,3] says we divide our output like this :\n[x1],[x2,x3],[x4,x5,x6] and apply a maximum algorithm on each group separately&quot;);
+                  &quot;this tells how to \&quot;divide\&quot; our diffrents inputs\nex: groupsizes = [1,2,3] says we divide our output like this :\n[x1],[x2,x3],[x4,x5,x6] and apply a maximum algorithm on each group separately&quot;);
 
     declareOption(ol, &quot;groupsize&quot;, &amp;MultiMaxVariable::groupsize,
                   OptionBase::buildoption,
-                  &quot;&quot;);
+                  &quot;shortcut if you want all groupsizes to be equals, for example if you set the value of this option to be 3, it will make groupsizes = [3,3,...,3]&quot;);
 
     declareOption(ol, &quot;computation_type&quot;, &amp;MultiMaxVariable::computation_type,
                   OptionBase::buildoption,

Modified: trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc	2007-05-15 18:32:58 UTC (rev 7108)
@@ -2,7 +2,7 @@
 
 // ProbabilityPairsVariable.cc
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file ProbabilityPairsVariable.cc */
 
@@ -46,37 +46,38 @@
 
 PLEARN_IMPLEMENT_OBJECT(
     ProbabilityPairsVariable,
-    &quot;ONE LINE USER DESCRIPTION&quot;,
+    &quot; Let define f(x) = (x-min)/(max-min) for min&lt;=x&lt;=max, then this variable is defined by [x1,x2,...,xn]  |-&gt;  [ f(x1), 1-f(x1), f(x2), 1-f(x2), ... , f(xn), 1-f(xn) ]&quot;,
     &quot;MULTI LINE\nHELP FOR USERS&quot;
     );
 
+ProbabilityPairsVariable::ProbabilityPairsVariable()
+    : min(0.), max(1.)
+{}
 
-
-
-
 ProbabilityPairsVariable::ProbabilityPairsVariable(Variable* input, real min, real max)
     : inherited(input, input-&gt;length(), input-&gt;width()*2),
       max(max),min(min)
 
 {
-    // ### You may (or not) want to call build_() to finish building the
-    // ### object
+    build_();
 }
 
 ProbabilityPairsVariable::ProbabilityPairsVariable(Variable* input, real max)
     :inherited(input, input-&gt;length(), input-&gt;width()*2),
-     max(max),min(0.)
-{}
+     min(0.), max(max)
+{
+    build_();
+}
 
 ProbabilityPairsVariable::ProbabilityPairsVariable(Variable* input)
     :inherited(input, input-&gt;length(), input-&gt;width()*2),
-     max(1.),min(0.)
-{}
+     min(0.), max(1.)
+{
+    build_();
+}
 
 void ProbabilityPairsVariable::recomputeSize(int&amp; l, int&amp; w) const
-{
-    // ### usual code to put here is:
-    
+{   
         if (input) {
             l = input-&gt;length(); // the computed length of this Var
             w = input-&gt;width()*2; // the computed width

Modified: trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h	2007-05-15 18:32:58 UTC (rev 7108)
@@ -2,7 +2,7 @@
 
 // ProbabilityPairsVariable.h
 //
-// Copyright (C) 2007 Simon Lemieux
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
 //
 // Redistribution and use in source and binary forms, with or without
 // modification, are permitted provided that the following conditions are met:
@@ -32,7 +32,7 @@
 // This file is part of the PLearn library. For more information on the PLearn
 // library, go to the PLearn Web site at www.plearn.org
 
-// Authors: Simon Lemieux
+// Authors: Simon Lemieux, Pascal Vincent
 
 /*! \file ProbabilityPairsVariable.h */
 
@@ -48,10 +48,11 @@
 /*! * ProbabilityPairsVariable * */
 
 /**
- * The first sentence should be a BRIEF DESCRIPTION of what the class does.
- * Place the rest of the class programmer documentation here.  Doxygen supports
- * Javadoc-style comments.  See <A HREF="http://www.doxygen.org/manual.html">http://www.doxygen.org/manual.html</A>
+ *  Let define f(x) = (x-min)/(max-min) for min&lt;=x&lt;=max, then this variable is defined by [x1,x2,...,xn]  |-&gt;  [ f(x1), 1-f(x1), f(x2), 1-f(x2), ... , f(xn), 1-f(xn) ]
+ *  
+ *  This can seen as pairs of probabilities 
  *
+ *
  * @todo Write class to-do's here if there are any.
  *
  * @deprecated Write deprecated stuff here if there is any.  Indicate what else
@@ -67,19 +68,19 @@
     //! ### declare public option fields (such as build options) here
     //! Start your comments with Doxygen-compatible comments such as //!
 
-    
-    //! same as min but for upper bound
-    real max;
 
     //! the lower bound a value of the input should be
     //! it will be used to calculate the corresponding probability of each input
     real min;
+    
+    //! same as min but for upper bound
+    real max;
 
 public:
     //#####  Public Member Functions  #########################################
 
     //! Default constructor, usually does nothing
-    ProbabilityPairsVariable() {}
+    ProbabilityPairsVariable();
 
 
     // ### If your class has parameters, you probably want a constructor that

Added: trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.cc	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.cc	2007-05-15 18:32:58 UTC (rev 7108)
@@ -0,0 +1,200 @@
+// -*- C++ -*-
+
+// SoftSoftMaxVariable.cc
+//
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Simon Lemieux, Pascal Vincent
+
+/*! \file SoftSoftMaxVariable.cc */
+
+
+#include &quot;SoftSoftMaxVariable.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+/** SoftSoftMaxVariable **/
+
+PLEARN_IMPLEMENT_OBJECT(
+    SoftSoftMaxVariable,
+    &quot;Kind of softmax variable&quot;,
+    &quot;Let X:=input1, A:=input2\nThen output(n,k) = exp(X(n,k))/(sum_j{exp[X(n,j)+A(k,j)]})&quot;
+    );
+
+
+// constructor from input variables.
+SoftSoftMaxVariable::SoftSoftMaxVariable(Variable* input1, Variable* input2)
+    : inherited(input1, input2, input1-&gt;length(), input1-&gt;width())
+{
+    build_();
+}
+
+
+void SoftSoftMaxVariable::recomputeSize(int&amp; l, int&amp; w) const
+{
+    // ### usual code to put here is:
+
+        if (input1) {
+            l = input1-&gt;length(); // the computed length of this Var
+            w = input1-&gt;width(); // the computed width
+        } else
+            l = w = 0;
+}
+
+// ### computes value from input1 and input2 values
+void SoftSoftMaxVariable::fprop()
+{
+    Mat X = input1-&gt;matValue,
+        A = input2-&gt;matValue;
+
+    real sum;
+
+    for (int n=0; n&lt;X.length(); n++)    
+        for (int k=0; k&lt;X.width(); k++)
+        {
+            sum=0;
+            for (int i=0; i&lt;X.width(); i++)
+                sum += safeexp(X(n,i) + A(k,i));
+            matValue(n,k) = safeexp(X(n,k))/sum;
+        }    
+}
+
+// ### computes input1 and input2 gradients from gradient
+void SoftSoftMaxVariable::bprop()
+{
+    Mat X = input1-&gt;matValue,
+        A = input2-&gt;matValue,
+        grad_X = input1-&gt;matGradient,
+        grad_A = input2-&gt;matGradient;
+
+    real temp;
+
+    //chacun des exemples de X
+    for (int n=0; n&lt;X.length(); n++)
+        //chaque coordonn&#233; dun exemple //correspond au gradient
+        for (int k=0; k&lt;X.width(); k++)
+            //m&#234;me exemple, coordonn&#233;e aussi // correspond &#224; un exemple
+            for (int j=0; j&lt;X.width(); j++)
+            {
+                temp = matGradient(n,j)*matValue(n,j)*matValue(n,j)*safeexp(X(n,k)+A(j,k))/safeexp(X(n,j));
+
+                if(k==j)
+                    grad_X(n,k) += matGradient(n,j)*matValue(n,k)*(1.-matValue(n,k));
+                else
+                    grad_X(n,k) -= temp;                    
+                                                                                            
+                grad_A(j,k) -= temp;
+            }
+}
+
+// ### You can implement these methods:
+// void SoftSoftMaxVariable::bbprop() {}
+// void SoftSoftMaxVariable::symbolicBprop() {}
+// void SoftSoftMaxVariable::rfprop() {}
+
+
+// ### Nothing to add here, simply calls build_
+void SoftSoftMaxVariable::build()
+{
+    inherited::build();
+    build_();
+}
+
+void SoftSoftMaxVariable::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all &quot;pointer-like&quot; fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+
+    // ### If you want to deepCopy a Var field:
+    // varDeepCopyField(somevariable, copies);
+
+    // ### Remove this line when you have fully implemented this method.
+    PLERROR(&quot;SoftSoftMaxVariable::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!&quot;);
+}
+
+void SoftSoftMaxVariable::declareOptions(OptionList&amp; ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the &quot;flags&quot; of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+    // ### ex:
+    // declareOption(ol, &quot;myoption&quot;, &amp;SoftSoftMaxVariable::myoption,
+    //               OptionBase::buildoption,
+    //               &quot;Help text describing this option&quot;);
+    // ...
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void SoftSoftMaxVariable::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a &quot;reloaded&quot; object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or &quot;re-building&quot; of an object after a few &quot;tuning&quot;
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+
+    if (input2.length() != input1.width() || input2.width() != input1.width())
+        PLERROR(&quot;Length and width of input2 must be equal to width of input1 in SoftSoftMaxVariable&quot;);
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.h	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/SoftSoftMaxVariable.h	2007-05-15 18:32:58 UTC (rev 7108)
@@ -0,0 +1,157 @@
+// -*- C++ -*-
+
+// SoftSoftMaxVariable.h
+//
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Simon Lemieux, Pascal Vincent
+
+/*! \file SoftSoftMaxVariable.h */
+
+
+#ifndef SoftSoftMaxVariable_INC
+#define SoftSoftMaxVariable_INC
+
+#include &lt;plearn/var/BinaryVariable.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+/*! * SoftSoftMaxVariable * */
+
+/**
+ * Kind of SoftMax 
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class SoftSoftMaxVariable : public BinaryVariable
+{
+    typedef BinaryVariable inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor, usually does nothing
+    SoftSoftMaxVariable(){}
+
+    //! Constructor initializing from two input variables
+    // ### Make sure the implementation in the .cc calls inherited constructor
+    // ### and initializes all fields with reasonable default values.
+    SoftSoftMaxVariable(Variable* input1, Variable* input2);
+
+    // Your other public member functions go here
+
+    //#####  PLearn::Variable methods #########################################
+    virtual void recomputeSize(int&amp; l, int&amp; w) const;
+    virtual void fprop();
+    virtual void bprop();
+
+    // ### These ones are not always implemented
+    // virtual void bbprop();
+    // virtual void symbolicBprop();
+    // virtual void rfprop();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(SoftSoftMaxVariable);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(SoftSoftMaxVariable);
+
+// ### Put here a convenient method for building your variable from two
+// ### existing ones.
+// ### e.g., if your class is TotoVariable, with two parameters foo_type foo
+// ### and bar_type bar, you could write:
+// inline Var toto(Var v1, Var v2,
+//                 foo_type foo=default_foo, bar_type bar=default_bar)
+// { return new TotoVariable(v1, v2, foo, bar); }
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Modified: trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.cc	2007-05-15 18:32:58 UTC (rev 7108)
@@ -46,81 +46,28 @@
 
 PLEARN_IMPLEMENT_OBJECT(
     TransposedDoubleProductVariable,
-    &quot;ONE LINE USER DESCRIPTION&quot;,
+    &quot;Let W, M and H be the inputs and nw the length of W. Then output(n,k) = sum_i{ sum_j { W(i,k)*M(j,k)*H(n,i+j*nw) } }&quot;,
     &quot;MULTI LINE\nHELP FOR USERS&quot;
     );
 
 TransposedDoubleProductVariable::TransposedDoubleProductVariable()
-    /* ### Initialize all fields to their default value */
-{
-    // ### You may (or not) want to call build_() to finish building the object
-    // ### (doing so assumes the parent classes' build_() have been called too
-    // ### in the parent classes' constructors, something that you must ensure)
-}
+{}
 
-// constructors from input variables.
-// NaryVariable constructor (inherited) takes a VarArray as argument.
-// You can either construct from a VarArray (if the number of parent Var is not
-// fixed, for instance), or construct a VarArray from Var by operator &amp;:
-// input1 &amp; input2 &amp; input3. You can also do both, uncomment what you prefer.
-
-// TransposedDoubleProductVariable::TransposedDoubleProductVariable(const VarArray&amp; vararray)
-// ### replace with actual parameters
-//  : inherited(vararray, this_variable_length, this_variable_width),
-//    parameter(default_value),
-//    ...
-// {
-//     // ### You may (or not) want to call build_() to finish building the
-//     // ### object
-// }
-
 TransposedDoubleProductVariable::TransposedDoubleProductVariable(Var w, Var m, Var h)
-
-// ### replace with actual parameters
     : inherited(w &amp; m &amp; h, h.length(), w.width())
-//    parameter(default_value),
-//    ...
 {
-//     // ### You may (or not) want to call build_() to finish building the
-//     // ### object
+    build_();
 }
 
-// constructor from input variable and parameters
-// TransposedDoubleProductVariable::TransposedDoubleProductVariable(const VarArray&amp; vararray
-//                            param_type the_parameter, ...)
-// ### replace with actual parameters
-//  : inherited(vararray, this_variable_length, this_variable_width),
-//    parameter(the_parameter),
-//    ...
-// {
-//     // ### You may (or not) want to call build_() to finish building the
-//     // ### object
-// }
 
-// constructor from input variable and parameters
-// TransposedDoubleProductVariable::TransposedDoubleProductVariable(Var input1, Var input2,
-//                            Var input3, ...,
-//                            param_type the_parameter, ...)
-// ### replace with actual parameters
-//  : inherited(input1 &amp; input2 &amp; input3 &amp; ...,
-//              this_variable_length, this_variable_width),
-//    parameter(the_parameter),
-//    ...
-// {
-//     // ### You may (or not) want to call build_() to finish building the
-//     // ### object
-// }
-
 void TransposedDoubleProductVariable::recomputeSize(int&amp; l, int&amp; w) const
 {
-    // ### usual code to put here is:
     
         if (varray.size() &gt; 0) {
               l = varray[2].length(); // the computed length of this Var
-             w = varray[0].length(); // the computed width
+             w = varray[0].width(); // the computed width
         } else
             l = w = 0;
-    
 }
 
 // ### computes value from varray values
@@ -235,6 +182,13 @@
     // ###    options have been modified.
     // ### You should assume that the parent class' build_() has already been
     // ### called.
+
+    if (varH().width() != varW().length()*varM().length())
+        PLERROR(&quot;The width of matrix H incompatible with lengths of matrix W and M in TranposedDoubleProductVariable&quot;);
+    if (varM().width() != varW().width())
+        PLERROR(&quot;Matrix W and M must have the same width in TranposedDoubleProduct&quot;);
+
+
 }
 
 

Modified: trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/plearn/var/EXPERIMENTAL/TransposedDoubleProductVariable.h	2007-05-15 18:32:58 UTC (rev 7108)
@@ -48,10 +48,9 @@
 /*! * TransposedDoubleProductVariable * */
 
 /**
- * The first sentence should be a BRIEF DESCRIPTION of what the class does.
- * Place the rest of the class programmer documentation here.  Doxygen supports
- * Javadoc-style comments.  See <A HREF="http://www.doxygen.org/manual.html">http://www.doxygen.org/manual.html</A>
+ * Let W, M and H be the inputs and nw the length of W. Then output(n,k) = sum_i{ sum_j { W(i,k)*M(j,k)*H(n,i+j*nw) } }
  *
+ *
  * @todo Write class to-do's here if there are any.
  *
  * @deprecated Write deprecated stuff here if there is any.  Indicate what else
@@ -74,29 +73,15 @@
     TransposedDoubleProductVariable();
 
     //! Constructor initializing from input variables
-    // NaryVariable constructor (inherited) takes a VarArray as
-    // argument.  You can either construct from a VarArray (if the
-    // number of parent Var is not fixed, for instance), or construct
-    // a VarArray from Var by operator &amp;: input1 &amp; input2 &amp;
-    // input3. You can also do both, uncomment what you prefer.
-
-    // ### Make sure the implementation in the .cc calls inherited constructor
-    // ### and initializes all fields with reasonable default values.
-    // TransposedDoubleProductVariable(const VarArray&amp; vararray);
     TransposedDoubleProductVariable(Var w, Var m, Var h);
 
-    // ### If your class has parameters, you probably want a constructor that
-    // ### initializes them
-    // TransposedDoubleProductVariable(Var input1, Var input2,
-    //              param_type the_parameter, ...);
 
-    // ### If your parent variables are a meaning and you want to be able to
-    // ### access them easily, you can add functions like:
+    //easy access to input
     Var&amp; varW() { return varray[0]; }
-    Var&amp; varM() { return varray[1]; }
+    Var&amp; varM() { return varray[1]; } 
     Var&amp; varH() { return varray[2]; }
-    // ...
 
+
     // Your other public member functions go here
 
     //#####  PLearn::Variable methods #########################################

Modified: trunk/python_modules/plearn/var/Var.py
===================================================================
--- trunk/python_modules/plearn/var/Var.py	2007-05-15 18:14:17 UTC (rev 7107)
+++ trunk/python_modules/plearn/var/Var.py	2007-05-15 18:32:58 UTC (rev 7108)
@@ -117,11 +117,13 @@
             return hidden, cost, (W, Wr)
 
     else: # use double product
-        M = Var(ing*igs, ong, 'U', -1/ing/igs, 1/ing/igs, False)
-        W = Var(ing*igs, ogs, 'U', -1/ing/igs, 1/ing/igs, False)
+       # M = Var(ing*igs, ong, 'U', -1/ing/igs, 1/ing/igs, False)
+       # W = Var(ing*igs, ogs, 'U', -1/ing/igs, 1/ing/igs, False)
+        M = Var(ong, ing*igs, 'U', -1/ing/igs, 1/ing/igs, False)
+        W = Var(ogs, ing*igs, 'U', -1/ing/igs, 1/ing/igs, False)
         hidden = input.doubleProduct(W,M).multiSoftMax(ogs)
         if tighed:
-            cost = -hidden.transposeDoubleProduct(W,M).multiLogSoftMax(igs).dot(input)
+            cost = -hidden.transposeDoubleProduct(W,M).multiLogSoftMax(igs).dot(input)            
             return hidden, cost, (W,M)
         else:
             Mr = Var()


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000556.html">[Plearn-commits] r7107 - trunk/plearn_learners/online/EXPERIMENTAL
</A></li>
	<LI>Next message: <A HREF="000558.html">[Plearn-commits] r7109 - trunk/plearn_learners/generic/EXPERIMENTAL
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#557">[ date ]</a>
              <a href="thread.html#557">[ thread ]</a>
              <a href="subject.html#557">[ subject ]</a>
              <a href="author.html#557">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
