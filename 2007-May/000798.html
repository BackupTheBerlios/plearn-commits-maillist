<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7349 - in	trunk/plearn_learners/online/test/ModuleLearner: .	.pytest/PL_ModuleLearner_Greedy/expected_results	.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-May/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7349%20-%20in%0A%09trunk/plearn_learners/online/test/ModuleLearner%3A%20.%0A%09.pytest/PL_ModuleLearner_Greedy/expected_results%0A%09.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0&In-Reply-To=%3C200705252232.l4PMWwb6016762%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000797.html">
   <LINK REL="Next"  HREF="000799.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7349 - in	trunk/plearn_learners/online/test/ModuleLearner: .	.pytest/PL_ModuleLearner_Greedy/expected_results	.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7349%20-%20in%0A%09trunk/plearn_learners/online/test/ModuleLearner%3A%20.%0A%09.pytest/PL_ModuleLearner_Greedy/expected_results%0A%09.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0&In-Reply-To=%3C200705252232.l4PMWwb6016762%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7349 - in	trunk/plearn_learners/online/test/ModuleLearner: .	.pytest/PL_ModuleLearner_Greedy/expected_results	.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0">tihocan at mail.berlios.de
       </A><BR>
    <I>Sat May 26 00:32:58 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000797.html">[Plearn-commits] r7348 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000799.html">[Plearn-commits] r7350 -	trunk/plearn_learners/online/test/ModuleLearner
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#798">[ date ]</a>
              <a href="thread.html#798">[ thread ]</a>
              <a href="subject.html#798">[ subject ]</a>
              <a href="author.html#798">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2007-05-26 00:32:47 +0200 (Sat, 26 May 2007)
New Revision: 7349

Modified:
   trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/RUN.log
   trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0/final_learner.psave
   trunk/plearn_learners/online/test/ModuleLearner/PL_ModuleLearner_Greedy.pyplearn
Log:
More generic test script that allows successive fine tuning steps with different learning rates

Modified: trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/RUN.log
===================================================================
--- trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/RUN.log	2007-05-25 22:30:03 UTC (rev 7348)
+++ trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/RUN.log	2007-05-25 22:32:47 UTC (rev 7349)
@@ -1,3 +1,4 @@
  WARNING: RBMMatrixConnection: cannot forget() without random_gen
  WARNING: RBMMatrixConnection: cannot forget() without random_gen
  WARNING: GradNNetLayerModule: cannot forget() without random_gen
+ WARNING: In PLearner::initTrain (called by 'ModuleLearner') - The learner is already trained

Modified: trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0/final_learner.psave
===================================================================
--- trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0/final_learner.psave	2007-05-25 22:30:03 UTC (rev 7348)
+++ trunk/plearn_learners/online/test/ModuleLearner/.pytest/PL_ModuleLearner_Greedy/expected_results/expdir-tester/Split0/final_learner.psave	2007-05-25 22:32:47 UTC (rev 7349)
@@ -334,8 +334,8 @@
 enforce_clean_expdir = 1  )
 ;
 option_fields = 1 [ &quot;nstages&quot; ] ;
-dont_restart_upon_change = 6 [ &quot;module.forward_to&quot; &quot;nstages&quot; &quot;cost_ports&quot; &quot;target_ports&quot; &quot;module.modules[1].modules[0].cd_learning_rate&quot; &quot;module.modules[2].modules[1].cd_learning_rate&quot; ] ;
-strategy = 6 [ *27 -&gt;HyperSetOption(
+dont_restart_upon_change = 10 [ &quot;module.forward_to&quot; &quot;nstages&quot; &quot;cost_ports&quot; &quot;target_ports&quot; &quot;module.modules[1].modules[0].cd_learning_rate&quot; &quot;module.modules[2].modules[1].cd_learning_rate&quot; &quot;module.modules[2].modules[0].grad_learning_rate&quot; &quot;module.modules[2].modules[1].grad_learning_rate&quot; &quot;module.modules[2].modules[2].start_learning_rate&quot; &quot;nstages&quot; ] ;
+strategy = 9 [ *27 -&gt;HyperSetOption(
 option_name = &quot;&quot; ;
 option_value = &quot;&quot; ;
 options = 4 [ (&quot;module.forward_to&quot; , &quot;network_0&quot; )(&quot;nstages&quot; , &quot;1000&quot; )(&quot;cost_ports&quot; , &quot;[]&quot; )(&quot;target_ports&quot; , &quot;[]&quot; )] ;
@@ -356,12 +356,26 @@
 *31 -&gt;HyperSetOption(
 option_name = &quot;&quot; ;
 option_value = &quot;&quot; ;
-options = 5 [ (&quot;module.forward_to&quot; , &quot;network_2&quot; )(&quot;nstages&quot; , &quot;4000&quot; )(&quot;cost_ports&quot; , &quot;[ \&quot;NLL\&quot; ]&quot; )(&quot;target_ports&quot; , &quot;[ \&quot;target\&quot; ]&quot; )(&quot;module.modules[2].modules[1].cd_learning_rate&quot; , &quot;0&quot; )] ;
+options = 4 [ (&quot;module.forward_to&quot; , &quot;network_2&quot; )(&quot;cost_ports&quot; , &quot;[ \&quot;NLL\&quot; ]&quot; )(&quot;target_ports&quot; , &quot;[ \&quot;target\&quot; ]&quot; )(&quot;module.modules[2].modules[1].cd_learning_rate&quot; , &quot;0&quot; )] ;
 call_build = 1  )
-*32 -&gt;HyperRetrain(
+*32 -&gt;HyperSetOption(
+option_name = &quot;&quot; ;
+option_value = &quot;&quot; ;
+options = 4 [ (&quot;module.modules[2].modules[0].grad_learning_rate&quot; , &quot;0.01&quot; )(&quot;module.modules[2].modules[1].grad_learning_rate&quot; , &quot;0.01&quot; )(&quot;module.modules[2].modules[2].start_learning_rate&quot; , &quot;0.01&quot; )(&quot;nstages&quot; , &quot;2000&quot; )] ;
+call_build = 0  )
+*33 -&gt;HyperRetrain(
 splitter = *0 ;
 provide_tester_expdir = 0 ;
 call_forget = 0  )
+*34 -&gt;HyperSetOption(
+option_name = &quot;&quot; ;
+option_value = &quot;&quot; ;
+options = 4 [ (&quot;module.modules[2].modules[0].grad_learning_rate&quot; , &quot;0.001&quot; )(&quot;module.modules[2].modules[1].grad_learning_rate&quot; , &quot;0.001&quot; )(&quot;module.modules[2].modules[2].start_learning_rate&quot; , &quot;0.001&quot; )(&quot;nstages&quot; , &quot;4000&quot; )] ;
+call_build = 0  )
+*35 -&gt;HyperRetrain(
+splitter = *0 ;
+provide_tester_expdir = 0 ;
+call_forget = 0  )
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;

Modified: trunk/plearn_learners/online/test/ModuleLearner/PL_ModuleLearner_Greedy.pyplearn
===================================================================
--- trunk/plearn_learners/online/test/ModuleLearner/PL_ModuleLearner_Greedy.pyplearn	2007-05-25 22:30:03 UTC (rev 7348)
+++ trunk/plearn_learners/online/test/ModuleLearner/PL_ModuleLearner_Greedy.pyplearn	2007-05-25 22:32:47 UTC (rev 7349)
@@ -6,14 +6,18 @@
 from plearn.pyplearn import pl
 
 cd_lr = 1e-3    # Contrastive divergence learning rate
-grad_lr = 1e-3  # Fine-tuning learning rate
 inputsize = 5
 targetsize = 1
 n_classes = 2
 batch_size = 10
 greedy_nstages = 1000 # Number of samples per greedy step.
-fine_tuning_nstages = 2000 # Number of samples for fine-tuning step.
 
+# List of pairs (number of stages, learning rate) for the fine-tuning step.
+fine_tuning = \
+        [ ( 0, 1e-2 ),      # Note: this is a dumb example. No training here (0 stages).
+          ( 2000, 1e-3 ),
+        ]
+          
 rbm_sizes = [ 15, 20 ] # Size of the 'hidden' layer of each RBM.
 
 n_rbms = len(rbm_sizes) # Number of RBMs
@@ -45,14 +49,13 @@
 
 layer_sizes = [ inputsize ] + rbm_sizes
 
-rbms = [ rbm(cd_lr, grad_lr, layer_sizes[k], layer_sizes[k + 1],
+rbms = [ rbm(cd_lr, 0, layer_sizes[k], layer_sizes[k + 1],
              'rbm_%s' % k ) for k in range(n_rbms) ]
 
 affine_net = pl.GradNNetLayerModule(
         name = 'affine_net',
         input_size = rbm_sizes[-1],
-        output_size = n_classes,
-        start_learning_rate = grad_lr)
+        output_size = n_classes)
 
 softmax = pl.SoftmaxModule(
         name = 'softmax',
@@ -127,12 +130,35 @@
 splitter = pl.ExplicitSplitter(
         splitsets = TMat(1, 2, [ dataset, dataset ]))
 
+# Compute list of options to be modified to change the learning rate during the
+# fine-tuning steps.
+n_ft_steps = len(fine_tuning)
+ft_option_names = \
+        [ # First the learning rates for all RBMs in the fine-tuning network.
+          'module.modules[%s].modules[%s].grad_learning_rate' % (n_rbms, i) \
+                for i in range(n_rbms)
+        ] + \
+        [ # Then the learning rate for the affine top layer.
+          'module.modules[%s].modules[%s].start_learning_rate' % (n_rbms, n_rbms),
+          # And finally the number of stages to perform.
+          'nstages'
+        ]
+# Compute the corresponding lists of values for each step of fine-tuning.
+ft_option_values = []
+current_nstages = greedy_nstages * n_rbms;
+for (nstages, grad_lr) in fine_tuning:
+    current_nstages += nstages;
+    ft_option_values.append(
+            [ str(grad_lr) for i in range(n_rbms + 1) ] +
+            [ str(current_nstages) ])
+
 hyper = pl.HyperLearner(
         # We need to declare here all options that will be modified, to ensure
         # the network is never reset.
         dont_restart_upon_change = \
             [ 'module.forward_to', 'nstages', 'cost_ports', 'target_ports' ] + \
-            [ 'module.modules[%s].modules[%s].cd_learning_rate' % (i, i - 1) for i in range(1, n_rbms + 1) ],
+            [ 'module.modules[%s].modules[%s].cd_learning_rate' % (i, i - 1) for i in range(1, n_rbms + 1) ] + \
+            ft_option_names,
         learner = learner,
         save_final_learner = 0,
         option_fields = [ 'nstages' ],
@@ -157,17 +183,28 @@
             for i in range(n_rbms)
         ]) + \
         [
+            # Initialize options for fine-tuning.
             pl.HyperSetOption(
                 call_build = 1,
                 options = [
                     ('module.forward_to', 'network_%s' % n_rbms),
-                    ('nstages', str(greedy_nstages * n_rbms + fine_tuning_nstages)),
                     ('cost_ports', '[ &quot;NLL&quot; ]'),
                     ('target_ports', '[ &quot;target&quot; ]'),
                     ('module.modules[%s].modules[%s].cd_learning_rate' % (n_rbms, n_rbms-1), '0')
-                ]),
-            pl.HyperRetrain( call_forget = False )
-        ],
+                ])
+        ] + \
+            # List of all pairs of (HyperSetoption, HyperRetrain) corresponding
+            # to a fine tuning step.
+            reduce(lambda x,y : x + y,
+        [
+            [ pl.HyperSetOption(
+                call_build = 0, # No need to call build when changing nstages or learning rates
+                options = [ (ft_option_names[i], ft_option_values[k][i]) \
+                            for i in range(len(ft_option_names)) ]),
+              pl.HyperRetrain( call_forget = False )
+            ]
+            for k in range(n_ft_steps)
+        ]),
         tester = pl.PTester(splitter = splitter)
         )
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000797.html">[Plearn-commits] r7348 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000799.html">[Plearn-commits] r7350 -	trunk/plearn_learners/online/test/ModuleLearner
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#798">[ date ]</a>
              <a href="thread.html#798">[ thread ]</a>
              <a href="subject.html#798">[ subject ]</a>
              <a href="author.html#798">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
