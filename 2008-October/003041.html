<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9601 - in trunk: examples/data/test_suite plearn_learners/meta/test plearn_learners/meta/test/MultiClassAdaBoost plearn_learners/meta/test/MultiClassAdaBoost/.pytest plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0 plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBo! ost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-October/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9601%20-%20in%20trunk%3A%20examples/data/test_suite%0A%20plearn_learners/meta/test%20plearn_learners/meta/test/MultiClassAdaBoost%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBo%21%0A%20ost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata&In-Reply-To=%3C200810211958.m9LJw8Cg007605%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003040.html">
   <LINK REL="Next"  HREF="003042.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9601 - in trunk: examples/data/test_suite plearn_learners/meta/test plearn_learners/meta/test/MultiClassAdaBoost plearn_learners/meta/test/MultiClassAdaBoost/.pytest plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0 plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBo! ost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9601%20-%20in%20trunk%3A%20examples/data/test_suite%0A%20plearn_learners/meta/test%20plearn_learners/meta/test/MultiClassAdaBoost%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBo%21%0A%20ost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata%0A%20plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata&In-Reply-To=%3C200810211958.m9LJw8Cg007605%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9601 - in trunk: examples/data/test_suite plearn_learners/meta/test plearn_learners/meta/test/MultiClassAdaBoost plearn_learners/meta/test/MultiClassAdaBoost/.pytest plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0 plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBo! ost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata">nouiz at mail.berlios.de
       </A><BR>
    <I>Tue Oct 21 21:58:08 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="003040.html">[Plearn-commits] r9600 - in trunk: plearn/math plearn_learners/meta
</A></li>
        <LI>Next message: <A HREF="003042.html">[Plearn-commits] r9602 - in	trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir:	. Split0
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3041">[ date ]</a>
              <a href="thread.html#3041">[ thread ]</a>
              <a href="subject.html#3041">[ subject ]</a>
              <a href="author.html#3041">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2008-10-21 21:58:07 +0200 (Tue, 21 Oct 2008)
New Revision: 9601

Added:
   trunk/examples/data/test_suite/linear_4x_2y_multi_class_3.vmat
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/RUN.log
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/fieldnames
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/sizes
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/fieldnames
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/sizes
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/fieldnames
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/sizes
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_stats.psave
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/fieldnames
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/sizes
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/fieldnames
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/sizes
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_stats.psave
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/train_stats.psave
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/fieldnames
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/sizes
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/test_cost_names.txt
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/train_cost_names.txt
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/pytest.config
Log:
-added new test dataset that have 3 class
-added new test for MultiClassAdaBoost


Added: trunk/examples/data/test_suite/linear_4x_2y_multi_class_3.vmat
===================================================================
--- trunk/examples/data/test_suite/linear_4x_2y_multi_class_3.vmat	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/examples/data/test_suite/linear_4x_2y_multi_class_3.vmat	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,22 @@
+# Dummy multi-class classification problem derived from the 'linear_4x_2y' dataset.
+# The target is one of:
+#   0 if y2 &lt; -20
+#   1 if -20 &lt;= y2 &lt; 20
+#   2 if y2 &gt;= 20
+# The first five columns (x1 -&gt; x4 and y1) are the inputs.
+# These five inputs are processed through a sigmoid to ensure they are
+# between 0 and 1.
+
+MemoryVMatrix(
+    source =
+        ProcessingVMatrix(
+            source =
+                AutoVMatrix(
+                    filename = &quot;PLEARNDIR:examples/data/test_suite/linear_4x_2y.amat&quot;
+                )
+            prg = &quot;[@x1:@y1:sigmoid] @y2 -20 &lt; 1 0  ifelse dup @y2 20 &lt; 2 3 ifelse ifelse 1 - :target&quot;
+            inputsize = 5
+            targetsize = 1
+            weightsize = 0
+        )
+)


Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest
___________________________________________________________________
Name: svn:ignore
   + *.compilation_log



Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost
___________________________________________________________________
Name: svn:ignore
   + .plearn
run_results
PSAVEDIFF


Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/RUN.log
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/RUN.log	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/RUN.log	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,121 @@
+HyperLearner: starting the optimization
+split_cols: 2 2 2 
+split_values: 0.00125079586853901747 0.000357032461916012567 0.000981625552665510437 
+weak learner at stage 0 has average loss = 0.02
+split_cols: 2 1 2 
+split_values: 0.991025168386145405 0.482293993618237549 0.891579732096156263 
+weak learner at stage 0 has average loss = 0.08
+split_cols: 4 3 2 
+split_values: 3.23307269844974599e-10 0.698651129400676418 0.000537488498421501149 
+weak learner at stage 1 has average loss = 0.0306122
+split_cols: 4 1 1 
+split_values: 1.54709578481515564e-13 0.588552410435003615 0.568316236782665074 
+weak learner at stage 1 has average loss = 0.13587
+split_cols: 2 0 3 
+split_values: 0.000528285193333644099 0.624507340564582236 0.406995257960652612 
+weak learner at stage 2 has average loss = 0.136257
+split_cols: 1 3 2 
+split_values: 0.526575453102100632 0.924226804347039965 0.995245802370935517 
+weak learner at stage 2 has average loss = 0.204444
+split_cols: 2 3 1 
+split_values: 0.000528285193333644099 0.406995257960652612 0.399391565505198165 
+weak learner at stage 3 has average loss = 0.119855
+split_cols: 2 0 3 
+split_values: 0.997650553369808346 0.441781515973124872 0.310957185430505323 
+weak learner at stage 3 has average loss = 0.179198
+split_cols: 2 1 2 
+split_values: 0.196634593877310471 0.36967671457248541 0.00125079586853901747 
+weak learner at stage 4 has average loss = 0.103659
+split_cols: 3 3 2 
+split_values: 0.141930657011306749 0.0564509465831030677 0.997650553369808346 
+weak learner at stage 4 has average loss = 0.27129
+split_cols: 0 3 1 
+split_values: 0.624507340564582236 0.698651129400676418 0.370088477642079638 
+weak learner at stage 5 has average loss = 0.0730531
+split_cols: 2 4 4 
+split_values: 0.00363231682035125569 0.999999964757892545 0.999999999538717876 
+weak learner at stage 5 has average loss = 0.217388
+split_cols: 2 0 3 
+split_values: 0.00125079586853901747 0.624507340564582236 0.763338630405507312 
+weak learner at stage 6 has average loss = 0.140932
+split_cols: 1 1 1 
+split_values: 0.564858493389006289 0.479480044756096346 0.379258691801199865 
+weak learner at stage 6 has average loss = 0.262423
+split_cols: 2 3 1 
+split_values: 0.000357032461916012567 0.130712305658957473 0.399391565505198165 
+weak learner at stage 7 has average loss = 0.214419
+split_cols: 4 1 0 
+split_values: 0.999999999999999334 0.569140400436275673 0.318872618050356049 
+weak learner at stage 7 has average loss = 0.26615
+split_cols: 1 3 1 
+split_values: 0.401581050193795197 0.360834998492078562 0.370088477642079638 
+weak learner at stage 8 has average loss = 0.135994
+split_cols: 2 1 1 
+split_values: 0.0696715340410815898 0.502718698860307178 0.526575453102100632 
+weak learner at stage 8 has average loss = 0.270747
+split_cols: 2 0 1 
+split_values: 0.00125079586853901747 0.624507340564582236 0.370088477642079638 
+weak learner at stage 9 has average loss = 0.154551
+split_cols: 1 1 1 
+split_values: 0.502718698860307178 0.479480044756096346 0.6805672568090122 
+weak learner at stage 9 has average loss = 0.210479
+split_cols: 2 2 2 
+split_values: 0.000357032461916012567 0.000981625552665510437 0.00125079586853901747 
+weak learner at stage 10 has average loss = 0.108164
+split_cols: 1 1 2 
+split_values: 0.662011169718969006 0.6805672568090122 0.122353510242232788 
+weak learner at stage 10 has average loss = 0.272979
+split_cols: 1 1 1 
+split_values: 0.401581050193795197 0.332158208341527428 0.272305619535323673 
+weak learner at stage 11 has average loss = 0.132455
+split_cols: 3 0 1 
+split_values: 0.141930657011306749 0.40739065223433224 0.574273867344056166 
+weak learner at stage 11 has average loss = 0.315862
+split_cols: 4 1 3 
+split_values: 7.04158953368505536e-14 0.384853138944362905 0.662373884583906003 
+weak learner at stage 12 has average loss = 0.110589
+split_cols: 1 1 2 
+split_values: 0.662011169718969006 0.6805672568090122 0.00363231682035125569 
+weak learner at stage 12 has average loss = 0.327692
+split_cols: 3 2 0 
+split_values: 0.357489402445920146 0.0015353418386078177 0.624507340564582236 
+weak learner at stage 13 has average loss = 0.181377
+split_cols: 1 4 1 
+split_values: 0.379258691801199865 8.80684414283905426e-14 0.479480044756096346 
+weak learner at stage 13 has average loss = 0.350098
+split_cols: 2 2 2 
+split_values: 0.000981625552665510437 0.000357032461916012567 0.196634593877310471 
+weak learner at stage 14 has average loss = 0.12825
+split_cols: 1 4 4 
+split_values: 0.564858493389006289 0.999999999999999334 0.999999991749624728 
+weak learner at stage 14 has average loss = 0.30729
+split_cols: 2 3 0 
+split_values: 0.000528285193333644099 0.406995257960652612 0.624507340564582236 
+weak learner at stage 15 has average loss = 0.207133
+split_cols: 1 1 1 
+split_values: 0.526575453102100632 0.544178240629241028 0.502718698860307178 
+weak learner at stage 15 has average loss = 0.329174
+split_cols: 2 2 2 
+split_values: 0.00125079586853901747 0.000981625552665510437 0.000528285193333644099 
+weak learner at stage 16 has average loss = 0.151516
+split_cols: 2 2 2 
+split_values: 0.995010648391392527 0.991025168386145405 0.977100614750671781 
+weak learner at stage 16 has average loss = 0.306159
+split_cols: 1 3 2 
+split_values: 0.36967671457248541 0.406995257960652612 0.000254178900377460826 
+weak learner at stage 17 has average loss = 0.179798
+split_cols: 2 2 1 
+split_values: 0.885239426681956321 0.627448174543832948 0.482293993618237549 
+weak learner at stage 17 has average loss = 0.348588
+split_cols: 0 3 1 
+split_values: 0.624507340564582236 0.698651129400676418 0.370088477642079638 
+weak learner at stage 18 has average loss = 0.126962
+split_cols: 2 4 3 
+split_values: 0.997650553369808346 0.999999999999998335 0.782913532932723921 
+weak learner at stage 18 has average loss = 0.283838
+split_cols: 2 2 2 
+split_values: 0.00125079586853901747 0.000981625552665510437 0.000528285193333644099 
+weak learner at stage 19 has average loss = 0.174564
+split_cols: 1 1 1 
+split_values: 0.662011169718969006 0.6805672568090122 0.502718698860307178 
+weak learner at stage 19 has average loss = 0.34564

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat
===================================================================
(Binary files differ)


Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/fieldnames
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/fieldnames	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/fieldnames	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,11 @@
+_trial_	0
+_objective_	0
+nstages	0
+E[test1.E[class_error]]	0
+E[test1.E[linear_class_error]]	0
+E[test1.E[square_class_error]]	0
+E[test1.E[conflict]]	0
+E[test2.E[class_error]]	0
+E[test2.E[linear_class_error]]	0
+E[test2.E[square_class_error]]	0
+E[test2.E[conflict]]	0

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/sizes
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/sizes	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/LearnerExpdir/Strat0results.pmat.metadata/sizes	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1 @@
+-1 -1 -1 0 

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,1402 @@
+*1 -&gt;HyperLearner(
+tester = *2 -&gt;PTester(
+expdir = &quot;&quot; ;
+dataset = *3 -&gt;MemoryVMatrix(
+data = 200  6  [ 
+0.337040679017727052 	0.412187421639805485 	0.000975192502189414778 	0.15342979927457695 	2.77555756156289135e-16 	1 	
+0.837768842251384371 	0.629942465869766655 	0.99999866745689503 	0.978455821589285457 	1 	2 	
+0.441028250703420444 	0.714550797205845578 	0.999661619121736456 	0.608818846025308336 	1 	2 	
+0.722711173292159503 	0.534139299013230762 	0.997887018334026488 	0.886113226735210535 	0.999999999976055154 	2 	
+0.299130871933929676 	0.360203732190537917 	4.5306261716615559e-05 	0.0928636905426252213 	0 	0 	
+0.411124184726996522 	0.639982916836899007 	0.981226002279039111 	0.464305822137039914 	1 	2 	
+0.710499249124032395 	0.539688826170337976 	0.997717138254322289 	0.875929972112166055 	0.999999999999153344 	2 	
+0.184288240546414961 	0.473853871201329102 	0.000206568890665281835 	0.0439810027269273429 	6.28895564069864577e-07 	0 	
+0.247835468384202062 	0.589217134980148494 	0.125253987172025016 	0.134643618374606644 	0.999999999999998446 	2 	
+0.819995942533578437 	0.3742750365623283 	0.920000218196554864 	0.925438956030885773 	1.72362124573055553e-13 	2 	
+0.208071391136063988 	0.288296895519905672 	1.48940319855128678e-07 	0.0271273696801949682 	0 	0 	
+0.964567830275638527 	0.267751622669661571 	0.998437149798841572 	0.996322178190460095 	0 	2 	
+0.622142023781279918 	0.569475125142184568 	0.994985677375217148 	0.781983006857181917 	0.999999999999999889 	2 	
+0.656000195973205136 	0.632384490644939956 	0.999825304257418446 	0.86209851532548476 	1 	2 	
+0.497917512041781807 	0.445255345050883378 	0.0961894574372425537 	0.441785210713063148 	0.00197616314790682868 	1 	
+0.678670792025397485 	0.841421101756496204 	0.999999998654930278 	0.959419859808275932 	1 	2 	
+0.283249432531651968 	0.394384255062699751 	0.000132176529349881111 	0.0922296303861396272 	0 	0 	
+0.821939000754816407 	0.661650928488066725 	0.999999416552044829 	0.976559491191049567 	1 	2 	
+0.623898818861622462 	0.568805675730366778 	0.995035619407568017 	0.783844059008265814 	1 	1 	
+0.64844932725094484 	0.369018445347890467 	0.090859937004917124 	0.665359349749000017 	3.77475828372553224e-15 	1 	
+0.617788016990077793 	0.845311267104432718 	0.999999996183034146 	0.934589218828132506 	1 	2 	
+0.560568598210385627 	0.572297230594697615 	0.984167012020504606 	0.685246751326321069 	0.99999999999999889 	1 	
+0.730797004413526241 	0.78620836832089469 	0.999999985005914471 	0.964466185212620175 	1 	2 	
+0.634618032132718835 	0.750340665972830778 	0.999998947993276044 	0.900715501675833585 	1 	2 	
+0.52095022666103985 	0.80575351668482309 	0.999999564090173987 	0.830723002874528271 	1 	2 	
+0.787660374462927582 	0.642419269024499417 	0.999995935842380668 	0.96105907030885418 	1 	2 	
+0.747573026163381504 	0.408777845324890643 	0.850478635167357888 	0.858465136763180037 	4.27088420185128825e-10 	1 	
+0.344049451797056649 	0.59974194633533795 	0.693694777941641361 	0.292132388915243735 	0.999999999999863221 	1 	
+0.380091470145261345 	0.390005285685505743 	0.000988058603141606095 	0.193680526820496524 	0 	0 	
+0.136071444498306604 	0.174038733327655182 	1.67205693735184013e-11 	0.00519572415845664937 	0 	0 	
+0.854708697955331553 	0.722448573065056387 	0.999999990058421329 	0.989025437968076515 	1 	2 	
+0.757560278233593398 	0.483466030526050028 	0.993536629503178892 	0.901417965358118689 	0.99950050332745155 	2 	
+0.883841283359871888 	0.51078332768391177 	0.999974531176691217 	0.983705356763069472 	0.999999999999489519 	2 	
+0.499495000171716774 	0.128114914706039529 	4.6449742940879446e-09 	0.127761238240634289 	0 	0 	
+0.518898492739471973 	0.278079094080102784 	0.000104947015177880854 	0.309516644117132977 	0 	0 	
+0.65642431966618342 	0.694308507904370042 	0.999989248773869965 	0.892398673461820557 	1 	2 	
+0.244436179936414477 	0.674302546821647364 	0.836802915551401627 	0.178239622821568466 	1 	1 	
+0.231735044202631524 	0.68041073208306635 	0.826919421809612087 	0.162198541462586776 	1 	1 	
+0.420495414774386123 	0.386383438501044674 	0.00196719004512274642 	0.249052878710770975 	0 	1 	
+0.464482422012391649 	0.128947152459879366 	2.4809357901389717e-09 	0.100213915042869361 	0 	0 	
+0.771956182942409086 	0.590668595471845581 	0.99994253517097742 	0.943001342964679301 	1 	2 	
+0.324400846566160694 	0.392763663780197392 	0.000326988014224482981 	0.129919580057503758 	0 	0 	
+0.104807823195401495 	0.662371410949871287 	0.0182405353402941284 	0.0261731357173424217 	1 	1 	
+0.440594416537475053 	0.256177855855037051 	7.11662389785150395e-06 	0.176037206805503443 	0 	0 	
+0.625115862267542122 	0.37115850993626881 	0.0620416273826774334 	0.621408291026117499 	1.66533453693773481e-16 	0 	
+0.432416163989962576 	0.202030774074823449 	2.77740037468721113e-07 	0.12810151112620638 	0 	0 	
+0.236708604174129145 	0.231879283006988346 	1.80263723947859944e-08 	0.0282227012152627688 	0 	0 	
+0.847015190912564275 	0.465124225802565849 	0.99922322286709675 	0.963882434314954462 	0.992415987887875772 	2 	
+0.538160645477002486 	0.737008943262299265 	0.999984420515098726 	0.791912130614169874 	1 	2 	
+0.28333470835393415 	0.182425523806356349 	2.95443025599695375e-09 	0.0336709161573283122 	0 	0 	
+0.587768965659763665 	0.547778771470676551 	0.975656839533297071 	0.711483510236805339 	0.999999999999949818 	2 	
+0.618892475744320492 	0.332005146247901783 	0.0102816464864412538 	0.566975061872418307 	0 	1 	
+0.694461302348206133 	0.609190310086851761 	0.99980542533631811 	0.88951435084880881 	1 	2 	
+0.565943613014406988 	0.506652107479236169 	0.831002657098736996 	0.635906306170384461 	0.999955927919579879 	1 	
+0.383086029073044121 	0.945550827907227998 	0.999999999995657696 	0.870359374800871999 	1 	2 	
+0.735058297271116379 	0.533385253030013939 	0.998405580711887009 	0.897825170411419959 	0.999999999999998668 	2 	
+0.247867159961008499 	0.587887685889858735 	0.11945303331244056 	0.134080683707188841 	0.999999999914290782 	1 	
+0.31437592471957404 	0.748901091228292737 	0.999114931451879573 	0.385305232435436462 	1 	2 	
+0.356049980032269731 	0.893799247488805126 	0.999999989146302282 	0.719902897371154649 	1 	2 	
+0.234179480769041271 	0.370334983797080408 	1.32408575363451853e-05 	0.0521402176285982177 	0 	0 	
+0.189684732456134986 	0.38424234704007143 	6.29266245716353367e-06 	0.0330792608751452888 	0 	0 	
+0.207031917429434331 	0.565840436553556536 	0.0168649332947274355 	0.0816482575673892486 	0.99999999937393691 	1 	
+0.489069241863633541 	0.385463930848654379 	0.00751776669233639172 	0.365124621784082615 	0 	1 	
+0.554223418555835012 	0.262956169409198082 	9.92380307193729827e-05 	0.35573593061885489 	0 	0 	
+0.546450670398301863 	0.275978125137457453 	0.000164348010774972852 	0.356545375200074566 	0 	0 	
+0.331477526458701544 	0.544313426940081446 	0.150549210479969497 	0.226920877779638486 	0.999999973227484795 	1 	
+0.608447255824831057 	0.576250504093414606 	0.994923430289251121 	0.766880537582550481 	1 	2 	
+0.74833652534817019 	0.217437897918653533 	0.000637167891637702155 	0.710754238216330991 	0 	1 	
+0.441918384856973989 	0.232118037868229266 	1.98305498017026238e-06 	0.159403906727846767 	0 	0 	
+0.190465240239958922 	0.205912881869682318 	9.90857895732943916e-10 	0.014155296160479891 	0 	0 	
+0.832796822890589872 	0.416922441027541113 	0.99074882064070191 	0.9466578043680558 	4.36913572099406622e-07 	1 	
+0.328675871745063797 	0.276433934128551662 	1.86322469714061967e-06 	0.0840677020810715048 	0 	0 	
+0.441644647089275755 	0.535400668942389912 	0.561201571146024536 	0.418897719404788704 	0.999999996397940238 	2 	
+0.253670691389482728 	0.458786221981034303 	0.000868408106177720462 	0.0890735277355632071 	6.48091025290398193e-10 	1 	
+0.585589013754027388 	0.224171518555312144 	2.28533497587668499e-05 	0.365583725331242504 	0 	0 	
+0.58986806678244541 	0.301534783997461253 	0.00138193182218504518 	0.47202923266442659 	0 	1 	
+0.85200702932755279 	0.811420997797132615 	0.999999999927318139 	0.993037708645332362 	1 	2 	
+0.392618188076281682 	0.680723781534957939 	0.995455985334303017 	0.471184465788363038 	1 	2 	
+0.293918116463156132 	0.507311978686203147 	0.016469475112039389 	0.151277035115703007 	0.0121899329063093198 	1 	
+0.44097155133617183 	0.518326786127685679 	0.388719008958370693 	0.400848725095580616 	0.999915657472835395 	1 	
+0.527938368925109258 	0.640300813976747207 	0.998214144045750151 	0.690179796975922688 	1 	2 	
+0.303877709616286351 	0.433800927030910277 	0.00110349363209288898 	0.127343927610726104 	6.8489658389125907e-13 	0 	
+0.413583708380048265 	0.495437626628920491 	0.126920024706036194 	0.328236931934144105 	0.4510101768362893 	2 	
+0.371933728396660779 	0.493815315450534476 	0.053806134247652182 	0.254998228149233563 	0.020177763157040729 	1 	
+0.42880705432535704 	0.710649379795884273 	0.99947513790175524 	0.580812579989998579 	1 	2 	
+0.519185575742599603 	0.860101109434101785 	0.999999991171935276 	0.877510112077225846 	1 	2 	
+0.433248369780109721 	0.603801463339838751 	0.9463565486409109 	0.470840625378211142 	1 	2 	
+0.333090528816623599 	0.178629567229022346 	7.35518734806817065e-09 	0.0515043955812375387 	0 	0 	
+0.363841364105409126 	0.420173792266473223 	0.00243767478559564488 	0.191508185938040587 	1.49880108324396133e-15 	1 	
+0.258024822034749468 	0.778690243501383939 	0.999324390855314215 	0.298376672395714193 	1 	2 	
+0.308444816500438312 	0.205530525293464994 	2.36985961965530123e-08 	0.0489708262894453794 	0 	0 	
+0.275265359242249819 	0.356809252589806836 	2.18167656550471989e-05 	0.0740054232710109505 	0 	0 	
+0.447978933902173193 	0.807225196990252192 	0.999998285967393041 	0.73374557424670217 	1 	2 	
+0.569710475705847208 	0.124579530102164993 	1.386039960582508e-08 	0.200000697780095438 	0 	0 	
+0.907073953054543303 	0.320080909610997666 	0.979327058711887077 	0.97818028340714902 	0 	1 	
+0.346022306600591856 	0.33957471551374363 	5.35527421994252961e-05 	0.125863341080325264 	0 	0 	
+0.603964125026318244 	0.633402136580338504 	0.999488949006740235 	0.800804485191756843 	1 	2 	
+0.684720245521482473 	0.837664162630183062 	0.999999998453590444 	0.960523011225891343 	1 	2 	
+0.708090895277180166 	0.471418691600586415 	0.963949563452032532 	0.840129240225992779 	0.000781299807628477172 	1 	
+0.771582763339008881 	0.645452661865975386 	0.999994314239608828 	0.954011308682431336 	1 	2 	
+0.460149701882857753 	0.332311270435153072 	0.000419402495029586042 	0.265641436326872871 	0 	0 	
+0.831530044133463875 	0.529186781004250317 	0.999893949594790166 	0.964762122623453844 	0.999999999999998224 	2 	
+0.65018898152607485 	0.387873429950195248 	0.187975328574094158 	0.686548020585021845 	1.37057032389975575e-13 	0 	
+0.424831603024144355 	0.785299307796495372 	0.999989387209282654 	0.666209358798257378 	1 	2 	
+0.223955933194476708 	0.85297906339534868 	0.9999884384030715 	0.325763342209897722 	1 	2 	
+0.568189952611602878 	0.5042149001566536 	0.823608596003203242 	0.637266608512469634 	0.999735435267097072 	1 	
+0.196164666090740902 	0.698362006304233507 	0.792958232215262515 	0.121199495873135221 	1 	2 	
+0.635883152908142013 	0.739603738348431294 	0.999998198375502856 	0.896384266143035013 	1 	2 	
+0.766440462928471122 	0.776889333222431144 	0.999999989972555126 	0.974032527455173658 	1 	2 	
+0.439712238997702287 	0.223776970430579092 	1.18040709834454915e-06 	0.150663062771468848 	0 	0 	
+0.270576426620127486 	0.800109679656329731 	0.999865169866101078 	0.355412841484316178 	1 	2 	
+0.595406137160540805 	0.273123998909772792 	0.000387076909607542152 	0.44840679059006272 	0 	1 	
+0.709583071638395624 	0.244892645065264869 	0.00111965991489298977 	0.659388419418811988 	0 	0 	
+0.631612337149145886 	0.741398499859989402 	0.999998200949979932 	0.893976621243775638 	1 	2 	
+0.694771004175420592 	0.532118213643730242 	0.995500010183678841 	0.854748431601624392 	0.99999999999676481 	2 	
+0.690109228104916594 	0.857407207850628961 	0.999999999704517029 	0.967619107040243787 	1 	2 	
+0.791478407262177441 	0.706123387877502617 	0.999999802130912219 	0.971923386203978446 	1 	2 	
+0.591951822229620506 	0.447380558507254611 	0.437225483940870852 	0.630336343554293577 	3.58298156311054328e-07 	1 	
+0.416691516057121847 	0.536761047080265952 	0.448011082314667908 	0.371359256055882048 	0.999999999896008296 	2 	
+0.241271710605322209 	0.574171145689825524 	0.0606744175626963145 	0.120029588541164689 	0.999999999998035904 	1 	
+0.61683834213865274 	0.786651776820837867 	0.999999800892349078 	0.905214887115931233 	1 	2 	
+0.893793552025074045 	0.56782679783496337 	0.999998454853059715 	0.989364338420214429 	1 	2 	
+0.65921321328677962 	0.755683846757965627 	0.99999953936066821 	0.920540241090206934 	1 	2 	
+0.403657119741667958 	0.475973518743775081 	0.0515078153070945288 	0.293677438926866541 	2.50858883715232572e-05 	1 	
+0.183188899325371801 	0.79680275397946343 	0.997954101035577246 	0.164779162168442184 	1 	2 	
+0.159915087742074802 	0.641405583127205969 	0.0773014406994857461 	0.0607616755376079176 	1 	2 	
+0.590438885457506224 	0.42420618845194985 	0.226805116304403587 	0.604891812518721261 	2.96487784323673509e-09 	1 	
+0.2739605965980349 	0.488614468492700071 	0.00482695885510686651 	0.119748916573926278 	4.1677502848891379e-06 	2 	
+0.265423008491722512 	0.573310286606669717 	0.105633508560364686 	0.149217695648006854 	0.999999999999996669 	1 	
+0.260515685218742687 	0.730119706711473304 	0.9913015161315889 	0.25152413682623348 	1 	2 	
+0.859460949480679082 	0.482986570768417611 	0.999769089631301733 	0.972226055181255377 	0.999999927521804555 	2 	
+0.715253965469259345 	0.501222497563960645 	0.990567622975351059 	0.863734471591099506 	0.999999956288300407 	2 	
+0.705809945524337068 	0.544043054318400721 	0.997853911496872081 	0.872929195401613289 	0.999999999703498843 	2 	
+0.384680150978340629 	0.709568646181242491 	0.998620053983448219 	0.488109742125673263 	1 	2 	
+0.477595014000419482 	0.277766030791077922 	4.52085102251031934e-05 	0.243125441624808647 	0 	0 	
+0.363834420308997264 	0.713118834028081405 	0.998188849124578059 	0.448461205598444546 	1 	2 	
+0.80244558809579325 	0.420965787314543094 	0.97854438996804638 	0.923014652663194157 	3.32325866825300409e-09 	1 	
+0.472425506246140436 	0.761427188712762382 	0.999984163384094682 	0.718962280122859676 	1 	2 	
+0.386511475642943525 	0.584620412924011124 	0.751705671104142548 	0.358433429691765726 	0.999999999999998224 	1 	
+0.313344389534551349 	0.563876550224456041 	0.205293859180526783 	0.212465091231545666 	0.999999850909174426 	2 	
+0.437498628835231718 	0.271487240160874554 	1.47010049714180191e-05 	0.18408839079913808 	0 	0 	
+0.349972520410344767 	0.823272754127770234 	0.999995406942313592 	0.574459628804300237 	1 	2 	
+0.511535452700446203 	0.163949577360044452 	1.05913818548852845e-07 	0.177025707750321615 	0 	0 	
+0.333981910556185979 	0.777083405190116761 	0.999881013318794643 	0.467065256689115749 	1 	2 	
+0.733563847159287241 	0.523964125199950947 	0.997583968485294292 	0.89304320560242656 	0.999999987101309107 	1 	
+0.664233998157672811 	0.223942029527671616 	0.000121280891147379499 	0.530026326836644524 	0 	0 	
+0.747159532501805002 	0.61025399546998349 	0.999949900528595004 	0.931935003882062851 	1 	2 	
+0.647068916766090241 	0.842445826312409496 	0.999999997473194568 	0.947256531484346631 	1 	2 	
+0.620160612968468916 	0.293360169711035401 	0.00176105431478684737 	0.525328301669363729 	0 	1 	
+0.180912118693824064 	0.473026213425085496 	0.000178464923893839611 	0.0419870523418195973 	2.19526119504820372e-10 	0 	
+0.171486298949319993 	0.453303976992695201 	5.83472488787095678e-05 	0.034303904575232691 	2.83106871279414918e-14 	1 	
+0.480642180523963292 	0.496247570451631481 	0.368762354055697128 	0.457569793089636412 	0.0782792313851559673 	1 	
+0.460646565225021232 	0.78734912020993153 	0.99999545505324261 	0.729662318511505426 	1 	2 	
+0.467164824120552491 	0.375671870776489891 	0.00321294243586323081 	0.316254176329649583 	0 	0 	
+0.43385005121768927 	0.85176982124301015 	0.99999990359908042 	0.771436448839911471 	1 	2 	
+0.537295599170006577 	0.625186163434580333 	0.997167078991974876 	0.692086063473239976 	1 	1 	
+0.77206002977913113 	0.408222101578465835 	0.915805160160764076 	0.887859404382179029 	5.1289749669614082e-09 	2 	
+0.215260988690660682 	0.421377785818776385 	6.51462934598834309e-05 	0.0518779202071764645 	5.5511151231257827e-17 	0 	
+0.526240868080626534 	0.344837501105276723 	0.00275164754263412803 	0.393932927643954378 	0 	1 	
+0.352332982714121834 	0.228780499937454418 	2.5141515719306895e-07 	0.0807752533440048159 	0 	0 	
+0.530556872338403984 	0.435769357914573607 	0.122211770968852884 	0.497170030219862114 	5.83355058703105556e-09 	0 	
+0.418968313566468575 	0.676882136091753517 	0.996857941138302728 	0.521337033709274533 	1 	1 	
+0.403587313458172448 	0.824644927680108442 	0.999998667856597523 	0.682776283308621723 	1 	2 	
+0.361998630782866759 	0.370204408571073618 	0.00028952770396439842 	0.159220420181713229 	0 	1 	
+0.908979683193673837 	0.839935736059859939 	0.999999999999364064 	0.99809217160669339 	1 	2 	
+0.832844161267142113 	0.489798915748868746 	0.999510418543040791 	0.959708536196156592 	0.999999999975029863 	2 	
+0.247191042132576255 	0.565702859063909158 	0.0509387213597051192 	0.123082290071373113 	0.999999999999863887 	1 	
+0.236347439196011755 	0.4184425886375715 	0.000105586969146143073 	0.064450896143266434 	1.17683640610266593e-14 	0 	
+0.878774939360102647 	0.250912786885272465 	0.262483546060253647 	0.946270181212051198 	0 	1 	
+0.560856785545585934 	0.387939911774027868 	0.0343357208576768325 	0.507874348900542727 	3.68705066478014487e-13 	1 	
+0.61900332590026208 	0.209175906866663652 	1.89742269794956897e-05 	0.411150816107167638 	0 	0 	
+0.198155916735463955 	0.72655228198141264 	0.941735419830920351 	0.13952389135164156 	1 	2 	
+0.869351838403421562 	0.6676266001109048 	0.999999928312545139 	0.988892993459312253 	1 	2 	
+0.314412568305269202 	0.379561463986388015 	0.000148908442682282871 	0.114100891594720921 	0 	0 	
+0.670922423671947432 	0.408098903170796223 	0.460947205585807318 	0.741358235198477655 	2.63092586605395695e-09 	2 	
+0.307845747776586576 	0.107073381074912766 	1.06973874203220021e-11 	0.0231603669418962155 	0 	0 	
+0.764897455283813699 	0.67360817009344176 	0.99999804306670792 	0.956255113223712705 	1 	2 	
+0.602099322710622831 	0.705791257374221992 	0.999980034404002849 	0.845851840468065497 	1 	2 	
+0.498410005359550323 	0.443684957890750631 	0.0916210989854581159 	0.440416965031909857 	9.98667815110820811e-12 	0 	
+0.2494982653002355 	0.551907308225648374 	0.0315959640562301081 	0.119655134207207636 	0.999999866082263766 	1 	
+0.371349918041573357 	0.649128355496379927 	0.971250387171610163 	0.392262925955319308 	1 	2 	
+0.676505835838878578 	0.232669252996851095 	0.000262714478394654449 	0.569629577497201667 	0 	0 	
+0.630375954790908244 	0.224279366557609772 	5.88853110093379151e-05 	0.45672355544882115 	0 	0 	
+0.300711932385879122 	0.149829364552470645 	4.24941304366655004e-10 	0.031597799967373108 	0 	0 	
+0.584741827477265108 	0.0924290853768408027 	6.64550636741978451e-10 	0.168118627952250577 	0 	0 	
+0.201814833111637948 	0.540414142004595033 	0.00519546572841989018 	0.0699693665010114874 	0.999805662526560335 	1 	
+0.558190128039561695 	0.616932877239985022 	0.997360703265658066 	0.720076277306989421 	1 	2 	
+0.470688646750369089 	0.210093817686775486 	9.85101667738685904e-07 	0.173895030928417071 	0 	0 	
+0.532031073717923908 	0.760036567480947722 	0.999994818185025225 	0.803668134940642487 	1 	2 	
+0.208994001596146228 	0.76073439080480787 	0.992696853128328893 	0.18157395531864462 	1 	2 	
+0.116346727192441657 	0.167537635143858665 	4.31321645066873316e-12 	0.0034723336958780715 	0 	0 	
+0.134669253672196843 	0.830249986777758409 	0.998603683097191275 	0.105850998399096619 	1 	2 	
+0.549769642170096162 	0.552231256528370573 	0.95671254064267286 	0.647573451897092478 	0.999840819088372856 	2 	
+0.165243489232508756 	0.537479564772721186 	0.0013631676983125729 	0.0434812741523764035 	0.925412731147525536 	1 	
+0.317949746542236178 	0.74753339550780562 	0.999123747824000263 	0.3910073121171318 	1 	2 	
+0.392801824493781482 	0.487425152233795955 	0.0641128554671341333 	0.284365332967790707 	0.994211403487852863 	1 	
+0.710161800997805237 	0.271536688465156772 	0.00455234525237191434 	0.690991769450284621 	0 	0 	
+0.258779846056689244 	0.328034106346786924 	3.98635217790932472e-06 	0.0561383721754414866 	0 	0 	
+0.606341601082149295 	0.530905550153722428 	0.967631950849599187 	0.728364397980203471 	0.999999999996517897 	0 	
+0.600135566392399955 	0.291099509296859849 	0.00103701637983616424 	0.48018039043485411 	0 	0 	
+]
+;
+fieldinfos = 6 [ &quot;x1&quot; 0 &quot;x2&quot; 0 &quot;x3&quot; 0 &quot;x4&quot; 0 &quot;y1&quot; 0 &quot;target&quot; 0 ] ;
+fieldnames = []
+;
+deep_copy_memory_data = 1 ;
+writable = 0 ;
+length = 200 ;
+width = 6 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 0 ;
+extrasize = 0 ;
+metadatadir = &quot;&quot; ;
+source = *0  )
+;
+splitter = *4 -&gt;FractionSplitter(
+round_to_closest = 0 ;
+splits = 1  3  [ 
+(0 , 0.75 )	(0 , 0.75 )	(0.75 , 1 )	
+]
+;
+one_is_absolute = 0  )
+;
+statnames = 8 [ &quot;E[test1.E[class_error]]&quot; &quot;E[test1.E[linear_class_error]]&quot; &quot;E[test1.E[square_class_error]]&quot; &quot;E[test1.E[conflict]]&quot; &quot;E[test2.E[class_error]]&quot; &quot;E[test2.E[linear_class_error]]&quot; &quot;E[test2.E[square_class_error]]&quot; &quot;E[test2.E[conflict]]&quot; ] ;
+statmask = []
+;
+learner = *5 -&gt;MultiClassAdaBoost(
+random_gen = *0 ;
+seed = 1827 ;
+stage = 1 ;
+n_examples = 150 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 0 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 1 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827 ;
+learner1 = *6 -&gt;AdaBoost(
+weak_learners = 1 [ *7 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 4 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *8 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+root = *9 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *10 -&gt;RegressionTreeLeave(
+id = 1 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 150 ;
+weights_sum = 1.00000000000000244 ;
+targets_sum = 112 ;
+weighted_targets_sum = 0.746666666666667589 ;
+weighted_squared_targets_sum = 0.746666666666667589 ;
+loss_function_factor = 2  )
+;
+leave = *10  ;
+leave_output = 2 [ 0.746666666666665813 1 ] ;
+leave_error = 3 [ 0.378311111111112819 0 0.378311111111112819 ] ;
+split_col = 2 ;
+split_balance = 70 ;
+split_feature_value = 0.00125079586853901747 ;
+after_split_error = 0.074181818181818418 ;
+missing_node = *0 ;
+missing_leave = *11 -&gt;RegressionTreeLeave(
+id = 2 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *12 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *13 -&gt;RegressionTreeLeave(
+id = 3 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 40 ;
+weights_sum = 0.266666666666666441 ;
+targets_sum = 4 ;
+weighted_targets_sum = 0.0266666666666666684 ;
+weighted_squared_targets_sum = 0.0266666666666666684 ;
+loss_function_factor = 2  )
+;
+leave = *13  ;
+leave_output = 2 [ 0.100000000000000089 1 ] ;
+leave_error = 3 [ 0.048000000000000001 0 0.048000000000000001 ] ;
+split_col = 2 ;
+split_balance = 24 ;
+split_feature_value = 0.000357032461916012567 ;
+after_split_error = 0.0266666666666666684 ;
+missing_node = *0 ;
+missing_leave = *14 -&gt;RegressionTreeLeave(
+id = 5 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *15 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *16 -&gt;RegressionTreeLeave(
+id = 6 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 32 ;
+weights_sum = 0.21333333333333318 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+leave = *16  ;
+leave_output = 2 [ 0 1 ] ;
+leave_error = 3 [ 0 0 0 ] ;
+split_col = 3 ;
+split_balance = 0 ;
+split_feature_value = 0.113038628061597313 ;
+after_split_error = 0 ;
+missing_node = *0 ;
+missing_leave = *17 -&gt;RegressionTreeLeave(
+id = 11 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *18 -&gt;RegressionTreeLeave(
+id = 12 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666665495 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *19 -&gt;RegressionTreeLeave(
+id = 13 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 31 ;
+weights_sum = 0.206666666666666526 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+ )
+;
+left_leave = *16  ;
+right_node = *20 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *21 -&gt;RegressionTreeLeave(
+id = 7 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 8 ;
+weights_sum = 0.0533333333333333368 ;
+targets_sum = 4 ;
+weighted_targets_sum = 0.0266666666666666684 ;
+weighted_squared_targets_sum = 0.0266666666666666684 ;
+loss_function_factor = 2  )
+;
+leave = *21  ;
+leave_output = 2 [ 0.5 1 ] ;
+leave_error = 3 [ 0.0266666666666666684 0 0.0266666666666666684 ] ;
+split_col = 2 ;
+split_balance = 2 ;
+split_feature_value = 0.000981625552665510437 ;
+after_split_error = 0.0106666666666666646 ;
+missing_node = *0 ;
+missing_leave = *22 -&gt;RegressionTreeLeave(
+id = 14 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *23 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *24 -&gt;RegressionTreeLeave(
+id = 15 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 5 ;
+weights_sum = 0.0333333333333333329 ;
+targets_sum = 4 ;
+weighted_targets_sum = 0.0266666666666666684 ;
+weighted_squared_targets_sum = 0.0266666666666666684 ;
+loss_function_factor = 2  )
+;
+leave = *24  ;
+leave_output = 2 [ 0.800000000000000044 1 ] ;
+leave_error = 3 [ 0.0106666666666666646 0 0.0106666666666666646 ] ;
+split_col = 2 ;
+split_balance = 1 ;
+split_feature_value = 0.000528285193333644099 ;
+after_split_error = 0.00666666666666666449 ;
+missing_node = *0 ;
+missing_leave = *25 -&gt;RegressionTreeLeave(
+id = 17 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *26 -&gt;RegressionTreeLeave(
+id = 18 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666666189 ;
+targets_sum = 1 ;
+weighted_targets_sum = 0.00666666666666666536 ;
+weighted_squared_targets_sum = 0.00666666666666666536 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *27 -&gt;RegressionTreeLeave(
+id = 19 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 4 ;
+weights_sum = 0.0266666666666666684 ;
+targets_sum = 3 ;
+weighted_targets_sum = 0.0200000000000000004 ;
+weighted_squared_targets_sum = 0.0200000000000000004 ;
+loss_function_factor = 2  )
+ )
+;
+left_leave = *24  ;
+right_node = *28 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *29 -&gt;RegressionTreeLeave(
+id = 16 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 3 ;
+weights_sum = 0.0200000000000000004 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+leave = *29  ;
+leave_output = 2 [ 0 1 ] ;
+leave_error = 3 [ 0 0 0 ] ;
+split_col = 4 ;
+split_balance = 1 ;
+split_feature_value = 3.42448291945629535e-13 ;
+after_split_error = 0 ;
+missing_node = *0 ;
+missing_leave = *30 -&gt;RegressionTreeLeave(
+id = 20 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *31 -&gt;RegressionTreeLeave(
+id = 21 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666666536 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *32 -&gt;RegressionTreeLeave(
+id = 22 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 2 ;
+weights_sum = 0.0133333333333333342 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+ )
+;
+right_leave = *29   )
+;
+right_leave = *21   )
+;
+left_leave = *13  ;
+right_node = *33 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *34 -&gt;RegressionTreeLeave(
+id = 4 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 110 ;
+weights_sum = 0.73333333333333417 ;
+targets_sum = 108 ;
+weighted_targets_sum = 0.720000000000000751 ;
+weighted_squared_targets_sum = 0.720000000000000751 ;
+loss_function_factor = 2  )
+;
+leave = *34  ;
+leave_output = 2 [ 0.981818181818181701 1 ] ;
+leave_error = 3 [ 0.026181818181818306 0 0.026181818181818306 ] ;
+split_col = 4 ;
+split_balance = 88 ;
+split_feature_value = 1.54709578481515564e-13 ;
+after_split_error = 0.0218181818181818338 ;
+missing_node = *0 ;
+missing_leave = *35 -&gt;RegressionTreeLeave(
+id = 8 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *36 -&gt;RegressionTreeLeave(
+id = 9 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666673822 ;
+targets_sum = 1 ;
+weighted_targets_sum = 0.00666666666666673822 ;
+weighted_squared_targets_sum = 0.00666666666666673822 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *37 -&gt;RegressionTreeLeave(
+id = 10 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 109 ;
+weights_sum = 0.72666666666666746 ;
+targets_sum = 107 ;
+weighted_targets_sum = 0.713333333333334041 ;
+weighted_squared_targets_sum = 0.713333333333334041 ;
+loss_function_factor = 2  )
+ )
+;
+right_leave = *34   )
+;
+priority_queue = *38 -&gt;RegressionTreeQueue(
+verbosity = 2 ;
+maximum_number_of_nodes = 4 ;
+next_available_node = 4 ;
+nodes = 4 [ *33  *15  *23  *28  ]  )
+;
+first_leave = *10  ;
+split_cols = 3 [ 2 2 2 ] ;
+split_values = 3 [ 0.00125079586853901747 0.000357032461916012567 0.000981625552665510437 ] ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 4 ;
+n_examples = 150 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+] ;
+voting_weights = 1 [ 1.94591014905531323 ] ;
+sum_voting_weights = 1.94591014905531323 ;
+initial_sum_weights = 150 ;
+example_weights = 150 [ 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.0034013605442176956!
 2 0.00340136054421769562 0.00340136054421769562 0.166666666666667018 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562!
  0.00340136054421769562 0.00340136054421769562 0.0034013605442!
 1769562 
0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.166666666666667018 0.00340136054421769562 0.166666666666667018 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00!
 340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 0.00340136054421769562 ] ;
+learners_error = 1 [ 0.0200000000000000004 ] ;
+weak_learner_template = *39 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 3 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *40 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 0 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 1  )
+;
+root = *0 ;
+priority_queue = *0 ;
+first_leave = *0 ;
+split_cols = []
+;
+split_values = []
+;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = 150 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+target_error = 0.5 ;
+pseudo_loss_adaboost = 1 ;
+conf_rated_adaboost = 0 ;
+weight_by_resampling = 0 ;
+output_threshold = 0.5 ;
+provide_learner_expdir = 1 ;
+early_stopping = 0 ;
+save_often = 0 ;
+compute_training_error = 0 ;
+forward_sub_learner_test_costs = 1 ;
+modif_train_set_weights = 1 ;
+found_zero_error_weak_learner = 0 ;
+reuse_test_results = 1 ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 1 ;
+n_examples = 150 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+learner2 = *41 -&gt;AdaBoost(
+weak_learners = 1 [ *42 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 4 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *43 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+root = *44 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *45 -&gt;RegressionTreeLeave(
+id = 1 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 150 ;
+weights_sum = 1.00000000000000244 ;
+targets_sum = 74 ;
+weighted_targets_sum = 0.49333333333333268 ;
+weighted_squared_targets_sum = 0.49333333333333268 ;
+loss_function_factor = 2  )
+;
+leave = *45  ;
+leave_output = 2 [ 0.493333333333331459 1 ] ;
+leave_error = 3 [ 0.499911111111112305 0 0.499911111111112305 ] ;
+split_col = 2 ;
+split_balance = 24 ;
+split_feature_value = 0.991025168386145405 ;
+after_split_error = 0.173253056011676648 ;
+missing_node = *0 ;
+missing_leave = *46 -&gt;RegressionTreeLeave(
+id = 2 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *47 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *48 -&gt;RegressionTreeLeave(
+id = 3 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 87 ;
+weights_sum = 0.579999999999999849 ;
+targets_sum = 13 ;
+weighted_targets_sum = 0.0866666666666666696 ;
+weighted_squared_targets_sum = 0.0866666666666666696 ;
+loss_function_factor = 2  )
+;
+leave = *48  ;
+leave_output = 2 [ 0.149425287356321879 1 ] ;
+leave_error = 3 [ 0.147432950191570877 0 0.147432950191570877 ] ;
+split_col = 1 ;
+split_balance = 31 ;
+split_feature_value = 0.482293993618237549 ;
+after_split_error = 0.104535916061339731 ;
+missing_node = *0 ;
+missing_leave = *49 -&gt;RegressionTreeLeave(
+id = 5 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *50 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *51 -&gt;RegressionTreeLeave(
+id = 6 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 59 ;
+weights_sum = 0.393333333333332869 ;
+targets_sum = 1 ;
+weighted_targets_sum = 0.00666666666666666709 ;
+weighted_squared_targets_sum = 0.00666666666666666709 ;
+loss_function_factor = 2  )
+;
+leave = *51  ;
+leave_output = 2 [ 0.0169491525423729021 1 ] ;
+leave_error = 3 [ 0.013107344632768362 0 0.013107344632768362 ] ;
+split_col = 3 ;
+split_balance = 53 ;
+split_feature_value = 0.924226804347039965 ;
+after_split_error = 0.00888888888888889062 ;
+missing_node = *0 ;
+missing_leave = *52 -&gt;RegressionTreeLeave(
+id = 11 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *53 -&gt;RegressionTreeLeave(
+id = 12 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666668271 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *54 -&gt;RegressionTreeLeave(
+id = 13 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 58 ;
+weights_sum = 0.386666666666666214 ;
+targets_sum = 1 ;
+weighted_targets_sum = 0.00666666666666666709 ;
+weighted_squared_targets_sum = 0.00666666666666666709 ;
+loss_function_factor = 2  )
+ )
+;
+left_leave = *51  ;
+right_node = *55 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *56 -&gt;RegressionTreeLeave(
+id = 7 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 28 ;
+weights_sum = 0.186666666666666564 ;
+targets_sum = 12 ;
+weighted_targets_sum = 0.0800000000000000017 ;
+weighted_squared_targets_sum = 0.0800000000000000017 ;
+loss_function_factor = 2  )
+;
+leave = *56  ;
+leave_output = 2 [ 0.428571428571428825 1 ] ;
+leave_error = 3 [ 0.0914285714285713869 0 0.0914285714285713869 ] ;
+split_col = 2 ;
+split_balance = 18 ;
+split_feature_value = 0.891579732096156263 ;
+after_split_error = 0.0802318840579709924 ;
+missing_node = *0 ;
+missing_leave = *57 -&gt;RegressionTreeLeave(
+id = 14 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *58 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *59 -&gt;RegressionTreeLeave(
+id = 15 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 23 ;
+weights_sum = 0.153333333333333294 ;
+targets_sum = 8 ;
+weighted_targets_sum = 0.0533333333333333368 ;
+weighted_squared_targets_sum = 0.0533333333333333368 ;
+loss_function_factor = 2  )
+;
+leave = *59  ;
+leave_output = 2 [ 0.34782608695652184 1 ] ;
+leave_error = 3 [ 0.0695652173913043348 0 0.0695652173913043348 ] ;
+split_col = 2 ;
+split_balance = 15 ;
+split_feature_value = 0.808283414109232878 ;
+after_split_error = 0.0617543859649122839 ;
+missing_node = *0 ;
+missing_leave = *60 -&gt;RegressionTreeLeave(
+id = 17 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *61 -&gt;RegressionTreeLeave(
+id = 18 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666665495 ;
+targets_sum = 1 ;
+weighted_targets_sum = 0.00666666666666666189 ;
+weighted_squared_targets_sum = 0.00666666666666666189 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *62 -&gt;RegressionTreeLeave(
+id = 19 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 22 ;
+weights_sum = 0.14666666666666664 ;
+targets_sum = 7 ;
+weighted_targets_sum = 0.0466666666666666688 ;
+weighted_squared_targets_sum = 0.0466666666666666688 ;
+loss_function_factor = 2  )
+ )
+;
+left_leave = *59  ;
+right_node = *63 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *64 -&gt;RegressionTreeLeave(
+id = 16 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 5 ;
+weights_sum = 0.0333333333333333329 ;
+targets_sum = 4 ;
+weighted_targets_sum = 0.0266666666666666684 ;
+weighted_squared_targets_sum = 0.0266666666666666684 ;
+loss_function_factor = 2  )
+;
+leave = *64  ;
+leave_output = 2 [ 0.800000000000000044 1 ] ;
+leave_error = 3 [ 0.0106666666666666646 0 0.0106666666666666646 ] ;
+split_col = 2 ;
+split_balance = 1 ;
+split_feature_value = 0.982696507149771858 ;
+after_split_error = 0.00666666666666666709 ;
+missing_node = *0 ;
+missing_leave = *65 -&gt;RegressionTreeLeave(
+id = 20 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *66 -&gt;RegressionTreeLeave(
+id = 21 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666666189 ;
+targets_sum = 1 ;
+weighted_targets_sum = 0.00666666666666666536 ;
+weighted_squared_targets_sum = 0.00666666666666666536 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *67 -&gt;RegressionTreeLeave(
+id = 22 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 4 ;
+weights_sum = 0.0266666666666666684 ;
+targets_sum = 3 ;
+weighted_targets_sum = 0.0200000000000000004 ;
+weighted_squared_targets_sum = 0.0200000000000000004 ;
+loss_function_factor = 2  )
+ )
+;
+right_leave = *64   )
+;
+right_leave = *56   )
+;
+left_leave = *48  ;
+right_node = *68 -&gt;RegressionTreeNode(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+leave_template = *69 -&gt;RegressionTreeLeave(
+id = 4 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 63 ;
+weights_sum = 0.419999999999999485 ;
+targets_sum = 61 ;
+weighted_targets_sum = 0.406666666666666177 ;
+weighted_squared_targets_sum = 0.406666666666666177 ;
+loss_function_factor = 2  )
+;
+leave = *69  ;
+leave_output = 2 [ 0.968253968253968256 1 ] ;
+leave_error = 3 [ 0.0258201058201057432 0 0.0258201058201057432 ] ;
+split_col = 2 ;
+split_balance = 47 ;
+split_feature_value = 0.997650553369808346 ;
+after_split_error = 0.0200000000000000039 ;
+missing_node = *0 ;
+missing_leave = *70 -&gt;RegressionTreeLeave(
+id = 8 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 2  )
+;
+left_node = *0 ;
+left_leave = *71 -&gt;RegressionTreeLeave(
+id = 9 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 1 ;
+weights_sum = 0.00666666666666668271 ;
+targets_sum = 1 ;
+weighted_targets_sum = 0.00666666666666668271 ;
+weighted_squared_targets_sum = 0.00666666666666668271 ;
+loss_function_factor = 2  )
+;
+right_node = *0 ;
+right_leave = *72 -&gt;RegressionTreeLeave(
+id = 10 ;
+missing_leave = 0 ;
+loss_function_weight = 1 ;
+verbosity = 2 ;
+length = 62 ;
+weights_sum = 0.413333333333332831 ;
+targets_sum = 60 ;
+weighted_targets_sum = 0.399999999999999523 ;
+weighted_squared_targets_sum = 0.399999999999999523 ;
+loss_function_factor = 2  )
+ )
+;
+right_leave = *69   )
+;
+priority_queue = *73 -&gt;RegressionTreeQueue(
+verbosity = 2 ;
+maximum_number_of_nodes = 4 ;
+next_available_node = 4 ;
+nodes = 4 [ *58  *50  *68  *63  ]  )
+;
+first_leave = *45  ;
+split_cols = 3 [ 2 1 2 ] ;
+split_values = 3 [ 0.991025168386145405 0.482293993618237549 0.891579732096156263 ] ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 4 ;
+n_examples = 150 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+] ;
+voting_weights = 1 [ 1.22117351768460214 ] ;
+sum_voting_weights = 1.22117351768460214 ;
+initial_sum_weights = 150 ;
+example_weights = 150 [ 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971!
 132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.00362318840579!
 71132 0.0036231884057971132 0.0036231884057971132 0.0036231884!
 05797113
2 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.00362318840579711!
 32 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0416666666666668031 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 0.0036231884057971132 ] ;
+learners_error = 1 [ 0.0800000000000000017 ] ;
+weak_learner_template = *74 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 3 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *75 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 0 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 1  )
+;
+root = *0 ;
+priority_queue = *0 ;
+first_leave = *0 ;
+split_cols = []
+;
+split_values = []
+;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = 150 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+target_error = 0.5 ;
+pseudo_loss_adaboost = 1 ;
+conf_rated_adaboost = 0 ;
+weight_by_resampling = 0 ;
+output_threshold = 0.5 ;
+provide_learner_expdir = 1 ;
+early_stopping = 0 ;
+save_often = 0 ;
+compute_training_error = 0 ;
+forward_sub_learner_test_costs = 1 ;
+modif_train_set_weights = 1 ;
+found_zero_error_weak_learner = 0 ;
+reuse_test_results = 1 ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 1 ;
+n_examples = 150 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+forward_sub_learner_test_costs = 1 ;
+learner_template = *76 -&gt;AdaBoost(
+weak_learners = []
+;
+voting_weights = []
+;
+sum_voting_weights = 0 ;
+initial_sum_weights = 0 ;
+example_weights = []
+;
+learners_error = []
+;
+weak_learner_template = *77 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 3 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *78 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 0 ;
+verbosity = 2 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 1  )
+;
+root = *0 ;
+priority_queue = *0 ;
+first_leave = *0 ;
+split_cols = []
+;
+split_values = []
+;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+target_error = 0.5 ;
+pseudo_loss_adaboost = 1 ;
+conf_rated_adaboost = 0 ;
+weight_by_resampling = 0 ;
+output_threshold = 0.5 ;
+provide_learner_expdir = 1 ;
+early_stopping = 0 ;
+save_often = 0 ;
+compute_training_error = 0 ;
+forward_sub_learner_test_costs = 1 ;
+modif_train_set_weights = 0 ;
+found_zero_error_weak_learner = 0 ;
+reuse_test_results = 1 ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+ )
+;
+perf_evaluators = {};
+report_stats = 1 ;
+save_initial_tester = 0 ;
+save_stat_collectors = 1 ;
+save_split_stats = 1 ;
+save_learners = 0 ;
+save_initial_learners = 0 ;
+save_data_sets = 0 ;
+save_test_outputs = 0 ;
+call_forget_in_run = 1 ;
+save_test_costs = 0 ;
+save_test_names = 0 ;
+provide_learner_expdir = 1 ;
+should_train = 1 ;
+should_test = 1 ;
+template_stats_collector = *0 ;
+global_template_stats_collector = *0 ;
+final_commands = []
+;
+save_test_confidence = 0 ;
+enforce_clean_expdir = 1 ;
+redirect_stdout = 0 ;
+redirect_stderr = 0  )
+;
+option_fields = 1 [ &quot;nstages&quot; ] ;
+dont_restart_upon_change = 1 [ &quot;nstages&quot; ] ;
+strategy = 1 [ *79 -&gt;HyperOptimize(
+which_cost = &quot;E[test2.E[class_error]]&quot; ;
+min_n_trials = 0 ;
+oracle = *80 -&gt;EarlyStoppingOracle(
+option = &quot;nstages&quot; ;
+values = []
+;
+range = 3 [ 1 21 1 ] ;
+min_value = -3.40282000000000014e+38 ;
+max_value = 3.40282000000000014e+38 ;
+max_degradation = 3.40282000000000014e+38 ;
+relative_max_degradation = -1 ;
+min_improvement = -3.40282000000000014e+38 ;
+relative_min_improvement = -1 ;
+max_degraded_steps = 120 ;
+min_n_steps = 2 ;
+nreturned = 20 ;
+best_objective = 0.220000000000000001 ;
+best_step = 2 ;
+met_early_stopping = 0  )
+;
+provide_tester_expdir = 0 ;
+sub_strategy = []
+;
+rerun_after_sub = 0 ;
+provide_sub_expdir = 1 ;
+save_best_learner = 0 ;
+splitter = *0 ;
+auto_save = 0 ;
+auto_save_diff_time = 10800 ;
+auto_save_test = 0 ;
+best_objective = 0.220000000000000001 ;
+best_results = 8 [ 0.100000000000000006 0.100000000000000006 0.100000000000000006 0 0.220000000000000001 0.239999999999999991 0.280000000000000027 0 ] ;
+best_learner = *5  ;
+trialnum = 20 ;
+option_vals = []
+;
+verbosity = 0  )
+] ;
+provide_strategy_expdir = 1 ;
+save_final_learner = 0 ;
+learner = *5  ;
+provide_learner_expdir = 1 ;
+expdir_append = &quot;&quot; ;
+forward_nstages = 0 ;
+random_gen = *0 ;
+stage = 1 ;
+n_examples = 200 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 0 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 1 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat
===================================================================
(Binary files differ)


Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/fieldnames
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/fieldnames	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/fieldnames	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,22 @@
+class_error	0
+linear_class_error	0
+square_class_error	0
+conflict	0
+class0	0
+class1	0
+class2	0
+sum_sublearner.binary_class_error	0
+sum_sublearner.exp_neg_margin	0
+sum_sublearner.class_error	0
+sum_sublearner.avg_weight_class_0	0
+sum_sublearner.avg_weight_class_1	0
+sum_sublearner.weighted_weak_learner.mse	0
+sum_sublearner.weighted_weak_learner.base_confidence	0
+sum_sublearner.weighted_weak_learner.base_reward_l2	0
+sum_sublearner.weighted_weak_learner.base_reward_l1	0
+sum_sublearner.weighted_weak_learner.class_error	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x1	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x2	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x3	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x4	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_y1	0

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/sizes
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/sizes	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_costs.pmat.metadata/sizes	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1 @@
+-1 -1 -1 0 

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat
===================================================================
(Binary files differ)


Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/fieldnames
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/fieldnames	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/fieldnames	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,3 @@
+prediction	0
+prediction_learner_1	0
+prediction_learner_2	0

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/sizes
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/sizes	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_outputs.pmat.metadata/sizes	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1 @@
+-1 -1 -1 0 

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_stats.psave
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_stats.psave	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test1_stats.psave	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,486 @@
+*1 -&gt;VecStatsCollector(
+maxnvalues = 0 ;
+fieldnames = 22 [ &quot;class_error&quot; &quot;linear_class_error&quot; &quot;square_class_error&quot; &quot;conflict&quot; &quot;class0&quot; &quot;class1&quot; &quot;class2&quot; &quot;sum_sublearner.binary_class_error&quot; &quot;sum_sublearner.exp_neg_margin&quot; &quot;sum_sublearner.class_error&quot; &quot;sum_sublearner.avg_weight_class_0&quot; &quot;sum_sublearner.avg_weight_class_1&quot; &quot;sum_sublearner.weighted_weak_learner.mse&quot; &quot;sum_sublearner.weighted_weak_learner.base_confidence&quot; &quot;sum_sublearner.weighted_weak_learner.base_reward_l2&quot; &quot;sum_sublearner.weighted_weak_learner.base_reward_l1&quot; &quot;sum_sublearner.weighted_weak_learner.class_error&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x1&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x2&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x3&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x4&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_y1&quot; ] ;
+compute_covariance = 0 ;
+epsilon = 0 ;
+window = -1 ;
+full_update_frequency = -1 ;
+window_nan_code = 0 ;
+no_removal_warnings = 0 ;
+stats = 22 [ StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 15 ;
+sumsquare_ = 15 ;
+sumcube_ = 15 ;
+sumfourth_ = 15 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 149 ;
+agemax_ = 141 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 15 ;
+sumsquare_ = 15 ;
+sumcube_ = 15 ;
+sumfourth_ = 15 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 149 ;
+agemax_ = 141 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 15 ;
+sumsquare_ = 15 ;
+sumcube_ = 15 ;
+sumfourth_ = 15 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 149 ;
+agemax_ = 141 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0 ;
+max_ = 0 ;
+agmemin_ = 149 ;
+agemax_ = 149 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 35 ;
+sumsquare_ = 35 ;
+sumcube_ = 35 ;
+sumfourth_ = 35 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 149 ;
+agemax_ = 145 ;
+first_ = 0 ;
+last_ = 1 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = -103 ;
+sumsquare_ = 103 ;
+sumcube_ = -103 ;
+sumfourth_ = 103 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 148 ;
+agemax_ = 149 ;
+first_ = 1 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 68 ;
+sumsquare_ = 68 ;
+sumcube_ = 68 ;
+sumfourth_ = 68 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 149 ;
+agemax_ = 148 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 15 ;
+sumsquare_ = 15 ;
+sumcube_ = 15 ;
+sumfourth_ = 15 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 149 ;
+agemax_ = 141 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 57.7268015224626438 ;
+sumsquare_ = 256.10470275066541 ;
+sumcube_ = 1323.4839129605939 ;
+sumfourth_ = 7735.67317571679087 ;
+min_ = 0.437741055166937176 ;
+max_ = 7.29488391230979349 ;
+agmemin_ = 149 ;
+agemax_ = 105 ;
+first_ = 0.437741055166937176 ;
+last_ = 0.437741055166937176 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 15 ;
+sumsquare_ = 15 ;
+sumcube_ = 15 ;
+sumfourth_ = 15 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 149 ;
+agemax_ = 141 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 150 ;
+nnonmissing_ = 0 ;
+sumsquarew_ = 0 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = nan ;
+max_ = nan ;
+agmemin_ = nan ;
+agemax_ = nan ;
+first_ = nan ;
+last_ = nan ;
+binary_ = -1 ;
+integer_ = -1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 150 ;
+nnonmissing_ = 0 ;
+sumsquarew_ = 0 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = nan ;
+max_ = nan ;
+agmemin_ = nan ;
+agemax_ = nan ;
+first_ = nan ;
+last_ = nan ;
+binary_ = -1 ;
+integer_ = -1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 20.4918126593811607 ;
+sumsquare_ = 29.254876048119641 ;
+sumcube_ = 43.9580698251016742 ;
+sumfourth_ = 69.7007002426492619 ;
+min_ = 0 ;
+max_ = 1.94591014905531323 ;
+agmemin_ = 149 ;
+agemax_ = 105 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 3.16708366673991559 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 149 ;
+agemax_ = 149 ;
+first_ = 3.16708366673991559 ;
+last_ = 3.16708366673991559 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = -40.9836253187623214 ;
+sumsquare_ = 117.019504192478593 ;
+sumcube_ = -351.66455860081345 ;
+sumfourth_ = 1115.21120388238842 ;
+min_ = -0.724736631370711093 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 105 ;
+agemax_ = 149 ;
+first_ = 3.16708366673991559 ;
+last_ = 3.16708366673991559 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = -40.9836253187623214 ;
+sumsquare_ = 117.019504192478593 ;
+sumcube_ = -351.66455860081345 ;
+sumfourth_ = 1115.21120388238842 ;
+min_ = -0.724736631370711093 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 105 ;
+agemax_ = 149 ;
+first_ = 3.16708366673991559 ;
+last_ = 3.16708366673991559 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 20.4918126593811607 ;
+sumsquare_ = 29.254876048119641 ;
+sumcube_ = 43.9580698251016742 ;
+sumfourth_ = 69.7007002426492619 ;
+min_ = 0 ;
+max_ = 1.94591014905531323 ;
+agmemin_ = 149 ;
+agemax_ = 105 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0 ;
+max_ = 0 ;
+agmemin_ = 149 ;
+agemax_ = 149 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = -76.9339316141300174 ;
+sumsquare_ = 93.9496798985337023 ;
+sumcube_ = -114.728861087034772 ;
+sumfourth_ = 140.103846873602322 ;
+min_ = 0 ;
+max_ = 1.22117351768460214 ;
+agmemin_ = 148 ;
+agemax_ = 149 ;
+first_ = 1.22117351768460214 ;
+last_ = 1.22117351768460214 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = -627.206680570492381 ;
+sumsquare_ = 2809.0382900802183 ;
+sumcube_ = -12982.9982919796639 ;
+sumfourth_ = 61788.1752789862949 ;
+min_ = 3.16708366673991559 ;
+max_ = 9.00481411390585507 ;
+agmemin_ = 140 ;
+agemax_ = 149 ;
+first_ = 9.00481411390585507 ;
+last_ = 5.11299381579522816 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = -48.8576653395287863 ;
+sumsquare_ = 256.875215049057431 ;
+sumcube_ = 70.0667038794879176 ;
+sumfourth_ = 661.190924265666354 ;
+min_ = 0 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 148 ;
+agemax_ = 145 ;
+first_ = 1.22117351768460214 ;
+last_ = 3.16708366673991559 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 150 ;
+sumsquarew_ = 150 ;
+sum_ = 219.887846843250685 ;
+sumsquare_ = 427.881992826202236 ;
+sumcube_ = 832.61991243851935 ;
+sumfourth_ = 1620.20353791965613 ;
+min_ = 0 ;
+max_ = 1.94591014905531323 ;
+agmemin_ = 149 ;
+agemax_ = 148 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+] ;
+cov = 0  0  [ 
+]
+;
+sum_cross = 0  0  [ 
+]
+;
+sum_cross_weights = 0  0  [ 
+]
+;
+sum_cross_square_weights = 0  0  [ 
+]
+;
+sum_non_missing_weights = 0 ;
+sum_non_missing_square_weights = 0  )

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat
===================================================================
(Binary files differ)


Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/fieldnames
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/fieldnames	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/fieldnames	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,22 @@
+class_error	0
+linear_class_error	0
+square_class_error	0
+conflict	0
+class0	0
+class1	0
+class2	0
+sum_sublearner.binary_class_error	0
+sum_sublearner.exp_neg_margin	0
+sum_sublearner.class_error	0
+sum_sublearner.avg_weight_class_0	0
+sum_sublearner.avg_weight_class_1	0
+sum_sublearner.weighted_weak_learner.mse	0
+sum_sublearner.weighted_weak_learner.base_confidence	0
+sum_sublearner.weighted_weak_learner.base_reward_l2	0
+sum_sublearner.weighted_weak_learner.base_reward_l1	0
+sum_sublearner.weighted_weak_learner.class_error	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x1	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x2	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x3	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x4	0
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_y1	0

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/sizes
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/sizes	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_costs.pmat.metadata/sizes	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1 @@
+-1 -1 -1 0 

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat
===================================================================
(Binary files differ)


Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/fieldnames
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/fieldnames	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/fieldnames	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,3 @@
+prediction	0
+prediction_learner_1	0
+prediction_learner_2	0

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/sizes
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/sizes	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_outputs.pmat.metadata/sizes	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1 @@
+-1 -1 -1 0 

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_stats.psave
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_stats.psave	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/test2_stats.psave	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,486 @@
+*1 -&gt;VecStatsCollector(
+maxnvalues = 0 ;
+fieldnames = 22 [ &quot;class_error&quot; &quot;linear_class_error&quot; &quot;square_class_error&quot; &quot;conflict&quot; &quot;class0&quot; &quot;class1&quot; &quot;class2&quot; &quot;sum_sublearner.binary_class_error&quot; &quot;sum_sublearner.exp_neg_margin&quot; &quot;sum_sublearner.class_error&quot; &quot;sum_sublearner.avg_weight_class_0&quot; &quot;sum_sublearner.avg_weight_class_1&quot; &quot;sum_sublearner.weighted_weak_learner.mse&quot; &quot;sum_sublearner.weighted_weak_learner.base_confidence&quot; &quot;sum_sublearner.weighted_weak_learner.base_reward_l2&quot; &quot;sum_sublearner.weighted_weak_learner.base_reward_l1&quot; &quot;sum_sublearner.weighted_weak_learner.class_error&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x1&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x2&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x3&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_x4&quot; &quot;sum_sublearner.weighted_weak_learner.SPLIT_VAR_y1&quot; ] ;
+compute_covariance = 0 ;
+epsilon = 0 ;
+window = -1 ;
+full_update_frequency = -1 ;
+window_nan_code = 0 ;
+no_removal_warnings = 0 ;
+stats = 22 [ StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -39 ;
+sumsquare_ = 39 ;
+sumcube_ = -39 ;
+sumfourth_ = 39 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 48 ;
+agemax_ = 49 ;
+first_ = 1 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -38 ;
+sumsquare_ = 40 ;
+sumcube_ = -38 ;
+sumfourth_ = 40 ;
+min_ = 0 ;
+max_ = 2 ;
+agmemin_ = 48 ;
+agemax_ = 1 ;
+first_ = 1 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -36 ;
+sumsquare_ = 48 ;
+sumcube_ = -12 ;
+sumfourth_ = 120 ;
+min_ = 0 ;
+max_ = 4 ;
+agmemin_ = 48 ;
+agemax_ = 1 ;
+first_ = 1 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0 ;
+max_ = 0 ;
+agmemin_ = 49 ;
+agemax_ = 49 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -34 ;
+sumsquare_ = 34 ;
+sumcube_ = -34 ;
+sumfourth_ = 34 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 48 ;
+agemax_ = 49 ;
+first_ = 1 ;
+last_ = 1 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 15 ;
+sumsquare_ = 15 ;
+sumcube_ = 15 ;
+sumfourth_ = 15 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 49 ;
+agemax_ = 48 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 19 ;
+sumsquare_ = 19 ;
+sumcube_ = 19 ;
+sumfourth_ = 19 ;
+min_ = 0 ;
+max_ = 1 ;
+agmemin_ = 49 ;
+agemax_ = 47 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -38 ;
+sumsquare_ = 40 ;
+sumcube_ = -38 ;
+sumfourth_ = 40 ;
+min_ = 0 ;
+max_ = 2 ;
+agmemin_ = 48 ;
+agemax_ = 1 ;
+first_ = 1 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -279.375737460878668 ;
+sumsquare_ = 1899.95920013866203 ;
+sumcube_ = -12757.6924101691002 ;
+sumfourth_ = 87117.962449798797 ;
+min_ = 0.437741055166937176 ;
+max_ = 10.3911649915626327 ;
+agmemin_ = 48 ;
+agemax_ = 1 ;
+first_ = 7.29488391230979349 ;
+last_ = 0.437741055166937176 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -38 ;
+sumsquare_ = 40 ;
+sumcube_ = -38 ;
+sumfourth_ = 40 ;
+min_ = 0 ;
+max_ = 2 ;
+agmemin_ = 48 ;
+agemax_ = 1 ;
+first_ = 1 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 50 ;
+nnonmissing_ = 0 ;
+sumsquarew_ = 0 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = nan ;
+max_ = nan ;
+agmemin_ = nan ;
+agemax_ = nan ;
+first_ = nan ;
+last_ = nan ;
+binary_ = -1 ;
+integer_ = -1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 50 ;
+nnonmissing_ = 0 ;
+sumsquarew_ = 0 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = nan ;
+max_ = nan ;
+agmemin_ = nan ;
+agemax_ = nan ;
+first_ = nan ;
+last_ = nan ;
+binary_ = -1 ;
+integer_ = -1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -77.5682688209554385 ;
+sumsquare_ = 151.268323519358859 ;
+sumcube_ = -287.065953431055107 ;
+sumfourth_ = 562.512684046600498 ;
+min_ = 0 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 48 ;
+agemax_ = 1 ;
+first_ = 1.94591014905531323 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 3.16708366673991559 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 49 ;
+agemax_ = 49 ;
+first_ = 3.16708366673991559 ;
+last_ = 3.16708366673991559 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 155.136537641910934 ;
+sumsquare_ = 605.073294077435435 ;
+sumcube_ = 2296.52762744844085 ;
+sumfourth_ = 9000.20294474560978 ;
+min_ = -3.16708366673991559 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 1 ;
+agemax_ = 48 ;
+first_ = -0.724736631370711093 ;
+last_ = 3.16708366673991559 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 155.136537641910934 ;
+sumsquare_ = 605.073294077435435 ;
+sumcube_ = 2296.52762744844085 ;
+sumfourth_ = 9000.20294474560978 ;
+min_ = -3.16708366673991559 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 1 ;
+agemax_ = 48 ;
+first_ = -0.724736631370711093 ;
+last_ = 3.16708366673991559 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -77.5682688209554385 ;
+sumsquare_ = 151.268323519358859 ;
+sumcube_ = -287.065953431055107 ;
+sumfourth_ = 562.512684046600498 ;
+min_ = 0 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 48 ;
+agemax_ = 1 ;
+first_ = 1.94591014905531323 ;
+last_ = 0 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0 ;
+max_ = 0 ;
+agmemin_ = 49 ;
+agemax_ = 49 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -18.3176027652690259 ;
+sumsquare_ = 22.3689714044127861 ;
+sumcube_ = -27.3163954969130316 ;
+sumfourth_ = 33.3580587794291077 ;
+min_ = 0 ;
+max_ = 1.22117351768460214 ;
+agmemin_ = 47 ;
+agemax_ = 49 ;
+first_ = 1.22117351768460214 ;
+last_ = 1.22117351768460214 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -21.4739617998642416 ;
+sumsquare_ = 48.208806675653527 ;
+sumcube_ = -63.4330204884323621 ;
+sumfourth_ = 148.126424077304165 ;
+min_ = 3.16708366673991559 ;
+max_ = 7.05890396485054161 ;
+agmemin_ = 46 ;
+agemax_ = 0 ;
+first_ = 5.11299381579522816 ;
+last_ = 7.05890396485054161 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = -98.6361931590509897 ;
+sumsquare_ = 288.626136885233507 ;
+sumcube_ = -867.862578938199249 ;
+sumfourth_ = 2658.61345294527882 ;
+min_ = 0 ;
+max_ = 3.16708366673991559 ;
+agmemin_ = 48 ;
+agemax_ = 49 ;
+first_ = 3.16708366673991559 ;
+last_ = 1.22117351768460214 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 50 ;
+sumsquarew_ = 50 ;
+sum_ = 68.1068552169359691 ;
+sumsquare_ = 132.529820786876485 ;
+sumcube_ = 257.891123321664736 ;
+sumfourth_ = 501.832954222902686 ;
+min_ = 0 ;
+max_ = 1.94591014905531323 ;
+agmemin_ = 49 ;
+agemax_ = 48 ;
+first_ = 0 ;
+last_ = 1.94591014905531323 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+] ;
+cov = 0  0  [ 
+]
+;
+sum_cross = 0  0  [ 
+]
+;
+sum_cross_weights = 0  0  [ 
+]
+;
+sum_cross_square_weights = 0  0  [ 
+]
+;
+sum_non_missing_weights = 0 ;
+sum_non_missing_square_weights = 0  )

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/train_stats.psave
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/train_stats.psave	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/train_stats.psave	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,192 @@
+*1 -&gt;VecStatsCollector(
+maxnvalues = 0 ;
+fieldnames = 8 [ &quot;E[test1.E[class_error]]&quot; &quot;E[test1.E[linear_class_error]]&quot; &quot;E[test1.E[square_class_error]]&quot; &quot;E[test1.E[conflict]]&quot; &quot;E[test2.E[class_error]]&quot; &quot;E[test2.E[linear_class_error]]&quot; &quot;E[test2.E[square_class_error]]&quot; &quot;E[test2.E[conflict]]&quot; ] ;
+compute_covariance = 0 ;
+epsilon = 0 ;
+window = -1 ;
+full_update_frequency = -1 ;
+window_nan_code = 0 ;
+no_removal_warnings = 0 ;
+stats = 8 [ StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0.100000000000000006 ;
+max_ = 0.100000000000000006 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0.100000000000000006 ;
+last_ = 0.100000000000000006 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0.100000000000000006 ;
+max_ = 0.100000000000000006 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0.100000000000000006 ;
+last_ = 0.100000000000000006 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0.100000000000000006 ;
+max_ = 0.100000000000000006 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0.100000000000000006 ;
+last_ = 0.100000000000000006 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0 ;
+max_ = 0 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0.220000000000000001 ;
+max_ = 0.220000000000000001 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0.220000000000000001 ;
+last_ = 0.220000000000000001 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0.239999999999999991 ;
+max_ = 0.239999999999999991 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0.239999999999999991 ;
+last_ = 0.239999999999999991 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0.280000000000000027 ;
+max_ = 0.280000000000000027 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0.280000000000000027 ;
+last_ = 0.280000000000000027 ;
+binary_ = 0 ;
+integer_ = 0 ;
+counts = {};
+more_than_maxnvalues = 1  )
+StatsCollector(
+epsilon = 0 ;
+maxnvalues = 0 ;
+no_removal_warnings = 0 ;
+nmissing_ = 0 ;
+nnonmissing_ = 1 ;
+sumsquarew_ = 1 ;
+sum_ = 0 ;
+sumsquare_ = 0 ;
+sumcube_ = 0 ;
+sumfourth_ = 0 ;
+min_ = 0 ;
+max_ = 0 ;
+agmemin_ = 0 ;
+agemax_ = 0 ;
+first_ = 0 ;
+last_ = 0 ;
+binary_ = 1 ;
+integer_ = 1 ;
+counts = {};
+more_than_maxnvalues = 1  )
+] ;
+cov = 0  0  [ 
+]
+;
+sum_cross = 0  0  [ 
+]
+;
+sum_cross_weights = 0  0  [ 
+]
+;
+sum_cross_square_weights = 0  0  [ 
+]
+;
+sum_non_missing_weights = 0 ;
+sum_non_missing_square_weights = 0  )

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,120 @@
+*12 -&gt; PTester(
+    dataset = *1 -&gt; AutoVMatrix( filename = &quot;PLEARNDIR:examples/data/test_suite/linear_4x_2y_multi_class_3.vmat&quot; ),
+    expdir = &quot;expdir&quot;,
+    learner = *10 -&gt; HyperLearner(
+        dont_restart_upon_change = [ &quot;nstages&quot; ],
+        forget_when_training_set_changes = 0,
+        learner = *5 -&gt; MultiClassAdaBoost(
+            forward_sub_learner_test_costs = 1,
+            learner_template = *4 -&gt; AdaBoost(
+                compute_training_error = False,
+                early_stopping = False,
+                forward_sub_learner_test_costs = True,
+                provide_learner_expdir = True,
+                report_progress = 1,
+                test_minibatch_size = 1,
+                verbosity = 2,
+                weak_learner_template = *3 -&gt; RegressionTree(
+                    complexity_penalty_factor = 0.0,
+                    compute_train_stats = 0,
+                    forget_when_training_set_changes = 1,
+                    leave_template = *2 -&gt; RegressionTreeLeave( ),
+                    loss_function_weight = 1,
+                    maximum_number_of_nodes = 3,
+                    missing_is_valid = 0,
+                    multiclass_outputs = [
+                        0,
+                        1,
+                        2
+                        ],
+                    nstages = 4,
+                    report_progress = 1,
+                    verbosity = 2
+                    ),
+                weight_by_resampling = 0
+                ),
+            test_minibatch_size = 1
+            ),
+        nstages = 1,
+        option_fields = [ &quot;nstages&quot; ],
+        provide_learner_expdir = 1,
+        provide_strategy_expdir = 1,
+        report_progress = 1,
+        save_final_learner = 0,
+        strategy = [
+            *7 -&gt; HyperOptimize(
+                oracle = *6 -&gt; EarlyStoppingOracle(
+                    max_degradation = 3.40282e+38,
+                    max_degraded_steps = 120,
+                    max_value = 3.40282e+38,
+                    min_improvement = -3.40282e+38,
+                    min_n_steps = 2,
+                    min_value = -3.40282e+38,
+                    option = &quot;nstages&quot;,
+                    range = [
+                        1,
+                        21,
+                        1
+                        ],
+                    relative_max_degradation = -1,
+                    relative_min_improvement = -1
+                    ),
+                provide_tester_expdir = 0,
+                which_cost = &quot;E[test2.E[class_error]]&quot;
+                )
+            ],
+        tester = *9 -&gt; PTester(
+            provide_learner_expdir = 1,
+            report_stats = 1,
+            save_data_sets = 0,
+            save_initial_learners = 0,
+            save_initial_tester = 0,
+            save_learners = 0,
+            save_test_confidence = 0,
+            save_test_costs = 0,
+            save_test_names = 0,
+            save_test_outputs = 0,
+            splitter = *8 -&gt; FractionSplitter(
+                splits = 1 3 [
+                        (0, 0.75),
+                        (0, 0.75),
+                        (0.75, 1)
+                        ]
+                ),
+            statnames = [
+                &quot;E[test1.E[class_error]]&quot;,
+                &quot;E[test1.E[linear_class_error]]&quot;,
+                &quot;E[test1.E[square_class_error]]&quot;,
+                &quot;E[test1.E[conflict]]&quot;,
+                &quot;E[test2.E[class_error]]&quot;,
+                &quot;E[test2.E[linear_class_error]]&quot;,
+                &quot;E[test2.E[square_class_error]]&quot;,
+                &quot;E[test2.E[conflict]]&quot;
+                ]
+            ),
+        verbosity = 1
+        ),
+    provide_learner_expdir = 1,
+    save_learners = 1,
+    save_split_stats = 0,
+    save_test_confidence = 0,
+    save_test_costs = 1,
+    save_test_outputs = 1,
+    splitter = *11 -&gt; FractionSplitter(
+        splits = 1 3 [
+                (0, 1),
+                (0, 0.75),
+                (0.75, 1)
+                ]
+        ),
+    statnames = [
+        &quot;E[test1.E[class_error]]&quot;,
+        &quot;E[test1.E[linear_class_error]]&quot;,
+        &quot;E[test1.E[square_class_error]]&quot;,
+        &quot;E[test1.E[conflict]]&quot;,
+        &quot;E[test2.E[class_error]]&quot;,
+        &quot;E[test2.E[linear_class_error]]&quot;,
+        &quot;E[test2.E[square_class_error]]&quot;,
+        &quot;E[test2.E[conflict]]&quot;
+        ]
+    )

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat
===================================================================
(Binary files differ)


Property changes on: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/fieldnames
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/fieldnames	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/fieldnames	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,8 @@
+E[test1.E[class_error]]	0
+E[test1.E[linear_class_error]]	0
+E[test1.E[square_class_error]]	0
+E[test1.E[conflict]]	0
+E[test2.E[class_error]]	0
+E[test2.E[linear_class_error]]	0
+E[test2.E[square_class_error]]	0
+E[test2.E[conflict]]	0

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/sizes
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/sizes	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/global_stats.pmat.metadata/sizes	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1 @@
+-1 -1 -1 0 

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,4 @@
+__REVISION__ = &quot;PL9555&quot;
+conf                                          = False
+pseudo                                        = False
+tms                                           = 1

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/test_cost_names.txt
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/test_cost_names.txt	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/test_cost_names.txt	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,22 @@
+class_error
+linear_class_error
+square_class_error
+conflict
+class0
+class1
+class2
+sum_sublearner.binary_class_error
+sum_sublearner.exp_neg_margin
+sum_sublearner.class_error
+sum_sublearner.avg_weight_class_0
+sum_sublearner.avg_weight_class_1
+sum_sublearner.weighted_weak_learner.mse
+sum_sublearner.weighted_weak_learner.base_confidence
+sum_sublearner.weighted_weak_learner.base_reward_l2
+sum_sublearner.weighted_weak_learner.base_reward_l1
+sum_sublearner.weighted_weak_learner.class_error
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x1
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x2
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x3
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_x4
+sum_sublearner.weighted_weak_learner.SPLIT_VAR_y1

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,418 @@
+PTester(
+expdir = &quot;PYTEST__PL_MultiClassAdaBoost__RESULTS:expdir/&quot; ;
+dataset = *1 -&gt;AutoVMatrix(
+filename = &quot;PLEARNDIR:examples/data/test_suite/linear_4x_2y_multi_class_3.vmat&quot; ;
+load_in_memory = 0 ;
+writable = 0 ;
+length = 200 ;
+width = 6 ;
+inputsize = 5 ;
+targetsize = 1 ;
+weightsize = 0 ;
+extrasize = 0 ;
+metadatadir = &quot;PLEARNDIR:examples/data/test_suite/linear_4x_2y_multi_class_3.vmat.metadata/&quot; ;
+fieldinfos = 6 [ &quot;x1&quot; 0 &quot;x2&quot; 0 &quot;x3&quot; 0 &quot;x4&quot; 0 &quot;y1&quot; 0 &quot;target&quot; 0 ]  )
+;
+splitter = *2 -&gt;FractionSplitter(
+round_to_closest = 0 ;
+splits = 1  3  [ 
+(0 , 1 )	(0 , 0.75 )	(0.75 , 1 )	
+]
+;
+one_is_absolute = 0  )
+;
+statnames = 8 [ &quot;E[test1.E[class_error]]&quot; &quot;E[test1.E[linear_class_error]]&quot; &quot;E[test1.E[square_class_error]]&quot; &quot;E[test1.E[conflict]]&quot; &quot;E[test2.E[class_error]]&quot; &quot;E[test2.E[linear_class_error]]&quot; &quot;E[test2.E[square_class_error]]&quot; &quot;E[test2.E[conflict]]&quot; ] ;
+statmask = []
+;
+learner = *3 -&gt;HyperLearner(
+tester = *4 -&gt;PTester(
+expdir = &quot;&quot; ;
+dataset = *0 ;
+splitter = *5 -&gt;FractionSplitter(
+round_to_closest = 0 ;
+splits = 1  3  [ 
+(0 , 0.75 )	(0 , 0.75 )	(0.75 , 1 )	
+]
+;
+one_is_absolute = 0  )
+;
+statnames = 8 [ &quot;E[test1.E[class_error]]&quot; &quot;E[test1.E[linear_class_error]]&quot; &quot;E[test1.E[square_class_error]]&quot; &quot;E[test1.E[conflict]]&quot; &quot;E[test2.E[class_error]]&quot; &quot;E[test2.E[linear_class_error]]&quot; &quot;E[test2.E[square_class_error]]&quot; &quot;E[test2.E[conflict]]&quot; ] ;
+statmask = []
+;
+learner = *6 -&gt;MultiClassAdaBoost(
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 1 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827 ;
+learner1 = *7 -&gt;AdaBoost(
+weak_learners = []
+;
+voting_weights = []
+;
+sum_voting_weights = 0 ;
+initial_sum_weights = 0 ;
+example_weights = []
+;
+learners_error = []
+;
+weak_learner_template = *8 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 3 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *9 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 0 ;
+verbosity = 0 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 1  )
+;
+root = *0 ;
+priority_queue = *0 ;
+first_leave = *0 ;
+split_cols = []
+;
+split_values = []
+;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+target_error = 0.5 ;
+pseudo_loss_adaboost = 1 ;
+conf_rated_adaboost = 0 ;
+weight_by_resampling = 0 ;
+output_threshold = 0.5 ;
+provide_learner_expdir = 1 ;
+early_stopping = 0 ;
+save_often = 0 ;
+compute_training_error = 0 ;
+forward_sub_learner_test_costs = 1 ;
+modif_train_set_weights = 0 ;
+found_zero_error_weak_learner = 0 ;
+reuse_test_results = 1 ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+learner2 = *10 -&gt;AdaBoost(
+weak_learners = []
+;
+voting_weights = []
+;
+sum_voting_weights = 0 ;
+initial_sum_weights = 0 ;
+example_weights = []
+;
+learners_error = []
+;
+weak_learner_template = *11 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 3 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *12 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 0 ;
+verbosity = 0 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 1  )
+;
+root = *0 ;
+priority_queue = *0 ;
+first_leave = *0 ;
+split_cols = []
+;
+split_values = []
+;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+target_error = 0.5 ;
+pseudo_loss_adaboost = 1 ;
+conf_rated_adaboost = 0 ;
+weight_by_resampling = 0 ;
+output_threshold = 0.5 ;
+provide_learner_expdir = 1 ;
+early_stopping = 0 ;
+save_often = 0 ;
+compute_training_error = 0 ;
+forward_sub_learner_test_costs = 1 ;
+modif_train_set_weights = 0 ;
+found_zero_error_weak_learner = 0 ;
+reuse_test_results = 1 ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+forward_sub_learner_test_costs = 1 ;
+learner_template = *13 -&gt;AdaBoost(
+weak_learners = []
+;
+voting_weights = []
+;
+sum_voting_weights = 0 ;
+initial_sum_weights = 0 ;
+example_weights = []
+;
+learners_error = []
+;
+weak_learner_template = *14 -&gt;RegressionTree(
+missing_is_valid = 0 ;
+loss_function_weight = 1 ;
+maximum_number_of_nodes = 3 ;
+compute_train_stats = 0 ;
+complexity_penalty_factor = 0 ;
+output_confidence_target = 0 ;
+multiclass_outputs = 3 [ 0 1 2 ] ;
+leave_template = *15 -&gt;RegressionTreeLeave(
+id = -1 ;
+missing_leave = 0 ;
+loss_function_weight = 0 ;
+verbosity = 0 ;
+length = 0 ;
+weights_sum = 0 ;
+targets_sum = 0 ;
+weighted_targets_sum = 0 ;
+weighted_squared_targets_sum = 0 ;
+loss_function_factor = 1  )
+;
+root = *0 ;
+priority_queue = *0 ;
+first_leave = *0 ;
+split_cols = []
+;
+split_values = []
+;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 1 ;
+nstages = 4 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+target_error = 0.5 ;
+pseudo_loss_adaboost = 1 ;
+conf_rated_adaboost = 0 ;
+weight_by_resampling = 0 ;
+output_threshold = 0.5 ;
+provide_learner_expdir = 1 ;
+early_stopping = 0 ;
+save_often = 0 ;
+compute_training_error = 0 ;
+forward_sub_learner_test_costs = 1 ;
+modif_train_set_weights = 0 ;
+found_zero_error_weak_learner = 0 ;
+reuse_test_results = 1 ;
+random_gen = *0 ;
+seed = 1827 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 2 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+ )
+;
+perf_evaluators = {};
+report_stats = 1 ;
+save_initial_tester = 0 ;
+save_stat_collectors = 1 ;
+save_split_stats = 1 ;
+save_learners = 0 ;
+save_initial_learners = 0 ;
+save_data_sets = 0 ;
+save_test_outputs = 0 ;
+call_forget_in_run = 1 ;
+save_test_costs = 0 ;
+save_test_names = 0 ;
+provide_learner_expdir = 1 ;
+should_train = 1 ;
+should_test = 1 ;
+template_stats_collector = *0 ;
+global_template_stats_collector = *0 ;
+final_commands = []
+;
+save_test_confidence = 0 ;
+enforce_clean_expdir = 1 ;
+redirect_stdout = 0 ;
+redirect_stderr = 0  )
+;
+option_fields = 1 [ &quot;nstages&quot; ] ;
+dont_restart_upon_change = 1 [ &quot;nstages&quot; ] ;
+strategy = 1 [ *16 -&gt;HyperOptimize(
+which_cost = &quot;E[test2.E[class_error]]&quot; ;
+min_n_trials = 0 ;
+oracle = *17 -&gt;EarlyStoppingOracle(
+option = &quot;nstages&quot; ;
+values = []
+;
+range = 3 [ 1 21 1 ] ;
+min_value = -3.40282000000000014e+38 ;
+max_value = 3.40282000000000014e+38 ;
+max_degradation = 3.40282000000000014e+38 ;
+relative_max_degradation = -1 ;
+min_improvement = -3.40282000000000014e+38 ;
+relative_min_improvement = -1 ;
+max_degraded_steps = 120 ;
+min_n_steps = 2 ;
+nreturned = 0 ;
+best_objective = 1.79769313486231571e+308 ;
+best_step = -1 ;
+met_early_stopping = 0  )
+;
+provide_tester_expdir = 0 ;
+sub_strategy = []
+;
+rerun_after_sub = 0 ;
+provide_sub_expdir = 1 ;
+save_best_learner = 0 ;
+splitter = *0 ;
+auto_save = 0 ;
+auto_save_diff_time = 10800 ;
+auto_save_test = 0 ;
+best_objective = 1.79769313486231571e+308 ;
+best_results = []
+;
+best_learner = *0 ;
+trialnum = 0 ;
+option_vals = []
+;
+verbosity = 0  )
+] ;
+provide_strategy_expdir = 1 ;
+save_final_learner = 0 ;
+learner = *6  ;
+provide_learner_expdir = 1 ;
+expdir_append = &quot;&quot; ;
+forward_nstages = 0 ;
+random_gen = *0 ;
+stage = 0 ;
+n_examples = -1 ;
+inputsize = -1 ;
+targetsize = -1 ;
+weightsize = -1 ;
+forget_when_training_set_changes = 0 ;
+nstages = 1 ;
+report_progress = 1 ;
+verbosity = 1 ;
+nservers = 0 ;
+save_trainingset_prefix = &quot;&quot; ;
+test_minibatch_size = 1 ;
+use_a_separate_random_generator_for_testing = 1827  )
+;
+perf_evaluators = {};
+report_stats = 1 ;
+save_initial_tester = 1 ;
+save_stat_collectors = 1 ;
+save_split_stats = 0 ;
+save_learners = 1 ;
+save_initial_learners = 0 ;
+save_data_sets = 0 ;
+save_test_outputs = 1 ;
+call_forget_in_run = 1 ;
+save_test_costs = 1 ;
+save_test_names = 1 ;
+provide_learner_expdir = 1 ;
+should_train = 1 ;
+should_test = 1 ;
+template_stats_collector = *0 ;
+global_template_stats_collector = *0 ;
+final_commands = []
+;
+save_test_confidence = 0 ;
+enforce_clean_expdir = 1 ;
+redirect_stdout = 0 ;
+redirect_stderr = 0  )

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/train_cost_names.txt
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/train_cost_names.txt	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/train_cost_names.txt	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,8 @@
+E[test1.E[class_error]]
+E[test1.E[linear_class_error]]
+E[test1.E[square_class_error]]
+E[test1.E[conflict]]
+E[test2.E[class_error]]
+E[test2.E[linear_class_error]]
+E[test2.E[square_class_error]]
+E[test2.E[conflict]]

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,103 @@
+import os.path
+from plearn.pyplearn import *
+plarg_defaults.conf    = False
+plarg_defaults.pseudo  = False
+plarg_defaults.tms     = 1
+
+learner=pl.MultiClassAdaBoost( 
+    forward_sub_learner_test_costs=1,
+    test_minibatch_size=plargs.tms,
+    learner_template = pl.AdaBoost(
+        weak_learner_template=pl.RegressionTree(
+            nstages = 4,
+            loss_function_weight = 1,
+            missing_is_valid = 0,
+            multiclass_outputs = [0, 1, 2],
+            maximum_number_of_nodes = 3,
+            compute_train_stats = 0,
+            complexity_penalty_factor = 0.0,
+            verbosity = 2,
+            report_progress = 1,
+            forget_when_training_set_changes = 1,
+            leave_template = pl.RegressionTreeLeave( )
+            ),
+        test_minibatch_size=plargs.tms,
+        weight_by_resampling=0,
+        #modif_train_set_weights=plargs.modif_train_set_weights;
+        early_stopping=False,
+        compute_training_error=False,
+        forward_sub_learner_test_costs=True,
+        provide_learner_expdir=True,
+        report_progress = 1,
+        verbosity = 2
+        )
+)
+
+learner=learner = pl.HyperLearner(
+    option_fields = [ &quot;nstages&quot; ],
+    dont_restart_upon_change = [ &quot;nstages&quot; ] ,
+    provide_strategy_expdir = 1 ,
+    save_final_learner = 0 ,
+    provide_learner_expdir = 1 ,
+    forget_when_training_set_changes = 0 ,
+    nstages = 1 ,
+    report_progress = 1 ,
+    verbosity = 1 ,
+    learner = learner,
+    tester = pl.PTester(
+        splitter = pl.FractionSplitter(splits = TMat(1,3,[ (0,0.75), (0,.75), (0.75,1) ])),
+        statnames = [
+            'E[test1.E[class_error]]',  'E[test1.E[linear_class_error]]',  'E[test1.E[square_class_error]]',  'E[test1.E[conflict]]',
+            'E[test2.E[class_error]]',  'E[test2.E[linear_class_error]]',  'E[test2.E[square_class_error]]',  'E[test2.E[conflict]]' ],
+        save_test_outputs = 0 ,
+        report_stats = 1  ,
+        save_initial_tester = 0 ,
+        save_learners = 0 ,
+        save_initial_learners = 0  ,
+        save_data_sets = 0  ,
+        save_test_costs = 0  ,
+        provide_learner_expdir = 1  ,
+        save_test_confidence = 0  ,
+        save_test_names = 0,
+        ),
+    strategy = [
+
+    pl.HyperOptimize(
+            which_cost = &quot;E[test2.E[class_error]]&quot; ,
+            provide_tester_expdir = 0 ,
+            oracle = pl.EarlyStoppingOracle(
+                option = &quot;nstages&quot; ,
+                range = [ 1, 21, 1 ],
+                min_value = -3.40282e+38 ,
+                max_value = 3.40282e+38 ,
+                max_degradation = 3.40282e+38 ,
+                relative_max_degradation = -1 ,
+                min_improvement = -3.40282e+38 ,
+                relative_min_improvement = -1 ,
+                max_degraded_steps = 120 ,
+                min_n_steps = 2 
+                )  # end of EarlyStoppingOracle
+            )  # end of sub_strategy.HyperOptimize
+    ]  # end of HyperLearner strategy
+    )
+splitter = pl.FractionSplitter(
+    splits = TMat(1,3, [ (0,1), (0,0.75), (0.75,1) ])
+    )
+tester = pl.PTester(
+    expdir = plargs.expdir,
+    dataset = pl.AutoVMatrix(filename=&quot;PLEARNDIR:examples/data/test_suite/linear_4x_2y_multi_class_3.vmat&quot;),
+    splitter = splitter,
+    learner = learner,
+    statnames = [
+        'E[test1.E[class_error]]',  'E[test1.E[linear_class_error]]',  'E[test1.E[square_class_error]]',  'E[test1.E[conflict]]',
+        'E[test2.E[class_error]]',  'E[test2.E[linear_class_error]]',  'E[test2.E[square_class_error]]',  'E[test2.E[conflict]]' ],
+    provide_learner_expdir = 1,
+    save_test_costs = 1,
+    save_test_outputs = 1,
+    save_test_confidence = 0,
+    save_learners = 1,
+    save_split_stats = 0#not need as their is only one split
+    )
+
+def main():
+    return tester

Added: trunk/plearn_learners/meta/test/MultiClassAdaBoost/pytest.config
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/pytest.config	2008-10-21 19:44:24 UTC (rev 9600)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/pytest.config	2008-10-21 19:58:07 UTC (rev 9601)
@@ -0,0 +1,109 @@
+&quot;&quot;&quot;Pytest config file.
+
+Test is a class regrouping the elements that define a test for PyTest.
+    
+    For each Test instance you declare in a config file, a test will be ran
+    by PyTest.
+    
+      @ivar(name):
+    The name of the Test must uniquely determine the
+    test. Among others, it will be used to identify the test's results
+    (.PyTest/name/*_results/) and to report test informations.
+      @type(name):
+    String
+    
+      @ivar(description):
+    The description must provide other users an
+    insight of what exactly is the Test testing. You are encouraged
+    to used triple quoted strings for indented multi-lines
+    descriptions.
+      @type(description):
+    String
+    
+      @ivar(category):
+    The category to which this test belongs. By default, a
+    test is considered a 'General' test.
+    
+    It is not desirable to let an extensive and lengthy test as 'General',
+    while one shall refrain abusive use of categories since it is likely
+    that only 'General' tests will be ran before most commits...
+    
+      @type(category):
+    string
+    
+      @ivar(program):
+    The program to be run by the Test. The program's name
+    PRGNAME is used to lookup for the program in the following manner:
+    
+    1) Look for a local program named PRGNAME
+    2) Look for a plearn-like command (plearn, plearn_tests, ...) named PRGNAME
+    3) Call 'which PRGNAME'
+    4) Fail
+    
+    Compilable program should provide the keyword argument 'compiler'
+    mapping to a string interpreted as the compiler name (e.g.
+    &quot;compiler = 'pymake'&quot;). If no compiler is provided while the program is
+    believed to be compilable, 'pymake' will be assigned by
+    default. Arguments to be forwarded to the compiler can be provided as a
+    string through the 'compile_options' keyword argument.  @type program:
+    Program
+    
+      @ivar(arguments):
+    The command line arguments to be passed to the program
+    for the test to proceed.
+      @type(arguments):
+    String
+    
+      @ivar(resources):
+    A list of resources that are used by your program
+    either in the command line or directly in the code (plearn or pyplearn
+    files, databases, ...).  The elements of the list must be string
+    representations of the path, absolute or relative, to the resource.
+      @type(resources):
+    List of Strings
+    
+      @ivar(precision):
+    The precision (absolute and relative) used when comparing
+    floating numbers in the test output (default = 1e-6)
+      @type(precision):
+    float
+    
+      @ivar(pfileprg):
+    The program to be used for comparing files of psave &amp;
+    vmat formats. It can be either:
+      - &quot;__program__&quot;: maps to this test's program if its compilable;
+    maps to 'plearn_tests' otherwise (default);
+      - &quot;__plearn__&quot;: always maps to 'plearn_tests' (for when the program
+    under test is not a version of PLearn);
+      - A Program (see 'program' option) instance
+      - None: if you are sure no files are to be compared.
+    
+      @ivar(ignored_files_re):
+    Default behaviour of a test is to compare all
+    files created by running the test. In some case, one may prefer some of
+    these files to be ignored.
+      @type(ignored_files_re):
+    list of regular expressions
+    
+      @ivar(disabled):
+    If true, the test will not be ran.
+      @type(disabled):
+    bool
+    
+&quot;&quot;&quot;
+Test(
+    name = &quot;PL_MultiClassAdaBoost&quot;,
+    description = &quot;&quot;,
+    category = &quot;General&quot;,
+    program = Program(
+        name = &quot;plearn_tests&quot;,
+        compiler = &quot;pymake&quot;
+        ),
+    arguments = &quot;PL_MutiClassAdaBoost.pyplearn&quot;,
+    resources = [ &quot;PL_MutiClassAdaBoost.pyplearn&quot; ],
+    precision = 1e-06,
+    pfileprg = &quot;__program__&quot;,
+    disabled = False,
+    runtime = None,
+    difftime = None
+    )


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003040.html">[Plearn-commits] r9600 - in trunk: plearn/math plearn_learners/meta
</A></li>
	<LI>Next message: <A HREF="003042.html">[Plearn-commits] r9602 - in	trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir:	. Split0
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3041">[ date ]</a>
              <a href="thread.html#3041">[ thread ]</a>
              <a href="subject.html#3041">[ subject ]</a>
              <a href="author.html#3041">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
