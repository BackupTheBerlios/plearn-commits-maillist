<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6655 - trunk/plearn/ker
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-February/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6655%20-%20trunk/plearn/ker&In-Reply-To=%3C200702131657.l1DGvwHv031508%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000103.html">
   <LINK REL="Next"  HREF="000105.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6655 - trunk/plearn/ker</H1>
    <B>chapados at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6655%20-%20trunk/plearn/ker&In-Reply-To=%3C200702131657.l1DGvwHv031508%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6655 - trunk/plearn/ker">chapados at mail.berlios.de
       </A><BR>
    <I>Tue Feb 13 17:57:58 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000103.html">[Plearn-commits] r6654 - trunk/python_modules/plearn/math
</A></li>
        <LI>Next message: <A HREF="000105.html">[Plearn-commits] r6656 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#104">[ date ]</a>
              <a href="thread.html#104">[ thread ]</a>
              <a href="subject.html#104">[ subject ]</a>
              <a href="author.html#104">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: chapados
Date: 2007-02-13 17:57:57 +0100 (Tue, 13 Feb 2007)
New Revision: 6655

Added:
   trunk/plearn/ker/MemoryCachedKernel.cc
   trunk/plearn/ker/MemoryCachedKernel.h
Log:
Kernel that implements some caching utilities to avoid virtual calls

Added: trunk/plearn/ker/MemoryCachedKernel.cc
===================================================================
--- trunk/plearn/ker/MemoryCachedKernel.cc	2007-02-13 16:46:03 UTC (rev 6654)
+++ trunk/plearn/ker/MemoryCachedKernel.cc	2007-02-13 16:57:57 UTC (rev 6655)
@@ -0,0 +1,160 @@
+// -*- C++ -*-
+
+// MemoryCachedKernel.cc
+//
+// Copyright (C) 2007 Nicolas Chapados
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Nicolas Chapados
+
+/*! \file MemoryCachedKernel.cc */
+
+
+#include &quot;MemoryCachedKernel.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_ABSTRACT_OBJECT(
+    MemoryCachedKernel,
+    &quot;Provide some memory-management utilities for kernels.&quot;,
+    &quot;This class is intended as a base class to provide some memory management\n&quot;
+    &quot;utilities for the data-matrix set with setDataForKernelMatrix function.  In\n&quot;
+    &quot;particular, it provides a single (inline, non-virtual) function to access a\n&quot;
+    &quot;given input vector of the data matrix.  If the data VMatrix passed to\n&quot;
+    &quot;setDataForKernelMatrix is within a certain size threshold, the VMatrix is\n&quot;
+    &quot;converted to a Mat and cached to memory (without requiring additional space\n&quot;
+    &quot;if the VMatrix is actually a MemoryVMatrix), and all further element access\n&quot;
+    &quot;are done without requiring virtual function calls.\n&quot;
+    &quot;\n&quot;
+    &quot;IMPORTANT NOTE: the 'cache_gram_matrix' option is enabled automatically by\n&quot;
+    &quot;default for this class.  This makes the computation of the Gram matrix\n&quot;
+    &quot;derivatives (with respect to kernel hyperparameters) quite faster in many\n&quot;
+    &quot;cases.  If you really don't want this caching to occur, just set it\n&quot;
+    &quot;explicitly to false.\n&quot;
+    &quot;\n&quot;
+    &quot;This class also provides utility functions to derived classes to compute\n&quot;
+    &quot;the Gram matrix and its derivative (with respect to kernel hyperparameters)\n&quot;
+    &quot;without requiring virtual function calls in data access or evaluation\n&quot;
+    &quot;function.\n&quot;
+    );
+
+
+//#####  MemoryCachedKernel::MemoryCachedKernel  ##############################
+
+MemoryCachedKernel::MemoryCachedKernel()
+    : m_cache_threshold(1000000)
+{
+    cache_gram_matrix = true;
+}
+
+
+//#####  declareOptions  ######################################################
+
+void MemoryCachedKernel::declareOptions(OptionList&amp; ol)
+{
+    declareOption(
+        ol, &quot;cache_threshold&quot;, &amp;MemoryCachedKernel::m_cache_threshold,
+        OptionBase::buildoption,
+        &quot;Threshold on the number of elements to cache the data VMatrix into a\n&quot;
+        &quot;real matrix.  Above this threshold, the VMatrix is left as-is, and\n&quot;
+        &quot;element access remains virtual.  (Default value = 1000000)\n&quot;);
+    
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+
+//#####  build  ###############################################################
+
+void MemoryCachedKernel::build()
+{
+    // ### Nothing to add here, simply calls build_
+    inherited::build();
+    build_();
+}
+
+
+//#####  build_  ##############################################################
+
+void MemoryCachedKernel::build_()
+{ }
+
+
+//#####  makeDeepCopyFromShallowCopy  #########################################
+
+void MemoryCachedKernel::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField(m_data_cache, copies);
+}
+
+
+//#####  setDataForKernelMatrix  ##############################################
+
+void MemoryCachedKernel::setDataForKernelMatrix(VMat the_data)
+{
+    inherited::setDataForKernelMatrix(the_data);
+
+    if (the_data.width() * the_data.length() &lt;= m_cache_threshold &amp;&amp;
+        the_data.isNotNull())
+    {
+        m_data_cache = the_data.toMat();
+    }
+    else
+        m_data_cache = Mat();
+}
+
+
+//#####  addDataForKernelMatrix  ##############################################
+
+void MemoryCachedKernel::addDataForKernelMatrix(const Vec&amp; newrow)
+{
+    inherited::addDataForKernelMatrix(newrow);
+
+    if (m_data_cache.isNotNull())
+        m_data_cache.appendRow(newrow);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/ker/MemoryCachedKernel.h
===================================================================
--- trunk/plearn/ker/MemoryCachedKernel.h	2007-02-13 16:46:03 UTC (rev 6654)
+++ trunk/plearn/ker/MemoryCachedKernel.h	2007-02-13 16:57:57 UTC (rev 6655)
@@ -0,0 +1,318 @@
+// -*- C++ -*-
+
+// MemoryCachedKernel.h
+//
+// Copyright (C) 2007 Nicolas Chapados
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Nicolas Chapados
+
+/*! \file MemoryCachedKernel.h */
+
+
+#ifndef MemoryCachedKernel_INC
+#define MemoryCachedKernel_INC
+
+#include &lt;plearn/ker/Kernel.h&gt;
+
+namespace PLearn {
+
+/**
+ *  Provide some memory-management utilities for kernels.
+ *
+ *  This class is intended as a base class to provide some memory management
+ *  utilities for the data-matrix set with setDataForKernelMatrix function.  In
+ *  particular, it provides a single (inline, non-virtual) function to access a
+ *  given input vector of the data matrix.  If the data VMatrix passed to
+ *  setDataForKernelMatrix is within a certain size threshold, the VMatrix is
+ *  converted to a Mat and cached to memory (without requiring additional space
+ *  if the VMatrix is actually a MemoryVMatrix), and all further element access
+ *  are done without requiring virtual function calls.
+ *
+ *  IMPORTANT NOTE: the 'cache_gram_matrix' option is enabled automatically by
+ *  default for this class.  This makes the computation of the Gram matrix
+ *  derivatives (with respect to kernel hyperparameters) quite faster in many
+ *  cases.  If you really don't want this caching to occur, just set it
+ *  explicitly to false.
+ *
+ *  This class also provides utility functions to derived classes to compute
+ *  the Gram matrix and its derivative (with respect to kernel hyperparameters)
+ *  without requiring virtual function calls in data access or evaluation
+ *  function.
+ */
+class MemoryCachedKernel : public Kernel
+{
+    typedef Kernel inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    /**
+     *  Threshold on the number of elements to cache the data VMatrix into a
+     *  real matrix.  Above this threshold, the VMatrix is left as-is, and
+     *  element access remains virtual.  (Default value = 1000000)
+     */
+    int m_cache_threshold;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    MemoryCachedKernel();
+
+
+    //#####  Kernel Member Functions  #########################################
+
+    //! Optionally cache the data to a real Mat if its number of elements lies
+    //! within the threshold.
+    virtual void setDataForKernelMatrix(VMat the_data);
+
+    //! Update the cache if a new row is added to the data
+    virtual void addDataForKernelMatrix(const Vec&amp; newRow);
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    PLEARN_DECLARE_ABSTRACT_OBJECT(MemoryCachedKernel);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+    /**
+     *  Interface for derived classes: access row i of the data matrix.  Note:
+     *  the contents of the Vec SHOULD ABSOLUTELY NOT BE MODIFIED after calling
+     *  this function.  For performance, the Vec may not contain a copy of the
+     *  input vector, but may point to the original data
+     */
+    inline void dataRow(int i, Vec&amp; row) const;
+
+    /**
+     *  Interface to ease derived-class implementation of computeGramMatrix
+     *  that avoids virtual function calls in kernel evaluation.  The
+     *  computeGramMatrixNV function should be called directly by the
+     *  implementation of computeGramMatrix in a derived class, passing the
+     *  name of the derived class as a template argument.
+     */
+    template &lt;class DerivedClass&gt;
+    void computeGramMatrixNV(Mat K, const DerivedClass* This) const;
+
+    /**
+     *  Interface to ease derived-class implementation of
+     *  computeGramMatrixDerivative, that avoids virtual function calls as much
+     *  as possible.  This template is instantiated with a member function
+     *  pointer in the derived class to compute the actual element-wise
+     *  derivative (with respect to some kernel hyperparameter, depending on
+     *  which a different member pointer is passed).  Both GCC 3.3.6 and 4.0.3
+     *  (which I tested on) generate very efficient code to call a member
+     *  function passed as a template argument within a loop [although the
+     *  generated code looks very different in both cases].
+     *
+     *  The member function is called with the following arguments:
+     *
+     *  - x1  : element at row i of the data matrix
+     *  - x2  : element at row j of the data matrix
+     *  - K   : kernel value for (x1,x2); obtained from cache if available
+     *  - arg : integer argument passed to the function; may be used to index
+     *          into a vector of hyperparameters
+     *
+     *  The last argument to computeGramMatrixDerivNV,
+     *  'derivative_func_requires_K', specifies whether the derivativeFunc
+     *  requires the value of K in order to compute the derivative.  Passing
+     *  the value 'false' can avoid unnecessary kernel computations in cases
+     *  where the Gram matrix is not cached.  In this case, the derivativeFunc
+     *  is called with a MISSING_VALUE for its argument K.
+     */
+    template &lt;class DerivedClass,
+              real (DerivedClass::*derivativeFunc)(const Vec&amp;, const Vec&amp;, real, int) const&gt;
+    void computeGramMatrixDerivNV(Mat&amp; KD, const DerivedClass* This, int arg,
+                                  bool derivative_func_requires_K = true) const;
+    
+    
+private:
+    //! This does the actual building.
+    void build_();
+
+private:
+    //! In-memory cache of the data matrix
+    Mat m_data_cache;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(MemoryCachedKernel);
+
+
+//#####  dataRow  #############################################################
+
+inline void MemoryCachedKernel::dataRow(int i, Vec&amp; row) const
+{
+    if (m_data_cache.isNotNull()) {
+        row = m_data_cache(i);
+        row.subVecSelf(0, dataInputsize());
+    }
+    else {
+        row.resize(dataInputsize());
+        data-&gt;getSubRow(i, 0, row);
+    }
+}
+
+
+//#####  computeGramMatrixNV  #################################################
+
+template &lt;class DerivedClass&gt;
+void MemoryCachedKernel::computeGramMatrixNV(Mat K, const DerivedClass* This) const
+{
+    if (!data)
+        PLERROR(&quot;Kernel::computeGramMatrix: setDataForKernelMatrix not yet called&quot;);
+    if (!is_symmetric)
+        PLERROR(&quot;Kernel::computeGramMatrix: not supported for non-symmetric kernels&quot;);
+    if (K.length() != data.length() || K.width() != data.length())
+        PLERROR(&quot;Kernel::computeGramMatrix: the argument matrix K should be\n&quot;
+                &quot;of size %d x %d (currently of size %d x %d)&quot;,
+                data.length(), data.length(), K.length(), K.width());
+    if (cache_gram_matrix &amp;&amp; gram_matrix_is_cached) {
+        K &lt;&lt; gram_matrix;
+        return;
+    }
+                
+    int l=data-&gt;length();
+    int m=K.mod();
+    PP&lt;ProgressBar&gt; pb;
+    int count = 0;
+    if (report_progress)
+        pb = new ProgressBar(&quot;Computing Gram matrix for &quot; + classname(),
+                             (l * (l + 1)) / 2);
+
+    Vec row_i, row_j;
+    real Kij;
+    real* Ki;
+    real* Kji;
+    for (int i=0 ; i&lt;l ; ++i) {
+        Ki = K[i];
+        Kji = &amp;K[0][i];
+        dataRow(i, row_i);
+        for (int j=0; j&lt;=i; ++j, Kji += m) {
+            dataRow(j, row_j);
+            Kij = This-&gt;DerivedClass::evaluate(row_i, row_j);
+            *Ki++ = Kij;
+            if (j&lt;i)
+                *Kji = Kij;
+        }
+        if (report_progress) {
+            count += i + 1;
+            PLASSERT( pb );
+            pb-&gt;update(count);
+        }
+    }
+    if (cache_gram_matrix) {
+        gram_matrix.resize(l,l);
+        gram_matrix &lt;&lt; K;
+        gram_matrix_is_cached = true;
+    }
+}
+
+
+//#####  computeGramMatrixDerivNV  ############################################
+
+template &lt;class DerivedClass,
+          real (DerivedClass::*derivativeFunc)(const Vec&amp;, const Vec&amp;, real, int) const&gt;
+void MemoryCachedKernel::computeGramMatrixDerivNV(Mat&amp; KD, const DerivedClass* This,
+                                                  int arg, bool require_K) const
+{
+    if (!data)
+        PLERROR(&quot;Kernel::computeGramMatrixDerivative: &quot;
+                &quot;setDataForKernelMatrix not yet called&quot;);
+    if (!is_symmetric)
+        PLERROR(&quot;Kernel::computeGramMatrixDerivative: &quot;
+                &quot;not supported for non-symmetric kernels&quot;);
+
+    int W = nExamples();
+    KD.resize(W,W);
+    int m=KD.mod();
+    
+    Vec row_i, row_j;
+    real KDij;
+    real* KDi;
+    real* KDji;
+    real  K  = MISSING_VALUE;
+    real* Ki = 0;                       // Current row of kernel matrix, if cached
+
+    for (int i=0 ; i&lt;W ; ++i) {
+        KDi  = KD[i];
+        KDji = &amp;KD[0][i];
+        dataRow(i, row_i);
+        if (gram_matrix_is_cached)
+            Ki = gram_matrix[i];
+        
+        for (int j=0 ; j &lt;= i ; ++j, KDji += m) {
+            dataRow(j, row_j);
+
+            // Access the current kernel value depending on whether it's cached
+            if (Ki)
+                K = *Ki++;
+            else if (require_K)
+                K = This-&gt;DerivedClass::evaluate(row_i, row_j);
+
+            // Compute and store the derivative
+            KDij   = (This-&gt;*derivativeFunc)(row_i, row_j, K, arg);
+            *KDi++ = KDij;
+            if (j &lt; i)
+                *KDji = KDij;
+        }
+    }
+}
+
+
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000103.html">[Plearn-commits] r6654 - trunk/python_modules/plearn/math
</A></li>
	<LI>Next message: <A HREF="000105.html">[Plearn-commits] r6656 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#104">[ date ]</a>
              <a href="thread.html#104">[ thread ]</a>
              <a href="subject.html#104">[ subject ]</a>
              <a href="author.html#104">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
