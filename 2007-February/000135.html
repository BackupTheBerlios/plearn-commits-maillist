<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r6686 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-February/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6686%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200702270235.l1R2ZOxn029913%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000134.html">
   <LINK REL="Next"  HREF="000136.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r6686 - trunk/plearn_learners/online</H1>
    <B>yoshua at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r6686%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200702270235.l1R2ZOxn029913%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r6686 - trunk/plearn_learners/online">yoshua at mail.berlios.de
       </A><BR>
    <I>Tue Feb 27 03:35:24 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000134.html">[Plearn-commits] r6685 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000136.html">[Plearn-commits] r6687 - trunk
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#135">[ date ]</a>
              <a href="thread.html#135">[ thread ]</a>
              <a href="subject.html#135">[ subject ]</a>
              <a href="author.html#135">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: yoshua
Date: 2007-02-27 03:35:23 +0100 (Tue, 27 Feb 2007)
New Revision: 6686

Modified:
   trunk/plearn_learners/online/DeepBeliefNet.cc
   trunk/plearn_learners/online/DeepBeliefNet.h
Log:


Modified: trunk/plearn_learners/online/DeepBeliefNet.cc
===================================================================
--- trunk/plearn_learners/online/DeepBeliefNet.cc	2007-02-26 22:39:58 UTC (rev 6685)
+++ trunk/plearn_learners/online/DeepBeliefNet.cc	2007-02-27 02:35:23 UTC (rev 6686)
@@ -547,7 +547,7 @@
         {
             int sample = stage % nsamples;
             train_set-&gt;getExample(sample, input, target, weight);
-            onlineStep( input, target );
+            onlineStep( input, target, train_costs );
             if( pb )
                 pb-&gt;update( stage + 1 );
         }
@@ -702,20 +702,18 @@
     train_stats-&gt;finalize();
 }
 
-void DeepBeliefNet::onlineStep( const Vec&amp; input, const Vec&amp; target)
+void DeepBeliefNet::onlineStep( const Vec&amp; input, const Vec&amp; target, Vec&amp; train_costs)
 {
-#if 0
     Vec cost;
     if (partial_costs)
         cost.resize(n_layers);
 
     layers[0]-&gt;expectation &lt;&lt; input;
-    for( int i=0 ; i&lt;n_layers ; i++ )
+    for( int i=0 ; i&lt;n_layers-1 ; i++ )
     {
         // mean-field fprop from layer i to layer i+1
-
         Vec input;
-        if (i==n_layers-1 &amp;&amp; use_classification_cost) // top layer is a joint layer
+        if (i==n_layers-1 &amp;&amp; use_classification_cost) // if top layer is a joint layer
         {
             // set the input of the joint layer 
             Vec joint_exp = joint_layer-&gt;expectation;
@@ -725,17 +723,19 @@
                           (int) round(target[0]), 0., 1. );
             classification_module-&gt;joint_connection-&gt;setAsDownInput(
                 joint_layer-&gt;expectation );
+            // this does the actual matrix-vector computation
             layers[ n_layers-1 ]-&gt;getAllActivations(
                 get_pointer( classification_module-&gt;joint_connection ) );
         }
         else
         {
             connections[i]-&gt;setAsDownInput( layers[i]-&gt;expectation );
+            // this does the actual matrix-vector computation
             layers[i+1]-&gt;getAllActivations( connections[i] );
         }
         layers[i+1]-&gt;computeExpectation();
 
-        // propagate into local cost
+        // propagate into local cost associated to this layer
         if( partial_costs &amp;&amp; partial_costs[ i ] )
         {
             partial_costs[ i ]-&gt;fprop( layers[ i+1 ]-&gt;expectation,
@@ -744,15 +744,14 @@
             // Backward pass
             partial_costs[ i ]-&gt;bpropUpdate( layers[ i+1 ]-&gt;expectation,
                                              target, cost,
+                                             // first time we set these gradients: do not accumulate
                                              expectation_gradients[ i+1 ] );
-            // HACK: since the update will combine the gradients from all sources,
-            // weigh the gradients according to the desired learning rates
-            expectation_gradients[i+1] *= grad_learning_rate/cd_learning_rate;
         }
         else
             expectation_gradients[i+1].clear();
 
-        if( i==n_layers-1 &amp;&amp; final_cost )
+        // top layer may be connected to a final_module followed by a final_cost
+        if( i==n_layers-2 &amp;&amp; final_cost )
         {
             if( final_module )
             {
@@ -761,14 +760,11 @@
                 final_cost-&gt;fprop( final_cost_input, target, final_cost_value );
                 final_cost-&gt;bpropUpdate( final_cost_input, target,
                                          final_cost_value[0],
-                                         final_cost_gradient );
-                // HACK: since the update will combine the gradients from all sources,
-                // weigh the gradients according to the desired learning rates
-                final_cost_gradient *= grad_learning_rate/cd_learning_rate;
+                                         final_cost_gradient ); //gradient on final_cost_input
                 final_module-&gt;bpropUpdate( layers[ n_layers-1 ]-&gt;expectation,
                                            final_cost_input,
                                            expectation_gradients[ n_layers-1 ],
-                                           final_cost_gradient );
+                                           final_cost_gradient, true );
             }
             else
             {
@@ -776,9 +772,16 @@
                                    final_cost_value );
                 final_cost-&gt;bpropUpdate( layers[ n_layers-1 ]-&gt;expectation,
                                          target, final_cost_value[0],
-                                         expectation_gradients[ n_layers-1 ] );
+                                         expectation_gradients[ n_layers-1 ],
+                                         true);
             }
 
+            // HACK: since the update will combine the gradients from all sources,
+            // weigh the gradients according to the desired learning rates
+            expectation_gradients[i+1] *= grad_learning_rate/cd_learning_rate;
+
+// HERE
+
             train_costs[final_cost_index] = final_cost_value[0];
 
             layers[ n_layers-1 ]-&gt;bpropUpdate( layers[ n_layers-1 ]-&gt;activation,
@@ -798,14 +801,10 @@
 
     }
         
-        contrastiveDivergenceStep( layers[ i ],
-                                   connections[ i ],
-                                   layers[ i+1 ] );
+    //contrastiveDivergenceStep( layers[ i ],
+    //                           connections[ i ],
+    //                           layers[ i+1 ] );
 
-    }
-    // fprop in joint layer
-#endif
-    
 }
 
 void DeepBeliefNet::greedyStep( const Vec&amp; input, const Vec&amp; target, int index )

Modified: trunk/plearn_learners/online/DeepBeliefNet.h
===================================================================
--- trunk/plearn_learners/online/DeepBeliefNet.h	2007-02-26 22:39:58 UTC (rev 6685)
+++ trunk/plearn_learners/online/DeepBeliefNet.h	2007-02-27 02:35:23 UTC (rev 6686)
@@ -188,7 +188,7 @@
     virtual TVec&lt;std::string&gt; getTrainCostNames() const;
 
 
-    void onlineStep( const Vec&amp; input, const Vec&amp; target );
+    void onlineStep( const Vec&amp; input, const Vec&amp; target, Vec&amp; train_costs );
 
     void greedyStep( const Vec&amp; input, const Vec&amp; target, int index );
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000134.html">[Plearn-commits] r6685 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000136.html">[Plearn-commits] r6687 - trunk
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#135">[ date ]</a>
              <a href="thread.html#135">[ thread ]</a>
              <a href="subject.html#135">[ subject ]</a>
              <a href="author.html#135">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
