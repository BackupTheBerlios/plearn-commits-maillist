<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8630 - trunk/plearn_learners/online
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-March/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8630%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200803051903.m25J3Jap027409%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002077.html">
   <LINK REL="Next"  HREF="002079.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8630 - trunk/plearn_learners/online</H1>
    <B>larocheh at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8630%20-%20trunk/plearn_learners/online&In-Reply-To=%3C200803051903.m25J3Jap027409%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8630 - trunk/plearn_learners/online">larocheh at mail.berlios.de
       </A><BR>
    <I>Wed Mar  5 20:03:19 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002077.html">[Plearn-commits] r8629 - trunk/plearn_learners/regressors
</A></li>
        <LI>Next message: <A HREF="002079.html">[Plearn-commits] r8631 - trunk/plearn/vmat
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2078">[ date ]</a>
              <a href="thread.html#2078">[ thread ]</a>
              <a href="subject.html#2078">[ subject ]</a>
              <a href="author.html#2078">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: larocheh
Date: 2008-03-05 20:03:19 +0100 (Wed, 05 Mar 2008)
New Revision: 8630

Modified:
   trunk/plearn_learners/online/RBMWoodsLayer.cc
   trunk/plearn_learners/online/RBMWoodsLayer.h
Log:
Added an option to have samples in {-1,1}


Modified: trunk/plearn_learners/online/RBMWoodsLayer.cc
===================================================================
--- trunk/plearn_learners/online/RBMWoodsLayer.cc	2008-03-04 19:43:35 UTC (rev 8629)
+++ trunk/plearn_learners/online/RBMWoodsLayer.cc	2008-03-05 19:03:19 UTC (rev 8630)
@@ -53,7 +53,8 @@
 RBMWoodsLayer::RBMWoodsLayer( real the_learning_rate ) :
     inherited( the_learning_rate ),
     n_trees( 10 ),
-    tree_depth( 3 )
+    tree_depth( 3 ),
+    use_signed_samples( false )
 {
 }
 
@@ -68,7 +69,10 @@
     PLCHECK_MSG(expectation_is_up_to_date, &quot;Expectation should be computed &quot;
             &quot;before calling generateSample()&quot;);
 
-    sample.clear();
+    if(use_signed_samples)
+        sample.fill(-1);
+    else
+        sample.clear();
 
     int n_nodes_per_tree = size / n_trees;    
     int node, depth, node_sample, sub_tree_size;
@@ -83,8 +87,11 @@
         {
             node_sample = random_gen-&gt;binomial_sample( 
                 local_node_expectation[ node + offset ] );
-            sample[node + offset] = node_sample;
-
+            if( use_signed_samples )
+                sample[node + offset] = 2*node_sample-1;
+            else
+                sample[node + offset] = node_sample;
+            
             // Descending in the tree
             sub_tree_size /= 2;
             if ( node_sample &gt; 0.5 )
@@ -115,156 +122,12 @@
 
 void RBMWoodsLayer::computeProbabilisticClustering(Vec&amp; prob_clusters)
 {
-    int n_nodes_per_tree = size / n_trees;    
-    int n_leaves = n_nodes_per_tree+1;
-    prob_clusters.resize( n_trees * n_leaves );
-    int node, depth, sub_tree_size, grand_parent;
+    computeExpectation();
     int offset = 0;
-    bool left_of_grand_parent;
-    real grand_parent_prob;
-
-    // Get local expectations at every node
-    
-    // Divide and conquer computation of local (conditional) free energies
+    int n_nodes_per_tree = size / n_trees;
+    prob_clusters.resize(n_trees*(n_nodes_per_tree+1));
     for( int t=0; t&lt;n_trees; t++ )
     {
-        depth = tree_depth-1;
-        sub_tree_size = 0;
-
-        // Initialize last level
-        for( int n=sub_tree_size; n&lt;n_nodes_per_tree; n += 2*sub_tree_size + 2 )
-        {
-            //on_free_energy[ n + offset ] = safeexp(activation[n+offset]);
-            //off_free_energy[ n + offset ] = 1;
-            // Now working in log-domain
-            on_free_energy[ n + offset ] = activation[n+offset];
-            off_free_energy[ n + offset ] = 0;
-            
-        }
-
-        depth = tree_depth-2;
-        sub_tree_size = 1;
-
-        while( depth &gt;= 0 )
-        {
-            for( int n=sub_tree_size; n&lt;n_nodes_per_tree; n += 2*sub_tree_size + 2 )
-            {
-                //on_free_energy[ n + offset ] = safeexp(activation[n+offset]) * 
-                //    ( on_free_energy[n + offset - sub_tree_size] + off_free_energy[n + offset - sub_tree_size] ) ;
-                //off_free_energy[ n + offset ] = 
-                //    ( on_free_energy[n + offset + sub_tree_size] + off_free_energy[n + offset + sub_tree_size] ) ;
-                // Now working in log-domain
-                on_free_energy[ n + offset ] = activation[n+offset] + 
-                    logadd( on_free_energy[n + offset - sub_tree_size],
-                            off_free_energy[n + offset - sub_tree_size] ) ;
-                off_free_energy[ n + offset ] = 
-                    logadd( on_free_energy[n + offset + sub_tree_size],
-                            off_free_energy[n + offset + sub_tree_size] ) ;
-
-            }
-            sub_tree_size = 2 * ( sub_tree_size + 1 ) - 1;
-            depth--;
-        }
-        offset += n_nodes_per_tree;
-    }    
-    
-    for( int i=0 ; i&lt;size ; i++ )
-        //local_node_expectation[i] = on_free_energy[i] / ( on_free_energy[i] + off_free_energy[i] );
-        // Now working in log-domain
-        local_node_expectation[i] = safeexp(on_free_energy[i] 
-                                            - logadd(on_free_energy[i], off_free_energy[i]));
-
-    // Compute marginal expectations over clustering
-    offset = 0;
-    for( int t=0; t&lt;n_trees; t++ )
-    {
-        // Initialize root        
-        node = n_nodes_per_tree / 2;
-        expectation[ node + offset ] = local_node_expectation[ node + offset ];
-        off_expectation[ node + offset ] = (1 - local_node_expectation[ node + offset ]);
-        sub_tree_size = node;
-
-        // First level nodes
-        depth = 1;
-        sub_tree_size /= 2;
-
-        // Left child
-        node = sub_tree_size;
-        expectation[ node + offset ] = local_node_expectation[ node + offset ]
-            * local_node_expectation[ node + offset + sub_tree_size + 1 ];
-        off_expectation[ node + offset ] = (1 - local_node_expectation[ node + offset ])
-            * local_node_expectation[ node + offset + sub_tree_size + 1 ];
-        
-        // Right child
-        node = 3*sub_tree_size+2;
-        expectation[ node + offset ] = local_node_expectation[ node + offset ]
-            * (1 - local_node_expectation[ node + offset - sub_tree_size - 1 ]);
-        off_expectation[ node + offset ] = (1 - local_node_expectation[ node + offset ])
-            * (1 - local_node_expectation[ node + offset - sub_tree_size - 1 ]);
-
-        // Set other nodes, level-wise
-        depth = 2;
-        sub_tree_size /= 2;
-        while( depth &lt; tree_depth )
-        {
-            // Left child
-            left_of_grand_parent = true;
-            for( int n=sub_tree_size; n&lt;n_nodes_per_tree; n += 4*sub_tree_size + 4 )
-            {
-                if( left_of_grand_parent )
-                {
-                    grand_parent = n + offset + 3*sub_tree_size + 3;
-                    grand_parent_prob = expectation[ grand_parent ];
-                    left_of_grand_parent = false;
-                }
-                else
-                {
-                    grand_parent = n + offset - sub_tree_size - 1;
-                    grand_parent_prob = off_expectation[ grand_parent ];
-                    left_of_grand_parent = true;
-                }
-
-                expectation[ n + offset ] = local_node_expectation[ n + offset ]
-                    * local_node_expectation[ n + offset + sub_tree_size + 1 ]
-                    * grand_parent_prob;
-                off_expectation[ n + offset ] = (1 - local_node_expectation[ n + offset ])
-                    * local_node_expectation[ n + offset + sub_tree_size + 1 ]
-                    * grand_parent_prob;
-            }
-
-            // Right child
-            left_of_grand_parent = true;
-            for( int n=3*sub_tree_size+2; n&lt;n_nodes_per_tree; n += 4*sub_tree_size + 4 )
-            {
-                if( left_of_grand_parent )
-                {
-                    grand_parent = n + offset + sub_tree_size + 1;
-                    grand_parent_prob = expectation[ grand_parent ];
-                    left_of_grand_parent = false;
-                }
-                else
-                {
-                    grand_parent = n + offset - 3*sub_tree_size - 3;
-                    grand_parent_prob = off_expectation[ grand_parent ];
-                    left_of_grand_parent = true;
-                }
-
-                expectation[ n + offset ] = local_node_expectation[ n + offset ]
-                    * (1 - local_node_expectation[ n + offset - sub_tree_size - 1 ])
-                    * grand_parent_prob;
-                off_expectation[ n + offset ] = (1 - local_node_expectation[ n + offset ])
-                    * (1 - local_node_expectation[ n + offset - sub_tree_size - 1 ])
-                    * grand_parent_prob;
-            }
-            sub_tree_size /= 2;
-            depth++;
-        }
-        offset += n_nodes_per_tree;
-    }
-
-    offset = 0;
-    for( int t=0; t&lt;n_trees; t++ )
-    {
         for( int i=0; i&lt;n_nodes_per_tree; i = i+2)
             prob_clusters[i+offset+t] = expectation[i+offset];
         for( int i=0; i&lt;n_nodes_per_tree; i = i+2)
@@ -302,8 +165,10 @@
             //off_free_energy[ n + offset ] = 1;
             // Now working in log-domain
             on_free_energy[ n + offset ] = activation[n+offset];
-            off_free_energy[ n + offset ] = 0;
-            
+            if( use_signed_samples )
+                off_free_energy[ n + offset ] = -activation[n+offset];
+            else
+                off_free_energy[ n + offset ] = 0;
         }
 
         depth = tree_depth-2;
@@ -321,10 +186,15 @@
                 on_free_energy[ n + offset ] = activation[n+offset] + 
                     logadd( on_free_energy[n + offset - (sub_tree_size/2+1)],
                             off_free_energy[n + offset - (sub_tree_size/2+1)] ) ;
-                off_free_energy[ n + offset ] = 
-                    logadd( on_free_energy[n + offset + (sub_tree_size/2+1)],
-                            off_free_energy[n + offset + (sub_tree_size/2+1)] ) ;
-
+                if( use_signed_samples )
+                    off_free_energy[ n + offset ] = -activation[n+offset] +
+                        logadd( on_free_energy[n + offset + (sub_tree_size/2+1)],
+                                off_free_energy[n + offset + (sub_tree_size/2+1)] ) ;
+                else
+                    off_free_energy[ n + offset ] = 
+                        logadd( on_free_energy[n + offset + (sub_tree_size/2+1)],
+                                off_free_energy[n + offset + (sub_tree_size/2+1)] ) ;
+                
             }
             sub_tree_size = 2 * ( sub_tree_size + 1 ) - 1;
             depth--;
@@ -472,7 +342,10 @@
             //off_free_energy[ n + offset ] = 1;
             // Now working in log-domain
             on_free_energy[ n + offset ] = input[n+offset] + bias[n+offset];
-            off_free_energy[ n + offset ] = 0;            
+            if( use_signed_samples )
+                off_free_energy[ n + offset ] = -(input[n+offset] + bias[n+offset]);
+            else
+                off_free_energy[ n + offset ] = 0;
         }
 
         depth = tree_depth-2;
@@ -490,9 +363,14 @@
                 on_free_energy[ n + offset ] = input[n+offset] + bias[n+offset] +
                     logadd( on_free_energy[n + offset - (sub_tree_size/2+1)], 
                             off_free_energy[n + offset - (sub_tree_size/2+1)] ) ;
-                off_free_energy[ n + offset ] = 
-                    logadd( on_free_energy[n + offset + (sub_tree_size/2+1)], 
-                            off_free_energy[n + offset + (sub_tree_size/2+1)] ) ;
+                if( use_signed_samples )
+                    off_free_energy[ n + offset ] = -(input[n+offset] + bias[n+offset]) +
+                        logadd( on_free_energy[n + offset + (sub_tree_size/2+1)], 
+                                off_free_energy[n + offset + (sub_tree_size/2+1)] ) ;
+                else
+                    off_free_energy[ n + offset ] = 
+                        logadd( on_free_energy[n + offset + (sub_tree_size/2+1)], 
+                                off_free_energy[n + offset + (sub_tree_size/2+1)] ) ;
             }
             sub_tree_size = 2 * ( sub_tree_size + 1 ) - 1;
             depth--;
@@ -826,6 +704,8 @@
 
                 out_grad = off_free_energy_gradient[ n + offset ];
                 node_exp = local_node_expectation[n + offset + (sub_tree_size/2+1)];
+                if( use_signed_samples )
+                    input_gradient[n+offset] -= out_grad;
                 on_free_energy_gradient[n + offset + (sub_tree_size/2+1)] += out_grad * node_exp; 
                 off_free_energy_gradient[n + offset + (sub_tree_size/2+1)] += 
                     out_grad * (1 - node_exp); 
@@ -838,7 +718,11 @@
         sub_tree_size = 0;
 
         for( int n=sub_tree_size; n&lt;n_nodes_per_tree; n += 2*sub_tree_size + 2 )
+        {
             input_gradient[n+offset] += on_free_energy_gradient[ n + offset ];
+            if( use_signed_samples )
+                input_gradient[n+offset] -= off_free_energy_gradient[ n + offset ];                
+        }
 
         offset += n_nodes_per_tree;
     }
@@ -1084,6 +968,10 @@
                   &quot;Depth of the trees in the woods (1 gives the ordinary &quot;
                   &quot;RBMBinomialLayer).&quot;);
 
+    declareOption(ol, &quot;use_signed_samples&quot;, &amp;RBMWoodsLayer::use_signed_samples,
+                  OptionBase::buildoption,
+                  &quot;Indication that samples should be in {-1,1}, not {0,1}.&quot;);
+
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
 }

Modified: trunk/plearn_learners/online/RBMWoodsLayer.h
===================================================================
--- trunk/plearn_learners/online/RBMWoodsLayer.h	2008-03-04 19:43:35 UTC (rev 8629)
+++ trunk/plearn_learners/online/RBMWoodsLayer.h	2008-03-05 19:03:19 UTC (rev 8630)
@@ -62,6 +62,9 @@
     // Depth of the trees in the woods (1 gives the ordinary RBMBinomialLayer)
     int tree_depth;
 
+    // Indication that samples should be in {-1,1}, not {0,1}
+    bool use_signed_samples;
+
 public:
     //#####  Public Member Functions  #########################################
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002077.html">[Plearn-commits] r8629 - trunk/plearn_learners/regressors
</A></li>
	<LI>Next message: <A HREF="002079.html">[Plearn-commits] r8631 - trunk/plearn/vmat
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2078">[ date ]</a>
              <a href="thread.html#2078">[ thread ]</a>
              <a href="subject.html#2078">[ subject ]</a>
              <a href="author.html#2078">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
