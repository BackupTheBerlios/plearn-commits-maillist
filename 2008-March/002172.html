<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r8723 - trunk/plearn_learners/meta
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-March/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8723%20-%20trunk/plearn_learners/meta&In-Reply-To=%3C200803262018.m2QKI0Jr018099%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002170.html">
   <LINK REL="Next"  HREF="002171.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r8723 - trunk/plearn_learners/meta</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r8723%20-%20trunk/plearn_learners/meta&In-Reply-To=%3C200803262018.m2QKI0Jr018099%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r8723 - trunk/plearn_learners/meta">nouiz at mail.berlios.de
       </A><BR>
    <I>Wed Mar 26 21:18:00 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002170.html">[Plearn-commits] r8722 - trunk/commands/PLearnCommands
</A></li>
        <LI>Next message: <A HREF="002171.html">[Plearn-commits] r8724 - trunk/python_modules/plearn/parallel
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2172">[ date ]</a>
              <a href="thread.html#2172">[ thread ]</a>
              <a href="subject.html#2172">[ subject ]</a>
              <a href="author.html#2172">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2008-03-26 21:18:00 +0100 (Wed, 26 Mar 2008)
New Revision: 8723

Modified:
   trunk/plearn_learners/meta/AdaBoost.cc
   trunk/plearn_learners/meta/AdaBoost.h
   trunk/plearn_learners/meta/MultiClassAdaBoost.cc
   trunk/plearn_learners/meta/MultiClassAdaBoost.h
Log:
-Adaboost now compute output as in the standard way of plearn.
-To compute output at an earlier stage, we must retrain with the wanted nstages. AdaBoost will revert to this stage.
  
This was done to simplify other part that was complicated by the fact that it was not done in the normal plearn way.


Modified: trunk/plearn_learners/meta/AdaBoost.cc
===================================================================
--- trunk/plearn_learners/meta/AdaBoost.cc	2008-03-26 18:35:37 UTC (rev 8722)
+++ trunk/plearn_learners/meta/AdaBoost.cc	2008-03-26 20:18:00 UTC (rev 8723)
@@ -220,25 +220,6 @@
     inherited::declareOptions(ol);
 }
 
-////////////////////
-// declareMethods //
-////////////////////
-void AdaBoost::declareMethods(RemoteMethodMap&amp; rmm)
-{
-    // Insert a backpointer to remote methods; note that this
-    // different than for declareOptions()
-    rmm.inherited(inherited::_getRemoteMethodMap_());
-
-    declareMethod(
-        rmm, &quot;computeOutput_at_stage&quot;, &amp;AdaBoost::remote_computeOutput_at_stage,
-        (BodyDoc(&quot;On a trained learner, this computes the output from the &quot;
-                 &quot;input with the first stage weak learner. There must be &quot;
-                 &quot;enough weak learners that have been trained&quot;),
-         ArgDoc (&quot;input&quot;, &quot;Input vector (should have width inputsize)&quot;),
-         ArgDoc (&quot;stage&quot;, &quot;The number of stage to use to compute the output&quot;),
-         RetDoc (&quot;Computed output (will have width outputsize)&quot;)));
-
-}
 void AdaBoost::build_()
 {
     if(conf_rated_adaboost &amp;&amp; pseudo_loss_adaboost)
@@ -289,19 +270,10 @@
 
 void AdaBoost::train()
 {
-    if(!train_set)
-        PLERROR(&quot;In AdaBoost::train, you did not setTrainingSet&quot;);
-    
-    if(!train_stats &amp;&amp; compute_training_error)
-        PLERROR(&quot;In AdaBoost::train, you did not setTrainStatsCollector&quot;);
-
-    if (train_set-&gt;targetsize()!=1)
-        PLERROR(&quot;In AdaBoost::train, targetsize should be 1, found %d&quot;, 
-                train_set-&gt;targetsize());
-
     if (nstages &lt; stage){        //!&lt; Asking to revert to previous stage
         PLCHECK(nstages&gt;0); // should use forget
-        cout&lt;&lt;&quot;In AdaBoost::train() - reverting to an old stage &quot;&lt;&lt;stage&lt;&lt;&quot; with nstages &quot;&lt;&lt;nstages&lt;&lt;endl;
+        cout&lt;&lt;&quot;In AdaBoost::train() - reverting from stage &quot;&lt;&lt;stage
+            &lt;&lt;&quot; to stage &quot;&lt;&lt;nstages&lt;&lt;endl;
         stage = nstages;
         PLCHECK(learners_error.size()&gt;=stage);
         PLCHECK(weak_learners.size()&gt;=stage);
@@ -322,6 +294,16 @@
         PLERROR(&quot;In AdaBoost::train() -  we can't retrain a reverted learner...&quot;);
     }
     
+    if(!train_set)
+        PLERROR(&quot;In AdaBoost::train, you did not setTrainingSet&quot;);
+    
+    if(!train_stats &amp;&amp; compute_training_error)
+        PLERROR(&quot;In AdaBoost::train, you did not setTrainStatsCollector&quot;);
+
+    if (train_set-&gt;targetsize()!=1)
+        PLERROR(&quot;In AdaBoost::train, targetsize should be 1, found %d&quot;, 
+                train_set-&gt;targetsize());
+
     if(found_zero_error_weak_learner) // Training is over...
         return;
 
@@ -692,28 +674,11 @@
 
 void AdaBoost::computeOutput(const Vec&amp; input, Vec&amp; output) const
 {
-    computeOutput(input,output,voting_weights.length());
-}
-void AdaBoost::computeOutput(const Vec&amp; input, Vec&amp; output, int nb_learner) const
-{
-    if(nb_learner&lt;0)
-        nb_learner=weak_learners.size();
-    PLASSERT(nb_learner&gt;0);
-    real local_sum_weight = sum_voting_weights;
-    if (nb_learner&gt;voting_weights.length() and not found_zero_error_weak_learner){
-        PLERROR(&quot;AdaBoost::computeOutput - Asked to compute the output with more learner(%d) then currently learned %d&quot;,
-                nb_learner,voting_weights.length());
-    }else if(nb_learner&gt;voting_weights.length()){
-        nb_learner=voting_weights.length();
-    }else if(nb_learner != voting_weights.length()){
-        local_sum_weight = 0;
-        for (int i=0;i&lt;nb_learner;i++)
-            local_sum_weight += voting_weights[i];
-    }
-    output.resize(weak_learner_template-&gt;outputsize());
+    PLASSERT(weak_learners.size()&gt;0);
+    
     real sum_out=0;
-    weak_learner_output.resize(output.size());
-    for (int i=0;i&lt;nb_learner;i++)
+    weak_learner_output.resize(weak_learners[0]-&gt;outputsize());
+    for (int i=0;i&lt;weak_learners.size();i++)
     {
         weak_learners[i]-&gt;computeOutput(input,weak_learner_output);
         if(!pseudo_loss_adaboost &amp;&amp; !conf_rated_adaboost)
@@ -722,7 +687,7 @@
         else
             sum_out += weak_learner_output[0]*voting_weights[i];
     }
-    output[0] = sum_out/local_sum_weight;
+    output[0] = sum_out/sum_voting_weights;
     output.resize(1);
 }
 
@@ -805,16 +770,6 @@
     return costs;
 }
 
-//! Version of computeOutput that returns a result by value
-Vec AdaBoost::remote_computeOutput_at_stage(const Vec&amp; input,
-                                            const int stage) const
-{
-    tmp_output2.resize(outputsize());
-    computeOutput(input, tmp_output2, stage);
-    return tmp_output2;
-}
-
-
 void AdaBoost::computeTrainingError(Vec input, Vec target)
 {
     if (compute_training_error)

Modified: trunk/plearn_learners/meta/AdaBoost.h
===================================================================
--- trunk/plearn_learners/meta/AdaBoost.h	2008-03-26 18:35:37 UTC (rev 8722)
+++ trunk/plearn_learners/meta/AdaBoost.h	2008-03-26 20:18:00 UTC (rev 8723)
@@ -142,13 +142,6 @@
     //! This does the actual building. 
     void build_();
 
-    // List of methods that are called by Remote Method Invocation.  Our
-    // convention is to have them start with the remote_ prefix.
-
-    //! Compute output at a given stage. Note that the returned vector may
-    //! be modified by subsequent use of this object, and thus should be copied
-    //! if it needs to be stored safely.
-    Vec remote_computeOutput_at_stage(const Vec&amp; input, const int stage) const;
     void computeTrainingError(Vec input, Vec target);
 
 protected: 
@@ -156,9 +149,6 @@
     // (Please implement in .cc)
     static void declareOptions(OptionList&amp; ol);
 
-    //! Declare the methods that are remote-callable
-    static void declareMethods(RemoteMethodMap&amp; rmm);
-
 public:
 
     // ************************
@@ -200,10 +190,6 @@
     //! Computes the output from the input
     virtual void computeOutput(const Vec&amp; input, Vec&amp; output) const;
 
-    //! Computes the output from the input with a specific number of learner
-    //! This way we don't need to save the learner at each stage, we can save just the last one
-    void computeOutput(const Vec&amp; input, Vec&amp; output, int nb_learner) const;
-
     //! Computes the costs from already computed output. 
     virtual void computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output, 
                                          const Vec&amp; target, Vec&amp; costs) const;

Modified: trunk/plearn_learners/meta/MultiClassAdaBoost.cc
===================================================================
--- trunk/plearn_learners/meta/MultiClassAdaBoost.cc	2008-03-26 18:35:37 UTC (rev 8722)
+++ trunk/plearn_learners/meta/MultiClassAdaBoost.cc	2008-03-26 20:18:00 UTC (rev 8723)
@@ -112,6 +112,9 @@
     // ###    options have been modified.
     // ### You should assume that the parent class' build_() has already been
     // ### called.
+    sub_target_tmp.resize(2);
+    for(int i=0;i&lt;sub_target_tmp.size();i++)
+        sub_target_tmp[i].resize(1);
 }
 
 // ### Nothing to add here, simply calls build_
@@ -198,23 +201,32 @@
     }
     */
     PLWARNING(&quot;In MultiClassAdaBoost::train() - not implemented, should be already trained&quot;);
+    int stage1=learner1.stage;
+    int stage2=learner2.stage;
+
+    if(stage1&gt;0 &amp;&amp; stage1&lt;nb_stage_to_use)
+        PLERROR(&quot;In  MultiClassAdaBoost::train() - asked to use more stage then already trained for learner1&quot;);
+    if(stage2&gt;0 &amp;&amp; stage2&lt;nb_stage_to_use)
+        PLERROR(&quot;In  MultiClassAdaBoost::train() - asked to use more stage then already trained for learner1&quot;);
+    if(nb_stage_to_use&gt;0){
+        learner1.nstages=nb_stage_to_use;
+        learner1.train();
+    }
+    if(nb_stage_to_use&gt;0){
+        learner2.nstages=nb_stage_to_use;
+        learner2.train();
+    }
 }
 
 void MultiClassAdaBoost::computeOutput(const Vec&amp; input, Vec&amp; output) const
 {
-    output.resize(outputsize());
-
     Vec tmp1(learner1.outputsize());
     Vec tmp2(learner2.outputsize());
-    if(nb_stage_to_use!=-1){
-        learner1.computeOutput(input,tmp1,nb_stage_to_use);
-        learner2.computeOutput(input,tmp2,nb_stage_to_use);
-    }else{
-        learner1.computeOutput(input,tmp1);
-        learner2.computeOutput(input,tmp2);
-    }
+    learner1.computeOutput(input,tmp1);
+    learner2.computeOutput(input,tmp2);
     int ind1=int(round(tmp1[0]));
     int ind2=int(round(tmp2[0]));
+
     int ind=-1;
     if(ind1==0 &amp;&amp; ind2==0)
         ind=0;
@@ -240,9 +252,12 @@
     Vec output2(learner2.outputsize());
     Vec subcosts1(learner1.nTestCosts());
     Vec subcosts2(learner1.nTestCosts());
+    getSubLearnerTarget(target, sub_target_tmp);
 
-    learner1.computeOutputAndCosts(input, target, output1, subcosts1);
-    learner2.computeOutputAndCosts(input, target, output2, subcosts2);
+    learner1.computeOutputAndCosts(input, sub_target_tmp[0],
+                                   output1, subcosts1);
+    learner2.computeOutputAndCosts(input, sub_target_tmp[1],
+                                   output2, subcosts2);
 
     int ind1=int(round(output1[0]));
     int ind2=int(round(output2[0]));
@@ -277,19 +292,6 @@
 
     if(forward_sub_learner_test_costs){
         costs.resize(7);
-        Vec subcosts1(learner1.nTestCosts());
-        Vec subcosts2(learner1.nTestCosts());
-        Vec target1(0,1), target2(0,1);
-        if(fast_is_equal(target[0],0.)){
-            target1.append(0);
-            target2.append(0);
-        }else if(fast_is_equal(target[0],1.)){
-            target1.append(1);
-            target2.append(0);
-        }else if(fast_is_equal(target[0],2.)){
-            target1.append(1);
-            target2.append(1);
-        }
         subcosts1+=subcosts2;
         costs.append(subcosts1);
     }
@@ -323,19 +325,10 @@
         costs.resize(7);
         Vec subcosts1(learner1.nTestCosts());
         Vec subcosts2(learner1.nTestCosts());
-        Vec target1(0,1), target2(0,1);
-        if(fast_is_equal(target[0],0.)){
-            target1.append(0);
-            target2.append(0);
-        }else if(fast_is_equal(target[0],1.)){
-            target1.append(1);
-            target2.append(0);
-        }else if(fast_is_equal(target[0],2.)){
-            target1.append(1);
-            target2.append(1);
-        }
-        learner1.computeCostsOnly(input,target1,subcosts1);
-        learner2.computeCostsOnly(input,target2,subcosts2);
+        getSubLearnerTarget(target, sub_target_tmp);
+
+        learner1.computeCostsOnly(input,sub_target_tmp[0],subcosts1);
+        learner2.computeCostsOnly(input,sub_target_tmp[1],subcosts2);
         subcosts1+=subcosts2;
         costs.append(subcosts1);
     }
@@ -379,7 +372,28 @@
     return names;
 }
 
-
+void MultiClassAdaBoost::getSubLearnerTarget(Vec target,
+                                             TVec&lt;Vec&gt; sub_target) 
+{
+    if(fast_is_equal(target[0],0.)){
+        sub_target[0]=0;
+        sub_target[1]=0;
+    }else if(fast_is_equal(target[0],1.)){
+        sub_target[0]=1;
+        sub_target[1]=0;
+    }else if(fast_is_equal(target[0],2.)){
+        sub_target[0]=1;
+        sub_target[1]=1;
+    }else if(target[0]&gt;2){
+        PLWARNING(&quot;In MultiClassAdaBoost::getSubLearnerTarget - &quot;
+                  &quot;We only support target 0/1/2. We got %f. We transform &quot;
+                  &quot;it to a target of 2.&quot;, target[0]);
+        sub_target[0]=1;
+        sub_target[1]=1;
+    }else
+        PLERROR(&quot;In MultiClassAdaBoost::getSubLearnerTarget - &quot;
+                  &quot;We only support target 0/1/2. We got %f.&quot;, target[0]); 
+}
 } // end of namespace PLearn
 
 

Modified: trunk/plearn_learners/meta/MultiClassAdaBoost.h
===================================================================
--- trunk/plearn_learners/meta/MultiClassAdaBoost.h	2008-03-26 18:35:37 UTC (rev 8722)
+++ trunk/plearn_learners/meta/MultiClassAdaBoost.h	2008-03-26 20:18:00 UTC (rev 8723)
@@ -156,6 +156,9 @@
     // (PLEASE IMPLEMENT IN .cc)
     virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
 
+
+//    virtual void setTrainingSet(VMat training_set, bool call_forget=true);
+
 protected:
     //#####  Protected Options  ###############################################
 
@@ -176,9 +179,10 @@
     // (PLEASE IMPLEMENT IN .cc)
     void build_();
 
+    static void getSubLearnerTarget(Vec target, TVec&lt;Vec&gt; sub_target);
 private:
     //#####  Private Data Members  ############################################
-
+    TVec&lt;Vec&gt; sub_target_tmp;
 };
 
 // Declares a few other classes and functions related to this class


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002170.html">[Plearn-commits] r8722 - trunk/commands/PLearnCommands
</A></li>
	<LI>Next message: <A HREF="002171.html">[Plearn-commits] r8724 - trunk/python_modules/plearn/parallel
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2172">[ date ]</a>
              <a href="thread.html#2172">[ thread ]</a>
              <a href="subject.html#2172">[ subject ]</a>
              <a href="author.html#2172">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
