<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7517 - trunk/python_modules/plearn/learners/autolr
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7517%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200706041442.l54EgFp3022914%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000965.html">
   <LINK REL="Next"  HREF="000967.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7517 - trunk/python_modules/plearn/learners/autolr</H1>
    <B>tihocan at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7517%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200706041442.l54EgFp3022914%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7517 - trunk/python_modules/plearn/learners/autolr">tihocan at mail.berlios.de
       </A><BR>
    <I>Mon Jun  4 16:42:15 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000965.html">[Plearn-commits] r7516 - in trunk/python_modules/plearn/learners:	autolr online
</A></li>
        <LI>Next message: <A HREF="000967.html">[Plearn-commits] r7518 - in trunk/python_modules/plearn/learners: .	autolr online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#966">[ date ]</a>
              <a href="thread.html#966">[ thread ]</a>
              <a href="subject.html#966">[ subject ]</a>
              <a href="author.html#966">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: tihocan
Date: 2007-06-04 16:42:15 +0200 (Mon, 04 Jun 2007)
New Revision: 7517

Modified:
   trunk/python_modules/plearn/learners/autolr/__init__.py
Log:
Added comments

Modified: trunk/python_modules/plearn/learners/autolr/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/autolr/__init__.py	2007-06-04 14:38:29 UTC (rev 7516)
+++ trunk/python_modules/plearn/learners/autolr/__init__.py	2007-06-04 14:42:15 UTC (rev 7517)
@@ -210,21 +210,21 @@
 
 def train_adapting_lr(learner,
                       trainset,testsets,expdir,
-                      lr_options,
-                      optimized_group=0,
-                      schedules=None,
-                      nstages=None,
-                      epoch=None,
-                      initial_lr=0.1,
-                      nskip=2,
-                      cost_to_select_best=0,
+                      lr_options, # List of lists of options (one list/group of options with a given schedule)
+                      optimized_group=0, # Group of options that is actually optimized
+                      schedules=None, # Matrix of schedules (number of columns = 1 (stage) + number of groups)
+                      nstages=None, # Used to construct default schedule if 'schedules' is None
+                      epoch=None,   # &quot;&quot;
+                      initial_lr=0.1, # Starting value for group being optimized
+                      nskip=2,   # Number of epochs after which we add/remove candidates
+                      cost_to_select_best=0, # Index of cost being optimized
                       return_best_model=False, # o/w return final model
                       save_best=False, # for paranoids: save best model each time an improvement is found
                       selected_costnames = False,
                       min_epochs_to_delete = 2,
-                      lr_steps=exp(log(10)/2),
+                      lr_steps=exp(log(10)/2), # Scaling coefficient when modifying learning rates
                       logfile=False,
-                      keep_lr=2):
+                      keep_lr=2): # Learning rate interval for heuristic
 
     min_epochs_to_delete = max(1,min_epochs_to_delete) # although 1 is probably too small
 
@@ -406,6 +406,11 @@
     schedules[:,1+optimized_group]=all_results[best_active][:,1]
     if logfile and best_err &lt; all_last_err[best_active]:
         print &gt;&gt;logfile, &quot;WARNING: best performing model would have stopped early at stage &quot;,best_early_stop
-    return (final_model,schedules,all_results[best_active], 
-            all_results,all_last_err,all_start,best_early_stop)
+    return (final_model,   # Learner
+            schedules,     # Matrix of schedules (including the one that was optimized)
+            all_results[best_active], # Error curve (matrix) for best model
+            all_results, # List of all error curve matrices
+            all_last_err, # List of all last errors recorded for each candidate (not necessarily at last epoch)
+            all_start,  # Epoch index where each candidate was created (not necessarily the first epoch)
+            best_early_stop) # Timestep (in stages) at which early-stopping should have happened (i.e. stage of best error found)
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000965.html">[Plearn-commits] r7516 - in trunk/python_modules/plearn/learners:	autolr online
</A></li>
	<LI>Next message: <A HREF="000967.html">[Plearn-commits] r7518 - in trunk/python_modules/plearn/learners: .	autolr online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#966">[ date ]</a>
              <a href="thread.html#966">[ thread ]</a>
              <a href="subject.html#966">[ subject ]</a>
              <a href="author.html#966">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
