<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7538 - in trunk: plearn/display	plearn_learners/generic/EXPERIMENTAL	python_modules/plearn/plotting python_modules/plearn/var
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7538%20-%20in%20trunk%3A%20plearn/display%0A%09plearn_learners/generic/EXPERIMENTAL%0A%09python_modules/plearn/plotting%20python_modules/plearn/var&In-Reply-To=%3C200706051604.l55G4GRc019463%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000986.html">
   <LINK REL="Next"  HREF="000988.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7538 - in trunk: plearn/display	plearn_learners/generic/EXPERIMENTAL	python_modules/plearn/plotting python_modules/plearn/var</H1>
    <B>simonl at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7538%20-%20in%20trunk%3A%20plearn/display%0A%09plearn_learners/generic/EXPERIMENTAL%0A%09python_modules/plearn/plotting%20python_modules/plearn/var&In-Reply-To=%3C200706051604.l55G4GRc019463%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7538 - in trunk: plearn/display	plearn_learners/generic/EXPERIMENTAL	python_modules/plearn/plotting python_modules/plearn/var">simonl at mail.berlios.de
       </A><BR>
    <I>Tue Jun  5 18:04:16 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000986.html">[Plearn-commits] r7537 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="000988.html">[Plearn-commits] r7539 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#987">[ date ]</a>
              <a href="thread.html#987">[ thread ]</a>
              <a href="subject.html#987">[ subject ]</a>
              <a href="author.html#987">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: simonl
Date: 2007-06-05 18:04:16 +0200 (Tue, 05 Jun 2007)
New Revision: 7538

Modified:
   trunk/plearn/display/DisplayUtils.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
   trunk/python_modules/plearn/plotting/netplot.py
   trunk/python_modules/plearn/var/Var.py
Log:
Added some options for displaying values of graphs in DisplayUtils.cc
improved deepReconstructorNet dans his friends netplot.py and Var.py


Modified: trunk/plearn/display/DisplayUtils.cc
===================================================================
--- trunk/plearn/display/DisplayUtils.cc	2007-06-05 14:55:53 UTC (rev 7537)
+++ trunk/plearn/display/DisplayUtils.cc	2007-06-05 16:04:16 UTC (rev 7538)
@@ -303,6 +303,14 @@
 }
 
 
+  //! returns a subvector made of the (max) n &quot;central&quot; values of v
+  Vec centerSubVec(Vec v, int n=16)
+  {
+    int l = v.length();
+    if(l&lt;=n)
+      return v;    
+    return v.subVec((l-n)/2,n);
+  }
 
 /** VarGraph **/
 
@@ -478,7 +486,7 @@
       PStream str_descr = openString(descr, PStream::raw_ascii, &quot;w&quot;);
       str_descr &lt;&lt; v;
 
-      if(display_values &amp;&amp; v-&gt;size() &lt;= 16)
+      if(display_values)
         {
           gs.usefont(&quot;Times-Bold&quot;, 11.0);
           gs.centerShow(my_x, my_y+boxheight/4, descr.c_str());
@@ -487,14 +495,14 @@
           gs.usefont(&quot;Courrier&quot;, 6.0);
           if (v-&gt;rValue.length()&gt;0) // print rvalue if there are some...
           {
-            gs.centerShow(my_x, my_y-boxheight/5, v-&gt;value);
-            gs.centerShow(my_x, my_y-boxheight/3, v-&gt;gradient);
-            gs.centerShow(my_x, my_y-boxheight/1, v-&gt;rValue);
+            gs.centerShow(my_x, my_y-boxheight/5, centerSubVec(v-&gt;value));
+            gs.centerShow(my_x, my_y-boxheight/3, centerSubVec(v-&gt;gradient));
+            gs.centerShow(my_x, my_y-boxheight/1, centerSubVec(v-&gt;rValue));
           }
           else
           {
-            gs.centerShow(my_x, my_y-boxheight/5, v-&gt;value);
-            gs.centerShow(my_x, my_y-boxheight/2.5, v-&gt;gradient);
+            gs.centerShow(my_x, my_y-boxheight/5, centerSubVec(v-&gt;value));
+            gs.centerShow(my_x, my_y-boxheight/2.5, centerSubVec(v-&gt;gradient));
           }
           /*
           cout &lt;&lt; descr &lt;&lt; &quot; &quot; &lt;&lt; nameline &lt;&lt; &quot; (&quot; &lt;&lt; v-&gt;value.length() &lt;&lt; &quot;)&quot; &lt;&lt; endl;

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2007-06-05 14:55:53 UTC (rev 7537)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2007-06-05 16:04:16 UTC (rev 7538)
@@ -406,6 +406,8 @@
     VarArray proppath = propagationPath(layers[0],layers[nlayers-1]);
     layers[0]-&gt;matValue &lt;&lt; input;
     proppath.fprop();
+    perr &lt;&lt; &quot;Graph for computing representations&quot; &lt;&lt; endl;
+    // displayVarGraph(proppath,true, 333, &quot;repr&quot;);
     for(int k=0; k&lt;nlayers; k++)
         representations[k] = layers[k]-&gt;matValue.copy();
     return representations;
@@ -417,7 +419,21 @@
     {
         VarArray proppath = propagationPath(layers[k],reconstructed_layers[k-1]);
         proppath.fprop();
-        reconstructed_layers[k-1]-&gt;matValue &gt;&gt; layers[k-1]-&gt;matValue;
+        perr &lt;&lt; &quot;Graph for reconstructing layer &quot; &lt;&lt; k-1 &lt;&lt; &quot; from layer &quot; &lt;&lt; k &lt;&lt; endl;
+        //displayVarGraph(proppath,true, 333, &quot;reconstr&quot;);
+
+        //WARNING MEGA-HACK
+        if (reconstructed_layers[k-1].width() == 2*layers[k-1].width())
+        {
+            Mat temp(layers[k-1].length(), layers[k-1].width());
+            for (int n=0; n &lt; layers[k-1].length(); n++)
+                for (int i=0; i &lt; layers[k-1].width(); i++)
+                    temp(n,i) = reconstructed_layers[k-1]-&gt;matValue(n,i*2);
+            temp &gt;&gt; layers[k-1]-&gt;matValue;
+        }        
+        //END OF MEGA-HACK
+        else
+            reconstructed_layers[k-1]-&gt;matValue &gt;&gt; layers[k-1]-&gt;matValue;
     }
 }
 
@@ -539,7 +555,7 @@
     perr &lt;&lt; &quot;*** each epoch has &quot; &lt;&lt; l &lt;&lt; &quot; examples and &quot; &lt;&lt; l/minibatch_size &lt;&lt; &quot; optimizer stages (updates)&quot; &lt;&lt; endl;
     Func f(layers[which_input_layer], reconstruction_costs[which_input_layer]);
     //displayVarGraph(reconstruction_costs[which_input_layer]);
-    // displayVarGraph(fproppath,true, 333, &quot;ffpp&quot;, false);
+    //displayFunction(f,false,false, 333, &quot;train_func&quot;);
     Var totalcost = sumOf(inputs, f, minibatch_size);
     VarArray params = totalcost-&gt;parents();
     reconstruction_optimizer-&gt;setToOptimize(params, totalcost);

Modified: trunk/python_modules/plearn/plotting/netplot.py
===================================================================
--- trunk/python_modules/plearn/plotting/netplot.py	2007-06-05 14:55:53 UTC (rev 7537)
+++ trunk/python_modules/plearn/plotting/netplot.py	2007-06-05 16:04:16 UTC (rev 7538)
@@ -34,6 +34,8 @@
 
 def customColorBar(min, max, (x,y,width,height) = (0.9,0.1,0.1,0.8), nb_ticks = 50., color_map = defaultColorMap):
     axes((x, y, width,height))
+    if(min == max):
+        max=min + 1e-6
     cbarh = arange(min, max,  (max-min)/50.)
     cbar = vecToVerticalMatrix(cbarh)
     cbarh_str = []
@@ -88,7 +90,7 @@
             imshow(rowToMatrix(toPlusRow(row),width), interpolation=&quot;nearest&quot;, cmap = colorMap)
             setPlotParams(names[i%2] + &quot;_&quot; + str(i) + &quot;_&quot; + str(j), False, True)
 
-def plotLayer1(M, width, plotWidth=.1, start=0, length=-1, space_between_images=.01, apply_to_rows_before = None):
+def plotLayer1(M, width, plotWidth=.1, start=0, length=-1, space_between_images=.01, apply_to_rows = None):
 
     
     #some calculations for plotting
@@ -100,12 +102,15 @@
     mWidth = float(len(M[0]))
     mHeight = float(len(M))
     sbi = space_between_images
-    plotHeight = mHeight/mWidth*plotWidth
+    #plotHeight = mHeight/mWidth*plotWidth
+    plotHeight = mWidth/width/width*plotWidth
     cbw = .01 # color bar width
 
     colorMap = defaultColorMap
 
     mi,ma = findMinMax(M)
+    print 'min', mi
+    print 'max', ma
     
     ma = max(abs(mi),abs(ma))
     mi = -ma
@@ -119,11 +124,18 @@
     
         #normal
         row = M[i]
+        if apply_to_rows != None:
+            row = apply_to_rows(row)
         
+
+        print x,y,plotWidth, plotHeight
+        
         axes((x, y, plotWidth, plotHeight))
         imshow(rowToMatrix(row, width), interpolation=&quot;nearest&quot;, cmap = colorMap, vmin = mi, vmax = ma)
         setPlotParams('row_' + str(i), False, True)
 
+        
+
         x = x + plotWidth + sbi
         if x + plotWidth +cbw &gt; 1:
             x = sbi
@@ -217,7 +229,7 @@
     '''
     colorMap = cm.gray
     nbMatrices = len(matrices)
-    print 'plotting ' + str(nbMatrices) + ' matrices'
+    #print 'plotting ' + str(nbMatrices) + ' matrices'
 
     totalWidth = 0
     maxHeight = 0
@@ -306,6 +318,8 @@
 
     #custom colorBar
     mi,ma = findMinMax(mat)
+    print 'min', mi
+    print 'max', ma
     
     ma = max(abs(mi),abs(ma))
     mi = -ma

Modified: trunk/python_modules/plearn/var/Var.py
===================================================================
--- trunk/python_modules/plearn/var/Var.py	2007-06-05 14:55:53 UTC (rev 7537)
+++ trunk/python_modules/plearn/var/Var.py	2007-06-05 16:04:16 UTC (rev 7538)
@@ -219,11 +219,17 @@
     cost = log_reconstructed.dot(input).neg()
     return hidden, cost, reconstructed_input
 
-def addMultiSoftMaxSimpleProductRLayer(input, iw, igs, ow, ogs):
+def addMultiSoftMaxSimpleProductRLayer(input, iw, igs, ow, ogs, add_bias=False, basename=&quot;&quot;):
     W = Var(ow, iw, &quot;uniform&quot;, -1./iw, 1./iw, varname=basename+'_W')
-    hidden = input.matrixProduct_A_Bt(W).multiSoftMax(ogs)
     Wr = Var(ow, iw, &quot;uniform&quot;, -1./ow, 1./ow, varname=basename+'_Wr')
-    log_reconstructed = hidden.matrixProduct(Wr).multiLogSoftMax(igs)
+    if add_bias:
+        b = Var(1,ow,&quot;fill&quot;,0, varname=basename+'_b')
+        hidden = input.matrixProduct_A_Bt(W).add(b).multiSoftMax(ogs)
+        br = Var(1,iw,&quot;fill&quot;,0, varname=basename+'_br')
+        log_reconstructed = hidden.matrixProduct(Wr).add(br).multiLogSoftMax(igs)
+    else:
+        hidden = input.matrixProduct_A_Bt(W).multiSoftMax(ogs)
+        log_reconstructed = hidden.matrixProduct(Wr).multiLogSoftMax(igs)
     reconstructed_input = log_reconstructed.exp()
     cost = log_reconstructed.dot(input).neg()
     return hidden, cost, reconstructed_input


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000986.html">[Plearn-commits] r7537 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="000988.html">[Plearn-commits] r7539 - trunk/plearn_learners/online
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#987">[ date ]</a>
              <a href="thread.html#987">[ thread ]</a>
              <a href="subject.html#987">[ subject ]</a>
              <a href="author.html#987">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
