<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7551 - in branches/cgi-desjardin: commands	commands/PLearnCommands plearn/base plearn/io plearn/sys	plearn/vmat plearn_learners plearn_learners/hyper	plearn_learners/online plearn_learners/second_iteration scripts
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7551%20-%20in%20branches/cgi-desjardin%3A%20commands%0A%09commands/PLearnCommands%20plearn/base%20plearn/io%20plearn/sys%0A%09plearn/vmat%20plearn_learners%20plearn_learners/hyper%0A%09plearn_learners/online%20plearn_learners/second_iteration%20scripts&In-Reply-To=%3C200706071547.l57Fltwo002358%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000999.html">
   <LINK REL="Next"  HREF="001001.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7551 - in branches/cgi-desjardin: commands	commands/PLearnCommands plearn/base plearn/io plearn/sys	plearn/vmat plearn_learners plearn_learners/hyper	plearn_learners/online plearn_learners/second_iteration scripts</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7551%20-%20in%20branches/cgi-desjardin%3A%20commands%0A%09commands/PLearnCommands%20plearn/base%20plearn/io%20plearn/sys%0A%09plearn/vmat%20plearn_learners%20plearn_learners/hyper%0A%09plearn_learners/online%20plearn_learners/second_iteration%20scripts&In-Reply-To=%3C200706071547.l57Fltwo002358%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7551 - in branches/cgi-desjardin: commands	commands/PLearnCommands plearn/base plearn/io plearn/sys	plearn/vmat plearn_learners plearn_learners/hyper	plearn_learners/online plearn_learners/second_iteration scripts">nouiz at mail.berlios.de
       </A><BR>
    <I>Thu Jun  7 17:47:55 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000999.html">[Plearn-commits] r7550 - in	trunk/plearn_learners/online/test/DeepBeliefNet: .	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-0/Split0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1/Split0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-0/Split0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-1/Split0
</A></li>
        <LI>Next message: <A HREF="001001.html">[Plearn-commits] r7552 -	branches/cgi-desjardin/plearn_learners/second_iteration
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1000">[ date ]</a>
              <a href="thread.html#1000">[ thread ]</a>
              <a href="subject.html#1000">[ subject ]</a>
              <a href="author.html#1000">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2007-06-07 17:47:42 +0200 (Thu, 07 Jun 2007)
New Revision: 7551

Added:
   branches/cgi-desjardin/commands/plearngg.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/
   branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.h
   branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.h
   branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.h
   branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.h
   branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.h
   branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.h
   branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h
   branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h
   branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.h
   branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.h
   branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.h
   branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.h
   branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h
   branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.h
   branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.h
   branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h
   branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.h
   branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.cc
   branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.h
Modified:
   branches/cgi-desjardin/commands/PLearnCommands/ServerCommand.cc
   branches/cgi-desjardin/plearn/base/PrUtils.cc
   branches/cgi-desjardin/plearn/base/TypeTraits.h
   branches/cgi-desjardin/plearn/base/ms_hash_wrapper.cpp
   branches/cgi-desjardin/plearn/io/PPath.cc
   branches/cgi-desjardin/plearn/io/PStream.cc
   branches/cgi-desjardin/plearn/io/Poll.h
   branches/cgi-desjardin/plearn/io/PrPStreamBuf.cc
   branches/cgi-desjardin/plearn/io/fileutils.cc
   branches/cgi-desjardin/plearn/io/openFile.cc
   branches/cgi-desjardin/plearn/io/openSocket.cc
   branches/cgi-desjardin/plearn/io/pl_NSPR_io.h
   branches/cgi-desjardin/plearn/sys/Popen.cc
   branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.cc
   branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.h
   branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.cc
   branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.h
   branches/cgi-desjardin/plearn_learners/hyper/OptimizeOptionOracle.cc
   branches/cgi-desjardin/plearn_learners/online/GaussianDBNClassification.h
   branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.cc
   branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.h
   branches/cgi-desjardin/plearn_learners/online/RBMBinomialLayer.cc
   branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.cc
   branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.h
   branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.cc
   branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.h
   branches/cgi-desjardin/plearn_learners/online/RBMLayer.cc
   branches/cgi-desjardin/plearn_learners/online/RBMLayer.h
   branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.cc
   branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.h
   branches/cgi-desjardin/scripts/appStart.py
   branches/cgi-desjardin/scripts/extract_classes
   branches/cgi-desjardin/scripts/mnd.py
Log:
Commit the version of PLearn I got from Gilles in a branch


Modified: branches/cgi-desjardin/commands/PLearnCommands/ServerCommand.cc
===================================================================
--- branches/cgi-desjardin/commands/PLearnCommands/ServerCommand.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/commands/PLearnCommands/ServerCommand.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -49,9 +49,9 @@
 #include &lt;plearn/io/pl_log.h&gt;
 #include &lt;plearn/io/PrPStreamBuf.h&gt;
 #include &lt;plearn/base/tostring.h&gt;
-#include &lt;mozilla/nspr/prio.h&gt;
-#include &lt;mozilla/nspr/prerror.h&gt;
-#include &lt;mozilla/nspr/prnetdb.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prerror.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prnetdb.h&gt;
 
 #ifndef WIN32
 // POSIX includes for getpid() and gethostname()

Added: branches/cgi-desjardin/commands/plearngg.cc
===================================================================
--- branches/cgi-desjardin/commands/plearngg.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/commands/plearngg.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,54 @@
+// -*- C++ -*-
+
+// plearngg.cc
+// Copyright (C) 2005 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************      
+   * $Id: plearn.cc 3636 2005-06-22 19:59:25Z godbout $
+   ******************************************************* */
+
+//! All includes should now go into plearn_inc.h and plearn_full_inc.h
+#include &quot;plearn_inc_gg.h&quot;
+#include &quot;plearn_full_inc_gg.h&quot;
+#include &quot;plearn_gg_inc.h&quot;
+#include &quot;PLearnCommands/plearn_main.h&quot;
+
+using namespace PLearn;
+
+int main(int argc, char** argv)
+{
+  return plearn_main( argc, argv, 
+                      PLEARN_MAJOR_VERSION, 
+                      PLEARN_MINOR_VERSION, 
+                      PLEARN_FIXLEVEL       );
+}
+

Modified: branches/cgi-desjardin/plearn/base/PrUtils.cc
===================================================================
--- branches/cgi-desjardin/plearn/base/PrUtils.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/base/PrUtils.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -42,7 +42,7 @@
 
 
 #include &quot;PrUtils.h&quot;
-#include &lt;mozilla/nspr/prerror.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prerror.h&gt;
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn/base/TypeTraits.h
===================================================================
--- branches/cgi-desjardin/plearn/base/TypeTraits.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/base/TypeTraits.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -50,7 +50,7 @@
 #include &lt;list&gt;
 #include &lt;map&gt;
 #include &lt;set&gt;
-#include &lt;mozilla/nspr/prlong.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prlong.h&gt;
 
 namespace PLearn {
 using std::string;

Modified: branches/cgi-desjardin/plearn/base/ms_hash_wrapper.cpp
===================================================================
--- branches/cgi-desjardin/plearn/base/ms_hash_wrapper.cpp	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/base/ms_hash_wrapper.cpp	2007-06-07 15:47:42 UTC (rev 7551)
@@ -1,6 +1,6 @@
-
-// dummy file: just as a test.. It will be soon erased!
-#include &lt;string&gt;
-#include &quot;ms_hash_wrapper.h&quot;
-
-
+
+// dummy file: just as a test.. It will be soon erased!
+#include &lt;string&gt;
+#include &quot;ms_hash_wrapper.h&quot;
+
+

Modified: branches/cgi-desjardin/plearn/io/PPath.cc
===================================================================
--- branches/cgi-desjardin/plearn/io/PPath.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/PPath.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -43,7 +43,7 @@
 // #define PL_LOG_MODULE_NAME &quot;PPath&quot;
 
 #include &lt;ctype.h&gt;
-#include &lt;mozilla/nspr/prenv.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prenv.h&gt;
 
 #include &quot;PPath.h&quot;
 #include &quot;PStream.h&quot;

Modified: branches/cgi-desjardin/plearn/io/PStream.cc
===================================================================
--- branches/cgi-desjardin/plearn/io/PStream.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/PStream.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -37,7 +37,7 @@
 #include &quot;NullPStreamBuf.h&quot;
 #include &quot;PrPStreamBuf.h&quot;
 #include &lt;plearn/math/pl_math.h&gt;
-#include &lt;mozilla/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
 #include &lt;ctype.h&gt;
 
 

Modified: branches/cgi-desjardin/plearn/io/Poll.h
===================================================================
--- branches/cgi-desjardin/plearn/io/Poll.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/Poll.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -45,7 +45,7 @@
 #define Poll_INC
 
 #include &lt;vector&gt;
-#include &lt;mozilla/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
 #include &lt;plearn/io/PStream.h&gt;
 
 

Modified: branches/cgi-desjardin/plearn/io/PrPStreamBuf.cc
===================================================================
--- branches/cgi-desjardin/plearn/io/PrPStreamBuf.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/PrPStreamBuf.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -42,7 +42,7 @@
 
 
 #include &quot;PrPStreamBuf.h&quot;
-#include &lt;mozilla/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
 #include &lt;stdio.h&gt;
 
 namespace PLearn {

Modified: branches/cgi-desjardin/plearn/io/fileutils.cc
===================================================================
--- branches/cgi-desjardin/plearn/io/fileutils.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/fileutils.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -65,10 +65,10 @@
 #include &lt;plearn/math/pl_math.h&gt;    //!&lt; For 'real'.
 
 #include &lt;plearn/base/PrUtils.h&gt;
-#include &lt;mozilla/nspr/prio.h&gt;
-#include &lt;mozilla/nspr/prtime.h&gt;
-#include &lt;mozilla/nspr/prerror.h&gt;
-#include &lt;mozilla/nspr/prlong.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prtime.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prerror.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prlong.h&gt;
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn/io/openFile.cc
===================================================================
--- branches/cgi-desjardin/plearn/io/openFile.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/openFile.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -42,7 +42,7 @@
 
 
 #include &quot;openFile.h&quot;
-#include &lt;mozilla/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
 #include &lt;plearn/io/fileutils.h&gt;
 #include &lt;plearn/io/PrPStreamBuf.h&gt;
 

Modified: branches/cgi-desjardin/plearn/io/openSocket.cc
===================================================================
--- branches/cgi-desjardin/plearn/io/openSocket.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/openSocket.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -45,9 +45,9 @@
 #include &lt;plearn/io/PStream.h&gt;
 #include &lt;plearn/io/PrPStreamBuf.h&gt;
 #include &quot;openSocket.h&quot;
-#include &lt;mozilla/nspr/prio.h&gt;
-#include &lt;mozilla/nspr/prerror.h&gt;
-#include &lt;mozilla/nspr/prnetdb.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prerror.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prnetdb.h&gt;
 
 
 namespace PLearn {

Modified: branches/cgi-desjardin/plearn/io/pl_NSPR_io.h
===================================================================
--- branches/cgi-desjardin/plearn/io/pl_NSPR_io.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/io/pl_NSPR_io.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -46,7 +46,7 @@
 #ifndef pl_NSPR_io_INC
 #define pl_NSPR_io_INC
 
-#include &lt;mozilla/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
 
 namespace PLearn {
 using namespace std;

Modified: branches/cgi-desjardin/plearn/sys/Popen.cc
===================================================================
--- branches/cgi-desjardin/plearn/sys/Popen.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/sys/Popen.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -42,9 +42,9 @@
 
 #include &quot;Popen.h&quot;
 
-#include &lt;mozilla/nspr/prio.h&gt;
-#include &lt;mozilla/nspr/prproces.h&gt;
-#include &lt;mozilla/nspr/prenv.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prio.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prproces.h&gt;
+#include &lt;mozilla-1.7.13/nspr/prenv.h&gt;
 #include &lt;plearn/base/stringutils.h&gt;
 #include &lt;plearn/base/PrUtils.h&gt;
 #include &lt;plearn/io/PrPStreamBuf.h&gt;

Modified: branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -50,9 +50,10 @@
 // AddMissingVMatrix //
 //////////////////
 AddMissingVMatrix::AddMissingVMatrix():
+  random_gen(new PRandom()),
   missing_prop(0),
   only_on_first(-1),
-  random_gen(new PRandom()),
+  on_variables(-1),
   seed(-1)
 {}
 
@@ -72,8 +73,11 @@
       &quot;Percentage of missing values.&quot;);
 
   declareOption(ol, &quot;only_on_first&quot;, &amp;AddMissingVMatrix::only_on_first, OptionBase::buildoption,
-      &quot;Only add missing values in the first 'only_on_first' samples (ignored if &lt; 0).&quot;);
+      &quot;Only insert missing values in the first 'only_on_first' samples (ignored if &lt; 0).&quot;);
 
+  declareOption(ol, &quot;on_variables&quot;, &amp;AddMissingVMatrix::on_variables, OptionBase::buildoption,
+      &quot;Insert missing values in the first on_variables variables, if &gt; 0.&quot;);
+
   declareOption(ol, &quot;seed&quot;, &amp;AddMissingVMatrix::seed, OptionBase::buildoption,
       &quot;Random numbers seed.&quot;);
 
@@ -117,6 +121,7 @@
   if (only_on_first &gt;= 0 &amp;&amp; i &gt;= only_on_first)
     return;
   int n = v.length();
+  if (on_variables &gt; 0 &amp;&amp; on_variables &lt;= n) n = on_variables;
   for (int j = 0; j &lt; n; j++)
     if (random_gen-&gt;uniform_sample() &lt; missing_prop)
       v[j] = MISSING_VALUE;

Modified: branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/vmat/AddMissingVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -72,6 +72,7 @@
 
   real missing_prop;
   int  only_on_first;
+  int  on_variables;
   long seed;
 
   // ****************

Modified: branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -49,42 +49,30 @@
 PLEARN_IMPLEMENT_OBJECT(
     VariableDeletionVMatrix,
     &quot;VMat class to select columns from a source VMat based on a given threshold percentage of non-missing variables.&quot;,
-    &quot;This class will scan the VMat provided as the complete dataset and compute the percentage of non-missing values\n&quot;
+    &quot;This class will scan the VMat provided as the train set and compute the percentage of non-missing values\n&quot;
     &quot;of each variables. It then only selects the columns with  a percentage of non-missing higher than the given\n&quot;
-    &quot;threshod parameter.\n&quot;
+    &quot;threshod parameter from the complete dataset.\n&quot;
     &quot;Optionnaly, variable with non-missing constant values will also be removed.\n&quot;
     &quot;Note that the ending targets and weight columns are always kept.\n&quot;
     &quot;The targetsize and weightsize of the underlying matrix are kept.\n&quot;
     );
 
 VariableDeletionVMatrix::VariableDeletionVMatrix()
-    : obtained_inputsize_from_source(false),
-      obtained_targetsize_from_source(false),
-      obtained_weightsize_from_source(false),
-      deletion_threshold(0),
+    : deletion_threshold(0),
       remove_columns_with_constant_value(0),
-      number_of_train_samples(0.0)
+      number_of_train_samples(0.0),
+      start_row(0)
 {
 }
 
-VariableDeletionVMatrix::VariableDeletionVMatrix(VMat the_complete_dataset, real the_threshold, bool the_remove_columns_with_constant_value, real the_number_of_train_samples)
-    : obtained_inputsize_from_source(false),
-      obtained_targetsize_from_source(false),
-      obtained_weightsize_from_source(false)
-{
-    complete_dataset = the_complete_dataset;
-    deletion_threshold = the_threshold;
-    remove_columns_with_constant_value = the_remove_columns_with_constant_value;
-    number_of_train_samples = the_number_of_train_samples;
-    build();
-}
-
 void VariableDeletionVMatrix::declareOptions(OptionList &amp;ol)
 {
-
     declareOption(ol, &quot;complete_dataset&quot;, &amp;VariableDeletionVMatrix::complete_dataset, OptionBase::buildoption,
                   &quot;The data set with all variables to select the columns from.&quot;);
 
+    declareOption(ol, &quot;train_set&quot;, &amp;VariableDeletionVMatrix::train_set, OptionBase::buildoption,
+                  &quot;The train set in which to compute the percentage of missing values.&quot;);
+
     declareOption(ol, &quot;deletion_threshold&quot;, &amp;VariableDeletionVMatrix::deletion_threshold, OptionBase::buildoption,
                   &quot;The percentage of non-missing values for a variable above which, the variable will be selected.&quot;);
 
@@ -92,25 +80,21 @@
                   &quot;If set to 1, the columns with constant non-missing values will be removed.&quot;);
 
     declareOption(ol, &quot;number_of_train_samples&quot;, &amp;VariableDeletionVMatrix::number_of_train_samples, OptionBase::buildoption,
-                  &quot;If equal to zero, all the underlying dataset samples are used to calculated the percentages and constant values.\n&quot;
+                  &quot;If equal to zero, all the train samples are used to calculated the percentages and constant values.\n&quot;
                   &quot;If it is a fraction between 0 and 1, this proportion of the samples will be used.\n&quot;
                   &quot;If greater or equal to 1, the integer portion will be interpreted as the number of samples to use.&quot;);
 
-    declareOption(ol, &quot;obtained_inputsize_from_source&quot;, &amp;VariableDeletionVMatrix::obtained_inputsize_from_source, OptionBase::learntoption,
-                  &quot;Set to 1 when the inputsize was obtained from the source matrix.&quot;);
+    declareOption(ol, &quot;start_row&quot;, &amp;VariableDeletionVMatrix::start_row, OptionBase::buildoption,
+                  &quot;The row at which, to start to calculate the percentages and constant values.&quot;);
 
-    declareOption(ol, &quot;obtained_targetsize_from_source&quot;, &amp;VariableDeletionVMatrix::obtained_targetsize_from_source, OptionBase::learntoption,
-                  &quot;Set to 1 when the targetsize was obtained from the source matrix.&quot;);
+    declareOption(ol, &quot;source&quot;, &amp;VariableDeletionVMatrix::source, OptionBase::learntoption,
+                  &quot;The resulting data set.&quot;);
 
-    declareOption(ol, &quot;obtained_weightsize_from_source&quot;, &amp;VariableDeletionVMatrix::obtained_weightsize_from_source, OptionBase::learntoption,
-                  &quot;Set to 1 when the weightsize was obtained from the source matrix.&quot;);
-
     inherited::declareOptions(ol);
 }
 
 void VariableDeletionVMatrix::build()
 {
-    buildIndices();
     inherited::build();
     build_();
 }
@@ -119,11 +103,11 @@
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
     deepCopyField(complete_dataset, copies);
+    deepCopyField(train_set, copies);
     deepCopyField(deletion_threshold, copies);
     deepCopyField(remove_columns_with_constant_value, copies);
-    deepCopyField(obtained_inputsize_from_source, copies);
-    deepCopyField(obtained_targetsize_from_source, copies);
-    deepCopyField(obtained_weightsize_from_source, copies);
+    deepCopyField(number_of_train_samples, copies);
+    deepCopyField(start_row, copies);
 }
 
 void VariableDeletionVMatrix::getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight)
@@ -163,7 +147,7 @@
 
 void VariableDeletionVMatrix::getRow(int i, Vec v) const
 {
-    source-&gt; getRow(i, v);
+    source-&gt;getRow(i, v);
 }
 
 void VariableDeletionVMatrix::putRow(int i, Vec v)
@@ -173,58 +157,37 @@
 
 void VariableDeletionVMatrix::getColumn(int i, Vec v) const
 {
-    source-&gt; getColumn(i, v);
+    source-&gt;getColumn(i, v);
 }
 
 void VariableDeletionVMatrix::build_()
 {
-    if (source) {
-        string error_msg =
-            &quot;In VariableDeletionVMatrix::build_ - For safety reasons, it is forbidden to &quot;
-            &quot;re-use sizes obtained from a previous source VMatrix with a new source &quot;
-            &quot;VMatrix having different sizes&quot;;
-        length_ = source-&gt;length();
-        width_ = source-&gt;width();
-        if(inputsize_&lt;0) {
-            inputsize_ = source-&gt;inputsize();
-            obtained_inputsize_from_source = true;
-        } else if (obtained_inputsize_from_source &amp;&amp; inputsize_ != source-&gt;inputsize())
-            PLERROR(error_msg.c_str());
-        if(targetsize_&lt;0) {
-            targetsize_ = source-&gt;targetsize();
-            obtained_targetsize_from_source = true;
-        } else if (obtained_targetsize_from_source &amp;&amp; targetsize_ != source-&gt;targetsize())
-            PLERROR(error_msg.c_str());
-        if(weightsize_&lt;0) {
-            weightsize_ = source-&gt;weightsize();
-            obtained_weightsize_from_source = true;
-        } else if (obtained_weightsize_from_source &amp;&amp; weightsize_ != source-&gt;weightsize())
-            PLERROR(error_msg.c_str());
-        fieldinfos = source-&gt;fieldinfos;
-    } else {
-        // Restore the original undefined sizes if the current one had been obtained
-        // from the source VMatrix.
-        if (obtained_inputsize_from_source) {
-            inputsize_ = -1;
-            obtained_inputsize_from_source = false;
-        }
-        if (obtained_targetsize_from_source) {
-            targetsize_ = -1;
-            obtained_targetsize_from_source = false;
-        }
-        if (obtained_weightsize_from_source) {
-            weightsize_ = -1;
-            obtained_weightsize_from_source = false;
-        }
-    }
+    if (!train_set || !complete_dataset) PLERROR(&quot;In VariableDeletionVMatrix::train set and complete_dataset vmat must be supplied&quot;);
+    buildIndices();
 }
 
 void VariableDeletionVMatrix::buildIndices()
 {
+    int train_set_length = train_set-&gt;length();
+    if(train_set_length &lt; 1) PLERROR(&quot;In VariableDeletionVMatrix::length of the number of train samples to use must be at least 1, got: %i&quot;, train_set_length);
+    int train_set_width = train_set-&gt;width();
+    int train_set_inputsize = train_set-&gt;inputsize();
+    if(train_set_inputsize &lt; 1) PLERROR(&quot;In VariableDeletionVMatrix::inputsize of the train vmat must be supplied, got : %i&quot;, train_set_inputsize);
+    int train_set_targetsize = train_set-&gt;targetsize();
+    int train_set_weightsize = train_set-&gt;weightsize();
     int complete_dataset_length = complete_dataset-&gt;length();
     int complete_dataset_width = complete_dataset-&gt;width();
+    int complete_dataset_inputsize = complete_dataset-&gt;inputsize();
     int complete_dataset_targetsize = complete_dataset-&gt;targetsize();
     int complete_dataset_weightsize = complete_dataset-&gt;weightsize();
+    if (train_set_width != complete_dataset_width)
+        PLERROR(&quot;In VariableDeletionVMatrix::train set and complete_dataset width must agree, got : %i, %i&quot;, train_set_width, complete_dataset_width);
+    if (train_set_inputsize != complete_dataset_inputsize)
+        PLERROR(&quot;In VariableDeletionVMatrix::train set and complete_dataset inputsize must agree, got : %i, %i&quot;, train_set_inputsize, complete_dataset_inputsize);
+    if (train_set_targetsize != complete_dataset_targetsize)
+        PLERROR(&quot;In VariableDeletionVMatrix::train set and complete_dataset targetsize must agree, got : %i, %i&quot;, train_set_targetsize, complete_dataset_targetsize);
+    if (train_set_weightsize != complete_dataset_weightsize)
+        PLERROR(&quot;In VariableDeletionVMatrix::train set and complete_dataset weightsize must agree, got : %i, %i&quot;, train_set_weightsize, complete_dataset_weightsize);
     int row;
     int col;
     TVec&lt;int&gt;  selected_columns_indices;
@@ -235,25 +198,23 @@
     variable_present_count.resize(complete_dataset_width);
     variable_last_value.resize(complete_dataset_width);
     variable_constant.resize(complete_dataset_width);
-    for (col = 0; col &lt; complete_dataset_width; col++)
-    {
-        variable_present_count[col] = 0;
-        variable_constant[col] = true;
-    }
+    variable_present_count.clear();
+    variable_constant.fill(true);
     real variable_value;
-    int scanned_length = complete_dataset_length;
+    int scanned_length = train_set_length;
     if (number_of_train_samples &gt; 0.0)
     {
         if (number_of_train_samples &gt;= 1.0) scanned_length = (int) number_of_train_samples;
-        else scanned_length = (int) ((double) complete_dataset_length * number_of_train_samples);
+        else scanned_length = (int) ((double) train_set_length * number_of_train_samples);
         if (scanned_length &lt; 1) scanned_length = 1;
-        if (scanned_length &gt; complete_dataset_length) scanned_length = complete_dataset_length;
     }
-    for (row = 0; row &lt; scanned_length; row++)
+    if (start_row + scanned_length &gt; train_set_length)        
+        PLERROR(&quot;In VariableDeletionVMatrix: start_row + number_of_train_samples must be less or equal to the train set length&quot;);
+    for (row = start_row; row &lt; start_row + scanned_length; row++)
     {
-        for (col = 0; col &lt; complete_dataset_width; col++)
+        for (col = 0; col &lt; train_set_width; col++)
         {
-            variable_value = complete_dataset-&gt;get(row, col);
+            variable_value = train_set-&gt;get(row, col);
             if (!is_missing(variable_value))
             {
                 if (variable_present_count[col] &gt; 0)
@@ -265,18 +226,21 @@
             }
         }
     }
-    real adjusted_threshold = deletion_threshold * (real) complete_dataset_length / 100.0;
-    if (complete_dataset_targetsize &lt; 0) complete_dataset_targetsize = 0;
-    if (complete_dataset_weightsize &lt; 0) complete_dataset_weightsize = 0;
-    int target_and_weight = complete_dataset_targetsize + complete_dataset_weightsize;
+    real adjusted_threshold = deletion_threshold * (real) scanned_length;
+    if (train_set_targetsize &lt; 0) train_set_targetsize = 0;
+    if (train_set_weightsize &lt; 0) train_set_weightsize = 0;
+    int target_and_weight = train_set_targetsize + train_set_weightsize;
     int new_width = target_and_weight;
-    for (col = 0; col &lt; complete_dataset_width - target_and_weight; col++)
+    for (col = 0; col &lt; train_set_width - target_and_weight; col++)
     {
         if ((real) variable_present_count[col] &gt; adjusted_threshold &amp;&amp; (!remove_columns_with_constant_value || !variable_constant[col])) new_width += 1;
     }
     selected_columns_indices.resize(new_width);
+    TVec&lt;string&gt; complete_dataset_names(complete_dataset_width);
+    TVec&lt;string&gt; new_names(new_width);
+    complete_dataset_names = complete_dataset-&gt;fieldNames();
     int selected_col = 0;
-    for (col = 0; col &lt; complete_dataset_width - target_and_weight; col++)
+    for (col = 0; col &lt; train_set_width - target_and_weight; col++)
     {
         if ((real) variable_present_count[col] &gt; adjusted_threshold &amp;&amp; (!remove_columns_with_constant_value || !variable_constant[col]))
         {
@@ -286,14 +250,23 @@
     }
     if (target_and_weight &gt; 0)
     {
-        for (col = complete_dataset_width - target_and_weight; col &lt; complete_dataset_width; col++)
+        for (col = train_set_width - target_and_weight; col &lt; train_set_width; col++)
         {
             selected_columns_indices[selected_col] = col;
             selected_col += 1;
         }
     }
+    for (col = 0; col &lt; new_width; col++)
+    {
+        new_names[col] = complete_dataset_names[selected_columns_indices[col]];
+    }
     source = new SelectColumnsVMatrix(complete_dataset, selected_columns_indices);
-    source-&gt;defineSizes(new_width - target_and_weight, complete_dataset_targetsize, complete_dataset_weightsize);
+    length_ = complete_dataset_length;
+    width_ = new_width;
+    inputsize_ = new_width - target_and_weight;
+    targetsize_ = complete_dataset_targetsize;
+    weightsize_ = complete_dataset_weightsize;
+    declareFieldNames(new_names);
 }
 
 } // end of namespace PLearn

Modified: branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn/vmat/VariableDeletionVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -45,7 +45,7 @@
 #ifndef VariableDeletionVMatrix_INC
 #define VariableDeletionVMatrix_INC
 
-#include &quot;SourceVMatrix.h&quot;
+#include &quot;VMatrix.h&quot;
 #include &quot;SelectColumnsVMatrix.h&quot;
 
 namespace PLearn {
@@ -53,27 +53,23 @@
 
 //!  provides mean imputation for missing variables
 
-class VariableDeletionVMatrix: public SourceVMatrix
+class VariableDeletionVMatrix: public VMatrix
 {
-    typedef SourceVMatrix inherited;
+    typedef VMatrix inherited;
 
-private:
-
-    bool obtained_inputsize_from_source;
-    bool obtained_targetsize_from_source;
-    bool obtained_weightsize_from_source;
-
 public:
 
     VMat       complete_dataset;
+    VMat       train_set;
+    VMat       source;
     real       deletion_threshold;
     bool       remove_columns_with_constant_value;
     real       number_of_train_samples;
+    int        start_row;
 
 public:
 
     VariableDeletionVMatrix();
-    VariableDeletionVMatrix(VMat the_complete_dataset, real the_threshold, bool the_remove_columns_with_constant_value, real the_number_of_train_samples);
 
     static void declareOptions(OptionList &amp;ol);
 

Modified: branches/cgi-desjardin/plearn_learners/hyper/OptimizeOptionOracle.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/hyper/OptimizeOptionOracle.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/hyper/OptimizeOptionOracle.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -269,15 +269,20 @@
 void OptimizeOptionOracle::makeDeepCopyFromShallowCopy(map&lt;const void*, void*&gt;&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
-
-    // ### Call deepCopyField on all &quot;pointer-like&quot; fields 
-    // ### that you wish to be deepCopied rather than 
-    // ### shallow-copied.
-    // ### ex:
-    // deepCopyField(trainvec, copies);
-
-    // ### Remove this line when you have fully implemented this method.
-    PLERROR(&quot;OptimizeOptionOracle::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!&quot;);
+    deepCopyField(option, copies);
+    deepCopyField(max_steps, copies);
+    deepCopyField(start_value, copies);
+    deepCopyField(min_value, copies);
+    deepCopyField(max_value, copies);
+    deepCopyField(relative_precision, copies);
+    deepCopyField(factor, copies);
+    deepCopyField(start_direction, copies);
+    deepCopyField(best, copies);
+    deepCopyField(best_objective, copies);
+    deepCopyField(current_direction, copies);
+    deepCopyField(lower_bound, copies);
+    deepCopyField(n_steps, copies);
+    deepCopyField(upper_bound, copies);
 }
 
 } // end of namespace PLearn

Modified: branches/cgi-desjardin/plearn_learners/online/GaussianDBNClassification.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/GaussianDBNClassification.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/GaussianDBNClassification.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -133,7 +133,6 @@
     // ### initializes all fields to reasonable default values.
     GaussianDBNClassification();
 
-
     //#####  PDistribution Member Functions  ##################################
 
     //! Return probability density p(y | x)

Modified: branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -64,7 +64,8 @@
 GaussianDBNRegression::GaussianDBNRegression() :
     learning_rate(0.),
     weight_decay(0.),
-    use_sample_rather_than_expectation_in_positive_phase_statistics(false)
+    use_sample_rather_than_expectation_in_positive_phase_statistics(false),
+    skip_backprop_on_model(0)
 {
     random_gen = new PRandom();
 }
@@ -142,6 +143,10 @@
                   &quot;In positive phase statistics use output-&gt;sample * input\n&quot;
                   &quot;rather than output-&gt;expectation * input.\n&quot;);
 
+    declareOption(ol, &quot;skip_backprop_on_model&quot;, &amp;GaussianDBNRegression::skip_backprop_on_model,
+                  OptionBase::buildoption,
+                  &quot;If &gt; 0, will only do backprop on target layer.&quot;);
+
     declareOption(ol, &quot;n_layers&quot;, &amp;GaussianDBNRegression::n_layers,
                   OptionBase::learntoption,
                   &quot;Number of unsupervised layers, including input layer&quot;);
@@ -356,7 +361,7 @@
     target_layer-&gt;computeExpectation();
 
     mu &lt;&lt; target_layer-&gt;expectation;
-
+    
 }
 
 /////////////
@@ -566,7 +571,6 @@
         {
             MODULE_LOG &lt;&lt; &quot;Fine-tuning all parameters, using method &quot;
                 &lt;&lt; fine_tuning_method &lt;&lt; endl;
-
             if( fine_tuning_method == &quot;&quot; ) // do nothing
                 sample += n_samples_to_see;
             else if( fine_tuning_method == &quot;EGD&quot; )
@@ -612,9 +616,16 @@
         }
         train_stats-&gt;finalize(); // finalize statistics for this epoch
     }
+    checkLearner();
     MODULE_LOG &lt;&lt; endl;
 }
 
+void GaussianDBNRegression::checkLearner()
+{
+// We do nothing here.
+// subclass may way to check various things.
+}
+
 void GaussianDBNRegression::greedyStep( const Vec&amp; predictor, int index )
 {
     // deterministic propagation until we reach index
@@ -696,11 +707,26 @@
 {
     // split input in predictor_part and predicted_part
     splitCond(input);
+    
+//    cout &lt;&lt; &quot;fineTuneByGradientDescent: input: &quot; &lt;&lt; input &lt;&lt; endl;
 
     // compute predicted_part expectation, conditioned on predictor_part
     // (forward pass)
     expectation( output_gradient );
 
+    /*    
+    cout &lt;&lt; &quot;we have gone up!&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;layers[0]&quot; &lt;&lt; endl;
+    layers[0]-&gt;printActivation();
+    cout &lt;&lt; &quot;input_params&quot; &lt;&lt; endl;
+    input_params-&gt;printParams();
+    cout &lt;&lt; &quot;layers[1]&quot; &lt;&lt; endl;
+    layers[1]-&gt;printActivation();
+    cout &lt;&lt; &quot;target_params&quot; &lt;&lt; endl;
+    target_params-&gt;printParams();
+    cout &lt;&lt; &quot;target_layer&quot; &lt;&lt; endl;
+    target_layer-&gt;printActivation();
+*/
     int target_size = predicted_part.size() ; 
 
     for(int i=0 ; i &lt; target_size ; ++i) { 
@@ -711,7 +737,7 @@
                                target_layer-&gt;expectation,
                                expectation_gradients[n_layers-1],
                                output_gradient );
-
+    if (skip_backprop_on_model &gt; 0) return;
     for( int i=n_layers-2 ; i&gt;1 ; i-- )
     {
         layers[i]-&gt;bpropUpdate( layers[i]-&gt;activations,
@@ -732,6 +758,20 @@
                                   layers[1]-&gt;activations,
                                   expectation_gradients[0],
                                   activation_gradients[1] );
+
+/*    
+    cout &lt;&lt; &quot;we have updated params!&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;target_layer&quot; &lt;&lt; endl;
+    target_layer-&gt;printActivation();
+    cout &lt;&lt; &quot;target_params&quot; &lt;&lt; endl;
+    target_params-&gt;printParams();
+    cout &lt;&lt; &quot;layers[1]&quot; &lt;&lt; endl;
+    layers[1]-&gt;printActivation();
+    cout &lt;&lt; &quot;input_params&quot; &lt;&lt; endl;
+    input_params-&gt;printParams();
+    cout &lt;&lt; &quot;layers[0]&quot; &lt;&lt; endl;
+    layers[0]-&gt;printActivation();
+*/
     
 }
 

Modified: branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/GaussianDBNRegression.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -116,6 +116,8 @@
     string fine_tuning_method;
 
     bool use_sample_rather_than_expectation_in_positive_phase_statistics;
+    
+    int skip_backprop_on_model;
 
 public:
     //#####  Public Member Functions  #########################################
@@ -124,8 +126,9 @@
     // ### Make sure the implementation in the .cc
     // ### initializes all fields to reasonable default values.
     GaussianDBNRegression();
+    
+    virtual void checkLearner();
 
-
     //#####  PDistribution Member Functions  ##################################
 
     //! Return probability density p(y | x)

Modified: branches/cgi-desjardin/plearn_learners/online/RBMBinomialLayer.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMBinomialLayer.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMBinomialLayer.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -113,7 +113,7 @@
     for( int i=0 ; i&lt;size ; i++ )
     {
         real output_i = output[i];
-        input_gradient[i] = output_i * (1-output_i) * output_gradient[i];
+        input_gradient[i] = -output_i * (1-output_i) * output_gradient[i];
     }
 }
 

Modified: branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -266,21 +266,25 @@
 //! this version allows to obtain the input gradient as well
 void RBMLLParameters::bpropUpdate(const Vec&amp; input, const Vec&amp; output,
                                   Vec&amp; input_gradient,
-                                  const Vec&amp; output_gradient)
+                                  const Vec&amp; output_gradient,
+                                  real fine_tuning_learning_rate)
 {
+    real bprop_learning_rate;
+    if (fine_tuning_learning_rate &lt; 0.00000001) bprop_learning_rate = learning_rate;
+    else bprop_learning_rate = fine_tuning_learning_rate;
     assert( input.size() == down_layer_size );
     assert( output.size() == up_layer_size );
     assert( output_gradient.size() == up_layer_size );
     input_gradient.resize( down_layer_size );
+    
+    // input_gradient = weights' * output_gradient
+    transposeProduct( input_gradient, weights, output_gradient );
 
     // weights -= learning_rate * output_gradient * input'
-    externalProductScaleAcc( weights, output_gradient, input, -learning_rate );
+    externalProductScaleAcc( weights, output_gradient, input, -bprop_learning_rate );
 
     // (up) bias -= learning_rate * output_gradient
-    multiplyAcc( up_units_bias, output_gradient, -learning_rate );
-
-    // input_gradient = weights' * output_gradient
-    transposeProduct( input_gradient, weights, output_gradient );
+    multiplyAcc( up_units_bias, output_gradient, -bprop_learning_rate );
 }
 
 //! reset the parameters to the state they would be BEFORE starting training.

Modified: branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMLLParameters.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -138,7 +138,8 @@
     //! N.B. THE DEFAULT IMPLEMENTATION IN SUPER-CLASS JUST RAISES A PLERROR.
     virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
                              Vec&amp; input_gradient,
-                             const Vec&amp; output_gradient);
+                             const Vec&amp; output_gradient,
+                             real fine_tuning_learning_rate = 0.0);
 
     //! reset the parameters to the state they would be BEFORE starting
     //! training.  Note that this method is necessarily called from

Modified: branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -163,7 +163,14 @@
     build_();
 }
 
+void RBMLQParameters::printParams()
+{
+    cout &lt;&lt; &quot;weights: &quot; &lt;&lt; weights &lt;&lt; endl;
+    cout &lt;&lt; &quot;down_units_bias: &quot; &lt;&lt; down_units_bias &lt;&lt; endl;
+    cout &lt;&lt; &quot;up_units_params: &quot; &lt;&lt; up_units_params &lt;&lt; endl;
+}
 
+
 void RBMLQParameters::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
@@ -304,8 +311,12 @@
 //! this version allows to obtain the input gradient as well
 void RBMLQParameters::bpropUpdate(const Vec&amp; input, const Vec&amp; output,
                                   Vec&amp; input_gradient,
-                                  const Vec&amp; output_gradient)
+                                  const Vec&amp; output_gradient,
+                                  real fine_tuning_learning_rate)
 {
+    real bprop_learning_rate;
+    if (fine_tuning_learning_rate &lt; 0.00000001) bprop_learning_rate = learning_rate;
+    else bprop_learning_rate = fine_tuning_learning_rate;
     //TODO: clean up the code a bit
     assert( input.size() == down_layer_size );
     assert( output.size() == up_layer_size );
@@ -317,37 +328,31 @@
 
     Vec scaled_out_grad(up_layer_size) ;  
     
-    Vec prod_w_input( up_layer_size ) ; 
+    Vec prod_w_input( up_layer_size ) ;
+    prod_w_input.clear(); 
+
+    //first, compute input_gradient = weights' * output_gradient.
+    for(int i=0 ; i&lt;up_layer_size ; ++i) 
+    { 
+        scaled_out_grad[i] = -0.5 * output_gradient[i] / (up_units_params[1][i] * up_units_params[1][i]) ;
+    }
+    transposeProduct( input_gradient, weights, scaled_out_grad );
     
+    
+    //now, update parameters
     for(int i=0 ; i&lt;up_layer_size ; ++i) 
     {
-        real a_i_square = up_units_params[1][i] * up_units_params[1][i] ; 
-        
-        scaled_out_grad[i] = -0.5 * output_gradient[i] / a_i_square ; 
-        
-        up_units_params[0][i] -= learning_rate * ( -0.5 / a_i_square ) *
-                                 output_gradient[i] ; 
-
-        
+        real partial_gradient = -0.5 * output_gradient[i] / (up_units_params[1][i] * up_units_params[1][i]);
         for(int j=0 ; j &lt; down_layer_size ; ++j) {             
             prod_w_input[i] += weights[i][j] * input[j] ; 
-            weights[i][j] -= learning_rate * ( - 0.5 * input[j] / a_i_square ) * 
-                             output_gradient[i];
+            weights[i][j] -= bprop_learning_rate * input[j] * partial_gradient;
         }
-    }
 
-    for(int i=0 ; i&lt;up_layer_size ; ++i) { 
-        up_units_params[1][i] -= learning_rate * ( up_units_params[0][i] +
-                prod_w_input[i] ) * output_gradient[i] ; 
+        up_units_params[1][i] -= bprop_learning_rate * ( up_units_params[0][i] +
+                prod_w_input[i] ) * output_gradient[i] / pow(up_units_params[1][i], 3.0);
+
+        up_units_params[0][i] -= bprop_learning_rate * partial_gradient;
     }
-
-    // (up) bias -= learning_rate * output_gradient
-//    multiplyAcc( up_units_params[0], output_gradient, -learning_rate );
-    
-
-
-    // input_gradient = weights' * output_gradient
-    transposeProduct( input_gradient, weights, scaled_out_grad );
 }
 
 //! reset the parameters to the state they would be BEFORE starting training.

Modified: branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMLQParameters.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -140,12 +140,16 @@
     //! N.B. THE DEFAULT IMPLEMENTATION IN SUPER-CLASS JUST RAISES A PLERROR.
     virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
                              Vec&amp; input_gradient,
-                             const Vec&amp; output_gradient);
+                             const Vec&amp; output_gradient,
+                             real fine_tuning_learning_rate = 0.0);
 
     //! reset the parameters to the state they would be BEFORE starting
     //! training.  Note that this method is necessarily called from
     //! build().
     virtual void forget();
+    
+    
+    void printParams();
 
     //! optionally perform some processing after training, or after a
     //! series of fprop/bpropUpdate calls to prepare the model for truly

Modified: branches/cgi-desjardin/plearn_learners/online/RBMLayer.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMLayer.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMLayer.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -104,7 +104,13 @@
     build_();
 }
 
+void RBMLayer::printActivation()
+{
+    cout &lt;&lt; &quot;activations: &quot; &lt;&lt; activations &lt;&lt; endl;
+    cout &lt;&lt; &quot;expectation: &quot; &lt;&lt; expectation &lt;&lt; endl;
+}
 
+
 void RBMLayer::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);

Modified: branches/cgi-desjardin/plearn_learners/online/RBMLayer.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMLayer.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMLayer.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -127,6 +127,9 @@
     {
         return units_types;
     }
+    
+    
+    virtual void printActivation();
 
 
     //#####  PLearn::Object Protocol  #########################################

Modified: branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -163,7 +163,14 @@
     build_();
 }
 
+void RBMQLParameters::printParams()
+{
+    cout &lt;&lt; &quot;weights: &quot; &lt;&lt; weights &lt;&lt; endl;
+    cout &lt;&lt; &quot;up_units_bias: &quot; &lt;&lt; up_units_bias &lt;&lt; endl;
+    cout &lt;&lt; &quot;down_units_params: &quot; &lt;&lt; down_units_params &lt;&lt; endl;
+}
 
+
 void RBMQLParameters::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
 {
     inherited::makeDeepCopyFromShallowCopy(copies);
@@ -310,21 +317,25 @@
 //! this version allows to obtain the input gradient as well
 void RBMQLParameters::bpropUpdate(const Vec&amp; input, const Vec&amp; output,
                                   Vec&amp; input_gradient,
-                                  const Vec&amp; output_gradient)
+                                  const Vec&amp; output_gradient,
+                                  real fine_tuning_learning_rate)
 {
+    real bprop_learning_rate;
+    if (fine_tuning_learning_rate &lt; 0.00000001) bprop_learning_rate = learning_rate;
+    else bprop_learning_rate = fine_tuning_learning_rate;
     assert( input.size() == down_layer_size );
     assert( output.size() == up_layer_size );
     assert( output_gradient.size() == up_layer_size );
     input_gradient.resize( down_layer_size );
+    
+    // input_gradient = weights' * output_gradient
+    transposeProduct( input_gradient, weights, output_gradient );
 
     // weights -= learning_rate * output_gradient * input'
-    externalProductAcc( weights, (-learning_rate)*output_gradient, input );
+    externalProductAcc( weights, (-bprop_learning_rate)*output_gradient, input );
 
     // (up) bias -= learning_rate * output_gradient
-    multiplyAcc( up_units_bias, output_gradient, -learning_rate );
-
-    // input_gradient = weights' * output_gradient
-    transposeProduct( input_gradient, weights, output_gradient );
+    multiplyAcc( up_units_bias, output_gradient, -bprop_learning_rate );
 }
 
 //! reset the parameters to the state they would be BEFORE starting training.

Modified: branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/online/RBMQLParameters.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -140,7 +140,8 @@
     //! N.B. THE DEFAULT IMPLEMENTATION IN SUPER-CLASS JUST RAISES A PLERROR.
     virtual void bpropUpdate(const Vec&amp; input, const Vec&amp; output,
                              Vec&amp; input_gradient,
-                             const Vec&amp; output_gradient);
+                             const Vec&amp; output_gradient,
+                             real fine_tuning_learning_rate = 0.0);
 
     //! reset the parameters to the state they would be BEFORE starting
     //! training.  Note that this method is necessarily called from
@@ -163,6 +164,9 @@
 
     //! Transforms a shallow copy into a deep copy
     virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+    
+    
+    virtual void printParams();
 
 protected:
 

Added: branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,221 @@
+// -*- C++ -*-
+
+// AnalyzeDond2DiscreteVariables.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file AnalyzeDond2DiscreteVariables.cc */
+
+#define PL_LOG_MODULE_NAME &quot;AnalyzeDond2DiscreteVariables&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;AnalyzeDond2DiscreteVariables.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    AnalyzeDond2DiscreteVariables,
+    &quot;Computes correlation coefficient between various discrete values and the target.&quot;,
+    &quot;name of the discrete variable, of the target and the values to check are options.\n&quot;
+);
+
+/////////////////////////
+// AnalyzeDond2DiscreteVariables //
+/////////////////////////
+AnalyzeDond2DiscreteVariables::AnalyzeDond2DiscreteVariables()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void AnalyzeDond2DiscreteVariables::declareOptions(OptionList&amp; ol)
+{
+
+    declareOption(ol, &quot;variable_name&quot;, &amp;AnalyzeDond2DiscreteVariables::variable_name,
+                  OptionBase::buildoption,
+                  &quot;The field name of the variable to be analyzed.&quot;);
+
+    declareOption(ol, &quot;target_name&quot;, &amp;AnalyzeDond2DiscreteVariables::target_name,
+                  OptionBase::buildoption,
+                  &quot;The field name of the target.&quot;);
+
+    declareOption(ol, &quot;values_to_analyze&quot;, &amp;AnalyzeDond2DiscreteVariables::values_to_analyze,
+                  OptionBase::buildoption,
+                  &quot;The vector of values to check the correlation with the target.\n&quot;
+                  &quot;The algorithm groups the values from, to of each pair specified.\n&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void AnalyzeDond2DiscreteVariables::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(values_to_analyze, copies);
+    deepCopyField(variable_name, copies);
+    deepCopyField(target_name, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void AnalyzeDond2DiscreteVariables::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void AnalyzeDond2DiscreteVariables::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        analyzeDiscreteVariable();
+        PLERROR(&quot;AnalyzeDond2DiscreteVariables: we are done here&quot;);
+    }
+}
+
+void AnalyzeDond2DiscreteVariables::analyzeDiscreteVariable()
+{    
+    // initialize primary dataset
+    main_row = 0;
+    main_col = 0;
+    main_length = train_set-&gt;length();
+    main_width = train_set-&gt;width();
+    main_input.resize(main_width);
+    main_names.resize(main_width);
+    main_names &lt;&lt; train_set-&gt;fieldNames();
+    
+    // check for valid options
+    number_of_values = values_to_analyze.size();
+    variable_col = -1;
+    target_col = -1;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (variable_name == main_names[main_col]) variable_col = main_col;
+        if (target_name == main_names[main_col]) target_col = main_col;
+    }
+    if (variable_col &lt; 0) PLERROR(&quot;In AnalyzeDond2DiscreteVariables: variable name not found: %s&quot;, variable_name.c_str());
+    if (target_col &lt; 0) PLERROR(&quot;In AnalyzeDond2DiscreteVariables: target name not found: %s&quot;, target_name.c_str());
+    if (number_of_values &lt;= 0) PLERROR(&quot;In AnalyzeDond2DiscreteVariables: invalid values_to_analyze&quot;);
+    
+    // initialize working variables
+    value_target_sum.resize(number_of_values);
+    value_present_count.resize(number_of_values);
+    value_target_sum.clear();
+    value_present_count.clear();
+    target_sum = 0.0;
+    target_squared_sum = 0.0;
+    variable_present_count = 0.0;
+    
+    //Now, we can process the discrete variable.
+    ProgressBar* pb = 0;
+    pb = new ProgressBar( &quot;Analyzing discrete variable &quot; + variable_name, main_length);
+    for (main_row = 0; main_row &lt; main_length; main_row++)
+    {
+        train_set-&gt;getRow(main_row, main_input);
+        variable_value = main_input[variable_col];
+        if (is_missing(variable_value)) continue;
+        target_value = main_input[target_col];
+        target_sum += target_value;
+        target_squared_sum += target_value * target_value;
+        variable_present_count += 1.0;
+        for (value_col = 0; value_col &lt; number_of_values; value_col++)
+        {
+            if (variable_value &lt; values_to_analyze[value_col].first || variable_value &gt; values_to_analyze[value_col].second) continue;
+            value_target_sum[value_col] += target_value;
+            value_present_count[value_col] += 1.0;
+        }
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+    if (variable_present_count &lt;= 0.0)
+    {
+        cout &lt;&lt; &quot;In AnalyzeDond2DiscreteVariables: no value present for this variable&quot; &lt;&lt; endl;
+        return;
+    }
+    target_mean = target_sum / variable_present_count;
+    cout &lt;&lt; &quot;In AnalyzeDond2DiscreteVariables, for variable:  &quot; &lt;&lt; variable_name &lt;&lt; endl;
+    cout &lt;&lt; variable_present_count &lt;&lt; &quot; values are present out of &quot; &lt;&lt; main_length &lt;&lt; &quot; samples.&quot; &lt;&lt; endl;
+    for (value_col = 0; value_col &lt; number_of_values; value_col++)
+    {
+        ssxy = value_target_sum[value_col] - value_present_count[value_col] * target_mean;
+        ss2xy = ssxy * ssxy;
+        ssxx = value_present_count[value_col] * (1.0 -  value_present_count[value_col] / variable_present_count);
+        ssyy = target_squared_sum - target_sum * target_mean;
+        correlation_coefficient = ss2xy / (ssxx * ssyy);
+        cout &lt;&lt; &quot;For value from: &quot; &lt;&lt; values_to_analyze[value_col].first &lt;&lt; &quot; to: &quot; &lt;&lt; values_to_analyze[value_col].second 
+             &lt;&lt; &quot; occurence: &quot; &lt;&lt; value_present_count[value_col] &lt;&lt; &quot; correlation coefficient: &quot; &lt;&lt; correlation_coefficient &lt;&lt; endl;
+    }
+}
+
+int AnalyzeDond2DiscreteVariables::outputsize() const {return 0;}
+void AnalyzeDond2DiscreteVariables::train() {}
+void AnalyzeDond2DiscreteVariables::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void AnalyzeDond2DiscreteVariables::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; AnalyzeDond2DiscreteVariables::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; AnalyzeDond2DiscreteVariables::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeDond2DiscreteVariables.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,167 @@
+// -*- C++ -*-
+
+// AnalyzeDond2DiscreteVariables.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file AnalyzeDond2DiscreteVariables.h */
+
+
+#ifndef AnalyzeDond2DiscreteVariables_INC
+#define AnalyzeDond2DiscreteVariables_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class AnalyzeDond2DiscreteVariables : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    
+    //! The field name of the variable to be analyzed.
+    string variable_name;
+    
+    //! The field name of the target.
+    string target_name;
+    
+    //! The vector of values to check the correlation with the target.
+    //! The algorithm groups the values from, to of each pair specified.
+    TVec&lt; pair&lt;real, real&gt; &gt; values_to_analyze;    
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    AnalyzeDond2DiscreteVariables();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(AnalyzeDond2DiscreteVariables);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void analyzeDiscreteVariable();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    
+    // input instructions variables
+    int value_col;
+    int number_of_values;
+    int variable_col;
+    int target_col;
+    Vec value_target_sum;
+    Vec value_present_count;
+    real target_sum;
+    real target_squared_sum;
+    real variable_present_count;
+    real ssxy;
+    real ss2xy;
+    real ssxx;
+    real ssyy;
+    real correlation_coefficient;
+    
+    // primary dataset variables
+    int main_length;
+    int main_width;
+    int main_row;
+    int main_col;
+    Vec main_input;
+    TVec&lt;string&gt; main_names;
+    real variable_value;
+    real target_value;
+    real target_mean;
+    
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(AnalyzeDond2DiscreteVariables);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,454 @@
+// -*- C++ -*-
+
+// AnalyzeFieldStats.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file AnalyzeFieldStats.cc */
+
+#define PL_LOG_MODULE_NAME &quot;AnalyzeFieldStats&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;AnalyzeFieldStats.h&quot;
+#include &lt;plearn/io/load_and_save.h&gt;          //!&lt;  For save
+#include &lt;plearn/io/fileutils.h&gt;              //!&lt;  For isfile()
+#include &lt;plearn/math/random.h&gt;               //!&lt;  For the seed stuff.
+#include &lt;plearn/vmat/ExplicitSplitter.h&gt;     //!&lt;  For the splitter stuff.
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    AnalyzeFieldStats,
+    &quot;Computes correlation coefficient between various discrete values and the target.&quot;,
+    &quot;name of the discrete variable, of the target and the values to check are options.\n&quot;
+);
+
+/////////////////////////
+// AnalyzeFieldStats //
+/////////////////////////
+AnalyzeFieldStats::AnalyzeFieldStats() :
+  min_number_of_samples(5000),
+  max_number_of_samples(50000)
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void AnalyzeFieldStats::declareOptions(OptionList&amp; ol)
+{
+
+    declareOption(ol, &quot;min_number_of_samples&quot;, &amp;AnalyzeFieldStats::min_number_of_samples,
+                  OptionBase::buildoption,
+                  &quot;The minimum number of samples required to train the learner.&quot;);
+    declareOption(ol, &quot;max_number_of_samples&quot;, &amp;AnalyzeFieldStats::max_number_of_samples,
+                  OptionBase::buildoption,
+                  &quot;The maximum number of samples used to train the learner&quot;);
+    declareOption(ol, &quot;targeted_set&quot;, &amp;AnalyzeFieldStats::targeted_set,
+                  OptionBase::buildoption,
+                  &quot;The train and test data sets with the target field.&quot;);
+    declareOption(ol, &quot;cond_mean_template&quot;, &amp;AnalyzeFieldStats::cond_mean_template,
+                  OptionBase::buildoption,
+                  &quot;The template of the script to learn the conditional mean.&quot;);
+    declareOption(ol, &quot;fields&quot;, &amp;AnalyzeFieldStats::fields,
+                  OptionBase::buildoption,
+                  &quot;The vector of fields to consider by names.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void AnalyzeFieldStats::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(min_number_of_samples, copies);
+    deepCopyField(max_number_of_samples, copies);
+    deepCopyField(targeted_set, copies);
+    deepCopyField(cond_mean_template, copies);
+    deepCopyField(fields, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void AnalyzeFieldStats::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void AnalyzeFieldStats::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        for (int iteration = 1; iteration &lt;= 50; iteration++)
+        {
+            cout &lt;&lt; &quot;In AnalyzeFieldStats, Iteration # &quot; &lt;&lt; iteration &lt;&lt; endl;
+            analyzeVariableStats();
+            train();
+        }
+        PLERROR(&quot;AnalyzeFieldStats: we are done here&quot;);
+    }
+}
+
+void AnalyzeFieldStats::analyzeVariableStats()
+{ 
+    // initialize primary dataset
+    main_row = 0;
+    main_col = 0;
+    main_length = train_set-&gt;length();
+    main_width = train_set-&gt;width();
+    main_input.resize(main_width);
+    main_names.resize(main_width);
+    main_names &lt;&lt; train_set-&gt;fieldNames();
+    main_metadata = train_set-&gt;getMetaDataDir();
+    
+    // validate the field instructions
+    fields_width = fields.size();
+    fields_selected.resize(main_width);
+    fields_selected.clear();
+    for (fields_col = 0; fields_col &lt; fields_width; fields_col++)
+    {
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (fields[fields_col] == main_names[main_col]) break;
+        }
+        if (main_col &gt;= main_width) PLERROR(&quot;In AnalyzeFieldStats: no field with this name in input dataset: %&quot;, (fields[fields_col]).c_str());
+        fields_selected[main_col] = 1;
+    }
+    
+    // initialize targeted datasets
+    cout &lt;&lt; &quot;initialize train_test datasets&quot; &lt;&lt; endl;
+    targeted_length = targeted_set-&gt;length();
+    targeted_width = targeted_set-&gt;width();
+    targeted_input.resize(targeted_width);
+    targeted_names.resize(targeted_width);
+    targeted_names &lt;&lt; targeted_set-&gt;fieldNames();
+    targeted_metadata = targeted_set-&gt;getMetaDataDir();
+    
+    // initialize the header file
+    cout &lt;&lt; &quot;initialize the header file&quot; &lt;&lt; endl;
+    train_set-&gt;lockMetaDataDir();
+    header_record.resize(main_width);
+    header_file_name = targeted_metadata + &quot;/TreeCondMean/header.pmat&quot;;
+    if (!isfile(header_file_name)) createHeaderFile();
+    else getHeaderRecord();
+    
+    // choose variable to build a conditionnal function for
+    cout &lt;&lt; &quot;choose variable to build a conditionnal function for&quot; &lt;&lt; endl;
+    TVec&lt;int&gt; indices;
+    to_deal_with_total = 0;
+    to_deal_with_next = -1;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (header_record[main_col] != 2.0) continue;
+        to_deal_with_total += 1;
+        if (to_deal_with_next &lt; 0) to_deal_with_next = main_col;
+    }
+    if (to_deal_with_next &lt; 0)
+    {
+        train_set-&gt;unlockMetaDataDir();
+        reviewGlobalStats();
+        PLERROR(&quot;AnalyzeFieldStats: we are done here&quot;);
+    }
+    to_deal_with_name = main_names[to_deal_with_next];
+    cout &lt;&lt; &quot;total number of variable left to deal with: &quot; &lt;&lt; to_deal_with_total &lt;&lt; endl;
+    cout &lt;&lt; &quot;next variable to deal with: &quot; &lt;&lt; main_names[to_deal_with_next] &lt;&lt; endl;
+    updateHeaderRecord(to_deal_with_next);
+    train_set-&gt;unlockMetaDataDir();
+    
+    // find the available targeted records for this variable
+    ProgressBar* pb = 0;
+    main_stats = train_set-&gt;getStats(to_deal_with_next);
+    main_total = main_stats.n();
+    main_missing = main_stats.nmissing();
+    main_present = main_total - main_missing;
+    indices.resize((int) main_present);
+    ind_next = 0;
+    pb = new ProgressBar( &quot;Building the indices for &quot; + to_deal_with_name, main_length);
+    for (main_row = 0; main_row &lt; main_length; main_row++)
+    {
+        to_deal_with_value = train_set-&gt;get(main_row, to_deal_with_next);
+        if (is_missing(to_deal_with_value)) continue;
+        if (ind_next &gt;= indices.length()) PLERROR(&quot;AnalyzeFieldStats: There seems to be more present values than indicated by the stats file&quot;);
+        indices[ind_next] = main_row;
+        ind_next += 1;
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+    
+    // shuffle the indices.
+    manual_seed(123456);
+    shuffleElements(indices);
+    
+    // initialize output datasets
+    output_length = (int) main_present;
+    if (output_length &gt; max_number_of_samples) output_length = max_number_of_samples;
+    output_width = 0;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (header_record[main_col] != 1) output_width += 1;
+    }
+    output_variable_src.resize(output_width);
+    output_names.resize(output_width);
+    output_vec.resize(output_width);
+    output_path = main_metadata + &quot;condmean_&quot; + to_deal_with_name + &quot;.pmat&quot;;
+    output_col = 0;
+    for (fields_col = 0; fields_col &lt; fields_width; fields_col++)
+    {
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (fields[fields_col] == main_names[main_col]) break;
+        }
+        if (main_col &gt;= main_width) PLERROR(&quot;In AnalyzeFieldStats: no field with this name in input dataset: %&quot;, (fields[fields_col]).c_str());
+        if (fields_col != to_deal_with_next &amp;&amp; header_record[main_col] != 1)
+        {
+            output_variable_src[output_col] = main_col;
+            output_names[output_col] = fields[fields_col];
+            output_col += 1;
+        }
+    }
+    output_variable_src[output_col] = to_deal_with_next;
+    output_names[output_col] = to_deal_with_name;
+    output_file = new MemoryVMatrix(output_length, output_width);
+    output_file-&gt;declareFieldNames(output_names);
+    output_file-&gt;defineSizes(output_width - 1, 1, 0);
+    
+    //Now, we can build the training file
+    pb = new ProgressBar( &quot;Building the training file for &quot; + to_deal_with_name, output_length);
+    for (main_row = 0; main_row &lt; output_length; main_row++)
+    {
+        train_set-&gt;getRow(indices[main_row], main_input);
+        for (output_col = 0; output_col &lt; output_width; output_col++)
+        {
+            output_vec[output_col] = main_input[output_variable_src[output_col]];
+        }
+        output_file-&gt;putRow(main_row, output_vec);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+    
+    // initialize train_test datasets
+    train_test_length = targeted_length;
+    train_test_variable_src.resize(output_width);
+    train_test_path = targeted_metadata + &quot;targeted_&quot; + to_deal_with_name + &quot;.pmat&quot;;
+    output_col = 0;
+    for (fields_col = 0; fields_col &lt; fields_width; fields_col++)
+    {
+        for (main_col = 0; main_col &lt; targeted_width; main_col++)
+        {
+            if (fields[fields_col] == targeted_names[main_col]) break;
+        }
+        if (main_col &gt;= targeted_width) PLERROR(&quot;In AnalyzeFieldStats: no field with this name in targeted dataset: %&quot;, (fields[fields_col]).c_str());
+        if (fields_col != to_deal_with_next &amp;&amp; header_record[main_col] != 1)
+        {
+            train_test_variable_src[output_col] = main_col;
+            output_col += 1;
+        }
+    }
+    train_test_variable_src[output_col] = to_deal_with_next;
+    train_test_file = new MemoryVMatrix(train_test_length, output_width);
+    train_test_file-&gt;declareFieldNames(output_names);
+    train_test_file-&gt;defineSizes(output_width - 1, 1, 0);
+    
+    //Now, we can build the targeted file
+    pb = new ProgressBar( &quot;Building the targeted file for &quot; + to_deal_with_name, train_test_length);
+    for (main_row = 0; main_row &lt; train_test_length; main_row++)
+    {
+        targeted_set-&gt;getRow(main_row, targeted_input);
+        for (output_col = 0; output_col &lt; output_width; output_col++)
+        {
+            output_vec[output_col] = targeted_input[train_test_variable_src[output_col]];
+        }
+        train_test_file-&gt;putRow(main_row, output_vec);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+}
+
+void AnalyzeFieldStats::createHeaderFile()
+{ 
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        targeted_stats = targeted_set-&gt;getStats(main_col);
+        targeted_missing = targeted_stats.nmissing();
+        main_stats = train_set-&gt;getStats(main_col);
+        main_total = main_stats.n();
+        main_missing = main_stats.nmissing();
+        main_present = main_total - main_missing;
+        if (fields_selected[main_col] &lt; 1) header_record[main_col] = 1;                  // delete column, field not selected
+        else if (targeted_missing &lt;= 0) header_record[main_col] = 0;                     // nothing to do
+        else if (main_present &lt; min_number_of_samples) header_record[main_col] = 1;      // delete column
+        else header_record[main_col] = 2;                                                // build tree
+    }
+    header_file = new FileVMatrix(header_file_name, 1, main_names);
+    header_file-&gt;putRow(0, header_record);
+}
+
+void AnalyzeFieldStats::getHeaderRecord()
+{ 
+    header_file = new FileVMatrix(header_file_name, true);
+    header_file-&gt;getRow(0, header_record);
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (header_record[main_col] == 0) continue;
+        if (header_record[main_col] == 2) continue;
+        if (header_record[main_col] == 1 &amp;&amp; fields_selected[main_col] &lt; 1) continue;
+        if (header_record[main_col] == 1)
+        {
+            main_stats = train_set-&gt;getStats(main_col);
+            main_total = main_stats.n();
+            main_missing = main_stats.nmissing();
+            main_present = main_total - main_missing;
+            if (main_present &gt;= min_number_of_samples) header_record[main_col] = 2;
+            continue;
+        }
+    }
+}
+
+void AnalyzeFieldStats::updateHeaderRecord(int var_col)
+{ 
+    header_file-&gt;put(0, var_col, 3.0);
+}
+
+void AnalyzeFieldStats::reviewGlobalStats()
+{ 
+    cout &lt;&lt; &quot;There is no more variable to deal with.&quot; &lt;&lt; endl;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (header_record[main_col] == 0)
+        { 
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : no missing values for this variable in the targeted files.&quot; &lt;&lt; endl;
+            continue;
+        }
+        if (header_record[main_col] == 1 &amp;&amp; fields_selected[main_col] &lt; 1)
+        {
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : field not selected.&quot; &lt;&lt; endl;
+            continue;
+        }
+        if (header_record[main_col] == 1)
+        {
+            main_stats = train_set-&gt;getStats(main_col);
+            main_total = main_stats.n();
+            main_missing = main_stats.nmissing();
+            main_present = main_total - main_missing;
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : field deleted, only &quot; &lt;&lt; setw(6) &lt;&lt; main_present &lt;&lt; &quot; records to train with.&quot; &lt;&lt; endl;
+            continue;
+        }
+        results_file_name = targeted_metadata + &quot;/TreeCondMean/dir/&quot; + main_names[main_col] + &quot;/Split0/LearnerExpdir/Strat0results.pmat&quot;;
+        if (!isfile(results_file_name))
+        {
+            header_file-&gt;put(0, main_col, 2.0);
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : missing results file.&quot; &lt;&lt; endl;
+            continue;
+        }
+        test_output_file_name = targeted_metadata + &quot;/TreeCondMean/dir/&quot; + main_names[main_col] + &quot;/Split0/test1_outputs.pmat&quot;;
+        if (!isfile(test_output_file_name))
+        {
+            header_file-&gt;put(0, main_col, 2.0);
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : missing test output file.&quot; &lt;&lt; endl;
+            continue;
+        }
+        results_file = new FileVMatrix(results_file_name);
+        results_length = results_file-&gt;length();
+        results_nstages = results_file-&gt;get(results_length - 1, 2);
+        results_mse = results_file-&gt;get(results_length - 1, 6);
+        results_std_err = results_file-&gt;get(results_length - 1, 7);
+        test_output_file = new FileVMatrix(test_output_file_name);
+        test_output_length = test_output_file-&gt;length();
+        cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+        cout &lt;&lt; &quot; : tree built with &quot; &lt;&lt; setw(2) &lt;&lt; (int) results_nstages &lt;&lt; &quot; leaves, &quot;
+             &lt;&lt; setw(6) &lt;&lt; test_output_length &lt;&lt; &quot; test output records found, &quot;
+             &lt;&lt; &quot;performance: &quot; &lt;&lt; setiosflags(ios::fixed) &lt;&lt; setprecision(4) &lt;&lt; results_mse
+             &lt;&lt; &quot; +/- &quot; &lt;&lt; setiosflags(ios::fixed) &lt;&lt; setprecision(4) &lt;&lt; results_std_err &lt;&lt; endl;
+    }
+}
+
+void AnalyzeFieldStats::train()
+{
+    PP&lt;ExplicitSplitter&gt; explicit_splitter = new ExplicitSplitter();
+    explicit_splitter-&gt;splitsets.resize(1,2);
+    explicit_splitter-&gt;splitsets(0,0) = output_file;
+    explicit_splitter-&gt;splitsets(0,1) = train_test_file;
+    cond_mean = ::PLearn::deepCopy(cond_mean_template);
+    cond_mean-&gt;setOption(&quot;expdir&quot;, targeted_metadata + &quot;/TreeCondMean/dir/&quot; + to_deal_with_name);
+    cond_mean-&gt;splitter = new ExplicitSplitter();
+    cond_mean-&gt;splitter = explicit_splitter;
+    cond_mean-&gt;build();
+    Vec results = cond_mean-&gt;perform(true);
+}
+
+int AnalyzeFieldStats::outputsize() const {return 0;}
+void AnalyzeFieldStats::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void AnalyzeFieldStats::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; AnalyzeFieldStats::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; AnalyzeFieldStats::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/AnalyzeFieldStats.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,200 @@
+// -*- C++ -*-
+
+// AnalyzeFieldStats.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file AnalyzeFieldStats.h */
+
+
+#ifndef AnalyzeFieldStats_INC
+#define AnalyzeFieldStats_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/testers/PTester.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/vmat/MemoryVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class AnalyzeFieldStats : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    
+    //! The minimum number of samples required to train the learner.
+    int min_number_of_samples;
+    //! The maximum number of samples used to train the learner.
+    int max_number_of_samples;
+    //! The train and test data sets with the target field.
+    VMat targeted_set;
+    //! The template of the script to learn the conditional mean
+    PP&lt;PTester&gt; cond_mean_template;
+    //! The field name of the variable to be analyzed.
+    TVec&lt;string&gt; fields;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    AnalyzeFieldStats();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(AnalyzeFieldStats);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void analyzeVariableStats();
+    void createHeaderFile();
+    void getHeaderRecord();
+    void updateHeaderRecord(int var_col);
+    void reviewGlobalStats();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    
+    int main_row;
+    int main_col;
+    int main_length;
+    int main_width;
+    Vec main_input;
+    TVec&lt;string&gt; main_names;
+    StatsCollector  main_stats;
+    PPath main_metadata;
+    TVec&lt;int&gt; main_ins;
+    real main_total;
+    real main_missing;
+    real main_present;
+    int targeted_length;
+    int targeted_width;
+    Vec targeted_input;
+    TVec&lt;string&gt; targeted_names;
+    StatsCollector  targeted_stats;
+    PPath targeted_metadata;
+    real targeted_missing;
+    PPath header_file_name;
+    VMat header_file;
+    Vec header_record;
+    int fields_col;
+    int fields_width;
+    TVec&lt;int&gt; fields_selected;
+    int to_deal_with_total;
+    int to_deal_with_next;
+    real to_deal_with_value;
+    string to_deal_with_name;
+    int ind_next;
+    int output_length;
+    int output_width;
+    int output_col;
+    string output_path;
+    TVec&lt;string&gt; output_names;
+    Vec output_vec;
+    TVec&lt;int&gt; output_variable_src;
+    VMat output_file;
+    int train_test_length;
+    string train_test_path;
+    TVec&lt;int&gt; train_test_variable_src;
+    VMat train_test_file;
+    PP&lt;PTester&gt; cond_mean;
+    PPath results_file_name;
+    VMat results_file;
+    int results_length;
+    real results_nstages;
+    real results_mse;
+    real results_std_err;
+    PPath test_output_file_name;
+    VMat test_output_file;
+    int test_output_length;
+    
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(AnalyzeFieldStats);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,797 @@
+// -*- C++ -*-
+
+// BallTreeNearestNeighbors.cc
+//
+// Copyright (C) 2004 Pascal Lamblin &amp; Marius Muja
+// 
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************      
+ * $Id: BallTreeNearestNeighbors.cc 4911 2006-02-09 22:02:57Z lamblin $ 
+ ******************************************************* */
+
+// Authors: Pascal Lamblin &amp; Marius Muja
+
+/*! \file BallTreeNearestNeighbors.cc */
+
+#include &quot;BallTreeNearestNeighbors.h&quot;
+#include &lt;plearn/base/lexical_cast.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+BallTreeNearestNeighbors::BallTreeNearestNeighbors() 
+    : rmin( 1 ),
+      train_method( &quot;anchor&quot; )
+{
+    num_neighbors = 1;
+    expdir = &quot;&quot;;
+    stage = 0;
+    nstages = -1;
+    report_progress = 0;
+}
+
+BallTreeNearestNeighbors::BallTreeNearestNeighbors( const VMat&amp; tr_set, const BinBallTree&amp; b_tree )
+    : rmin( 1 ),
+      train_method( &quot;anchor&quot; )
+{
+    num_neighbors = 1;
+    expdir = &quot;&quot;;
+    stage = 1;
+    nstages = 1;
+    report_progress = 0;
+
+    setTrainingSet( tr_set );
+    ball_tree = b_tree;
+}
+
+PLEARN_IMPLEMENT_OBJECT( BallTreeNearestNeighbors, 
+                         &quot;Organizes hierarchically a set of points to perform efficient  KNN search&quot;, 
+                         &quot;This learner builds a Ball Tree, a hierarchized structure\n&quot;
+                         &quot;allowing to perform efficient KNN search.\n&quot;
+                         &quot;Output is formatted as in GenericNearestNeighbors.\n&quot;
+                         &quot;The square distance to this point can be computed as the error.\n&quot; );
+
+void BallTreeNearestNeighbors::declareOptions( OptionList&amp; ol )
+{
+    // build options
+    declareOption( ol, &quot;point_indices&quot;, &amp;BallTreeNearestNeighbors::point_indices, 
+                   OptionBase::buildoption,
+                   &quot;Indices of the points we will consider&quot; );
+
+    declareOption( ol, &quot;rmin&quot;, &amp;BallTreeNearestNeighbors::rmin, OptionBase::buildoption,
+                   &quot;Max number of points in a leaf node of the tree&quot; );
+
+    declareOption( ol, &quot;train_method&quot;, &amp;BallTreeNearestNeighbors::train_method, 
+                   OptionBase::buildoption,
+                   &quot;Method used to build the tree. Just one is supported:\n&quot;
+                   &quot;  \&quot;anchor\&quot; (middle-out building based on Anchor\'s hierarchy\n&quot;
+        );
+
+    declareOption( ol, &quot;anchor_set&quot;, &amp;BallTreeNearestNeighbors::anchor_set, 
+                   OptionBase::learntoption, 
+                   &quot;Set of anchors, hierarchizing the set of points&quot; );
+
+    declareOption( ol, &quot;pivot_indices&quot;, &amp;BallTreeNearestNeighbors::pivot_indices, 
+                   OptionBase::learntoption, &quot;Indices of the anchors' centers&quot; );
+
+    // saved options
+    declareOption( ol, &quot;train_set&quot;, &amp;BallTreeNearestNeighbors::train_set, 
+                   OptionBase::buildoption,
+                   &quot;Indexed set of points we will be working with&quot; );
+
+    declareOption( ol, &quot;nb_train_points&quot;, &amp;BallTreeNearestNeighbors::nb_train_points, 
+                   OptionBase::learntoption, &quot;Number of points in train_set&quot; );
+
+    declareOption( ol, &quot;nb_points&quot;, &amp;BallTreeNearestNeighbors::nb_points, 
+                   OptionBase::learntoption, &quot;Number of points in point_indices&quot; );
+
+    declareOption( ol, &quot;ball_tree&quot;, &amp;BallTreeNearestNeighbors::ball_tree, 
+                   OptionBase::learntoption, &quot;Built ball-tree&quot; );
+
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions( ol );
+}
+
+void BallTreeNearestNeighbors::build_()
+{
+    if (train_set) {
+        // initialize nb_train_points
+        nb_train_points = train_set.length();
+        
+        // if point_indices isn't specified, we take all the points in train_set
+        if( !point_indices )
+            point_indices = TVec&lt;int&gt;( 0, nb_train_points-1, 1 );
+
+        // initialize nb_points
+        nb_points = point_indices.size();
+    }
+}
+
+
+void BallTreeNearestNeighbors::build()
+{
+    inherited::build();
+    build_();
+}
+
+
+void BallTreeNearestNeighbors::makeDeepCopyFromShallowCopy(map&lt;const void*, void*&gt;&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField( ball_tree, copies );
+    deepCopyField( point_indices, copies );
+    deepCopyField( anchor_set, copies );
+    deepCopyField( pivot_indices, copies );
+}
+
+
+void BallTreeNearestNeighbors::forget()
+{
+    //! (Re-)initialize the PLearner in its fresh state (that state may depend on the 'seed' option)
+    //! And sets 'stage' back to 0   (this is the stage of a fresh learner!)
+
+    anchor_set.resize( 0 );
+    pivot_indices.resize( 0 );
+    ball_tree = new BinaryBallTree;
+    stage = 0;
+    build();
+}
+
+
+
+
+void BallTreeNearestNeighbors::train()
+{
+    // The role of the train method is to bring the learner up to stage==nstages,
+    // updating train_stats with training costs measured on-line in the process.
+
+    if( train_method == &quot;anchor&quot; )
+    {
+        anchorTrain();
+    }
+    else
+        PLERROR( &quot;train_method \&quot;%s\&quot; not implemented&quot;, train_method.c_str() );
+}
+
+
+void BallTreeNearestNeighbors::anchorTrain()
+{
+    /*  nstages and stage conventions, for &quot;anchor&quot; train method:
+     *
+     *  nstages == -1
+     *    We will construct ball_tree recursively,
+     *    until, for all leaf, nb_points &lt;= rmin,
+     *    no matter how many iterations it will take.
+     *
+     *  nstages == 0
+     *    We want the PLearner il its fresh, blank state.
+     *
+     *  nstages == 1
+     *    We want ball_tree to be a unique leaf node,
+     *    containing all the point indices, with no children.
+     *
+     *  nstages &gt; 1
+     *    We want to build ball_tree recursively,
+     *    but limiting the levels of recursion.
+     *    This means we will decrement this number at each recursive call,
+     *    the recursion will stop when nstages == 1 or nb_points &lt;= rmin.
+     *
+     *  stage == 0
+     *    The learner is it its fresh, blank state.
+     *
+     *  stage == 1
+     *    The learner has one anchor, that's all.
+     *
+     *  Other values of stage might be used one day or anoter...
+     */
+
+    if( stage == 0 &amp;&amp; nstages !=0 )
+    {
+        // That means we weren't provided with any anchor nor node parameter,
+        // or that they were just bullsh!t
+
+        // So, we build a single anchor
+        pivot_indices.resize( 1 );
+        pivot_indices[ 0 ] = 0;
+        Vec pivot = train_set.getSubRow( 0, inputsize() );
+
+        distance_kernel-&gt;setDataForKernelMatrix( train_set );
+        distance_kernel-&gt;build();
+        Vec distances_from_pivot( nb_train_points );
+        distance_kernel-&gt;evaluate_all_i_x( pivot, distances_from_pivot );
+
+        anchor_set.resize( 1 );
+        Mat* p_anchor = &amp;anchor_set[ 0 ];
+        p_anchor-&gt;resize( nb_points, 2 );
+        p_anchor-&gt;column( 0 ) &lt;&lt; Vec( 0, nb_points-1, 1 );
+        p_anchor-&gt;column( 1 ) &lt;&lt; distances_from_pivot;
+        sortRows( *p_anchor, TVec&lt;int&gt;( 1, 1 ), false );
+
+        // then, we build the corresponding tree
+        ball_tree = leafFromAnchor( 0 );
+
+        ++stage;
+    }
+
+    if( nstages == 0 )
+    {
+        // we want a fresh, blank learner
+        forget();
+    }
+    else if( nstages == 1 )
+    {
+        // We have an anchor, and we want a leaf node
+        ball_tree = leafFromAnchor( 0 );
+    }
+    else
+    {
+        // nstages to be used on children learners
+        int new_nstages = nstages&lt;0 ? -1 : nstages-1;
+
+        // First create sqrt( R )-1 anchors, from the initial anchor_set
+        int nb_anchors = (int) sqrt( (float) nb_points ) + 1 ;
+        nb_anchors = min( nb_anchors, nb_points );
+
+        createAnchors( nb_anchors-1 ); // because we already have one
+
+        // Convert them into leaf nodes
+        TVec&lt; BinBallTree &gt; leaf_set = TVec&lt;BinBallTree&gt;( nb_anchors );
+        for ( int i=0 ; i&lt;nb_anchors ; i++ )
+        {
+            leaf_set[ i ] = leafFromAnchor( i );
+        }
+
+        // Then, group them to form the ball_tree
+        // keep an index of the leaves
+        ball_tree = treeFromLeaves( leaf_set );
+
+        // Now, recurse...
+        for( int i=0 ; i&lt;leaf_set.size() ; i++ )
+        {
+            int rec_nb_points = anchor_set[ i ].length();
+
+            // if the leaf is too small, don't do anything
+            if( rec_nb_points &gt; rmin )
+            {
+                // child learner
+                PP&lt;BallTreeNearestNeighbors&gt; p_rec_learner = new BallTreeNearestNeighbors();
+
+                // initializes child's nstages (see explanation above)
+                stringstream out;
+                out &lt;&lt; new_nstages;
+                p_rec_learner-&gt;setOption( &quot;nstages&quot; , out.str() );
+
+                // keep the same training set: it give us all the point coordinates !
+                // but we don't want to call forget() after that
+                p_rec_learner-&gt;setTrainingSet( train_set, false );
+
+                // however, we only work on the points contained by current leaf
+                p_rec_learner-&gt;anchor_set.resize( 1 );
+                p_rec_learner-&gt;anchor_set[ 0 ].resize( rec_nb_points, 2 );
+                p_rec_learner-&gt;anchor_set[ 0 ] &lt;&lt; anchor_set[ i ];
+
+                p_rec_learner-&gt;pivot_indices.resize( 1 );
+                p_rec_learner-&gt;pivot_indices[ 0 ] = pivot_indices[ i ];
+
+                p_rec_learner-&gt;point_indices.resize( rec_nb_points );
+                p_rec_learner-&gt;point_indices &lt;&lt; 
+                    p_rec_learner-&gt;anchor_set[ 0 ].column( 0 );
+
+                p_rec_learner-&gt;stage = 1; 
+                // faudra peut-etre faire &#231;a plus subtilement
+
+                p_rec_learner-&gt;rmin = rmin;
+                p_rec_learner-&gt;train_method = train_method;
+                p_rec_learner-&gt;build();
+                p_rec_learner-&gt;train();
+
+                // once the child learner is trained, we can get the sub-tree,
+                // and link it correctly
+                BinBallTree subtree = p_rec_learner-&gt;getBallTree();
+                leaf_set[ i ]-&gt;pivot = subtree-&gt;pivot;
+                leaf_set[ i ]-&gt;radius = subtree-&gt;radius;
+                leaf_set[ i ]-&gt;point_set.resize( subtree-&gt;point_set.size() );
+                leaf_set[ i ]-&gt;point_set &lt;&lt; subtree-&gt;point_set;
+                leaf_set[ i ]-&gt;setFirstChild( subtree-&gt;getFirstChild() );
+                leaf_set[ i ]-&gt;setSecondChild( subtree-&gt;getSecondChild() );
+
+            }
+        }
+    }
+}
+
+
+void BallTreeNearestNeighbors::createAnchors( int nb_anchors )
+{
+    // This method creates nb_anchors new anchors, and adds them to anchor_set
+
+    // Make room
+    int anchor_set_size = anchor_set.size();
+    anchor_set.resize( anchor_set_size, nb_anchors );
+
+    for( int i=0 ; i&lt;nb_anchors ; i++ )
+    {
+        Mat new_anchor = Mat( 1, 2 );
+        int new_pivot_index;
+
+        // Search for the largest ball.
+        // pivot of the new anchor will be the point of this ball
+        // that is the furthest from the pivot.
+        int largest_index = 0;
+        real largest_radius = 0;
+        for( int j=0 ; j&lt;anchor_set_size ; j++ )
+        {
+            // points are sorted in decreasing order of distance, 
+            // so anchor_set[ j ]( 0, 1 ) is the furthest point from 
+            // pivot_indices[ j ]
+            real current_radius = anchor_set[ j ]( 0, 1 );
+            if( current_radius &gt; largest_radius )
+            {
+                largest_radius = current_radius;
+                largest_index = j;
+            }
+        }
+
+        Mat* p_largest_anchor = &amp;anchor_set[ largest_index ];
+        new_pivot_index = (int) (*p_largest_anchor)( 0, 0 );
+
+        // assign the point to its new anchor
+        new_anchor( 0, 0 ) = new_pivot_index;
+        new_anchor( 0, 1 ) = 0;
+        Vec new_pivot = train_set.getSubRow( new_pivot_index, inputsize() );
+
+        int largest_anchor_length = p_largest_anchor-&gt;length();
+
+        // Verify that largest_anchor owns at least 2 points
+        if( largest_anchor_length &lt;= 1 )
+        {
+            PLERROR(&quot;In BallTreeNearestNeighbors::createAnchors, more anchors asked than points&quot;);
+        }
+
+        // delete this point from its original anchor
+        *p_largest_anchor = p_largest_anchor-&gt;
+            subMatRows( 1, largest_anchor_length-1 );
+
+        // now, try to steal points from all the existing anchors
+        for( int j=0 ; j&lt;anchor_set_size ; j++ )
+        {
+            Mat* p_anchor = &amp;anchor_set[ j ];
+            int nb_points = p_anchor-&gt;length();
+            int pivot_index = pivot_indices[ j ];
+            Vec pivot = train_set.getSubRow( pivot_index, inputsize() );
+            real pivot_pow_dist = powdistance( new_pivot, pivot, 2 );
+
+            // loop on the anchor's points
+            for( int k=0 ; k&lt;nb_points ; k++ )
+            {
+                int point_index = (int) (*p_anchor)( k, 0 );
+                real point_pow_dist = (*p_anchor)( k, 1 );
+
+                // if this inequality is verified,
+                // then we're sure that all the points closer to the pivot 
+                // belong to the pivot, and we don't need to check
+                if( 4*point_pow_dist &lt; pivot_pow_dist )
+                {
+                    break;
+                }
+
+                Vec point = train_set.getSubRow( point_index, inputsize() );
+                real new_pow_dist = powdistance( new_pivot, point, 2 );
+
+                // if the point is closer to the new pivot, then steal it
+                if( new_pow_dist &lt; point_pow_dist )
+                {
+                    Vec new_row( 2 );
+                    new_row[ 0 ] = point_index;
+                    new_row[ 1 ] = new_pow_dist;
+                    new_anchor.appendRow( new_row );
+
+                    *p_anchor = removeRow( *p_anchor, k );
+                    // bleaah, this is ugly !
+                    --k;
+                    --nb_points;
+                }
+            }
+        }
+
+        // sort the points by decreasing distance
+        sortRows( new_anchor, TVec&lt;int&gt;( 1, 1 ), false );
+
+        // append the new anchor to the anchor_set (and same for pivot)
+        anchor_set.append( new_anchor );
+        pivot_indices.append( new_pivot_index );
+        ++anchor_set_size;
+    }
+}
+
+BinBallTree BallTreeNearestNeighbors::leafFromAnchor( int anchor_index )
+{
+    BinBallTree leaf = new BinaryBallTree();
+
+    int pivot_index = pivot_indices[ anchor_index ];
+    leaf-&gt;pivot = train_set.getSubRow( pivot_index, inputsize() );
+
+    leaf-&gt;radius = anchor_set[ anchor_index ]( 0, 1 );
+
+    int nb_leaf_points = anchor_set[ anchor_index ].length();
+    leaf-&gt;point_set.resize( nb_leaf_points );
+    leaf-&gt;point_set &lt;&lt; anchor_set[ anchor_index ].column( 0 );
+
+    return leaf;
+}
+
+
+BinBallTree BallTreeNearestNeighbors::treeFromLeaves( const TVec&lt;BinBallTree&gt;&amp; leaves )
+{
+    int nb_nodes = leaves.size();
+    TVec&lt;BinBallTree&gt; nodes = TVec&lt;BinBallTree&gt;( nb_nodes );
+    nodes &lt;&lt; leaves;
+
+    // if there is no leaf
+    if( nb_nodes &lt; 1 )
+    {
+        PLERROR( &quot;In BallTreeNearestNeighbors::treeFromLeaves(): no leaf existing&quot; );
+    }
+
+    while( nb_nodes &gt; 1 )
+    {
+        int min_i = 0;
+        int min_j = 0;
+        Vec min_center;
+        real min_radius = -1;
+
+        // we get the most &quot;compatible&quot; pair of nodes :
+        // the ball containing them both is the smallest
+        for( int i=0 ; i&lt;nb_nodes ; i++ )
+        {
+            Vec center_i = nodes[ i ]-&gt;pivot;
+            real radius_i = nodes[ i ]-&gt;radius;
+
+            // to scan all pairs only once, and avoid i==j
+            for( int j=0 ; j&lt;i ; j++ )
+            {
+                Vec center_j = nodes[ j ]-&gt;pivot;
+                real radius_j = nodes[ j ]-&gt;radius;
+
+                Vec t_center;
+                real t_radius;
+                smallestContainer( center_i, radius_i, center_j, radius_j, 
+                                   t_center, t_radius );
+
+                if( t_radius &lt; min_radius || min_radius &lt; 0 )
+                {
+                    min_i = i;
+                    min_j = j ;
+                    min_radius = t_radius;
+                    min_center = t_center;
+                }
+            }
+        }
+
+#ifdef DEBUG_CHECK_NAN
+        if (min_center.hasMissing())
+            PLERROR(&quot;In BallTreeNearestNeighbors::treeFromLeaves: min_center is NaN&quot;);
+#endif
+        
+        // Group these two nodes into a parent_node.
+        // TODO: something more sensible for the radius and center...
+        BinBallTree parent_node = new BinaryBallTree();
+        parent_node-&gt;pivot = min_center;
+        parent_node-&gt;radius = min_radius;
+        parent_node-&gt;setFirstChild( nodes[ min_i ] );
+        parent_node-&gt;setSecondChild( nodes[ min_j ] );
+
+        nodes[ min_j ] = parent_node;
+        nodes.remove( min_i );
+
+        --nb_nodes;
+    }
+
+    // then, we have only one anchor
+    BinBallTree root = nodes[ 0 ];
+    return root;
+}
+
+
+BinBallTree BallTreeNearestNeighbors::getBallTree()
+{
+    return ball_tree;
+}
+
+
+void BallTreeNearestNeighbors::computeOutputAndCosts(
+    const Vec&amp; input, const Vec&amp; target, Vec&amp; output, Vec&amp; costs ) const
+{
+    int nout = outputsize();
+    output.resize( nout );
+    costs.resize( num_neighbors );
+
+    // we launch a k-nearest-neighbors query on the root node (ball_tree)
+    priority_queue&lt; pair&lt;real,int&gt; &gt; q;
+    FindBallKNN( q, input, num_neighbors );
+
+    // dequeue the found nearest neighbors, beginning by the farthest away
+    int n_found = q.size();
+    TVec&lt;int&gt; neighbors( n_found );
+    for( int i=n_found-1 ; i&gt;=0 ; i-- )
+    {
+        const pair&lt;real,int&gt;&amp; cur_top = q.top();
+        costs[i] = cur_top.first;
+        neighbors[i] = cur_top.second;
+        q.pop();
+    }
+
+    // fill costs with missing values
+    for( int i= n_found ; i&lt;num_neighbors ; i++ )
+        costs[i] = MISSING_VALUE;
+
+    constructOutputVector( neighbors, output );
+}
+
+void BallTreeNearestNeighbors::computeOutput(
+    const Vec&amp; input, Vec&amp; output ) const
+{
+    // Compute the output from the input.
+    // int nout = outputsize();
+    // output.resize(nout);
+
+    int nout = outputsize();
+    output.resize( nout );
+
+    // we launch a k-nearest-neighbors query on the root node (ball_tree)
+    priority_queue&lt; pair&lt;real,int&gt; &gt; q;
+    FindBallKNN( q, input, num_neighbors );
+
+    // dequeue the found nearest neighbors, beginning by the farthest away
+    int n_found = q.size();
+    TVec&lt;int&gt; neighbors( n_found );
+    for( int i=n_found-1 ; i&gt;=0 ; i-- )
+    {
+        const pair&lt;real,int&gt;&amp; cur_top = q.top();
+        neighbors[i] = cur_top.second;
+        q.pop();
+    }
+
+    constructOutputVector( neighbors, output );
+
+}
+
+
+void BallTreeNearestNeighbors::computeCostsFromOutputs(
+    const Vec&amp; input, const Vec&amp; output, const Vec&amp; target, Vec&amp; costs ) const
+{
+    // Compute the costs from *already* computed output.
+    costs.resize( num_neighbors );
+
+    int inputsize = train_set-&gt;inputsize();
+    int targetsize = train_set-&gt;targetsize();
+    int weightsize = train_set-&gt;weightsize();
+
+    Mat out( num_neighbors, inputsize );
+
+    if( copy_input )
+    {
+        for( int i=0 ; i&lt;num_neighbors ; i++ )
+            out( i ) &lt;&lt; output.subVec( i*outputsize(), inputsize );
+    }
+    else if( copy_index )
+    {
+        int offset = 0;
+
+        if( copy_target )
+            offset += targetsize;
+
+        if( copy_weight )
+            offset += weightsize;
+
+        for( int i=0 ; i&lt;num_neighbors ; i++ )
+            out( i ) &lt;&lt; train_set( (int) output[ i*outputsize() + offset ] );
+    }
+    else
+    {
+        PLERROR( &quot;computeCostsFromOutput:\n&quot;
+                 &quot;neither indices nor coordinates of output computed\n&quot; );
+    }
+
+    for( int i=0 ; i&lt;num_neighbors ; i++ )
+        costs[ i ] = powdistance( input, out( i ) );
+}
+
+TVec&lt;string&gt; BallTreeNearestNeighbors::getTestCostNames() const
+{
+    return TVec&lt;string&gt;( num_neighbors, &quot;squared_distance&quot; );
+}
+
+TVec&lt;string&gt; BallTreeNearestNeighbors::getTrainCostNames() const
+{
+    return TVec&lt;string&gt;();
+}
+
+bool BallTreeNearestNeighbors::intersect(
+    const Vec&amp; center1, const real&amp; powrad1,
+    const Vec&amp; center2, const real&amp; powrad2 )
+{
+    real radius1 = sqrt( powrad1 );
+    real radius2 = sqrt( powrad2 );
+
+    real pow_dist = powdistance( center1, center2, 2 );
+    real rad_sum = radius1 + radius2;
+    bool result = ( pow_dist &lt;= ( rad_sum * rad_sum ) );
+    return result;
+}
+
+bool BallTreeNearestNeighbors::contain(
+    const Vec&amp; center1, const real&amp; powrad1,
+    const Vec&amp; center2, const real&amp; powrad2 )
+{
+    real radius1 = sqrt( powrad1 );
+    real radius2 = sqrt( powrad2 );
+    real rad_dif = radius1 - radius2;
+
+    if( rad_dif &gt;= 0 )
+    {
+        real pow_dist = powdistance( center1, center2, 2 );
+        bool result = ( pow_dist &lt;= ( rad_dif * rad_dif ) );
+        return result;
+    }
+    else
+    {
+        return false;
+    }
+}
+
+void BallTreeNearestNeighbors::smallestContainer(
+    const Vec&amp; center1, const real&amp; powrad1,
+    const Vec&amp; center2, const real&amp; powrad2,
+    Vec&amp; t_center, real&amp; t_powrad )
+{
+    if( center1 == center2 )
+    {
+        t_center = center1;
+        t_powrad = max( powrad1, powrad2 );
+    }
+    else if( contain( center1, powrad1, center2, powrad2 ) )
+    {
+        t_center = center1;
+        t_powrad = powrad1;
+    }
+    else if( contain( center2, powrad2, center1, powrad1 ) )
+    {
+        t_center = center2;
+        t_powrad = powrad2;
+    }
+    else
+    {
+        real radius1 = sqrt( powrad1 );
+        real radius2 = sqrt( powrad2 );
+        real center_dist = dist( center1, center2, 2 ) ;
+        real coef = ( radius1 - radius2 ) / center_dist ;
+        t_center = real(0.5) * ( ( 1 + coef ) * center1  +  ( 1 - coef ) * center2 ) ;
+        real t_radius = real(0.5) * ( center_dist + radius1 + radius2 ) ;
+        t_powrad = t_radius * t_radius;
+    }
+
+#ifdef DEBUG_CHECK_NAN
+    if (t_center.hasMissing())
+        PLERROR(&quot;In BallTreeNearestNeighbors::smallestContainer: t_center is NaN.&quot;);
+#endif
+}
+
+
+
+void BallTreeNearestNeighbors::BallKNN(
+     priority_queue&lt; pair&lt;real,int&gt; &gt;&amp; q, BinBallTree node,
+     const Vec&amp; t, real&amp; d2_sofar, real d2_pivot, const int k ) const
+{
+    real d_minp = max( sqrt(d2_pivot) - node-&gt;radius, 0.0 );
+#ifdef DEBUG_CHECK_NAN
+    if (isnan(d_minp))
+        PLERROR(&quot;BallTreeNearestNeighbors::BallKNN: d_minp is NaN&quot;);
+#endif
+
+    if (d_minp*d_minp &gt; d2_sofar)
+    {
+        // no chance of finding anything closer around this node
+        return;
+    }
+    else if (node-&gt;point_set.size()!=0) // node is leaf
+    {
+        int n_points = node-&gt;point_set.size();
+        for( int i=0 ; i&lt;n_points ; i++ )
+        {
+            int j = node-&gt;point_set[i];
+            real dist;
+            // last point is pivot, and we already now the distance
+            if( i==n_points-1 )
+            {
+                dist = d2_pivot;
+            }
+            else
+            {
+                Vec x = train_set.getSubRow(j, inputsize());
+                dist = powdistance(x, t, 2);
+            }
+            if( dist &lt; d2_sofar )
+            {
+                q.push( make_pair(dist, j) );
+                int n_found = q.size();
+                if( n_found &gt; k )
+                    q.pop();
+                if( n_found &gt;= k )
+                    d2_sofar = q.top().first;
+            }
+        }
+    }
+    else if (!node-&gt;isEmpty()) // node is not leaf
+    {
+        BinBallTree node1 = node-&gt;getFirstChild();
+        BinBallTree node2 = node-&gt;getSecondChild();
+
+        real d2_pivot1 = powdistance(t, node1-&gt;pivot, 2);
+        real d2_pivot2 = powdistance(t, node2-&gt;pivot, 2);
+
+        if( d2_pivot1 &gt; d2_pivot2 ) // node1 is closer to t
+        {
+            pl_swap(node1, node2);
+            pl_swap(d2_pivot1, d2_pivot2);
+        }
+
+        BallKNN(q, node1, t, d2_sofar, d2_pivot1, k);
+        BallKNN(q, node2, t, d2_sofar, d2_pivot2, k); 
+    }
+}
+
+
+void BallTreeNearestNeighbors::FindBallKNN(
+    priority_queue&lt; pair&lt;real,int&gt; &gt;&amp; q, const Vec&amp; point, const int k ) const
+{
+    real d2_sofar;
+    pl_isnumber(&quot;+inf&quot;, &amp;d2_sofar);
+    real d2_pivot = powdistance(point, ball_tree-&gt;pivot, 2);
+//    real d_minp = 0;
+    BallKNN(q, ball_tree, point, d2_sofar, d2_pivot, k);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


Property changes on: branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.cc
___________________________________________________________________
Name: svn:executable
   + *

Added: branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,227 @@
+// -*- C++ -*-
+
+// BallTreeNearestNeighbors.h
+//
+// Copyright (C) 2004 Pascal Lamblin &amp; Marius Muja
+// 
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************      
+ * $Id: BallTreeNearestNeighbors.h 4900 2006-02-05 08:42:31Z lamblin $ 
+ ******************************************************* */
+
+// Authors: Pascal Lamblin &amp; Marius Muja
+
+/*! \file BallTreeNearestNeighbors.h */
+
+
+#ifndef BallTreeNearestNeighbors_INC
+#define BallTreeNearestNeighbors_INC
+
+#include &lt;queue&gt;
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/nearest_neighbors/GenericNearestNeighbors.h&gt;
+#include &lt;plearn/vmat/SelectRowsVMatrix.h&gt;
+#include &lt;plearn/ker/DistanceKernel.h&gt;
+
+#include &quot;BinaryBallTree.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+class BallTreeNearestNeighbors;
+typedef PP&lt; BallTreeNearestNeighbors &gt; BallTreeNN;
+
+class BallTreeNearestNeighbors: public GenericNearestNeighbors
+{
+
+private:
+
+    typedef GenericNearestNeighbors inherited;
+
+protected:
+
+    // *********************
+    // * protected options *
+    // *********************
+
+    BinBallTree ball_tree;
+    int nb_train_points;
+    int nb_points;
+
+public:
+
+    // ************************
+    // * public build options *
+    // ************************
+
+    TVec&lt;int&gt; point_indices;
+    int rmin;
+    string train_method;
+    TVec&lt;Mat&gt; anchor_set;
+    TVec&lt;int&gt; pivot_indices;
+
+    // ****************
+    // * Constructors *
+    // ****************
+
+    //! Default constructor.
+    BallTreeNearestNeighbors();
+
+    //! Constructor from a TrainSet and a BinBallTree.
+    BallTreeNearestNeighbors( const VMat&amp; tr_set, const BinBallTree&amp; b_tree );
+
+    // ********************
+    // * PLearner methods *
+    // ********************
+
+private: 
+
+    //! This does the actual building. 
+    // (Please implement in .cc)
+    void build_();
+    void anchorTrain();
+
+protected: 
+  
+    //! Declares this class' options.
+    // (Please implement in .cc)
+    static void declareOptions(OptionList&amp; ol);
+
+public:
+
+    // ************************
+    // **** Static methods ****
+    // ************************
+    // Maybe should I put this somewhere else...
+
+    // Returns true if the balls defined by (center1, radius1) and
+    // (center2, radius2) have a common part
+
+    static bool intersect( const Vec&amp; center1, const real&amp; radius1,
+                           const Vec&amp; center2, const real&amp; radius2 );
+
+    // Returns true if the first ball contains the second one
+    static bool contain( const Vec&amp; center1, const real&amp; radius1,
+                         const Vec&amp; center2, const real&amp; radius2 );
+
+    // Returns the smallest ball containing two balls
+    static void smallestContainer( const Vec&amp; center1, const real&amp; radius1,
+                                   const Vec&amp; center2, const real&amp; radius2,
+                                   Vec&amp; t_center, real&amp; t_radius);
+
+    virtual void BallKNN( priority_queue&lt; pair&lt;real,int&gt; &gt;&amp; q,
+                          BinBallTree node, const Vec&amp; t,
+                          real&amp; d_sofar, real d_minp, const int k ) const;
+
+    virtual void FindBallKNN( priority_queue&lt; pair&lt;real,int&gt; &gt;&amp; q,
+                              const Vec&amp; point, int k ) const;
+
+
+    // ************************
+    // **** Object methods ****
+    // ************************
+
+    //! Simply calls inherited::build() then build_().
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy.
+    virtual void makeDeepCopyFromShallowCopy(map&lt;const void*, void*&gt;&amp; copies);
+
+    // Declares other standard object methods.
+    PLEARN_DECLARE_OBJECT(BallTreeNearestNeighbors);
+
+
+    // **************************
+    // **** PLearner methods ****
+    // **************************
+
+    //! (Re-)initializes the PLearner in its fresh state (that state may
+    //! depend on the 'seed' option) And sets 'stage' back to 0 (this is
+    //! the stage of a fresh learner!).
+    virtual void forget();
+
+
+    //! The role of the train method is to bring the learner up to
+    //! stage==nstages, updating the train_stats collector with training
+    //! costs measured on-line in the process.
+    virtual void train();
+
+    void createAnchors( int nb_anchors );
+
+
+    BinBallTree leafFromAnchor( int anchor_index );
+
+    BinBallTree treeFromLeaves( const TVec&lt;BinBallTree&gt;&amp; leaves );
+
+    BinBallTree getBallTree();
+
+
+    //! Computes the output and costs from the input (more effectively)
+    virtual void computeOutputAndCosts( const Vec&amp; input, const Vec&amp; target,
+                                        Vec&amp; output, Vec&amp; costs ) const;
+    //! Computes the output from the input.
+    virtual void computeOutput(const Vec&amp; input, Vec&amp; output) const;
+
+    //! Computes the costs from already computed output. 
+    virtual void computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output, 
+                                         const Vec&amp; target, Vec&amp; costs) const;
+
+
+    //! Returns the names of the costs computed by computeCostsFromOutpus
+    //! (and thus the test method).
+    virtual TVec&lt;string&gt; getTestCostNames() const;
+
+    //! Returns the names of the objective costs that the train method
+    //computes and ! for which it updates the VecStatsCollector
+    //train_stats.  (PLEASE IMPLEMENT IN .cc)
+    virtual TVec&lt;string&gt; getTrainCostNames() const;
+
+};
+
+// Declares a few other classes and functions related to this class.
+DECLARE_OBJECT_PTR(BallTreeNearestNeighbors);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


Property changes on: branches/cgi-desjardin/plearn_learners/second_iteration/BallTreeNearestNeighbors.h
___________________________________________________________________
Name: svn:executable
   + *

Added: branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,153 @@
+// -*- C++ -*-
+
+// BinaryBallTree.cc
+//
+// Copyright (C) 2004 Pascal Lamblin 
+// 
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************      
+ * $Id: BinaryBallTree.cc 3994 2005-08-25 13:35:03Z chapados $ 
+ ******************************************************* */
+
+// Authors: Pascal Lamblin
+
+/*! \file BinaryBallTree.cc */
+
+
+#include &quot;BinaryBallTree.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+BinaryBallTree::BinaryBallTree() 
+    : pivot( Vec() ),
+      radius( 0 )
+{}
+
+PLEARN_IMPLEMENT_OBJECT( BinaryBallTree,
+                         &quot;Binary Tree, containing a point, a radius, and a set of points&quot;, 
+                         &quot;Each node of the tree contains the parameters of a ball :\n&quot;
+                         &quot;a point and a radius.\n&quot;
+                         &quot;Each leaf node contains a list of indices of points,\n&quot;
+                         &quot;each non-leaf node has two children nodes.&quot;);
+
+void BinaryBallTree::declareOptions( OptionList&amp; ol )
+{
+    declareOption( ol, &quot;pivot&quot;, &amp;BinaryBallTree::pivot, OptionBase::buildoption,
+                   &quot;Center of the ball&quot; );
+
+    declareOption(ol, &quot;radius&quot;, &amp;BinaryBallTree::radius, OptionBase::buildoption,
+                  &quot;Radius of the ball&quot; );
+
+    declareOption(ol, &quot;point_set&quot;, &amp;BinaryBallTree::point_set, OptionBase::buildoption,
+                  &quot;List of indices of the points owned by this node (leaf only)&quot; );
+
+    declareOption(ol, &quot;child1&quot;, &amp;BinaryBallTree::child1, OptionBase::tuningoption,
+                  &quot;Pointer to first child (non-leaf only)&quot; );
+
+    declareOption(ol, &quot;child2&quot;, &amp;BinaryBallTree::child2, OptionBase::tuningoption,
+                  &quot;Pointer to second child (non-leaf only)&quot; );
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void BinaryBallTree::build_()
+{
+    if( child1 )
+    { child1-&gt;parent = this; }
+
+    if( child2 )
+    { child2-&gt;parent = this; }
+}
+
+void BinaryBallTree::build()
+{
+    inherited::build();
+    build_();
+}
+
+void BinaryBallTree::setFirstChild( const BinBallTree&amp; first_child )
+{
+    this-&gt;child1 = first_child;
+    if( first_child )
+    {
+        first_child-&gt;parent = this;
+    }
+}
+
+void BinaryBallTree::setSecondChild( const BinBallTree&amp; second_child )
+{
+    this-&gt;child2 = second_child;
+    if( second_child )
+    {
+        second_child-&gt;parent = this;
+    }
+}
+
+BinBallTree BinaryBallTree::getFirstChild()
+{
+    return this-&gt;child1;
+}
+
+BinBallTree BinaryBallTree::getSecondChild()
+{
+    return this-&gt;child2;
+}
+
+BinaryBallTree* BinaryBallTree::getParent()
+{
+    return this-&gt;parent;
+}
+
+void BinaryBallTree::makeDeepCopyFromShallowCopy(map&lt;const void*, void*&gt;&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    deepCopyField( child1, copies );
+    deepCopyField( child2, copies );
+    deepCopyField( pivot, copies );
+    deepCopyField( point_set, copies );
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


Property changes on: branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.cc
___________________________________________________________________
Name: svn:executable
   + *

Added: branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,147 @@
+// -*- C++ -*-
+
+// BinaryBallTree.h
+//
+// Copyright (C) 2004 Pascal Lamblin 
+// 
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************      
+ * $Id: BinaryBallTree.h 3994 2005-08-25 13:35:03Z chapados $ 
+ ******************************************************* */
+
+// Authors: Pascal Lamblin
+
+/*! \file BinaryBallTree.h */
+
+
+#ifndef BinaryBallTree_INC
+#define BinaryBallTree_INC
+
+#include &lt;plearn/base/Object.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class BinaryBallTree;
+typedef PP&lt;BinaryBallTree&gt; BinBallTree;
+
+class BinaryBallTree: public Object
+{
+
+private:
+  
+    typedef Object inherited;
+
+protected:
+    // *********************
+    // * protected options *
+    // *********************
+
+    BinaryBallTree* parent;
+    BinBallTree child1;
+    BinBallTree child2;
+
+public:
+
+    // ************************
+    // * public build options *
+    // ************************
+
+    Vec pivot;
+    real radius;
+    TVec&lt;int&gt; point_set;
+
+    // ****************
+    // * Constructors *
+    // ****************
+
+    //! Default constructor.
+    BinaryBallTree();
+
+
+    // ******************
+    // * Object methods *
+    // ******************
+
+private: 
+    //! This does the actual building. 
+    void build_();
+
+protected: 
+    //! Declares this class' options.
+    static void declareOptions(OptionList&amp; ol);
+
+public:
+    // Declares other standard object methods.
+    PLEARN_DECLARE_OBJECT(BinaryBallTree);
+
+    // simply calls inherited::build() then build_() 
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(map&lt;const void*, void*&gt;&amp; copies);
+
+    virtual void setFirstChild( const BinBallTree&amp; first_child );
+
+    virtual void setSecondChild( const BinBallTree&amp; second_child );
+
+    virtual BinBallTree getFirstChild();
+
+    virtual BinBallTree getSecondChild();
+
+    virtual BinaryBallTree* getParent();
+
+    bool isEmpty() const
+    {
+        bool result = !pivot &amp;&amp; !child1 &amp;&amp; !child2 ;
+        return result;
+    }
+
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(BinaryBallTree);
+  
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :


Property changes on: branches/cgi-desjardin/plearn_learners/second_iteration/BinaryBallTree.h
___________________________________________________________________
Name: svn:executable
   + *

Added: branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,155 @@
+// -*- C++ -*-
+
+// CheckDond2FileSequence.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file CheckDond2FileSequence.cc */
+
+#define PL_LOG_MODULE_NAME &quot;CheckDond2FileSequence&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;CheckDond2FileSequence.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    CheckDond2FileSequence,
+    &quot;Checks that the train set is in sequence&quot;,
+    &quot;&quot;
+);
+
+/////////////////////////
+// CheckDond2FileSequence //
+/////////////////////////
+CheckDond2FileSequence::CheckDond2FileSequence()
+{
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void CheckDond2FileSequence::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;key_col&quot;, &amp;CheckDond2FileSequence::key_col,
+                  OptionBase::buildoption,
+                  &quot;The column of the sequence key.&quot;);
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void CheckDond2FileSequence::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(key_col, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void CheckDond2FileSequence::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void CheckDond2FileSequence::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        int row;
+        real prev_key;
+        Vec input(train_set-&gt;width());
+        train_set-&gt;getRow(0, input);
+        prev_key = input[key_col];
+        for (row = 1; row &lt; train_set-&gt;length(); row++)
+        {
+            train_set-&gt;getRow(row, input);
+            if (input[key_col] &lt; prev_key)
+            {
+                cout &lt;&lt; &quot;CheckDond2FileSequence: train set out of sequence&quot; &lt;&lt; endl;
+                cout &lt;&lt; &quot;CheckDond2FileSequence: row: &quot; &lt;&lt; row &lt;&lt; &quot; previous key: &quot; &lt;&lt; prev_key &lt;&lt; &quot; current key: &quot; &lt;&lt; input[key_col] &lt;&lt; endl;
+                PLERROR(&quot;CheckDond2FileSequence: we are done here&quot;);
+            }
+            if (input[key_col] == prev_key)
+            {
+                cout &lt;&lt; &quot;CheckDond2FileSequence: row: &quot; &lt;&lt; row &lt;&lt; &quot; previous key: &quot; &lt;&lt; prev_key &lt;&lt; &quot; current key: &quot; &lt;&lt; input[key_col] &lt;&lt; endl;
+            }
+            prev_key = input[key_col];
+            if (row % 25000 == 0) cout &lt;&lt; &quot;CheckDond2FileSequence: &quot; &lt;&lt; row &lt;&lt; &quot; records processed.&quot; &lt;&lt; endl;
+        }
+        cout &lt;&lt; &quot;CheckDond2FileSequence: &quot; &lt;&lt; row &lt;&lt; &quot; records processed.&quot; &lt;&lt; endl;
+        PLERROR(&quot;CheckDond2FileSequence: we are done here&quot;);
+    }
+}
+
+int CheckDond2FileSequence::outputsize() const {return 0;}
+void CheckDond2FileSequence::train() {}
+void CheckDond2FileSequence::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void CheckDond2FileSequence::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; CheckDond2FileSequence::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; CheckDond2FileSequence::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/CheckDond2FileSequence.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,128 @@
+// -*- C++ -*-
+
+// CheckDond2FileSequence.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file CheckDond2FileSequence.h */
+
+
+#ifndef CheckDond2FileSequence_INC
+#define CheckDond2FileSequence_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class CheckDond2FileSequence : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    
+    int key_col;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    CheckDond2FileSequence();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(CheckDond2FileSequence);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(CheckDond2FileSequence);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,247 @@
+// -*- C++ -*-
+
+// ComputeDond2Target.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file ComputeDond2Target.cc */
+
+#define PL_LOG_MODULE_NAME &quot;ComputeDond2Target&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;ComputeDond2Target.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    ComputeDond2Target,
+    &quot;Computes the class target for the training and the test datasets.&quot;,
+    &quot;the program reorders the input variables to group them between the binary variables,\n&quot;
+    &quot;the discrete variables and the continuous variables.\n&quot;
+    &quot;It reorders the variables in the order specified by the input vector option.\n&quot;
+    &quot;It also computes the predicted class target from the predicted annual sales figure\n&quot;
+    &quot;of the financial institution and computes the real class target.\n&quot;
+);
+
+/////////////////////////
+// ComputeDond2Target //
+/////////////////////////
+ComputeDond2Target::ComputeDond2Target()
+  : unknown_sales(0)
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void ComputeDond2Target::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;input_vector&quot;, &amp;ComputeDond2Target::input_vector,
+                  OptionBase::buildoption,
+                  &quot;The variables to assemble in the input vector by names.\n&quot;
+                  &quot;To ease the following steps they are grouped with the binary variables first,\n&quot;
+                  &quot;the discrete variables, the continuous variables and finally some variables unused in the training.\n&quot;);
+
+    declareOption(ol, &quot;unknown_sales&quot;, &amp;ComputeDond2Target::unknown_sales,
+                  OptionBase::buildoption,
+                  &quot;If set to 1 and annual sales attribute is missing, the class will be set to missing.&quot;);
+
+    declareOption(ol, &quot;target_sales&quot;, &amp;ComputeDond2Target::target_sales,
+                  OptionBase::buildoption,
+                  &quot;The column of the real annual sales used to compute the real class target.&quot;);
+
+    declareOption(ol, &quot;predicted_sales&quot;, &amp;ComputeDond2Target::predicted_sales,
+                  OptionBase::buildoption,
+                  &quot;The column of the predicted annual sales used to compute the predicted class target.&quot;);
+
+    declareOption(ol, &quot;margin&quot;, &amp;ComputeDond2Target::margin,
+                  OptionBase::buildoption,
+                  &quot;The column of the total authorized margins including SLA.&quot;);
+
+    declareOption(ol, &quot;loan&quot;, &amp;ComputeDond2Target::loan,
+                  OptionBase::buildoption,
+                  &quot;The column of the total loan balances excluding mortgages.&quot;);
+
+    declareOption(ol, &quot;output_path&quot;, &amp;ComputeDond2Target::output_path,
+                  OptionBase::buildoption,
+                  &quot;The file path for the targeted output file.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void ComputeDond2Target::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(input_vector, copies);
+    deepCopyField(unknown_sales, copies);
+    deepCopyField(target_sales, copies);
+    deepCopyField(predicted_sales, copies);
+    deepCopyField(margin, copies);
+    deepCopyField(loan, copies);
+    deepCopyField(output_path, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void ComputeDond2Target::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void ComputeDond2Target::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        computeTarget();
+    }
+}
+
+void ComputeDond2Target::computeTarget()
+{    
+    // initialize primary dataset
+    main_row = 0;
+    main_col = 0;
+    main_length = train_set-&gt;length();
+    main_width = train_set-&gt;width();
+    main_input.resize(main_width);
+    main_names.resize(main_width);
+    ins_width = input_vector.size();
+    predicted_class = ins_width;
+    target_class = ins_width + 1;
+    output_width = ins_width + 2;
+    output_variable_src.resize(ins_width);
+    output_names.resize(output_width);
+    output_vec.resize(output_width);
+    main_names &lt;&lt; train_set-&gt;fieldNames();
+    for (ins_col = 0; ins_col &lt; ins_width; ins_col++)
+    {
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (input_vector[ins_col] == main_names[main_col]) break;
+        }
+        if (main_col &gt;= main_width) PLERROR(&quot;In ComputeDond2Target: no field with this name in input dataset: %&quot;, (input_vector[ins_col]).c_str());
+        output_variable_src[ins_col] = main_col;
+        output_names[ins_col] = input_vector[ins_col];
+    }
+    output_names[predicted_class] = &quot;CLASSE_PRED&quot;;
+    output_names[target_class] = &quot;CLASSE_REEL&quot;;
+    
+    // initialize output datasets
+    output_file = new FileVMatrix(output_path + &quot;.pmat&quot;, main_length, output_names);
+    output_file-&gt;defineSizes(output_width, 0, 0);
+    
+    //Now, we can group the input and compute the class target
+    ProgressBar* pb = 0;
+    pb = new ProgressBar( &quot;Computing target classes&quot;, main_length);
+    for (main_row = 0; main_row &lt; main_length; main_row++)
+    {
+        train_set-&gt;getRow(main_row, main_input);
+        for (ins_col = 0; ins_col &lt; ins_width; ins_col++)
+        {
+            output_vec[ins_col] = main_input[output_variable_src[ins_col]];
+        }
+        if (is_missing(main_input[predicted_sales])) main_input[predicted_sales] = 0.0;
+        commitment = 0.0;
+        if (!is_missing(main_input[margin])) commitment += main_input[margin];
+        if (!is_missing(main_input[loan])) commitment += main_input[loan];
+        if (main_input[predicted_sales] &lt; 1000000.0 &amp;&amp; commitment &lt; 200000.0) output_vec[predicted_class] = 1.0;
+        else if (main_input[predicted_sales] &lt; 10000000.0 &amp;&amp; commitment &lt; 1000000.0) output_vec[predicted_class] = 2.0;
+        else if (main_input[predicted_sales] &lt; 100000000.0 &amp;&amp; commitment &lt; 20000000.0) output_vec[predicted_class] = 3.0;
+        else output_vec[predicted_class] = 4.0;
+        if (is_missing(main_input[target_sales]) &amp;&amp; unknown_sales == 0)
+            PLERROR(&quot;In ComputeDond2Target: no target information for record: %i&quot;, main_row);
+        commitment = 0.0;
+        if (!is_missing(main_input[margin])) commitment += main_input[margin];
+        if (!is_missing(main_input[loan])) commitment += main_input[loan];
+        if (is_missing(main_input[target_sales]))  output_vec[target_class] = main_input[target_sales];
+        else if (main_input[target_sales] &lt; 1000000.0 &amp;&amp; commitment &lt; 200000.0) output_vec[target_class] = 1.0;
+        else if (main_input[target_sales] &lt; 10000000.0 &amp;&amp; commitment &lt; 1000000.0) output_vec[target_class] = 2.0;
+        else if (main_input[target_sales] &lt; 100000000.0 &amp;&amp; commitment &lt; 20000000.0) output_vec[target_class] = 3.0;
+        else output_vec[target_class] = 4.0;
+        output_file-&gt;putRow(main_row, output_vec);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+}
+
+VMat ComputeDond2Target::getOutputFile()
+{
+    return output_file;
+}
+
+int ComputeDond2Target::outputsize() const {return 0;}
+void ComputeDond2Target::train()
+{
+    PLERROR(&quot;ComputeDond2Target: we are done here&quot;);
+}
+void ComputeDond2Target::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void ComputeDond2Target::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; ComputeDond2Target::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; ComputeDond2Target::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ComputeDond2Target.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,175 @@
+// -*- C++ -*-
+
+// ComputeDond2Target.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file ComputeDond2Target.h */
+
+
+#ifndef ComputeDond2Target_INC
+#define ComputeDond2Target_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class ComputeDond2Target : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! The variables to assemble in the input vector by names.
+    //! To ease the following steps they are grouped with the binary variables first,
+    //! the discrete variables, the continuous variables and finally some variables unused in the training.
+    TVec&lt;string&gt; input_vector;
+    
+    //! If set to 1 and annual sales attribute is missing, the class will be set to missing.
+    int unknown_sales;
+    
+    //! The column of the real annual sales used to compute the real class target.
+    int target_sales;
+    
+    //! The column of the predicted annual sales used to compute the predicted class target.
+    int predicted_sales;
+    
+    //! The column of the total authorized margins including SLA.
+    int margin;
+    
+    //! The column of the total loan balances excluding mortgages.
+    int loan;
+    
+    //! The file path for the targeted output file.
+    string output_path;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    ComputeDond2Target();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+    VMat getOutputFile();
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(ComputeDond2Target);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void computeTarget();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    
+    // input instructions variables
+    int ins_width;
+    int ins_col;
+    
+    // primary dataset variables
+    int main_length;
+    int main_width;
+    int main_row;
+    int main_col;
+    Vec main_input;
+    TVec&lt;string&gt; main_names;
+    
+    // output dataset variables
+    int target_class;
+    int predicted_class;
+    int output_width;
+    real commitment;
+    Vec output_vec;
+    TVec&lt;string&gt; output_names;
+    TVec&lt;int&gt; output_variable_src;
+    VMat output_file;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(ComputeDond2Target);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,162 @@
+// -*- C++ -*-
+
+// ComputePurenneError.cc
+// Copyright (c) 1998-2002 Pascal Vincent
+// Copyright (C) 1999-2002 Yoshua Bengio and University of Montreal
+// Copyright (c) 2002 Jean-Sebastien Senecal, Xavier Saint-Mleux, Rejean Ducharme
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ********************************************************************************    
+ * $Id: ComputePurenneError.cc, v 1.0 2004/07/19 10:00:00 Bengio/Kegl/Godbout        *
+ * This file is part of the PLearn library.                                     *
+ ******************************************************************************** */
+
+#include &quot;ComputePurenneError.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(ComputePurenneError,
+                        &quot;A PLearner to compute the prediction error of Vincent.&quot;, 
+                        &quot;\n&quot;
+    );
+
+ComputePurenneError::ComputePurenneError()  
+{
+}
+
+ComputePurenneError::~ComputePurenneError()
+{
+}
+
+void ComputePurenneError::declareOptions(OptionList&amp; ol)
+{
+    inherited::declareOptions(ol);
+}
+
+void ComputePurenneError::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+void ComputePurenneError::build()
+{
+    inherited::build();
+    build_();
+}
+
+void ComputePurenneError::build_()
+{
+}
+
+void ComputePurenneError::train()
+{
+    int row;
+    Vec sample_input(train_set-&gt;inputsize());
+    Vec sample_target(train_set-&gt;targetsize());
+    real sample_weight;
+    Vec sample_output(2);
+    Vec sample_costs(3);
+    ProgressBar* pb = NULL;
+    if (report_progress)
+    {
+        pb = new ProgressBar(&quot;Purenne error: computing the train statistics: &quot;, train_set-&gt;length());
+    } 
+    train_stats-&gt;forget();
+    for (row = 0; row &lt; train_set-&gt;length(); row++)
+    {  
+        train_set-&gt;getExample(row, sample_input, sample_target, sample_weight);
+        computeOutput(sample_input, sample_output);
+        computeCostsFromOutputs(sample_input, sample_output, sample_target, sample_costs); 
+        train_stats-&gt;update(sample_costs);
+        if (report_progress) pb-&gt;update(row);
+    }
+    train_stats-&gt;finalize();
+    if (report_progress) delete pb; 
+}
+
+void ComputePurenneError::forget()
+{
+}
+
+int ComputePurenneError::outputsize() const
+{
+    return 2;
+}
+
+TVec&lt;string&gt; ComputePurenneError::getTrainCostNames() const
+{
+    TVec&lt;string&gt; return_msg(3);
+    return_msg[0] = &quot;mse&quot;;
+    return_msg[1] = &quot;cse&quot;;
+    return_msg[2] = &quot;cle&quot;;
+    return return_msg;
+}
+
+TVec&lt;string&gt; ComputePurenneError::getTestCostNames() const
+{ 
+    return getTrainCostNames();
+}
+
+void ComputePurenneError::computeOutput(const Vec&amp; inputv, Vec&amp; outputv) const
+{
+    outputv[0] = inputv[0];
+    outputv[1] = inputv[1];
+}
+
+void ComputePurenneError::computeOutputAndCosts(const Vec&amp; inputv, const Vec&amp; targetv, Vec&amp; outputv, Vec&amp; costsv) const
+{
+    computeOutput(inputv, outputv);
+    computeCostsFromOutputs(inputv, outputv, targetv, costsv);
+}
+
+void ComputePurenneError::computeCostsFromOutputs(const Vec&amp; inputv, const Vec&amp; outputv, const Vec&amp; targetv, Vec&amp; costsv) const
+{
+    costsv[0] = pow((outputv[0] - targetv[0]), 2.0);
+    costsv[1] = pow((outputv[1] - targetv[1]), 2.0);
+    if (outputv[1] == targetv[1]) costsv[2] = 0.0;
+    else costsv[2] = 1.0;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ComputePurenneError.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,96 @@
+// -*- C++ -*-
+
+// ComputePurenneError.h
+// Copyright (c) 1998-2002 Pascal Vincent
+// Copyright (C) 1999-2002 Yoshua Bengio and University of Montreal
+// Copyright (c) 2002 Jean-Sebastien Senecal, Xavier Saint-Mleux, Rejean Ducharme
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ********************************************************************************    
+ * $Id: ComputePurenneError.h, v 1.0 2004/07/19 10:00:00 Bengio/Kegl/Godbout   *
+ * This file is part of the PLearn library.                                     *
+ ******************************************************************************** */
+
+/*! \file PLearnLibrary/PLearnAlgo/ComputePurenneError.h */
+
+#ifndef ComputePurenneError_INC
+#define ComputePurenneError_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn/base/stringutils.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class ComputePurenneError: public PLearner
+{
+    typedef PLearner inherited;   
+  
+public:
+    ComputePurenneError();
+    virtual              ~ComputePurenneError();
+    
+    PLEARN_DECLARE_OBJECT(ComputePurenneError);
+
+    static  void         declareOptions(OptionList&amp; ol);
+    virtual void         makeDeepCopyFromShallowCopy(CopiesMap &amp;copies);
+    virtual void         build();
+    virtual void         train();
+    virtual void         forget();
+    virtual int          outputsize() const;
+    virtual TVec&lt;string&gt; getTrainCostNames() const;
+    virtual TVec&lt;string&gt; getTestCostNames() const;
+    virtual void         computeOutput(const Vec&amp; input, Vec&amp; output) const;
+    virtual void         computeOutputAndCosts(const Vec&amp; input, const Vec&amp; target, Vec&amp; output, Vec&amp; costs) const;
+    virtual void         computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output, const Vec&amp; target, Vec&amp; costs) const;
+  
+private:
+    void         build_();
+};
+
+DECLARE_OBJECT_PTR(ComputePurenneError);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,229 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************************    
+   * $Id: ConditionalMeanImputationVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
+   ******************************************************************* */
+
+
+#include &quot;ConditionalMeanImputationVMatrix.h&quot;
+#include &lt;plearn/io/fileutils.h&gt;              //!&lt;  For isfile()
+
+namespace PLearn {
+using namespace std;
+
+/** ConditionalMeanImputationVMatrix **/
+
+PLEARN_IMPLEMENT_OBJECT(
+  ConditionalMeanImputationVMatrix,
+  &quot;VMat class to impute the conditional mean to replace missing values in the source matrix.&quot;,
+  &quot;This class will replace missing values in the underlying dataset with the estimated values\n&quot;
+  &quot;from a preceding machine learning step where each variable with missing value have to have.\n&quot;
+  &quot;been considered as target in turns.\n&quot;
+  &quot;The predictions are expected in the metadata directory of the data set.\n&quot;
+  );
+
+ConditionalMeanImputationVMatrix::ConditionalMeanImputationVMatrix()
+{
+}
+
+ConditionalMeanImputationVMatrix::~ConditionalMeanImputationVMatrix()
+{
+}
+
+void ConditionalMeanImputationVMatrix::declareOptions(OptionList &amp;ol)
+{
+  declareOption(ol, &quot;source&quot;, &amp;ConditionalMeanImputationVMatrix::source, OptionBase::buildoption, 
+                &quot;The source VMatrix with missing values.\n&quot;);
+  declareOption(ol, &quot;condmean_dir&quot;, &amp;ConditionalMeanImputationVMatrix::condmean_dir, OptionBase::buildoption, 
+                &quot;The directory in the source metadatadir housing the variable conditional mean files.\n&quot;);
+  declareOption(ol, &quot;condmean&quot;, &amp;ConditionalMeanImputationVMatrix::condmean, OptionBase::learntoption, 
+                &quot;The matrix of conditional means.\n&quot;);
+  declareOption(ol, &quot;condmean_col_ref&quot;, &amp;ConditionalMeanImputationVMatrix::condmean_col_ref, OptionBase::learntoption, 
+                &quot;The cross reference between columns of source and condmean.\n&quot;);
+  inherited::declareOptions(ol);
+}
+
+void ConditionalMeanImputationVMatrix::build()
+{
+  inherited::build();
+  build_();
+}
+
+void ConditionalMeanImputationVMatrix::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+  deepCopyField(source, copies);
+  deepCopyField(condmean_dir, copies);
+  deepCopyField(condmean, copies);
+  deepCopyField(condmean_col_ref, copies);
+  inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+void ConditionalMeanImputationVMatrix::getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight)
+{
+  source-&gt;getExample(i, input, target, weight);
+  for (int source_col = 0; source_col &lt; input-&gt;length(); source_col++)
+    if (is_missing(input[source_col]) &amp;&amp; condmean_col_ref[source_col] &gt;= 0) input[source_col] = condmean(i, condmean_col_ref[source_col]);
+    else if (is_missing(input[source_col])) cout &lt;&lt; &quot;getExample : &quot; &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; source_col &lt;&lt; endl;
+}
+
+real ConditionalMeanImputationVMatrix::get(int i, int j) const
+{ 
+  real variable_value = source-&gt;get(i, j);
+  if (!is_missing(variable_value) &amp;&amp; condmean_col_ref[j] &gt;= 0) return condmean(i, condmean_col_ref[j]);
+    else if (is_missing(variable_value)) cout &lt;&lt; &quot;get : &quot; &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; j &lt;&lt; endl;
+  return variable_value;
+}
+
+void ConditionalMeanImputationVMatrix::put(int i, int j, real value)
+{
+  PLERROR(&quot;In ConditionalMeanImputationVMatrix::put not implemented&quot;);
+}
+
+void ConditionalMeanImputationVMatrix::getSubRow(int i, int j, Vec v) const
+{  
+  source-&gt;getSubRow(i, j, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++) 
+    if (is_missing(v[source_col])) v[source_col] = condmean(i, condmean_col_ref[source_col + j]);
+    else if (is_missing(v[source_col])) cout &lt;&lt; &quot;getSubRow : &quot; &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; source_col + j &lt;&lt; endl;
+}
+
+void ConditionalMeanImputationVMatrix::putSubRow(int i, int j, Vec v)
+{
+  PLERROR(&quot;In ConditionalMeanImputationVMatrix::putSubRow not implemented&quot;);
+}
+
+void ConditionalMeanImputationVMatrix::appendRow(Vec v)
+{
+  PLERROR(&quot;In ConditionalMeanImputationVMatrix::appendRow not implemented&quot;);
+}
+
+void ConditionalMeanImputationVMatrix::insertRow(int i, Vec v)
+{
+  PLERROR(&quot;In ConditionalMeanImputationVMatrix::insertRow not implemented&quot;);
+}
+
+void ConditionalMeanImputationVMatrix::getRow(int i, Vec v) const
+{  
+  source-&gt; getRow(i, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++)
+    if (is_missing(v[source_col]) &amp;&amp; condmean_col_ref[source_col] &gt;= 0) v[source_col] = condmean(i, condmean_col_ref[source_col]);
+    else if (is_missing(v[source_col])) cout &lt;&lt; &quot;getRow : &quot; &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; source_col &lt;&lt; endl;
+}
+
+void ConditionalMeanImputationVMatrix::putRow(int i, Vec v)
+{
+  PLERROR(&quot;In ConditionalMeanImputationVMatrix::putRow not implemented&quot;);
+}
+
+void ConditionalMeanImputationVMatrix::getColumn(int i, Vec v) const
+{  
+  source-&gt; getColumn(i, v);
+  for (int source_row = 0; source_row &lt; v-&gt;length(); source_row++)
+    if (is_missing(v[source_row]) &amp;&amp; condmean_col_ref[i] &gt;= 0) v[source_row] = condmean(source_row, condmean_col_ref[i]);
+    else if (is_missing(v[source_row])) cout &lt;&lt; &quot;getColumn : &quot; &lt;&lt; source_row &lt;&lt; &quot; &quot; &lt;&lt; i &lt;&lt; endl;
+}
+
+
+
+void ConditionalMeanImputationVMatrix::build_()
+{
+    if (!source) PLERROR(&quot;In ConditionalMeanImputationVMatrix::source vmat must be supplied&quot;);
+    loadCondMeanMatrix(); 
+}
+
+void ConditionalMeanImputationVMatrix::loadCondMeanMatrix()
+/*  
+Imputation step:
+  count the # of variables with missing values in the train and test datasets.
+  create a matrix in memory with this number of columns and keep cross reference of columns.
+  at the build stage, for each variable of train and test:
+    if # of missing = 0 there is nothing to do.
+    look for the (cond_mean_dir (/TreeCondMean/dir/) + field_name + /Split0/test1_outputs.pmat) file in the metadatadir;
+    add its column 0 as a column of the matrix.
+  then, if is_missing(source[i,j]) replace it with matrix[i, cross_reference[j]]
+*/
+{
+    // initialize source dataset
+    source_length = source-&gt;length();
+    source_width = source-&gt;width();
+    source_inputsize = source-&gt;inputsize();
+    source_targetsize = source-&gt;targetsize();
+    source_weightsize = source-&gt;weightsize();
+    source_names.resize(source_width);
+    source_names = source-&gt;fieldNames();
+    source_metadata = source-&gt;getMetaDataDir();
+    length_ = source_length;
+    width_ = source_width;
+    inputsize_ = source_inputsize;
+    targetsize_ = source_targetsize;
+    weightsize_ = source_weightsize;
+    declareFieldNames(source_names);
+    
+    // count the # of variables with missing values in the source datasets.
+    // create a matrix in memory with this number of columns and keep cross reference of columns.
+    int count_variable_with_missing = 0;
+    condmean_col_ref.resize(source_width);
+    condmean_col_ref.fill(-1);
+    for (source_col = 0; source_col &lt; source_width; source_col++)
+    {
+        source_stats = source-&gt;getStats(source_col);
+        if (source_stats.nmissing() &lt;= 0) continue;
+        condmean_col_ref[source_col] = count_variable_with_missing;
+        count_variable_with_missing += 1;
+    }
+    condmean.resize(source_length, count_variable_with_missing);
+    
+    // for each variable with missing value, 
+    // look for the (cond_mean_dir (/TreeCondMean/dir/) + field_name + /Split0/test1_outputs.pmat) file in the metadatadir;
+    // add its column 0 as a column of the condmean matrix.
+    for (source_col = 0; source_col &lt; source_width; source_col++)
+    {
+        source_stats = source-&gt;getStats(source_col);
+        if (source_stats.nmissing() &lt;= 0) continue;
+        condmean_col = condmean_col_ref[source_col];
+        condmean_variable_file_name = source_metadata + &quot;/&quot; + condmean_dir + &quot;/dir/&quot; + source_names[source_col] + &quot;/Split0/test1_outputs.pmat&quot;;
+        if (!isfile(condmean_variable_file_name)) PLERROR(&quot;In ConditionalMeanImputationVMatrix::A conditional mean file was not found for variable %s&quot;, source_names[source_col].c_str());
+        condmean_variable_file = new FileVMatrix(condmean_variable_file_name, false);
+        if (condmean_variable_file-&gt;length() != source_length)
+            PLERROR(&quot;In ConditionalMeanImputationVMatrix::Source and conditional mean file length are not equal for variable %s&quot;, source_names[source_col].c_str());
+        for (source_row = 0; source_row &lt; source_length; source_row++)
+            condmean(source_row, condmean_col) = condmean_variable_file-&gt;get(source_row, 0);
+    }
+}
+
+} // end of namespcae PLearn

Added: branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/ConditionalMeanImputationVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,118 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ******************************************************************      
+   * $Id: ConditionalMeanImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
+   ****************************************************************** */
+
+/*! \file PLearnLibrary/PLearnCore/VMat.h */
+
+#ifndef ConditionalMeanImputationVMatrix_INC
+#define ConditionalMeanImputationVMatrix_INC
+
+#include &lt;plearn/vmat/SourceVMatrix.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class ConditionalMeanImputationVMatrix: public VMatrix
+{
+  typedef VMatrix inherited;
+  
+public:
+
+  //! The source VMatrix with missing values.
+  VMat                 source;
+
+  //! The directory in the source metadatadir housing the variable conditional mean files.
+  string               condmean_dir;
+
+  //! The matrix of conditional means.
+  Mat                  condmean;
+
+  //! The cross reference between columns of source and condmean.
+  TVec&lt;int&gt;            condmean_col_ref;
+
+  
+                        ConditionalMeanImputationVMatrix();
+  virtual               ~ConditionalMeanImputationVMatrix();
+
+  static void           declareOptions(OptionList &amp;ol);
+
+  virtual void          build();
+  virtual void          makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+  virtual void         getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight);
+  virtual real         get(int i, int j) const;
+  virtual void         put(int i, int j, real value);
+  virtual void         getSubRow(int i, int j, Vec v) const;
+  virtual void         putSubRow(int i, int j, Vec v);
+  virtual void         appendRow(Vec v);
+  virtual void         insertRow(int i, Vec v);  
+  virtual void         getRow(int i, Vec v) const;
+  virtual void         putRow(int i, Vec v);
+  virtual void         getColumn(int i, Vec v) const;
+
+private:
+  
+  int                  source_length;
+  int                  source_width;
+  int                  source_inputsize;
+  int                  source_targetsize;
+  int                  source_weightsize;
+  int                  source_row;
+  int                  source_col;
+  PPath                source_metadata;
+  TVec&lt;string&gt;         source_names;
+  StatsCollector       source_stats;
+  PPath                condmean_variable_file_name;
+  VMat                 condmean_variable_file;
+  int                  condmean_col;
+        
+
+          void         build_();
+          void         loadCondMeanMatrix();  
+  
+  PLEARN_DECLARE_OBJECT(ConditionalMeanImputationVMatrix);
+
+};
+
+DECLARE_OBJECT_PTR(ConditionalMeanImputationVMatrix);
+
+} // end of namespcae PLearn
+#endif

Added: branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,305 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************************    
+   * $Id: CovariancePreservationImputationVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
+   ******************************************************************* */
+
+
+#include &quot;CovariancePreservationImputationVMatrix.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+/** CovariancePreservationImputationVMatrix **/
+
+PLEARN_IMPLEMENT_OBJECT(
+  CovariancePreservationImputationVMatrix,
+  &quot;VMat class to impute values preserving the observed relationships between variables on a global basis.&quot;,
+  &quot;This class will replace a missing value in the underlying dataset with a value computed to minimized\n&quot;
+  &quot;the distance of the sample covariates with the global covariance vector of the observed data.\n&quot;
+  );
+
+CovariancePreservationImputationVMatrix::CovariancePreservationImputationVMatrix()
+{
+}
+
+CovariancePreservationImputationVMatrix::~CovariancePreservationImputationVMatrix()
+{
+}
+
+void CovariancePreservationImputationVMatrix::declareOptions(OptionList &amp;ol)
+{
+  declareOption(ol, &quot;source&quot;, &amp;CovariancePreservationImputationVMatrix::source, OptionBase::buildoption, 
+                &quot;The source VMatrix with missing values.\n&quot;);
+
+  declareOption(ol, &quot;train_set&quot;, &amp;CovariancePreservationImputationVMatrix::train_set, OptionBase::buildoption, 
+                &quot;A referenced train set.\n&quot;
+                &quot;The covariance imputation is computed with the observed values in this data set.\n&quot;);
+
+  inherited::declareOptions(ol);
+}
+
+void CovariancePreservationImputationVMatrix::build()
+{
+  inherited::build();
+  build_();
+}
+
+void CovariancePreservationImputationVMatrix::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+  deepCopyField(source, copies);
+  deepCopyField(train_set, copies);
+  inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+void CovariancePreservationImputationVMatrix::getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight)
+{
+  source-&gt;getExample(i, input, target, weight);
+  for (int source_col = 0; source_col &lt; input-&gt;length(); source_col++)
+  {
+    if (is_missing(input[source_col])) input[source_col] = computeImputation(i, source_col, input);
+  }  
+}
+
+real CovariancePreservationImputationVMatrix::get(int i, int j) const
+{ 
+  real variable_value = source-&gt;get(i, j);
+  if (is_missing(variable_value)) computeImputation(i, j);
+  return variable_value;
+}
+
+void CovariancePreservationImputationVMatrix::put(int i, int j, real value)
+{
+  PLERROR(&quot;In CovariancePreservationImputationVMatrix::put not implemented&quot;);
+}
+
+void CovariancePreservationImputationVMatrix::getSubRow(int i, int j, Vec v) const
+{  
+  source-&gt;getSubRow(i, j, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++) 
+    if (is_missing(v[source_col])) v[source_col] = computeImputation(i, source_col + j);
+}
+
+void CovariancePreservationImputationVMatrix::putSubRow(int i, int j, Vec v)
+{
+  PLERROR(&quot;In CovariancePreservationImputationVMatrix::putSubRow not implemented&quot;);
+}
+
+void CovariancePreservationImputationVMatrix::appendRow(Vec v)
+{
+  PLERROR(&quot;In CovariancePreservationImputationVMatrix::appendRow not implemented&quot;);
+}
+
+void CovariancePreservationImputationVMatrix::insertRow(int i, Vec v)
+{
+  PLERROR(&quot;In CovariancePreservationImputationVMatrix::insertRow not implemented&quot;);
+}
+
+void CovariancePreservationImputationVMatrix::getRow(int i, Vec v) const
+{  
+  source-&gt; getRow(i, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++)
+    if (is_missing(v[source_col])) v[source_col] = computeImputation(i, source_col, v);
+}
+
+void CovariancePreservationImputationVMatrix::putRow(int i, Vec v)
+{
+  PLERROR(&quot;In CovariancePreservationImputationVMatrix::putRow not implemented&quot;);
+}
+
+void CovariancePreservationImputationVMatrix::getColumn(int i, Vec v) const
+{  
+  source-&gt; getColumn(i, v);
+  for (int source_row = 0; source_row &lt; v-&gt;length(); source_row++)
+    if (is_missing(v[source_row])) v[source_row] = computeImputation(source_row, i);
+}
+
+
+
+void CovariancePreservationImputationVMatrix::build_()
+{
+    if (!train_set || !source) PLERROR(&quot;In CovariancePreservationImputationVMatrix::train set and source vmat must be supplied&quot;);
+    train_length = train_set-&gt;length();
+    if(train_length &lt; 1) PLERROR(&quot;In CovariancePreservationImputationVMatrix::length of the number of train samples to use must be at least 1, got: %i&quot;, train_length);
+    train_width = train_set-&gt;width();
+    train_targetsize = train_set-&gt;targetsize();
+    train_weightsize = train_set-&gt;weightsize();
+    train_inputsize = train_set-&gt;inputsize();
+    if(train_inputsize &lt; 1) PLERROR(&quot;In CovariancePreservationImputationVMatrix::inputsize of the train vmat must be supplied, got : %i&quot;, train_inputsize);
+    source_width = source-&gt;width();
+    source_targetsize = source-&gt;targetsize();
+    source_weightsize = source-&gt;weightsize();
+    source_inputsize = source-&gt;inputsize();
+    if (train_width != source_width) PLERROR(&quot;In CovariancePreservationImputationVMatrix::train set and source width must agree, got : %i, %i&quot;, train_width, source_width);
+    if (train_targetsize != source_targetsize) PLERROR(&quot;In CovariancePreservationImputationVMatrix::train set and source targetsize must agree, got : %i, %i&quot;, train_targetsize, source_targetsize);
+    if (train_weightsize != source_weightsize) PLERROR(&quot;In CovariancePreservationImputationVMatrix::train set and source weightsize must agree, got : %i, %i&quot;, train_weightsize, source_weightsize);
+    if (train_inputsize != source_inputsize) PLERROR(&quot;In CovariancePreservationImputationVMatrix::train set and source inputsize must agree, got : %i, %i&quot;, train_inputsize, source_inputsize);
+    train_field_names.resize(train_width);
+    train_field_names = train_set-&gt;fieldNames();
+    source_length = source-&gt;length();
+    length_ = source_length;
+    width_ = source_width;
+    inputsize_ = source_inputsize;
+    targetsize_ = source_targetsize;
+    weightsize_ = source_weightsize;
+    declareFieldNames(train_field_names);
+    train_metadata = train_set-&gt;getMetaDataDir();
+    covariance_file_name = train_metadata + &quot;covariance_file.pmat&quot;;
+    cov.resize(train_width, train_width);
+    mu.resize(train_width);
+    if (!isfile(covariance_file_name))
+    {
+        computeCovariances();
+        createCovarianceFile();
+    }
+    else loadCovarianceFile();
+}
+
+void CovariancePreservationImputationVMatrix::createCovarianceFile()
+{
+    covariance_file = new FileVMatrix(covariance_file_name, train_width + 1, train_field_names);
+    for (indj = 0; indj &lt; train_width; indj++)
+    {
+        for (indk = 0; indk &lt; train_width; indk++)
+        {
+            covariance_file-&gt;put(indj, indk, cov(indj, indk));
+        }
+    }
+    for (indk = 0; indk &lt; train_width; indk++)
+    {
+        covariance_file-&gt;put(train_width, indk, mu[indk]);
+    }
+}
+
+void CovariancePreservationImputationVMatrix::loadCovarianceFile()
+{
+    covariance_file = new FileVMatrix(covariance_file_name);
+    for (indj = 0; indj &lt; train_width; indj++)
+    {
+        for (indk = 0; indk &lt; train_width; indk++)
+        {
+            cov(indj, indk) = covariance_file-&gt;get(indj, indk);
+        }
+    }
+    for (indk = 0; indk &lt; train_width; indk++)
+    {
+        mu[indk] = covariance_file-&gt;get(train_width, indk);
+    }
+}
+
+VMat CovariancePreservationImputationVMatrix::getCovarianceFile()
+{
+    return covariance_file;
+}
+
+void CovariancePreservationImputationVMatrix::computeCovariances()
+{
+/*
+    We need to populate the matrix of COV for all combinations of input variables
+    we need in one pass to populate 4 matrices of dxd:
+    n(j,k) the number of samples where x(i, j) and x(i, k) are simultaneously observed.
+    sum_x(j)(k) the sum of the x(i, j) values where x(i, j) and x(i, k) are simultaneously observed.
+    sum_x(j)_x(k) the sum of the x(i, j)*x(i, k) values where x(i, j) and x(i, k) are simultaneously observed.
+    we can the calculate mu(k) = sum_x(k, k)/n(k, k)
+    COV(j, k) = (sum_x(j)_x(k) - sum_x(j)(k) * mu(k) - sum_x(k)(j) * mu(j) + mu(k) * mu(j)) (1 / n(j,k))
+    All we need after is the COV matrix to impute values on missing values.
+    
+*/
+    n_obs.resize(train_width, train_width);
+    sum_xj.resize(train_width, train_width);
+    sum_xj_xk.resize(train_width, train_width);
+    train_input.resize(train_width);
+    n_obs.clear();
+    sum_xj.clear();
+    sum_xj_xk.clear();
+    mu.clear();
+    cov.clear();
+    ProgressBar* pb = 0;
+    pb = new ProgressBar(&quot;Computing the covariance matrix&quot;, train_length);
+    for (train_row = 0; train_row &lt; train_length; train_row++)
+    {
+        train_set-&gt;getRow(train_row, train_input);
+        for (indj = 0; indj &lt; train_width; indj++)
+        {
+            for (indk = 0; indk &lt; train_width; indk++)
+            {
+                if (is_missing(train_input[indj]) || is_missing(train_input[indk])) continue;
+                n_obs(indj, indk) += 1.0;
+                sum_xj(indj, indk) += train_input[indj];
+                sum_xj_xk(indj, indk) += train_input[indj] * train_input[indk];
+            }
+        }
+        pb-&gt;update( train_row ); 
+    }
+    delete pb;
+    for (indj = 0; indj &lt; train_width; indj++)
+    {
+        mu[indj] = sum_xj(indj, indj) / n_obs(indj, indj); 
+    }
+    for (indj = 0; indj &lt; train_width; indj++)
+    {
+        for (indk = 0; indk &lt; train_width; indk++)
+        {
+            cov(indj, indk) = sum_xj_xk(indj, indk) - sum_xj(indj, indk) * mu[indk] - sum_xj(indk, indj) * mu[indj];
+            cov(indj, indk) = (cov(indj, indk) /  n_obs(indj, indk)) + mu[indk] * mu[indj];
+        }
+    }
+}
+
+real CovariancePreservationImputationVMatrix::computeImputation(int row, int col) const
+{
+    Vec input(source_width);
+    source-&gt;getRow(row, input);
+    return computeImputation(row, col, input);
+}
+
+real CovariancePreservationImputationVMatrix::computeImputation(int row, int col, Vec input) const
+{
+    real sum_cov_xl = 0;
+    real sum_xl_square = 0;
+    for (int indl = 0; indl &lt; source_width; indl++)
+    {
+        if (is_missing(input[indl])) continue;
+        sum_cov_xl += cov(indl, col) * (input[indl] - mu[indl]);
+        sum_xl_square += (input[indl] - mu[indl]) * (input[indl] - mu[indl]);
+    }
+    if (sum_xl_square == 0.0) return mu[col];
+    return mu[col] + sum_cov_xl / sum_xl_square;
+}
+
+} // end of namespcae PLearn

Added: branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,129 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ******************************************************************      
+   * $Id: CovariancePreservationImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
+   ****************************************************************** */
+
+/*! \file PLearnLibrary/PLearnCore/VMat.h */
+
+#ifndef CovariancePreservationImputationVMatrix_INC
+#define CovariancePreservationImputationVMatrix_INC
+
+#include &lt;plearn/vmat/SourceVMatrix.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/io/fileutils.h&gt;                     //!&lt;  For isfile()
+#include &lt;plearn/math/BottomNI.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class CovariancePreservationImputationVMatrix: public VMatrix
+{
+  typedef VMatrix inherited;
+  
+public:
+
+  //! The source VMatrix with missing values.
+  VMat                  source;
+  
+  //! A referenced train set.
+  //! The covariance imputation is computed with the observed values in this data set.
+  VMat                  train_set;
+  
+
+                        CovariancePreservationImputationVMatrix();
+  virtual               ~CovariancePreservationImputationVMatrix();
+
+  static void           declareOptions(OptionList &amp;ol);
+
+  virtual void          build();
+  virtual void          makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+  virtual void         getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight);
+  virtual real         get(int i, int j) const;
+  virtual void         put(int i, int j, real value);
+  virtual void         getSubRow(int i, int j, Vec v) const;
+  virtual void         putSubRow(int i, int j, Vec v);
+  virtual void         appendRow(Vec v);
+  virtual void         insertRow(int i, Vec v);  
+  virtual void         getRow(int i, Vec v) const;
+  virtual void         putRow(int i, Vec v);
+  virtual void         getColumn(int i, Vec v) const;
+          VMat         getCovarianceFile();
+
+private:
+  
+  int                  train_length;
+  int                  train_width;
+  int                  train_inputsize;
+  int                  train_targetsize;
+  int                  train_weightsize;
+  int                  train_row;
+  Vec                  train_input;
+  TVec&lt;string&gt;         train_field_names;
+  PPath                train_metadata;
+  int                  source_length;
+  int                  source_width;
+  int                  source_inputsize;
+  int                  source_targetsize;
+  int                  source_weightsize;
+  PPath                covariance_file_name;
+  VMat                 covariance_file;
+  int                  indj;
+  int                  indk;
+  Mat                  n_obs;
+  Mat                  sum_xj;
+  Mat                  sum_xj_xk;
+  Vec                  mu;
+  Mat                  cov;
+
+          void         build_();
+          void         createCovarianceFile(); 
+          void         loadCovarianceFile(); 
+          void         computeCovariances();  
+          real         computeImputation(int row, int col) const;
+          real         computeImputation(int row, int col, Vec input) const;
+  
+  PLEARN_DECLARE_OBJECT(CovariancePreservationImputationVMatrix);
+
+};
+
+DECLARE_OBJECT_PTR(CovariancePreservationImputationVMatrix);
+
+} // end of namespcae PLearn
+#endif

Added: branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,243 @@
+// -*- C++ -*-
+
+// DichotomizeDond2DiscreteVariables.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file DichotomizeDond2DiscreteVariables.cc */
+
+#define PL_LOG_MODULE_NAME &quot;DichotomizeDond2DiscreteVariables&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;DichotomizeDond2DiscreteVariables.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    DichotomizeDond2DiscreteVariables,
+    &quot;Dichotomize variables with discrete values.&quot;,
+    &quot;Instructions are provided with the discrete_variable_instructions option.\n&quot;
+);
+
+/////////////////////////
+// DichotomizeDond2DiscreteVariables //
+/////////////////////////
+DichotomizeDond2DiscreteVariables::DichotomizeDond2DiscreteVariables()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void DichotomizeDond2DiscreteVariables::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;discrete_variable_instructions&quot;, &amp;DichotomizeDond2DiscreteVariables::discrete_variable_instructions,
+                  OptionBase::buildoption,
+                  &quot;The instructions to dichotomize the variables in the form of field_name : TVec&lt;pair&gt;.\n&quot;
+                  &quot;The pairs are values from : to, each creating a 0, 1 variable.\n&quot;
+                  &quot;Variables with no specification will be kept as_is.\n&quot;);
+
+    declareOption(ol, &quot;output_path&quot;, &amp;DichotomizeDond2DiscreteVariables::output_path,
+                  OptionBase::buildoption,
+                  &quot;The file path for the fixed output file.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void DichotomizeDond2DiscreteVariables::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(discrete_variable_instructions, copies);
+    deepCopyField(output_path, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void DichotomizeDond2DiscreteVariables::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void DichotomizeDond2DiscreteVariables::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        dichotomizeDiscreteVariables();
+    }
+}
+
+void DichotomizeDond2DiscreteVariables::dichotomizeDiscreteVariables()
+{    
+    // initialize primary dataset
+    main_row = 0;
+    main_col = 0;
+    main_length = train_set-&gt;length();
+    main_width = train_set-&gt;width();
+    main_input.resize(main_width);
+    main_names.resize(main_width);
+    main_ins.resize(main_width);
+    ins_width = discrete_variable_instructions.size();
+    main_names &lt;&lt; train_set-&gt;fieldNames();
+    main_ins.fill(-1);
+    for (ins_col = 0; ins_col &lt; ins_width; ins_col++)
+    {
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (discrete_variable_instructions[ins_col].first == main_names[main_col]) break;
+        }
+        if (main_col &gt;= main_width) PLERROR(&quot;In DichotomizeDond2DiscreteVariables: no field with this name in data set: %s&quot;, (discrete_variable_instructions[ins_col].first).c_str());
+        else main_ins[main_col] = ins_col;
+    }
+    
+    // initialize output datasets
+    output_length = main_length;
+    output_width = 0;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (main_ins[main_col] &lt; 0) output_width += 1;
+        else
+        {
+            instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
+            output_width += instruction_ptr.size();
+        }
+    }
+    output_record.resize(output_width);
+    output_names.resize(output_width);
+    output_col = 0;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (main_ins[main_col] &lt; 0)
+        {
+            output_names[output_col] = main_names[main_col];
+            output_col += 1;
+        }
+        else
+        {
+           instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
+           if (instruction_ptr.size() == 0) continue;
+           for (ins_col = 0; ins_col &lt; instruction_ptr.size(); ins_col++)
+           {
+               output_names[output_col] = main_names[main_col] + &quot;_&quot;
+                                        + tostring(instruction_ptr[ins_col].first) + &quot;_&quot; 
+                                        + tostring(instruction_ptr[ins_col].second);
+               output_col += 1;
+           }
+        }    
+    }
+    output_file = new FileVMatrix(output_path + &quot;.pmat&quot;, output_length, output_names);
+    output_file-&gt;defineSizes(output_width, 0, 0);
+    
+    //Now, we can process the discrete variables.
+    ProgressBar* pb = 0;
+    pb = new ProgressBar( &quot;Dichotomizing the discrete variables&quot;, main_length);
+    for (main_row = 0; main_row &lt; main_length; main_row++)
+    {
+        train_set-&gt;getRow(main_row, main_input);
+        output_col = 0;
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (main_ins[main_col] &lt; 0)
+            {
+                output_record[output_col] = main_input[main_col];
+                output_col += 1;
+            }
+            else
+            {
+               instruction_ptr = discrete_variable_instructions[main_ins[main_col]].second;
+               if (instruction_ptr.size() == 0) continue;
+               for (ins_col = 0; ins_col &lt; instruction_ptr.size(); ins_col++)
+               {
+                   if (is_missing(main_input[main_col])) output_record[output_col] = MISSING_VALUE;
+                   else if (main_input[main_col] &lt; instruction_ptr[ins_col].first || main_input[main_col] &gt; instruction_ptr[ins_col].second) output_record[output_col] = 0.0;
+                   else output_record[output_col] = 1.0;
+                   output_col += 1;
+               }
+            }    
+        }
+        output_file-&gt;putRow(main_row, output_record);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+}
+
+VMat DichotomizeDond2DiscreteVariables::getOutputFile()
+{
+    return output_file;
+}
+
+int DichotomizeDond2DiscreteVariables::outputsize() const {return 0;}
+void DichotomizeDond2DiscreteVariables::train()
+{
+        PLERROR(&quot;DichotomizeDond2DiscreteVariables: we are done here&quot;);
+}
+void DichotomizeDond2DiscreteVariables::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void DichotomizeDond2DiscreteVariables::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; DichotomizeDond2DiscreteVariables::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; DichotomizeDond2DiscreteVariables::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,160 @@
+// -*- C++ -*-
+
+// DichotomizeDond2DiscreteVariables.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file DichotomizeDond2DiscreteVariables.h */
+
+
+#ifndef DichotomizeDond2DiscreteVariables_INC
+#define DichotomizeDond2DiscreteVariables_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class DichotomizeDond2DiscreteVariables : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! The instructions to fix the binary variables in the form of field_name : instruction.
+    //! Supported instructions are 9_is_one, not_0_is_one, not_missing_is_one, not_1000_is_one.
+    //! Variables with no specification will be kept as_is.
+    TVec&lt; pair&lt;string, TVec&lt; pair&lt;real, real&gt; &gt; &gt; &gt; discrete_variable_instructions;
+    
+    //! The file path for the fixed output file.
+    string output_path;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    DichotomizeDond2DiscreteVariables();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+    VMat getOutputFile();
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(DichotomizeDond2DiscreteVariables);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void dichotomizeDiscreteVariables();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    
+    // input instructions variables
+    int ins_width;
+    int ins_col;
+    TVec&lt;pair&lt;real, real&gt; &gt; instruction_ptr;
+    
+    // primary dataset variables
+    int main_length;
+    int main_width;
+    int main_row;
+    int main_col;
+    Vec main_input;
+    TVec&lt;string&gt; main_names;
+    TVec&lt;int&gt; main_ins;
+    
+    // output dataset variables
+    int output_length;
+    int output_width;
+    int output_col;
+    Vec output_record;
+    TVec&lt;string&gt; output_names;
+    VMat output_file;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(DichotomizeDond2DiscreteVariables);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,519 @@
+// -*- C++ -*-
+
+// Experimentation.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file Experimentation.cc */
+
+#define PL_LOG_MODULE_NAME &quot;Experimentation&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;Experimentation.h&quot;
+#include &lt;plearn/io/load_and_save.h&gt;                 //!&lt;  For save
+#include &lt;plearn/io/fileutils.h&gt;                     //!&lt;  For isfile()
+#include &lt;plearn/math/random.h&gt;                      //!&lt;  For the seed stuff.
+#include &lt;plearn/vmat/ExplicitSplitter.h&gt;            //!&lt;  For the splitter stuff.
+#include &lt;plearn/vmat/VariableDeletionVMatrix.h&gt;     //!&lt;  For the new_set stuff.
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    Experimentation,
+    &quot;Computes correlation coefficient between various discrete values and the target.&quot;,
+    &quot;name of the discrete variable, of the target and the values to check are options.\n&quot;
+);
+
+/////////////////////////
+// Experimentation //
+/////////////////////////
+Experimentation::Experimentation()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void Experimentation::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;save_files&quot;, &amp;Experimentation::save_files,
+                  OptionBase::buildoption,
+                  &quot;If set to 1, save the built train and test files instead of running the experiment.&quot;);
+    declareOption(ol, &quot;experiment_without_missing_indicator&quot;, &amp;Experimentation::experiment_without_missing_indicator,
+                  OptionBase::buildoption,
+                  &quot;If set to 1, the missing_indicator_field_names will be excluded from the built training files.&quot;);
+    declareOption(ol, &quot;target_field_name&quot;, &amp;Experimentation::target_field_name,
+                  OptionBase::buildoption,
+                  &quot;The name of the field to select from the target_set as target for the built training files.&quot;);
+    declareOption(ol, &quot;missing_indicator_field_names&quot;, &amp;Experimentation::missing_indicator_field_names,
+                  OptionBase::buildoption,
+                  &quot;The field names of the missing indicators to exclude when we experiment without them.&quot;);
+    declareOption(ol, &quot;experiment_name&quot;, &amp;Experimentation::experiment_name,
+                  OptionBase::buildoption,
+                  &quot;The name of the group of experiments to conduct.&quot;);
+    declareOption(ol, &quot;number_of_test_samples&quot;, &amp;Experimentation::number_of_test_samples,
+                  OptionBase::buildoption,
+                  &quot;The number of test samples at the beginning of the train set.&quot;);
+    declareOption(ol, &quot;number_of_train_samples&quot;, &amp;Experimentation::number_of_train_samples,
+                  OptionBase::buildoption,
+                  &quot;The number of train samples in the reference set to compute the % of missing.&quot;);
+    declareOption(ol, &quot;reference_train_set&quot;, &amp;Experimentation::reference_train_set,
+                  OptionBase::buildoption,
+                  &quot;The train and valid set with missing values to compute the % of missing.&quot;);
+    declareOption(ol, &quot;target_set&quot;, &amp;Experimentation::target_set,
+                  OptionBase::buildoption,
+                  &quot;The data set with the targets corresponding to the train set.&quot;);
+    declareOption(ol, &quot;deletion_thresholds&quot;, &amp;Experimentation::deletion_thresholds,
+                  OptionBase::buildoption,
+                  &quot;The vector of the various deletion threshold to run this experiment with.&quot;);
+    declareOption(ol, &quot;experiment_directory&quot;, &amp;Experimentation::experiment_directory,
+                  OptionBase::buildoption,
+                  &quot;The path in which to build the directories for the experiment's results.&quot;);
+    declareOption(ol, &quot;experiment_template&quot;, &amp;Experimentation::experiment_template,
+                  OptionBase::buildoption,
+                  &quot;The template of the script to conduct the experiment.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void Experimentation::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(experiment_name, copies);
+    deepCopyField(number_of_test_samples, copies);
+    deepCopyField(number_of_train_samples, copies);
+    deepCopyField(reference_train_set, copies);
+    deepCopyField(target_set, copies);
+    deepCopyField(deletion_thresholds, copies);
+    deepCopyField(experiment_directory, copies);
+    deepCopyField(experiment_template, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void Experimentation::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void Experimentation::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        for (int iteration = 1; iteration &lt;= 50; iteration++)
+        {
+            cout &lt;&lt; &quot;In Experimentation, Iteration # &quot; &lt;&lt; iteration &lt;&lt; endl;
+            experimentSetUp();
+            train();
+            ::PLearn::save(header_expdir + &quot;/&quot; + deletion_threshold_str + &quot;/source_names.psave&quot;, source_names);
+        }
+        PLERROR(&quot;In Experimentation: we are done here&quot;);
+    }
+}
+
+void Experimentation::experimentSetUp()
+{ 
+    // initialize primary dataset
+    main_row = 0;
+    main_col = 0;
+    main_length = train_set-&gt;length();
+    main_width = train_set-&gt;width();
+    main_names.resize(main_width);
+    main_names &lt;&lt; train_set-&gt;fieldNames();
+    if (train_set-&gt;hasMetaDataDir()) main_metadata = train_set-&gt;getMetaDataDir();
+    else if (experiment_directory == &quot;&quot;) PLERROR(&quot;In Experimentation: we need one of experiment_directory or train_set-&gt;metadatadir&quot;);
+         else main_metadata = experiment_directory;
+    if (experiment_without_missing_indicator &gt; 0)
+    {
+        fields_width = missing_indicator_field_names.size();
+        main_fields_selected.resize(main_width - fields_width);
+        for (fields_col = 0; fields_col &lt; fields_width; fields_col++)
+        {
+            for (main_col = 0; main_col &lt; main_width; main_col++)
+            {
+                if (missing_indicator_field_names[fields_col] == main_names[main_col]) break;
+            }
+            if (main_col &gt;= main_width) PLERROR(&quot;In Experimentation: no field with this name in input dataset: %&quot;, (missing_indicator_field_names[fields_col]).c_str());
+        }
+        main_fields_selected_col = 0;
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            for (fields_col = 0; fields_col &lt; fields_width; fields_col++)
+            {
+                if (missing_indicator_field_names[fields_col] == main_names[main_col]) break;
+            }
+            if (fields_col &lt; fields_width) continue;
+            main_fields_selected[main_fields_selected_col] = main_names[main_col];
+            main_fields_selected_col += 1;
+        }
+    }
+    
+    // initialize target dataset
+    target_row = 0;
+    target_col = 0;
+    target_length = target_set-&gt;length();
+    target_width = target_set-&gt;width();
+    target_names.resize(target_width);
+    target_names &lt;&lt; target_set-&gt;fieldNames();
+    if (target_length != main_length) PLERROR(&quot;In Experimentation: target and main train datasets should have equal length&quot;);
+    for (target_col = 0; target_col &lt; target_width; target_col++)
+    {
+        if (target_field_name == target_names[target_col]) break;
+    }
+    if (target_col &gt;= target_width) PLERROR(&quot;In Experimentation: no field with this name in target dataset: %&quot;, target_field_name.c_str());
+    
+    // initialize the header file
+    cout &lt;&lt; &quot;initialize the header file&quot; &lt;&lt; endl;
+    reference_train_set-&gt;lockMetaDataDir();
+    if (experiment_directory == &quot;&quot;) header_expdir = main_metadata + &quot;/Experiment/&quot; + experiment_name;
+    else header_expdir = experiment_directory;
+    header_expdir += &quot;/&quot; + target_field_name;
+    if (experiment_without_missing_indicator &gt; 0) header_expdir += &quot;/no_ind/&quot;;
+    else header_expdir += &quot;/ind/&quot;;
+    header_file_name = header_expdir + &quot;header.pmat&quot;;
+    if (deletion_thresholds.length() &lt;= 0)
+    {
+        deletion_thresholds.resize(20);
+        for (header_col = 0; header_col &lt; 20; header_col++) deletion_thresholds[header_col] = (real) to_deal_with_next / 20.0;
+    } 
+    header_width = deletion_thresholds.length();
+    header_record.resize(header_width);
+    if (!isfile(header_file_name)) createHeaderFile();
+    else getHeaderRecord();
+    
+    // choose deletion threshold to experiment with
+    cout &lt;&lt; &quot;choose deletion threshold to experiment with&quot; &lt;&lt; endl;
+    to_deal_with_total = 0;
+    to_deal_with_next = -1;
+    for (header_col = 0; header_col &lt; header_width; header_col++)
+    {
+        if (header_record[header_col] != 0.0) continue;
+        to_deal_with_total += 1;
+        if (to_deal_with_next &lt; 0) to_deal_with_next = header_col;
+    }
+    if (to_deal_with_next &lt; 0)
+    {
+        reference_train_set-&gt;unlockMetaDataDir();
+        reviewGlobalStats();
+        PLERROR(&quot;In Experimentation: we are done here&quot;);
+    }
+    deletion_threshold = deletion_thresholds[to_deal_with_next];
+    deletion_threshold_str = tostring(deletion_threshold + 0.005).substr(0,4);
+    cout &lt;&lt; &quot;total number of thresholds left to deal with: &quot; &lt;&lt; to_deal_with_total &lt;&lt; endl;
+    cout &lt;&lt; &quot;next thresholds to deal with: &quot; &lt;&lt; deletion_threshold &lt;&lt; endl;
+    updateHeaderRecord(to_deal_with_next);
+    reference_train_set-&gt;unlockMetaDataDir();
+    
+    // build the train and test sets
+    setSourceDataset();
+    cout &lt;&lt; &quot;source data set width: &quot; &lt;&lt; source_set-&gt;width() &lt;&lt; endl;
+    main_input.resize(source_set-&gt;width());
+    source_names.resize(source_set-&gt;width());
+    source_names &lt;&lt; source_set-&gt;fieldNames();
+    source_names.resize(source_set-&gt;width() + 1);
+    source_names[source_set-&gt;width()] = target_field_name;
+    
+    // load test data set
+    ProgressBar* pb = 0;
+    test_length = number_of_test_samples;
+    test_width = source_set-&gt;width() + 1;
+    test_file = new MemoryVMatrix(test_length, test_width);
+    test_file-&gt;defineSizes(test_width - 1, 1, 0);
+    test_record.resize(test_width);
+    pb = new ProgressBar( &quot;loading the test file for threshold: &quot; + deletion_threshold_str, test_length);
+    for (main_row = 0; main_row &lt; test_length; main_row++)
+    {
+        source_set-&gt;getRow(main_row, main_input);
+        for (main_col = 0; main_col &lt; source_set-&gt;width(); main_col++) test_record[main_col] = main_input[main_col];
+        test_record[source_set-&gt;width()] = target_set-&gt;get(main_row, target_col);
+        test_file-&gt;putRow(main_row, test_record);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+    
+    // load training and validation data set
+    train_valid_length = main_length - test_length;
+    train_valid_width = source_set-&gt;width() + 1;
+    train_valid_file = new MemoryVMatrix(train_valid_length, train_valid_width);
+    train_valid_file-&gt;defineSizes(train_valid_width - 1, 1, 0);
+    train_valid_record.resize(train_valid_width);
+    pb = new ProgressBar( &quot;loading the training and validation file for threshold: &quot; + deletion_threshold_str, train_valid_length);
+    for (main_row = test_length; main_row &lt; main_length; main_row++)
+    {
+        source_set-&gt;getRow(main_row, main_input);
+        for (main_col = 0; main_col &lt; source_set-&gt;width(); main_col++) train_valid_record[main_col] = main_input[main_col];
+        train_valid_record[source_set-&gt;width()] = target_set-&gt;get(main_row, target_col);
+        train_valid_file-&gt;putRow(main_row - test_length, train_valid_record);
+        pb-&gt;update( main_row - test_length );
+    }
+    delete pb;
+    
+    // save files if requested
+    if (save_files &lt;= 0) return;
+    VMat save_test = new FileVMatrix(header_expdir + &quot;/&quot; + deletion_threshold_str + &quot;/test.pmat&quot;, test_length, test_width);
+    save_test-&gt;declareFieldNames(source_names);
+    pb = new ProgressBar( &quot;saving the test file for threshold: &quot; + deletion_threshold_str, test_length);
+    for (main_row = 0; main_row &lt; test_length; main_row++)
+    {
+        test_file-&gt;getRow(main_row, test_record);
+        save_test-&gt;putRow(main_row, test_record);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+    VMat save_train_valid = new FileVMatrix(header_expdir + &quot;/&quot; + deletion_threshold_str + &quot;/train_valid.pmat&quot;, train_valid_length, train_valid_width);
+    save_train_valid-&gt;declareFieldNames(source_names);
+    pb = new ProgressBar( &quot;saving the training and validation file for threshold: &quot; + deletion_threshold_str, train_valid_length);
+    for (main_row = 0; main_row &lt; train_valid_length; main_row++)
+    {
+        train_valid_file-&gt;getRow(main_row, train_valid_record);
+        save_train_valid-&gt;putRow(main_row, train_valid_record);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+    PLERROR(&quot;In Experimentation: we are done here&quot;);
+}
+
+void Experimentation::createHeaderFile()
+{ 
+    header_record.clear();
+    header_names.resize(header_width);
+    for (header_col = 0; header_col &lt; header_width; header_col++) 
+        header_names[header_col] = tostring(deletion_thresholds[header_col] + 0.005).substr(0,4);
+    header_file = new FileVMatrix(header_file_name, 1, header_names);
+    header_file-&gt;putRow(0, header_record);
+}
+
+void Experimentation::getHeaderRecord()
+{ 
+    header_file = new FileVMatrix(header_file_name, true);
+    if (header_width != header_file-&gt;width()) PLERROR(&quot;In Experimentation: the existing header file does not match the deletion_thresholds width)&quot;);
+    header_names = header_file-&gt;fieldNames();
+    for (header_col = 0; header_col &lt; header_width; header_col++) 
+        if (header_names[header_col] != tostring(deletion_thresholds[header_col] + 0.005).substr(0,4))
+            PLERROR(&quot;In Experimentation: the existing header file names does not match the deletion_thresholds values)&quot;);;
+    header_file-&gt;getRow(0, header_record);
+}
+
+void Experimentation::updateHeaderRecord(int var_col)
+{ 
+    header_file-&gt;put(0, var_col, 1.0);
+    header_file-&gt;flush();
+}
+
+void Experimentation::setSourceDataset()
+{
+    VMat selected_train_set = train_set;
+    VMat selected_reference_set= reference_train_set;
+    if (experiment_without_missing_indicator &gt; 0)
+    {
+            SelectColumnsVMatrix* new_train_set = new SelectColumnsVMatrix();
+            new_train_set-&gt;source = train_set;
+            new_train_set-&gt;fields = main_fields_selected;
+            selected_train_set = new_train_set;
+            selected_train_set-&gt;build();
+            selected_train_set-&gt;defineSizes(selected_train_set-&gt;width(), 0, 0);
+            SelectColumnsVMatrix* new_reference_set = new SelectColumnsVMatrix();
+            new_reference_set-&gt;source = reference_train_set;
+            new_reference_set-&gt;fields = main_fields_selected;
+            selected_reference_set = new_reference_set;
+            selected_reference_set-&gt;build();
+            selected_reference_set-&gt;defineSizes(selected_reference_set-&gt;width(), 0, 0);
+    }
+    if (deletion_threshold &lt;= 0.0)
+    {
+        source_set = selected_train_set;
+        return;
+    }
+    VariableDeletionVMatrix* new_set = new VariableDeletionVMatrix();
+    // VMat: The data set with all variables to select the columns from.
+    new_set-&gt;complete_dataset = selected_train_set;
+    // VMat: The train set in which to compute the percentage of missing values.
+    new_set-&gt;train_set = selected_reference_set;
+    // double: The percentage of non-missing values for a variable above which, the variable will be selected.
+    new_set-&gt;deletion_threshold = deletion_threshold;
+    // bool: If set to 1, the columns with constant non-missing values will be removed.
+    new_set-&gt;remove_columns_with_constant_value = 1;
+    // double: If equal to zero, all the train samples are used to calculated the percentages and constant values.
+    // If it is a fraction between 0 and 1, this proportion of the samples will be used.
+    // If greater or equal to 1, the integer portion will be interpreted as the number of samples to use.
+    new_set-&gt;number_of_train_samples = number_of_train_samples;
+    // int: The row at which, to start to calculate the percentages and constant values.
+    new_set-&gt;start_row = 0;
+    source_set = new_set;
+    source_set-&gt;build();
+}
+
+void Experimentation::reviewGlobalStats()
+{
+    cout &lt;&lt; &quot;There is no more variable to deal with.&quot; &lt;&lt; endl;
+    bool missing_results_file = false;
+    for (header_col = 0; header_col &lt; header_width; header_col++)
+    {
+        deletion_threshold = deletion_thresholds[header_col];
+        deletion_threshold_str = tostring(deletion_threshold + 0.005).substr(0,4);
+        PPath expdir = header_expdir + &quot;/&quot; + deletion_threshold_str;
+        PPath train_valid_results_file_name = expdir + &quot;/Split0/LearnerExpdir/Strat0results.pmat&quot;;
+        PPath test_results_file_name = expdir + &quot;/global_stats.pmat&quot;;
+        PPath source_names_file_name = expdir + &quot;/source_names.psave&quot;;
+        if (!isfile(train_valid_results_file_name))
+        {
+            cout &lt;&lt; &quot;Missing training and validation results for threshold &quot; &lt;&lt; deletion_threshold_str &lt;&lt; endl;
+            missing_results_file = true;
+        }
+        if (!isfile(test_results_file_name))
+        {
+            cout &lt;&lt; &quot;Missing test results for threshold &quot; &lt;&lt; deletion_threshold_str &lt;&lt; endl;
+            missing_results_file = true;
+        }
+        if (!isfile(source_names_file_name))
+        {
+            cout &lt;&lt; &quot;Missing variable selected saved file for threshold &quot; &lt;&lt; deletion_threshold_str &lt;&lt; endl;
+            missing_results_file = true;
+        }
+    }
+    if (missing_results_file) return;
+    cout &lt;&lt; endl &lt;&lt; endl;
+    cout &lt;&lt; &quot;Results for experiment &quot; &lt;&lt; experiment_name &lt;&lt; endl;
+    cout &lt;&lt; &quot;       The file used for this experiment was &quot; &lt;&lt; main_metadata &lt;&lt; endl;
+    cout &lt;&lt; &quot;       The target used was &quot; &lt;&lt; target_field_name &lt;&lt; endl;
+    if (experiment_without_missing_indicator &gt; 0) cout &lt;&lt; &quot;       The experiment was carried without missing indicators&quot; &lt;&lt; endl;
+    else cout &lt;&lt; &quot;       The experiment was carried with missing indicators&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; endl;
+    cout &lt;&lt; &quot;           number                                                                  &quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;             of                                                                    &quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot; deletion variable   weigth    train    valid     test     test       std      test&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;threshold selected    decay     mse      mse      mse      cse       error     cle &quot; &lt;&lt; endl;
+    cout &lt;&lt; endl;
+    cout &lt;&lt; fixed &lt;&lt; showpoint;
+    real best_valid_mse_threshold = -1.0;
+    real best_valid_mse_value;
+    for (header_col = 0; header_col &lt; header_width; header_col++)
+    {
+        deletion_threshold = deletion_thresholds[header_col];
+        deletion_threshold_str = tostring(deletion_threshold + 0.005).substr(0,4);
+        PPath expdir = header_expdir + &quot;/&quot; + deletion_threshold_str;
+        PPath train_valid_results_file_name = expdir + &quot;/Split0/LearnerExpdir/Strat0results.pmat&quot;;
+        PPath test_results_file_name = expdir + &quot;/global_stats.pmat&quot;;
+        PPath source_names_file_name = expdir + &quot;/source_names.psave&quot;;
+        ::PLearn::load(source_names_file_name, source_names);
+        VMat train_valid_results_file = new FileVMatrix(train_valid_results_file_name);
+        VMat test_results_file = new FileVMatrix(test_results_file_name);
+        int train_valid_last_row = train_valid_results_file-&gt;length() - 1;
+        real weight_decay = train_valid_results_file-&gt;get(train_valid_last_row, 2);
+        real train_mse =    train_valid_results_file-&gt;get(train_valid_last_row, 3);
+        real valid_mse =    train_valid_results_file-&gt;get(train_valid_last_row, 4);
+        if (best_valid_mse_threshold &lt; 0.0)
+        {
+            best_valid_mse_threshold = deletion_threshold;
+            best_valid_mse_value = valid_mse;
+        }
+        else if (valid_mse &lt; best_valid_mse_value)
+        {
+            best_valid_mse_threshold = deletion_threshold;
+            best_valid_mse_value = valid_mse;
+        }
+        real test_mse =     test_results_file-&gt;get(1, 0);
+        real test_cse =     test_results_file-&gt;get(1, 2);
+        real test_cse_std = test_results_file-&gt;get(1, 3);
+        real test_cle =     test_results_file-&gt;get(1, 4);
+        cout &lt;&lt; setiosflags(ios::right) &lt;&lt; setw(9) &lt;&lt; deletion_threshold_str &lt;&lt; &quot;   &quot;
+             &lt;&lt; setw(4) &lt;&lt; source_names.size() &lt;&lt; &quot;    &quot;
+             &lt;&lt; setw(6) &lt;&lt; weight_decay &lt;&lt; &quot; &quot;
+             &lt;&lt; setw(6) &lt;&lt; train_mse &lt;&lt; &quot; &quot;
+             &lt;&lt; setw(6) &lt;&lt; valid_mse &lt;&lt; &quot; &quot;
+             &lt;&lt; setw(6) &lt;&lt; test_mse &lt;&lt; &quot; &quot;
+             &lt;&lt; setw(6) &lt;&lt; test_cse &lt;&lt; &quot;+/-&quot;
+             &lt;&lt; setw(6) &lt;&lt; test_cse_std &lt;&lt; &quot; &quot;
+             &lt;&lt; setw(6) &lt;&lt; test_cle &lt;&lt; endl;
+    }
+    cout &lt;&lt; endl &lt;&lt; endl;
+    cout &lt;&lt; &quot;       Based on the validation mse, the suggested threshold is &quot; &lt;&lt; best_valid_mse_threshold &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; endl;
+}
+
+void Experimentation::train()
+{
+    PP&lt;ExplicitSplitter&gt; explicit_splitter = new ExplicitSplitter();
+    explicit_splitter-&gt;splitsets.resize(1,2);
+    explicit_splitter-&gt;splitsets(0,0) = train_valid_file;
+    explicit_splitter-&gt;splitsets(0,1) = test_file;
+    experiment = ::PLearn::deepCopy(experiment_template);
+    experiment-&gt;setOption(&quot;expdir&quot;, header_expdir + &quot;/&quot; + deletion_threshold_str);
+    experiment-&gt;splitter = new ExplicitSplitter();
+    experiment-&gt;splitter = explicit_splitter;
+    experiment-&gt;build();
+    Vec results = experiment-&gt;perform(true);
+}
+
+int Experimentation::outputsize() const {return 0;}
+void Experimentation::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void Experimentation::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; Experimentation::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; Experimentation::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/Experimentation.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,221 @@
+// -*- C++ -*-
+
+// Experimentation.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file Experimentation.h */
+
+
+#ifndef Experimentation_INC
+#define Experimentation_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/testers/PTester.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/vmat/MemoryVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class Experimentation : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    
+    //! If set to 1, save the built train and test files instead of running the experiment.
+    int save_files;
+    //! If set to 1, the missing_indicator_field_names will be excluded from the built training files.
+    int experiment_without_missing_indicator;
+    //! The name of the field to select from the target_set as target for the built training files.
+    string target_field_name;
+    //! The field names of the missing indicators to exclude when we experiment without them.
+    TVec&lt;string&gt; missing_indicator_field_names;
+    //! The name of the group of experiments to conduct.
+    string experiment_name;
+    //! The number of test samples at the beginning of the train set.
+    int number_of_test_samples;
+    //! The number of train samples in the reference set to compute the % of missing.
+    int number_of_train_samples;
+    //! The train and valid set with missing values to compute the % of missing.
+    VMat reference_train_set;
+    //! The data set with the targets corresponding to the train set.
+    VMat target_set;
+    //! The vector of the various deletion threshold to run this experiment with.
+    Vec deletion_thresholds;
+    //! The path in which to build the directories for the experiment's results.
+    PPath experiment_directory;
+    //! The template of the script to conduct the experiment
+    PP&lt;PTester&gt; experiment_template;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    Experimentation();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(Experimentation);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void experimentSetUp();
+    void createHeaderFile();
+    void getHeaderRecord();
+    void updateHeaderRecord(int var_col);
+    void setSourceDataset();
+    void reviewGlobalStats();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    
+    int          main_row;
+    int          main_col;
+    int          main_length;
+    int          main_width;
+    Vec          main_input;
+    TVec&lt;string&gt; main_names;
+    PPath        main_metadata;
+    int          main_fields_selected_col;
+    TVec&lt;string&gt; main_fields_selected;
+    
+    int          fields_width;
+    int          fields_col;
+    
+    int          target_row;
+    int          target_col;
+    int          target_length;
+    int          target_width;
+    Vec          target_input;
+    TVec&lt;string&gt; target_names;
+    
+    int             header_col;
+    int             header_width;
+    Vec             header_record;
+    TVec&lt;string&gt;    header_names;
+    string          header_expdir;
+    PPath           header_file_name;
+    PP&lt;FileVMatrix&gt; header_file;
+    
+    int          to_deal_with_total;
+    int          to_deal_with_next;
+    real         deletion_threshold;
+    string       deletion_threshold_str;
+    
+    int          test_length;
+    int          test_width;
+    Vec          test_record;
+    VMat         test_file;
+    
+    int          train_valid_length;
+    int          train_valid_width;
+    Vec          train_valid_record;
+    VMat         train_valid_file;
+    
+    VMat         source_set;
+    TVec&lt;string&gt; source_names;
+    PP&lt;PTester&gt;  experiment;
+    
+/*
+    PPath results_file_name;
+    VMat results_file;
+    int results_length;
+    real results_nstages;
+    real results_mse;
+    real results_std_err;
+    PPath test_output_file_name;
+    VMat test_output_file;
+    int test_output_length;
+*/
+    
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(Experimentation);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,221 @@
+// -*- C++ -*-
+
+// FixDond2BinaryVariables.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file FixDond2BinaryVariables.cc */
+
+#define PL_LOG_MODULE_NAME &quot;FixDond2BinaryVariables&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;FixDond2BinaryVariables.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    FixDond2BinaryVariables,
+    &quot;Fix binary variables with values 0, 1.0 or possibly is_missing.&quot;,
+    &quot;Instructions are provided with the binary_variable_instructions option.\n&quot;
+);
+
+/////////////////////////
+// FixDond2BinaryVariables //
+/////////////////////////
+FixDond2BinaryVariables::FixDond2BinaryVariables()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void FixDond2BinaryVariables::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;binary_variable_instructions&quot;, &amp;FixDond2BinaryVariables::binary_variable_instructions,
+                  OptionBase::buildoption,
+                  &quot;The instructions to fix the binary variables in the form of field_name : instruction.\n&quot;
+                  &quot;Supported instructions are 9_is_one, not_0_is_one, not_missing_is_one, not_1000_is_one.\n&quot;
+                  &quot;Variables with no specification will be kept as_is.\n&quot;);
+
+    declareOption(ol, &quot;output_path&quot;, &amp;FixDond2BinaryVariables::output_path,
+                  OptionBase::buildoption,
+                  &quot;The file path for the fixed output file.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void FixDond2BinaryVariables::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(binary_variable_instructions, copies);
+    deepCopyField(output_path, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void FixDond2BinaryVariables::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void FixDond2BinaryVariables::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        fixBinaryVariables();
+    }
+}
+
+void FixDond2BinaryVariables::fixBinaryVariables()
+{    
+    // initialize primary dataset
+    main_row = 0;
+    main_col = 0;
+    main_length = train_set-&gt;length();
+    main_width = train_set-&gt;width();
+    main_input.resize(main_width);
+    main_names.resize(main_width);
+    main_ins.resize(main_width);
+    ins_width = binary_variable_instructions.size();
+    main_names &lt;&lt; train_set-&gt;fieldNames();
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        main_ins[main_col] = &quot;as_is&quot;;
+    }
+    for (ins_col = 0; ins_col &lt; ins_width; ins_col++)
+    {
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (binary_variable_instructions[ins_col].first == main_names[main_col]) break;
+        }
+        if (main_col &gt;= main_width) PLERROR(&quot;In FixDond2BinaryVariables: no field with this name in train data set: %s&quot;, (binary_variable_instructions[ins_col].first).c_str());
+        if (binary_variable_instructions[ins_col].second == &quot;9_is_one&quot;) main_ins[main_col] = &quot;9_is_one&quot;;
+        else if (binary_variable_instructions[ins_col].second == &quot;not_0_is_one&quot;) main_ins[main_col] = &quot;not_0_is_one&quot;;
+        else if (binary_variable_instructions[ins_col].second == &quot;not_missing_is_one&quot;) main_ins[main_col] = &quot;not_missing_is_one&quot;;
+        else if (binary_variable_instructions[ins_col].second == &quot;not_1000_is_one&quot;) main_ins[main_col] = &quot;not_1000_is_one&quot;;
+        else PLERROR(&quot;In FixDond2BinaryVariables: unsupported instruction: %s&quot;, (binary_variable_instructions[ins_col].second).c_str());
+    }
+    
+    // initialize output datasets
+    output_file = new FileVMatrix(output_path + &quot;.pmat&quot;, main_length, main_names);
+    output_file-&gt;defineSizes(main_width, 0, 0);
+    
+    //Now, we can process the binary variables.
+    ProgressBar* pb = 0;
+    pb = new ProgressBar( &quot;Fixing the binary variables&quot;, main_length);
+    for (main_row = 0; main_row &lt; main_length; main_row++)
+    {
+        train_set-&gt;getRow(main_row, main_input);
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (main_ins[main_col] == &quot;not_missing_is_one&quot;)
+            {
+                if (is_missing(main_input[main_col])) main_input[main_col] = 0.0;
+                else  main_input[main_col] = 1.0;
+            }
+            else if (main_ins[main_col] == &quot;not_0_is_one&quot;)
+            {
+                if (is_missing(main_input[main_col])) continue;
+                if (main_input[main_col] != 0.0)  main_input[main_col] = 1.0;
+                else  main_input[main_col] = 0.0;
+            }
+            else if (main_ins[main_col] == &quot;9_is_one&quot;)
+            {
+                if (is_missing(main_input[main_col])) continue;
+                if (main_input[main_col] == 9.0)  main_input[main_col] = 1.0;
+                else  main_input[main_col] = 0.0;
+            }
+            else if (main_ins[main_col] == &quot;not_1000_is_one&quot;)
+            {
+                if (is_missing(main_input[main_col])) continue;
+                if (main_input[main_col] != -1000.0)  main_input[main_col] = 1.0;
+                else  main_input[main_col] = 0.0;
+            }
+        }
+        output_file-&gt;putRow(main_row, main_input);
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+}
+
+VMat FixDond2BinaryVariables::getOutputFile()
+{
+    return output_file;
+}
+
+int FixDond2BinaryVariables::outputsize() const {return 0;}
+void FixDond2BinaryVariables::train()
+{
+    PLERROR(&quot;FixDond2BinaryVariables: we are done here&quot;);
+}
+void FixDond2BinaryVariables::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void FixDond2BinaryVariables::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; FixDond2BinaryVariables::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; FixDond2BinaryVariables::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/FixDond2BinaryVariables.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,154 @@
+// -*- C++ -*-
+
+// FixDond2BinaryVariables.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file FixDond2BinaryVariables.h */
+
+
+#ifndef FixDond2BinaryVariables_INC
+#define FixDond2BinaryVariables_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class FixDond2BinaryVariables : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! The instructions to fix the binary variables in the form of field_name : instruction.
+    //! Supported instructions are 9_is_one, not_0_is_one, not_missing_is_one, not_1000_is_one.
+    //! Variables with no specification will be kept as_is.
+    TVec&lt; pair&lt;string, string&gt; &gt; binary_variable_instructions;
+    
+    //! The file path for the fixed output file.
+    string output_path;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    FixDond2BinaryVariables();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+    VMat getOutputFile();
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(FixDond2BinaryVariables);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void fixBinaryVariables();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    
+    // input instructions variables
+    int ins_width;
+    int ins_col;
+    
+    // primary dataset variables
+    int main_length;
+    int main_width;
+    int main_row;
+    int main_col;
+    Vec main_input;
+    TVec&lt;string&gt; main_names;
+    TVec&lt;string&gt; main_ins;
+    
+    // output dataset variables
+    VMat output_file;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(FixDond2BinaryVariables);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,327 @@
+// -*- C++ -*-
+
+// GaussianizeVMatrix.cc
+//
+// Copyright (C) 2006 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Olivier Delalleau
+
+/*! \file GaussianizeVMatrix.cc */
+
+
+#include &quot;GaussianizeVMatrix.h&quot;
+#include &lt;plearn/math/pl_erf.h&gt;
+#include &lt;plearn/vmat/VMat_computeStats.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    GaussianizeVMatrix,
+    &quot;Transforms its source VMatrix so that its features look Gaussian.&quot;,
+
+    &quot;This VMat transforms the features of its source that are obviously non-\n&quot;
+    &quot;Gaussian, i.e. when the difference between the maximum and minimum\n&quot;
+    &quot;value is too large compared to the standard deviation (the meaning of\n&quot;
+    &quot;'too large' being controlled by the 'threshold_ratio' option).\n&quot;
+    &quot;\n&quot;
+    &quot;When this happens, the values of a features are sorted and their rank\n&quot;
+    &quot;is used to transform them through the inverse cumulative of a normal\n&quot;
+    &quot;Gaussian, resulting on a distribution that actually looks Gaussian.\n&quot;
+    &quot;Note that, unless specified otherwise through the options, only the\n&quot;
+    &quot;input features are transformed.\n&quot;
+    &quot;\n&quot;
+    &quot;An additional 'train_source' VMat can also be specified in order to\n&quot;
+    &quot;transform new data (in the 'source' option) while the transformation\n&quot;
+    &quot;parameters are learned on a fixed 'train_source' VMat (e.g. when new\n&quot;
+    &quot;test data are obtained and need to be properly Gaussianized).\n&quot;
+);
+
+////////////////////////
+// GaussianizeVMatrix //
+////////////////////////
+GaussianizeVMatrix::GaussianizeVMatrix():
+    gaussianize_input(true),
+    gaussianize_target(false),
+    gaussianize_weight(false),
+    gaussianize_extra(false),
+    threshold_ratio(10)
+{}
+
+////////////////////
+// declareOptions //
+////////////////////
+void GaussianizeVMatrix::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;threshold_ratio&quot;, &amp;GaussianizeVMatrix::threshold_ratio,
+                                         OptionBase::buildoption,
+        &quot;A source's feature will be Gaussianized when the following holds:\n&quot;
+        &quot;(max - min) / stddev &gt; threshold_ratio.&quot;);
+
+    declareOption(ol, &quot;gaussianize_input&quot;,
+                  &amp;GaussianizeVMatrix::gaussianize_input,
+                  OptionBase::buildoption,
+        &quot;Whether or not to Gaussianize the input part.&quot;);
+
+    declareOption(ol, &quot;gaussianize_target&quot;,
+                  &amp;GaussianizeVMatrix::gaussianize_target,
+                  OptionBase::buildoption,
+        &quot;Whether or not to Gaussianize the target part.&quot;);
+
+    declareOption(ol, &quot;gaussianize_weight&quot;,
+                  &amp;GaussianizeVMatrix::gaussianize_weight,
+                  OptionBase::buildoption,
+        &quot;Whether or not to Gaussianize the weight part.&quot;);
+
+    declareOption(ol, &quot;gaussianize_extra&quot;,
+                  &amp;GaussianizeVMatrix::gaussianize_extra,
+                  OptionBase::buildoption,
+        &quot;Whether or not to Gaussianize the extra part.&quot;);
+
+    declareOption(ol, &quot;excluded_fields&quot;,
+                  &amp;GaussianizeVMatrix::excluded_fields,
+                  OptionBase::buildoption,
+        &quot;A list of fields to exclude from the process by field name.&quot;);
+
+    declareOption(ol, &quot;train_source&quot;, &amp;GaussianizeVMatrix::train_source,
+                                      OptionBase::buildoption,
+        &quot;An optional VMat that will be used instead of 'source' to compute\n&quot;
+        &quot;the transformation parameters from the distribution statistics.&quot;);
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+///////////
+// build //
+///////////
+void GaussianizeVMatrix::build()
+{
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void GaussianizeVMatrix::build_()
+{
+    if (!source)
+        return;
+
+    if (train_source) {
+        assert( train_source-&gt;width() == source-&gt;width() );
+        assert( train_source-&gt;inputsize()  == source-&gt;inputsize() &amp;&amp;
+                train_source-&gt;targetsize() == source-&gt;targetsize() &amp;&amp;
+                train_source-&gt;weightsize() == source-&gt;weightsize() &amp;&amp;
+                train_source-&gt;extrasize()  == source-&gt;extrasize() );
+    }
+
+    VMat the_source = train_source ? train_source : source;
+
+    assert( the_source-&gt;inputsize() &gt;= 0 &amp;&amp; the_source-&gt;targetsize() &gt;= 0 &amp;&amp;
+            the_source-&gt;weightsize() &gt;= 0 &amp;&amp; the_source-&gt;extrasize() &gt;= 0 );
+
+    // Find which excluded_fields to exclude
+    int the_source_col;
+    int the_source_width = the_source-&gt;width();
+    TVec&lt;string&gt; the_source_names(the_source_width);
+    the_source_names &lt;&lt; the_source-&gt;fieldNames();
+    int excluded_fields_col;
+    int excluded_fields_width = excluded_fields.size();
+    TVec&lt;int&gt; excluded_fields_selected(the_source_width);
+    excluded_fields_selected.clear();
+    for (excluded_fields_col = 0; excluded_fields_col &lt; excluded_fields_width; excluded_fields_col++)
+    {
+        for (the_source_col = 0; the_source_col &lt; the_source_width; the_source_col++)
+        {
+            if (excluded_fields[excluded_fields_col] == the_source_names[the_source_col]) break;
+        }
+        if (the_source_col &gt;= the_source_width)
+            PLERROR(&quot;In GaussianizeVMatrix: no field with this name in input dataset: %s&quot;, (excluded_fields[excluded_fields_col]).c_str());
+        excluded_fields_selected[the_source_col] = 1;
+    }
+
+
+    // Find which dimensions to Gaussianize.
+    features_to_gaussianize.resize(0);
+    int col = 0;
+    if (gaussianize_input)
+        features_to_gaussianize.append(
+                TVec&lt;int&gt;(col, col + the_source-&gt;inputsize() - 1, 1));
+    col += the_source-&gt;inputsize();
+    if (gaussianize_target)
+        features_to_gaussianize.append(
+                TVec&lt;int&gt;(col, col + the_source-&gt;targetsize() - 1, 1));
+    col += the_source-&gt;targetsize();
+    if (gaussianize_weight)
+        features_to_gaussianize.append(
+                TVec&lt;int&gt;(col, col + the_source-&gt;weightsize() - 1, 1));
+    col += the_source-&gt;weightsize();
+    if (gaussianize_extra)
+        features_to_gaussianize.append(
+                TVec&lt;int&gt;(col, col + the_source-&gt;extrasize() - 1, 1));
+    col += the_source-&gt;extrasize();
+
+    // Compute source statistics.
+    TVec&lt;StatsCollector&gt; stats = PLearn::computeStats(the_source, -1, false);
+
+    // See which dimensions violate the Gaussian assumption and will be
+    // actually Gaussianized, and store the corresponding list of values.
+    TVec&lt;int&gt; candidates = features_to_gaussianize.copy();
+    features_to_gaussianize.resize(0);
+    counts.resize(0);
+    Vec row(2);
+    for (int i = 0; i &lt; candidates.length(); i++) {
+        int j = candidates[i];
+        StatsCollector&amp; stat = stats[j];
+        if (excluded_fields_selected[j] &gt; 0)
+            continue;
+        if (fast_exact_is_equal(stat.stddev(), 0))
+            continue;
+        if ((stat.max() - stat.min()) &gt; threshold_ratio * stat.stddev()) {
+            features_to_gaussianize.append(j);
+            counts.append(Mat());
+            Mat&amp; counts_j = counts.lastElement();
+            // We use a dummy iterator to get rid of the last element in the
+            // counts, which is the max real value.
+            map&lt;real, StatsCollectorCounts&gt;::const_iterator it, it_dummy;
+            map&lt;real,StatsCollectorCounts&gt;* count_map = stat.getCounts();
+            it_dummy = count_map-&gt;begin();
+            it_dummy++;
+            int count_values = 0;
+            for (it = count_map-&gt;begin(); it_dummy != count_map-&gt;end();
+                                          it++, it_dummy++)
+            {
+                row[0] = it-&gt;first;
+                row[1] = count_values;
+                count_values += (int) it-&gt;second.n;
+                counts_j.appendRow(row);
+            }
+            // This scales the ranks so that they are between 0 and 1.
+            counts_j.column(1) /= row[1];
+        }
+    }
+
+    // Obtain meta information from source.
+    setMetaInfoFromSource();
+}
+
+///////////////
+// getNewRow //
+///////////////
+void GaussianizeVMatrix::getNewRow(int i, const Vec&amp; v) const
+{
+    assert( source );
+    source-&gt;getRow(i, v);
+    for (int k = 0; k &lt; features_to_gaussianize.length(); k++) {
+        int j = features_to_gaussianize[k];
+        real current_val = v[j];
+        if (is_missing(current_val))
+            continue;
+        // Find closest value in the training data.
+        Mat&amp; counts_j = counts[k];
+        real closest;
+        if (current_val &lt; counts_j(0, 0)) {
+            // Smaller than the minimum.
+            closest = 0;
+        } else if (current_val &gt; counts_j(counts_j.length() - 1, 0)) {
+            // Higher than the maximum.
+            closest = 1;
+        } else {
+            int min = 0;
+            int max = counts_j.length() - 1;
+            while (max - min &gt; 1) {
+                int mid = (max + min) / 2;
+                real mid_val = counts_j(mid, 0);
+                if (current_val &lt; mid_val)
+                    max = mid;
+                else if (current_val &gt; mid_val)
+                    min = mid;
+                else {
+                    // Found the exact value.
+                    min = max = mid;
+                }
+            }
+            if (min == max)
+                closest = counts_j(min, 1);
+            else {
+                assert( max - min == 1 );
+                if (fabs(current_val - counts_j(min, 0)) &lt;
+                    fabs(current_val - counts_j(max, 0)))
+                {
+                    closest = counts_j(min, 1);
+                } else
+                    closest = counts_j(max, 1);
+            }
+        }
+        assert( closest &gt;= 0 &amp;&amp; closest &lt;= 1 );
+        // The expectation of the minimum and maximum of n numbers taken from a
+        // uniform(0,1) distribution are respectively 1/n+1 and n/n+1: we shift
+        // and rescale 'closest' to be in [1/n+1, n/n+1] before using the
+        // inverse of the Gaussian cumulative function.
+        real n = counts_j.length();
+        closest = (n - 1) / (n + 1) * closest + 1 / (n + 1);
+        v[j] = gauss_01_quantile(closest);
+    }
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void GaussianizeVMatrix::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all &quot;pointer-like&quot; fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+
+    // ### Remove this line when you have fully implemented this method.
+    PLERROR(&quot;GaussianizeVMatrix::makeDeepCopyFromShallowCopy not fully (correctly) implemented yet!&quot;);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/GaussianizeVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,160 @@
+// -*- C++ -*-
+
+// GaussianizeVMatrix.h
+//
+// Copyright (C) 2006 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Olivier Delalleau
+
+/*! \file GaussianizeVMatrix.h */
+
+
+#ifndef GaussianizeVMatrix_INC
+#define GaussianizeVMatrix_INC
+
+#include &lt;plearn/vmat/SourceVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * The first sentence should be a BRIEF DESCRIPTION of what the class does.
+ * Place the rest of the class programmer documentation here.  Doxygen supports
+ * Javadoc-style comments.  See <A HREF="http://www.doxygen.org/manual.html">http://www.doxygen.org/manual.html</A>
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class GaussianizeVMatrix : public SourceVMatrix
+{
+    typedef SourceVMatrix inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    bool gaussianize_input;
+    bool gaussianize_target;
+    bool gaussianize_weight;
+    bool gaussianize_extra;
+    real threshold_ratio;
+    TVec&lt;string&gt; excluded_fields;
+    VMat train_source;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    GaussianizeVMatrix();
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(GaussianizeVMatrix);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+
+    //! List of features that need to be Gaussianized.
+    TVec&lt;int&gt; features_to_gaussianize;
+
+    //! Scaling factor to map the rank to [0,1].
+    Vec scaling_factor;
+
+    //! The j-th element is a two-column matrix whose first row is the (sorted)
+    //! list of values appearing in the variable features_to_gaussianize[j],
+    //! and the second row indicates how many occurences are strictly below
+    //! each of these values (i.e. gives their rank).
+    TVec&lt;Mat&gt; counts;
+
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList&amp; ol);
+
+    //! Fill the vector 'v' with the content of the i-th row.
+    //! v is assumed to be the right size.
+    //! ### This function must be overridden in your class
+    virtual void getNewRow(int i, const Vec&amp; v) const;
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(GaussianizeVMatrix);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,454 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************************    
+   * $Id: MeanMedianModeImputationVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
+   ******************************************************************* */
+
+
+#include &quot;MeanMedianModeImputationVMatrix.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+/** MeanMedianModeImputationVMatrix **/
+
+PLEARN_IMPLEMENT_OBJECT(
+  MeanMedianModeImputationVMatrix,
+  &quot;VMat class to impute the observed variable mean to replace missing values in the source matrix.&quot;,
+  &quot;This class will replace missing values in the underlying dataset with the mean, median or mode observed on the train set.\n&quot;
+  &quot;The imputed value is based on the imputation instruction option.\n&quot;
+  );
+
+MeanMedianModeImputationVMatrix::MeanMedianModeImputationVMatrix()
+: number_of_train_samples_to_use(0.0)
+{
+}
+
+MeanMedianModeImputationVMatrix::~MeanMedianModeImputationVMatrix()
+{
+}
+
+void MeanMedianModeImputationVMatrix::declareOptions(OptionList &amp;ol)
+{
+  declareOption(ol, &quot;source&quot;, &amp;MeanMedianModeImputationVMatrix::source, OptionBase::buildoption, 
+                &quot;The source VMatrix with missing values.\n&quot;);
+
+  declareOption(ol, &quot;train_set&quot;, &amp;MeanMedianModeImputationVMatrix::train_set, OptionBase::buildoption, 
+                &quot;A referenced train set.\n&quot;
+                &quot;The mean, median or mode is computed with the observed values in this data set.\n&quot;
+                &quot;It is used in combination with the option number_of_train_samples_to_use\n&quot;);
+
+  declareOption(ol, &quot;number_of_train_samples_to_use&quot;, &amp;MeanMedianModeImputationVMatrix::number_of_train_samples_to_use, OptionBase::buildoption, 
+                &quot;The number of samples from the train set that will be examined to compute the required statistic for each variable.\n&quot; 
+                &quot;If equal to zero, all the samples from the train set are used to calculated the statistics.\n&quot;
+                &quot;If it is a fraction between 0 and 1, this proportion of the samples are used.\n&quot;
+                &quot;If greater or equal to 1, the integer portion is interpreted as the number of samples to use.&quot;);
+      
+  declareOption(ol, &quot;imputation_spec&quot;, &amp;MeanMedianModeImputationVMatrix::imputation_spec, OptionBase::buildoption, 
+                &quot;Pairs of instruction of the form field_name : mean | median | mode.&quot;);
+
+  declareOption(ol, &quot;variable_mean&quot;, &amp;MeanMedianModeImputationVMatrix::variable_mean, OptionBase::learntoption, 
+                &quot;The vector of variable means observed from the train set.&quot;);
+
+  declareOption(ol, &quot;variable_median&quot;, &amp;MeanMedianModeImputationVMatrix::variable_median, OptionBase::learntoption, 
+                &quot;The vector of variable medians observed from the train set.&quot;);
+
+  declareOption(ol, &quot;variable_mode&quot;, &amp;MeanMedianModeImputationVMatrix::variable_mode, OptionBase::learntoption, 
+                &quot;The vector of variable modes observed from the train set.&quot;);
+
+  declareOption(ol, &quot;variable_present_count&quot;, &amp;MeanMedianModeImputationVMatrix::variable_present_count, OptionBase::learntoption, 
+                &quot;The vector of non missing variable counts from the train set.&quot;);
+
+  declareOption(ol, &quot;variable_missing_count&quot;, &amp;MeanMedianModeImputationVMatrix::variable_missing_count, OptionBase::learntoption, 
+                &quot;The vector of missing variable counts from the train set.&quot;);
+
+  declareOption(ol, &quot;variable_mode_count&quot;, &amp;MeanMedianModeImputationVMatrix::variable_mode_count, OptionBase::learntoption, 
+                &quot;The vector of variable mode counts from the train set.&quot;);
+
+  declareOption(ol, &quot;variable_imputation_instruction&quot;, &amp;MeanMedianModeImputationVMatrix::variable_imputation_instruction, OptionBase::learntoption, 
+                &quot;The vector of coded instruction for each variables.&quot;);
+
+  inherited::declareOptions(ol);
+}
+
+void MeanMedianModeImputationVMatrix::build()
+{
+  inherited::build();
+  build_();
+}
+
+void MeanMedianModeImputationVMatrix::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+  deepCopyField(source, copies);
+  deepCopyField(train_set, copies);
+  deepCopyField(number_of_train_samples_to_use, copies);
+  deepCopyField(imputation_spec, copies);
+  deepCopyField(variable_mean, copies);
+  deepCopyField(variable_median, copies);
+  deepCopyField(variable_mode, copies);
+  deepCopyField(variable_present_count, copies);
+  deepCopyField(variable_missing_count, copies);
+  deepCopyField(variable_imputation_instruction, copies);
+  inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+void MeanMedianModeImputationVMatrix::getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight)
+{
+  source-&gt;getExample(i, input, target, weight);
+  for (int source_col = 0; source_col &lt; input-&gt;length(); source_col++)
+  {
+    if (is_missing(input[source_col]) &amp;&amp; variable_imputation_instruction[source_col] &gt; 0)
+      if (variable_imputation_instruction[source_col] == 1) input[source_col] = variable_mean[source_col];
+      else if (variable_imputation_instruction[source_col] == 2) input[source_col] = variable_median[source_col];
+      else if (variable_imputation_instruction[source_col] == 3) input[source_col] = variable_mode[source_col];
+  }  
+}
+
+real MeanMedianModeImputationVMatrix::get(int i, int j) const
+{ 
+  real variable_value = source-&gt;get(i, j);
+  if (!is_missing(variable_value)) return variable_value;
+  if (variable_imputation_instruction[j] == 1) return variable_mean[j];
+  if (variable_imputation_instruction[j] == 2) return variable_median[j];
+  if (variable_imputation_instruction[j] == 3) return variable_mode[j];
+  return variable_value;
+}
+
+void MeanMedianModeImputationVMatrix::put(int i, int j, real value)
+{
+  PLERROR(&quot;In MeanMedianModeImputationVMatrix::put not implemented&quot;);
+}
+
+void MeanMedianModeImputationVMatrix::getSubRow(int i, int j, Vec v) const
+{  
+  source-&gt;getSubRow(i, j, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++) 
+    if (is_missing(v[source_col]) &amp;&amp; variable_imputation_instruction[source_col + j] &gt; 0)
+      if (variable_imputation_instruction[source_col + j] == 1) v[source_col] = variable_mean[source_col + j];
+      else if (variable_imputation_instruction[source_col + j] == 2) v[source_col] = variable_median[source_col + j];
+      else if (variable_imputation_instruction[source_col + j] == 3) v[source_col] = variable_mode[source_col + j];
+}
+
+void MeanMedianModeImputationVMatrix::putSubRow(int i, int j, Vec v)
+{
+  PLERROR(&quot;In MeanMedianModeImputationVMatrix::putSubRow not implemented&quot;);
+}
+
+void MeanMedianModeImputationVMatrix::appendRow(Vec v)
+{
+  PLERROR(&quot;In MeanMedianModeImputationVMatrix::appendRow not implemented&quot;);
+}
+
+void MeanMedianModeImputationVMatrix::insertRow(int i, Vec v)
+{
+  PLERROR(&quot;In MeanMedianModeImputationVMatrix::insertRow not implemented&quot;);
+}
+
+void MeanMedianModeImputationVMatrix::getRow(int i, Vec v) const
+{  
+  source-&gt; getRow(i, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++)
+    if (is_missing(v[source_col]) &amp;&amp; variable_imputation_instruction[source_col] &gt; 0)
+      if (variable_imputation_instruction[source_col] == 1) v[source_col] = variable_mean[source_col];
+      else if (variable_imputation_instruction[source_col] == 2) v[source_col] = variable_median[source_col];
+      else if (variable_imputation_instruction[source_col] == 3) v[source_col] = variable_mode[source_col]; 
+}
+
+void MeanMedianModeImputationVMatrix::putRow(int i, Vec v)
+{
+  PLERROR(&quot;In MeanMedianModeImputationVMatrix::putRow not implemented&quot;);
+}
+
+void MeanMedianModeImputationVMatrix::getColumn(int i, Vec v) const
+{  
+  source-&gt; getColumn(i, v);
+  for (int source_row = 0; source_row &lt; v-&gt;length(); source_row++)
+    if (is_missing(v[source_row]) &amp;&amp; variable_imputation_instruction[i] &gt; 0)
+      if (variable_imputation_instruction[i] == 1) v[source_row] = variable_mean[i];
+      else if (variable_imputation_instruction[i] == 2) v[source_row] = variable_median[i];
+      else if (variable_imputation_instruction[i] == 3) v[source_row] = variable_mode[i];
+}
+
+
+
+void MeanMedianModeImputationVMatrix::build_()
+{
+    if (!train_set || !source) PLERROR(&quot;In MeanMedianModeImputationVMatrix::train set and source vmat must be supplied&quot;);
+    train_length = train_set-&gt;length();
+    if (number_of_train_samples_to_use &gt; 0.0)
+        if (number_of_train_samples_to_use &lt; 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
+        else train_length = (int) number_of_train_samples_to_use;
+    if (train_length &gt; train_set-&gt;length()) train_length = train_set-&gt;length();
+    if(train_length &lt; 1) PLERROR(&quot;In MeanMedianModeImputationVMatrix::length of the number of train samples to use must be at least 1, got: %i&quot;, train_length);
+    train_width = train_set-&gt;width();
+    train_targetsize = train_set-&gt;targetsize();
+    train_weightsize = train_set-&gt;weightsize();
+    train_inputsize = train_set-&gt;inputsize();
+    if(train_inputsize &lt; 1) PLERROR(&quot;In MeanMedianModeImputationVMatrix::inputsize of the train vmat must be supplied, got : %i&quot;, train_inputsize);
+    source_width = source-&gt;width();
+    source_targetsize = source-&gt;targetsize();
+    source_weightsize = source-&gt;weightsize();
+    source_inputsize = source-&gt;inputsize();
+    if (train_width != source_width) PLERROR(&quot;In MeanMedianModeImputationVMatrix::train set and source width must agree, got : %i, %i&quot;, train_width, source_width);
+    if (train_targetsize != source_targetsize) PLERROR(&quot;In MeanMedianModeImputationVMatrix::train set and source targetsize must agree, got : %i, %i&quot;, train_targetsize, source_targetsize);
+    if (train_weightsize != source_weightsize) PLERROR(&quot;In MeanMedianModeImputationVMatrix::train set and source weightsize must agree, got : %i, %i&quot;, train_weightsize, source_weightsize);
+    if (train_inputsize != source_inputsize) PLERROR(&quot;In MeanMedianModeImputationVMatrix::train set and source inputsize must agree, got : %i, %i&quot;, train_inputsize, source_inputsize);
+    train_field_names.resize(train_width);
+    train_field_names = train_set-&gt;fieldNames();
+    source_length = source-&gt;length();
+    length_ = source_length;
+    width_ = source_width;
+    inputsize_ = source_inputsize;
+    targetsize_ = source_targetsize;
+    weightsize_ = source_weightsize;
+    declareFieldNames(train_field_names);
+    variable_mean.resize(train_width);
+    variable_median.resize(train_width);
+    variable_mode.resize(train_width);
+    variable_imputation_instruction.resize(train_width);
+    variable_imputation_instruction.clear();
+    for (spec_col = 0; spec_col &lt; imputation_spec.size(); spec_col++)
+    {
+        for (train_col = 0; train_col &lt; train_width; train_col++)
+        {
+            if (imputation_spec[spec_col].first == train_field_names[train_col]) break;
+        }
+        if (train_col &gt;= train_width) PLERROR(&quot;In MeanMedianModeImputationVMatrix: no field with this name in train data set: %s&quot;, (imputation_spec[spec_col].first).c_str());
+        if (imputation_spec[spec_col].second == &quot;mean&quot;) variable_imputation_instruction[train_col] = 1;
+        else if (imputation_spec[spec_col].second == &quot;median&quot;) variable_imputation_instruction[train_col] = 2;
+        else if (imputation_spec[spec_col].second == &quot;mode&quot;) variable_imputation_instruction[train_col] = 3;
+        else PLERROR(&quot;In MeanMedianModeImputationVMatrix: unsupported imputation instruction: %s : %s&quot;, (imputation_spec[spec_col].first).c_str(), (imputation_spec[spec_col].second).c_str());
+    }
+    train_metadata = train_set-&gt;getMetaDataDir();
+    mean_median_mode_file_name = train_metadata + &quot;mean_median_mode_file.pmat&quot;;
+    
+    if (!isfile(mean_median_mode_file_name))
+    {
+        computeMeanMedianModeVectors();
+        createMeanMedianModeFile();
+    }
+    else loadMeanMedianModeFile();
+}
+
+void MeanMedianModeImputationVMatrix::createMeanMedianModeFile()
+{
+    mean_median_mode_file = new FileVMatrix(mean_median_mode_file_name, 3, train_field_names);
+    mean_median_mode_file-&gt;putRow(0, variable_mean);
+    mean_median_mode_file-&gt;putRow(1, variable_median);
+    mean_median_mode_file-&gt;putRow(2, variable_mode);
+}
+
+void MeanMedianModeImputationVMatrix::loadMeanMedianModeFile()
+{
+    mean_median_mode_file = new FileVMatrix(mean_median_mode_file_name);
+    mean_median_mode_file-&gt;getRow(0, variable_mean);
+    mean_median_mode_file-&gt;getRow(1, variable_median);
+    mean_median_mode_file-&gt;getRow(2, variable_mode);
+}
+
+VMat MeanMedianModeImputationVMatrix::getMeanMedianModeFile()
+{
+    return mean_median_mode_file;
+}
+
+void MeanMedianModeImputationVMatrix::computeMeanMedianModeVectors()
+{
+    variable_present_count.resize(train_width);
+    variable_missing_count.resize(train_width);
+    variable_mode_count.resize(train_width);
+    variable_mean.clear();
+    variable_median.clear();
+    variable_mode.clear();
+    variable_present_count.clear();
+    variable_missing_count.clear();
+    variable_mode_count.clear();
+    variable_vec.resize(train_set-&gt;length());
+    cout &lt;&lt; fixed &lt;&lt; showpoint;
+    ProgressBar* pb = 0;
+    pb = new ProgressBar(&quot;Computing the mean, median and mode vectors&quot;, train_width);
+    for (train_col = 0; train_col &lt; train_width; train_col++)
+    {
+        current_value = 0.0;
+        current_value_count = 0;
+        train_set-&gt;getColumn(train_col, variable_vec);
+        sortColumn(variable_vec, 0, train_length);
+        for (train_row = 0; train_row &lt; train_length; train_row++)
+        {
+            if (is_missing(variable_vec[train_row]))
+            {
+                variable_missing_count[train_col] += 1;
+                continue;
+            }
+            variable_mean[train_col] += variable_vec[train_row];
+            variable_present_count[train_col] += 1;
+            if (variable_vec[train_row] != current_value)
+            {
+                if (current_value_count &gt; variable_mode_count[train_col])
+                {
+                    variable_mode[train_col] = current_value;
+                    variable_mode_count[train_col] = current_value_count;
+                }
+                current_value_count = 0;
+                current_value = variable_vec[train_row];
+            }
+            current_value_count += 1;
+        }
+        if (variable_present_count[train_col] &gt; 0)
+        {
+            variable_mean[train_col] = variable_mean[train_col] / variable_present_count[train_col];
+            variable_median[train_col] = variable_vec[(variable_present_count[train_col] / 2)];
+        }
+        if (current_value_count &gt; variable_mode_count[train_col])
+        {
+            variable_mode[train_col] = current_value;
+            variable_mode_count[train_col] = current_value_count;
+        }
+        pb-&gt;update( train_col );
+        /*
+        cout &lt;&lt; &quot;col: &quot;         &lt;&lt; setw(3)  &lt;&lt;                     train_col
+             &lt;&lt; &quot; present: &quot;    &lt;&lt; setw(5)  &lt;&lt;                     variable_present_count[train_col]
+             &lt;&lt; &quot; missing: &quot;    &lt;&lt; setw(5)  &lt;&lt;                     variable_missing_count[train_col]
+             &lt;&lt; &quot; mean: &quot;       &lt;&lt; setw(11) &lt;&lt; setprecision(2) &lt;&lt;  variable_mean[train_col]
+             &lt;&lt; &quot; median: &quot;     &lt;&lt; setw(11) &lt;&lt; setprecision(2) &lt;&lt;  variable_median[train_col]
+             &lt;&lt; &quot; mode count: &quot; &lt;&lt; setw(5)  &lt;&lt;                     variable_mode_count[train_col]
+             &lt;&lt; &quot; mode: &quot;       &lt;&lt; setw(11) &lt;&lt; setprecision(2) &lt;&lt;  variable_mode[train_col]
+             &lt;&lt; &quot; name: &quot;       &lt;&lt;                                 train_field_names[train_col]
+             &lt;&lt; endl;
+        */
+    }
+    delete pb;
+}
+
+void MeanMedianModeImputationVMatrix::sortColumn(Vec input_vec, int start, int end)
+{
+  int start_index = start;
+  int end_index = end - 1;
+  int forward_index;
+  int backward_index;
+  int stack_index = -1;
+  real pivot_value;
+  TVec&lt;int&gt; stack(50);
+  for (;;)
+  {
+    if ((end_index - start_index) &lt; 7)
+    {
+      if (end_index &gt; start_index)
+      {
+        sortSmallSubArray(input_vec, start_index, end_index);
+      }
+      if (stack_index &lt; 0)
+      {
+        break;
+      }
+      end_index = stack[stack_index--];
+      start_index = stack[stack_index--];
+    }
+    else
+    {
+      swapValues(input_vec, start_index + 1, (start_index + end_index) / 2);
+      if (compare(input_vec[start_index], input_vec[end_index]) &gt; 0.0) swapValues(input_vec, start_index, end_index);
+      if (compare(input_vec[start_index + 1], input_vec[end_index]) &gt; 0.0) swapValues(input_vec, start_index + 1, end_index);
+      if (compare(input_vec[start_index], input_vec[start_index + 1]) &gt; 0.0) swapValues(input_vec, start_index, start_index + 1);
+      forward_index = start_index + 1;
+      backward_index = end_index;
+      pivot_value = input_vec[start_index + 1];
+      for (;;)
+      {
+        do forward_index++; while (compare(input_vec[forward_index], pivot_value) &lt; 0.0);
+        do backward_index--; while (compare(input_vec[backward_index], pivot_value) &gt; 0.0);
+        if (backward_index &lt; forward_index)
+        {
+          break;
+        }
+        swapValues(input_vec, forward_index, backward_index);
+      }
+      swapValues(input_vec, start_index + 1, backward_index);
+      stack_index += 2;
+      if (stack_index &gt; 50)
+        PLERROR(&quot;RegressionTreeRegistersVMatrix: the stack for sorting the rows is too small&quot;);
+      if ((end_index - forward_index + 1) &gt;= (backward_index - start_index))
+      {
+        stack[stack_index] = end_index;
+        stack[stack_index - 1] = forward_index;
+        end_index = backward_index - 1;
+      }
+      else
+      {
+        stack[stack_index] = backward_index - 1;
+        stack[stack_index - 1] = start_index;
+        start_index = forward_index;
+      }
+    }
+  }
+}
+  
+void MeanMedianModeImputationVMatrix::sortSmallSubArray(Vec input_vec, int start_index, int end_index)
+{
+  int index_i;
+  int index_j;
+  for (index_i = start_index + 1; index_i &lt;= end_index; index_i++)
+  {
+    real saved_value = input_vec[index_i];
+    for (index_j = index_i - 1; index_j &gt;= start_index; index_j--)
+    {
+      if (compare(input_vec[index_j], saved_value) &lt;= 0.0)
+      {
+        break;
+      }
+      input_vec[index_j + 1] = input_vec[index_j];
+    }
+    input_vec[index_j + 1] = saved_value;
+  }  
+}
+
+void MeanMedianModeImputationVMatrix::swapValues(Vec input_vec, int index_i, int index_j)
+{
+  real saved_value = input_vec[index_i];
+  input_vec[index_i] = input_vec[index_j];
+  input_vec[index_j] = saved_value;
+}
+
+double MeanMedianModeImputationVMatrix::compare(double field1, double field2)
+{
+  if (is_missing(field1) &amp;&amp; is_missing(field2)) return 0.0;
+  if (is_missing(field1)) return +1.0;
+  if (is_missing(field2)) return -1.0;
+  return field1 - field2;
+}
+
+} // end of namespcae PLearn

Added: branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,161 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ******************************************************************      
+   * $Id: MeanMedianModeImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
+   ****************************************************************** */
+
+/*! \file PLearnLibrary/PLearnCore/VMat.h */
+
+#ifndef MeanMedianModeImputationVMatrix_INC
+#define MeanMedianModeImputationVMatrix_INC
+
+#include &lt;plearn/vmat/SourceVMatrix.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/io/fileutils.h&gt;                     //!&lt;  For isfile()
+#include &lt;plearn/math/BottomNI.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class MeanMedianModeImputationVMatrix: public VMatrix
+{
+  typedef VMatrix inherited;
+  
+public:
+
+  //! The source VMatrix with missing values.
+  VMat                          source;
+  
+  //! A referenced train set.
+  //! The mean, median or mode is computed with the observed values in this data set.
+  //! It is used in combination with the option number_of_train_samples_to_use.
+  VMat                          train_set;
+  
+  //! The number of samples from the train set that will be examined to compute the required statistic for each variable.
+  //! If equal to zero, all the samples from the train set are used to calculated the statistics.
+  //! If it is a fraction between 0 and 1, this proportion of the samples are used.
+  //! If greater or equal to 1, the integer portion is interpreted as the number of samples to use.
+  real                          number_of_train_samples_to_use;
+  
+  //! Pairs of instruction of the form field_name : mean | median | mode.
+  TVec&lt; pair&lt;string, string&gt; &gt;  imputation_spec;
+  
+  //! The vector of variable means observed from the train set.
+  Vec                           variable_mean;
+  
+  //! The vector of variable medians observed from the train set.
+  Vec                           variable_median;
+  
+  //! The vector of variable modes observed from the train set.
+  Vec                           variable_mode;
+  
+  //! The vector of non missing variable counts from the train set.
+  TVec&lt;int&gt;                     variable_present_count;
+  
+  //! The vector of missing variable counts from the train set.
+  TVec&lt;int&gt;                     variable_missing_count;
+  
+  //! The vector of variable mode counts from the train set.
+  TVec&lt;int&gt;                     variable_mode_count;
+  
+  //! The vector of coded instruction for each variables.
+  TVec&lt;int&gt;                     variable_imputation_instruction;
+  
+  //! Pairs of instruction of the form field_name : mean | median | mode.
+  
+
+                        MeanMedianModeImputationVMatrix();
+  virtual               ~MeanMedianModeImputationVMatrix();
+
+  static void           declareOptions(OptionList &amp;ol);
+
+  virtual void          build();
+  virtual void          makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+  virtual void         getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight);
+  virtual real         get(int i, int j) const;
+  virtual void         put(int i, int j, real value);
+  virtual void         getSubRow(int i, int j, Vec v) const;
+  virtual void         putSubRow(int i, int j, Vec v);
+  virtual void         appendRow(Vec v);
+  virtual void         insertRow(int i, Vec v);  
+  virtual void         getRow(int i, Vec v) const;
+  virtual void         putRow(int i, Vec v);
+  virtual void         getColumn(int i, Vec v) const;
+          VMat         getMeanMedianModeFile();
+
+private:
+  
+  int                  train_length;
+  int                  train_width;
+  int                  train_inputsize;
+  int                  train_targetsize;
+  int                  train_weightsize;
+  int                  train_row;
+  int                  train_col;
+  TVec&lt;string&gt;         train_field_names;
+  PPath                train_metadata;
+  int                  source_length;
+  int                  source_width;
+  int                  source_inputsize;
+  int                  source_targetsize;
+  int                  source_weightsize;
+  Vec                  variable_vec;
+  int                  spec_col;
+  int                  current_value_count;
+  real                 current_value;
+  PPath                mean_median_mode_file_name;
+  VMat                 mean_median_mode_file;
+
+          void         build_();
+          void         createMeanMedianModeFile(); 
+          void         loadMeanMedianModeFile(); 
+          void         computeMeanMedianModeVectors();  
+          void         sortColumn(Vec input_vec, int start, int end);
+          void         sortSmallSubArray(Vec input_vec, int start_index, int end_index);
+          void         swapValues(Vec input_vec, int index_i, int index_j);
+          real         compare(real field1, real field2);
+  
+  PLEARN_DECLARE_OBJECT(MeanMedianModeImputationVMatrix);
+
+};
+
+DECLARE_OBJECT_PTR(MeanMedianModeImputationVMatrix);
+
+} // end of namespcae PLearn
+#endif

Added: branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,490 @@
+// -*- C++ -*-
+
+// MergeDond2Files.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file MergeDond2Files.cc */
+
+#define PL_LOG_MODULE_NAME &quot;MergeDond2Files&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;MergeDond2Files.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    MergeDond2Files,
+    &quot;Merge two files on specified keys.&quot;,
+    &quot;If more than 1 matching record is found in the secondary datatset,\n&quot;
+    &quot;mean, mode or variable presence will be appended based on variable merge instruction.\n&quot;
+    &quot;a variable from the secondary dataset may also be skipped.\n&quot;
+);
+
+/////////////////////////
+// MergeDond2Files //
+/////////////////////////
+MergeDond2Files::MergeDond2Files()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void MergeDond2Files::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;external_dataset&quot;, &amp;MergeDond2Files::external_dataset,
+                  OptionBase::buildoption,
+                  &quot;The secondary dataset to merge with the main one.\n&quot;
+                  &quot;The main one is provided as the train_set.&quot;);
+
+    declareOption(ol, &quot;missing_instructions&quot;, &amp;MergeDond2Files::missing_instructions,
+                  OptionBase::buildoption,
+                  &quot;The variable missing regeneration instructions in the form of pairs field : instruction.\n&quot;
+                  &quot;Supported instructions are skip, as_is, zero_is_missing, 2436935_is_missing, present.&quot;);
+
+    declareOption(ol, &quot;merge_instructions&quot;, &amp;MergeDond2Files::merge_instructions,
+                  OptionBase::buildoption,
+                  &quot;The variable merge instructions in the form of pairs field : instruction.\n&quot;
+                  &quot;Supported instructions are skip, mean, mode, present.&quot;);
+
+    declareOption(ol, &quot;merge_path&quot;, &amp;MergeDond2Files::merge_path,
+                  OptionBase::buildoption,
+                  &quot;The root name of merge files to be created.\n&quot;
+                  &quot;3 files will be created: a root_train.pmat, a root_test.pmat and a root_uknown.pmat&quot;);
+
+    declareOption(ol, &quot;sec_key&quot;, &amp;MergeDond2Files::sec_key,
+                  OptionBase::buildoption,
+                  &quot;The column of the merge key in the secondary dataset.&quot;);
+
+    declareOption(ol, &quot;main_key&quot;, &amp;MergeDond2Files::main_key,
+                  OptionBase::buildoption,
+                  &quot;The column of the merge key in the main dataset.&quot;);
+
+    declareOption(ol, &quot;train_ind&quot;, &amp;MergeDond2Files::train_ind,
+                  OptionBase::buildoption,
+                  &quot;The column of the indicator of a train record in the main dataset.&quot;);
+
+    declareOption(ol, &quot;test_ind&quot;, &amp;MergeDond2Files::test_ind,
+                  OptionBase::buildoption,
+                  &quot;The column of the indicator of a test record in the main dataset.&quot;);
+
+    declareOption(ol, &quot;train_file&quot;, &amp;MergeDond2Files::train_file,
+                  OptionBase::learntoption,
+                  &quot;The train file created.&quot;);
+
+    declareOption(ol, &quot;test_file&quot;, &amp;MergeDond2Files::test_file,
+                  OptionBase::learntoption,
+                  &quot;The test file created.&quot;);
+
+    declareOption(ol, &quot;unknown_file&quot;, &amp;MergeDond2Files::unknown_file,
+                  OptionBase::learntoption,
+                  &quot;The unknown target file created.&quot;);
+
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void MergeDond2Files::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(external_dataset, copies);
+    deepCopyField(missing_instructions, copies);
+    deepCopyField(merge_instructions, copies);
+    deepCopyField(merge_path, copies);
+    deepCopyField(sec_key, copies);
+    deepCopyField(main_key, copies);
+    deepCopyField(train_ind, copies);
+    deepCopyField(test_ind, copies);
+    deepCopyField(train_file, copies);
+    deepCopyField(test_file, copies);
+    deepCopyField(unknown_file, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void MergeDond2Files::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void MergeDond2Files::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        mergeFiles();
+        PLERROR(&quot;MergeDond2Files: we are done here&quot;);
+    }
+}
+
+void MergeDond2Files::mergeFiles()
+{
+    // initialization with merge instructions
+    sec_row = 0;
+    sec_col = 0;
+    sec_length = external_dataset-&gt;length();
+    sec_width = external_dataset-&gt;width();
+    sec_names.resize(sec_width);
+    sec_ins.resize(sec_width);
+    sec_input.resize(sec_width);
+    ins_col = 0;
+    extension_width = 0;
+    sec_names &lt;&lt; external_dataset-&gt;fieldNames();
+    for (sec_col = 0; sec_col &lt; sec_width; sec_col++)
+    {
+        sec_ins[sec_col] = &quot;mean&quot;;
+    }
+    for (ins_col = 0; ins_col &lt; merge_instructions.size(); ins_col++)
+    {
+        for (sec_col = 0; sec_col &lt; sec_width; sec_col++)
+        {
+            if (merge_instructions[ins_col].first == sec_names[sec_col]) break;
+        }
+        if (sec_col &gt;= sec_width) PLERROR(&quot;In MergeDond2Files: no field with this name in external_dataset data set: %&quot;, (merge_instructions[ins_col].first).c_str());
+        if (merge_instructions[ins_col].second == &quot;skip&quot;) sec_ins[sec_col] = &quot;skip&quot;;
+        else if (merge_instructions[ins_col].second == &quot;mean&quot;) sec_ins[sec_col] = &quot;mean&quot;;
+        else if (merge_instructions[ins_col].second == &quot;mode&quot;) sec_ins[sec_col] = &quot;mode&quot;;
+        else if (merge_instructions[ins_col].second == &quot;present&quot;) sec_ins[sec_col] = &quot;present&quot;;
+        else PLERROR(&quot;In MergeDond2Files: unsupported merge instruction: %&quot;, (merge_instructions[ins_col].second).c_str());
+        if (sec_ins[sec_col] != &quot;skip&quot;) extension_width += 1;
+    }
+    ext_col = 0;
+    extension_pos.resize(sec_width);
+    extension_names.resize(extension_width);
+    for (sec_col = 0; sec_col &lt; sec_width; sec_col++)
+    {
+        if (sec_ins[sec_col] == &quot;skip&quot;)
+        {
+            extension_pos[sec_col] = -1; 
+        }
+        else
+        {
+            extension_pos[sec_col] = ext_col;
+            extension_names[ext_col] = sec_names[sec_col];
+            ext_col += 1;
+        }
+    }
+    sec_values.resize(extension_width, 10);
+    sec_value_cnt.resize(extension_width, 10);
+    sec_value_ind.resize(extension_width);
+    sec_values.clear();
+    sec_value_cnt.clear();
+    sec_value_ind.clear();
+    external_dataset-&gt;getRow(sec_row, sec_input);
+    
+    // initialize primary dataset
+    main_row = 0;
+    main_col = 0;
+    main_length = train_set-&gt;length();
+    main_width = train_set-&gt;width();
+    main_input.resize(main_width);
+    main_names.resize(main_width);
+    main_ins.resize(main_width);
+    main_names &lt;&lt; train_set-&gt;fieldNames();
+    primary_width = 0;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        main_ins[main_col] = &quot;as_is&quot;;
+    }
+    for (ins_col = 0; ins_col &lt; missing_instructions.size(); ins_col++)
+    {
+        for (main_col = 0; main_col &lt; main_width; main_col++)
+        {
+            if (missing_instructions[ins_col].first == main_names[main_col]) break;
+        }
+        if (main_col &gt;= main_width) PLERROR(&quot;In MergeDond2Files: no field with this name in external_dataset data set: %&quot;, (missing_instructions[ins_col].first).c_str());
+        if (missing_instructions[ins_col].second == &quot;skip&quot;) main_ins[main_col] = &quot;skip&quot;;
+        else if (missing_instructions[ins_col].second == &quot;as_is&quot;) main_ins[main_col] = &quot;as_is&quot;;
+        else if (missing_instructions[ins_col].second == &quot;zero_is_missing&quot;) main_ins[main_col] = &quot;zero_is_missing&quot;;
+        else if (missing_instructions[ins_col].second == &quot;2436935_is_missing&quot;) main_ins[main_col] = &quot;2436935_is_missing&quot;;
+        else if (missing_instructions[ins_col].second == &quot;present&quot;) main_ins[main_col] = &quot;present&quot;;
+        else PLERROR(&quot;In MergeDond2Files: unsupported merge instruction: %&quot;, (missing_instructions[ins_col].second).c_str());
+        if (main_ins[main_col] != &quot;skip&quot;) primary_width += 1;
+    }
+    prim_col = 0;
+    primary_names.resize(primary_width);
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (main_ins[main_col] != &quot;skip&quot;)
+        {
+            primary_names[prim_col] = main_names[main_col];
+            prim_col += 1;
+        }
+    }
+    
+    // initialize output datasets
+    merge_col = 0;
+    merge_width = primary_width + extension_width;
+    merge_output.resize(merge_width);
+    merge_names.resize(merge_width);
+    for (prim_col = 0; prim_col &lt; primary_width; prim_col++)
+    {
+       merge_names[merge_col] = primary_names[prim_col];
+       merge_col +=1;
+    }
+    for (ext_col = 0; ext_col &lt; extension_width; ext_col++)
+    {
+       merge_names[merge_col] = extension_names[ext_col];
+       merge_col +=1;
+    }
+    train_length = 0;
+    test_length = 0;
+    unknown_length = 0;
+    ProgressBar* pb = 0;
+    pb = new ProgressBar( &quot;Counting the number of records in the train, test and unknown datasets&quot;, main_length);
+    for (main_row = 0; main_row &lt; main_length; main_row++)
+    {
+        train_set-&gt;getRow(main_row, main_input);
+        if (main_input[train_ind] &gt; 0.0) train_length += 1;
+        else if (main_input[test_ind] &gt; 0.0) test_length += 1;
+        else unknown_length += 1;
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+    train_file = new FileVMatrix(merge_path + &quot;_train.pmat&quot;, train_length, merge_width);
+    test_file = new FileVMatrix(merge_path + &quot;_test.pmat&quot;, test_length, merge_width);
+    unknown_file = new FileVMatrix(merge_path + &quot;_unknown.pmat&quot;, unknown_length, merge_width);
+    train_file-&gt;declareFieldNames(merge_names);
+    test_file-&gt;declareFieldNames(merge_names);
+    unknown_file-&gt;declareFieldNames(merge_names);
+    train_row = 0;
+    test_row = 0;
+    unknown_row = 0;
+    
+    //Now, we can merge
+    pb = new ProgressBar( &quot;Merging primary and secondary datasets with instructions&quot;, main_length);
+    for (main_row = 0; main_row &lt; main_length; main_row++)
+    {
+        train_set-&gt;getRow(main_row, main_input);
+        if (sec_row &gt;= sec_length)
+        {
+            combineAndPut();
+            continue;
+        }
+        while (sec_input[sec_key] &lt; main_input[main_key])
+        {
+            sec_row += 1;
+            if (sec_row &gt;= sec_length) break;   
+            external_dataset-&gt;getRow(sec_row, sec_input);
+        }
+        while (sec_input[sec_key] == main_input[main_key])
+        {
+            accumulateVec();
+            sec_row += 1;
+            if (sec_row &gt;= sec_length) break;   
+            external_dataset-&gt;getRow(sec_row, sec_input);
+        }
+        combineAndPut();
+        pb-&gt;update( main_row );
+    }
+    delete pb;
+}
+
+void MergeDond2Files::accumulateVec()
+{
+    for (sec_col = 0; sec_col &lt; sec_width; sec_col++)
+    {
+        if (is_missing(sec_input[sec_col])) continue;
+        if (sec_ins[sec_col] == &quot;skip&quot;) continue;
+        ext_col = extension_pos[sec_col];
+        if (sec_ins[sec_col] == &quot;mean&quot;)
+        {
+            sec_values(ext_col, 0) += sec_input[sec_col];
+            sec_value_cnt(ext_col, 0) += 1.0;
+        }
+        if (sec_ins[sec_col] == &quot;mode&quot;)
+        {
+            sec_value_found = false;
+            for (sec_value_col = 0; sec_value_col &lt; sec_value_ind[sec_col]; sec_value_col++)
+            {
+                if (sec_values(ext_col, sec_value_col) == sec_input[sec_col])
+                {
+                    sec_value_found = true;
+                    sec_value_cnt(ext_col, sec_value_col) += 1;
+                    break;
+                }
+            }
+            if (!sec_value_found)
+            {
+                if (sec_value_ind[sec_col] &gt;= 10)
+                {
+                    cout &lt;&lt; &quot;MergeDond2Files: main file row: &quot; &lt;&lt; main_row &lt;&lt; &quot; external file row: &quot; &lt;&lt; sec_row &lt;&lt; endl;
+                    PLERROR(&quot;MergeDond2Files: we have exceeded the capacity of the value MAT.&quot;);
+                }
+                sec_values(ext_col, sec_value_ind[sec_col]) = sec_input[sec_col];
+                sec_value_ind[sec_col] += 1;
+            }
+        }
+        if (sec_ins[sec_col] == &quot;present&quot;)
+        {
+            sec_value_cnt(ext_col, 0) = 1.0;
+        }
+    }
+}
+
+void MergeDond2Files::combineAndPut()
+{
+    merge_col = 0;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (main_ins[main_col] == &quot;skip&quot;) continue;
+        if (main_ins[main_col] == &quot;as_is&quot;)
+        {
+            merge_output[merge_col] = main_input[main_col];
+            merge_col +=1;
+            continue;
+        }
+        if (main_ins[main_col] == &quot;zero_is_missing&quot;)
+        {
+            if (main_input[main_col] == 0.0) merge_output[merge_col] = MISSING_VALUE;
+            else merge_output[merge_col] = main_input[main_col];
+            merge_col +=1;
+            continue;
+        }
+        if (main_ins[main_col] == &quot;2436935_is_missing&quot;)
+        {
+            if (main_input[main_col] == 2436935.0) merge_output[merge_col] = MISSING_VALUE;
+            else merge_output[merge_col] = main_input[main_col];
+            merge_col +=1;
+            continue;
+        }
+        if (main_ins[main_col] == &quot;present&quot;)
+        {
+            if (is_missing(main_input[main_col])) merge_output[merge_col] = 0.0;
+            else merge_output[merge_col] = 1.0;
+            merge_col +=1;
+            continue;
+        }
+    }
+    for (sec_col = 0; sec_col &lt; sec_width; sec_col++)
+    {
+        if (sec_ins[sec_col] == &quot;skip&quot;) continue;
+        ext_col = extension_pos[sec_col];
+        if (sec_ins[sec_col] == &quot;mean&quot;)
+        {
+            if (sec_value_cnt(ext_col, 0) &lt;= 0.0)  merge_output[merge_col] = MISSING_VALUE;
+            else merge_output[merge_col] = sec_values(ext_col, 0) / sec_value_cnt(ext_col, 0);
+            merge_col +=1;
+            continue;
+        }
+        if (sec_ins[sec_col] == &quot;mode&quot;)
+        {
+            if (sec_value_ind[sec_col] &lt;= 0.0)
+            {
+                merge_output[merge_col] = MISSING_VALUE;
+                merge_col +=1;
+                continue;
+            }
+            merge_output[merge_col] = sec_values(ext_col, 0);
+            sec_value_count_max = sec_value_cnt(ext_col, 0);
+            for (sec_value_col = 1; sec_value_col &lt; sec_value_ind[sec_col]; sec_value_col++)
+            {
+                if (sec_value_cnt(ext_col, sec_value_col) &gt;= sec_value_count_max)
+                {
+                    merge_output[merge_col] = sec_values(ext_col, sec_value_col);
+                    sec_value_count_max = sec_value_cnt(ext_col, sec_value_col);
+                }
+            }
+            merge_col +=1;
+            continue;
+        }
+        if (sec_ins[sec_col] == &quot;present&quot;)
+        {
+            merge_output[merge_col] = sec_value_cnt(ext_col, 0);
+            merge_col +=1;
+            continue;
+        }
+    }
+    if (main_input[train_ind] &gt; 0.0)
+    {
+        train_file-&gt;putRow(train_row, merge_output);
+        train_row += 1;
+    }
+    else if (main_input[test_ind] &gt; 0.0)
+    {
+        test_file-&gt;putRow(test_row, merge_output);
+        test_row += 1;
+    }
+    else
+    {
+        unknown_file-&gt;putRow(unknown_row, merge_output);
+        unknown_row += 1;
+    }
+    sec_values.clear();
+    sec_value_cnt.clear();
+    sec_value_ind.clear();
+}
+
+int MergeDond2Files::outputsize() const {return 0;}
+void MergeDond2Files::train() {}
+void MergeDond2Files::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void MergeDond2Files::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; MergeDond2Files::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; MergeDond2Files::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MergeDond2Files.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,210 @@
+// -*- C++ -*-
+
+// MergeDond2Files.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file MergeDond2Files.h */
+
+
+#ifndef MergeDond2Files_INC
+#define MergeDond2Files_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class MergeDond2Files : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    
+    //! The secondary dataset to merge with the main one.
+    //! The main one is provided as the train_set.
+    VMat external_dataset;
+
+    //! The variable missing regeneration instructions in the form of pairs field : instruction.
+    //! Supported instructions are skip, as_is, zero_is_missing, 2436935_is_missing.
+    TVec&lt; pair&lt;string, string&gt; &gt;  missing_instructions;
+    
+    //! The variable merge instructions in the form of pairs field : instruction.
+    //! Supported instructions are skip, mean, mode, present.
+    TVec&lt; pair&lt;string, string&gt; &gt;  merge_instructions;
+    
+    //! The file name of the merge file to be created.
+    string merge_path;
+    
+    //! The column of the merge key in the secondary dataset.
+    int sec_key;
+    
+    //! The column of the merge key in the main dataset.
+    int main_key;
+    
+    //! The column of the indicator of a train record in the main dataset.
+    int train_ind;
+    
+    //! The column of the indicator of a test record in the main dataset.
+    int test_ind;
+    
+    //! The train file created.
+    VMat train_file;
+    
+    //! The test file created.
+    VMat test_file;
+    
+    //! The unknown target file created.
+    VMat unknown_file;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    MergeDond2Files();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(MergeDond2Files);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void mergeFiles();
+    void accumulateVec();
+    void combineAndPut();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    // secondary dataset variables
+    int sec_length;
+    int sec_width;
+    int sec_row;
+    int sec_col;
+    Vec sec_input;
+    TVec&lt;string&gt; sec_names;
+    TVec&lt;string&gt; sec_ins;
+    int ins_col;
+    int extension_width;
+    int ext_col;
+    TVec&lt;int&gt; extension_pos;
+    TVec&lt;string&gt; extension_names;
+    Mat sec_values;
+    Mat sec_value_cnt;
+    TVec&lt;int&gt; sec_value_ind;
+    bool sec_value_found;
+    real sec_value_count_max;
+    int sec_value_col;
+    
+    // primary dataset variables
+    int main_length;
+    int main_width;
+    int main_row;
+    int main_col;
+    Vec main_input;
+    TVec&lt;string&gt; main_names;
+    TVec&lt;string&gt; main_ins;
+    int primary_width;
+    int prim_col;
+    TVec&lt;string&gt; primary_names;
+    
+    // merge dataset variables
+    int train_length;
+    int test_length;
+    int unknown_length;
+    int merge_width;
+    int train_row;
+    int test_row;
+    int unknown_row;
+    int merge_col;
+    Vec merge_output;
+    TVec&lt;string&gt; merge_names;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(MergeDond2Files);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,257 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************************    
+   * $Id: MissingIndicatorVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
+   ******************************************************************* */
+
+
+#include &quot;MissingIndicatorVMatrix.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+/** MissingIndicatorVMatrix **/
+
+PLEARN_IMPLEMENT_OBJECT(
+  MissingIndicatorVMatrix,
+  &quot;VMat class to add a missing indicator for each variable.&quot;,
+  &quot;For each variable with a missing value in the referenced train set, an indicator is added.\n&quot;
+  &quot;It is set to 1 if the value of the corresponding variable`in the underlying dataset is missing.\n&quot;
+  &quot;It is set to 0 otherwise.\n&quot;
+  );
+
+MissingIndicatorVMatrix::MissingIndicatorVMatrix()
+: number_of_train_samples_to_use(0.0)
+{
+}
+
+MissingIndicatorVMatrix::MissingIndicatorVMatrix(VMat the_source, VMat the_train_set, real the_number_of_train_samples_to_use)
+{
+  source = the_source;
+  train_set = the_train_set;
+  number_of_train_samples_to_use = the_number_of_train_samples_to_use;
+}
+
+MissingIndicatorVMatrix::~MissingIndicatorVMatrix()
+{
+}
+
+void MissingIndicatorVMatrix::declareOptions(OptionList &amp;ol)
+{
+  declareOption(ol, &quot;source&quot;, &amp;MissingIndicatorVMatrix::source, OptionBase::buildoption, 
+                &quot;The source VMatrix with missing values.\n&quot;);
+
+  declareOption(ol, &quot;train_set&quot;, &amp;MissingIndicatorVMatrix::train_set, OptionBase::buildoption, 
+                &quot;A referenced train set.\n&quot;
+                &quot;A missing indicator is added for variables with missing values in this data set.\n&quot;
+                &quot;It is used in combination with the option number_of_train_samples_to_use\n&quot;);
+
+  declareOption(ol, &quot;number_of_train_samples_to_use&quot;, &amp;MissingIndicatorVMatrix::number_of_train_samples_to_use, OptionBase::buildoption, 
+                &quot;The number of samples from the train set that will be examined to see\n&quot;
+                &quot;if an indicator should be added for each variable\n&quot;);
+
+  inherited::declareOptions(ol);
+}
+
+void MissingIndicatorVMatrix::build()
+{
+  inherited::build();
+  build_();
+}
+
+void MissingIndicatorVMatrix::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+  deepCopyField(source, copies);
+  deepCopyField(train_set, copies);
+  deepCopyField(number_of_train_samples_to_use, copies);
+  inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+void MissingIndicatorVMatrix::getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight)
+{
+    source-&gt;getExample(i, source_input, target, weight);
+    new_col = 0;
+    for (int source_col = 0; source_col &lt; source_inputsize; source_col++)
+    {
+      input[new_col] = source_input[source_col];
+      new_col += 1;
+      if (train_var_missing[source_col] &gt; 0)
+      {
+          if (is_missing(source_input[source_col])) input[new_col] = 1.0;
+          else input[new_col] = 0.0;
+          new_col += 1;
+      }
+    }
+}
+
+real MissingIndicatorVMatrix::get(int i, int j) const
+{
+  if (source_rel_pos[j] &lt; 0)
+  {
+    if (is_missing(source-&gt;get(i, source_rel_pos[j - 1]))) return 1.0;
+    else return 0.0;
+  }
+  return source-&gt;get(i, source_rel_pos[j]);
+}
+
+void MissingIndicatorVMatrix::put(int i, int j, real value)
+{
+  PLERROR(&quot;In MissingIndicatorVMatrix::put not implemented&quot;);
+}
+
+void MissingIndicatorVMatrix::getSubRow(int i, int j, Vec v) const
+{  
+  for (int source_col = j; source_col &lt; j + v.length(); source_col++) v[source_col] = get(i, source_col);
+}
+
+void MissingIndicatorVMatrix::putSubRow(int i, int j, Vec v)
+{
+  PLERROR(&quot;In MissingIndicatorVMatrix::putSubRow not implemented&quot;);
+}
+
+void MissingIndicatorVMatrix::appendRow(Vec v)
+{
+  PLERROR(&quot;In MissingIndicatorVMatrix::appendRow not implemented&quot;);
+}
+
+void MissingIndicatorVMatrix::insertRow(int i, Vec v)
+{
+  PLERROR(&quot;In MissingIndicatorVMatrix::insertRow not implemented&quot;);
+}
+
+void MissingIndicatorVMatrix::getRow(int i, Vec v) const
+{  
+  for (int source_col = 0; source_col &lt; width_; source_col++) v[source_col] = get(i, source_col); 
+}
+
+void MissingIndicatorVMatrix::putRow(int i, Vec v)
+{
+  PLERROR(&quot;In MissingIndicatorVMatrix::putRow not implemented&quot;);
+}
+
+void MissingIndicatorVMatrix::getColumn(int i, Vec v) const
+{
+  if (source_rel_pos[i] &lt; 0) source-&gt;getColumn(source_rel_pos[i - 1], v);
+  else source-&gt;getColumn(source_rel_pos[i], v);
+  if (source_rel_pos[i] &gt;= 0) return;
+  for (int source_row = 0; source_row &lt; v-&gt;length(); source_row++)
+  {
+    if (is_missing(v[source_row])) v[source_row] = 1.0;
+    else v[source_row] = 0.0;
+  } 
+}
+
+void MissingIndicatorVMatrix::build_()
+{
+    if (!train_set || !source) PLERROR(&quot;In MissingIndicatorVMatrix::train set and source vmat must be supplied&quot;);
+    buildNewRecordFormat(); 
+}
+
+void MissingIndicatorVMatrix::buildNewRecordFormat()
+{
+    train_length = train_set-&gt;length();
+    if (number_of_train_samples_to_use &gt; 0.0)
+        if (number_of_train_samples_to_use &lt; 1.0) train_length = (int) (number_of_train_samples_to_use * (real) train_length);
+        else train_length = (int) number_of_train_samples_to_use;
+    if (train_length &gt; train_set-&gt;length()) train_length = train_set-&gt;length();
+    if(train_length &lt; 1) PLERROR(&quot;In MissingIndicatorVMatrix::length of the number of train samples to use must be at least 1, got: %i&quot;, train_length);
+    train_width = train_set-&gt;width();
+    train_targetsize = train_set-&gt;targetsize();
+    train_weightsize = train_set-&gt;weightsize();
+    train_inputsize = train_set-&gt;inputsize();
+    if(train_inputsize &lt; 1) PLERROR(&quot;In MissingIndicatorVMatrix::inputsize of the train vmat must be supplied, got : %i&quot;, train_inputsize);
+    source_width = source-&gt;width();
+    source_targetsize = source-&gt;targetsize();
+    source_weightsize = source-&gt;weightsize();
+    source_inputsize = source-&gt;inputsize();
+    if (train_width != source_width) PLERROR(&quot;In MissingIndicatorVMatrix::train set and source width must agree, got : %i, %i&quot;, train_width, source_width);
+    if (train_targetsize != source_targetsize) PLERROR(&quot;In MissingIndicatorVMatrix::train set and source targetsize must agree, got : %i, %i&quot;, train_targetsize, source_targetsize);
+    if (train_weightsize != source_weightsize) PLERROR(&quot;In MissingIndicatorVMatrix::train set and source weightsize must agree, got : %i, %i&quot;, train_weightsize, source_weightsize);
+    if (train_inputsize != source_inputsize) PLERROR(&quot;In MissingIndicatorVMatrix::train set and source inputsize must agree, got : %i, %i&quot;, train_inputsize, source_inputsize);
+    train_input.resize(train_width);
+    train_var_missing.resize(train_inputsize);
+    train_var_missing.clear();
+    for (train_row = 0; train_row &lt; train_length; train_row++)
+    {
+        train_set-&gt;getRow(train_row, train_input);
+        for (train_col = 0; train_col &lt; train_inputsize; train_col++)
+        {
+            if (is_missing(train_input[train_col])) train_var_missing[train_col] = 1;
+        }
+    }
+    new_width = train_width;
+    new_inputsize = train_inputsize;
+    for (train_col = 0; train_col &lt; train_inputsize; train_col++)
+    {
+        new_width += train_var_missing[train_col];
+        new_inputsize += train_var_missing[train_col];
+    }
+    train_field_names.resize(train_width);
+    source_rel_pos.resize(new_width);
+    new_field_names.resize(new_width);
+    train_field_names = train_set-&gt;fieldNames();
+    new_col = 0;
+    for (train_col = 0; train_col &lt; train_inputsize; train_col++)
+    {
+      new_field_names[new_col] = train_field_names[train_col];
+      source_rel_pos[new_col] = train_col;
+      new_col += 1;
+      if (train_var_missing[train_col] &gt; 0)
+      {
+          new_field_names[new_col] = train_field_names[train_col] + &quot;_MI&quot;;
+          source_rel_pos[new_col] = -1;
+          new_col += 1;
+      }
+    }
+    for (train_col = train_inputsize; train_col &lt; train_width; train_col++)
+    {
+      new_field_names[new_col] = train_field_names[train_col];
+      source_rel_pos[new_col] = train_col;
+      new_col += 1;
+    }
+    source_length = source-&gt;length();
+    length_ = source_length;
+    width_ = new_width;
+    inputsize_ = new_inputsize;
+    targetsize_ = source_targetsize;
+    weightsize_ = train_weightsize;
+    source_input.resize(source_inputsize);
+    declareFieldNames(new_field_names);
+}
+
+} // end of namespcae PLearn

Added: branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/MissingIndicatorVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,126 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ******************************************************************      
+   * $Id: MissingIndicatorVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
+   ****************************************************************** */
+
+/*! \file PLearnLibrary/PLearnCore/VMat.h */
+
+#ifndef MissingIndicatorVMatrix_INC
+#define MissingIndicatorVMatrix_INC
+
+#include &lt;plearn/vmat/SourceVMatrix.h&gt;
+#include &lt;plearn/math/BottomNI.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class MissingIndicatorVMatrix: public VMatrix
+{
+  typedef VMatrix inherited;
+  
+public:
+
+  //! The source VMatrix with missing values.
+  VMat         source;
+  
+  //! A referenced train set.
+  //! A missing indicator is added for variables with missing values in this data set.
+  //! It is used in combination with the option number_of_train_samples_to_use.
+  VMat         train_set;
+  
+  //! The number of samples from the train set that will be examined to see
+  //! if an indicator should be added for each variable.
+  real         number_of_train_samples_to_use;
+  
+
+                        MissingIndicatorVMatrix();
+                        MissingIndicatorVMatrix(VMat the_source, VMat the_train_set, real the_number_of_train_samples_to_use);
+  virtual               ~MissingIndicatorVMatrix();
+
+  static void           declareOptions(OptionList &amp;ol);
+
+  virtual void          build();
+  virtual void          makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+  virtual void         getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight);
+  virtual real         get(int i, int j) const;
+  virtual void         put(int i, int j, real value);
+  virtual void         getSubRow(int i, int j, Vec v) const;
+  virtual void         putSubRow(int i, int j, Vec v);
+  virtual void         appendRow(Vec v);
+  virtual void         insertRow(int i, Vec v);  
+  virtual void         getRow(int i, Vec v) const;
+  virtual void         putRow(int i, Vec v);
+  virtual void         getColumn(int i, Vec v) const;
+
+private:
+  
+  int          train_length;
+  int          train_width;
+  int          train_inputsize;
+  int          train_targetsize;
+  int          train_weightsize;
+  int          train_row;
+  int          train_col;
+  Vec          train_input;
+  TVec&lt;string&gt; train_field_names;
+  TVec&lt;int&gt;    train_var_missing;
+  int          source_length;
+  int          source_width;
+  int          source_inputsize;
+  int          source_targetsize;
+  int          source_weightsize;
+  Vec          source_input;
+  TVec&lt;int&gt;    source_rel_pos;
+  int          new_width;
+  int          new_inputsize;
+  int          new_col;
+  TVec&lt;string&gt; new_field_names;
+
+          void         build_();
+          void         buildNewRecordFormat();
+  
+  PLEARN_DECLARE_OBJECT(MissingIndicatorVMatrix);
+
+};
+
+DECLARE_OBJECT_PTR(MissingIndicatorVMatrix);
+
+} // end of namespcae PLearn
+#endif

Added: branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,540 @@
+// -*- C++ -*-
+
+// NeighborhoodConditionalMean.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file NeighborhoodConditionalMean.cc */
+
+#define PL_LOG_MODULE_NAME &quot;NeighborhoodConditionalMean&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;NeighborhoodConditionalMean.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    NeighborhoodConditionalMean,
+    &quot;Computes correlation coefficient between various discrete values and the target.&quot;,
+    &quot;name of the discrete variable, of the target and the values to check are options.\n&quot;
+);
+
+/////////////////////////
+// NeighborhoodConditionalMean //
+/////////////////////////
+NeighborhoodConditionalMean::NeighborhoodConditionalMean()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void NeighborhoodConditionalMean::declareOptions(OptionList&amp; ol)
+{
+
+    declareOption(ol, &quot;test_train_input_set&quot;, &amp;NeighborhoodConditionalMean::test_train_input_set,
+                  OptionBase::buildoption,
+                  &quot;The concatenated test and train input vectors with missing values.&quot;);
+    declareOption(ol, &quot;test_train_target_set&quot;, &amp;NeighborhoodConditionalMean::test_train_target_set,
+                  OptionBase::buildoption,
+                  &quot;The corresponding target vectors.&quot;);
+    declareOption(ol, &quot;number_of_test_samples&quot;, &amp;NeighborhoodConditionalMean::number_of_test_samples,
+                  OptionBase::buildoption,
+                  &quot;The number of test samples at the beginning of the test train concatenated sets.&quot;);
+    declareOption(ol, &quot;number_of_train_samples&quot;, &amp;NeighborhoodConditionalMean::number_of_train_samples,
+                  OptionBase::buildoption,
+                  &quot;The number of train samples in the reference set to compute the % of missing.&quot;);
+    declareOption(ol, &quot;target_field_names&quot;, &amp;NeighborhoodConditionalMean::target_field_names,
+                  OptionBase::buildoption,
+                  &quot;The vector of names of the field to select from the target_set as target for the built training files.&quot;);
+    declareOption(ol, &quot;dir_offset&quot;, &amp;NeighborhoodConditionalMean::dir_offset,
+                  OptionBase::buildoption,
+                  &quot;The directory offset where to find and/or create the various files.&quot;);
+    declareOption(ol, &quot;various_ks&quot;, &amp;NeighborhoodConditionalMean::various_ks,
+                  OptionBase::buildoption,
+                  &quot;The vector of various Ks to experiment with. Values must be between 1 and 100.&quot;);
+    declareOption(ol, &quot;deletion_thresholds&quot;, &amp;NeighborhoodConditionalMean::deletion_thresholds,
+                  OptionBase::buildoption,
+                  &quot;The vector of thresholds to be tested for each of the various Ks.&quot;);
+    declareOption(ol, &quot;experiment_name&quot;, &amp;NeighborhoodConditionalMean::experiment_name,
+                  OptionBase::buildoption,
+                  &quot;The name of the group of experiments to conduct.&quot;);
+    declareOption(ol, &quot;missing_indicator_field_names&quot;, &amp;NeighborhoodConditionalMean::missing_indicator_field_names,
+                  OptionBase::buildoption,
+                  &quot;The field names of the missing indicators to exclude when we experiment without them.&quot;);
+    declareOption(ol, &quot;experiment_template&quot;, &amp;NeighborhoodConditionalMean::experiment_template,
+                  OptionBase::buildoption,
+                  &quot;The template of the script to conduct the experiment.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void NeighborhoodConditionalMean::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(test_train_input_set, copies);
+    deepCopyField(test_train_target_set, copies);
+    deepCopyField(number_of_test_samples, copies);
+    deepCopyField(number_of_train_samples, copies);
+    deepCopyField(target_field_names, copies);
+    deepCopyField(dir_offset, copies);
+    deepCopyField(various_ks, copies);
+    deepCopyField(deletion_thresholds, copies);
+    deepCopyField(experiment_name, copies);
+    deepCopyField(missing_indicator_field_names, copies);
+    deepCopyField(deletion_thresholds, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void NeighborhoodConditionalMean::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void NeighborhoodConditionalMean::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        for (int iteration = 1; iteration &lt;= 1; iteration++)
+        {
+            cout &lt;&lt; &quot;In NeighborhoodConditionalMean, Iteration # &quot; &lt;&lt; iteration &lt;&lt; endl;
+            computeNeighborhood();
+            experimentWithVariousKs();
+            train();
+        }
+        PLERROR(&quot;In NeighborhoodConditionalMean: we are done here&quot;);
+    }
+}
+
+void NeighborhoodConditionalMean::computeNeighborhood()
+{
+/*
+    prepare correlation based versions of datatset: we have to write a VMatrix for that
+    use the ball tree nearest neighbor to build a ball tree using train only, with unknown it would be too long
+    find the 100 nearest neighbors of samples in train and test in order from the closest to the furthest
+    now we can create a neighborhood imputation for K from 1 up to 100 averaging 
+    the observed values of the the k closest input vectors.
+    If there is no observed values in the k closest, we have to use something else:
+    mean of the covariance preservation imputationof the the k closest input vectors.
+*/
+    cout &lt;&lt; &quot;In NeighborhoodConditionalMean:&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 1 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The first thing to do is to impute an initial value the the missing values in order to be able&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;to compute distance between samples.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step uses the CovariancePreservationVMatrix to do that.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The Covariance PreservationVMatrix creates a covariance_file in the metadata of the  source file&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;if it is not already there.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The file is kept in train_imputed_with_covariance_preservation.pmat.&quot; &lt;&lt; endl;
+    if (dir_offset != &quot;&quot;) dir_offset += &quot;/&quot;;
+    train_covariance_name = dir_offset + &quot;train_imputed_with_covariance_preservation.pmat&quot;;
+    if (isfile(train_covariance_name))
+    {
+        train_covariance_file = new FileVMatrix(train_covariance_name);
+        train_covariance_file-&gt;defineSizes(train_covariance_file-&gt;width(), 0, 0);
+        cout &lt;&lt; train_covariance_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_covariance_vmatrix = new CovariancePreservationImputationVMatrix();
+        train_covariance_vmatrix-&gt;source = train_set;
+        train_covariance_vmatrix-&gt;train_set = train_set;
+        train_covariance_vmatrix-&gt;build();
+        train_covariance_vmat = train_covariance_vmatrix;
+        train_covariance_file = new FileVMatrix(train_covariance_name, train_covariance_vmat-&gt;length(), train_covariance_vmat-&gt;fieldNames());
+        train_covariance_file-&gt;defineSizes(train_covariance_vmat-&gt;width(), 0, 0);
+        pb = new ProgressBar(&quot;Saving the train file imputed with the covariance preservation&quot;, train_covariance_vmat-&gt;length());
+        train_covariance_vector.resize(train_covariance_vmat-&gt;width());
+        for (int train_covariance_row = 0; train_covariance_row &lt; train_covariance_vmat-&gt;length(); train_covariance_row++)
+        {
+            train_covariance_vmat-&gt;getRow(train_covariance_row, train_covariance_vector);
+            train_covariance_file-&gt;putRow(train_covariance_row, train_covariance_vector);
+            pb-&gt;update( train_covariance_row );
+        }
+        delete pb;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 2 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;We do the same thing with the test_train dataset&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;using the covariance file created at the previous step.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The file is kept in test_train_imputed_with_covariance_preservation.pmat.&quot; &lt;&lt; endl;
+    test_train_covariance_file_name = dir_offset + &quot;test_train_imputed_with_covariance_preservation.pmat&quot;;
+    if (isfile(test_train_covariance_file_name))
+    {
+        test_train_covariance_file = new FileVMatrix(test_train_covariance_file_name);
+        test_train_covariance_file-&gt;defineSizes(test_train_covariance_file-&gt;width(), 0, 0);
+        cout &lt;&lt; test_train_covariance_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_train_covariance_vmatrix = new CovariancePreservationImputationVMatrix();
+        test_train_covariance_vmatrix-&gt;source = test_train_input_set;
+        test_train_covariance_vmatrix-&gt;train_set = train_set;
+        test_train_covariance_vmatrix-&gt;build();
+        test_train_covariance_vmat = test_train_covariance_vmatrix;
+        test_train_covariance_file = new FileVMatrix(test_train_covariance_file_name, test_train_covariance_vmat-&gt;length(), test_train_covariance_vmat-&gt;fieldNames());
+        test_train_covariance_file-&gt;defineSizes(test_train_covariance_vmat-&gt;width(), 0, 0);
+        pb = new ProgressBar(&quot;Saving the test_train file imputed with the covariance preservation&quot;, test_train_covariance_vmat-&gt;length());
+        test_train_covariance_vector.resize(test_train_covariance_vmat-&gt;width());
+        for (int test_train_covariance_row = 0; test_train_covariance_row &lt; test_train_covariance_vmat-&gt;length(); test_train_covariance_row++)
+        {
+            test_train_covariance_vmat-&gt;getRow(test_train_covariance_row, test_train_covariance_vector);
+            test_train_covariance_file-&gt;putRow(test_train_covariance_row, test_train_covariance_vector);
+            pb-&gt;update( test_train_covariance_row );
+        }
+        delete pb;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 3 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;We this initial imputation, we find the 100 nearest neighbors of each sample in the test_train dataset.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Their indexes are kept in the neighborhood_file of the test_train dataset metadata.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The BallTreeNearestNeighbors learner is used to build a tree with the train set&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;in order to speed up the identification of the 100 nearest neighbors of the test_train dataset.&quot; &lt;&lt; endl;
+    test_train_neighborhood_file_name = test_train_covariance_file_name + &quot;.metadata/neighborhood_file.pmat&quot;;
+    if (isfile(test_train_neighborhood_file_name))
+    {
+        test_train_neighborhood_file = new FileVMatrix(test_train_neighborhood_file_name);
+        cout &lt;&lt; test_train_neighborhood_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_train_neighborhood_learner = new BallTreeNearestNeighbors();
+        test_train_neighborhood_learner-&gt;setOption(&quot;rmin&quot;, &quot;1&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;train_method&quot;, &quot;anchor&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;num_neighbors&quot;, &quot;100&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;copy_input&quot;, &quot;0&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;copy_target&quot;, &quot;0&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;copy_weight&quot;, &quot;0&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;copy_index&quot;, &quot;1&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;nstages&quot;, &quot;-1&quot;);
+        test_train_neighborhood_learner-&gt;setOption(&quot;report_progress&quot;, &quot;1&quot;);
+        test_train_neighborhood_learner-&gt;setTrainingSet(train_covariance_file, true);
+        test_train_neighborhood_learner-&gt;train();
+        test_train_neighborhood_file = new FileVMatrix(test_train_neighborhood_file_name, test_train_covariance_file-&gt;length(), 100);
+        test_train_covariance_vector.resize(test_train_covariance_file-&gt;width());
+        test_train_neighborhood_vector.resize(100);
+        pb = new ProgressBar(&quot;Saving the test_train file with the index of the 100 nearest neighbors&quot;, test_train_covariance_file-&gt;length());
+        for (int test_train_neighborhood_row = 0; test_train_neighborhood_row &lt; test_train_covariance_file-&gt;length(); test_train_neighborhood_row++)
+        {
+            test_train_covariance_file-&gt;getRow(test_train_neighborhood_row, test_train_covariance_vector);
+            test_train_neighborhood_learner-&gt;computeOutput(test_train_covariance_vector, test_train_neighborhood_vector);
+            test_train_neighborhood_file-&gt;putRow(test_train_neighborhood_row, test_train_neighborhood_vector);
+            pb-&gt;update( test_train_neighborhood_row );
+        }
+        delete pb;
+    }
+}
+
+void NeighborhoodConditionalMean::experimentWithVariousKs()
+{
+/*
+    We control the experiments using a  master header file giving the status for each ks.
+    If the file is not there, we create it.
+    An experiment directory is created for each ks to eexperiment with various level 
+    of variable deletion.
+*/
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 4 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;We now prepare experimentation at various levels of Ks, the number of neighbors between 1 and 100.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The first thing is to load the master header file from the test_train_imputed_with_covariance_preservation.pmat metadata.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;If it is not there, the file is created.&quot; &lt;&lt; endl;
+    train_set-&gt;lockMetaDataDir();
+    master_header_file_name = test_train_covariance_file_name + &quot;.metadata&quot;;
+    master_header_file_name += &quot;/Experiment/&quot; + experiment_name + &quot;/&quot;;
+    master_header_file_name += &quot;neighborhood_header.pmat&quot;;
+    if (!isfile(master_header_file_name)) createMasterHeaderFile();
+    else getMasterHeaderRecords();
+    cout &lt;&lt; &quot;With the master header data, we can choose which K to experiment with.&quot; &lt;&lt; endl;
+    for (master_header_row = 0; master_header_row &lt; master_header_length; master_header_row++)
+    {
+        for (master_header_col = 0; master_header_col &lt; master_header_width; master_header_col++)
+            if (master_header_records(master_header_row, master_header_col) &lt;= 0.0) break;
+        if (master_header_col &lt; master_header_width) break;
+    }
+    if (master_header_row &gt;= master_header_length)
+    {
+        train_set-&gt;unlockMetaDataDir();
+        //reviewGlobalStats();
+        PLERROR(&quot;In NeighborhoodConditionalMean: we are done here&quot;);
+    }
+    to_deal_with_k = various_ks[master_header_col];
+    to_deal_with_target = target_field_names[master_header_row / 2];
+    to_deal_with_ind = master_header_row % 2;
+    cout &lt;&lt; &quot;Next target to deal with: &quot; &lt;&lt; to_deal_with_target &lt;&lt; endl;
+    cout &lt;&lt; &quot;Next experiment missing indicator: &quot; &lt;&lt; to_deal_with_ind &lt;&lt; endl;
+    cout &lt;&lt; &quot;Next k (number of neighbors) to experiment with: &quot; &lt;&lt; to_deal_with_k &lt;&lt; endl;
+    updateMasterHeaderRecords(master_header_row, master_header_col);
+    train_set-&gt;unlockMetaDataDir();
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 5 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;We perform the imputaton with the selected number of neighbors.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting file is loaded in memory to be passed to the experimentation script.&quot; &lt;&lt; endl;
+    test_train_neighbor_imputation_vmatrix = new NeighborhoodImputationVMatrix();
+    test_train_neighbor_imputation_vmatrix-&gt;source_with_missing = test_train_input_set;
+    test_train_neighbor_imputation_vmatrix-&gt;reference_index = test_train_neighborhood_file;
+    test_train_neighbor_imputation_vmatrix-&gt;reference_with_missing = train_set;
+    test_train_neighbor_imputation_vmatrix-&gt;reference_with_covariance_preserved = train_covariance_file;
+    test_train_neighbor_imputation_vmatrix-&gt;number_of_neighbors = to_deal_with_k;
+    test_train_neighbor_imputation_vmatrix-&gt;build();
+    test_train_neighbor_imputation_vmat = test_train_neighbor_imputation_vmatrix;
+    test_train_neighbor_imputation_file = new MemoryVMatrix(test_train_neighbor_imputation_vmat-&gt;length(), test_train_neighbor_imputation_vmat-&gt;width());
+    test_train_neighbor_imputation_file-&gt;defineSizes(test_train_neighbor_imputation_vmat-&gt;width(), 0, 0);
+    test_train_neighbor_imputation_file-&gt;declareFieldNames(test_train_neighbor_imputation_vmat-&gt;fieldNames());
+    test_train_neighbor_imputation_vector.resize(test_train_neighbor_imputation_vmat-&gt;width());
+    pb = new ProgressBar(&quot;Loading the test_train file imputed with the selected # of neighbors&quot;, test_train_neighbor_imputation_vmat-&gt;length());
+    for (int  test_train_neighbor_imputation_row = 0;
+              test_train_neighbor_imputation_row &lt; test_train_neighbor_imputation_vmat-&gt;length();
+              test_train_neighbor_imputation_row++)
+    {
+        test_train_neighbor_imputation_vmat-&gt;getRow(test_train_neighbor_imputation_row, test_train_neighbor_imputation_vector);
+        test_train_neighbor_imputation_file-&gt;putRow(test_train_neighbor_imputation_row, test_train_neighbor_imputation_vector);
+        pb-&gt;update( test_train_neighbor_imputation_row );
+    }
+     //       ::PLearn::save(header_expdir + &quot;/&quot; + deletion_threshold_str + &quot;/source_names.psave&quot;, source_names);
+    delete pb;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 6 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;We are now ready to launch the experimentation for this k.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The Experimentation program will build learners for the specified deletion thresholds.&quot; &lt;&lt; endl;
+    experimentation_learner = new Experimentation();
+    experimentation_learner-&gt;save_files = 0;
+    experimentation_learner-&gt;experiment_without_missing_indicator = to_deal_with_ind;
+    experimentation_learner-&gt;target_field_name = to_deal_with_target;
+    experimentation_learner-&gt;missing_indicator_field_names = missing_indicator_field_names;
+    experimentation_learner-&gt;experiment_name = experiment_name;
+    experimentation_learner-&gt;number_of_test_samples = number_of_test_samples;
+    experimentation_learner-&gt;number_of_train_samples = number_of_train_samples;
+    experimentation_learner-&gt;reference_train_set = train_set;
+    experimentation_learner-&gt;target_set = test_train_target_set;
+    experimentation_learner-&gt;experiment_template = experiment_template;
+    experimentation_learner-&gt;deletion_thresholds = deletion_thresholds;
+    experimentation_learner-&gt;experiment_directory = test_train_covariance_file_name + &quot;.metadata&quot;;
+    experimentation_learner-&gt;experiment_directory += &quot;/Experiment/&quot; + experiment_name + &quot;/&quot;;
+    experimentation_learner-&gt;experiment_directory += &quot;K_&quot; + tostring(to_deal_with_k);
+    experimentation_learner-&gt;setTrainingSet(test_train_neighbor_imputation_file);
+}
+
+void NeighborhoodConditionalMean::createMasterHeaderFile()
+{
+    master_header_length = target_field_names.length() * 2;
+    master_header_width = various_ks.length();
+    master_header_names.resize(master_header_width);
+    master_header_records.resize(master_header_length, master_header_width);
+    master_header_records.clear();
+    for (master_header_col = 0; master_header_col &lt; master_header_width; master_header_col++)
+        master_header_names[master_header_col] = &quot;K_&quot; + tostring(master_header_col);
+    master_header_file = new FileVMatrix(master_header_file_name, master_header_length, master_header_names);
+    for (master_header_row = 0; master_header_row &lt; master_header_length; master_header_row++)
+        for (master_header_col = 0; master_header_col &lt; master_header_width; master_header_col++)
+            master_header_file-&gt;put(master_header_row, master_header_col, 0.0);
+}
+void NeighborhoodConditionalMean::getMasterHeaderRecords()
+{ 
+    master_header_file = new FileVMatrix(master_header_file_name, true);
+    master_header_length = master_header_file-&gt;length();
+    master_header_width = master_header_file-&gt;width();
+    if (master_header_length != target_field_names.length() * 2)
+        PLERROR(&quot;In NeighborhoodConditionalMean: master header file length and target_field_names do not agree&quot;);
+    if (master_header_width != various_ks.length())
+        PLERROR(&quot;In NeighborhoodConditionalMean: master header file width and various_ks do not agree&quot;);
+    master_header_records.resize(master_header_length, master_header_width);
+    for (master_header_row = 0; master_header_row &lt; master_header_length; master_header_row++)
+        for (master_header_col = 0; master_header_col &lt; master_header_width; master_header_col++)
+            master_header_records(master_header_row, master_header_col) = master_header_file-&gt;get(master_header_row, master_header_col);
+}
+
+void NeighborhoodConditionalMean::updateMasterHeaderRecords(int row, int col)
+{
+    master_header_records(row, col) += 1.0;
+    master_header_file-&gt;put(row, col, master_header_records(row, col));
+    master_header_file-&gt;flush();
+}
+
+/*
+void NeighborhoodConditionalMean::createHeaderFile()
+{ 
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        targeted_stats = targeted_set-&gt;getStats(main_col);
+        targeted_missing = targeted_stats.nmissing();
+        main_stats = train_set-&gt;getStats(main_col);
+        main_total = main_stats.n();
+        main_missing = main_stats.nmissing();
+        main_present = main_total - main_missing;
+        if (fields_selected[main_col] &lt; 1) header_record[main_col] = 1;                  // delete column, field not selected
+        else if (targeted_missing &lt;= 0) header_record[main_col] = 0;                     // nothing to do
+        else if (main_present &lt; min_number_of_samples) header_record[main_col] = 1;      // delete column
+        else header_record[main_col] = 2;                                                // build tree
+    }
+    header_file = new FileVMatrix(header_file_name, 1, main_names);
+    header_file-&gt;putRow(0, header_record);
+}
+
+void NeighborhoodConditionalMean::getHeaderRecord()
+{ 
+    header_file = new FileVMatrix(header_file_name, true);
+    header_file-&gt;getRow(0, header_record);
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (header_record[main_col] == 0) continue;
+        if (header_record[main_col] == 2) continue;
+        if (header_record[main_col] == 1 &amp;&amp; fields_selected[main_col] &lt; 1) continue;
+        if (header_record[main_col] == 1)
+        {
+            main_stats = train_set-&gt;getStats(main_col);
+            main_total = main_stats.n();
+            main_missing = main_stats.nmissing();
+            main_present = main_total - main_missing;
+            if (main_present &gt;= min_number_of_samples) header_record[main_col] = 2;
+            continue;
+        }
+    }
+}
+
+void NeighborhoodConditionalMean::updateHeaderRecord(int var_col)
+{ 
+    header_file-&gt;put(0, var_col, 3.0);
+}
+
+void NeighborhoodConditionalMean::reviewGlobalStats()
+{ 
+    cout &lt;&lt; &quot;There is no more variable to deal with.&quot; &lt;&lt; endl;
+    for (main_col = 0; main_col &lt; main_width; main_col++)
+    {
+        if (header_record[main_col] == 0)
+        { 
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : no missing values for this variable in the targeted files.&quot; &lt;&lt; endl;
+            continue;
+        }
+        if (header_record[main_col] == 1 &amp;&amp; fields_selected[main_col] &lt; 1)
+        {
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : field not selected.&quot; &lt;&lt; endl;
+            continue;
+        }
+        if (header_record[main_col] == 1)
+        {
+            main_stats = train_set-&gt;getStats(main_col);
+            main_total = main_stats.n();
+            main_missing = main_stats.nmissing();
+            main_present = main_total - main_missing;
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : field deleted, only &quot; &lt;&lt; setw(6) &lt;&lt; main_present &lt;&lt; &quot; records to train with.&quot; &lt;&lt; endl;
+            continue;
+        }
+        results_file_name = targeted_metadata + &quot;/TreeCondMean/dir/&quot; + main_names[main_col] + &quot;/Split0/LearnerExpdir/Strat0results.pmat&quot;;
+        if (!isfile(results_file_name))
+        {
+            header_file-&gt;put(0, main_col, 2.0);
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : missing results file.&quot; &lt;&lt; endl;
+            continue;
+        }
+        test_output_file_name = targeted_metadata + &quot;/TreeCondMean/dir/&quot; + main_names[main_col] + &quot;/Split0/test1_outputs.pmat&quot;;
+        if (!isfile(test_output_file_name))
+        {
+            header_file-&gt;put(0, main_col, 2.0);
+            cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+            cout &lt;&lt; &quot; : missing test output file.&quot; &lt;&lt; endl;
+            continue;
+        }
+        results_file = new FileVMatrix(results_file_name);
+        results_length = results_file-&gt;length();
+        results_nstages = results_file-&gt;get(results_length - 1, 2);
+        results_mse = results_file-&gt;get(results_length - 1, 6);
+        results_std_err = results_file-&gt;get(results_length - 1, 7);
+        test_output_file = new FileVMatrix(test_output_file_name);
+        test_output_length = test_output_file-&gt;length();
+        cout &lt;&lt; setiosflags(ios::left) &lt;&lt; setw(30) &lt;&lt; main_names[main_col];
+        cout &lt;&lt; &quot; : tree built with &quot; &lt;&lt; setw(2) &lt;&lt; (int) results_nstages &lt;&lt; &quot; leaves, &quot;
+             &lt;&lt; setw(6) &lt;&lt; test_output_length &lt;&lt; &quot; test output records found, &quot;
+             &lt;&lt; &quot;performance: &quot; &lt;&lt; setiosflags(ios::fixed) &lt;&lt; setprecision(4) &lt;&lt; results_mse
+             &lt;&lt; &quot; +/- &quot; &lt;&lt; setiosflags(ios::fixed) &lt;&lt; setprecision(4) &lt;&lt; results_std_err &lt;&lt; endl;
+    }
+}
+*/
+
+void NeighborhoodConditionalMean::train()
+{
+/*
+    PP&lt;ExplicitSplitter&gt; explicit_splitter = new ExplicitSplitter();
+    explicit_splitter-&gt;splitsets.resize(1,2);
+    explicit_splitter-&gt;splitsets(0,0) = output_file;
+    explicit_splitter-&gt;splitsets(0,1) = train_test_file;
+    cond_mean = ::PLearn::deepCopy(cond_mean_template);
+    cond_mean-&gt;setOption(&quot;expdir&quot;, targeted_metadata + &quot;/TreeCondMean/dir/&quot; + to_deal_with_name);
+    cond_mean-&gt;splitter = new ExplicitSplitter();
+    cond_mean-&gt;splitter = explicit_splitter;
+    cond_mean-&gt;build();
+    Vec results = cond_mean-&gt;perform(true);
+*/
+}
+
+int NeighborhoodConditionalMean::outputsize() const {return 0;}
+void NeighborhoodConditionalMean::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void NeighborhoodConditionalMean::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; NeighborhoodConditionalMean::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; NeighborhoodConditionalMean::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodConditionalMean.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,252 @@
+// -*- C++ -*-
+
+// NeighborhoodConditionalMean.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file NeighborhoodConditionalMean.h */
+
+
+#ifndef NeighborhoodConditionalMean_INC
+#define NeighborhoodConditionalMean_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/testers/PTester.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/vmat/MemoryVMatrix.h&gt;
+#include &lt;plearn/io/load_and_save.h&gt;          //!&lt;  For save
+#include &lt;plearn/io/fileutils.h&gt;              //!&lt;  For isfile()
+#include &lt;plearn/math/random.h&gt;               //!&lt;  For the seed stuff.
+#include &lt;plearn/vmat/ExplicitSplitter.h&gt;     //!&lt;  For the splitter stuff.
+#include &lt;plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h&gt;
+#include &lt;plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h&gt;
+#include &lt;plearn_learners/second_iteration/BallTreeNearestNeighbors.h&gt;
+#include &lt;plearn_learners/second_iteration/Experimentation.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class NeighborhoodConditionalMean : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    
+    //! The concatenated test and train input vectors with missing values.
+    VMat test_train_input_set;
+    //! The corresponding target vectors.
+    VMat test_train_target_set;
+    //! The number of test samples at the beginning of the test train concatenated sets.
+    int number_of_test_samples;
+    //! The number of train samples in the reference set to compute the % of missing.
+    int number_of_train_samples;
+    //! The vector of names of the field to select from the target_set as target for the built training files.
+    TVec&lt;string&gt; target_field_names;
+    //! The directory offset where to find and/or create the various files.
+    string dir_offset;
+    //! The vector of various Ks to experiment with. Values must be between 1 and 100.
+    TVec&lt;int&gt; various_ks;
+    //! The vector of thresholds to be tested for each of the various Ks.
+    Vec deletion_thresholds;
+    //! The name of the group of experiments to conduct.
+    string experiment_name;
+    //!  The field names of the missing indicators to exclude when we experiment without them.
+    TVec&lt; string &gt; missing_indicator_field_names;
+    //! The template of the script to conduct the experiment.
+    PP&lt; PTester &gt; experiment_template;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    NeighborhoodConditionalMean();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(NeighborhoodConditionalMean);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void computeNeighborhood();
+    void experimentWithVariousKs();
+    void createMasterHeaderFile();
+    void getMasterHeaderRecords();
+    void updateMasterHeaderRecords(int row, int col);
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    ProgressBar*                              pb;
+    PPath                                     train_covariance_name;
+    VMat                                      train_covariance_file;
+    CovariancePreservationImputationVMatrix*  train_covariance_vmatrix;
+    VMat                                      train_covariance_vmat;
+    Vec                                       train_covariance_vector;
+    PPath                                     test_train_covariance_file_name;
+    VMat                                      test_train_covariance_file;
+    CovariancePreservationImputationVMatrix*  test_train_covariance_vmatrix;
+    VMat                                      test_train_covariance_vmat;
+    Vec                                       test_train_covariance_vector;
+    PPath                                     test_train_neighborhood_file_name;
+    BallTreeNearestNeighbors*                 test_train_neighborhood_learner;
+    VMat                                      test_train_neighborhood_file;
+    Vec                                       test_train_neighborhood_vector;
+    PPath                                     master_header_file_name;
+    VMat                                      master_header_file;
+    int                                       master_header_length;
+    int                                       master_header_width;
+    int                                       master_header_row;
+    int                                       master_header_col;
+    TVec&lt;string&gt;                              master_header_names;
+    Mat                                       master_header_records;
+    int                                       to_deal_with_k;
+    string                                    to_deal_with_target;
+    int                                       to_deal_with_ind;
+    NeighborhoodImputationVMatrix*            test_train_neighbor_imputation_vmatrix;
+    VMat                                      test_train_neighbor_imputation_vmat;
+    VMat                                      test_train_neighbor_imputation_file;
+    Vec                                       test_train_neighbor_imputation_vector;
+    Experimentation*                          experimentation_learner;
+    
+ /*   
+    int main_row;
+    int main_col;
+    int main_length;
+    int main_width;
+    Vec main_input;
+    TVec&lt;string&gt; main_names;
+    StatsCollector  main_stats;
+    PPath main_metadata;
+    TVec&lt;int&gt; main_ins;
+    real main_total;
+    real main_missing;
+    real main_present;
+    int targeted_length;
+    int targeted_width;
+    Vec targeted_input;
+    TVec&lt;string&gt; targeted_names;
+    StatsCollector  targeted_stats;
+    PPath targeted_metadata;
+    real targeted_missing;
+    PPath header_file_name;
+    VMat header_file;
+    Vec header_record;
+    int fields_col;
+    int fields_width;
+    TVec&lt;int&gt; fields_selected;
+    int to_deal_with_total;
+    int to_deal_with_next;
+    real to_deal_with_value;
+    string to_deal_with_name;
+    int ind_next;
+    int output_length;
+    int output_width;
+    int output_col;
+    string output_path;
+    TVec&lt;string&gt; output_names;
+    Vec output_vec;
+    TVec&lt;int&gt; output_variable_src;
+    VMat output_file;
+    int train_test_length;
+    string train_test_path;
+    TVec&lt;int&gt; train_test_variable_src;
+    VMat train_test_file;
+    PP&lt;PTester&gt; cond_mean;
+    PPath results_file_name;
+    VMat results_file;
+    int results_length;
+    real results_nstages;
+    real results_mse;
+    real results_std_err;
+    PPath test_output_file_name;
+    VMat test_output_file;
+    int test_output_length;
+*/    
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(NeighborhoodConditionalMean);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,233 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************************    
+   * $Id: NeighborhoodImputationVMatrix.cc 3658 2005-07-06 20:30:15  Godbout $
+   ******************************************************************* */
+
+
+#include &quot;NeighborhoodImputationVMatrix.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+/** NeighborhoodImputationVMatrix **/
+
+PLEARN_IMPLEMENT_OBJECT(
+  NeighborhoodImputationVMatrix,
+  &quot;VMat class to impute the observed variable mean to replace missing values in the source matrix.&quot;,
+  &quot;This class will replace missing values in the underlying dataset with the mean, median or mode observed on the train set.\n&quot;
+  &quot;The imputed value is based on the imputation instruction option.\n&quot;
+  );
+
+NeighborhoodImputationVMatrix::NeighborhoodImputationVMatrix()
+{
+}
+
+NeighborhoodImputationVMatrix::~NeighborhoodImputationVMatrix()
+{
+}
+
+void NeighborhoodImputationVMatrix::declareOptions(OptionList &amp;ol)
+{
+  declareOption(ol, &quot;source_with_missing&quot;, &amp;NeighborhoodImputationVMatrix::source_with_missing, OptionBase::buildoption, 
+                &quot;The source VMatrix with missing values.\n&quot;);
+
+  declareOption(ol, &quot;reference_index&quot;, &amp;NeighborhoodImputationVMatrix::reference_index, OptionBase::buildoption, 
+                &quot;The set of pre-computed neighbors index.\n&quot;
+                &quot;his can be done with BallTreeNearestNeighbors.\n&quot;);
+
+  declareOption(ol, &quot;reference_with_missing&quot;, &amp;NeighborhoodImputationVMatrix::reference_with_missing, OptionBase::buildoption, 
+                &quot;The reference set corresponding to the pre-computed index with missing values.&quot;);
+      
+  declareOption(ol, &quot;reference_with_covariance_preserved&quot;, &amp;NeighborhoodImputationVMatrix::reference_with_covariance_preserved, OptionBase::buildoption, 
+                &quot;The reference set corresponding to the pre-computed index with the initial imputations.&quot;);
+
+  declareOption(ol, &quot;number_of_neighbors&quot;, &amp;NeighborhoodImputationVMatrix::number_of_neighbors, OptionBase::learntoption,
+                &quot;This is usually called K, the number of neighbors to consider.\n&quot;   
+                &quot;It must be less or equal than the with of the reference index.&quot;);
+
+  inherited::declareOptions(ol);
+}
+
+void NeighborhoodImputationVMatrix::build()
+{
+  inherited::build();
+  build_();
+}
+
+void NeighborhoodImputationVMatrix::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+  deepCopyField(source_with_missing, copies);
+  deepCopyField(reference_index, copies);
+  deepCopyField(reference_with_missing, copies);
+  deepCopyField(reference_with_covariance_preserved, copies);
+  deepCopyField(number_of_neighbors, copies);
+  inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+void NeighborhoodImputationVMatrix::getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight)
+{
+  source_with_missing-&gt;getExample(i, input, target, weight);
+  for (int source_col = 0; source_col &lt; input-&gt;length(); source_col++)
+  {
+    if (is_missing(input[source_col])) input[source_col] = impute(i, source_col);
+  }  
+}
+
+real NeighborhoodImputationVMatrix::get(int i, int j) const
+{ 
+  real variable_value = source_with_missing-&gt;get(i, j);
+  if (!is_missing(variable_value)) return variable_value;
+  return impute(i, j);
+}
+
+void NeighborhoodImputationVMatrix::put(int i, int j, real value)
+{
+  PLERROR(&quot;In NeighborhoodImputationVMatrix::put not implemented&quot;);
+}
+
+void NeighborhoodImputationVMatrix::getSubRow(int i, int j, Vec v) const
+{  
+  source_with_missing-&gt;getSubRow(i, j, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++) 
+    if (is_missing(v[source_col])) v[source_col] = impute(i, source_col + j);
+}
+
+void NeighborhoodImputationVMatrix::putSubRow(int i, int j, Vec v)
+{
+  PLERROR(&quot;In NeighborhoodImputationVMatrix::putSubRow not implemented&quot;);
+}
+
+void NeighborhoodImputationVMatrix::appendRow(Vec v)
+{
+  PLERROR(&quot;In NeighborhoodImputationVMatrix::appendRow not implemented&quot;);
+}
+
+void NeighborhoodImputationVMatrix::insertRow(int i, Vec v)
+{
+  PLERROR(&quot;In NeighborhoodImputationVMatrix::insertRow not implemented&quot;);
+}
+
+void NeighborhoodImputationVMatrix::getRow(int i, Vec v) const
+{  
+  source_with_missing-&gt; getRow(i, v);
+  for (int source_col = 0; source_col &lt; v-&gt;length(); source_col++)
+    if (is_missing(v[source_col])) v[source_col] = impute(i, source_col); 
+}
+
+void NeighborhoodImputationVMatrix::putRow(int i, Vec v)
+{
+  PLERROR(&quot;In NeighborhoodImputationVMatrix::putRow not implemented&quot;);
+}
+
+void NeighborhoodImputationVMatrix::getColumn(int i, Vec v) const
+{  
+  source_with_missing-&gt; getColumn(i, v);
+  for (int source_row = 0; source_row &lt; v-&gt;length(); source_row++)
+    if (is_missing(v[source_row])) v[source_row] = impute(source_row, i);
+}
+
+void NeighborhoodImputationVMatrix::build_()
+{
+    if (!source_with_missing)                 PLERROR(&quot;In NeighborhoodImputationVMatrix::source with missing set must be supplied&quot;);
+    if (!reference_index)                     PLERROR(&quot;In NeighborhoodImputationVMatrix::reference index set must be supplied&quot;);
+    if (!reference_with_missing)              PLERROR(&quot;In NeighborhoodImputationVMatrix::reference with missing set must be supplied&quot;);
+    if (!reference_with_covariance_preserved) PLERROR(&quot;In NeighborhoodImputationVMatrix::reference with covariance preserved must be supplied&quot;);
+    src_length = source_with_missing-&gt;length();
+    if (src_length != reference_index-&gt;length())
+        PLERROR(&quot;In NeighborhoodImputationVMatrix::length of the source and its index must agree, got: %i - %i&quot;, src_length, reference_index-&gt;length());
+    ref_length = reference_with_missing-&gt;length();
+    if (ref_length != reference_with_covariance_preserved-&gt;length())
+        PLERROR(&quot;In NeighborhoodImputationVMatrix::length of the reference set with missing and with covariance preserved must agree, got: %i - %i&quot;,
+                ref_length, reference_with_covariance_preserved-&gt;length());
+    src_width = source_with_missing-&gt;width();
+    if (src_width != reference_with_missing-&gt;width())
+        PLERROR(&quot;In NeighborhoodImputationVMatrix::width of the source and the reference with missing must agree, got: %i - %i&quot;,
+                src_width, reference_with_missing-&gt;width());
+    if (src_width != reference_with_covariance_preserved-&gt;width())
+        PLERROR(&quot;In NeighborhoodImputationVMatrix::width of the source and the reference with missing must agree, got: %i - %i&quot;,
+                src_width, reference_with_covariance_preserved-&gt;width());
+    if (number_of_neighbors &lt; 1)
+        PLERROR(&quot;In NeighborhoodImputationVMatrix::the index must contains at least as many reference as the specified number of neighbors, got: %i - %i&quot;,
+                number_of_neighbors, reference_index-&gt;width());
+    if (number_of_neighbors &gt; reference_index-&gt;width())
+        PLERROR(&quot;In NeighborhoodImputationVMatrix::the index must contains at least as many reference as the specified number of neighbors, got: %i - %i&quot;,
+                number_of_neighbors, reference_index-&gt;width());
+    ref_idx.resize(reference_index-&gt;length(), reference_index-&gt;width());
+    ref_idx = reference_index-&gt;toMat();
+    ref_mis.resize(reference_with_missing-&gt;length(), reference_with_missing-&gt;width());
+    ref_mis = reference_with_missing-&gt;toMat();
+    ref_cov.resize(reference_with_covariance_preserved-&gt;length(), reference_with_covariance_preserved-&gt;width());
+    ref_cov = reference_with_covariance_preserved-&gt;toMat();
+    length_ = src_length;
+    width_ = src_width;
+    inputsize_ = source_with_missing-&gt;inputsize();
+    targetsize_ = source_with_missing-&gt;targetsize();
+    weightsize_ = source_with_missing-&gt;weightsize();
+    declareFieldNames(source_with_missing-&gt;fieldNames());
+}
+real NeighborhoodImputationVMatrix::impute(int i, int j) const
+{
+    int ref_idx_col;
+    int ref_row;
+    real return_value = 0.0;
+    real value_count = 0.0;
+    for (ref_idx_col = 0; ref_idx_col &lt; number_of_neighbors; ref_idx_col++)
+    {
+        ref_row = (int) ref_idx(i, ref_idx_col);
+        if (ref_row &lt; 0 || ref_row &gt;= ref_length)
+            PLERROR(&quot;In NeighborhoodImputationVMatrix::invalid index reference, got: %i for sample %i&quot;, ref_row, i);
+        if (is_missing(ref_mis(ref_row, j))) continue;
+        return_value += ref_mis(ref_row, j);
+        value_count += 1.0;
+    }
+    if (value_count &gt; 0) return return_value / value_count;
+    return_value = 0.0;
+    value_count = 0.0;
+    for (ref_idx_col = 0; ref_idx_col &lt; number_of_neighbors; ref_idx_col++)
+    {
+        ref_row = (int) ref_idx(i, ref_idx_col);
+        if (is_missing(ref_cov(ref_row, j)))
+            PLERROR(&quot;In NeighborhoodImputationVMatrix::missing value found in the reference with covariance preserved at: %i , %i&quot;, ref_row, j);
+        return_value += ref_cov(ref_row, j);
+        value_count += 1.0;
+    }
+    return return_value / value_count;
+}
+
+} // end of namespcae PLearn

Added: branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,117 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2001 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2002 Pascal Vincent, Julien Keable, Xavier Saint-Mleux
+// Copyright (C) 2003 Olivier Delalleau
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ******************************************************************      
+   * $Id: NeighborhoodImputationVMatrix.h 3658 2005-07-06 20:30:15  Godbout $
+   ****************************************************************** */
+
+/*! \file PLearnLibrary/PLearnCore/VMat.h */
+
+#ifndef NeighborhoodImputationVMatrix_INC
+#define NeighborhoodImputationVMatrix_INC
+
+#include &lt;plearn/vmat/SourceVMatrix.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/io/fileutils.h&gt;                     //!&lt;  For isfile()
+#include &lt;plearn/math/BottomNI.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class NeighborhoodImputationVMatrix: public VMatrix
+{
+  typedef VMatrix inherited;
+  
+public:
+
+  //! The source VMatrix with missing values.
+  VMat                          source_with_missing;
+  
+  //! The set of pre-computed neighbors index.
+  //! This can be done with BallTreeNearestNeighbors.
+  VMat                          reference_index;
+  
+  //! The reference set corresponding to the pre-computed index with missing values.
+  VMat                          reference_with_missing;
+  
+  //! The reference set corresponding to the pre-computed index with the initial imputations.
+  VMat                          reference_with_covariance_preserved;
+   
+  //! This is usually called K, the number of neighbors to consider.
+  //! It must be less or equal than the with of the reference index.
+  int                           number_of_neighbors;
+  
+
+                        NeighborhoodImputationVMatrix();
+  virtual               ~NeighborhoodImputationVMatrix();
+
+  static void           declareOptions(OptionList &amp;ol);
+
+  virtual void          build();
+  virtual void          makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+  virtual void         getExample(int i, Vec&amp; input, Vec&amp; target, real&amp; weight);
+  virtual real         get(int i, int j) const;
+  virtual void         put(int i, int j, real value);
+  virtual void         getSubRow(int i, int j, Vec v) const;
+  virtual void         putSubRow(int i, int j, Vec v);
+  virtual void         appendRow(Vec v);
+  virtual void         insertRow(int i, Vec v);  
+  virtual void         getRow(int i, Vec v) const;
+  virtual void         putRow(int i, Vec v);
+  virtual void         getColumn(int i, Vec v) const;
+
+private:
+  
+          int          src_length;
+          int          src_width;
+          int          ref_length;
+          Mat          ref_idx;
+          Mat          ref_mis;
+          Mat          ref_cov;
+
+          void         build_();
+          real         impute(int i, int j) const;
+  
+  PLEARN_DECLARE_OBJECT(NeighborhoodImputationVMatrix);
+
+};
+
+DECLARE_OBJECT_PTR(NeighborhoodImputationVMatrix);
+
+} // end of namespcae PLearn
+#endif

Added: branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,990 @@
+// -*- C++ -*-
+
+// Preprocessing.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file Preprocessing.cc */
+
+#define PL_LOG_MODULE_NAME &quot;Preprocessing&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;Preprocessing.h&quot;
+#include &lt;plearn/io/load_and_save.h&gt;                 //!&lt;  For save
+#include &lt;plearn/io/fileutils.h&gt;                     //!&lt;  For isfile()
+#include &lt;plearn/math/random.h&gt;                      //!&lt;  For the seed stuff.
+#include &lt;plearn/vmat/ExplicitSplitter.h&gt;            //!&lt;  For the splitter stuff.
+#include &lt;plearn/vmat/VariableDeletionVMatrix.h&gt;     //!&lt;  For the new_set stuff.
+#include &lt;plearn/vmat/BootstrapVMatrix.h&gt;            //!&lt;  For the shuffle stuff.
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    Preprocessing,
+    &quot;Computes correlation coefficient between various discrete values and the target.&quot;,
+    &quot;name of the discrete variable, of the target and the values to check are options.\n&quot;
+);
+
+/////////////////////////
+// Preprocessing //
+/////////////////////////
+Preprocessing::Preprocessing()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void Preprocessing::declareOptions(OptionList&amp; ol)
+{
+    declareOption(ol, &quot;test_set&quot;, &amp;Preprocessing::test_set,
+                  OptionBase::buildoption,
+                  &quot;The test data set.\n&quot;);
+    declareOption(ol, &quot;unknown_set&quot;, &amp;Preprocessing::unknown_set,
+                  OptionBase::buildoption,
+                  &quot;The unknown data set.\n&quot;);
+    declareOption(ol, &quot;compute_target_learner_template&quot;, &amp;Preprocessing::compute_target_learner_template,
+                  OptionBase::buildoption,
+                  &quot;The template of the script to generate the class target.\n&quot;);
+    declareOption(ol, &quot;fix_binary_variables_template&quot;, &amp;Preprocessing::fix_binary_variables_template,
+                  OptionBase::buildoption,
+                  &quot;The template of the script to fix the binary variables.\n&quot;);
+    declareOption(ol, &quot;imputation_spec&quot;, &amp;Preprocessing::imputation_spec,
+                  OptionBase::buildoption,
+                  &quot;Pairs of instruction of the form field_name : mean | median | mode.\n&quot;);
+    declareOption(ol, &quot;discrete_variable_instructions&quot;, &amp;Preprocessing::discrete_variable_instructions,
+                  OptionBase::buildoption,
+                  &quot;The instructions to dichotomize the variables in the form of field_name : TVec&lt;pair&gt;.\n&quot;
+                  &quot;The pairs are values from : to, each creating a 0, 1 variable.\n&quot;
+                  &quot;Variables with no specification will be kept as_is.\n&quot;);
+    declareOption(ol, &quot;selected_variables_for_input&quot;, &amp;Preprocessing::selected_variables_for_input,
+                  OptionBase::buildoption,
+                  &quot;The list of variables selected as input vector.\n&quot;);
+    declareOption(ol, &quot;selected_variables_for_target&quot;, &amp;Preprocessing::selected_variables_for_target,
+                  OptionBase::buildoption,
+                  &quot;The list of variables selected as target vector.\n&quot;);
+    declareOption(ol, &quot;inputs_excluded_from_gaussianization&quot;, &amp;Preprocessing::inputs_excluded_from_gaussianization,
+                  OptionBase::buildoption,
+                  &quot;The list of input variables excluded from the gaussianization step.\n&quot;);
+    declareOption(ol, &quot;targets_excluded_from_gaussianization&quot;, &amp;Preprocessing::targets_excluded_from_gaussianization,
+                  OptionBase::buildoption,
+                  &quot;The list of target variables excluded from the gaussianization step.\n&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void Preprocessing::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(test_set, copies);
+    deepCopyField(unknown_set, copies);
+    deepCopyField(compute_target_learner_template, copies);
+    deepCopyField(fix_binary_variables_template, copies);
+    deepCopyField(imputation_spec, copies);
+    deepCopyField(discrete_variable_instructions, copies);
+    deepCopyField(selected_variables_for_input, copies);
+    deepCopyField(selected_variables_for_target, copies);
+    deepCopyField(inputs_excluded_from_gaussianization, copies);
+    deepCopyField(targets_excluded_from_gaussianization, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void Preprocessing::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void Preprocessing::build_()
+{
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        manageTrainTestUnknownSets();
+        PLERROR(&quot;In Preprocessing: Everything completed successfuly, we are done here&quot;);
+    }
+}
+
+void Preprocessing::manageTrainTestUnknownSets()
+{
+
+    // defining all the variables for the train set
+    PPath                                 output_path;
+    PPath                                 train_with_class_target_file_name;
+    VMat                                  train_with_class_target_file;
+    PP&lt;ComputeDond2Target&gt;                compute_target_learner;
+    BootstrapVMatrix*                     train_shufffled_vmatrix;
+    VMat                                  train_shuffled_file;
+    PPath                                 train_with_binary_fixed_file_name;
+    VMat                                  train_with_binary_fixed_file;
+    PP&lt;FixDond2BinaryVariables&gt;           fix_binary_variables_learner;
+    PPath                                 train_with_ind_file_name;
+    MissingIndicatorVMatrix*              train_with_ind_vmatrix;
+    VMat                                  train_with_ind_vmat;
+    VMat                                  train_with_ind_file;
+    Vec                                   train_with_ind_vector;
+    MeanMedianModeImputationVMatrix*      train_with_imp_vmatrix;
+    VMat                                  mean_median_mode_with_ind_file;
+    PPath                                 train_with_dichotomies_file_name;
+    VMat                                  train_with_dichotomies_file;
+    PPath                                 mean_median_mode_with_dichotmies_file_name;
+    VMat                                  mean_median_mode_with_dichotmies_file;
+    PP&lt;DichotomizeDond2DiscreteVariables&gt; dichotomize_discrete_variables_learner;
+    SelectColumnsVMatrix*                 train_with_selected_columns_vmatrix;
+    VMat                                  train_with_selected_columns_vmat;
+    SelectColumnsVMatrix*                 mean_median_mode_with_selected_columns_vmatrix;
+    VMat                                  mean_median_mode_with_selected_columns_vmat;
+    GaussianizeVMatrix*                   train_gaussianized_vmatrix;
+    VMat                                  train_gaussianized_vmat;
+    GaussianizeVMatrix*                   mean_median_mode_gaussianized_vmatrix;
+    VMat                                  mean_median_mode_gaussianized_vmat;
+    PPath                                 train_input_preprocessed_file_name;
+    VMat                                  train_input_preprocessed_file;
+    Vec                                   train_input_preprocessed_vector;
+    PPath                                 mean_median_mode_input_preprocessed_file_name;
+    VMat                                  mean_median_mode_input_preprocessed_file;
+    Vec                                   mean_median_mode_input_preprocessed_vector;
+    SelectColumnsVMatrix*                 train_target_with_selected_columns_vmatrix;
+    VMat                                  train_target_with_selected_columns_vmat;
+    GaussianizeVMatrix*                   train_target_gaussianized_vmatrix;
+    VMat                                  train_target_gaussianized_vmat;
+    PPath                                 train_target_preprocessed_file_name;
+    VMat                                  train_target_preprocessed_file;
+    Vec                                   train_target_preprocessed_vector;
+    ProgressBar*                          pb = 0;
+    
+    // managing the train set
+    cout &lt;&lt; &quot;In Preprocessing: we start by formatting the training set&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 1 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The first step groups variables by type, skips untrustworthy variables, and generate class targets&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses ComputeDond2Target to transform base_train.pmat into step1_train_with_class_target.pmat&quot; &lt;&lt; endl;
+    output_path = &quot;step1_train_with_class_target&quot;;
+    train_with_class_target_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(train_with_class_target_file_name))
+    {
+        train_with_class_target_file = new FileVMatrix(train_with_class_target_file_name);
+        train_with_class_target_file-&gt;defineSizes(train_with_class_target_file-&gt;width(), 0, 0);
+        cout &lt;&lt; train_with_class_target_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        compute_target_learner = ::PLearn::deepCopy(compute_target_learner_template);
+        compute_target_learner-&gt;unknown_sales = 0;
+        compute_target_learner-&gt;output_path = output_path;
+        compute_target_learner-&gt;setTrainingSet(train_set, true);
+        train_with_class_target_file = compute_target_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 2 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step shuffles the training set to get training data in random order.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses BootstrapVMatrix to transform step1_train_with_class_target.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 3&quot; &lt;&lt; endl;
+    output_path = &quot;step3_train_with_binary_fixed&quot;;
+    train_with_binary_fixed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(train_with_binary_fixed_file_name))
+    {
+         cout &lt;&lt; train_with_binary_fixed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_shufffled_vmatrix = new BootstrapVMatrix();
+        train_shufffled_vmatrix-&gt;shuffle = 1;
+        train_shufffled_vmatrix-&gt;frac = 1.0;
+        train_shufffled_vmatrix-&gt;own_seed = 123456;
+        train_shufffled_vmatrix-&gt;source = train_with_class_target_file;
+        train_shufffled_vmatrix-&gt;build();
+        train_shuffled_file = train_shufffled_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 3 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;For strictly binary variables, various situations arise: zero or non-zero, missing or not-missing, a given value or not, etc...&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step uses FixDond2BinaryVariables to create step3_train_with_binary_fixed.pmat with 0-1 binary variables.&quot; &lt;&lt; endl;
+    if (isfile(train_with_binary_fixed_file_name))
+    {
+        train_with_binary_fixed_file = new FileVMatrix(train_with_binary_fixed_file_name);
+        train_with_binary_fixed_file-&gt;defineSizes(train_with_binary_fixed_file-&gt;width(), 0, 0);
+        cout &lt;&lt; train_with_binary_fixed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        fix_binary_variables_learner = ::PLearn::deepCopy(fix_binary_variables_template);
+        fix_binary_variables_learner-&gt;output_path = output_path;
+        fix_binary_variables_learner-&gt;setTrainingSet(train_shuffled_file, true);
+        train_with_binary_fixed_file = fix_binary_variables_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 4 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step adds missing indicators variables to each variable with missing values.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses MissingIndicatorVMatrix to transform step3_train_with_binary_fixed.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is stored in step4_train_with_ind.pmat.&quot; &lt;&lt; endl;
+    train_with_ind_file_name = &quot;step4_train_with_ind.pmat&quot;;
+    if (isfile(train_with_ind_file_name))
+    {
+        train_with_ind_file = new FileVMatrix(train_with_ind_file_name);
+        train_with_ind_file-&gt;defineSizes(train_with_ind_file-&gt;width(), 0, 0);
+        cout &lt;&lt; train_with_ind_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_with_ind_vmatrix = new MissingIndicatorVMatrix();
+        train_with_ind_vmatrix-&gt;source = train_with_binary_fixed_file;
+        train_with_ind_vmatrix-&gt;train_set = train_with_binary_fixed_file;
+        train_with_ind_vmatrix-&gt;number_of_train_samples_to_use = 30000.0;
+        train_with_ind_vmatrix-&gt;build();
+        train_with_ind_vmat = train_with_ind_vmatrix;
+        train_with_ind_file = new FileVMatrix(train_with_ind_file_name, train_with_ind_vmat-&gt;length(), train_with_ind_vmat-&gt;fieldNames());
+        train_with_ind_file-&gt;defineSizes(train_with_ind_vmat-&gt;inputsize(), train_with_ind_vmat-&gt;targetsize(), train_with_ind_vmat-&gt;weightsize());
+        pb = new ProgressBar(&quot;Saving the train file with missing indicators&quot;, train_with_ind_vmat-&gt;length());
+        train_with_ind_vector.resize(train_with_ind_vmat-&gt;width());
+        for (int train_with_ind_row = 0; train_with_ind_row &lt; train_with_ind_vmat-&gt;length(); train_with_ind_row++)
+        {
+            train_with_ind_vmat-&gt;getRow(train_with_ind_row, train_with_ind_vector);
+            train_with_ind_file-&gt;putRow(train_with_ind_row, train_with_ind_vector);
+            pb-&gt;update( train_with_ind_row );
+        }
+        delete pb;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 5 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step computes the mean, median and mode vectors on step4_train_with_ind.pmat.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The vectors are kept in the mean_median_mode_file.pmat of the metadata.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses MeanMedianModeImputationVMatrix to do that&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not used.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;But the mean, median and mode vectors have to go thru the same transformation than the training file&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;from here on to the end of the preprocessing steps..&quot; &lt;&lt; endl;
+    train_with_imp_vmatrix = new MeanMedianModeImputationVMatrix();
+    train_with_imp_vmatrix-&gt;source = train_with_ind_file;
+    train_with_imp_vmatrix-&gt;train_set = train_with_ind_file;
+    train_with_imp_vmatrix-&gt;number_of_train_samples_to_use = 30000.0;
+    train_with_imp_vmatrix-&gt;imputation_spec = imputation_spec;
+    train_with_imp_vmatrix-&gt;build();
+    mean_median_mode_with_ind_file = train_with_imp_vmatrix-&gt;getMeanMedianModeFile();
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 6 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This steps generates as many dichotomized variables as there are significant code values.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses DichotomizeDond2DiscreteVariables to transform step4_train_with_ind.pmat into step6_train_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    output_path = &quot;step6_train_with_dichotomies&quot;;
+    train_with_dichotomies_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(train_with_dichotomies_file_name))
+    {
+        train_with_dichotomies_file = new FileVMatrix(train_with_dichotomies_file_name);
+        train_with_dichotomies_file-&gt;defineSizes(train_with_dichotomies_file-&gt;width(), 0, 0);
+        cout &lt;&lt; train_with_dichotomies_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        dichotomize_discrete_variables_learner = new DichotomizeDond2DiscreteVariables();
+        dichotomize_discrete_variables_learner-&gt;discrete_variable_instructions = discrete_variable_instructions;
+        dichotomize_discrete_variables_learner-&gt;output_path = output_path;
+        dichotomize_discrete_variables_learner-&gt;setTrainingSet(train_with_ind_file, true);
+        train_with_dichotomies_file = dichotomize_discrete_variables_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 7 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This steps does the same thing to the mean, median and mode vectors.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses DichotomizeDond2DiscreteVariables to transform step4_train_with_ind.pmat.metadata/mean_median_mode_file.pmat &quot;
+         &lt;&lt; &quot;into step6_train_with_dichotomies.pmat.metadata/mean_median_mode_file.pmat&quot; &lt;&lt; endl;
+    output_path = train_with_dichotomies_file_name + &quot;.metadata/mean_median_mode_file&quot;;
+    mean_median_mode_with_dichotmies_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(mean_median_mode_with_dichotmies_file_name))
+    {
+        mean_median_mode_with_dichotmies_file = new FileVMatrix(mean_median_mode_with_dichotmies_file_name);
+        mean_median_mode_with_dichotmies_file-&gt;defineSizes(mean_median_mode_with_dichotmies_file-&gt;width(), 0, 0);
+        cout &lt;&lt; mean_median_mode_with_dichotmies_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        dichotomize_discrete_variables_learner = new DichotomizeDond2DiscreteVariables();
+        dichotomize_discrete_variables_learner-&gt;discrete_variable_instructions = discrete_variable_instructions;
+        dichotomize_discrete_variables_learner-&gt;output_path = output_path;
+        dichotomize_discrete_variables_learner-&gt;setTrainingSet(mean_median_mode_with_ind_file, true);
+        mean_median_mode_with_dichotmies_file = dichotomize_discrete_variables_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 8 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step select the desired columns from the training set to create the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses SelectColumnsVMatrix to transform step6_train_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 10&quot; &lt;&lt; endl;
+    output_path = &quot;final_train_input_preprocessed&quot;;
+    train_input_preprocessed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(train_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; train_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_with_selected_columns_vmatrix = new SelectColumnsVMatrix();
+        train_with_selected_columns_vmatrix-&gt;source = train_with_dichotomies_file;
+        train_with_selected_columns_vmatrix-&gt;fields_partial_match = 0;
+        train_with_selected_columns_vmatrix-&gt;extend_with_missing = 0;
+        train_with_selected_columns_vmatrix-&gt;fields = selected_variables_for_input;
+        train_with_selected_columns_vmatrix-&gt;build();
+        train_with_selected_columns_vmatrix-&gt;defineSizes(train_with_selected_columns_vmatrix-&gt;width(), 0, 0);
+        train_with_selected_columns_vmat = train_with_selected_columns_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 9 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step does the same thing to the mean, median and mode vectors.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses SelectColumnsVMatrix to transform step6_train_with_dichotomies.pmat.metadata/mean_median_mode_file.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 11&quot; &lt;&lt; endl;
+    output_path = train_input_preprocessed_file_name + &quot;.metadata/mean_median_mode_file&quot;;
+    mean_median_mode_input_preprocessed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(mean_median_mode_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; mean_median_mode_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        mean_median_mode_with_selected_columns_vmatrix = new SelectColumnsVMatrix();
+        mean_median_mode_with_selected_columns_vmatrix-&gt;source = mean_median_mode_with_dichotmies_file;
+        mean_median_mode_with_selected_columns_vmatrix-&gt;fields_partial_match = 0;
+        mean_median_mode_with_selected_columns_vmatrix-&gt;extend_with_missing = 0;
+        mean_median_mode_with_selected_columns_vmatrix-&gt;fields = selected_variables_for_input;
+        mean_median_mode_with_selected_columns_vmatrix-&gt;build();
+        mean_median_mode_with_selected_columns_vmatrix-&gt;defineSizes(mean_median_mode_with_selected_columns_vmatrix-&gt;width(), 0, 0);
+        mean_median_mode_with_selected_columns_vmat = mean_median_mode_with_selected_columns_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 10 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This gaussianizes the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses GaussianizeVMatrix to transform the vmat from step 8&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 12&quot; &lt;&lt; endl;
+    if (isfile(train_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; train_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_gaussianized_vmatrix = new GaussianizeVMatrix();
+        train_gaussianized_vmatrix-&gt;source = train_with_selected_columns_vmat;
+        train_gaussianized_vmatrix-&gt;train_source = train_with_selected_columns_vmat;
+        train_gaussianized_vmatrix-&gt;threshold_ratio = 1;
+        train_gaussianized_vmatrix-&gt;gaussianize_input = 1;
+        train_gaussianized_vmatrix-&gt;gaussianize_target = 0;
+        train_gaussianized_vmatrix-&gt;gaussianize_weight = 0;
+        train_gaussianized_vmatrix-&gt;gaussianize_extra = 0;
+        train_gaussianized_vmatrix-&gt;excluded_fields = inputs_excluded_from_gaussianization;
+        train_gaussianized_vmatrix-&gt;build();
+        train_gaussianized_vmat = train_gaussianized_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 11 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step does the same thing to the mean, median and mode vectors.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses the vmat from step 9&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 13&quot; &lt;&lt; endl;
+    if (isfile(mean_median_mode_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; mean_median_mode_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        mean_median_mode_gaussianized_vmatrix = new GaussianizeVMatrix();
+        mean_median_mode_gaussianized_vmatrix-&gt;source = mean_median_mode_with_selected_columns_vmat;
+        mean_median_mode_gaussianized_vmatrix-&gt;train_source = train_with_selected_columns_vmat;
+        mean_median_mode_gaussianized_vmatrix-&gt;threshold_ratio = 1;
+        mean_median_mode_gaussianized_vmatrix-&gt;gaussianize_input = 1;
+        mean_median_mode_gaussianized_vmatrix-&gt;gaussianize_target = 0;
+        mean_median_mode_gaussianized_vmatrix-&gt;gaussianize_weight = 0;
+        mean_median_mode_gaussianized_vmatrix-&gt;gaussianize_extra = 0;
+        mean_median_mode_gaussianized_vmatrix-&gt;excluded_fields = inputs_excluded_from_gaussianization;
+        mean_median_mode_gaussianized_vmatrix-&gt;build();
+        mean_median_mode_gaussianized_vmat = mean_median_mode_gaussianized_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 12 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Finaly, the preprocessed input vectors are store on disk.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The vmat from step 10 is converted to final_train_input_preprocessed.pmat.&quot; &lt;&lt; endl;
+    if (isfile(train_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; train_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_input_preprocessed_file = new FileVMatrix(train_input_preprocessed_file_name, train_gaussianized_vmat-&gt;length(), train_gaussianized_vmat-&gt;fieldNames());
+        train_input_preprocessed_file-&gt;defineSizes(train_gaussianized_vmat-&gt;inputsize(), train_gaussianized_vmat-&gt;targetsize(), train_gaussianized_vmat-&gt;weightsize());
+        pb = new ProgressBar(&quot;Saving the final train preprocessed input records&quot;, train_gaussianized_vmat-&gt;length());
+        train_input_preprocessed_vector.resize(train_gaussianized_vmat-&gt;width());
+        for (int train_gaussianized_row = 0; train_gaussianized_row &lt; train_gaussianized_vmat-&gt;length(); train_gaussianized_row++)
+        {
+            train_gaussianized_vmat-&gt;getRow(train_gaussianized_row, train_input_preprocessed_vector);
+            train_input_preprocessed_file-&gt;putRow(train_gaussianized_row, train_input_preprocessed_vector);
+            pb-&gt;update( train_gaussianized_row );
+        }
+        delete pb;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 13 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;And we do the same for the mean, median and mode vectors.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The vmat from step 11 is converted to final_train_input_preprocessed.pmat.metadata/men_median_mode_file.pmat&quot; &lt;&lt; endl;
+    if (isfile(mean_median_mode_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; mean_median_mode_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        mean_median_mode_input_preprocessed_file = 
+            new FileVMatrix(mean_median_mode_input_preprocessed_file_name, mean_median_mode_gaussianized_vmat-&gt;length(), mean_median_mode_gaussianized_vmat-&gt;fieldNames());
+        mean_median_mode_input_preprocessed_file-&gt;defineSizes(mean_median_mode_gaussianized_vmat-&gt;inputsize(),
+                                                              mean_median_mode_gaussianized_vmat-&gt;targetsize(), mean_median_mode_gaussianized_vmat-&gt;weightsize());
+        pb = new ProgressBar(&quot;Saving the final mean,median and mode preprocessed input vectors&quot;, mean_median_mode_gaussianized_vmat-&gt;length());
+        mean_median_mode_input_preprocessed_vector.resize(mean_median_mode_gaussianized_vmat-&gt;width());
+        for (int mean_median_mode_gaussianized_row = 0; mean_median_mode_gaussianized_row &lt; mean_median_mode_gaussianized_vmat-&gt;length(); mean_median_mode_gaussianized_row++)
+        {
+            mean_median_mode_gaussianized_vmat-&gt;getRow(mean_median_mode_gaussianized_row, mean_median_mode_input_preprocessed_vector);
+            mean_median_mode_input_preprocessed_file-&gt;putRow(mean_median_mode_gaussianized_row, mean_median_mode_input_preprocessed_vector);
+            pb-&gt;update( mean_median_mode_gaussianized_row );
+        }
+        delete pb;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 14 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step select the desired columns from the training set to create the target records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses SelectColumnsVMatrix to transform step6_train_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 15&quot; &lt;&lt; endl;
+    output_path = &quot;final_train_target_preprocessed&quot;;
+    train_target_preprocessed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(train_target_preprocessed_file_name))
+    {
+        cout &lt;&lt; train_target_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_target_with_selected_columns_vmatrix = new SelectColumnsVMatrix();
+        train_target_with_selected_columns_vmatrix-&gt;source = train_with_dichotomies_file;
+        train_target_with_selected_columns_vmatrix-&gt;fields_partial_match = 0;
+        train_target_with_selected_columns_vmatrix-&gt;extend_with_missing = 0;
+        train_target_with_selected_columns_vmatrix-&gt;fields = selected_variables_for_target;
+        train_target_with_selected_columns_vmatrix-&gt;build();
+        train_target_with_selected_columns_vmatrix-&gt;defineSizes(train_target_with_selected_columns_vmatrix-&gt;width(), 0, 0);
+        train_target_with_selected_columns_vmat = train_target_with_selected_columns_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 15 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This gaussianizes the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses GaussianizeVMatrix to transform the vmat from step 14&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 16&quot; &lt;&lt; endl;
+    if (isfile(train_target_preprocessed_file_name))
+    {
+        cout &lt;&lt; train_target_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_target_gaussianized_vmatrix = new GaussianizeVMatrix();
+        train_target_gaussianized_vmatrix-&gt;source = train_target_with_selected_columns_vmat;
+        train_target_gaussianized_vmatrix-&gt;train_source = train_target_with_selected_columns_vmat;
+        train_target_gaussianized_vmatrix-&gt;threshold_ratio = 1;
+        train_target_gaussianized_vmatrix-&gt;gaussianize_input = 1;
+        train_target_gaussianized_vmatrix-&gt;gaussianize_target = 0;
+        train_target_gaussianized_vmatrix-&gt;gaussianize_weight = 0;
+        train_target_gaussianized_vmatrix-&gt;gaussianize_extra = 0;
+        train_target_gaussianized_vmatrix-&gt;excluded_fields = targets_excluded_from_gaussianization;;
+        train_target_gaussianized_vmatrix-&gt;build();
+        train_target_gaussianized_vmat = train_target_gaussianized_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 16 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Finaly, the preprocessed input vectors are store on disk.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The vmat from step 15 is converted to final_train_target_preprocessed.pmat.&quot; &lt;&lt; endl;
+    if (isfile(train_target_preprocessed_file_name))
+    {
+        cout &lt;&lt; train_target_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        train_target_preprocessed_file = new FileVMatrix(train_target_preprocessed_file_name, train_target_gaussianized_vmat-&gt;length(),
+                                                         train_target_gaussianized_vmat-&gt;fieldNames());
+        train_target_preprocessed_file-&gt;defineSizes(train_target_gaussianized_vmat-&gt;inputsize(), train_target_gaussianized_vmat-&gt;targetsize(),
+                                                   train_target_gaussianized_vmat-&gt;weightsize());
+        pb = new ProgressBar(&quot;Saving the final train preprocessed target records&quot;, train_target_gaussianized_vmat-&gt;length());
+        train_target_preprocessed_vector.resize(train_target_gaussianized_vmat-&gt;width());
+        for (int train_gaussianized_row = 0; train_gaussianized_row &lt; train_target_gaussianized_vmat-&gt;length(); train_gaussianized_row++)
+        {
+            train_target_gaussianized_vmat-&gt;getRow(train_gaussianized_row, train_target_preprocessed_vector);
+            train_target_preprocessed_file-&gt;putRow(train_gaussianized_row, train_target_preprocessed_vector);
+            pb-&gt;update( train_gaussianized_row );
+        }
+        delete pb;
+    }
+    
+    // defining all the variables for the test set
+    PPath                                 test_with_class_target_file_name;
+    VMat                                  test_with_class_target_file;
+    PPath                                 test_with_binary_fixed_file_name;
+    VMat                                  test_with_binary_fixed_file;
+    PPath                                 test_with_ind_file_name;
+    MissingIndicatorVMatrix*              test_with_ind_vmatrix;
+    VMat                                  test_with_ind_vmat;
+    PPath                                 test_with_dichotomies_file_name;
+    VMat                                  test_with_dichotomies_file;
+    SelectColumnsVMatrix*                 test_with_selected_columns_vmatrix;
+    VMat                                  test_with_selected_columns_vmat;
+    GaussianizeVMatrix*                   test_gaussianized_vmatrix;
+    VMat                                  test_gaussianized_vmat;
+    PPath                                 test_input_preprocessed_file_name;
+    VMat                                  test_input_preprocessed_file;
+    Vec                                   test_input_preprocessed_vector;
+    SelectColumnsVMatrix*                 test_target_with_selected_columns_vmatrix;
+    VMat                                  test_target_with_selected_columns_vmat;
+    GaussianizeVMatrix*                   test_target_gaussianized_vmatrix;
+    VMat                                  test_target_gaussianized_vmat;
+    PPath                                 test_target_preprocessed_file_name;
+    VMat                                  test_target_preprocessed_file;
+    Vec                                   test_target_preprocessed_vector;
+    
+    // managing the test set
+    cout &lt;&lt; endl &lt;&lt; &quot;********************&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;In Preprocessing: now, we format the test set&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 1 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The first step groups variables by type, skips untrustworthy variables, and generate class targets&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses ComputeDond2Target to transform base_test.pmat into step1_test_with_class_target.pmat&quot; &lt;&lt; endl;
+    output_path = &quot;step1_test_with_class_target&quot;;
+    test_with_class_target_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(test_with_class_target_file_name))
+    {
+        test_with_class_target_file = new FileVMatrix(test_with_class_target_file_name);
+        test_with_class_target_file-&gt;defineSizes(test_with_class_target_file-&gt;width(), 0, 0);
+        cout &lt;&lt; test_with_class_target_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        compute_target_learner = ::PLearn::deepCopy(compute_target_learner_template);
+        compute_target_learner-&gt;unknown_sales = 0;
+        compute_target_learner-&gt;output_path = output_path;
+        compute_target_learner-&gt;setTrainingSet(test_set, true);
+        test_with_class_target_file = compute_target_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 2 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Shuffling is not required for the test set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 3 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;For strictly binary variables, various situations arise: zero or non-zero, missing or not-missing, a given value or not, etc...&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step uses FixDond2BinaryVariables to create step3_test_with_binary_fixed.pmat with 0-1 binary variables.&quot; &lt;&lt; endl;
+    output_path = &quot;step3_test_with_binary_fixed&quot;;
+    test_with_binary_fixed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(test_with_binary_fixed_file_name))
+    {
+        test_with_binary_fixed_file = new FileVMatrix(test_with_binary_fixed_file_name);
+        test_with_binary_fixed_file-&gt;defineSizes(test_with_binary_fixed_file-&gt;width(), 0, 0);
+        cout &lt;&lt; test_with_binary_fixed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        fix_binary_variables_learner = ::PLearn::deepCopy(fix_binary_variables_template);
+        fix_binary_variables_learner-&gt;output_path = output_path;
+        fix_binary_variables_learner-&gt;setTrainingSet(test_with_class_target_file, true);
+        test_with_binary_fixed_file = fix_binary_variables_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 4 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step adds missing indicators variables to each variable with missing values.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses MissingIndicatorVMatrix to transform step3_test_with_binary_fixed.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 6&quot; &lt;&lt; endl;
+    output_path = &quot;step6_test_with_dichotomies&quot;;
+    test_with_dichotomies_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(test_with_dichotomies_file_name))
+    {
+        cout &lt;&lt; test_with_dichotomies_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_with_ind_vmatrix = new MissingIndicatorVMatrix();
+        test_with_ind_vmatrix-&gt;source = test_with_binary_fixed_file;
+        test_with_ind_vmatrix-&gt;train_set = train_with_binary_fixed_file;
+        test_with_ind_vmatrix-&gt;number_of_train_samples_to_use = 30000.0;
+        test_with_ind_vmatrix-&gt;build();
+        test_with_ind_vmat = test_with_ind_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 5 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Computing mean, median and mode is not required for the test set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 6 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This steps generates as many dichotomized variables as there are significant code values.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses DichotomizeDond2DiscreteVariables to transform the vmat from step 4 into step6_test_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    if (isfile(test_with_dichotomies_file_name))
+    {
+        test_with_dichotomies_file = new FileVMatrix(test_with_dichotomies_file_name);
+        test_with_dichotomies_file-&gt;defineSizes(test_with_dichotomies_file-&gt;width(), 0, 0);
+        cout &lt;&lt; test_with_dichotomies_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        dichotomize_discrete_variables_learner = new DichotomizeDond2DiscreteVariables();
+        dichotomize_discrete_variables_learner-&gt;discrete_variable_instructions = discrete_variable_instructions;
+        dichotomize_discrete_variables_learner-&gt;output_path = output_path;
+        dichotomize_discrete_variables_learner-&gt;setTrainingSet(test_with_ind_vmat, true);
+        test_with_dichotomies_file = dichotomize_discrete_variables_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 7 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Dichotomizing mean median and mode is not required for the test set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 8 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step select the desired columns from the test set to create the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses SelectColumnsVMatrix to transform step6_test_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 10&quot; &lt;&lt; endl;
+    output_path = &quot;final_test_input_preprocessed&quot;;
+    test_input_preprocessed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(test_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; test_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_with_selected_columns_vmatrix = new SelectColumnsVMatrix();
+        test_with_selected_columns_vmatrix-&gt;source = test_with_dichotomies_file;
+        test_with_selected_columns_vmatrix-&gt;fields_partial_match = 0;
+        test_with_selected_columns_vmatrix-&gt;extend_with_missing = 0;
+        test_with_selected_columns_vmatrix-&gt;fields = selected_variables_for_input;
+        test_with_selected_columns_vmatrix-&gt;build();
+        test_with_selected_columns_vmatrix-&gt;defineSizes(test_with_selected_columns_vmatrix-&gt;width(), 0, 0);
+        test_with_selected_columns_vmat = test_with_selected_columns_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 9 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Selecting variables for the mean, median and mode is not required for the test set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 10 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This gaussianizes the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses GaussianizeVMatrix to transform the vmat from step 8&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 12&quot; &lt;&lt; endl;
+    if (isfile(test_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; test_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_gaussianized_vmatrix = new GaussianizeVMatrix();
+        test_gaussianized_vmatrix-&gt;source = test_with_selected_columns_vmat;
+        test_gaussianized_vmatrix-&gt;train_source = train_with_selected_columns_vmat;
+        test_gaussianized_vmatrix-&gt;threshold_ratio = 1;
+        test_gaussianized_vmatrix-&gt;gaussianize_input = 1;
+        test_gaussianized_vmatrix-&gt;gaussianize_target = 0;
+        test_gaussianized_vmatrix-&gt;gaussianize_weight = 0;
+        test_gaussianized_vmatrix-&gt;gaussianize_extra = 0;
+        test_gaussianized_vmatrix-&gt;excluded_fields = inputs_excluded_from_gaussianization;
+        test_gaussianized_vmatrix-&gt;build();
+        test_gaussianized_vmat = test_gaussianized_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 11 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Gaussianizing the mean, meadian and mode is not required for the test set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 12 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Finaly, the preprocessed input vectors are store on disk.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The vmat from step 10 is converted to final_test_input_preprocessed.pmat.&quot; &lt;&lt; endl;
+    if (isfile(test_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; test_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_input_preprocessed_file = new FileVMatrix(test_input_preprocessed_file_name, test_gaussianized_vmat-&gt;length(), test_gaussianized_vmat-&gt;fieldNames());
+        test_input_preprocessed_file-&gt;defineSizes(test_gaussianized_vmat-&gt;inputsize(), test_gaussianized_vmat-&gt;targetsize(), test_gaussianized_vmat-&gt;weightsize());
+        pb = new ProgressBar(&quot;Saving the final test preprocessed input records&quot;, test_gaussianized_vmat-&gt;length());
+        test_input_preprocessed_vector.resize(test_gaussianized_vmat-&gt;width());
+        for (int test_gaussianized_row = 0; test_gaussianized_row &lt; test_gaussianized_vmat-&gt;length(); test_gaussianized_row++)
+        {
+            test_gaussianized_vmat-&gt;getRow(test_gaussianized_row, test_input_preprocessed_vector);
+            test_input_preprocessed_file-&gt;putRow(test_gaussianized_row, test_input_preprocessed_vector);
+            pb-&gt;update( test_gaussianized_row );
+        }
+        delete pb;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 13 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Saving the final mean, median and mode is not required for the test set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 14 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step select the desired columns from the testing set to create the target records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses SelectColumnsVMatrix to transform step6_test_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 15&quot; &lt;&lt; endl;
+    output_path = &quot;final_test_target_preprocessed&quot;;
+    test_target_preprocessed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(test_target_preprocessed_file_name))
+    {
+        cout &lt;&lt; test_target_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_target_with_selected_columns_vmatrix = new SelectColumnsVMatrix();
+        test_target_with_selected_columns_vmatrix-&gt;source = test_with_dichotomies_file;
+        test_target_with_selected_columns_vmatrix-&gt;fields_partial_match = 0;
+        test_target_with_selected_columns_vmatrix-&gt;extend_with_missing = 0;
+        test_target_with_selected_columns_vmatrix-&gt;fields = selected_variables_for_target;
+        test_target_with_selected_columns_vmatrix-&gt;build();
+        test_target_with_selected_columns_vmatrix-&gt;defineSizes(test_target_with_selected_columns_vmatrix-&gt;width(), 0, 0);
+        test_target_with_selected_columns_vmat = test_target_with_selected_columns_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 15 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This gaussianizes the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses GaussianizeVMatrix to transform the vmat from step 14&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 16&quot; &lt;&lt; endl;
+    if (isfile(test_target_preprocessed_file_name))
+    {
+        cout &lt;&lt; test_target_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_target_gaussianized_vmatrix = new GaussianizeVMatrix();
+        test_target_gaussianized_vmatrix-&gt;source = test_target_with_selected_columns_vmat;
+        test_target_gaussianized_vmatrix-&gt;train_source = train_target_with_selected_columns_vmat;
+        test_target_gaussianized_vmatrix-&gt;threshold_ratio = 1;
+        test_target_gaussianized_vmatrix-&gt;gaussianize_input = 1;
+        test_target_gaussianized_vmatrix-&gt;gaussianize_target = 0;
+        test_target_gaussianized_vmatrix-&gt;gaussianize_weight = 0;
+        test_target_gaussianized_vmatrix-&gt;gaussianize_extra = 0;
+        test_target_gaussianized_vmatrix-&gt;excluded_fields = targets_excluded_from_gaussianization;;
+        test_target_gaussianized_vmatrix-&gt;build();
+        test_target_gaussianized_vmat = test_target_gaussianized_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 16 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Finaly, the preprocessed input vectors are store on disk.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The vmat from step 15 is converted to final_test_target_preprocessed.pmat.&quot; &lt;&lt; endl;
+    if (isfile(test_target_preprocessed_file_name))
+    {
+        cout &lt;&lt; test_target_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        test_target_preprocessed_file = new FileVMatrix(test_target_preprocessed_file_name, test_target_gaussianized_vmat-&gt;length(),
+                                                         test_target_gaussianized_vmat-&gt;fieldNames());
+        test_target_preprocessed_file-&gt;defineSizes(test_target_gaussianized_vmat-&gt;inputsize(), test_target_gaussianized_vmat-&gt;targetsize(),
+                                                   test_target_gaussianized_vmat-&gt;weightsize());
+        pb = new ProgressBar(&quot;Saving the final test preprocessed target records&quot;, test_target_gaussianized_vmat-&gt;length());
+        test_target_preprocessed_vector.resize(test_target_gaussianized_vmat-&gt;width());
+        for (int test_gaussianized_row = 0; test_gaussianized_row &lt; test_target_gaussianized_vmat-&gt;length(); test_gaussianized_row++)
+        {
+            test_target_gaussianized_vmat-&gt;getRow(test_gaussianized_row, test_target_preprocessed_vector);
+            test_target_preprocessed_file-&gt;putRow(test_gaussianized_row, test_target_preprocessed_vector);
+            pb-&gt;update( test_gaussianized_row );
+        }
+        delete pb;
+    }
+    
+    // defining all the variables for the unknown set
+    PPath                                 unknown_with_class_target_file_name;
+    VMat                                  unknown_with_class_target_file;
+    PPath                                 unknown_with_binary_fixed_file_name;
+    VMat                                  unknown_with_binary_fixed_file;
+    PPath                                 unknown_with_ind_file_name;
+    MissingIndicatorVMatrix*              unknown_with_ind_vmatrix;
+    VMat                                  unknown_with_ind_vmat;
+    PPath                                 unknown_with_dichotomies_file_name;
+    VMat                                  unknown_with_dichotomies_file;
+    SelectColumnsVMatrix*                 unknown_with_selected_columns_vmatrix;
+    VMat                                  unknown_with_selected_columns_vmat;
+    GaussianizeVMatrix*                   unknown_gaussianized_vmatrix;
+    VMat                                  unknown_gaussianized_vmat;
+    PPath                                 unknown_input_preprocessed_file_name;
+    VMat                                  unknown_input_preprocessed_file;
+    Vec                                   unknown_input_preprocessed_vector;
+    
+    // managing the unknown set
+    cout &lt;&lt; endl &lt;&lt; &quot;********************&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;In Preprocessing: finally, we format the unknown set&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 1 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The first step groups variables by type, skips untrustworthy variables, and generate class targets&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses ComputeDond2Target to transform base_unknown.pmat into step1_unknown_with_class_target.pmat&quot; &lt;&lt; endl;
+    output_path = &quot;step1_unknown_with_class_target&quot;;
+    unknown_with_class_target_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(unknown_with_class_target_file_name))
+    {
+        unknown_with_class_target_file = new FileVMatrix(unknown_with_class_target_file_name);
+        unknown_with_class_target_file-&gt;defineSizes(unknown_with_class_target_file-&gt;width(), 0, 0);
+        cout &lt;&lt; unknown_with_class_target_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        compute_target_learner = ::PLearn::deepCopy(compute_target_learner_template);
+        compute_target_learner-&gt;unknown_sales = 1;
+        compute_target_learner-&gt;output_path = output_path;
+        compute_target_learner-&gt;setTrainingSet(unknown_set, true);
+        unknown_with_class_target_file = compute_target_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 2 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Shuffling is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 3 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;For strictly binary variables, various situations arise: zero or non-zero, missing or not-missing, a given value or not, etc...&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step uses FixDond2BinaryVariables to create step3_unknown_with_binary_fixed.pmat with 0-1 binary variables.&quot; &lt;&lt; endl;
+    output_path = &quot;step3_unknown_with_binary_fixed&quot;;
+    unknown_with_binary_fixed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(unknown_with_binary_fixed_file_name))
+    {
+        unknown_with_binary_fixed_file = new FileVMatrix(unknown_with_binary_fixed_file_name);
+        unknown_with_binary_fixed_file-&gt;defineSizes(unknown_with_binary_fixed_file-&gt;width(), 0, 0);
+        cout &lt;&lt; unknown_with_binary_fixed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        fix_binary_variables_learner = ::PLearn::deepCopy(fix_binary_variables_template);
+        fix_binary_variables_learner-&gt;output_path = output_path;
+        fix_binary_variables_learner-&gt;setTrainingSet(unknown_with_class_target_file, true);
+        unknown_with_binary_fixed_file = fix_binary_variables_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 4 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step adds missing indicators variables to each variable with missing values.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses MissingIndicatorVMatrix to transform step3_unknown_with_binary_fixed.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 6&quot; &lt;&lt; endl;
+    output_path = &quot;step6_unknown_with_dichotomies&quot;;
+    unknown_with_dichotomies_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(unknown_with_dichotomies_file_name))
+    {
+        cout &lt;&lt; unknown_with_dichotomies_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        unknown_with_ind_vmatrix = new MissingIndicatorVMatrix();
+        unknown_with_ind_vmatrix-&gt;source = unknown_with_binary_fixed_file;
+        unknown_with_ind_vmatrix-&gt;train_set = train_with_binary_fixed_file;
+        unknown_with_ind_vmatrix-&gt;number_of_train_samples_to_use = 30000.0;
+        unknown_with_ind_vmatrix-&gt;build();
+        unknown_with_ind_vmat = unknown_with_ind_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 5 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Computing mean, median and mode is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 6 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This steps generates as many dichotomized variables as there are significant code values.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses DichotomizeDond2DiscreteVariables to transform the vmat from step 4 into step6_unknown_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    if (isfile(unknown_with_dichotomies_file_name))
+    {
+        unknown_with_dichotomies_file = new FileVMatrix(unknown_with_dichotomies_file_name);
+        unknown_with_dichotomies_file-&gt;defineSizes(unknown_with_dichotomies_file-&gt;width(), 0, 0);
+        cout &lt;&lt; unknown_with_dichotomies_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        dichotomize_discrete_variables_learner = new DichotomizeDond2DiscreteVariables();
+        dichotomize_discrete_variables_learner-&gt;discrete_variable_instructions = discrete_variable_instructions;
+        dichotomize_discrete_variables_learner-&gt;output_path = output_path;
+        dichotomize_discrete_variables_learner-&gt;setTrainingSet(unknown_with_ind_vmat, true);
+        unknown_with_dichotomies_file = dichotomize_discrete_variables_learner-&gt;getOutputFile();
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 7 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Dichotomizing mean median and mode is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 8 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This step select the desired columns from the unknown set to create the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses SelectColumnsVMatrix to transform step6_unknown_with_dichotomies.pmat&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 10&quot; &lt;&lt; endl;
+    output_path = &quot;final_unknown_input_preprocessed&quot;;
+    unknown_input_preprocessed_file_name = output_path + &quot;.pmat&quot;;
+    if (isfile(unknown_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; unknown_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        unknown_with_selected_columns_vmatrix = new SelectColumnsVMatrix();
+        unknown_with_selected_columns_vmatrix-&gt;source = unknown_with_dichotomies_file;
+        unknown_with_selected_columns_vmatrix-&gt;fields_partial_match = 0;
+        unknown_with_selected_columns_vmatrix-&gt;extend_with_missing = 0;
+        unknown_with_selected_columns_vmatrix-&gt;fields = selected_variables_for_input;
+        unknown_with_selected_columns_vmatrix-&gt;build();
+        unknown_with_selected_columns_vmatrix-&gt;defineSizes(unknown_with_selected_columns_vmatrix-&gt;width(), 0, 0);
+        unknown_with_selected_columns_vmat = unknown_with_selected_columns_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 9 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Selecting variables for the mean, median and mode is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 10 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;This gaussianizes the input records.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;It uses GaussianizeVMatrix to transform the vmat from step 8&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The resulting vitual view is not stored on disk, it is fed as input to step 12&quot; &lt;&lt; endl;
+    if (isfile(unknown_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; unknown_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        unknown_gaussianized_vmatrix = new GaussianizeVMatrix();
+        unknown_gaussianized_vmatrix-&gt;source = unknown_with_selected_columns_vmat;
+        unknown_gaussianized_vmatrix-&gt;train_source = train_with_selected_columns_vmat;
+        unknown_gaussianized_vmatrix-&gt;threshold_ratio = 1;
+        unknown_gaussianized_vmatrix-&gt;gaussianize_input = 1;
+        unknown_gaussianized_vmatrix-&gt;gaussianize_target = 0;
+        unknown_gaussianized_vmatrix-&gt;gaussianize_weight = 0;
+        unknown_gaussianized_vmatrix-&gt;gaussianize_extra = 0;
+        unknown_gaussianized_vmatrix-&gt;excluded_fields = inputs_excluded_from_gaussianization;
+        unknown_gaussianized_vmatrix-&gt;build();
+        unknown_gaussianized_vmat = unknown_gaussianized_vmatrix;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 11 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Gaussianizing the mean, meadian and mode is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 12 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Finaly, the preprocessed input vectors are store on disk.&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;The vmat from step 10 is converted to final_unknown_input_preprocessed.pmat.&quot; &lt;&lt; endl;
+    if (isfile(unknown_input_preprocessed_file_name))
+    {
+        cout &lt;&lt; unknown_input_preprocessed_file_name &lt;&lt; &quot; already exist, we are skipping this step.&quot; &lt;&lt; endl;
+    }
+    else 
+    {
+        unknown_input_preprocessed_file = new FileVMatrix(unknown_input_preprocessed_file_name, unknown_gaussianized_vmat-&gt;length(), unknown_gaussianized_vmat-&gt;fieldNames());
+        unknown_input_preprocessed_file-&gt;defineSizes(unknown_gaussianized_vmat-&gt;inputsize(), unknown_gaussianized_vmat-&gt;targetsize(), unknown_gaussianized_vmat-&gt;weightsize());
+        pb = new ProgressBar(&quot;Saving the final unknown preprocessed input records&quot;, unknown_gaussianized_vmat-&gt;length());
+        unknown_input_preprocessed_vector.resize(unknown_gaussianized_vmat-&gt;width());
+        for (int unknown_gaussianized_row = 0; unknown_gaussianized_row &lt; unknown_gaussianized_vmat-&gt;length(); unknown_gaussianized_row++)
+        {
+            unknown_gaussianized_vmat-&gt;getRow(unknown_gaussianized_row, unknown_input_preprocessed_vector);
+            unknown_input_preprocessed_file-&gt;putRow(unknown_gaussianized_row, unknown_input_preprocessed_vector);
+            pb-&gt;update( unknown_gaussianized_row );
+        }
+        delete pb;
+    }
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 13 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Saving the final mean, median and mode is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 14 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Saving the final target preprocessed records is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 15 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Saving the final target preprocessed records is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+    cout &lt;&lt; endl &lt;&lt; &quot;****** STEP 16 ******&quot; &lt;&lt; endl;
+    cout &lt;&lt; &quot;Saving the final target preprocessed records is not required for the unknown set, skipped.&quot; &lt;&lt; endl;
+}
+
+void Preprocessing::train()
+{
+}
+
+int Preprocessing::outputsize() const {return 0;}
+void Preprocessing::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void Preprocessing::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; Preprocessing::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; Preprocessing::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/Preprocessing.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,161 @@
+// -*- C++ -*-
+
+// Preprocessing.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file Preprocessing.h */
+
+
+#ifndef Preprocessing_INC
+#define Preprocessing_INC
+
+#include &lt;plearn_learners/second_iteration/ComputeDond2Target.h&gt;
+#include &lt;plearn_learners/second_iteration/FixDond2BinaryVariables.h&gt;
+#include &lt;plearn_learners/second_iteration/DichotomizeDond2DiscreteVariables.h&gt;
+#include &lt;plearn_learners/second_iteration/MeanMedianModeImputationVMatrix.h&gt;
+#include &lt;plearn_learners/second_iteration/GaussianizeVMatrix.h&gt;
+#include &lt;plearn_learners/second_iteration/MissingIndicatorVMatrix.h&gt;     //!&lt;  For the missing indicators stuff.
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/testers/PTester.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/vmat/MemoryVMatrix.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class Preprocessing : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! The test data set.
+    VMat test_set;
+    //! The unknown data set.
+    VMat unknown_set;
+    //! The template of the script to generate the class target.
+    PP&lt;ComputeDond2Target&gt; compute_target_learner_template;
+    //! The template of the script to fix the binary variables.
+    PP&lt;FixDond2BinaryVariables&gt; fix_binary_variables_template;
+    //! Pairs of instruction of the form field_name : mean | median | mode.
+    TVec&lt; pair&lt;string, string&gt; &gt;  imputation_spec;
+    //! The instructions to fix the binary variables in the form of field_name : instruction.
+    //! Supported instructions are 9_is_one, not_0_is_one, not_missing_is_one, not_1000_is_one.
+    //! Variables with no specification will be kept as_is.
+    TVec&lt; pair&lt;string, TVec&lt; pair&lt;real, real&gt; &gt; &gt; &gt; discrete_variable_instructions;
+    //! The list of variables selected as input vector.
+    TVec&lt; string &gt; selected_variables_for_input;
+    //! The list of variables selected as target vector.
+    TVec&lt; string &gt; selected_variables_for_target;
+    //! The list of variables excluded from the gaussianization step.
+    TVec&lt; string &gt; inputs_excluded_from_gaussianization;
+    //! The list of variables excluded from the gaussianization step.
+    TVec&lt; string &gt; targets_excluded_from_gaussianization;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    Preprocessing();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(Preprocessing);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void manageTrainTestUnknownSets();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(Preprocessing);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,113 @@
+// -*- C++ -*-
+
+// SecondIterationTester.cc
+// 
+// Copyright (C) 2002 Pascal Vincent, Frederic Morin
+// 
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************      
+ * $Id: SecondIterationTester.cc 5587 2006-05-12 16:31:54Z plearner $ 
+ ******************************************************* */
+
+/*! \file SecondIterationTester.cc */
+#include &quot;SecondIterationTester.h&quot;
+
+
+namespace PLearn {
+using namespace std;
+
+SecondIterationTester::SecondIterationTester() 
+{}
+
+PLEARN_IMPLEMENT_OBJECT(
+    SecondIterationTester,
+    &quot;Manages a learning experiment, with training and estimation of generalization error.&quot;, 
+    &quot;The SecondIterationTester class allows you to describe a typical learning experiment that you wish to perform, \n&quot;
+    &quot;as a training/testing of a learning algorithm on a particular dataset.\n&quot;
+    &quot;The splitter is used to obtain one or several (such as for k-fold) splits of the dataset \n&quot;
+    &quot;and training/testing is performed on each split. \n&quot;
+    &quot;Requested statistics are computed, and all requested results are written in an appropriate \n&quot;
+    &quot;file inside the specified experiment directory. \n&quot;
+    &quot;Statistics can be either specified entirely from the 'statnames' option, or built from\n&quot;
+    &quot;'statnames' and 'statmask'. For instance, one may set:\n&quot;
+    &quot;   statnames = [ \&quot;NLL\&quot; \&quot;mse\&quot; ]\n&quot;
+    &quot;   statmask  = [ [ \&quot;E[*]\&quot; ] [ \&quot;test#1-2#.*\&quot; ] [ \&quot;E[*]\&quot; \&quot;STDERROR[*]\&quot; ] ]\n&quot;
+    &quot;and this will compute:\n&quot;
+    &quot;   E[test1.E[NLL]], STDERROR[test1.E[NLL]], E[test2.E[NLL]], STDERROR[test2.E[NLL]]\n&quot;
+    &quot;   E[test1.E[mse]], STDERROR[test1.E[mse]], E[test2.E[mse]], STDERROR[test2.E[mse]]\n&quot;
+    );
+
+
+void SecondIterationTester::declareOptions(OptionList&amp; ol)
+{
+    inherited::declareOptions(ol);
+}
+
+void SecondIterationTester::build_()
+{
+}
+
+// ### Nothing to add here, simply calls build_
+void SecondIterationTester::build()
+{
+    inherited::build();
+    build_();
+}
+
+////////////////////////////
+// setExperimentDirectory //
+////////////////////////////
+void SecondIterationTester::setSplitter(string splitter_template)
+{ 
+ //   splitter = ::PLearn::deepCopy(splitter_template);
+    splitter-&gt;build();
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void SecondIterationTester::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies) {
+    inherited::makeDeepCopyFromShallowCopy(copies);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationTester.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,117 @@
+// -*- C++ -*-
+
+// SecondIterationTester.h
+// 
+// Copyright (C) 2002 Pascal Vincent, Frederic Morin
+// 
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+/* *******************************************************      
+ * $Id: SecondIterationTester.h 5587 2006-05-12 16:31:54Z plearner $ 
+ ******************************************************* */
+
+/*! \file SecondIterationTester.h */
+#ifndef SecondIterationTester_INC
+#define SecondIterationTester_INC
+
+#include &lt;plearn/vmat/ExplicitSplitter.h&gt;
+#include &lt;plearn_learners/testers/PTester.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class SecondIterationTester: public PTester
+{    
+
+private:
+
+    typedef PTester inherited;
+
+public:
+
+    // ************************
+    // * public build options *
+    // ************************
+  
+    // See declareOptions method in .cc for the role of these options.
+
+    // ****************
+    // * Constructors *
+    // ****************
+
+    // Default constructor
+    SecondIterationTester();
+
+
+    // ******************
+    // * Object methods *
+    // ******************
+
+private: 
+    //! This does the actual building. 
+    // (Please implement in .cc)
+    void build_();
+
+protected: 
+    //! Declares this class' options
+    static void declareOptions(OptionList&amp; ol);
+
+public:
+    // simply calls inherited::build() then build_() 
+    virtual void build();
+
+    //! Declares name and deepCopy methods
+    PLEARN_DECLARE_OBJECT(SecondIterationTester);
+    
+  
+    //! This returns the currently set expdir (see setExperimentDirectory)
+    void setSplitter(string splitter_template);
+
+    //! Transforms a shallow copy into a deep copy
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+};
+
+DECLARE_OBJECT_PTR(SecondIterationTester);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,381 @@
+// -*- C++ -*-
+
+// SecondIterationWrapper.cc
+// Copyright (c) 1998-2002 Pascal Vincent
+// Copyright (C) 1999-2002 Yoshua Bengio and University of Montreal
+// Copyright (c) 2002 Jean-Sebastien Senecal, Xavier Saint-Mleux, Rejean Ducharme
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ********************************************************************************    
+ * $Id: SecondIterationWrapper.cc, v 1.0 2004/07/19 10:00:00 Bengio/Kegl/Godbout        *
+ * This file is part of the PLearn library.                                     *
+ ******************************************************************************** */
+
+#include &quot;SecondIterationWrapper.h&quot;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(SecondIterationWrapper,
+                        &quot;A PLearner to wrap around a generic regressor to calculate the predicted class.&quot;, 
+                        &quot;Algorithm built to wrap around a generic regressor in the context of the second iteration\n&quot;
+                        &quot;of the annual sales estimation project.\n&quot;
+                        &quot;It calculates the predicted class and computes the cse error.\n&quot;
+    );
+
+SecondIterationWrapper::SecondIterationWrapper()  
+  : class_prediction(1)
+{
+}
+
+SecondIterationWrapper::~SecondIterationWrapper()
+{
+}
+
+void SecondIterationWrapper::declareOptions(OptionList&amp; ol)
+{ 
+    declareOption(ol, &quot;class_prediction&quot;, &amp;SecondIterationWrapper::class_prediction, OptionBase::buildoption,
+                  &quot;When set to 1 (default), indicates the base regression is on the class target.\n&quot;
+                  &quot;Otherwise, we assume the regression is on the sales target.\n&quot;); 
+ 
+    declareOption(ol, &quot;base_regressor_template&quot;, &amp;SecondIterationWrapper::base_regressor_template, OptionBase::buildoption,
+                  &quot;The template for the base regressor to be used.\n&quot;);  
+ 
+    declareOption(ol, &quot;ref_train&quot;, &amp;SecondIterationWrapper::ref_train, OptionBase::buildoption,
+                  &quot;The reference set to compute train statistics.\n&quot;);  
+ 
+    declareOption(ol, &quot;ref_test&quot;, &amp;SecondIterationWrapper::ref_test, OptionBase::buildoption,
+                  &quot;The reference set to compute test statistice.\n&quot;);  
+ 
+    declareOption(ol, &quot;ref_sales&quot;, &amp;SecondIterationWrapper::ref_sales, OptionBase::buildoption,
+                  &quot;The reference set to de-gaussianize the prediction.\n&quot;); 
+ 
+    declareOption(ol, &quot;train_dataset&quot;, &amp;SecondIterationWrapper::train_dataset, OptionBase::buildoption,
+                  &quot;The train data set.\n&quot;); 
+ 
+    declareOption(ol, &quot;test_dataset&quot;, &amp;SecondIterationWrapper::test_dataset, OptionBase::buildoption,
+                  &quot;The test data set.\n&quot;); 
+      
+    declareOption(ol, &quot;base_regressor&quot;, &amp;SecondIterationWrapper::base_regressor, OptionBase::learntoption,
+                  &quot;The base regressor built from the template.\n&quot;);
+    inherited::declareOptions(ol);
+}
+
+void SecondIterationWrapper::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+    deepCopyField(class_prediction, copies);
+    deepCopyField(ref_train, copies);
+    deepCopyField(ref_test, copies);
+    deepCopyField(ref_sales, copies);
+    deepCopyField(test_dataset, copies);
+    deepCopyField(base_regressor_template, copies);
+    deepCopyField(base_regressor, copies);
+}
+
+void SecondIterationWrapper::build()
+{
+    inherited::build();
+    build_();
+}
+
+void SecondIterationWrapper::build_()
+{
+    if (train_set)
+    {
+        if (class_prediction == 0)
+            if(!ref_train || !ref_test || !ref_test || !train_dataset || !test_dataset)
+                PLERROR(&quot;In SecondIterationWrapper: missing reference data sets to compute statistics&quot;);
+        margin = 0;
+        loan = 1;
+        sales = 2;
+        tclass = 3;
+        base_regressor = ::PLearn::deepCopy(base_regressor_template);
+        base_regressor-&gt;setTrainingSet(train_set, true);
+        base_regressor-&gt;setTrainStatsCollector(new VecStatsCollector);
+        if (class_prediction == 0) search_table = ref_sales-&gt;toMat();
+    }
+}
+
+void SecondIterationWrapper::train()
+{
+    base_regressor-&gt;setOption(&quot;nstages&quot;, tostring(nstages));
+    base_regressor-&gt;train();
+    if (class_prediction == 1) computeClassStatistics();
+    else computeSalesStatistics();
+}
+
+void SecondIterationWrapper::computeClassStatistics()
+{
+    int row;
+    Vec sample_input(train_set-&gt;inputsize());
+    Vec sample_target(train_set-&gt;targetsize());
+    real sample_weight;
+    Vec sample_output(base_regressor-&gt;outputsize());
+    Vec sample_costs(3);
+    ProgressBar* pb = NULL;
+    if (report_progress)
+    {
+        pb = new ProgressBar(&quot;Second Iteration : computing the train statistics: &quot;, train_set-&gt;length());
+    } 
+    train_stats-&gt;forget();
+    for (row = 0; row &lt; train_set-&gt;length(); row++)
+    {  
+        train_set-&gt;getExample(row, sample_input, sample_target, sample_weight);
+        computeOutput(sample_input, sample_output);
+        computeCostsFromOutputs(sample_input, sample_output, sample_target, sample_costs); 
+        train_stats-&gt;update(sample_costs);
+        if (report_progress) pb-&gt;update(row);
+    }
+    train_stats-&gt;finalize();
+    if (report_progress) delete pb; 
+}
+
+void SecondIterationWrapper::computeSalesStatistics()
+{
+    int row;
+    Vec sample_input(train_set-&gt;inputsize());
+    Vec sample_target(train_set-&gt;targetsize());
+    Vec reference_vector(ref_train-&gt;width());
+    real sample_weight;
+    Vec sample_output(base_regressor-&gt;outputsize());
+    Vec sample_costs(3);
+    Vec train_mean(3);
+    Vec train_std_error(3);
+    Vec valid_mean(3);
+    Vec valid_std_error(3);
+    Vec test_mean(3);
+    Vec test_std_error(3);
+    real sales_prediction;
+    real commitment;
+    real predicted_class;
+    ProgressBar* pb = NULL;
+    if (report_progress)
+    {
+        pb = new ProgressBar(&quot;Second Iteration : computing the train statistics: &quot;, train_set-&gt;length());
+    } 
+    train_stats-&gt;forget();
+    for (row = 0; row &lt; train_set-&gt;length(); row++)
+    {  
+        train_set-&gt;getExample(row, sample_input, sample_target, sample_weight);
+        ref_train-&gt;getRow(row, reference_vector);
+        computeOutput(sample_input, sample_output);
+        sales_prediction = deGaussianize(sample_output[0]);
+        commitment = 0.0;
+        if (!is_missing(reference_vector[margin])) commitment += reference_vector[margin];
+        if (!is_missing(reference_vector[loan])) commitment += reference_vector[loan];
+        if (sales_prediction &lt; 1000000.0 &amp;&amp; commitment &lt; 200000.0) predicted_class = 1.0;
+        else if (sales_prediction &lt; 10000000.0 &amp;&amp; commitment &lt; 1000000.0) predicted_class = 2.0;
+        else if (sales_prediction &lt; 100000000.0 &amp;&amp; commitment &lt; 20000000.0) predicted_class = 3.0;
+        else predicted_class = 4.0;
+        sample_costs[0] = pow((sales_prediction - reference_vector[sales]), 2.0);
+        sample_costs[1] = pow((predicted_class - reference_vector[tclass]), 2.0);
+        if (predicted_class == reference_vector[tclass]) sample_costs[2] = 0.0;
+        else sample_costs[2] = 1.0;
+        train_stats-&gt;update(sample_costs);
+        if (report_progress) pb-&gt;update(row);
+    }
+    train_stats-&gt;finalize();
+    train_mean &lt;&lt; train_stats-&gt;getMean();
+    train_std_error &lt;&lt; train_stats-&gt;getStdError();
+    if (report_progress) delete pb; 
+    if (report_progress)
+    {
+        pb = new ProgressBar(&quot;Second Iteration : computing the valid statistics: &quot;, train_dataset-&gt;length() - train_set-&gt;length());
+    } 
+    train_stats-&gt;forget();
+    for (row = train_set-&gt;length(); row &lt; train_dataset-&gt;length(); row++)
+    {  
+        train_dataset-&gt;getExample(row, sample_input, sample_target, sample_weight);
+        ref_train-&gt;getRow(row, reference_vector);
+        computeOutput(sample_input, sample_output);
+        sales_prediction = deGaussianize(sample_output[0]);
+        commitment = 0.0;
+        if (!is_missing(reference_vector[margin])) commitment += reference_vector[margin];
+        if (!is_missing(reference_vector[loan])) commitment += reference_vector[loan];
+        if (sales_prediction &lt; 1000000.0 &amp;&amp; commitment &lt; 200000.0) predicted_class = 1.0;
+        else if (sales_prediction &lt; 10000000.0 &amp;&amp; commitment &lt; 1000000.0) predicted_class = 2.0;
+        else if (sales_prediction &lt; 100000000.0 &amp;&amp; commitment &lt; 20000000.0) predicted_class = 3.0;
+        else predicted_class = 4.0;
+        sample_costs[0] = pow((sales_prediction - reference_vector[sales]), 2.0);
+        sample_costs[1] = pow((predicted_class - reference_vector[tclass]), 2.0);
+        if (predicted_class == reference_vector[tclass]) sample_costs[2] = 0.0;
+        else sample_costs[2] = 1.0;
+        train_stats-&gt;update(sample_costs);
+        if (report_progress) pb-&gt;update(row);
+    }
+    train_stats-&gt;finalize();
+    valid_mean &lt;&lt; train_stats-&gt;getMean();
+    valid_std_error &lt;&lt; train_stats-&gt;getStdError();
+    if (report_progress) delete pb; 
+    if (report_progress)
+    {
+        pb = new ProgressBar(&quot;Second Iteration : computing the test statistics: &quot;, test_dataset-&gt;length());
+    } 
+    train_stats-&gt;forget();
+    for (row = 0; row &lt; test_dataset-&gt;length(); row++)
+    {  
+        test_dataset-&gt;getExample(row, sample_input, sample_target, sample_weight);
+        ref_test-&gt;getRow(row, reference_vector);
+        computeOutput(sample_input, sample_output);
+        sales_prediction = deGaussianize(sample_output[0]);
+        commitment = 0.0;
+        if (!is_missing(reference_vector[margin])) commitment += reference_vector[margin];
+        if (!is_missing(reference_vector[loan])) commitment += reference_vector[loan];
+        if (sales_prediction &lt; 1000000.0 &amp;&amp; commitment &lt; 200000.0) predicted_class = 1.0;
+        else if (sales_prediction &lt; 10000000.0 &amp;&amp; commitment &lt; 1000000.0) predicted_class = 2.0;
+        else if (sales_prediction &lt; 100000000.0 &amp;&amp; commitment &lt; 20000000.0) predicted_class = 3.0;
+        else predicted_class = 4.0;
+        sample_costs[0] = pow((sales_prediction - reference_vector[sales]), 2.0);
+        sample_costs[1] = pow((predicted_class - reference_vector[tclass]), 2.0);
+        if (predicted_class == reference_vector[tclass]) sample_costs[2] = 0.0;
+        else sample_costs[2] = 1.0;
+        train_stats-&gt;update(sample_costs);
+        if (report_progress) pb-&gt;update(row);
+    }
+    train_stats-&gt;finalize();
+    test_mean &lt;&lt; train_stats-&gt;getMean();
+    test_std_error &lt;&lt; train_stats-&gt;getStdError();
+    if (report_progress) delete pb;
+    TVec&lt;string&gt; stat_names(6);
+    stat_names[0] = &quot;mse&quot;;
+    stat_names[1] = &quot;mse_stderr&quot;;
+    stat_names[2] = &quot;cse&quot;;
+    stat_names[3] = &quot;cse_stderr&quot;;
+    stat_names[4] = &quot;cle&quot;;
+    stat_names[5] = &quot;cle_stderr&quot;;
+    VMat stat_file = new FileVMatrix(expdir + &quot;class_stats.pmat&quot;, 3, stat_names);
+    stat_file-&gt;put(0, 0, train_mean[0]);
+    stat_file-&gt;put(0, 1, train_std_error[0]);
+    stat_file-&gt;put(0, 2, train_mean[1]);
+    stat_file-&gt;put(0, 3, train_std_error[1]);
+    stat_file-&gt;put(0, 4, train_mean[2]);
+    stat_file-&gt;put(0, 5, train_std_error[2]);
+    stat_file-&gt;put(1, 0, valid_mean[0]);
+    stat_file-&gt;put(1, 1, valid_std_error[0]);
+    stat_file-&gt;put(1, 2, valid_mean[1]);
+    stat_file-&gt;put(1, 3, valid_std_error[1]);
+    stat_file-&gt;put(1, 4, valid_mean[2]);
+    stat_file-&gt;put(1, 5, valid_std_error[2]);
+    stat_file-&gt;put(2, 0, test_mean[0]);
+    stat_file-&gt;put(2, 1, test_std_error[0]);
+    stat_file-&gt;put(2, 2, test_mean[1]);
+    stat_file-&gt;put(2, 3, test_std_error[1]);
+    stat_file-&gt;put(2, 4, test_mean[2]);
+    stat_file-&gt;put(2, 5, test_std_error[2]);
+}
+
+real SecondIterationWrapper::deGaussianize(real prediction)
+{
+    if (prediction &lt; search_table(0, 0)) return search_table(0, 1);
+    if (prediction &gt; search_table(search_table.length() - 1, 0)) return search_table(search_table.length() - 1, 1);
+    int mid;
+    int min = 0;
+    int max = search_table.length() - 1;
+    while (max - min &gt; 1)
+    {
+        mid = (max + min) / 2;
+        real mid_val = search_table(mid, 0);
+        if (prediction &lt; mid_val) max = mid;
+        else if (prediction &gt; mid_val) min = mid;
+        else min = max = mid;
+    }
+    if (min == max) return search_table(min, 1);
+    return (search_table(min, 1) + search_table(max, 1)) / 2.0;
+}
+
+void SecondIterationWrapper::forget()
+{
+}
+
+int SecondIterationWrapper::outputsize() const
+{
+    return base_regressor-&gt;outputsize();
+}
+
+TVec&lt;string&gt; SecondIterationWrapper::getTrainCostNames() const
+{
+    TVec&lt;string&gt; return_msg(3);
+    return_msg[0] = &quot;mse&quot;;
+    return_msg[1] = &quot;cse&quot;;
+    return_msg[2] = &quot;cle&quot;;
+    return return_msg;
+}
+
+TVec&lt;string&gt; SecondIterationWrapper::getTestCostNames() const
+{ 
+    return getTrainCostNames();
+}
+
+void SecondIterationWrapper::computeOutput(const Vec&amp; inputv, Vec&amp; outputv) const
+{
+    base_regressor-&gt;computeOutput(inputv, outputv);
+}
+
+void SecondIterationWrapper::computeOutputAndCosts(const Vec&amp; inputv, const Vec&amp; targetv, Vec&amp; outputv, Vec&amp; costsv) const
+{
+    computeOutput(inputv, outputv);
+    computeCostsFromOutputs(inputv, outputv, targetv, costsv);
+}
+
+void SecondIterationWrapper::computeCostsFromOutputs(const Vec&amp; inputv, const Vec&amp; outputv, const Vec&amp; targetv, Vec&amp; costsv) const
+{
+    costsv[0] = pow((outputv[0] - targetv[0]), 2.0);
+    if (class_prediction == 1)
+    {
+        real class_pred;
+        if (outputv[0] &lt;= 1.5) class_pred = 1.0;
+        else if (outputv[0] &lt;= 2.5) class_pred = 2.0;
+        else class_pred = 3.0;
+        costsv[1] = pow((class_pred - targetv[0]), 2.0);
+        if (class_pred == targetv[0]) costsv[2] = 0.0;
+        else costsv[2] = 1.0;
+        return;
+    }
+    costsv[1] = 0.0;
+    costsv[2] = 0.0;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/SecondIterationWrapper.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,131 @@
+// -*- C++ -*-
+
+// SecondIterationWrapper.h
+// Copyright (c) 1998-2002 Pascal Vincent
+// Copyright (C) 1999-2002 Yoshua Bengio and University of Montreal
+// Copyright (c) 2002 Jean-Sebastien Senecal, Xavier Saint-Mleux, Rejean Ducharme
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* ********************************************************************************    
+ * $Id: SecondIterationWrapper.h, v 1.0 2004/07/19 10:00:00 Bengio/Kegl/Godbout   *
+ * This file is part of the PLearn library.                                     *
+ ******************************************************************************** */
+
+/*! \file PLearnLibrary/PLearnAlgo/SecondIterationWrapper.h */
+
+#ifndef SecondIterationWrapper_INC
+#define SecondIterationWrapper_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn/base/stringutils.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+class SecondIterationWrapper: public PLearner
+{
+    typedef PLearner inherited;
+  
+private:
+
+/*
+  Build options: they have to be set before training
+*/
+
+    int class_prediction;
+    VMat ref_train;
+    VMat ref_test;
+    VMat ref_sales;
+    VMat train_dataset;
+    VMat test_dataset;
+    PP&lt;PLearner&gt; base_regressor_template;                     // template for a generic regressor as the base learner to be boosted 
+  
+/*
+  Learnt options: they are sized and initialized if need be, at stage 0
+*/
+
+
+    PP&lt;PLearner&gt; base_regressor;                              // base regressors built at each boosting stage 
+ 
+/*
+  Work fields: they are sized and initialized if need be, at buid time
+*/ 
+    int margin;
+    int loan;
+    int sales;
+    int tclass;
+    Mat search_table;
+    
+   
+  
+public:
+    SecondIterationWrapper();
+    virtual              ~SecondIterationWrapper();
+    
+    PLEARN_DECLARE_OBJECT(SecondIterationWrapper);
+
+    static  void         declareOptions(OptionList&amp; ol);
+    virtual void         makeDeepCopyFromShallowCopy(CopiesMap &amp;copies);
+    virtual void         build();
+    virtual void         train();
+    virtual void         forget();
+    virtual int          outputsize() const;
+    virtual TVec&lt;string&gt; getTrainCostNames() const;
+    virtual TVec&lt;string&gt; getTestCostNames() const;
+    virtual void         computeOutput(const Vec&amp; input, Vec&amp; output) const;
+    virtual void         computeOutputAndCosts(const Vec&amp; input, const Vec&amp; target, Vec&amp; output, Vec&amp; costs) const;
+    virtual void         computeCostsFromOutputs(const Vec&amp; input, const Vec&amp; output, const Vec&amp; target, Vec&amp; costs) const;
+  
+private:
+    void         build_();
+    void         computeClassStatistics();
+    void         computeSalesStatistics();
+    real         deGaussianize(real prediction);
+};
+
+DECLARE_OBJECT_PTR(SecondIterationWrapper);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,609 @@
+// -*- C++ -*-
+
+// TestImputations.cc
+//
+// Copyright (C) 2006 Dan Popovici, Pascal Lamblin
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file TestImputations.cc */
+
+#define PL_LOG_MODULE_NAME &quot;TestImputations&quot;
+#include &lt;plearn/io/pl_log.h&gt;
+
+#include &quot;TestImputations.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+PLEARN_IMPLEMENT_OBJECT(
+    TestImputations,
+    &quot;Computes imputations errors using various imputation methods.&quot;,
+    &quot;name of the discrete variable, of the target and the values to check are options.\n&quot;
+);
+
+/////////////////////////
+// TestImputations //
+/////////////////////////
+TestImputations::TestImputations()
+{
+}
+    
+////////////////////
+// declareOptions //
+////////////////////
+void TestImputations::declareOptions(OptionList&amp; ol)
+{
+
+    declareOption(ol, &quot;min_number_of_samples&quot;, &amp;TestImputations::min_number_of_samples,
+                  OptionBase::buildoption,
+                  &quot;The minimum number of samples required to test imputations for a variable.&quot;);
+    declareOption(ol, &quot;max_number_of_samples&quot;, &amp;TestImputations::max_number_of_samples,
+                  OptionBase::buildoption,
+                  &quot;The maximum number of samples used to test imputations for a variable.&quot;);
+    declareOption(ol, &quot;mean_median_mode_file_name&quot;, &amp;TestImputations::mean_median_mode_file_name,
+                  OptionBase::buildoption,
+                  &quot;The Path of the file with those statistics for all the variables.&quot;);
+    declareOption(ol, &quot;tree_conditional_mean_directory&quot;, &amp;TestImputations::tree_conditional_mean_directory,
+                  OptionBase::buildoption,
+                  &quot;The Path of the dircetory containing the tree conditional means computed for each variable.&quot;);
+    declareOption(ol, &quot;covariance_preservation_file_name&quot;, &amp;TestImputations::covariance_preservation_file_name,
+                  OptionBase::buildoption,
+                  &quot;The Path of the file with the train_set empirically observed covariances and means.&quot;);
+    declareOption(ol, &quot;reference_set_with_covpres&quot;, &amp;TestImputations::reference_set_with_covpres,
+                  OptionBase::buildoption,
+                  &quot;The reference set corresponding to the index computed with the ball_tree, with the initial imputations.&quot;);
+    declareOption(ol, &quot;reference_set_with_missing&quot;, &amp;TestImputations::reference_set_with_missing,
+                  OptionBase::buildoption,
+                  &quot;The reference set corresponding to the index computed with the ball_tree, with missing values.&quot;);
+    declareOption(ol, &quot;missing_indicators&quot;, &amp;TestImputations::missing_indicators,
+                  OptionBase::buildoption,
+                  &quot;The vector of missing indicator field names to be excluded in the distance computation.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+/////////////////////////////////
+// makeDeepCopyFromShallowCopy //
+/////////////////////////////////
+void TestImputations::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    deepCopyField(min_number_of_samples, copies);
+    deepCopyField(max_number_of_samples, copies);
+    deepCopyField(mean_median_mode_file_name, copies);
+    deepCopyField(tree_conditional_mean_directory, copies);
+    deepCopyField(covariance_preservation_file_name, copies);
+    deepCopyField(reference_set_with_covpres, copies);
+    deepCopyField(reference_set_with_missing, copies);
+    deepCopyField(missing_indicators, copies);
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+}
+
+///////////
+// build //
+///////////
+void TestImputations::build()
+{
+    // ### Nothing to add here, simply calls build_().
+    inherited::build();
+    build_();
+}
+
+////////////
+// build_ //
+////////////
+void TestImputations::build_()
+{
+/*
+  for each variable with missing values in the train set(which is in this case the test set)
+    - radomly choose up to n samples with a value in the variable
+    - build a set with these samples replacing the value with missing
+    - perform the various type of imputations and compute the errors
+  valider meanmedianmode, treeconditionalmean  covariancepreservation, neighborhood
+  create a Mat: width is #of variables with missing values
+  row 0: nb_present
+  row 1: mean/mode imputation from preprocessing/final_train_input_preprocessed.pmat.metadata/mean_median_mode_file.pmat
+  row 2: median/mode imputation from preprocessing/final_train_input_preprocessed.pmat.metadata/mean_median_mode_file.pmat
+  row 3: treeconditionalmean imputation from prep/data/targeted_ind_no_imp.vmat.metadata/TreeCondMean/dir/'field_names'/Split0/test1_outputs.pmat
+  row 4: covariance preservation imputation from preprocessing/final_train_input_preprocessed.pmat.metadata/covariance_file.pmat
+  row 5 to 24: (row - 4) * i neighbors imputation from neighborhood/test_train_imputed_with_covariance_preservation.pmat.metadata/neighborhood_file.pmat
+  lire le train_set
+*/
+    MODULE_LOG &lt;&lt; &quot;build_() called&quot; &lt;&lt; endl;
+    if (train_set)
+    {
+        build_ball_tree();
+        for (int iteration = 1; iteration &lt;= 50; iteration++)
+        {
+            cout &lt;&lt; &quot;In TestImputations, Iteration # &quot; &lt;&lt; iteration &lt;&lt; endl;
+            initialize();
+            computeMeanMedianModeStats();
+            computeTreeCondMeanStats();
+            computeCovPresStats();
+            computeNeighborhoodStats();
+            train();
+        }
+        PLERROR(&quot;In TestImputations: we are done here&quot;);
+    }
+}
+
+void TestImputations::build_ball_tree()
+{
+    // initialize primary dataset
+    cout &lt;&lt; &quot;initialize the train set&quot; &lt;&lt; endl;
+    train_row = 0;
+    train_col = 0;
+    train_length = train_set-&gt;length();
+    train_width = train_set-&gt;width();
+    train_input.resize(train_width);
+    train_names.resize(train_width);
+    train_names &lt;&lt; train_set-&gt;fieldNames();
+    train_metadata = train_set-&gt;getMetaDataDir();
+    weights.resize(train_width);
+    weights.fill(1.0);
+    for (mi_col = 0; mi_col &lt; missing_indicators.length(); mi_col++)
+    {
+        for (train_col = 0; train_col &lt; train_width; train_col++)
+        {
+            if (missing_indicators[mi_col] != train_names[train_col]) continue;
+            weights[train_col] = 0.0;
+            break;
+        }
+        if (train_col &gt;= train_width)
+            PLERROR(&quot;In TestImputations:: no field with this name in input dataset: %s&quot;, (missing_indicators[mi_col]).c_str());
+    }
+    weighted_distance_kernel = new WeightedDistance(weights);
+/*
+    if (!reference_set_with_covpres) PLERROR(&quot;In TestImputations:: no reference_set_with_covpres provided.&quot;);
+    if (!reference_set_with_missing) PLERROR(&quot;In TestImputations:: no reference_set_with_missing provided.&quot;);
+    ball_tree = new BallTreeNearestNeighbors();
+    ball_tree-&gt;setOption(&quot;rmin&quot;, &quot;1&quot;);
+    ball_tree-&gt;setOption(&quot;train_method&quot;, &quot;anchor&quot;);
+    ball_tree-&gt;setOption(&quot;num_neighbors&quot;, &quot;100&quot;);
+    ball_tree-&gt;setOption(&quot;copy_input&quot;, &quot;0&quot;);
+    ball_tree-&gt;setOption(&quot;copy_target&quot;, &quot;0&quot;);
+    ball_tree-&gt;setOption(&quot;copy_weight&quot;, &quot;0&quot;);
+    ball_tree-&gt;setOption(&quot;copy_index&quot;, &quot;1&quot;);
+    ball_tree-&gt;setOption(&quot;nstages&quot;, &quot;-1&quot;);
+    ball_tree-&gt;setOption(&quot;report_progress&quot;, &quot;1&quot;);
+    ball_tree-&gt;setTrainingSet(reference_set_with_covpres, true);
+    ball_tree-&gt;train();
+    ref_cov = reference_set_with_covpres-&gt;toMat();
+    ref_mis = reference_set_with_missing-&gt;toMat();
+*/
+    if (!reference_set_with_covpres) PLERROR(&quot;In TestImputations:: no reference_set_with_covpres provided.&quot;);
+    if (!reference_set_with_missing) PLERROR(&quot;In TestImputations:: no reference_set_with_missing provided.&quot;);
+    ball_tree = new ExhaustiveNearestNeighbors();
+    ball_tree-&gt;setOption(&quot;num_neighbors&quot;, &quot;100&quot;);
+    ball_tree-&gt;setOption(&quot;copy_input&quot;, &quot;0&quot;);
+    ball_tree-&gt;setOption(&quot;copy_target&quot;, &quot;0&quot;);
+    ball_tree-&gt;setOption(&quot;copy_weight&quot;, &quot;0&quot;);
+    ball_tree-&gt;setOption(&quot;copy_index&quot;, &quot;1&quot;);
+    ball_tree-&gt;setOption(&quot;nstages&quot;, &quot;-1&quot;);
+    ball_tree-&gt;setOption(&quot;report_progress&quot;, &quot;1&quot;);
+    ball_tree-&gt;distance_kernel = weighted_distance_kernel;
+    ball_tree-&gt;setTrainingSet(reference_set_with_covpres, true);
+    ball_tree-&gt;train();
+    ref_cov = reference_set_with_covpres-&gt;toMat();
+    ref_mis = reference_set_with_missing-&gt;toMat();
+/*
+ExhaustiveNearestNeighbors(
+# bool: Whether the kernel defined by the 'distance_kernel' option should be
+# interpreted as a (pseudo-)distance measure (true) or a similarity
+# measure (false). Default = true.  Note that this interpretation is
+# strictly specific to the class ExhaustiveNearestNeighbors.
+kernel_is_pseudo_distance = 1  ;
+
+# Ker: Alternate name for 'distance_kernel'.  (Deprecated; use only so that
+# existing scripts can run.)
+kernel = *1 -&gt;DistanceKernel(
+n = 2 ;
+pow_distance = 0 ;
+optimized = 0 ;
+is_symmetric = 1 ;
+report_progress = 0 ;
+specify_dataset = *0 ;
+cache_gram_matrix = 0 ;
+data_inputsize = -1 ;
+n_examples = -1  )
+ ;
+
+# int: Number of nearest-neighbors to compute.  This is usually called &quot;K&quot;.
+# The output vector is simply the concatenation of all found neighbors.
+# (Default = 1)
+num_neighbors = 1  ;
+
+# bool: If true, the output contains a copy of the found input vector(s).
+# (Default = false)
+copy_input = 0  ;
+
+# bool: If true, the output contains a copy of the found target vector(s).
+# (Default = true)
+copy_target = 1  ;
+
+# bool: If true, the output contains a copy of the found weight.  If no
+# weight is present in the training set, a weight of 1.0 is put.
+# (Default = true)
+copy_weight = 0  ;
+
+# bool: If true, the output contains the index of the found neighbor
+# (as the row number, zero-based, in the training set.)
+# (Default = false)
+copy_index = 0  ;
+
+# Ker: An optional alternative to the Euclidean distance (DistanceKernel with
+# n=2 and pow_distance=1).  It should be a 'distance-like' kernel rather
+# than a 'dot-product-like' kernel, i.e. small when the arguments are
+# similar, and it should always be non-negative, and 0 only if arguments
+# are equal.
+distance_kernel = *1 -&gt;DistanceKernel(
+n = 2 ;
+pow_distance = 0 ;
+optimized = 0 ;
+is_symmetric = 1 ;
+report_progress = 0 ;
+specify_dataset = *0 ;
+cache_gram_matrix = 0 ;
+data_inputsize = -1 ;
+n_examples = -1  )
+ ;
+*/
+
+}
+
+void TestImputations::initialize()
+{
+    
+    // initialize the header file
+    cout &lt;&lt; &quot;initialize the header file&quot; &lt;&lt; endl;
+    train_set-&gt;lockMetaDataDir();
+    header_record.resize(train_width);
+    header_file_name = train_metadata + &quot;/TestImputation/header.pmat&quot;;
+    if (!isfile(header_file_name)) createHeaderFile();
+    else getHeaderRecord();
+    
+    // choose a variable to test imputations for
+    cout &lt;&lt; &quot;choose a variable to test imputations for&quot; &lt;&lt; endl;
+    to_deal_with_total = 0;
+    to_deal_with_next = -1;
+    for (train_col = 0; train_col &lt; train_width; train_col++)
+    {
+        if (header_record[train_col] != 1.0) continue;
+        to_deal_with_total += 1;
+        if (to_deal_with_next &lt; 0) to_deal_with_next = train_col;
+    }
+    if (to_deal_with_next &lt; 0)
+    {
+        train_set-&gt;unlockMetaDataDir();
+        // reviewGlobalStats();
+        PLERROR(&quot;In TestImputations:: we are done here&quot;);
+    }
+    to_deal_with_name = train_names[to_deal_with_next];
+    cout &lt;&lt; &quot;total number of variable left to deal with: &quot; &lt;&lt; to_deal_with_total &lt;&lt; endl;
+    cout &lt;&lt; &quot;next variable to deal with: &quot; &lt;&lt; train_names[to_deal_with_next] &lt;&lt; endl;
+    updateHeaderRecord(to_deal_with_next);
+    train_set-&gt;unlockMetaDataDir();
+    
+    // find the available samples with non-missing values for this variable
+    pb = 0;
+    train_stats = train_set-&gt;getStats(to_deal_with_next);
+    train_total = train_stats.n();
+    train_missing = train_stats.nmissing();
+    train_present = train_total - train_missing;
+    indices.resize((int) train_present);
+    ind_next = 0;
+    pb = new ProgressBar( &quot;Building the indices for &quot; + to_deal_with_name, train_length);
+    for (train_row = 0; train_row &lt; train_length; train_row++)
+    {
+        to_deal_with_value = train_set-&gt;get(train_row, to_deal_with_next);
+        if (is_missing(to_deal_with_value)) continue;
+        if (ind_next &gt;= indices.length()) PLERROR(&quot;In TestImputations:: There seems to be more present values than indicated by the stats file&quot;);
+        indices[ind_next] = train_row;
+        ind_next += 1;
+        pb-&gt;update( train_row );
+    }
+    delete pb;
+    
+    // shuffle the indices.
+    manual_seed(123456);
+    shuffleElements(indices);
+    
+    // load the test samples for this variable
+    if (indices.length() &gt; max_number_of_samples) test_length = max_number_of_samples;
+    else test_length = indices.length();
+    test_width = train_width;
+    test_samples_set = new MemoryVMatrix(test_length, test_width);
+    pb = new ProgressBar( &quot;Loading the test samples for &quot; + to_deal_with_name, test_length);
+    for (test_row = 0; test_row &lt; test_length; test_row++)
+    {
+        train_set-&gt;getRow(indices[test_row], train_input);
+        test_samples_set-&gt;putRow(test_row, train_input);
+        pb-&gt;update( test_row );
+    }
+    delete pb;
+}
+
+void TestImputations::computeMeanMedianModeStats()
+{
+    if (!isfile(mean_median_mode_file_name)) PLERROR(&quot;In TestImputations:: a valid mean_median_mode_file path must be provided.&quot;);
+    mmmf_file = new FileVMatrix(mean_median_mode_file_name);
+    mmmf_length = mmmf_file-&gt;length();
+    mmmf_width = mmmf_file-&gt;width();
+    if (mmmf_length != 3) PLERROR(&quot;In TestImputations:: there should be exactly 3 records in the mmm file, got %i.&quot;, mmmf_length);
+    if (mmmf_width != train_width) PLERROR(&quot;In TestImputations:: train set and mmm width should be the same, got %i.&quot;, mmmf_width);
+    mmmf_mean = mmmf_file-&gt;get(0, to_deal_with_next);
+    mmmf_median = mmmf_file-&gt;get(1, to_deal_with_next);
+    mmmf_mode = mmmf_file-&gt;get(2, to_deal_with_next);
+    mmmf_mean_err = 0.0;
+    mmmf_median_err = 0.0;
+    mmmf_mode_err = 0.0;
+    pb = new ProgressBar( &quot;computing the mean, median and mode imputation errors for &quot; + to_deal_with_name, test_length);
+    for (test_row = 0; test_row &lt; test_length; test_row++)
+    {
+        to_deal_with_value = test_samples_set-&gt;get(test_row, to_deal_with_next);
+        mmmf_mean_err += pow(to_deal_with_value - mmmf_mean, 2.0);
+        mmmf_median_err += pow(to_deal_with_value - mmmf_median, 2.0);
+        mmmf_mode_err += pow(to_deal_with_value - mmmf_mode, 2.0);
+        pb-&gt;update( test_row );
+    }
+    delete pb;
+    mmmf_mean_err = mmmf_mean_err / (real) test_length;
+    mmmf_median_err = mmmf_median_err / (real) test_length;
+    mmmf_mode_err = mmmf_mode_err / (real) test_length;
+}
+
+void TestImputations::computeTreeCondMeanStats()
+{
+    tcmf_file_name = tree_conditional_mean_directory + &quot;/&quot; + to_deal_with_name + &quot;/Split0/test1_outputs.pmat&quot;;
+    if (!isfile(tcmf_file_name)) PLERROR(&quot;In TestImputations:: a file was not found in the tcf directory.&quot;);
+    tcmf_file = new FileVMatrix(tcmf_file_name);
+    tcmf_length = tcmf_file-&gt;length();
+    tcmf_width = tcmf_file-&gt;width();
+    if (tcmf_length &lt; train_length) PLERROR(&quot;In TestImputations:: there are not enough records in the tree conditional output file.&quot;);
+    tcmf_mean_err = 0.0;
+    pb = new ProgressBar( &quot;computing the tree conditional mean imputation errors for &quot; + to_deal_with_name, test_length);
+    for (test_row = 0; test_row &lt; test_length; test_row++)
+    {
+        to_deal_with_value = test_samples_set-&gt;get(test_row, to_deal_with_next);
+        tcmf_mean_err += pow(to_deal_with_value - tcmf_file-&gt;get(indices[test_row], 0), 2.0);
+        pb-&gt;update( test_row );
+    }
+    delete pb;
+    tcmf_mean_err = tcmf_mean_err / (real) test_length;
+}
+
+void TestImputations::computeCovPresStats()
+{
+    if (!isfile(covariance_preservation_file_name)) PLERROR(&quot;In TestImputations:: a valid covariance_preservation_file path must be provided.&quot;);
+    cvpf_file = new FileVMatrix(covariance_preservation_file_name);
+    cvpf_length = cvpf_file-&gt;length();
+    cvpf_width = cvpf_file-&gt;width();
+    if (cvpf_length != train_width + 1) PLERROR(&quot;In TestImputations:: there should be %i records in the cvp file, got %i.&quot;, train_width + 1, cvpf_length);
+    if (cvpf_width != train_width) PLERROR(&quot;In TestImputations:: train set and cvp width should be the same, got %i.&quot;, cvpf_width);
+    cvpf_file = new FileVMatrix(covariance_preservation_file_name);
+    cvpf_cov.resize(train_width, train_width);
+    cvpf_mu.resize(train_width);
+    for (cvpf_row = 0; cvpf_row &lt; train_width; cvpf_row++)
+    {
+        for (cvpf_col = 0; cvpf_col &lt; train_width; cvpf_col++)
+        {
+            cvpf_cov(cvpf_row, cvpf_col) = cvpf_file-&gt;get(cvpf_row, cvpf_col);
+        }
+    }
+    for (cvpf_col = 0; cvpf_col &lt; train_width; cvpf_col++)
+    {
+        cvpf_mu[cvpf_col] = cvpf_file-&gt;get(train_width, cvpf_col);
+    }
+    cvpf_mean_err = 0.0;
+    pb = new ProgressBar( &quot;computing the covariance preservation imputation errors for &quot; + to_deal_with_name, test_length);
+    for (test_row = 0; test_row &lt; test_length; test_row++)
+    {
+        test_samples_set-&gt;getRow(test_row, train_input);
+        cvpf_mean_err += pow(to_deal_with_value - covariancePreservationValue(to_deal_with_next), 2.0);
+        pb-&gt;update( test_row );
+    }
+    delete pb;
+    cvpf_mean_err = cvpf_mean_err / (real) test_length;
+}
+
+real TestImputations::covariancePreservationValue(int col)
+{
+    cvpf_sum_cov_xl = 0;
+    cvpf_sum_xl_square = 0;
+    for (cvpf_col = 0; cvpf_col &lt; train_width; cvpf_col++)
+    {
+        if (cvpf_col == col) continue;
+        if (is_missing(train_input[cvpf_col])) continue;
+        cvpf_sum_cov_xl += cvpf_cov(cvpf_col, col) * (train_input[cvpf_col] - cvpf_mu[cvpf_col]);
+        cvpf_sum_xl_square += (train_input[cvpf_col] - cvpf_mu[cvpf_col]) * (train_input[cvpf_col] - cvpf_mu[cvpf_col]);
+    }
+    if (cvpf_sum_xl_square == 0.0) cvpf_value = cvpf_mu[col];
+    else cvpf_value = cvpf_mu[col] + cvpf_sum_cov_xl / cvpf_sum_xl_square;
+    return cvpf_value;
+}
+
+void TestImputations::computeNeighborhoodStats()
+{
+    knnf_input.resize(train_width);
+    knnf_neighbors.resize(100);
+    knnf_mean_err.resize(100);
+    knnf_mean_err.clear();
+    pb = new ProgressBar( &quot;computing the neighborhood imputation errors for &quot; + to_deal_with_name, test_length);
+    for (test_row = 0; test_row &lt; test_length; test_row++)
+    {
+        test_samples_set-&gt;getRow(test_row, train_input);
+        for (test_col = 0; test_col &lt; train_width; test_col++)
+        {
+            if (test_col == to_deal_with_next) knnf_input[test_col] = covariancePreservationValue(test_col);
+            else if (is_missing(train_input[test_col])) knnf_input[test_col] = covariancePreservationValue(test_col);
+            else knnf_input[test_col] = train_input[test_col];
+        }
+        ball_tree-&gt;computeOutput(knnf_input, knnf_neighbors);
+        knnf_sum_value = 0.0;
+        knnf_sum_cov = 0.0;
+        knnv_value_count = 0.0;
+        for (knnf_row = 0; knnf_row &lt; 100; knnf_row++)
+        {
+            knnf_value = ref_mis((int) knnf_neighbors[knnf_row], to_deal_with_next);
+            if (!is_missing(knnf_value))
+            {
+                knnf_sum_value += knnf_value;
+                knnv_value_count += 1.0;
+            }
+            if (knnv_value_count &gt; 0.0)
+            {
+                knnf_mean_err[knnf_row] += pow(to_deal_with_value - (knnf_sum_value / knnv_value_count), 2.0);
+                continue;
+            }
+            knnf_value = ref_cov((int) knnf_neighbors[knnf_row], to_deal_with_next);
+            if (is_missing(knnf_value))
+                PLERROR(&quot;In TestImputations::missing value found in the reference with covariance preserved at: %i , %i&quot;,
+                         (int) knnf_neighbors[knnf_row], to_deal_with_next);
+            knnf_sum_cov += knnf_value;
+            knnf_mean_err[knnf_row] += pow(to_deal_with_value - (knnf_sum_cov / (knnf_row + 1)), 2.0);
+        }
+        pb-&gt;update( test_row );
+    }
+    delete pb;
+    for (knnf_row = 0; knnf_row &lt; 100; knnf_row++) knnf_mean_err[knnf_row] = knnf_mean_err[knnf_row] /  (real) test_length;
+}
+
+void TestImputations::createHeaderFile()
+{ 
+    for (train_col = 0; train_col &lt; train_width; train_col++)
+    {
+        train_stats = train_set-&gt;getStats(train_col);
+        train_total = train_stats.n();
+        train_missing = train_stats.nmissing();
+        train_present = train_total - train_missing;
+        if (train_missing &lt;= 0.0) header_record[train_col] = 0.0;                       // no missing, noting to do.
+        else if (train_present &lt; min_number_of_samples) header_record[train_col] = 0.0; // should not happen
+        else header_record[train_col] = 1.0;                                            // test imputations
+    }
+    header_file = new FileVMatrix(header_file_name, 1, train_names);
+    header_file-&gt;putRow(0, header_record);
+}
+
+void TestImputations::getHeaderRecord()
+{ 
+    header_file = new FileVMatrix(header_file_name, true);
+    header_file-&gt;getRow(0, header_record);
+}
+
+void TestImputations::updateHeaderRecord(int var_col)
+{ 
+    header_file-&gt;put(0, var_col, 2.0);
+    header_file-&gt;flush();
+}
+
+void TestImputations::train()
+{
+    // initialize the output file
+    cout &lt;&lt; &quot;initialize the output file&quot; &lt;&lt; endl;
+    train_set-&gt;lockMetaDataDir();
+    output_record.resize(105);
+    output_file_name = train_metadata + &quot;/TestImputation/output.pmat&quot;;
+    if (!isfile(output_file_name)) createOutputFile();
+    else getOutputRecord(to_deal_with_next);
+    output_record[0] = mmmf_mean_err;
+    output_record[1] = mmmf_median_err;
+    output_record[2] = mmmf_mode_err;
+    output_record[3] = tcmf_mean_err;
+    output_record[4] = cvpf_mean_err;
+    for (knnf_row = 0; knnf_row &lt; 100; knnf_row++)
+    {
+       output_record[knnf_row + 5] = knnf_mean_err[knnf_row];
+    }
+    updateOutputRecord(to_deal_with_next);
+    train_set-&gt;unlockMetaDataDir();
+}
+
+void TestImputations::createOutputFile()
+{
+    output_names.resize(105);
+    output_names[0] = &quot;mean&quot;;
+    output_names[1] = &quot;median&quot;;
+    output_names[2] = &quot;mode&quot;;
+    output_names[3] = &quot;tree_cond&quot;;
+    output_names[4] = &quot;cov_pres&quot;;
+    for (knnf_row = 0; knnf_row &lt; 100; knnf_row++)
+    {
+       output_names[knnf_row + 5] = &quot;KNN_&quot; + tostring(knnf_row);
+    }
+    output_record.clear();
+    output_file = new FileVMatrix(output_file_name, train_width, output_names);
+    for (train_col = 0; train_col &lt; train_width; train_col++)
+        output_file-&gt;putRow(train_col, output_record);
+}
+
+void TestImputations::getOutputRecord(int var_col)
+{ 
+    output_file = new FileVMatrix(output_file_name, true);
+    output_file-&gt;getRow(var_col, output_record);
+}
+
+void TestImputations::updateOutputRecord(int var_col)
+{ 
+    output_file-&gt;putRow(var_col, output_record);
+    output_file-&gt;flush();
+}
+
+int TestImputations::outputsize() const {return 0;}
+void TestImputations::computeOutput(const Vec&amp;, Vec&amp;) const {}
+void TestImputations::computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const {}
+TVec&lt;string&gt; TestImputations::getTestCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+TVec&lt;string&gt; TestImputations::getTrainCostNames() const
+{
+    TVec&lt;string&gt; result;
+    result.append( &quot;MSE&quot; );
+    return result;
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/TestImputations.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,239 @@
+// -*- C++ -*-
+
+// TestImputations.h
+//
+// Copyright (C) 2006 Dan Popovici
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Dan Popovici
+
+/*! \file TestImputations.h */
+
+
+#ifndef TestImputations_INC
+#define TestImputations_INC
+
+#include &lt;plearn_learners/generic/PLearner.h&gt;
+#include &lt;plearn_learners/testers/PTester.h&gt;
+#include &lt;plearn/vmat/FileVMatrix.h&gt;
+#include &lt;plearn/vmat/MemoryVMatrix.h&gt;
+#include &lt;plearn/io/load_and_save.h&gt;          //!&lt;  For save
+#include &lt;plearn/io/fileutils.h&gt;              //!&lt;  For isfile()
+#include &lt;plearn/math/random.h&gt;               //!&lt;  For the seed stuff.
+#include &lt;plearn/vmat/ExplicitSplitter.h&gt;     //!&lt;  For the splitter stuff.
+#include &lt;plearn_learners/second_iteration/CovariancePreservationImputationVMatrix.h&gt;
+#include &lt;plearn_learners/second_iteration/NeighborhoodImputationVMatrix.h&gt;
+#include &lt;plearn_learners/second_iteration/BallTreeNearestNeighbors.h&gt;
+#include &lt;plearn_learners/second_iteration/WeightedDistance.h&gt;
+#include &lt;plearn_learners/nearest_neighbors/ExhaustiveNearestNeighbors.h&gt;
+#include &lt;plearn_learners/second_iteration/Experimentation.h&gt;
+
+namespace PLearn {
+
+/**
+ * Generate samples from a mixture of two gaussians
+ *
+ */
+class TestImputations : public PLearner
+{
+    typedef PLearner inherited;
+
+public:
+
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+    
+    //! The minimum number of samples required to test imputations for a variable.
+    int min_number_of_samples;
+    //! The maximum number of samples used to test imputations for a variable.
+    int max_number_of_samples;
+    //! The Path of the file with those statistics for all the variables.
+    PPath mean_median_mode_file_name;
+    //! The Path of the dircetory containing the tree conditional means computed for each variable.
+    PPath tree_conditional_mean_directory;
+    //! The Path of the file with the train_set empirically observed covariances and means.
+    PPath covariance_preservation_file_name;
+    //! The reference set corresponding to the index computed with the ball_tree, with the initial imputations.
+    VMat reference_set_with_covpres;
+    //! The reference set corresponding to the index computed with the ball_tree, with missing values.
+    VMat reference_set_with_missing;
+    //! The vector of missing indicator field names to be excluded in the distance computation.
+    TVec&lt;string&gt; missing_indicators;
+    
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor
+    // ### Make sure the implementation in the .cc
+    // ### initializes all fields to reasonable default values.
+    TestImputations();
+    int outputsize() const;
+    void train();
+    void computeOutput(const Vec&amp;, Vec&amp;) const;
+    void computeCostsFromOutputs(const Vec&amp;, const Vec&amp;, const Vec&amp;, Vec&amp;) const;
+    TVec&lt;string&gt; getTestCostNames() const;
+    TVec&lt;string&gt; getTrainCostNames() const;
+
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT_METHODS
+    PLEARN_DECLARE_OBJECT(TestImputations);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);    
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    void build_();
+    void build_ball_tree();
+    void initialize();
+    void computeMeanMedianModeStats();
+    void computeTreeCondMeanStats();
+    void computeCovPresStats();
+    real covariancePreservationValue(int col);
+    void computeNeighborhoodStats();
+    void createHeaderFile();
+    void getHeaderRecord();
+    void updateHeaderRecord(int var_col);
+    void createOutputFile();
+    void getOutputRecord(int var_col);
+    void updateOutputRecord(int var_col);
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+    ProgressBar* pb;
+    ExhaustiveNearestNeighbors* ball_tree;
+    Mat ref_cov;
+    Mat ref_mis;
+    int train_length;
+    int train_width;
+    Vec train_input;
+    TVec&lt;string&gt; train_names;
+    PPath train_metadata;
+    StatsCollector train_stats;
+    real train_total;
+    real train_missing;
+    real train_present;
+    int train_row;
+    int train_col;
+    PPath header_file_name;
+    VMat header_file;
+    Vec header_record;
+    int to_deal_with_total;
+    int to_deal_with_next;
+    string to_deal_with_name;
+    real to_deal_with_value;
+    VMat test_samples_set;
+    TVec&lt;int&gt; indices;
+    int ind_next;
+    int test_length;
+    int test_width;
+    int test_row;
+    int test_col;
+    VMat mmmf_file;
+    int mmmf_length;
+    int mmmf_width;
+    real mmmf_mean;
+    real mmmf_median;
+    real mmmf_mode;
+    real mmmf_mean_err;
+    real mmmf_median_err;
+    real mmmf_mode_err;
+    PPath tcmf_file_name;
+    VMat tcmf_file;
+    int tcmf_length;
+    int tcmf_width;
+    real tcmf_mean_err;
+    VMat cvpf_file;
+    int cvpf_length;
+    int cvpf_width;
+    int cvpf_row;
+    int cvpf_col;
+    Mat cvpf_cov;
+    Vec cvpf_mu;
+    real cvpf_sum_cov_xl;
+    real cvpf_sum_xl_square;
+    real cvpf_value;
+    real cvpf_mean_err;
+    Vec knnf_input;
+    Vec knnf_neighbors;
+    Vec knnf_mean_err;
+    real knnf_value;
+    real knnf_sum_value;
+    real knnf_sum_cov;
+    real knnv_value_count;
+    int knnf_row;
+    Vec weights;
+    int mi_col;
+    WeightedDistance* weighted_distance_kernel;
+    PPath output_file_name;
+    VMat output_file;
+    Vec output_record;
+    TVec&lt;string&gt; output_names;
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(TestImputations);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.cc
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.cc	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.cc	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,125 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2002 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2001-2002 Nicolas Chapados, Ichiro Takeuchi, Jean-Sebastien Senecal
+// Copyright (C) 2002 Xiangdong Wang, Christian Dorion
+
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************      
+ * $Id: WeightedDistance.cc 4253 2005-10-18 19:02:25Z tihocan $
+ * This file is part of the PLearn library.
+ ******************************************************* */
+
+#include &quot;WeightedDistance.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+
+PLEARN_IMPLEMENT_OBJECT(
+    WeightedDistance,
+    &quot;Implements an weighted distance.&quot;,
+    &quot;Output is as follows:\n&quot;
+    &quot;- k(x1,x2) = \\sum_i w[i]*(x1[i]-x2[i])^2\n&quot;
+);
+
+////////////////////
+// WeightedDistance //
+////////////////////
+WeightedDistance::WeightedDistance()
+{
+}
+
+WeightedDistance::WeightedDistance(Vec the_weights)
+ : weights(the_weights)
+{
+}
+
+////////////////////
+// declareOptions //
+////////////////////
+void WeightedDistance::declareOptions(OptionList&amp; ol)
+{
+
+    declareOption(ol, &quot;weights&quot;, &amp;WeightedDistance::weights, OptionBase::buildoption, 
+                  &quot;The vector of weights to apply to the distance computation.&quot;);
+
+    inherited::declareOptions(ol);
+}
+
+//////////////
+// evaluate //
+//////////////
+real WeightedDistance::evaluate(const Vec&amp; x1, const Vec&amp; x2) const
+{
+    if (weights.length() != x1.length()) PLERROR(&quot;In WeightedDistance: inconsistent length between weigths and x1&quot;);
+    if (weights.length() != x2.length()) PLERROR(&quot;In WeightedDistance: inconsistent length between weigths and x2&quot;);
+    real return_value = 0.0;
+    for (int i = 0; i &lt; weights.length(); i++)
+    {
+        return_value += weights[i] * pow(x1[i] - x2[i], 2.0);
+    }
+    return return_value;
+}
+
+//////////////////
+// evaluate_i_j //
+//////////////////
+real WeightedDistance::evaluate_i_j(int i, int j) const
+{
+    PLERROR(&quot;In WeightedDistance: evaluate_i_j not implemented&quot;);
+    return 0.0;
+}
+
+////////////////////////////
+// setDataForKernelMatrix //
+////////////////////////////
+void WeightedDistance::setDataForKernelMatrix(VMat the_data)
+{
+    PLERROR(&quot;In WeightedDistance: setDataForKernelMatrix not implemented&quot;);
+}
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.h
===================================================================
--- branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.h	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/plearn_learners/second_iteration/WeightedDistance.h	2007-06-07 15:47:42 UTC (rev 7551)
@@ -0,0 +1,100 @@
+// -*- C++ -*-
+
+// PLearn (A C++ Machine Learning Library)
+// Copyright (C) 1998 Pascal Vincent
+// Copyright (C) 1999-2002 Pascal Vincent, Yoshua Bengio, Rejean Ducharme and University of Montreal
+// Copyright (C) 2001-2002 Nicolas Chapados, Ichiro Takeuchi, Jean-Sebastien Senecal
+// Copyright (C) 2002 Xiangdong Wang, Christian Dorion
+
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+// 
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+// 
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+// 
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+// 
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+// 
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+
+/* *******************************************************      
+ * $Id: WeightedDistance.h 3994 2005-08-25 13:35:03Z chapados $
+ * This file is part of the PLearn library.
+ ******************************************************* */
+
+#ifndef WeightedDistance_INC
+#define WeightedDistance_INC
+
+#include &lt;plearn/ker/Kernel.h&gt;
+#include &lt;plearn/base/tostring.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+//! This class implements an Ln distance (defaults to L2 i.e. euclidean distance).
+class WeightedDistance: public Kernel
+{
+
+private:
+
+    typedef Kernel inherited;
+
+public:
+
+    Vec weights;
+
+    WeightedDistance();
+    WeightedDistance(Vec the_weights);
+    
+    PLEARN_DECLARE_OBJECT(WeightedDistance);
+
+    virtual string info() const
+    { return &quot;WL2&quot;; }
+
+    virtual real evaluate(const Vec&amp; x1, const Vec&amp; x2) const;
+    virtual real evaluate_i_j(int i, int j) const;
+
+    //!  This method precomputes the squared norm for all the data to
+    //! later speed up evaluate methods, if n == 2.
+    virtual void setDataForKernelMatrix(VMat the_data);
+
+protected:
+    static void declareOptions(OptionList&amp; ol);
+};
+
+DECLARE_OBJECT_PTR(WeightedDistance);
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Modified: branches/cgi-desjardin/scripts/appStart.py
===================================================================
--- branches/cgi-desjardin/scripts/appStart.py	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/scripts/appStart.py	2007-06-07 15:47:42 UTC (rev 7551)
@@ -1,4 +1,4 @@
-__cvs_id__ = &quot;$Id: appStart.py,v 1.3 2004/12/21 16:23:47 dorionc Exp $&quot;
+__cvs_id__ = &quot;$Id$&quot;
 
 import string, sys, fpformat, os, copy, time
 from popen2 import *

Modified: branches/cgi-desjardin/scripts/extract_classes
===================================================================
--- branches/cgi-desjardin/scripts/extract_classes	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/scripts/extract_classes	2007-06-07 15:47:42 UTC (rev 7551)
@@ -593,7 +593,7 @@
 // by a prior agreement signed with ApSTAT Technologies Inc.
 
 /* *******************************************************      
-   * $Id: extract_classes,v 1.3 2004/06/28 19:19:57 dorionc Exp $ 
+   * $Id$ 
    ******************************************************* */
 
 // Authors: Nicolas Chapados

Modified: branches/cgi-desjardin/scripts/mnd.py
===================================================================
--- branches/cgi-desjardin/scripts/mnd.py	2007-06-07 15:42:58 UTC (rev 7550)
+++ branches/cgi-desjardin/scripts/mnd.py	2007-06-07 15:47:42 UTC (rev 7551)
@@ -1,4 +1,4 @@
-__cvs_id__ = &quot;$Id: mnd.py,v 1.2 2004/12/21 16:23:47 dorionc Exp $&quot;
+__cvs_id__ = &quot;$Id$&quot;
 
 from Numeric import *
 from LinearAlgebra import *


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000999.html">[Plearn-commits] r7550 - in	trunk/plearn_learners/online/test/DeepBeliefNet: .	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-0/Split0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-1-1/Split0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-0/Split0	.pytest/PL_DBN_Mini-batch/expected_results/expdir-dbn-3-1/Split0
</A></li>
	<LI>Next message: <A HREF="001001.html">[Plearn-commits] r7552 -	branches/cgi-desjardin/plearn_learners/second_iteration
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1000">[ date ]</a>
              <a href="thread.html#1000">[ thread ]</a>
              <a href="subject.html#1000">[ subject ]</a>
              <a href="author.html#1000">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
