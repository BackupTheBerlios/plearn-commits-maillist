<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7562 - in trunk: plearn/var/EXPERIMENTAL	plearn_learners/generic/EXPERIMENTAL	python_modules/plearn/plotting python_modules/plearn/var
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7562%20-%20in%20trunk%3A%20plearn/var/EXPERIMENTAL%0A%09plearn_learners/generic/EXPERIMENTAL%0A%09python_modules/plearn/plotting%20python_modules/plearn/var&In-Reply-To=%3C200706082103.l58L3CeO022939%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001010.html">
   <LINK REL="Next"  HREF="001012.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7562 - in trunk: plearn/var/EXPERIMENTAL	plearn_learners/generic/EXPERIMENTAL	python_modules/plearn/plotting python_modules/plearn/var</H1>
    <B>simonl at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7562%20-%20in%20trunk%3A%20plearn/var/EXPERIMENTAL%0A%09plearn_learners/generic/EXPERIMENTAL%0A%09python_modules/plearn/plotting%20python_modules/plearn/var&In-Reply-To=%3C200706082103.l58L3CeO022939%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7562 - in trunk: plearn/var/EXPERIMENTAL	plearn_learners/generic/EXPERIMENTAL	python_modules/plearn/plotting python_modules/plearn/var">simonl at mail.berlios.de
       </A><BR>
    <I>Fri Jun  8 23:03:12 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001010.html">[Plearn-commits] r7561 - trunk/python_modules/plearn/learners/autolr
</A></li>
        <LI>Next message: <A HREF="001012.html">[Plearn-commits] r7563 - trunk/python_modules/plearn/parallel
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1011">[ date ]</a>
              <a href="thread.html#1011">[ thread ]</a>
              <a href="subject.html#1011">[ subject ]</a>
              <a href="author.html#1011">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: simonl
Date: 2007-06-08 23:03:11 +0200 (Fri, 08 Jun 2007)
New Revision: 7562

Added:
   trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.cc
   trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.h
Modified:
   trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc
   trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
   trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h
   trunk/python_modules/plearn/plotting/netplot.py
   trunk/python_modules/plearn/var/Var.py
Log:
minor improvements...


Added: trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.cc	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.cc	2007-06-08 21:03:11 UTC (rev 7562)
@@ -0,0 +1,182 @@
+// -*- C++ -*-
+
+// ProbabilityPairsInverseVariable.cc
+//
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Simon Lemieux
+
+/*! \file ProbabilityPairsInverseVariable.cc */
+
+
+#include &quot;ProbabilityPairsInverseVariable.h&quot;
+
+namespace PLearn {
+using namespace std;
+
+/** ProbabilityPairsInverseVariable **/
+
+PLEARN_IMPLEMENT_OBJECT(
+    ProbabilityPairsInverseVariable,
+    &quot;[x1,x2,x3,...,xn] -&gt; [f(x1), f(x3), ..., f(xn)] with f(x) = (max-min)*x - min and with n even&quot;,
+    &quot;MULTI LINE\nHELP FOR USERS&quot;
+    );
+
+
+ProbabilityPairsInverseVariable::ProbabilityPairsInverseVariable()
+    : min(0.), max(1.)
+{}
+
+ProbabilityPairsInverseVariable::ProbabilityPairsInverseVariable(Variable* input, real min, real max)
+    : inherited(input, input-&gt;length(), input-&gt;width()/2),
+      min(min),max(max)
+{
+    build_();
+}
+
+ProbabilityPairsInverseVariable::ProbabilityPairsInverseVariable(Variable* input, real max)
+    :inherited(input, input-&gt;length(), input-&gt;width()/2),
+     min(0.), max(max)
+{
+    build_();
+}
+
+ProbabilityPairsInverseVariable::ProbabilityPairsInverseVariable(Variable* input)
+    :inherited(input, input-&gt;length(), input-&gt;width()/2),
+     min(0.), max(1.)
+{
+    build_();
+}
+
+void ProbabilityPairsInverseVariable::recomputeSize(int&amp; l, int&amp; w) const
+{
+        if (input) {
+            l = input-&gt;length(); // the computed length of this Var
+            w = input-&gt;width()/2; // the computed width
+        } else
+            l = w = 0;
+}
+
+// ### computes value from input's value
+void ProbabilityPairsInverseVariable::fprop()
+{
+    for(int n=0; n&lt;input-&gt;length(); n++)
+        for(int i=0; i&lt;input-&gt;width()/2; i++)
+            matValue(n,i) = input-&gt;matValue(n,i*2)*(max-min) + min;
+}
+
+// ### computes input's gradient from gradient
+void ProbabilityPairsInverseVariable::bprop()
+{
+    for(int n=0; n&lt;input-&gt;length(); n++)
+        for(int i=0; i&lt;input-&gt;width()/2; i++)
+            input-&gt;matGradient(n,i*2) += matGradient(n,i)*(max-min);
+}
+
+// ### You can implement these methods:
+// void ProbabilityPairsInverseVariable::bbprop() {}
+// void ProbabilityPairsInverseVariable::symbolicBprop() {}
+// void ProbabilityPairsInverseVariable::rfprop() {}
+
+
+// ### Nothing to add here, simply calls build_
+void ProbabilityPairsInverseVariable::build()
+{
+    inherited::build();
+    build_();
+}
+
+void ProbabilityPairsInverseVariable::makeDeepCopyFromShallowCopy(CopiesMap&amp; copies)
+{
+    inherited::makeDeepCopyFromShallowCopy(copies);
+
+    // ### Call deepCopyField on all &quot;pointer-like&quot; fields
+    // ### that you wish to be deepCopied rather than
+    // ### shallow-copied.
+    // ### ex:
+    // deepCopyField(trainvec, copies);
+
+    // ### If you want to deepCopy a Var field:
+    // varDeepCopyField(somevariable, copies);
+}
+
+void ProbabilityPairsInverseVariable::declareOptions(OptionList&amp; ol)
+{
+    // ### Declare all of this object's options here.
+    // ### For the &quot;flags&quot; of each option, you should typically specify
+    // ### one of OptionBase::buildoption, OptionBase::learntoption or
+    // ### OptionBase::tuningoption. If you don't provide one of these three,
+    // ### this option will be ignored when loading values from a script.
+    // ### You can also combine flags, for example with OptionBase::nosave:
+    // ### (OptionBase::buildoption | OptionBase::nosave)
+
+  
+    declareOption(ol, &quot;min&quot;, &amp;ProbabilityPairsInverseVariable::min,
+                  OptionBase::buildoption,
+                  &quot;The lower bound a value of the input should be. It will be used to calculate the corresponding probability of each input.&quot;);
+
+    declareOption(ol, &quot;max&quot;, &amp;ProbabilityPairsInverseVariable::max,
+                  OptionBase::buildoption,
+                  &quot;analog to min&quot;);
+
+    // Now call the parent class' declareOptions
+    inherited::declareOptions(ol);
+}
+
+void ProbabilityPairsInverseVariable::build_()
+{
+    // ### This method should do the real building of the object,
+    // ### according to set 'options', in *any* situation.
+    // ### Typical situations include:
+    // ###  - Initial building of an object from a few user-specified options
+    // ###  - Building of a &quot;reloaded&quot; object: i.e. from the complete set of
+    // ###    all serialised options.
+    // ###  - Updating or &quot;re-building&quot; of an object after a few &quot;tuning&quot;
+    // ###    options have been modified.
+    // ### You should assume that the parent class' build_() has already been
+    // ### called.
+}
+
+
+} // end of namespace PLearn
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Added: trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.h	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsInverseVariable.h	2007-06-08 21:03:11 UTC (rev 7562)
@@ -0,0 +1,163 @@
+// -*- C++ -*-
+
+// ProbabilityPairsInverseVariable.h
+//
+// Copyright (C) 2007 Simon Lemieux, Pascal Vincent
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are met:
+//
+//  1. Redistributions of source code must retain the above copyright
+//     notice, this list of conditions and the following disclaimer.
+//
+//  2. Redistributions in binary form must reproduce the above copyright
+//     notice, this list of conditions and the following disclaimer in the
+//     documentation and/or other materials provided with the distribution.
+//
+//  3. The name of the authors may not be used to endorse or promote
+//     products derived from this software without specific prior written
+//     permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
+// IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+// OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
+// NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+// TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+// LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+// NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+//
+// This file is part of the PLearn library. For more information on the PLearn
+// library, go to the PLearn Web site at www.plearn.org
+
+// Authors: Simon Lemieux
+
+/*! \file ProbabilityPairsInverseVariable.h */
+
+
+#ifndef ProbabilityPairsInverseVariable_INC
+#define ProbabilityPairsInverseVariable_INC
+
+#include &lt;plearn/var/UnaryVariable.h&gt;
+
+namespace PLearn {
+using namespace std;
+
+/*! * ProbabilityPairsInverseVariable * */
+
+/**
+ * [x1,x2,x3,...,xn] -&gt; [f(x1), f(x3), ..., f(xn)] with f(x) = (max-min)*x - min and with n even
+ * It is the inverse of ProbabilityPairsVariable
+ *
+ *
+ *
+ * @todo Write class to-do's here if there are any.
+ *
+ * @deprecated Write deprecated stuff here if there is any.  Indicate what else
+ * should be used instead.
+ */
+class ProbabilityPairsInverseVariable : public UnaryVariable
+{
+    typedef UnaryVariable inherited;
+
+public:
+    //#####  Public Build Options  ############################################
+
+    //! ### declare public option fields (such as build options) here
+    //! Start your comments with Doxygen-compatible comments such as //!
+
+    //! see ProbabilityPairsVariable documentation
+    real min;
+    
+    //! see ProbabilityPairsVariable documentation
+    real max;
+
+public:
+    //#####  Public Member Functions  #########################################
+
+    //! Default constructor, usually does nothing
+    ProbabilityPairsInverseVariable();
+     
+    ProbabilityPairsInverseVariable(Variable* input, real min, real max);
+    ProbabilityPairsInverseVariable(Variable* input, real max);
+    ProbabilityPairsInverseVariable(Variable* input);
+
+
+    //#####  PLearn::Variable methods #########################################
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void recomputeSize(int&amp; l, int&amp; w) const;
+    virtual void fprop();
+    virtual void bprop();
+
+    // ### These ones are not always implemented
+    // virtual void bbprop();
+    // virtual void symbolicBprop();
+    // virtual void rfprop();
+
+    //#####  PLearn::Object Protocol  #########################################
+
+    // Declares other standard object methods.
+    // ### If your class is not instantiatable (it has pure virtual methods)
+    // ### you should replace this by PLEARN_DECLARE_ABSTRACT_OBJECT
+    PLEARN_DECLARE_OBJECT(ProbabilityPairsInverseVariable);
+
+    // Simply calls inherited::build() then build_()
+    virtual void build();
+
+    //! Transforms a shallow copy into a deep copy
+    // (PLEASE IMPLEMENT IN .cc)
+    virtual void makeDeepCopyFromShallowCopy(CopiesMap&amp; copies);
+
+protected:
+    //#####  Protected Options  ###############################################
+
+    // ### Declare protected option fields (such as learned parameters) here
+    // ...
+
+protected:
+    //#####  Protected Member Functions  ######################################
+
+    //! Declares the class options.
+    // (PLEASE IMPLEMENT IN .cc)
+    static void declareOptions(OptionList&amp; ol);
+
+private:
+    //#####  Private Member Functions  ########################################
+
+    //! This does the actual building.
+    // (PLEASE IMPLEMENT IN .cc)
+    void build_();
+
+private:
+    //#####  Private Data Members  ############################################
+
+    // The rest of the private stuff goes here
+};
+
+// Declares a few other classes and functions related to this class
+DECLARE_OBJECT_PTR(ProbabilityPairsInverseVariable);
+
+// ### Put here a convenient method for building your variable.
+// ### e.g., if your class is TotoVariable, with two parameters foo_type foo
+// ### and bar_type bar, you could write:
+// inline Var toto(Var v, foo_type foo=default_foo, bar_type bar=default_bar)
+// { return new TotoVariable(v, foo, bar); }
+
+} // end of namespace PLearn
+
+#endif
+
+
+/*
+  Local Variables:
+  mode:c++
+  c-basic-offset:4
+  c-file-style:&quot;stroustrup&quot;
+  c-file-offsets:((innamespace . 0)(inline-open . 0))
+  indent-tabs-mode:nil
+  fill-column:79
+  End:
+*/
+// vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:encoding=utf-8:textwidth=79 :

Modified: trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.cc	2007-06-08 21:03:11 UTC (rev 7562)
@@ -57,7 +57,6 @@
 ProbabilityPairsVariable::ProbabilityPairsVariable(Variable* input, real min, real max)
     : inherited(input, input-&gt;length(), input-&gt;width()*2),
       min(min),max(max)
-
 {
     build_();
 }
@@ -103,9 +102,7 @@
 {
     for(int n=0; n&lt;length(); n++)
         for(int i=0; i&lt;input-&gt;width(); i++)
-        {
             input-&gt;matGradient(n,i) += 1./(max-min)*(matGradient(n,2*i) - matGradient(n,2*i+1));
-        }
 }
 
 // ### You can implement these methods:

Modified: trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h
===================================================================
--- trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/plearn/var/EXPERIMENTAL/ProbabilityPairsVariable.h	2007-06-08 21:03:11 UTC (rev 7562)
@@ -50,7 +50,7 @@
 /**
  *  Let define f(x) = (x-min)/(max-min) for min&lt;=x&lt;=max, then this variable is defined by [x1,x2,...,xn]  |-&gt;  [ f(x1), 1-f(x1), f(x2), 1-f(x2), ... , f(xn), 1-f(xn) ]
  *  
- *  This can seen as pairs of probabilities 
+ *  This can be interpreted  as pairs of probabilities 
  *
  *
  * @todo Write class to-do's here if there are any.
@@ -82,10 +82,6 @@
     //! Default constructor, usually does nothing
     ProbabilityPairsVariable();
 
-
-    // ### If your class has parameters, you probably want a constructor that
-    // ### initializes them
-    //! constructor
     ProbabilityPairsVariable(Variable* input, real min, real max);
     ProbabilityPairsVariable(Variable* input, real max);
     ProbabilityPairsVariable(Variable* input);

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.cc	2007-06-08 21:03:11 UTC (rev 7562)
@@ -134,6 +134,9 @@
                   OptionBase::buildoption,
                   &quot;&quot;);
 
+    declareOption(ol, &quot;group_sizes&quot;, &amp;DeepReconstructorNet::group_sizes,
+                  OptionBase::buildoption,
+                  &quot;&quot;);
     
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
@@ -267,6 +270,7 @@
     deepCopyField(compute_output, copies);
     deepCopyField(output_and_target_to_cost, copies);
     deepCopyField(outmat, copies);
+    deepCopyField(group_sizes, copies);
 }
 
 int DeepReconstructorNet::outputsize() const

Modified: trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h
===================================================================
--- trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/plearn_learners/generic/EXPERIMENTAL/DeepReconstructorNet.h	2007-06-08 21:03:11 UTC (rev 7562)
@@ -107,6 +107,9 @@
 
     PP&lt;Optimizer&gt; fine_tuning_optimizer;
 
+
+    TVec&lt;int&gt; group_sizes;
+
 protected:
     // protected members (not options)
 

Modified: trunk/python_modules/plearn/plotting/netplot.py
===================================================================
--- trunk/python_modules/plearn/plotting/netplot.py	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/python_modules/plearn/plotting/netplot.py	2007-06-08 21:03:11 UTC (rev 7562)
@@ -42,7 +42,7 @@
     for el in cbarh:
         cbarh_str.append(str(el)[0:5])
     yticks(arange(len(cbarh)),cbarh_str)
-    xticks([],[])                              
+    xticks([],[])
     imshow(cbar, cmap = color_map, vmin=min, vmax=max)
 
 
@@ -119,6 +119,7 @@
     #THE plotting
     
     x,y = sbi,sbi
+    toReturn = -1
     
     for i in arange(start,length):
     
@@ -128,7 +129,7 @@
             row = apply_to_rows(row)
         
 
-        print x,y,plotWidth, plotHeight
+       # print x,y,plotWidth, plotHeight
         
         axes((x, y, plotWidth, plotHeight))
         imshow(rowToMatrix(row, width), interpolation=&quot;nearest&quot;, cmap = colorMap, vmin = mi, vmax = ma)
@@ -142,10 +143,12 @@
             y = y + plotHeight + sbi
         if y + plotHeight &gt; 1:
             # images that follows would be out of the figure...
+            toReturn = i
             break
 
     #custom color bar
-    customColorBar(mi,ma,(1.-cbw-sbi, sbi, sbi, 1.-2.*cbw))    
+    customColorBar(mi,ma,(1.-cbw-sbi, sbi, sbi, 1.-2.*cbw))
+    return toReturn
         
 
         #1 sur 2 -
@@ -163,69 +166,11 @@
         # setPlotParams(str(i), False, True)
             
 
-def plotCharOLD(char, layers=[], space_between_layers = 5):
-    '''plots a caracter and hidden layers
-    '''  
-    #some 'plotting' consts
-    nbLayers = len(layers)
-    print 'nbLayers', nbLayers
-    totalLayersWidth = 0
-    for layer in layers:
-        totalLayersWidth += len(layer[0]) + space_between_layers
-    totalLayersWidth += space_between_layers
-    print 'totalLayersWidth', totalLayersWidth
-    
-    unit = .9/totalLayersWidth
-    print 'unit', unit
-    sbl = space_between_layers*unit
-    print 'sbl', sbl
-    plotCharWidth = .099
-    plotCharHeight = plotCharWidth
-    #plotLayerWidth = unit
-    plotCharBottom = (1.-plotCharHeight)/2.
-    
-    #plot of the char
-    axes((sbl,          
-          plotCharBottom,
-          plotCharWidth,
-          plotCharHeight))
-    imshow(char, interpolation=&quot;nearest&quot;, cmap = defaultColorMap)
-    setPlotParams(&quot;&quot;, True, True)
-    print 'char ok'
-    #plots of the layers
 
 
-    x,y=sbl,1.-2*len(layers[0])
-    axes((x,y,len(layers[0][0]), len(layers[0])))
-    imshow(layer, interpolation = &quot;nearest&quot;, cmap = defaultColorMap)
-    print 'layer[0] ok'
-    
-    k=1
-    x+=len(layers[0][0])
-    
-    while k &lt; nbLayers:
-
-       
-        
-        plotLayerHeight = unit*len(layers[k])
-        plotLayerWidth = unit*len(layers[k][0])
-        if plotLayerHeight &gt; 1:
-            plotLayerHeight = 1.-2.*sbl
-            
-        plotLayerBottom = (1.-plotLayerHeight)/2.
-
-        print 'k',k
-        print 'x',x
-        print 'plotLayerBottom', plotLayerBottom
-        print 'plotLayerWidth', plotLayer
-        axes((x,plotLayerBottom, plotLayerWidth, plotLayerHeight))
-        imshow(layers[k], interpolation=&quot;nearest&quot;, cmap = defaultColorMap)
-        setPlotParams(&quot;&quot;,True,True)
-        x += plotLayerWidth
-        k += 1
-
 def plotMatrices(matrices, same_color_bar = False, space_between_matrices = 5):
     '''plot matrices from left to right
+    TODO : same_color_bar does nothing !!
     '''
     colorMap = cm.gray
     nbMatrices = len(matrices)
@@ -244,6 +189,7 @@
     sbm = space_between_matrices*unit
 
     x=sbm
+    the_axes = []
     for matrix in matrices:
         
         h = len(matrix)*unit
@@ -252,12 +198,16 @@
             h = 1.-2*sbm
         bottom = (1.-h)/2.
 
-        axes(( x,bottom, w,h))
+        temp = axes(( x,bottom, w,h))
+        the_axes.append(temp)
         imshow(matrix, interpolation = 'nearest', cmap = colorMap)
         colorbar()
         x += w+sbm
 
+    return the_axes
 
+
+
 def truncate_imshow(mat, max_height_or_width = 200, width_height_ratio = 1, space_between_submatrices=5):
 
     matWidth = float(len(mat[0]))
@@ -348,7 +298,7 @@
         row2.append(row[i])
     return row2
 
-def rowToMatrix(row, width, validate_size = True, fill_value = 0.):
+def rowToMatrixOld(row, width, validate_size = True, fill_value = 0.):
     '''change a row [1,2,3,4,5,6] into a matrix [[1,2],[3,4],[5,6]] if width = 2
        or [1,2,3,4,5,6] -&gt; [[1,2,3,4],[5,6,fill_value,fill_value]] if width = 4 and validate_size = False
     '''
@@ -371,13 +321,24 @@
     
     return m
 
+def rowToMatrix(row, width, validate_size = True, fill_value = 0.):
+    '''change a row [1,2,3,4,5,6] into a matrix [[1,2],[3,4],[5,6]] if width = 2
+       or [1,2,3,4,5,6] -&gt; [[1,2,3,4],[5,6,fill_value,fill_value]] if width = 4 and validate_size = False
+    '''
+    copy = list(row)
+    if len(copy)%width != 0:
+        if validate_size:
+            raise Exception, &quot;dimensions does not fit ( &quot; + str(width) + &quot; does not divide &quot; + str(len(copy)) + &quot;)&quot;
+        for i in arange(len(copy)%width-1):
+            copy.append(fill_value)
+
+    return reshape(copy, (-1,width))
+
+
 def vecToVerticalMatrix(vec):
     '''ex : [1,2,3,4,5] --&gt; [[1],[2],[3],[4],[5]]
     '''
-    mat = []
-    for elem in vec:
-        mat.append([elem])
-    return mat
+    return reshape(array(vec), (len(vec),-1))
 
 def truncateMatrixOld(mat, maxHeight=10, maxWidth=10):
     

Modified: trunk/python_modules/plearn/var/Var.py
===================================================================
--- trunk/python_modules/plearn/var/Var.py	2007-06-08 18:46:57 UTC (rev 7561)
+++ trunk/python_modules/plearn/var/Var.py	2007-06-08 21:03:11 UTC (rev 7562)
@@ -71,6 +71,9 @@
 
     def probabilityPairs(self, min, max, varname=&quot;&quot;):
         return Var(pl.ProbabilityPairsVariable(input=self.v, min=min, max=max, varname=varname))
+    
+    def probabilityPairsInverse(self, min, max, varname=&quot;&quot;):
+        return Var(pl.ProbabilityPairsInverseVariable(input=self.v, min=min, max=max, varname=varname))
 
     def transpose(self):
         return Var(pl.TransposeVariable(input=self.v))
@@ -150,7 +153,7 @@
     
 
 ###################################################    
-# RLayer stands for reconstruciton hidden layer
+# RLayer stands for reconstruction hidden layer
 
 
 def addSigmoidTiedRLayer(input, iw, ow, add_bias=True, basename=&quot;&quot;):
@@ -211,10 +214,37 @@
     cost = log_reconstructed.dot(input).neg()
     return hidden, cost, reconstructed_input
 
-def addMultiSoftMaxSimpleProductTiedRLayer(input, iw, igs, ow, ogs, basename=&quot;&quot;):
+def addMultiSoftMaxMixedProductRLayer(input, iw, igs, ow, ogs, add_bias=False, basename=&quot;&quot;):
+    &quot;&quot;&quot;iw is the input's width
+    igs is the input's group size
+    ow and ogs analog but for output&quot;&quot;&quot;
+    M = Var(ow/ogs, iw, &quot;uniform&quot;, -1./iw, 1./iw, False, varname=basename+&quot;_M&quot;)
+    W = Var(ogs, iw, &quot;uniform&quot;, -1./iw, 1./iw, False, varname=basename+&quot;_W&quot;)
+    Wr = Var(ow, iw, &quot;uniform&quot;, -1./ow, 1./ow, varname=basename+'_Wr')
+
+    if add_bias:
+        b = Var(1,ow,&quot;fill&quot;,0, varname=basename+'_b')
+        hidden = input.doubleProduct(W,M).add(b).multiSoftMax(ogs)
+        br = Var(1,iw,&quot;fill&quot;,0, varname=basename+'_br')
+        log_reconstructed = hidden.matrixProduct(Wr).add(br).multiLogSoftMax(igs)
+    else:
+        hidden = input.doubleProduct(W,M).multiSoftMax(ogs)
+        log_reconstructed = hidden.matrixProduct(Wr).multiLogSoftMax(igs)
+
+    reconstructed_input = log_reconstructed.exp()
+    cost = log_reconstructed.dot(input).neg()
+    return hidden, cost, reconstructed_input
+
+def addMultiSoftMaxSimpleProductTiedRLayer(input, iw, igs, ow, ogs, add_bias=False, basename=&quot;&quot;):
     W = Var(ow, iw, &quot;uniform&quot;, -1./iw, 1./iw, varname=basename+'_W')
-    hidden = input.matrixProduct_A_Bt(W).multiSoftMax(ogs)
-    log_reconstructed = hidden.matrixProduct(W).multiLogSoftMax(igs)
+    if add_bias:
+        b = Var(1,ow,&quot;fill&quot;,0, varname=basename+'_b')
+        hidden = input.matrixProduct_A_Bt(W).add(b).multiSoftMax(ogs)
+        br = Var(1,iw,&quot;fill&quot;,0, varname=basename+'_br')
+        log_reconstructed = hidden.matrixProduct(W).add(br).multiLogSoftMax(igs)
+    else:        
+        hidden = input.matrixProduct_A_Bt(W).multiSoftMax(ogs)
+        log_reconstructed = hidden.matrixProduct(W).multiLogSoftMax(igs)
     reconstructed_input = log_reconstructed.exp()
     cost = log_reconstructed.dot(input).neg()
     return hidden, cost, reconstructed_input


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001010.html">[Plearn-commits] r7561 - trunk/python_modules/plearn/learners/autolr
</A></li>
	<LI>Next message: <A HREF="001012.html">[Plearn-commits] r7563 - trunk/python_modules/plearn/parallel
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1011">[ date ]</a>
              <a href="thread.html#1011">[ thread ]</a>
              <a href="subject.html#1011">[ subject ]</a>
              <a href="author.html#1011">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
