<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7634 - in	trunk/python_modules/plearn/learners/modulelearners: . examples
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7634%20-%20in%0A%09trunk/python_modules/plearn/learners/modulelearners%3A%20.%20examples&In-Reply-To=%3C200706222220.l5MMKvsi019517%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001081.html">
   <LINK REL="Next"  HREF="001083.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7634 - in	trunk/python_modules/plearn/learners/modulelearners: . examples</H1>
    <B>louradou at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7634%20-%20in%0A%09trunk/python_modules/plearn/learners/modulelearners%3A%20.%20examples&In-Reply-To=%3C200706222220.l5MMKvsi019517%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7634 - in	trunk/python_modules/plearn/learners/modulelearners: . examples">louradou at mail.berlios.de
       </A><BR>
    <I>Sat Jun 23 00:20:57 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001081.html">[Plearn-commits] r7633 -	branches/cgi-desjardin/plearn_learners/second_iteration
</A></li>
        <LI>Next message: <A HREF="001083.html">[Plearn-commits] r7635 -	trunk/python_modules/plearn/learners/modulelearners/examples
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1082">[ date ]</a>
              <a href="thread.html#1082">[ thread ]</a>
              <a href="subject.html#1082">[ subject ]</a>
              <a href="author.html#1082">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: louradou
Date: 2007-06-23 00:20:56 +0200 (Sat, 23 Jun 2007)
New Revision: 7634

Added:
   trunk/python_modules/plearn/learners/modulelearners/examples/do_sampling.py
   trunk/python_modules/plearn/learners/modulelearners/examples/sample.py
   trunk/python_modules/plearn/learners/modulelearners/examples/sample_from_hidden.py
Modified:
   trunk/python_modules/plearn/learners/modulelearners/__init__.py
Log:
Some examples to see images generated with Gibbs sampling



Modified: trunk/python_modules/plearn/learners/modulelearners/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/__init__.py	2007-06-22 19:24:00 UTC (rev 7633)
+++ trunk/python_modules/plearn/learners/modulelearners/__init__.py	2007-06-22 22:20:56 UTC (rev 7634)
@@ -18,13 +18,14 @@
     learner  = serv.new(learner)
     trainset = serv.new(trainset)
     validset = serv.new(validset)
-    testset  = serv.new(testset)
+    testset  = serv.new(testset)    
 
-
 # examples:
 #   isModule(module,'RBM')
 #   isModule(module,'Split')
 #
+# return True OR False (whether the type of the Module match or not)
+#
 def isModule(module,name):
     return name+'Module' in str(type(module))
 
@@ -90,12 +91,17 @@
        return copy.copy( myObject.modules )
     # Module Learner
     elif 'ModuleLearner' in str(type(myObject)):
-       return copy.copy( myObject.module.modules )
+       return getModules( myObject.module )
+    # Hyper Learner
+    elif 'HyperLearner' in str(type(myObject)):
+       if 'module' not in myObject.learner._optionnames:
+          raise TypeError, &quot;The Hyperlearner must have a learner with module&quot;
+       return getModules( myObject.learner.module )
     # List of modules
     elif type(myObject) == list and 'Module' in str(type(myObject[0])):
          return myObject
     else:
-        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule (not a &quot;+str(type(myObject))+&quot;)&quot;
 
 def setModules( myObject , new_connections_list):
     if 'NetworkModule' in str(type(myObject)):
@@ -126,9 +132,9 @@
        return deepcopy( myObject.module.modules[index] )
     # List of modules
     elif type(myObject) == list and 'Module' in str(type(myObject[0])):
-       return myObject[index]
+       return deepcopy( myObject[index] )
     else:
-       raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+       raise TypeError, &quot;Please give a ModuleLearner or NetworkModule or a List of modules&quot;
     
 def getConnections( myObject ):
     if 'NetworkModule' in str(type(myObject)):
@@ -162,7 +168,8 @@
     else:
         raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
 
-def get_last_layer_module_name( learner ):
+
+def getPreviousTopModuleName( learner ):
     last_layer = []
     output_layer = getOutputModuleName(learner)
     connections_list = getConnections(learner)
@@ -173,17 +180,37 @@
        raise TypeError, &quot;find several layers before output layer\n(&quot; + str(last_layer) + &quot;)&quot;
     return last_layer[0]
 
-def get_last_layer_module( learner ):
-    last_module_name = get_last_layer_module_name(learner)
+def getPreviousTopModule( learner ):
+    last_module_name = getPreviousTopModuleName(learner)
     modules_list = getModules( learner )
     for module in modules_list:
         if module.name == last_module_name:
 	   return module
 
+def getTopRBMModule( learner ):
+    topModule = getOutputModule(learner)
+    if isModule( topModule, 'RBM' ):
+       return topModule
+    previous_connections, previous_modulenames = getAllPrevious( learner, topModule.name )
+    for modulename in previous_modulenames:
+        module = getModule(learner,modulename)
+        if isModule( module , 'RBM' ):
+	   return module
+    return None
+
+def getTopRBMModuleName( learner ):
+    module = getTopRBMModule(learner)
+    if module != None:
+       return module.name
+    return None
+
 def getOutputModuleName( learner ):
     outputPort = getOutputPort(learner)
     return port2moduleName(outputPort[1])
 
+def getOutputModule( learner ):
+    return getModule(learner, getOutputModuleName(learner))
+
 def getOutputPort( learner ):
     ports_list = getPorts(learner)
     for port in ports_list:
@@ -593,7 +620,7 @@
 	   learner=learner.learner
         else:
            raise TypeError,  'Sorry, but this code can only be used with ModuleLearner !!!'
-    learner_nickname = 'DBN-2-2-1_'+get_last_layer_module_name( learner ) #os.path.basename(learner_filename)
+    learner_nickname = 'DBN-2-2-1_'+getPreviousTopModuleName( learner ) #os.path.basename(learner_filename)
     
   
     for typeDataSet in ['Train','Valid','Test']:

Added: trunk/python_modules/plearn/learners/modulelearners/examples/do_sampling.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/examples/do_sampling.py	2007-06-22 19:24:00 UTC (rev 7633)
+++ trunk/python_modules/plearn/learners/modulelearners/examples/do_sampling.py	2007-06-22 22:20:56 UTC (rev 7634)
@@ -0,0 +1,98 @@
+from plearn.learners.modulelearners import *
+
+def basename_withoutExt(name):
+    return '.'.join(os.path.basename(name).split('.')[:-1])
+
+
+####################################
+## Choosing the model to generate ##
+####################################
+
+
+plarg_defaults.gibbs_step                    = 10
+gibbs_step                                   = plargs.gibbs_step # Number of Gibbs step between each sampling
+
+##############################
+# Characteristics of the data
+
+plarg_defaults.Path                          = '/cluster/pauli/data/babyAI/textual_v3'
+plarg_defaults.Encoding                      = '3gram01'
+plarg_defaults.Topics                        = 'shape' #, 'color', location', 'size', 
+plarg_defaults.Size                          = 32
+plarg_defaults.Nobj                          = 1 # 1, 2, 3, 4
+plarg_defaults.ImageType                     = 'gray' # 'gray', 'gray_norot' (without rotation of objects)
+plarg_defaults.trainNsamples                 = 10000
+plarg_defaults.unsupervised_trainNsamples    = 250000 # 10000 250000 1250000
+plarg_defaults.testNsamples                  = 5000
+plarg_defaults.validNsamples                 = plargs.testNsamples
+plarg_defaults.Extension                     = 'vmat'
+
+Path                          = plargs.Path                       # Directory where are the datasets'files
+Encoding                      = plargs.Encoding                   # layerType of Encoding (onehot, 1gram, 2gram, 3gram, ...)
+Topics                        = plargs.Topics                     # Question topic (color, color-size, color-size-location, color-size-location-shape, ...)
+Size                          = plargs.Size                       # Image width/height
+Nobj                          = plargs.Nobj                       # Number of objects in the image
+ImageType                     = plargs.ImageType                  # Color encoding (gray, color) and other features (no rotation...)
+trainNsamples                 = plargs.trainNsamples              # number of training samples
+unsupervised_trainNsamples    = plargs.unsupervised_trainNsamples # number of training samples
+testNsamples                  = plargs.testNsamples               # number of samples to test
+validNsamples                 = plargs.validNsamples              # number of validation samples
+Extension                     = plargs.Extension                  # extension of the input files
+
+
+plarg_defaults.nRBM                     = 3
+plarg_defaults.NH1                      = 500
+plarg_defaults.NH2                      = 500
+plarg_defaults.NH3                      = 500
+plarg_defaults.batchSize                = 50
+plarg_defaults.layerType                = 'gaussian'
+plarg_defaults.unsupervised_nStages     = int(unsupervised_trainNsamples)
+plarg_defaults.supervised_nStages       = 100  # /!\ see after: supervised_nStages   *= trainNsamples
+plarg_defaults.nStagesStep              = 5
+plarg_defaults.LR_CDiv                  = 0.01
+plarg_defaults.LR_GRAD_UNSUP            = 0.003
+plarg_defaults.LR_SUP                   = 0.03
+plarg_defaults.L2wd_SUP                 = 1e-5
+plarg_defaults.nGibbs                   = 1
+plarg_defaults.Tag                      = 'dbn-'+str(plargs.nRBM)+'RBMimage'
+
+# Network structure
+nRBM          = int(plargs.nRBM)
+NH1           = int(plargs.NH1)                        # num units for the image part
+NH2           = int(plargs.NH2)                        # num units, 2nd hid layer (image part)
+NH3           = int(plargs.NH3)                        # num units, 2rd hid layer
+layerType                = plargs.layerType
+#
+# Network learning parameters
+batchSize                 = int(plargs.batchSize)                # num of samples in the minibatch
+unsupervised_nStages      = int(plargs.unsupervised_nStages)                # total number of samples to see (unsupervised phase)
+supervised_nStages        = int(plargs.supervised_nStages)                # total number of samples to see (supervised phase)
+supervised_nStages       *= trainNsamples
+nStagesStep               = int(plargs.nStagesStep)                #
+LR_CDiv                   = float(plargs.LR_CDiv)                # unsup. lr
+LR_GRAD_UNSUP             = float(plargs.LR_GRAD_UNSUP)         # super. lr
+LR_SUP                    = float(plargs.LR_SUP) # super. lr
+L2wd_SUP                  = float(plargs.L2wd_SUP)
+nGibbs                     = int(plargs.nGibbs)
+#
+# Other
+Tag                     = plargs.Tag
+
+
+
+BaseDir =  '/u/louradoj/PRGM/blocksworld/res/'+os.path.basename(Path)
+data_filename = Path+'/BABYAI_'+ImageType+'_'+str(unsupervised_trainNsamples)+'x'+str(Nobj)+'obj_'+str(Size)+'x'+str(Size)+'.'+Topics+'.train.'+Encoding+'.'+Extension
+BaseTag = Tag+'_'+layerType+'_'+basename_withoutExt(data_filename)
+
+unsupervised_expdir = BaseDir + '/greedyDBN/UNSUP_' + BaseTag + '_'+layerType+''.join(['_N'+str(i)+'-'+str(globals()['NH'+str(i)]) for i in range(1,nRBM+1)])+'_LRs'+str(LR_CDiv)+'-'+str(LR_GRAD_UNSUP)+'_ns'+str(unsupervised_nStages)+'_ng'+str(nGibbs) 
+finetuning_expdir = BaseDir + '/greedyDBN/FINETUNE_' + BaseTag + '_'+layerType+''.join(['_N'+str(i)+'-'+str(globals()['NH'+str(i)]) for i in range(1,nRBM+1)])+'_LRs'+str(LR_CDiv)+'-'+str(LR_GRAD_UNSUP)+'-'+str(LR_SUP)+'_WD'+str(L2wd_SUP)+'_ns'+str(unsupervised_nStages)+'-'+str(supervised_nStages)+'_ng'+str(nGibbs)
+
+if LR_SUP==None or LR_SUP == 0:
+   print &quot;UNSUPERVISED-way trained model&quot;
+   learner_filename = unsupervised_expdir+&quot;/init_learner.psave&quot;
+else:
+   print &quot;supervised FINETUNED model&quot;
+   learner_filename = finetuning_expdir+&quot;/Split0/final_learner.psave&quot;
+
+#os.system('python '+os.path.dirname(os.path.abspath(sys.argv[0]))+'/sample.py '+' '.join([ learner_filename, str(Size*Size), data_filename, 'gibbs_step='+str(gibbs_step) ]))
+os.system('python '+os.path.dirname(os.path.abspath(sys.argv[0]))+'/sample_from_hidden.py '+' '.join([ learner_filename, str(Size*Size), 'gibbs_step='+str(gibbs_step) ]))

Added: trunk/python_modules/plearn/learners/modulelearners/examples/sample.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/examples/sample.py	2007-06-22 19:24:00 UTC (rev 7633)
+++ trunk/python_modules/plearn/learners/modulelearners/examples/sample.py	2007-06-22 22:20:56 UTC (rev 7634)
@@ -0,0 +1,211 @@
+from plearn.learners.modulelearners import *
+import random, sys, os.path
+
+from pygame import *
+from math import *
+
+
+zoom_factor = 5
+
+def init_screen(Nim):
+    init()
+    width = int(sqrt(Nim*1.0))
+    if width**2 != Nim:
+       width = int(sqrt(Nim*1.0))+1
+#       raise TypeError, &quot;This code only deals with square images\n(and image size &quot;+str(Nim)+&quot; is not the square of an integer)&quot;
+    width *= zoom_factor
+    return display.set_mode([width, width])
+
+
+def draw_image(visible,screen):
+    Nim=len(visible)
+    width = int(sqrt(Nim*1.0))
+#    if width**2 != Nim:
+#       raise TypeError, &quot;This code only deals with square images\n(and image size &quot;+str(Nim)+&quot; is not the square of an integer)&quot;
+    width *= zoom_factor
+    surface = Surface((width, width),0,8)
+    surface.set_palette([(i,i,i) for i in range(2**8)])
+    for x in range(width/zoom_factor):
+       for y in range(width/zoom_factor):
+           graycol = max(min(255,int(255.0*visible[x*width/zoom_factor+y])),0)
+           for i in range(zoom_factor):
+               for j in range(zoom_factor):
+                   surface.set_at((x*zoom_factor+i,y*zoom_factor+j),(graycol,graycol,graycol,255))
+    screen.blit(surface, (0,0))
+    display.update()
+    return pause()
+  
+def pause():
+   c = sys.stdin.readline()
+   if c.strip() == 'q' or  c.strip() == 'x':
+      sys.exit(0)
+   if c.strip() == 'n' :
+      return -1
+   try: return int(c.strip())
+   except: return 0
+
+
+if __name__ == &quot;__main__&quot;:
+
+  if len(sys.argv) &lt; 2:
+     print &quot;Usage:\n\t&quot; + sys.argv[0] + &quot; &lt;ModuleLearner_filename&gt; &lt;Image_size&gt; &lt;dataSet_filename&gt; [gibbs_step=&lt;gibbs_step&gt;]\n&quot;
+     print &quot;Purpose:\n\tSee consecutive Gibbs sample&quot;
+     print &quot;\twhen input visible units are initalized with real images&quot;
+     print &quot;Tips:\n\tOnce you can see an image type&quot;
+     print &quot;\t:    &lt;ENTER&gt;   : to continue Gibbs Sampling (same gibbs step)&quot;
+     print &quot;\t: &lt;an integer&gt; : to change the gibbs step (10 will set the number of gibbs step between each example to 10)&quot;
+     print &quot;\t:      n       : (next) to try with another image as initialization&quot;
+     print &quot;\t:      q       : (quit) to stop the massacre\n&quot;
+     sys.exit()
+
+  learner_filename = sys.argv[1]
+  Nim = int(sys.argv[2])
+  data_filename = sys.argv[3]
+     
+  plarg_defaults.gibbs_step                    = 10
+  gibbs_step                                   = plargs.gibbs_step # Number of Gibbs step between each sampling
+
+     
+  if os.path.isfile(learner_filename) == False:
+     raise TypeError, &quot;Cannot find file &quot;+learner_filename
+  print &quot; loading... &quot;+learner_filename
+  learner = loadObject(learner_filename)
+  if 'HyperLearner' in str(type(learner)):
+     learner=learner.learner
+  
+  if os.path.isfile(data_filename) == False:
+     raise TypeError, &quot;Cannot find file &quot;+data_filename
+  print &quot; loading... &quot;+data_filename
+  dataSet = pl.AutoVMatrix( specification = data_filename )
+
+  #
+  # Getting the RBMmodule which sees the image (looking at size of the down layer)
+  #
+  modules=getModules(learner)
+  for i in range(len(modules)):
+     module = modules[i]
+     if isModule(module,'RBM') and module.connection.down_size == Nim:
+        image_RBM=learner.module.modules[i]
+        break
+  image_RBM_name=image_RBM.name
+  #
+  # Getting the top RBMmodule
+  #
+
+  top_RBM = getTopRBMModule( learner )
+  top_RBM_name = top_RBM.name
+  
+  NH=top_RBM.connection.up_size
+
+
+  init_ports = [ ('input',  image_RBM_name+'.visible'),
+                 ('output', top_RBM_name+'.hidden_sample')
+               ]
+  ports = [ ('input', top_RBM_name+'.hidden_sample' ),
+            ('output', image_RBM_name+'.visible_expectation')
+            ]
+
+  #
+  # Removing useless connections for sampling
+  #
+  old_connections_list = copy.copy(learner.module.connections)
+  conn_toremove=[]
+  connections_list_down=[]
+  connections_list_up=[]
+  for connection in old_connections_list:
+      source_module = getModule( learner, port2moduleName( connection.source ))
+      dest_module   = getModule( learner, port2moduleName( connection.destination ))
+      if isModule( source_module, 'RBM') and isModule( dest_module,'RBM'):
+         connections_list_up.append ( pl.NetworkConnection(source = port2moduleName( connection.source )+'.hidden_sample',
+                                                           destination = port2moduleName( connection.destination )+'.visible_sample',
+                                                           propagate_gradient = 0) )
+         connections_list_down.append ( pl.NetworkConnection(source = port2moduleName( connection.destination )+'.visible_sample',
+                                                    destination = port2moduleName( connection.source )+'.hidden_sample',
+                                                    propagate_gradient = 0) )
+  
+  #
+  # Removing useless modules for sampling
+  #
+  modules_list = getModules(learner)
+  mod_toremove=[]
+  for module in modules_list:
+      if isModule( module, 'RBM') == False:
+         mod_toremove.append(module)
+  for module in mod_toremove:
+      modules_list.remove(module)
+  
+  
+  RBMnetwork = pl.NetworkModule(
+                          modules = modules_list,
+                          connections = connections_list_down,
+                          ports = ports,
+                          # to avoid calling the forget() method in ModuleLearner                          
+                          random_gen = pl.PRandom( seed = 1827 ),
+                          # Hack from Olivier
+                          save_states = 0
+                         )
+  RBMnetworkInit = pl.NetworkModule(
+                          modules = modules_list,
+                          connections = connections_list_up,
+                          ports = init_ports,
+                          # to avoid calling the forget() method in ModuleLearner                          
+                          random_gen = pl.PRandom( seed = 1827 ),
+                          # Hack from Olivier
+                          save_states = 0
+                         )
+
+  
+  RBMmodel = pl.ModuleLearner(
+                              cost_ports = [],
+                              target_ports = [],
+                              module = RBMnetwork
+                           )
+  RBMmodelInit = pl.ModuleLearner(
+                              cost_ports = [],
+                              target_ports = [],
+                              module = RBMnetworkInit
+                           )
+
+
+
+  RBMmodelInit.setTrainingSet(pl.AutoVMatrix(inputsize=Nim, targetsize=0, weightsize=0), False)
+  RBMmodel.setTrainingSet(pl.AutoVMatrix(inputsize=NH, targetsize=0, weightsize=0), False)
+
+
+  screen=init_screen(Nim)
+  random.seed(1969)
+
+  for i in range(len(RBMmodel.module.modules)):
+    module = RBMmodel.module.modules[i]
+    if isModule( module, 'RBM'):
+       RBMmodel.module.modules[i].compute_contrastive_divergence = False
+       if module.name == top_RBM_name:
+          RBMmodel.module.modules[i].n_Gibbs_steps_per_generated_sample = gibbs_step
+          top_RBM = RBMmodel.module.modules[i]
+
+  while True:
+ 
+   random_index=random.randint(0,dataSet.length)
+   init_image=[dataSet.getRow(random_index)[i] for i in range(Nim)]
+   
+   c = draw_image( init_image, screen )
+   if c&lt;0:
+      continue
+   elif c&gt;0:
+      top_RBM.n_Gibbs_steps_per_generated_sample = c
+   
+   init_hidden = RBMmodelInit.computeOutput(init_image)
+   c = draw_image( RBMmodel.computeOutput(init_hidden), screen )
+   if c&lt;0:
+      break
+   elif c&gt;0:
+      top_RBM.n_Gibbs_steps_per_generated_sample = c
+   
+      
+   while True:
+       c = draw_image( RBMmodel.computeOutput([]) , screen)
+       if c&lt;0:
+          break
+       elif c&gt;0:
+          top_RBM.n_Gibbs_steps_per_generated_sample = c
+    

Added: trunk/python_modules/plearn/learners/modulelearners/examples/sample_from_hidden.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/examples/sample_from_hidden.py	2007-06-22 19:24:00 UTC (rev 7633)
+++ trunk/python_modules/plearn/learners/modulelearners/examples/sample_from_hidden.py	2007-06-22 22:20:56 UTC (rev 7634)
@@ -0,0 +1,173 @@
+from plearn.learners.modulelearners import *
+import random, sys, os.path
+
+from pygame import *
+from math import *
+
+
+zoom_factor = 5
+
+def init_screen(Nim):
+    init()
+    width = int(sqrt(Nim*1.0))
+    if width**2 != Nim:
+       width = int(sqrt(Nim*1.0))+1
+#       raise TypeError, &quot;This code only deals with square images\n(and image size &quot;+str(Nim)+&quot; is not the square of an integer)&quot;
+    width *= zoom_factor
+    return display.set_mode([width, width])
+
+
+def draw_image(visible,screen):
+    Nim=len(visible)
+    width = int(sqrt(Nim*1.0))
+#    if width**2 != Nim:
+#       raise TypeError, &quot;This code only deals with square images\n(and image size &quot;+str(Nim)+&quot; is not the square of an integer)&quot;
+    width *= zoom_factor
+    surface = Surface((width, width),0,8)
+    surface.set_palette([(i,i,i) for i in range(2**8)])
+    for x in range(width/zoom_factor):
+       for y in range(width/zoom_factor):
+           graycol = max(min(255,int(255.0*visible[x*width/zoom_factor+y])),0)
+           for i in range(zoom_factor):
+               for j in range(zoom_factor):
+                   surface.set_at((x*zoom_factor+i,y*zoom_factor+j),(graycol,graycol,graycol,255))
+    screen.blit(surface, (0,0))
+    display.update()
+    return pause()
+  
+def pause():
+   c = sys.stdin.readline()
+   if c.strip() == 'q' or  c.strip() == 'x':
+      sys.exit(0)
+   if c.strip() == 'n' :
+      return -1
+   try: return int(c.strip())
+   except: return 0
+
+
+if __name__ == &quot;__main__&quot;:
+
+  if len(sys.argv) &lt; 2:
+     print &quot;Usage:\n\t&quot; + sys.argv[0] + &quot; &lt;ModuleLearner_filename&gt; &lt;Image_size&gt;\n&quot;
+     print &quot;Purpose:\n\tSee consecutive Gibbs sample&quot;
+     print &quot;\twhen top hidden units are initalized randomly&quot;
+     print &quot;Tips:\n\tOnce you can see an image type&quot;
+     print &quot;\t:    &lt;ENTER&gt;   : to continue Gibbs Sampling (same gibbs step)&quot;
+     print &quot;\t: &lt;an integer&gt; : to change the gibbs step (10 will set the number of gibbs step between each example to 10)&quot;
+     print &quot;\t:      n       : (next) to try another hidden state for initialization&quot;
+     print &quot;\t:      q       : (quit) to stop the massacre\n&quot;
+     sys.exit()
+
+  learner_filename = sys.argv[1]
+  Nim = int(sys.argv[2])
+     
+  plarg_defaults.gibbs_step                    = 10
+  gibbs_step                                   = plargs.gibbs_step # Number of Gibbs step between each sampling
+
+     
+  if os.path.isfile(learner_filename) == False:
+     raise TypeError, &quot;Cannot find file &quot;+learner_filename
+  print &quot; loading... &quot;+learner_filename
+  learner = loadObject(learner_filename)
+  if 'HyperLearner' in str(type(learner)):
+     learner=learner.learner
+
+  #
+  # Getting the RBMmodule which sees the image (looking at size of the down layer)
+  #
+  modules=getModules(learner)
+  for i in range(len(modules)):
+     module = modules[i]
+     if isModule(module,'RBM') and module.connection.down_size == Nim:
+        image_RBM=learner.module.modules[i]
+        break
+  image_RBM_name=image_RBM.name
+  #
+  # Getting the top RBMmodule
+  #
+
+  top_RBM = getTopRBMModule( learner )
+  top_RBM_name = top_RBM.name
+  
+  NH=top_RBM.connection.up_size
+
+
+  ports = [ ('input', top_RBM_name+'.hidden_sample' ),
+            ('output', image_RBM_name+'.visible_expectation')
+            ]
+
+  #
+  # Removing useless connections for sampling
+  #
+  old_connections_list = copy.copy(learner.module.connections)
+  conn_toremove=[]
+  connections_list_down=[]
+  connections_list_up=[]
+  for connection in old_connections_list:
+      source_module = getModule( learner, port2moduleName( connection.source ))
+      dest_module   = getModule( learner, port2moduleName( connection.destination ))
+      if isModule( source_module, 'RBM') and isModule( dest_module,'RBM'):
+         connections_list_down.append ( pl.NetworkConnection(source = port2moduleName( connection.destination )+'.visible_sample',
+                                                    destination = port2moduleName( connection.source )+'.hidden_sample',
+                                                    propagate_gradient = 0) )
+  
+  #
+  # Removing useless modules for sampling
+  #
+  modules_list = getModules(learner)
+  mod_toremove=[]
+  for module in modules_list:
+      if isModule( module, 'RBM') == False:
+         mod_toremove.append(module)
+  for module in mod_toremove:
+      modules_list.remove(module)
+  
+  
+  RBMnetwork = pl.NetworkModule(
+                          modules = modules_list,
+                          connections = connections_list_down,
+                          ports = ports,
+                          # to avoid calling the forget() method in ModuleLearner                          
+                          random_gen = pl.PRandom( seed = 1827 ),
+                          # Hack from Olivier
+                          save_states = 0
+                         )
+
+  
+  RBMmodel = pl.ModuleLearner(
+                              cost_ports = [],
+                              target_ports = [],
+                              module = RBMnetwork
+                           )
+
+
+  RBMmodel.setTrainingSet(pl.AutoVMatrix(inputsize=NH, targetsize=0, weightsize=0), False)
+
+  screen=init_screen(Nim)
+  random.seed(1969)
+
+  for i in range(len(RBMmodel.module.modules)):
+    module = RBMmodel.module.modules[i]
+    if isModule( module, 'RBM'):
+       RBMmodel.module.modules[i].compute_contrastive_divergence = False
+       if module.name == top_RBM_name:
+          RBMmodel.module.modules[i].n_Gibbs_steps_per_generated_sample = gibbs_step
+          top_RBM = RBMmodel.module.modules[i]
+
+  while True:
+ 
+   init_hidden=[random.randint(0,1) for i in range(NH)]
+   
+   c = draw_image( RBMmodel.computeOutput(init_hidden), screen )
+   if c&lt;0:
+      continue
+   elif c&gt;0:
+      top_RBM.n_Gibbs_steps_per_generated_sample = c
+      
+   while True:
+       c = draw_image( RBMmodel.computeOutput([]) , screen)
+       if c&lt;0:
+          break
+       elif c&gt;0:
+          top_RBM.n_Gibbs_steps_per_generated_sample = c
+    


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001081.html">[Plearn-commits] r7633 -	branches/cgi-desjardin/plearn_learners/second_iteration
</A></li>
	<LI>Next message: <A HREF="001083.html">[Plearn-commits] r7635 -	trunk/python_modules/plearn/learners/modulelearners/examples
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1082">[ date ]</a>
              <a href="thread.html#1082">[ thread ]</a>
              <a href="subject.html#1082">[ subject ]</a>
              <a href="author.html#1082">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
