<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7578 - in trunk/python_modules/plearn/learners: .	modulelearners modulelearners/examples
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7578%20-%20in%20trunk/python_modules/plearn/learners%3A%20.%0A%09modulelearners%20modulelearners/examples&In-Reply-To=%3C200706132115.l5DLFwWY007639%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001026.html">
   <LINK REL="Next"  HREF="001028.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7578 - in trunk/python_modules/plearn/learners: .	modulelearners modulelearners/examples</H1>
    <B>louradou at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7578%20-%20in%20trunk/python_modules/plearn/learners%3A%20.%0A%09modulelearners%20modulelearners/examples&In-Reply-To=%3C200706132115.l5DLFwWY007639%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7578 - in trunk/python_modules/plearn/learners: .	modulelearners modulelearners/examples">louradou at mail.berlios.de
       </A><BR>
    <I>Wed Jun 13 23:15:58 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001026.html">[Plearn-commits] r7577 - trunk/plearn/misc
</A></li>
        <LI>Next message: <A HREF="001028.html">[Plearn-commits] r7579 -	trunk/python_modules/plearn/learners/modulelearners
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1027">[ date ]</a>
              <a href="thread.html#1027">[ thread ]</a>
              <a href="subject.html#1027">[ subject ]</a>
              <a href="author.html#1027">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: louradou
Date: 2007-06-13 23:15:55 +0200 (Wed, 13 Jun 2007)
New Revision: 7578

Added:
   trunk/python_modules/plearn/learners/modulelearners/
   trunk/python_modules/plearn/learners/modulelearners/__init__.py
   trunk/python_modules/plearn/learners/modulelearners/__init__.pyc
   trunk/python_modules/plearn/learners/modulelearners/examples/
   trunk/python_modules/plearn/learners/modulelearners/examples/plugNetwork2SVM.py
   trunk/python_modules/plearn/learners/modulelearners/network_view.py
   trunk/python_modules/plearn/learners/modulelearners/network_view.pyc
   trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.py
   trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.pyc
Modified:
   trunk/python_modules/plearn/learners/discr_power_SVM.py
Log:
Some tools to &quot;easily&quot; handle NetworkModule and ModuleLearner objects.
In particular, to &quot;plug&quot; SVM on some module(s) of a network (see in modulelearners/examples).
run network_view.py to draw a network (or several) declared in a .pyplearn
script or saved in a .psave file (.py file will be functional soon...)



Modified: trunk/python_modules/plearn/learners/discr_power_SVM.py
===================================================================
--- trunk/python_modules/plearn/learners/discr_power_SVM.py	2007-06-13 03:07:30 UTC (rev 7577)
+++ trunk/python_modules/plearn/learners/discr_power_SVM.py	2007-06-13 21:15:55 UTC (rev 7578)
@@ -68,7 +68,7 @@
 	  self.parameters_names += ['gamma']
 
       def init_gamma(self, gamma):
-          return [gamma/9., gamma, gamma*9.]
+          return [gamma, gamma/9., gamma*9.]
 	  
       def init_parameters( self, samples ):
           dim = len(samples[0])
@@ -131,7 +131,8 @@
       __attributes__ = ['accuracy',
                         'valid_accuracy',
 			'best_parameters',
-			'tried_parameters'
+			'tried_parameters',
+			'save_filename'
 			]
        
       def __init__( self ):
@@ -146,6 +147,8 @@
 	  self.best_parameters      = None  
 	  self.tried_parameters     = {}
 	  
+	  self.save_filename        = None
+	  
           # For cross-validation
 	  self.nr_fold        = 5
 
@@ -197,6 +200,16 @@
 		     train_problem = svm_problem( samples_target_list[0][1] , samples_target_list[0][0] )
 		     model = svm_model(train_problem, param)
 		     accuracy = do_simple_validation(model, samples_target_list[1][0], samples_target_list[1][1], param)
+		     
+		     if self.save_filename != None:
+		        try:
+		           FID=open(self.save_filename,'a')
+		           FID.write('------------\nTry with '+kernel_type+' kernel :\n')
+		           FID.write('parameters : '+str(parameters)+'\n')
+		           FID.write(' --&gt; Accuracy = '+str(accuracy)+'\n')
+		           FID.close()
+		        except:
+		           print &quot;COULD not write in save_filename&quot;   
 		     	     
 		  if accuracy &gt; best_accuracy:
 		         best_parameters = parameters
@@ -232,7 +245,26 @@
 	     model = svm_model(train_problem, param)
 	     accuracy = do_simple_validation(model, samples_target_list[1][0], samples_target_list[1][1], param)
 	  return accuracy
-    
+
+def normalize(data,mean,std):
+    if mean == None:
+       mean=[]
+       for i in range(len(data[0])):
+           mean.append( get_mean_cmp(data,i) )
+    if std == None:
+       std=[]
+       for i in range(len(data[0])):
+           std_tmp=get_std_cmp(data,i)
+	   if std_tmp == 0.:
+	      print &quot;WARNING : standard deviation is 0 on component &quot;+str(i)
+	      std.append( 1. )
+	   else:
+              std.append( std_tmp )
+    for i in range(len(data[0])):
+        for j in range(len(data)):
+	    data[j][i]=(data[j][i]-mean[i])/std[i]
+    return mean, std
+
 def mean_std(data):
     stds=[get_std_cmp(data,i) for i in range(len(data[0]))]
     return sum(stds)/len(stds)
@@ -242,6 +274,9 @@
     avg = tot*1.0/len(values)
     sdsq = sum([(i-avg)**2 for i in values])
     return (sdsq*1.0/(len(values)-1 or 1))**.5
+def get_mean_cmp(data,i):
+    values=[vec[i] for vec in data]
+    return  sum(values)/len(values)
 
 def arithm_mean(data):
     if type(data[0]) == list:

Added: trunk/python_modules/plearn/learners/modulelearners/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/__init__.py	2007-06-13 03:07:30 UTC (rev 7577)
+++ trunk/python_modules/plearn/learners/modulelearners/__init__.py	2007-06-13 21:15:55 UTC (rev 7578)
@@ -0,0 +1,647 @@
+import sys, os, os.path
+import plearn.bridgemode
+plearn.bridgemode.interactive = False
+plearn.bridgemode.useserver= False
+from plearn.bridge import *
+#from plearn.pyplearn import *
+
+from plearn.learners.autolr import deepcopy
+
+from plearn.learners.modulelearners.network_view import *
+
+tmp_file='/tmp/modulelearner.py'
+
+def dirtydeepcopy( myObject ):
+    myObject.save(tmp_file,'plearn_ascii')
+    return loadObject(tmp_file)
+
+if plearn.bridgemode.useserver:
+    learner  = serv.new(learner)
+    trainset = serv.new(trainset)
+    validset = serv.new(validset)
+    testset  = serv.new(testset)
+
+
+# examples:
+#   isModule(module,'RBM')
+#   isModule(module,'Split')
+#
+def isModule(module,name):
+    return name+'Module' in str(type(module))
+
+
+# Handling files...
+
+def loadNetworkModule(filename):
+    modulelearner = loadModuleLearner(filename)
+    if 'module' not in modulelearner._optionnames:
+       raise TypeError, &quot;ModuleLearner has no option module&quot;
+    if 'NetworkModule' not in str(type(modulelearner.module)):
+       raise TypeError, &quot;ModuleLearner.module is not a NetworkModule&quot;
+    return modulelearner.module
+    
+
+def loadModuleLearner(filename):
+    if os.path.isfile(filename) == False:
+       raise TypeError, &quot;could not find the file &quot;+filename
+    extension = os.path.splitext(filename)[1]
+    
+    if extension == '.pyplearn':
+       from plearn.learners.modulelearners.pyplearn_read import *
+       object_dict = read_objects( filename, ['HyperLearner', 'PTester', 'MemoryVMatrix', 'AutoVMatrix'] , tmp_file)
+       execfile(tmp_file)
+       modules=[]
+       for i in object_dict['ModuleLearner']:
+           modules += eval(i)
+       if len(modules) == 0:
+          raise TypeError, &quot;could not find a NetworkModule in &quot;+filename
+       if len(modules) == 1:
+          return modules[0]
+       else:
+          print &quot;WARNING: found several NetworkModules in &quot;+filename+&quot; (a list is returned)&quot;
+	  return modules
+	  
+    elif extension == '.psave':
+       myObject = loadObject(filename)
+       if 'ModuleLearner' in str(type(myObject)):
+          return myObject
+       elif 'HyperLearner' in str(type(myObject)):
+          if 'ModuleLearner' in str(type(myObject.learner)):
+	     return myObject.learner
+	  else:
+	     raise TypeError, &quot;The learner of HyperLearner in &quot;+filename+&quot; has type &quot;+str(type(myObject.learner))
+       else:
+          raise TypeError, &quot;Could not recognize the type &quot;+str(type(myObject))
+
+    else:
+       raise TypeError, &quot;could not recognize the extension (&quot;+extension+&quot;) of &quot;+filename
+
+# String tools...
+
+def port2moduleName( portName ):
+    return portName.split('.')[0]
+
+
+# Getting information about the network...
+
+
+def getModules( myObject ):
+    # Network module
+    if 'NetworkModule' in str(type(myObject)):
+       return copy.copy( myObject.modules )
+    # Module Learner
+    elif 'ModuleLearner' in str(type(myObject)):
+       return copy.copy( myObject.module.modules )
+    # List of modules
+    elif type(myObject) == list and 'Module' in str(type(myObject[0])):
+         return myObject
+    else:
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+
+def setModules( myObject , new_connections_list):
+    if 'NetworkModule' in str(type(myObject)):
+       myObject.setOptionFromPython('modules',new_connections_list)
+    elif 'ModuleLearner' in str(type(myObject)):
+       myObject.module.setOptionFromPython('modules',new_connections_list)
+    else:
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+
+
+def getModulesNames( myObject ):
+    modules_names=[]
+    for module in getModules(myObject):
+        modules_names.append(module.name)
+    return modules_names
+
+
+def getModule( myObject, modulename ):
+    modules_names = getModulesNames( myObject )
+    if modulename not in modules_names:
+       raise TypeError, &quot;Could not find module &quot;+modulename
+    index = modules_names.index( modulename )
+    # Network module
+    if 'NetworkModule' in str(type(myObject)):
+       return copy.copy( myObject.modules[index] )
+    # Module Learner
+    elif 'ModuleLearner' in str(type(myObject)):
+       return copy.copy( myObject.module.modules[index] )
+    # List of modules
+    elif type(myObject) == list and 'Module' in str(type(myObject[0])):
+       return myObject[index]
+    else:
+       raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+    
+def getConnections( myObject ):
+    if 'NetworkModule' in str(type(myObject)):
+       return copy.copy( myObject.connections )
+    elif 'ModuleLearner' in str(type(myObject)):
+       return copy.copy( myObject.module.connections )
+    else:
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+
+def setConnections( myObject , new_connections_list):
+    if 'NetworkModule' in str(type(myObject)):
+       myObject.setOptionFromPython('connections',new_connections_list)
+    elif 'ModuleLearner' in str(type(myObject)):
+       myObject.module.setOptionFromPython('connections',new_connections_list)
+    else:
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+
+def getPorts( myObject ):
+    if 'NetworkModule' in str(type(myObject)):
+       return copy.copy( myObject.ports )
+    elif 'ModuleLearner' in str(type(myObject)):
+       return copy.copy( myObject.module.ports )
+    else:
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+
+def setPorts( myObject , new_connections_list):
+    if 'NetworkModule' in str(type(myObject)):
+       myObject.setOptionFromPython('ports',new_connections_list)
+    elif 'ModuleLearner' in str(type(myObject)):
+       myObject.module.setOptionFromPython('ports',new_connections_list)
+    else:
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+
+def get_last_layer_module_name( learner ):
+    last_layer = []
+    output_layer = getOutputModuleName(learner)
+    connections_list = getConnections(learner)
+    for connection in connections_list:
+        if output_layer in connection.destination:
+	   last_layer.append( port2moduleName( connection.source ) )
+    if len(last_layer) != 1:
+       raise TypeError, &quot;find several layers before output layer\n(&quot; + str(last_layer) + &quot;)&quot;
+    return last_layer[0]
+
+def get_last_layer_module( learner ):
+    last_module_name = get_last_layer_module_name(learner)
+    modules_list = getModules( learner )
+    for module in modules_list:
+        if module.name == last_module_name:
+	   return module
+
+def getOutputModuleName( learner ):
+    outputPort = getOutputPort(learner)
+    return port2moduleName(outputPort[1])
+
+def getOutputPort( learner ):
+    ports_list = getPorts(learner)
+    for port in ports_list:
+        if 'output' in port:
+           return port
+    raise 'cannot find output port of learner'
+
+def getCostModuleName( learner ):
+    costPort = getCostPort(learner)
+    return port2moduleName(costPort[1])
+
+def getCostPort( learner ):
+    cost_port = learner.cost_ports[0]
+    ports_list = getPorts(learner)
+    for port in ports_list:
+        if cost_port in port:
+           return port
+    raise 'cannot find output port of learner'
+
+
+def getSourcePorts( learner, modulename ):
+    inputports = []
+    for connection in getConnections(learner):
+        if modulename in connection.destination:
+	   inputports.append( connection.source )
+    return inputports
+
+def getAllPrevious( myObject, modulename ):
+    connections_list = getConnections(myObject)
+    previous_connections = []
+    previous_modulenames = []
+    for connection in connections_list:
+        if modulename in connection.destination:
+	   previous_connections.append(connection)
+	   previous_modulenames.append(port2moduleName(connection.source))
+    for sourcename in previous_modulenames:
+        connections, sources = getAllPrevious(myObject, sourcename)
+        for connection in connections:
+	    if connection not in previous_connections:
+               previous_connections.append(connection)
+	       source = port2moduleName(connection.source)
+	       if source not in previous_modulenames:
+	          previous_modulenames.append(source)
+    return previous_connections, previous_modulenames
+
+def getAllPreviousConnection( myObject, modulename ):
+    previous_connections, previous_modulenames = getAllPrevious( myObject, modulename )
+    return previous_connections
+
+
+def getPrevious( myObject, modulename ):
+    connections_list = getConnections(myObject)
+    previous_connections = []
+    previous_modulenames = []
+    for connection in connections_list:
+        if modulename in connection.destination:
+	   previous_connections.append(connection)
+	   previous_modulenames.append(port2moduleName(connection.source))
+    return previous_connections, previous_modulenames
+
+def getPreviousConnection( myObject, modulename ):
+    connections_list = getConnections(myObject)
+    previous_connections = []
+    for connection in connections_list:
+        if modulename in connection.destination:
+	   previous_connections.append(connection)
+    return previous_connections
+
+def getAllNext( myObject, modulename ):
+    connections_list = getConnections(myObject)
+    next_connections = []
+    next_modulenames = []
+    for connection in connections_list:
+        if modulename in connection.source:
+	   next_connections.append(connection)
+	   next_modulenames.append(port2moduleName(connection.destination))
+    for sourcename in next_modulenames:
+        connections, sources = getAllNext(myObject, sourcename)
+        for connection in connections:
+	    if connection not in next_connections:
+               next_connections.append(connection)
+	       source = port2moduleName(connection.destination)
+	       if source not in next_modulenames:
+	          next_modulenames.append(source)
+    return next_connections, next_modulenames
+
+def getNext( myObject, modulename ):
+    connections_list = getConnections(myObject)
+    next_connections = []
+    next_modulenames = []
+    for connection in connections_list:
+        if modulename in connection.source:
+	   next_connections.append(connection)
+	   next_modulenames.append(port2moduleName(connection.destination))
+    return next_connections, next_modulenames
+
+
+def removeLastModule( learner , modulename ):
+    return removeModule( learner , getOutputModuleName(learner) )
+
+def removeModuleFromNetwork( network , modulename ):
+    modules_name_list = getModulesNames(network)
+    if modulename not in modules_name_list:
+       raise TypeError, &quot;Module's name &quot;+modulename+&quot; not found in ModuleLearner&quot; 
+
+    new_network = deepcopy(network)
+
+    connections_list     = getConnections(network)
+    new_connections_list = getConnections(network)
+    ports_list     = getPorts(network)
+    new_ports_list = getPorts(network)
+    modules_list     = getModules(network)
+    new_modules_list = getModules(network)
+
+
+           
+    # Creating the list of top modules to remove
+    # (looking at the connections)
+    #        
+    connections_to_reject, modules_to_reject = getAllNext( network, modulename )
+    modules_to_reject.append(modulename)
+    #connections_to_reject.append(getPreviousConnection(network, modulename))
+
+    # Rejecting modules
+    #
+    for module in modules_list:
+        if module.name in modules_to_reject:
+	   new_modules_list.remove(module)
+
+
+    # Rejecting connections
+    #
+    for module_being_rejected in modules_to_reject:
+          for connection in connections_list:
+              if module_being_rejected in connection.source+&quot; &quot;+connection.destination and connection in new_connections_list:
+                 new_connections_list.remove(connection)
+		 
+    # Rejecting ports
+    #
+    new_output = None
+    for port in ports_list:
+        if port2moduleName(port[1]) in modules_to_reject:
+           new_ports_list.remove(port)
+           if port[0] in ['output']:
+	      module_being_rejected = port2moduleName(port[1])
+	      print module_being_rejected
+	      #
+	      # Getting the inputs (to connect to ports)
+              #
+              if new_output == None:
+	         new_outputs = getSourcePorts( network, module_being_rejected )
+		 test_new_outputs = True
+		 while test_new_outputs:
+		       test_new_outputs = False
+		       for checked_output in new_outputs:
+		           checked_module = port2moduleName(checked_output)
+		           if checked_module in modules_to_reject:
+			      new_outputs.remove(checked_output)
+			      new_outputs += getSourcePorts( network, checked_module )
+		              test_new_outputs = True
+			      break
+		 print new_outputs
+                 if len(new_outputs)&gt;1:
+	            output_sizes = []
+		    name_join = '_'+port[0]
+	            for i in range(len(new_outputs)):
+		        port_tmp = new_outputs[i]
+		        new_connections_list.append(pl.NetworkConnection(source = port_tmp,
+		   			                                 destination = name_join+'.in'+str(i),
+		   				                         propagate_gradient = connections_to_reject[0].propagate_gradient
+		   				   ))
+		        module = learner.module.modules[modules_name_list.index(port2moduleName(port_tmp))]
+		        output_size = module.output_size
+		        if output_size == -1:
+		           if 'connection' in module._optionnames:
+			      output_size = module.connection.output_size
+			   else:
+			      raise TypeError, &quot;could not find outputsize of module &quot;+module.name
+                    new_modules_list.append(pl.SplitModule(
+							name = name_join,
+							down_port_name = 'output',
+							up_port_names = ['in'+str(j) for j in range(len(new_outputs))],
+							up_port_sizes = output_sizes
+                                        ))
+                    new_output = name_join+'.output'
+                 else:
+                    new_output = new_outputs[0]
+	      new_port=(port[0],new_output)
+	      new_ports_list.append(new_port)
+
+	   
+    setConnections(new_network, new_connections_list)
+    setPorts(new_network, new_ports_list)
+    setModules(new_network, new_modules_list)
+#    new_network.setOptionFromPython('connections',new_connections_list)
+#    new_network.setOptionFromPython('ports',new_ports_list)
+#    new_network.setOptionFromPython('modules',new_modules_list)
+    return dirtydeepcopy( new_network )
+    return new_network
+    
+
+def removeModuleFromLearner( learner , modulename ):
+    new_learner = deepcopy( learner )
+    new_network = removeModuleFromNetwork( learner.module , modulename )
+    new_ports_list = [ port[0] for port in getPorts(new_network)  ]
+    
+    print new_ports_list
+
+    # Rejecting ports
+    #
+    for port_option_name in ['target_ports', 'cost_ports', 'weight_ports']:
+        output_ports_list     = copy.copy( learner.getOption(port_option_name) )
+	new_output_ports_list = copy.copy( learner.getOption(port_option_name) )
+        for port in output_ports_list:
+            if port not in new_ports_list:
+	       new_output_ports_list.remove(port)
+        new_learner.setOptionFromPython(port_option_name, new_output_ports_list)
+    new_learner.setOptionFromPython('module',new_network)
+
+    return dirtydeepcopy( new_learner )
+    return new_learner
+
+
+def plug2output(myObject, portslist):
+    output_port_tuple = getOutputPort(myObject)
+    output_port = output_port_tuple[1]
+    if len(portslist) == 1 and portslist[0] == output_port:
+       print &quot;WARNING: plug2output return the same myObject&quot;
+       return myObject
+       
+    mynewObject = deepcopy(myObject)
+    new_ports_list = getPorts(myObject)
+    new_ports_list.remove(output_port_tuple)
+    if len(portslist) == 1:
+       new_ports_list.append((output_port_tuple[0],portslist[0]))
+       setPorts(mynewObject, new_ports_list)
+       return dirtydeepcopy( mynewObject )
+       return mynewObject
+    new_modules_list = getModules(myObject)
+    new_connections_list = getConnections(myObject)
+    name_join = &quot;_&quot;.join(portslist).replace('.','')
+    output_sizes = []
+    modules_name_list = getModulesNames(myObject)
+    for i in range(len(portslist)):
+        port = portslist[i]
+        new_connections_list.append(pl.NetworkConnection(source = port,
+		   			                 destination = name_join+'.in'+str(i),
+		   				         propagate_gradient = 0
+		   		    ))
+        module = myObject.module.modules[modules_name_list.index(port2moduleName(port))]
+        output_size = module.output_size
+	optionnames = module._optionnames
+        if 'connection' in optionnames: # RBM
+           output_size = module.connection.output_size
+	elif 'up_port_sizes' in optionnames: # splitModule
+           output_size = module.up_port_sizes[module.up_port_names.index(port.split('.')[1])]
+	else:
+	   output_size = module.output_size
+	   if output_size == -1:      
+              raise TypeError, &quot;could not find outputsize of module &quot;+module.name
+	output_sizes.append(output_size)
+    new_modules_list.append(pl.SplitModule(
+							name = name_join,
+							down_port_name = 'output',
+							up_port_names = ['in'+str(j) for j in range(len(portslist))],
+							up_port_sizes = output_sizes
+                           ))
+    new_ports_list.append((output_port_tuple[0],name_join+'.output'))
+    setConnections(mynewObject, new_connections_list)
+    setPorts(mynewObject, new_ports_list)
+    setModules(mynewObject, new_modules_list)
+    return dirtydeepcopy( mynewObject )
+    return mynewObject
+
+
+
+
+def mean_std(data):
+    stds=[get_std_cmp(data,i) for i in range(len(data[0]))]
+    return sum(stds)/len(stds)
+def get_std_cmp(data,i):
+    values=[vec[i] for vec in data]
+    tot = sum(values)
+    avg = tot*1.0/len(values)
+    sdsq = sum([(i-avg)**2 for i in values])
+    return (sdsq*1.0/(len(values)-1 or 1))**.5
+def proposed_gamma(samples):
+          dim = len(samples[0])
+	  std = mean_std(samples)
+	  rho=sqrt(dim)*std
+          return 1/(2*rho**2)
+	  
+def compute_entries_SVM_write_libSVM_file( learner, dataSet, output_filename ):
+    if os.path.isfile( output_filename ):
+       print &quot;WARNING: file &quot;+output_filename+&quot;already exists&quot;
+       pass
+    temp_file='/tmp/new_learner.psave'
+    learner.save(temp_file,'plearn_ascii')
+    learner = loadObject(temp_file)
+    connect_last_layer2outputs( learner )
+    learner.save(temp_file,'plearn_ascii')
+    learner = loadObject(temp_file)
+    outputs=make_test_output(learner,dataSet)
+    nsamples = dataSet.length
+    outputsize = len(outputs[0])
+    if nsamples != len(outputs):
+       raise &quot;ERROR: conflict in dimensions&quot;
+    else:
+       print str(nsamples)+&quot; samples, new input size =&quot;+str(outputsize)
+    if dataSet.targetsize != 1:
+       raise &quot;ERROR: target size not equal to 1 in &quot;+data_filename
+    dim = len(dataSet.getRow(0))-1
+    data = [ dataSet.getRow(i)[0:dim] for i in range(dataSet.length) ]
+    print &quot;SUGGESTED gamma: &quot;+str(proposed_gamma(data))
+    FID = open(output_filename, 'w')
+    for i in range(nsamples):
+        X = dataSet.getRow(i)
+        target = X[dataSet.inputsize]
+        FID.write(str(int(target))+&quot; &quot;)
+	for j in range(outputsize):
+            FID.write(str(j+1)+&quot;:&quot;+str(output[i][j])+&quot; &quot;)
+	FID.write(&quot;\n&quot;)
+    FID.close()
+
+
+
+def compute_entries_SVM( learner, dataSet):
+    temp_file='/tmp/new_learner.psave'
+#    learner.save(temp_file,'plearn_ascii')
+#    learner = loadObject(temp_file)   
+    learner = deepcopy(learner)
+    connect_last_layer2outputs( learner )
+    learner.save(temp_file,'plearn_ascii')
+    learner = loadObject(temp_file)
+    outputs=make_test_output(learner,dataSet)
+    nsamples = dataSet.length
+    outputsize = len(outputs[0])
+    if nsamples != len(outputs):
+       raise &quot;ERROR: conflict in dimensions&quot;
+    else:
+       print str(nsamples)+&quot; samples, new input size =&quot;+str(outputsize)
+    if dataSet.targetsize != 1:
+       raise &quot;ERROR: target size not equal to 1 in &quot;+data_filename
+    return outputs, [ dataSet.getRow(i)[dataSet.inputsize] for i in range(nsamples) ]
+
+def computeOutputsTargets(learner,dataSet):
+    ts=pl.VecStatsCollector()
+    (stats,outputs,costs)=learner.test(dataSet,ts,True,False)
+    targets=pl.SelectColumnsVMatrix(
+       source = dataSet.getObject(),
+       inputsize=0,
+       targetsize = dataSet.targetsize,
+       weightsize=0,
+       indices = range(dataSet.inputsize, dataSet.inputsize+dataSet.targetsize)
+    ).getMat()
+    return outputs, [int(target) for target in targets]
+
+    
+if __name__ == '__main__':
+
+    from plearn.learners.discr_power_SVM import *
+
+    learner_filename = &quot;/u/louradoj/PRGM/blocksworld/res/textual_v2/BESTdbn/final_learner.psave&quot;
+    if os.path.isfile(learner_filename) == False:
+       raise TypeError, &quot;ERROR : Learner file cannot be find\n\tCould not find file &quot;+learner_filename
+    learner = loadModuleLearner(learner_filename)
+        
+    #networkview( learner )
+
+    new_learner = removeModuleFromLearner( learner, &quot;rbm_21&quot; )
+    networkview( new_learner )
+
+    raise TypeError, &quot;OK&quot;
+
+    data_filename = &quot;/cluster/opter/data/babyAI/textual_v2/BABYAI_gray_10x2obj_32x32.color-size-location-shape.3gram.amat&quot;
+    if os.path.isfile(data_filename) == False:
+       raise TypeError, &quot;ERROR : Data file cannot be find\n\tCould not find file &quot;+data_filename
+    dataSet = pl.AutoVMatrix( filename = data_filename )
+    
+    new_learner = plug2output( learner, ['split.out1', 'rbm_3.hidden.state', 'rbm_12.hidden.state'])
+    getModulesNames(new_learner)  
+    outputs, targets = computeOutputsTargets( new_learner, dataSet)
+    #networkview( new_learner )
+    
+
+#    learner_filename = &quot;/u/louradoj/PRGM/blocksworld/res/textual_v2/BESTdbn/final_learner.psave&quot;
+#    learner = loadObject(learner_filename)
+#    data_filename = '/cluster/opter/data/babyAI/textual_v2/BABYAI_gray_10x2obj_32x32.color-size-location-shape.3gram.amat'
+#    dataSet = pl.AutoVMatrix( filename = data_filename )
+    
+#    outputs2, targets2 = compute_entries_SVM( learner, dataSet)
+#    outputs3, targets3 = compute_entries_SVM( learner, dataSet)    
+#    raise TypeError, &quot;douuuu&quot;
+
+    dataPath='/u/lisa/db/babyAI/textual_v2/BACKUP' #'/cluster/opter/data/babyAI/textual_v2/'
+    
+        
+    
+    dataTrain_filename = dataPath+'/BABYAI_gray_10000x2obj_32x32.color-size-location-shape.train.3gram.vmat'
+    dataValid_filename = dataPath+'/BABYAI_gray_5000x2obj_32x32.color-size-location-shape.valid.3gram.vmat'
+    dataTest_filename = dataPath+'/BABYAI_gray_5000x2obj_32x32.color-size-location-shape.test.3gram.vmat'
+    result_dir = os.path.dirname(learner_filename)
+
+    if 'ModuleLearner' not in str(type(learner)):
+        if learner.hasOption('learner') and 'ModuleLearner' in str(type(learner.learner)):
+	   learner=learner.learner
+        else:
+           raise TypeError,  'Sorry, but this code can only be used with ModuleLearner !!!'
+    learner_nickname = 'DBN-2-2-1_'+get_last_layer_module_name( learner ) #os.path.basename(learner_filename)
+    
+  
+    for typeDataSet in ['Train','Valid','Test']:
+        data_filename = globals()['data'+typeDataSet+'_filename']
+        if os.path.isfile(data_filename) == False:
+           raise TypeError, &quot;ERROR : Data file cannot be find\n\tCould not find file &quot;+data_filename
+        print &quot;CONVERSION &quot;+data_filename
+	dataSet = pl.AutoVMatrix( filename = data_filename )
+        globals()[typeDataSet+'_outputs'], globals()[typeDataSet+'_targets'] = compute_entries_SVM( learner, dataSet)
+
+    
+    E=discr_power_SVM_eval()
+    output_filename = result_dir+'/SVM_results_'+&quot;_&quot;+learner_nickname+os.path.basename(data_filename).replace(&quot;.vmat&quot;,&quot;&quot;).replace(&quot;.amat&quot;,&quot;&quot;)
+    
+    print &quot;Writing results in &quot;+output_filename
+    if os.path.isfile(output_filename):
+       print &quot;WARNING : output &quot;+output_filename+&quot; already exists&quot;
+       FID = open(output_filename, 'a')
+       abspath = os.path.realpath(learner_filename)
+       FID.write('LEARNER.: '+abspath+'\n')
+       for i in range(3):
+           abspath = os.path.dirname(abspath)
+       global_results = abspath+'/global_stats.pmat'
+       if os.path.isfile(global_results):
+          os.system(&quot;echo   baseline test error rate : `plearn vmat cat &quot;+global_results+&quot; | tail -1 | awk '{print $NF}'` \%   &gt;&gt; &quot;+output_filename )
+       else:
+          print &quot;WARNING : could not find global_stats.pmat\n\t( &quot;+abspath+&quot;/global_stats.pmat )&quot;
+       FID.write('Train...: '+os.path.realpath(dataTrain_filename)+'\n')
+       FID.write('Valid...: '+os.path.realpath(dataValid_filename)+'\n')
+       FID.write('Test....: '+os.path.realpath(dataTest_filename)+'\n')
+    else:
+       FID = open(output_filename, 'w')
+    FID.write('--------\n')
+
+    E.save_filename = output_filename
+    E.valid_and_compute_accuracy( 'RBF' ,     [[Train_outputs,Train_targets], [Valid_outputs,Valid_targets], [Test_outputs,Test_targets]])
+    FID = open(output_filename, 'a')
+    FID.write(&quot;Tried parameters : &quot;+str(E.tried_parameters)+'\n')
+    FID.write('BEST ACCURACY: '+str(E.valid_accuracy)+' (valid) - '+str(E.accuracy)+' (test) for '+str(E.best_parameters)+'\n')
+    FID.close()
+    E.valid_and_compute_accuracy( 'RBF' ,     [[Train_outputs,Train_targets], [Valid_outputs,Valid_targets], [Test_outputs,Test_targets]])
+    FID = open(output_filename, 'a')
+    FID.write(&quot;Tried parameters : &quot;+str(E.tried_parameters)+'\n')
+    FID.write('BEST ACCURACY: '+str(E.valid_accuracy)+' (valid) - '+str(E.accuracy)+' (test) for '+str(E.best_parameters)+'\n')
+    FID.close()
+    E.valid_and_compute_accuracy( 'RBF' ,     [[Train_outputs,Train_targets], [Valid_outputs,Valid_targets], [Test_outputs,Test_targets]])
+    FID = open(output_filename, 'a')
+    FID.write(&quot;Tried parameters : &quot;+str(E.tried_parameters)+'\n')
+    FID.write('BEST ACCURACY: '+str(E.valid_accuracy)+' (valid) - '+str(E.accuracy)+' (test) for '+str(E.best_parameters)+'\n')
+    FID.close()
+    print &quot;Results written in &quot;+output_filename

Added: trunk/python_modules/plearn/learners/modulelearners/__init__.pyc
===================================================================
(Binary files differ)


Property changes on: trunk/python_modules/plearn/learners/modulelearners/__init__.pyc
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/python_modules/plearn/learners/modulelearners/examples/plugNetwork2SVM.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/examples/plugNetwork2SVM.py	2007-06-13 03:07:30 UTC (rev 7577)
+++ trunk/python_modules/plearn/learners/modulelearners/examples/plugNetwork2SVM.py	2007-06-13 21:15:55 UTC (rev 7578)
@@ -0,0 +1,99 @@
+import sys
+from plearn.learners.modulelearners  import *
+from plearn.learners.discr_power_SVM import *
+
+if __name__ == '__main__':
+
+
+    ports_list = sys.argv[1:]
+    # ex: 'split.out1', 'split.out2',  'rbm_3.hidden.state', 'rbm_12.hidden.state'
+
+
+    learner_filename = &quot;/u/louradoj/PRGM/blocksworld/res/textual_v2/BESTdbn/final_learner.psave&quot;
+    if os.path.isfile(learner_filename) == False:
+       raise TypeError, &quot;ERROR : Learner file cannot be find\n\tCould not find file &quot;+learner_filename
+    learner = loadModuleLearner(learner_filename)
+    learner_nickname = 'DBN-2-2-1_'+&quot;_&quot;.join(ports_list).replace(&quot;.&quot;,&quot;&quot;)
+
+    dataPath='/cluster/opter/data/babyAI/textual_v2/'    
+    dataTrain_filename = dataPath+'/BABYAI_gray_10000x2obj_32x32.color-size-location-shape.train.3gram.vmat'
+    dataValid_filename = dataPath+'/BABYAI_gray_5000x2obj_32x32.color-size-location-shape.valid.3gram.vmat'
+    dataTest_filename = dataPath+'/BABYAI_gray_5000x2obj_32x32.color-size-location-shape.test.3gram.vmat'
+
+
+#
+#    A small dataset for debug...
+#
+#    data_filename = &quot;/cluster/opter/data/babyAI/textual_v2/BABYAI_gray_10x2obj_32x32.color-size-location-shape.3gram.amat&quot;
+#    dataTrain_filename = data_filename
+#    dataTest_filename = data_filename
+#    dataValid_filename = data_filename
+
+    result_dir = os.path.dirname(learner_filename)
+    output_filename = result_dir+'/SVM_results_'+&quot;_&quot;+learner_nickname+&quot;-&quot;+os.path.basename(dataTrain_filename).replace(&quot;.vmat&quot;,&quot;&quot;).replace(&quot;.amat&quot;,&quot;&quot;)
+
+
+#               #
+#   MAIN PART   #
+#               #
+
+
+    new_learner = plug2output( learner, ports_list)
+
+    
+  
+    for typeDataSet in ['Train','Valid','Test']:
+        data_filename = globals()['data'+typeDataSet+'_filename']
+        if os.path.isfile(data_filename) == False:
+           print &quot;ERROR : Data file cannot be find\n\tCould not find file &quot;+data_filename
+           sys.exit(0)
+        print &quot;CONVERSION &quot;+data_filename
+	dataSet = pl.AutoVMatrix( filename = data_filename )
+        globals()[typeDataSet+'_outputs'], globals()[typeDataSet+'_targets'] = computeOutputsTargets( new_learner, dataSet)
+	#
+	# Normalizing the data (/!\ compute statistics on the training data and assumes it comes first)
+	#
+        if typeDataSet == 'Train':
+           mean, std = normalize(globals()[typeDataSet+'_outputs'],None,None)
+	else:
+	   normalize(globals()[typeDataSet+'_outputs'],mean,std)
+
+    E=discr_power_SVM_eval()
+    
+    print &quot;Writing results in &quot;+output_filename
+    if os.path.isfile(output_filename):
+       print &quot;WARNING : output &quot;+output_filename+&quot; already exists&quot;
+       FID = open(output_filename, 'a')
+       abspath = os.path.realpath(learner_filename)
+       FID.write('LEARNER.: '+abspath+'\n')
+       for i in range(3):
+           abspath = os.path.dirname(abspath)
+       global_results = abspath+'/global_stats.pmat'
+       if os.path.isfile(global_results):
+          os.system(&quot;echo   baseline test error rate : `plearn vmat cat &quot;+global_results+&quot; | tail -1 | awk '{print $NF}'` \%   &gt;&gt; &quot;+output_filename )
+       else:
+          print &quot;WARNING : could not find global_stats.pmat\n\t( &quot;+abspath+&quot;/global_stats.pmat )&quot;
+       FID.write('Train...: '+os.path.realpath(dataTrain_filename)+'\n')
+       FID.write('Valid...: '+os.path.realpath(dataValid_filename)+'\n')
+       FID.write('Test....: '+os.path.realpath(dataTest_filename)+'\n')
+    else:
+       FID = open(output_filename, 'w')
+    FID.write('--------\n')
+
+    E.save_filename = output_filename
+    E.valid_and_compute_accuracy( 'LINEAR' ,     [[Train_outputs,Train_targets], [Valid_outputs,Valid_targets], [Test_outputs,Test_targets]])
+    FID = open(output_filename, 'a')
+    FID.write(&quot;Tried parameters : &quot;+str(E.tried_parameters)+'\n')
+    FID.write('BEST ACCURACY: '+str(E.valid_accuracy)+' (valid) - '+str(E.accuracy)+' (test) for '+str(E.best_parameters)+'\n')
+    FID.close()
+    E.valid_and_compute_accuracy( 'RBF' ,     [[Train_outputs,Train_targets], [Valid_outputs,Valid_targets], [Test_outputs,Test_targets]])
+    FID = open(output_filename, 'a')
+    FID.write(&quot;Tried parameters : &quot;+str(E.tried_parameters)+'\n')
+    FID.write('BEST ACCURACY: '+str(E.valid_accuracy)+' (valid) - '+str(E.accuracy)+' (test) for '+str(E.best_parameters)+'\n')
+    FID.close()
+    E.valid_and_compute_accuracy( 'RBF' ,     [[Train_outputs,Train_targets], [Valid_outputs,Valid_targets], [Test_outputs,Test_targets]])
+    FID = open(output_filename, 'a')
+    FID.write(&quot;Tried parameters : &quot;+str(E.tried_parameters)+'\n')
+    FID.write('BEST ACCURACY: '+str(E.valid_accuracy)+' (valid) - '+str(E.accuracy)+' (test) for '+str(E.best_parameters)+'\n')
+    FID.close()
+    print &quot;Results written in &quot;+output_filename

Added: trunk/python_modules/plearn/learners/modulelearners/network_view.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/network_view.py	2007-06-13 03:07:30 UTC (rev 7577)
+++ trunk/python_modules/plearn/learners/modulelearners/network_view.py	2007-06-13 21:15:55 UTC (rev 7578)
@@ -0,0 +1,287 @@
+#!/usr/bin/env python
+
+import os, os.path
+import sys
+
+from plearn.pymake.pymake import *
+
+try:
+  from plearn.pyext import *
+except:
+  PLEARNDIR = os.environ.get('PLEARNDIR', os.getcwd())
+  PLEARNDIRpyext = os.path.join(PLEARNDIR,'python_modules','plearn','pyext')
+  PLEARNDIRpyextOBJ =  os.path.join(PLEARNDIRpyext,'OBJS')
+  DIRS=os.listdir(PLEARNDIRpyextOBJ)
+  l=len(DIRS)
+  for dirname in DIRS:
+      l -= 1
+      if l&gt;0 and 'double' in dirname:
+         DIRS.append(dirname)
+         continue
+      elif l&gt;0 and 'dbg' in dirname:
+         DIRS.append(dirname)
+         continue
+      dirname = os.path.join(PLEARNDIRpyextOBJ, dirname)      
+      if 'libplext.so' in os.listdir(dirname):
+         linux_command = 'ln -sf '+ os.path.join(dirname,'libplext.so') + ' ' + os.path.join(PLEARNDIRpyext, 'libplext.so') 
+         os.system(linux_command)
+      try :
+           from plearn.pyext import *
+	   break
+      except: pass
+  
+  
+
+
+
+printAllPorts=False
+
+
+from pyplearn_read import *
+
+import pydot
+
+# global variables:
+modules_dict = {}
+
+    
+
+def countModules(mynetwork):
+    n=0
+    for module in mynetwork.modules:
+        if is_SplitModule(module) == False:
+	   n += 1
+    return n
+
+def Network2dict(mynetwork):
+    mydict={}
+    for module in mynetwork.modules:
+        mydict[module.name]=module
+    return mydict
+
+def Modules2dict(modules):
+    mydict={}
+    for module in modules:
+        mydict[module.name]=module
+    return mydict
+
+def getPortDict(ports):
+    mydict={}
+    if type(ports[0]) == tuple:
+        for i in range(0,len(ports)):
+	    mydict[ports[i][1].split('.')[0]] = ports[i][0]
+    else:
+        for i in range(0,len(ports),2):
+            mydict[ports[i+1].split('.')[0]] = ports[i]
+    return mydict
+
+def getPortLists(ports):
+    mylist=[]
+    if type(ports[0]) == tuple:
+        for i in range(0,len(ports)):
+	    mylist.append( [ ports[i][1].split('.')[0] , ports[i][0] ] )
+    else:
+       for i in range(0,len(ports),2):
+           mylist.append( [ ports[i+1].split('.')[0] , ports[i] ] )
+    return mylist
+    
+def formatModulesNames(name,modules_dict):
+    if modules_dict.has_key(name):
+       return name.upper()
+       #return str(type(modules_dict[name])).split(&quot;&lt;class '&quot;)[1].split(&quot;Module&quot;)[0].upper()
+    print &quot;ERROR: while executing formatModulesNames(name):\n\tCannot find &quot;+name+&quot; in modules_dict&quot;
+    return name
+
+def formatPortNames(name,portname,modules_dict,printAllPorts):
+    if portname in ['input','target','cost','weight']:
+       return '*'+portname.lower()+'*'
+    elif portname in ['output']:
+       return formatModulesNames(name,modules_dict)
+    else:
+       if printAllPorts:
+          return '-*'+portname.lower()+'*'
+       else:
+          return formatModulesNames(name,modules_dict)
+       
+
+def checkName(ModuleName, ports_dict, modules_dict):
+    if ports_dict.has_key(ModuleName):
+       return formatPortNames(ModuleName,ports_dict[ModuleName],modules_dict,False)
+    return formatModulesNames(ModuleName,modules_dict)
+
+
+def is_SplitModule(module):
+    return 'SplitModule' in str(type(module))
+       
+def module_type(module):
+    return str(type(module)).upper()
+
+def getInputOutputSize(mymodule):
+    inputSize = ['?']
+    outputSize = ['?']
+    if 'connection' in mymodule.__dict__:
+       inputSize = [mymodule.connection.down_size]
+       outputSize = [mymodule.connection.up_size]
+    elif 'input_size' in mymodule.__dict__:
+       inputSize = [mymodule.input_size]
+       outputSize = [mymodule.output_size]
+    elif 'up_port_sizes' in mymodule.__dict__:
+       inputSize = [mymodule.up_port_sizes]
+    elif 'weights' in mymodule.__dict__:
+       inputSize = [len(mymodule.weights)]
+    return inputSize, outputSize 
+
+        
+def getInputOutput(connection):
+    nameport = connection.source.split('.')[1]
+    inputModuleName = connection.source.split('.')[0]
+    outputModuleName = connection.destination.split('.')[0]
+    if nameport in ['hidden','hidden.state','output','target']:
+       #nameport = connection.destination.split('.')[1]
+       #if nameport in ['visible','input','target']:
+          nameport = ' '
+    #tp, outSize = getInputOutputSize(modules_dict[inputModuleName])
+    #inSize, tp  = getInputOutputSize(modules_dict[outputModuleName])
+    #nameport = str(outSize) + nameport + str(inSize)
+    return inputModuleName, outputModuleName, nameport
+
+def get_graph(modules, connections, ports):
+    edges=[]
+    edges_toAdd={}
+    globals()['modules_dict'] = Modules2dict(modules)
+    ports_dict = getPortDict(ports)
+    for connection in connections:
+        inputModuleName , outputModuleName, inputModulePort = getInputOutput(connection)
+	inputModuleNameToplot = checkName(inputModuleName,ports_dict,modules_dict)
+	outputModuleNameToplot = checkName(outputModuleName,ports_dict,modules_dict)
+	
+	if is_SplitModule(modules_dict[inputModuleName]):
+	   if edges_toAdd.has_key(inputModuleName):
+	      edges_toAdd[inputModuleName][1].append(outputModuleNameToplot)
+	   else:
+	      edges_toAdd[inputModuleName]=[[],[]]
+	      edges_toAdd[inputModuleName][1]=[outputModuleNameToplot]
+	elif is_SplitModule(modules_dict[outputModuleName]):
+	   if edges_toAdd.has_key(outputModuleName):
+	      edges_toAdd[outputModuleName][0].append(inputModuleNameToplot)
+	   else:
+	      edges_toAdd[outputModuleName]=[[],[]]
+	      edges_toAdd[outputModuleName][0]=[inputModuleNameToplot]
+	else:
+	   edges.append( [inputModuleNameToplot, outputModuleNameToplot, inputModulePort] )
+	   
+    for split_module in edges_toAdd:
+        # split from/to a port (input, output)
+	if len(edges_toAdd[split_module][0]) == 0: 
+	   edges_toAdd[split_module][0]=[checkName(split_module,ports_dict,modules_dict)]
+	elif len(edges_toAdd[split_module][1]) == 0:
+	   edges_toAdd[split_module][1]=[checkName(split_module,ports_dict,modules_dict)]
+	for i in edges_toAdd[split_module][0]:
+	    for j in edges_toAdd[split_module][1]:
+                edges.append( [ i, j, ' ' ])
+
+    port_list = getPortLists(ports)
+
+    graphSIZE = len(modules_dict)
+    graph=pydot.Dot(size=str(graphSIZE)+','+str(graphSIZE))
+    for edge in edges:
+        myedge=pydot.Edge(edge[0],edge[1])
+	myedge.set_label(edge[2])
+        graph.add_edge(myedge)
+
+
+    for port in port_list:
+        inputPort = checkName(port[0],ports_dict,modules_dict)
+#        outputPort = formatPortNames(port[0],port[1],modules_dict)
+	outputPort = formatPortNames(port[0],port[1],modules_dict,printAllPorts)
+	if outputPort != inputPort:
+	   #graph.add_node(pydot.Node(inputPort+'-&gt;'+outputPort))
+	   #for edge in edges:
+	   #    for i in range(len(edge)):
+	   #        if inputPort in edge[i]:
+	   #           edge[i] += ' '+outputPort	          
+	   myedge=pydot.Edge(outputPort,inputPort)
+   	   myedge.set_arrowsize(1)
+#  	   myedge.set_label('label')
+           graph.add_edge(myedge)
+
+	
+    return graph
+    
+
+def save_graph( outputname, modules, connections, ports ):
+    graph = get_graph( modules, connections, ports )
+    graph.write_jpeg(outputname, prog='neato') #'dot', 'twopi' and 'neato'
+    #import Image
+    #im=Image.open(outputname,&quot;r&quot;)
+    #im.show()
+    print &quot;to see the network: kuickview &quot;+outputname
+
+def show_graph( modules, connections, ports ):
+    outputname='temp.jpeg'
+    graph = get_graph( modules, connections, ports )
+    graph.write_jpeg(outputname, prog='dot')
+    im=Image.open(outputname,&quot;r&quot;)
+    im.show()
+
+def networkview( myObject ):
+    if 'NetworkModule' in str(type(myObject)):
+       graph = get_graph( myObject.modules, myObject.connections, myObject.ports )
+    elif 'ModuleLearner' in str(type(myObject)):
+       graph = get_graph( myObject.module.modules, myObject.module.connections, myObject.module.ports )
+    else:
+        raise TypeError, &quot;Please give a ModuleLearner or NetworkModule&quot;
+    outputname = '/tmp/networkview.jpeg'
+    graph.write_jpeg(outputname, prog='dot')
+    os.system('kuickshow '+outputname+' &amp;')
+
+if __name__ == '__main__':
+
+    inputname  = sys.argv[1]
+    outputname = inputname+'.network.jpeg'
+    extension = os.path.splitext(inputname)[1]
+    if extension == '.pyplearn' or extension == '.py':
+       types_to_discard = ['HyperLearner', 'PTester', 'MemoryVMatrix', 'AutoVMatrix']
+       if extension == '.py':
+          commands_to_discard = ['.run()', '.test()', '.train()', '.save(',
+	                         'choose_initial_lr', 'train_adapting_lr', 'train_with_schedule']
+          types_to_discard.append('ModuleLearner')
+       else:
+          commands_to_discard = []
+       tmp_file = '/tmp/tp.py'
+       object_dict = write_objects_from_pyplearn( inputname, types_to_discard ,commands_to_discard, tmp_file)
+#      for debug...
+#       os.system('nedit '+tmp_file+' &amp;')
+       execfile(tmp_file)
+       nets=[]
+       names=[]
+       print object_dict
+       for variable_name in object_dict['NetworkModule']:
+           names += variable_name
+	   nets += eval(variable_name)
+    elif extension == '.psave':
+       myObject = loadObject(inputname)
+       if 'ModuleLearner' in str(type(myObject)):
+          net = myObject.module
+       else:
+          raise TypeError, &quot;Could not recognize the type &quot;+str(type(myObject))
+       nets = [net]
+    else:
+       raise TypeError, &quot;could not recognize the extension (&quot;+extension+&quot;) of &quot;+inputname
+    
+    for i in range(len(nets)):
+        net = nets[i]
+        if len(nets)==1:
+	   outputname_i = outputname
+	else:
+	   print &quot;making the graph of &quot; + names[i]
+	   outputname_i = outputname+'_'+str(i)
+        graph = get_graph( net.modules, net.connections, net.ports )
+        graph.write_jpeg(outputname_i, prog='dot')
+        if os.path.isfile(outputname_i) == False:
+           print &quot;ERROR: could not write &quot;+outputname_i
+           sys.exit(0)
+        print &quot;to see the network: kuickshow &quot;+outputname_i
+        os.system('kuickshow '+outputname_i+' &amp;')
+    
+#    show_graph_network( modules, connections, ports )


Property changes on: trunk/python_modules/plearn/learners/modulelearners/network_view.py
___________________________________________________________________
Name: svn:executable
   + *

Added: trunk/python_modules/plearn/learners/modulelearners/network_view.pyc
===================================================================
(Binary files differ)


Property changes on: trunk/python_modules/plearn/learners/modulelearners/network_view.pyc
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream

Added: trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.py
===================================================================
--- trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.py	2007-06-13 03:07:30 UTC (rev 7577)
+++ trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.py	2007-06-13 21:15:55 UTC (rev 7578)
@@ -0,0 +1,231 @@
+#!/usr/bin/env python
+
+import sys, os, os.path
+
+FID=0
+
+class pyplearnFile:
+
+#      Nbrack
+#      Nparen
+#      FID
+#      cline
+#      cline_previous
+#      ctype
+#      cname
+#      islocal
+
+      def __init__(self,fname):
+            self.FID = open(fname, 'r')
+	    self.cline = ''  # current line
+            self.Nbrack  = [] # number of opened brackets [
+            self.Nparen  = [] # number of opened parenthesis (
+	    self.islocal = 0 # being in a subfunction?
+	    self.ctypes = [] # type that i being defined (hierarchical)
+	    self.cnames = [] # ...and corresponding names
+	    self.isaffect = False # is the previous line affecting something?
+      def close(self):
+          self.FID.close()
+
+      def read(self):
+          self.cline_previous = self.cline
+          self.cline = self.FID.readline()
+	  if len(self.cline) == 0:
+	     return False
+	  
+	  comment = self.cline.find(&quot;#&quot;)
+	  if comment &gt; -1:
+   	     # The '#' may be in a string...
+  	     prev = 0
+ 	     while is_odd(number_occurence(self.cline[prev:comment],&quot;'&quot;)) or is_odd(number_occurence(self.cline[prev:comment],'&quot;')):
+	        prev = comment
+		tp = self.cline[comment+1:].find(&quot;#&quot;)
+		if tp &gt; -1:
+		   comment += tp+1 
+		else:
+		   comment = len(self.cline)
+	     self.cline = self.cline[0:comment]+'\n'
+	     
+	  return True
+
+      def actualize_previous(self):
+          if is_def(self.cline):
+	     self.islocal = indent_level(self.cline)
+	  elif self.islocal &gt; 0:
+	     if indent_level(self.cline) &lt;= self.islocal:
+	        self.islocal = 0
+	  if self.islocal == 0:
+  	     closed_paren = number_occurence(self.cline_previous,&quot;)&quot;) - number_occurence(self.cline_previous,&quot;(&quot;) + number_occurence(self.cline_previous,&quot;]&quot;) - number_occurence(self.cline_previous,&quot;[&quot;)
+	     if closed_paren == 0 and self.isaffect:
+	        self.isaffect = False
+		closed_paren = 1
+	     self.cnames = self.cnames[0:len(self.cnames)-closed_paren]
+	     self.ctypes = self.ctypes[0:len(self.ctypes)-closed_paren]
+
+	     being_affect = self.name_affect()
+	     if len(being_affect[0]) &gt; 0:
+	        self.cnames.append(being_affect[0])
+		self.ctypes.append(being_affect[1])
+	  
+          self.Nbrack += number_occurence(self.cline,&quot;[&quot;) -  number_occurence(self.cline,&quot;]&quot;)
+          self.Nparen += number_occurence(self.cline,&quot;(&quot;) -  number_occurence(self.cline,&quot;)&quot;)
+
+      def actualize(self):
+          if is_def(self.cline):
+	     self.islocal = indent_level(self.cline)
+	  elif self.islocal &gt; 0:
+	     if indent_level(self.cline) &lt;= self.islocal:
+	        self.islocal = 0
+	  if self.islocal == 0:
+	     assend = 0
+	     level = len(self.Nbrack)-1
+	     N = 0
+	     while N == 0 and level &gt;= 0:
+  	        if len(self.Nbrack) &gt; 0:
+	           N = self.Nbrack[level]
+                else:
+	           N = 0
+	        if len(self.Nparen) &gt; 0:
+	           N += self.Nparen[level]
+                if N &gt; 0:
+		   break
+	        assend += 1
+		level  -= 1
+		N -= N
+	     
+             self.cnames = self.cnames[0:len(self.cnames)-assend]
+             self.ctypes = self.ctypes[0:len(self.ctypes)-assend]
+             self.Nbrack = self.Nbrack[0:len(self.Nbrack)-assend]
+             self.Nparen = self.Nparen[0:len(self.Nparen)-assend]
+
+	     being_affect = self.name_affect()
+	     if len(being_affect[0]) &gt; 0:
+	        self.cnames.append(being_affect[0])
+		self.ctypes.append(being_affect[1])
+		self.Nbrack.append(number_occurence(self.cline,&quot;[&quot;) -  number_occurence(self.cline,&quot;]&quot;))
+		self.Nparen.append(number_occurence(self.cline,&quot;(&quot;) -  number_occurence(self.cline,&quot;)&quot;))
+             elif len(self.Nbrack) &gt; 0:
+	        self.Nbrack[len(self.Nbrack)-1] += number_occurence(self.cline,&quot;[&quot;) -  number_occurence(self.cline,&quot;]&quot;)
+	        self.Nparen[len(self.Nparen)-1] += number_occurence(self.cline,&quot;(&quot;) -  number_occurence(self.cline,&quot;)&quot;)
+
+
+       # is there an affectation in the line?
+      def name_affect(self):
+          tp = self.cline.split('=')
+          if len(tp) &gt; 1:
+             if '' not in tp: # discard the case of '=='
+	        tp[1] = '='.join(tp[1:])
+                first_term = tp[0].strip()
+                second_term = tp[1].split('(')[0].strip()
+		if len(second_term) == 0:
+		   while len(second_term) &lt; 1:
+		         line = self.cline
+		         self.read()
+			 self.cline = line + self.cline
+		         temp, second_term = self.name_affect()
+		   return first_term, second_term
+		self.isaffect = True
+                if len(second_term) &gt; 3 and second_term[0:3] == 'pl.':
+                   return first_term, second_term[3:]
+		elif '[' in second_term:
+		   return first_term, 'list'
+		else:
+		   self.isaffect = False
+		   return '', type(second_term)
+          self.isaffect = False
+	  return '',''
+
+# is it a definition line?
+def is_def(line):
+    tp = line.split('def')
+    if len(tp) &gt; 1:
+       if len(tp[1]) &gt; 0:
+          if len(tp[0]) == 0 and tp[1][0] == ' ':
+             return True
+    return False
+
+
+
+# the level of indentation of the line    
+def indent_level(line):
+    return line.replace(&quot;\t&quot;,&quot;        &quot;).find(line.lstrip()) + 1
+
+def number_occurence(line,string):
+    n = 0
+    while line.find(string) &gt; -1  and len(string) &gt; 0:
+          n += 1
+          line = line[line.find(string)+1:]
+    return n
+    
+def is_odd(number): # nombre impair?
+    return int(number/2.0) != number/2.0
+    
+    
+    
+    
+	  
+# fname           : name of the *.pyplearn or *.py file to read
+# types_to_discard : list of module names we don't want to construct
+#                     (ex: ['ModuleLearner', 'NetworkModule', 'MemoryVMatrix', 'AutoVMatrix'])
+#                   but we will get their components
+def write_objects_from_pyplearn( fname, types_to_discard, commands_to_discard, fname_out):
+    if os.path.isfile(fname) == False:
+       print &quot;ERROR: cannot find file &quot;+fname
+       sys.exit(0)
+       
+    module_dict={}
+    
+    FILE = pyplearnFile(fname)
+    
+    globals()['FID'] = open(fname_out,'w')
+    FID=globals()['FID']
+    
+    cnames=[]
+    
+    while FILE.read():
+       FILE.actualize()
+	  
+       if len(FILE.ctypes) == 0 or FILE.ctypes[0] not in types_to_discard:
+          
+	  print FILE.cline
+	  do_not_consider = False
+	  for command in commands_to_discard:
+	      print command
+	      if command in FILE.cline:
+	         do_not_consider = True
+              print do_not_consider
+	  if do_not_consider:
+	     continue
+	  
+	  if cnames != FILE.cnames:
+	     if len(cnames) &lt; len(FILE.cnames):
+	        cname = '.'.join(FILE.cnames)
+		ctype = FILE.ctypes[len(FILE.ctypes)-1]
+                if module_dict.has_key(ctype):
+		   if cname not in module_dict[ctype]:
+		      module_dict[ctype].append( cname )
+		else:
+		   module_dict[ctype] = [ cname ]
+	        FID.write(&quot;#&quot;+&quot;/&quot;*10*len(FILE.cnames)+&quot;\n&quot;)
+                FID.write(&quot;# &quot;+' / '.join(FILE.cnames)+&quot;\n# &quot;+' / '.join(FILE.ctypes)+&quot;\n&quot;)
+	     else: 
+                FID.write(&quot;# &quot;+' / '.join(FILE.cnames)+&quot;\n&quot;)
+		if len(cnames) != len(FILE.cnames):
+		   FID.write(&quot;# &quot;+' / '.join(FILE.ctypes)+&quot;\n&quot;)
+	           FID.write(&quot;#&quot;+&quot;\\&quot;*10*len(FILE.cnames)+&quot;\n&quot;)
+	     cnames = FILE.cnames
+	  FID.write(FILE.cline)
+   
+    FILE.close()
+    FID.close()
+    
+    return module_dict
+    
+if __name__ == '__main__':
+
+    object_dict = write_objects_from_pyplearn( sys.argv[1], ['HyperLearner', 'PTester', 'MemoryVMatrix'] , [] , '/tmp/pyplearn_read.py')
+    print str(object_dict)
+    execfile('/tmp/pyplearn_read.py')
+    for i in object_dict['NetworkModule']:
+        m = eval(i)
+        print m


Property changes on: trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.py
___________________________________________________________________
Name: svn:executable
   + *

Added: trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.pyc
===================================================================
(Binary files differ)


Property changes on: trunk/python_modules/plearn/learners/modulelearners/pyplearn_read.pyc
___________________________________________________________________
Name: svn:mime-type
   + application/octet-stream


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001026.html">[Plearn-commits] r7577 - trunk/plearn/misc
</A></li>
	<LI>Next message: <A HREF="001028.html">[Plearn-commits] r7579 -	trunk/python_modules/plearn/learners/modulelearners
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1027">[ date ]</a>
              <a href="thread.html#1027">[ thread ]</a>
              <a href="subject.html#1027">[ subject ]</a>
              <a href="author.html#1027">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
