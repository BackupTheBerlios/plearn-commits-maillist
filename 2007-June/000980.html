<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r7531 - trunk/python_modules/plearn/learners/autolr
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2007-June/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7531%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200706042238.l54McrcC032137%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000979.html">
   <LINK REL="Next"  HREF="000981.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r7531 - trunk/python_modules/plearn/learners/autolr</H1>
    <B>breuleux at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r7531%20-%20trunk/python_modules/plearn/learners/autolr&In-Reply-To=%3C200706042238.l54McrcC032137%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r7531 - trunk/python_modules/plearn/learners/autolr">breuleux at mail.berlios.de
       </A><BR>
    <I>Tue Jun  5 00:38:53 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000979.html">[Plearn-commits] r7530 - trunk/python_modules/plearn/learners/autolr
</A></li>
        <LI>Next message: <A HREF="000981.html">[Plearn-commits] r7532 - in trunk/plearn_learners/online: .	test/ModuleLearner
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#980">[ date ]</a>
              <a href="thread.html#980">[ thread ]</a>
              <a href="subject.html#980">[ subject ]</a>
              <a href="author.html#980">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: breuleux
Date: 2007-06-05 00:38:47 +0200 (Tue, 05 Jun 2007)
New Revision: 7531

Modified:
   trunk/python_modules/plearn/learners/autolr/__init__.py
Log:
Added parallelism for multiple cores.

Modified: trunk/python_modules/plearn/learners/autolr/__init__.py
===================================================================
--- trunk/python_modules/plearn/learners/autolr/__init__.py	2007-06-04 22:10:13 UTC (rev 7530)
+++ trunk/python_modules/plearn/learners/autolr/__init__.py	2007-06-04 22:38:47 UTC (rev 7531)
@@ -1,15 +1,79 @@
 from math import *
 from numarray import *
 from plearn.bridge import *
+from threading import *
 
 # YET TO BE DOCUMENTED AND CLEANED UP CODE
 
 
+servers_lock = Lock() # Lock on the servers list so we don't have race conditions
+servers = [[serv, 0]] # List of [server, amount_of_jobs_server_is_running] lists
+servers_max = 1e10 # Maximal amount of servers we are willing to run
+
+
+def execute(object, tasks, use_threads = False):
+    def job(object):
+        for method, args in tasks: # do each task sequentially
+            getattr(object, method)(*args)
+        
+    if plearn.bridgemode.useserver and use_threads:
+        t = Thread(target = job, args = (object,))
+        t.start()
+        return t
+    else:
+        for method, args in tasks:
+            getattr(object, method)(*args)
+        return True
+
+def acquire_server(use_threads = False):
+    if not use_threads:
+        return serv
+    servers_lock.acquire()
+    min_load = 1e10
+    least_loaded = 0
+    nservers = len(servers)
+    for servinfo, i in zip(servers, xrange(nservers)):
+        server, njobs = servinfo
+        if not njobs:
+            servinfo[1] = 1
+            servers_lock.release()
+            return server
+        if njobs &lt; min_load:
+            min_load = njobs
+            least_loaded = i
+    if nservers &lt; servers_max:
+        command = 'plearn_curses server'
+        server = launch_plearn_server(command)
+        servers.append([server, 1])
+    else:
+        servinfo = servers[least_loaded]
+        server = servinfo[0]
+        servinfo[1] += 1
+    servers_lock.release()
+    return server
+
+def release_server(object, use_threads = False):
+    if plearn.bridgemode.useserver and use_threads:
+        server = object.server
+        servers_lock.acquire()
+        for servinfo in servers:
+            server_, njobs = servinfo
+            if server_ is server: # == doesn't work
+                servinfo[1] -= 1 # this server is done so we reduce its job count
+                break
+        servers_lock.release()
+
+def assign(object, use_threads = False):
+    server = acquire_server(use_threads)
+    o = server.new(object)
+    return o
+
+
 # ugly way to copy until done properly with PLearn's deepcopy
-def deepcopy(plearnobject):
+def deepcopy(plearnobject, use_threads = False):
     # actually not a deep-copy, only copy options
     if plearn.bridgemode.useserver:
-        o = serv.new(plearnobject.getObject())
+        o = assign(plearnobject.getObject(), use_threads)
     else:
         o = newObject(str(plearnobject))
     if o==None:
@@ -229,8 +293,12 @@
                       lr_steps=exp(log(10)/2), # Scaling coefficient when modifying learning rates
                       logfile=False,
                       min_lr=1e-6, # do not try to go below this learning rate
-                      keep_lr=2): # Learning rate interval for heuristic
+                      keep_lr=2, # Learning rate interval for heuristic
+                      use_threads=False):
 
+    if plearn.bridgemode.useserver:
+        servers[0][1] = 1 # learner
+
     min_epochs_to_delete = max(1,min_epochs_to_delete) # although 1 is probably too small
 
     def error_curve(active,start_t,current_t):
@@ -313,6 +381,9 @@
             print &gt;&gt;logfile, &quot;At stage &quot;, stage
         print &quot;actives now: &quot;,actives, &quot; with lr=&quot;, array(all_lr)[actives]
         print &gt;&gt;logfile, &quot;actives now: &quot;,actives, &quot; with lr=&quot;, array(all_lr)[actives]
+
+        threads = []
+        active_stats = []
         for active in actives:
             candidate = all_candidates[active]
             results = all_results[active]
@@ -326,16 +397,30 @@
                         options[lr_option]=str(learning_rates[t,s])
             candidate.changeOptions(options)
             candidate.setTrainingSet(trainset,False)
-            candidate.train()
+            tasks = [('train', ())]
+            stats = []
+            for j in range(0,n_tests):
+                ts = pl.VecStatsCollector()
+                if plearn.bridgemode.useserver:
+                    ts = candidate.server.new(ts)
+                stats.append(ts)
+                tasks.append(('test', (testsets[j], ts, 0, 0)))
+            active_stats.append(stats)
+            threads.append(execute(candidate, tasks, use_threads))
+
+        for thread in threads:
+            if isinstance(thread, Thread):
+                thread.join() # wait for all experiments to finish
+
+        for active, stats in zip(actives, active_stats):
+            candidate = all_candidates[active]
+            results = all_results[active]
+        
             results[t,0] = candidate.stage
             results[t,1] = all_lr[active]
             if logfile:
                 print &gt;&gt;logfile, &quot;candidate &quot;,active,&quot;:&quot;,
-            for j in range(0,n_tests):
-                ts = pl.VecStatsCollector()
-                if plearn.bridgemode.useserver:
-                    ts=serv.new(ts)
-                candidate.test(testsets[j],ts,0,0)
+            for j, ts in zip(range(0,n_tests), stats):
                 if logfile:
                     print &gt;&gt;logfile, &quot; test&quot; + str(j+1),&quot;: &quot;,
                 for k in range(0,n_costs):
@@ -395,6 +480,7 @@
                 if a!=best_active and error_curve_dominates(best_active,a,t):
                     if logfile:
                         print &gt;&gt;logfile,&quot;REMOVE candidate &quot;,a
+                    release_server(all_candidates[a], use_threads)
                     all_candidates[a]=None # hopefully this destroys the candidate
                     del actives[j-ndeleted]
                     ndeleted+=1
@@ -402,7 +488,7 @@
             new_lr=all_lr[best_active]/lr_steps # only try a smaller learning rate
             if new_lr&gt;=min_lr:
                 all_lr.append(new_lr)
-                new_candidate = deepcopy(all_candidates[best_active])
+                new_candidate = deepcopy(all_candidates[best_active], use_threads)
                 new_a = len(all_candidates)
                 actives.append(new_a)
                 all_candidates.append(new_candidate)


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000979.html">[Plearn-commits] r7530 - trunk/python_modules/plearn/learners/autolr
</A></li>
	<LI>Next message: <A HREF="000981.html">[Plearn-commits] r7532 - in trunk/plearn_learners/online: .	test/ModuleLearner
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#980">[ date ]</a>
              <a href="thread.html#980">[ thread ]</a>
              <a href="subject.html#980">[ subject ]</a>
              <a href="author.html#980">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
