<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9410 - trunk/plearn_learners_experimental
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-August/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9410%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200808271829.m7RITl26026965%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002849.html">
   <LINK REL="Next"  HREF="002851.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9410 - trunk/plearn_learners_experimental</H1>
    <B>larocheh at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9410%20-%20trunk/plearn_learners_experimental&In-Reply-To=%3C200808271829.m7RITl26026965%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9410 - trunk/plearn_learners_experimental">larocheh at mail.berlios.de
       </A><BR>
    <I>Wed Aug 27 20:29:47 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002849.html">[Plearn-commits] r9409 - trunk/plearn_learners/online
</A></li>
        <LI>Next message: <A HREF="002851.html">[Plearn-commits] r9411 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2850">[ date ]</a>
              <a href="thread.html#2850">[ thread ]</a>
              <a href="subject.html#2850">[ subject ]</a>
              <a href="author.html#2850">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: larocheh
Date: 2008-08-27 20:29:46 +0200 (Wed, 27 Aug 2008)
New Revision: 9410

Modified:
   trunk/plearn_learners_experimental/PseudolikelihoodRBM.cc
   trunk/plearn_learners_experimental/PseudolikelihoodRBM.h
Log:
Added CD for sparse inputs and corrected bug with sparse input classification and pseudolikelihood which wasn't using the hidden layer bias...


Modified: trunk/plearn_learners_experimental/PseudolikelihoodRBM.cc
===================================================================
--- trunk/plearn_learners_experimental/PseudolikelihoodRBM.cc	2008-08-27 18:28:35 UTC (rev 9409)
+++ trunk/plearn_learners_experimental/PseudolikelihoodRBM.cc	2008-08-27 18:29:46 UTC (rev 9410)
@@ -73,6 +73,7 @@
     input_is_sparse( false ),
     factorized_connection_rank( -1 ),
     n_selected_inputs_pseudolikelihood( -1 ),
+    n_selected_inputs_cd( -1 ),
     //select_among_k_most_frequent( -1 ),
     compute_input_space_nll( false ),
     pseudolikelihood_context_size ( 0 ),
@@ -184,6 +185,15 @@
                   &quot;This option is ignored for pseudolikelihood_context_size &gt; 0.\n&quot;
                   );    
 
+    declareOption(ol, &quot;n_selected_inputs_cd&quot;, 
+                  &amp;PseudolikelihoodRBM::n_selected_inputs_cd,
+                  OptionBase::buildoption,
+                  &quot;Number of randomly selected inputs for CD in sparse &quot;
+                  &quot;input case.\n&quot;
+                  &quot;Note that CD for sparse inputs assumes RBMBinomialLayer in &quot;
+                  &quot;input.\n&quot;
+                  );    
+
     //declareOption(ol, &quot;select_among_k_most_frequent&quot;, 
     //              &amp;PseudolikelihoodRBM::select_among_k_most_frequent,
     //              OptionBase::buildoption,
@@ -465,6 +475,11 @@
         }
         input_is_active.resize( inputsize() );
         input_is_active.clear();
+        hidden_act_non_selected.resize( hidden_layer-&gt;size );
+        // CD option
+        pos_hidden.resize( hidden_layer-&gt;size );
+        pos_input_sparse.resize( input_layer-&gt;size );
+        pos_input_sparse.clear();
     }
     else
     {
@@ -624,6 +639,9 @@
     deepCopyField(V_gradients, copies);
     deepCopyField(input_is_active, copies);
     deepCopyField(input_indices, copies);
+    deepCopyField(input_is_selected, copies);
+    deepCopyField(hidden_act_non_selected, copies);
+    deepCopyField(pos_input_sparse, copies);
     deepCopyField(persistent_gibbs_chain_is_started, copies);
 }
 
@@ -928,6 +946,7 @@
                         input_is_active[(int)extra[i]] = true;
                     }
                 }
+                hidden_act += hidden_layer-&gt;bias;
             }
             else
             {
@@ -1184,6 +1203,7 @@
                 //                    input_is_active[(int)extra[i]] = true;
                 //                }
                 //            }
+                //            hidden_act += hidden_layer-&gt;bias;
                 //        }
                 //        else
                 //        {
@@ -1315,6 +1335,7 @@
                 //                            input_is_active[(int)extra[i]] = true;
                 //                        }
                 //                    }
+                //                    hidden_act += hidden_layer-&gt;bias;
                 //                }
                 //                else
                 //                {
@@ -1447,6 +1468,7 @@
                 //                    input_is_active[(int)extra[i]] = true;
                 //                }
                 //            }
+                //            hidden_act += hidden_layer-&gt;bias;
                 //        }
                 //        else
                 //        {
@@ -1578,6 +1600,7 @@
                 //                            input_is_active[(int)extra[i]] = true;
                 //                        }
                 //                    }
+                //                    hidden_act += hidden_layer-&gt;bias;
                 //                }
                 //                else
                 //                {
@@ -1715,6 +1738,7 @@
                 //                    input_is_active[(int)extra[i]] = true;
                 //                }
                 //            }
+                //            hidden_act += hidden_layer-&gt;bias;
                 //        }
                 //        else
                 //        {
@@ -1846,6 +1870,7 @@
                 //                            input_is_active[(int)extra[i]] = true;
                 //                        }
                 //                    }
+                //                    hidden_act += hidden_layer-&gt;bias;
                 //                }
                 //                else
                 //                {
@@ -1951,7 +1976,6 @@
                 //    }
                 //}
 
-
                 // Compute activations
                 if( input_is_sparse )
                 {
@@ -1977,6 +2001,7 @@
                             input_is_active[(int)extra[i]] = true;
                         }
                     }
+                    hidden_act += hidden_layer-&gt;bias;
                 }
                 else
                 {
@@ -2741,9 +2766,193 @@
             (targetsize() == 0 || generative_learning_weight &gt; 0) )
         {
             if( input_is_sparse )
+            {
                 PLERROR(&quot;In PseudolikelihoodRBM::train(): CD is not implemented &quot;
                         &quot;for sparse inputs&quot;);
 
+                // Randomly select inputs
+                if( n_selected_inputs_cd &gt; inputsize() &amp;&amp;
+                    n_selected_inputs_cd &lt;= 0 )
+                    PLERROR(&quot;In PseudolikelihoodRBM::train(): &quot;
+                            &quot;n_selected_inputs_cd should be &gt; 0 and &quot;
+                            &quot;&lt;= inputsize()&quot; );
+
+                if ( input_indices.length() == 0 )
+                {
+                    input_indices.resize(inputsize());
+                    for( int i=0; i&lt;input_indices.length(); i++ )
+                        input_indices[i] = i;
+                        
+                }
+                 
+                // Randomly selected inputs
+                int tmp;
+                int k;
+                for (int j = 0; j &lt; n_selected_inputs_cd; j++) 
+                {
+                    k = j + 
+                        random_gen-&gt;uniform_multinomial_sample(
+                            inputsize() - j);
+                        
+                    tmp = input_indices[j];
+                    input_indices[j] = input_indices[k];
+                    input_indices[k] = tmp;
+                }
+
+                if( factorized_connection_rank &gt; 0 )
+                    PLERROR(&quot;In PseudolikelihoodRBM::train(): factorized &quot;
+                            &quot;connection is not implemented for CD and &quot;
+                            &quot;sparse inputs&quot; );
+
+                if( !fast_exact_is_equal(persistent_cd_weight, 0) )
+                    PLERROR(&quot;In PseudolikelihoodRBM::train(): persistent CD &quot;
+                            &quot;cannot be used for sparse inputs&quot; );
+
+                if( use_mean_field_cd )
+                    PLERROR(&quot;In PseudolikelihoodRBM::train(): MF-CD &quot;
+                            &quot;is not implemented for sparse inputs&quot; );
+
+                if( !fast_exact_is_equal(cd_decrease_ct, 0) )
+                    lr = cd_learning_rate / (1.0 + stage * cd_decrease_ct );
+                else
+                    lr = cd_learning_rate;
+
+                if( targetsize() &gt; 0 )
+                    lr *= generative_learning_weight;
+
+                setLearningRate(lr);
+
+                // Positive phase
+                if( targetsize() &gt; 0 )
+                    pos_target = target_one_hot;
+
+                Vec hidden_act = hidden_layer-&gt;activation;
+                hidden_act.clear();
+                hidden_act_non_selected.clear();
+                train_set-&gt;getExtra(stage%nsamples,extra);
+                input_is_selected.resize( extra.length() );
+                input_is_selected.clear();
+                for( int i=0; i&lt;extra.length(); i++ )
+                {
+                    hidden_act += V((int)extra[i]);
+                    if( input_indices.subVec(0,n_selected_inputs_cd).find((int)extra[i]) &gt;= 0 )
+                    {
+                        input_is_selected[i] = true;
+                        pos_input_sparse[(int)extra[i]] = 1;
+                    }
+                    else
+                        hidden_act_non_selected += V((int)extra[i]);                        
+                }
+                hidden_act += hidden_layer-&gt;bias;
+                hidden_act_non_selected += hidden_layer-&gt;bias;
+
+                if( targetsize() == 1 )
+                    productAcc( hidden_layer-&gt;activation,
+                                target_connection-&gt;weights,
+                                target_one_hot );
+                else if( targetsize() &gt; 1 )
+                    productAcc( hidden_layer-&gt;activation,
+                                target_connection-&gt;weights,
+                                target );
+
+                hidden_layer-&gt;expectation_is_not_up_to_date();
+                hidden_layer-&gt;computeExpectation();
+                //pos_hidden.resize( hidden_layer-&gt;size );
+                pos_hidden &lt;&lt; hidden_layer-&gt;expectation;
+                    
+                // Negative phase
+                real *w;
+                Vec input_act = input_layer-&gt;activation;
+                Vec input_sample = input_layer-&gt;sample;
+                Vec hidden_sample = hidden_layer-&gt;sample;
+                int in;
+                for(int i=0; i&lt;cd_n_gibbs; i++)
+                {
+                    // Down pass
+                    hidden_layer-&gt;generateSample();
+                    for (int j = 0; j &lt; n_selected_inputs_cd; j++) 
+                    {
+                        in = input_indices[j];
+                        w = V[in];
+                        input_act[in] = input_layer-&gt;bias[in];
+                        for( int k=0; k&lt;hidden_layer-&gt;size; k++ )
+                            input_act[in] += w[k] * hidden_sample[k];
+                        
+                        if( input_layer-&gt;use_fast_approximations )
+                        {
+                            input_sample[in] = random_gen-&gt;binomial_sample(
+                                fastsigmoid( input_act[in] ));
+                        }
+                        else
+                        {
+                            input_sample[in] = random_gen-&gt;binomial_sample(
+                                fastsigmoid( input_act[in] ));
+                        }
+                    }
+
+                    // Up pass
+                    hidden_act &lt;&lt; hidden_act_non_selected;
+                    for (int j = 0; j &lt; n_selected_inputs_cd; j++) 
+                    {
+                        in = input_indices[j];
+                        if( fast_exact_is_equal(input_sample[in], 1) )
+                            hidden_act += V(in);
+                    }
+
+                    if( targetsize() &gt; 0 )
+                    {
+                        // Down-up pass for target
+                        target_connection-&gt;setAsUpInput( 
+                            hidden_layer-&gt;sample );
+                        target_layer-&gt;getAllActivations( 
+                            (RBMMatrixConnection*) target_connection );
+                        target_layer-&gt;computeExpectation();
+                        target_layer-&gt;generateSample();
+                        productAcc( hidden_act,
+                                    target_connection-&gt;weights,
+                                    target_layer-&gt;sample );
+                    }
+                    
+                    hidden_layer-&gt;expectation_is_not_up_to_date();
+                    hidden_layer-&gt;computeExpectation();
+                }
+
+                neg_hidden = hidden_layer-&gt;expectation;
+                    
+                hidden_layer-&gt;update(pos_hidden,neg_hidden);
+                if( targetsize() &gt; 0 )
+                {
+                    neg_target = target_layer-&gt;sample;
+                    target_layer-&gt;update(pos_target,neg_target);
+                    target_connection-&gt;update(pos_target,pos_hidden,
+                                              neg_target,neg_hidden);
+                }
+
+                // Selected inputs connection update
+                for (int j = 0; j &lt; n_selected_inputs_cd; j++) 
+                {
+                    in = input_indices[j];
+                    w = V[in];
+                    for( int k=0; k&lt;hidden_layer-&gt;size; k++ )
+                        w[k] += lr * (pos_hidden[k] * pos_input_sparse[in] - 
+                                    neg_hidden[k] * input_sample[in]);
+                    input_layer-&gt;bias[in] += lr * ( pos_input_sparse[in] - 
+                                                    input_sample[in]);
+                }
+                
+                // Non-selected inputs connection update
+                hidden_activation_gradient &lt;&lt; neg_hidden;
+                hidden_activation_gradient -= pos_hidden;
+                hidden_activation_gradient *= -lr;
+                for( int i=0; i&lt;extra.length(); i++ )
+                {
+                    if( input_is_selected[i] = true )
+                        pos_input_sparse[(int)extra[i]] = 0;
+                    else
+                        V((int)extra[i]) += hidden_activation_gradient;
+                }
+            }
+            
             if( !fast_exact_is_equal(persistent_cd_weight, 1.) )
             {
                 if( !fast_exact_is_equal(cd_decrease_ct, 0) )
@@ -3163,7 +3372,8 @@
                 for( int e=0; e&lt;extra.length(); e++ )
                     hidden_act += V((int)extra[e]);
             }
-            
+            hidden_act += hidden_layer-&gt;bias;
+
             for( int i=0 ; i&lt;target_layer-&gt;size ; i++ )
             {
                 target_act[i] = target_layer-&gt;bias[i];

Modified: trunk/plearn_learners_experimental/PseudolikelihoodRBM.h
===================================================================
--- trunk/plearn_learners_experimental/PseudolikelihoodRBM.h	2008-08-27 18:28:35 UTC (rev 9409)
+++ trunk/plearn_learners_experimental/PseudolikelihoodRBM.h	2008-08-27 18:29:46 UTC (rev 9410)
@@ -118,6 +118,9 @@
     //! Number of randomly selected inputs for pseudolikelihood cost
     int n_selected_inputs_pseudolikelihood;
 
+    //! Number of randomly selected inputs for CD in sparse input case
+    int n_selected_inputs_cd;
+
     ////! Indication that inputs for pseudolikelihood cost are selected among the
     ////! k most frequently active inputs
     //int select_among_k_most_frequent;
@@ -315,6 +318,9 @@
     Mat V_gradients;
     TVec&lt;bool&gt; input_is_active;
     TVec&lt;int&gt; input_indices;
+    TVec&lt;bool&gt; input_is_selected;
+    Vec hidden_act_non_selected;
+    Vec pos_input_sparse;
 
     //! Keeps the index of the NLL cost in train_costs
     int nll_cost_index;


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002849.html">[Plearn-commits] r9409 - trunk/plearn_learners/online
</A></li>
	<LI>Next message: <A HREF="002851.html">[Plearn-commits] r9411 - trunk/plearn_learners/generic
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2850">[ date ]</a>
              <a href="thread.html#2850">[ thread ]</a>
              <a href="subject.html#2850">[ subject ]</a>
              <a href="author.html#2850">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
