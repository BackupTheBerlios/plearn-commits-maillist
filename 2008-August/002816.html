<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9371 - trunk/plearn_learners/regressors
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-August/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9371%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200808142041.m7EKfd4F029526%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002810.html">
   <LINK REL="Next"  HREF="002811.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9371 - trunk/plearn_learners/regressors</H1>
    <B>ducharme at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9371%20-%20trunk/plearn_learners/regressors&In-Reply-To=%3C200808142041.m7EKfd4F029526%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9371 - trunk/plearn_learners/regressors">ducharme at mail.berlios.de
       </A><BR>
    <I>Thu Aug 14 22:41:39 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002810.html">[Plearn-commits] r9370 - trunk/plearn/math
</A></li>
        <LI>Next message: <A HREF="002811.html">[Plearn-commits] r9372 - trunk/plearn_learners_experimental
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2816">[ date ]</a>
              <a href="thread.html#2816">[ thread ]</a>
              <a href="subject.html#2816">[ subject ]</a>
              <a href="author.html#2816">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: ducharme
Date: 2008-08-14 22:41:39 +0200 (Thu, 14 Aug 2008)
New Revision: 9371

Modified:
   trunk/plearn_learners/regressors/BasisSelectionRegressor.cc
   trunk/plearn_learners/regressors/BasisSelectionRegressor.h
Log:
Utilisation d'un &quot;template learner&quot;.


Modified: trunk/plearn_learners/regressors/BasisSelectionRegressor.cc
===================================================================
--- trunk/plearn_learners/regressors/BasisSelectionRegressor.cc	2008-08-14 13:52:38 UTC (rev 9370)
+++ trunk/plearn_learners/regressors/BasisSelectionRegressor.cc	2008-08-14 20:41:39 UTC (rev 9371)
@@ -84,9 +84,7 @@
       n_threads(0),
       thread_subtrain_length(0),
       residue_sum(0),
-      residue_sum_sq(0),
-      weights_sum(0)
-
+      residue_sum_sq(0)
 {}
 
 void BasisSelectionRegressor::declareOptions(OptionList&amp; ol)
@@ -199,9 +197,9 @@
                   OptionBase::buildoption,
                   &quot;EXPERIMENTAL OPTION (under development)&quot;);
 
-    declareOption(ol, &quot;learner&quot;, &amp;BasisSelectionRegressor::learner,
+    declareOption(ol, &quot;learner&quot;, &amp;BasisSelectionRegressor::template_learner,
                   OptionBase::buildoption,
-                  &quot;The underlying learner to be trained with the extracted features.&quot;);
+                  &quot;The underlying template learner.&quot;);
 
     declareOption(ol, &quot;precompute_features&quot;, &amp;BasisSelectionRegressor::precompute_features,
                   OptionBase::buildoption,
@@ -242,7 +240,11 @@
                   &quot;will get included in the dictionary for interaction terms ONLY\n&quot;
                   &quot;(i.e. these interact with the other functions.)&quot;);
 
+    declareOption(ol, &quot;true_learner&quot;, &amp;BasisSelectionRegressor::learner,
+                  OptionBase::learntoption,
+                  &quot;The underlying learner to be trained with the extracted features.&quot;);
 
+
     // Now call the parent class' declareOptions
     inherited::declareOptions(ol);
 }
@@ -255,7 +257,7 @@
 void BasisSelectionRegressor::setExperimentDirectory(const PPath&amp; the_expdir)
 { 
     inherited::setExperimentDirectory(the_expdir);
-    learner-&gt;setExperimentDirectory(the_expdir / &quot;SubLearner&quot;);
+    template_learner-&gt;setExperimentDirectory(the_expdir / &quot;SubLearner&quot;);
 }
 
 
@@ -278,6 +280,7 @@
     deepCopyField(kernels, copies);
     deepCopyField(kernel_centers, copies);
     deepCopyField(learner, copies);
+    deepCopyField(template_learner, copies);
     deepCopyField(selected_functions, copies);
     deepCopyField(alphas, copies);
     deepCopyField(scores, copies);
@@ -302,17 +305,6 @@
 
 void BasisSelectionRegressor::forget()
 {
-    
-    //! (Re-)initialize the PLearner in its fresh state (that state may depend
-    //! on the 'seed' option) and sets 'stage' back to 0 (this is the stage of
-    //! a fresh learner!)
-    /*!
-      A typical forget() method should do the following:
-      - initialize a random number generator with the seed option
-      - initialize the learner's parameters, using this random generator
-      - stage = 0
-    */
-
     selected_functions.resize(0);
     targets.resize(0);
     residue.resize(0);
@@ -1078,11 +1070,22 @@
     bool weighted = train_set-&gt;hasWeights();
 
     // set dummy training set, so that undelying learner frees reference to previous training set
+    /*
     VMat newtrainset = new MemoryVMatrix(1,nf+(weighted?2:1));
     newtrainset-&gt;defineSizes(nf,1,weighted?1:0);
     learner-&gt;setTrainingSet(newtrainset);
     learner-&gt;forget();
+    */
 
+    // Deep-copy the underlying learner
+    CopiesMap copies;
+    learner = template_learner-&gt;deepCopy(copies);
+    PP&lt;VecStatsCollector&gt; statscol = template_learner-&gt;getTrainStatsCollector();
+    learner-&gt;setTrainStatsCollector(statscol);
+    PPath expdir = template_learner-&gt;getExperimentDirectory();
+    learner-&gt;setExperimentDirectory(expdir);
+
+    VMat newtrainset;
     if(precompute_features)
     {
         features.resize(l,nf+(weighted?2:1), max(1,int(0.25*l*nf)), true); // enlarge width while preserving content
@@ -1102,12 +1105,9 @@
     else
         newtrainset= new RealFunctionsProcessedVMatrix(train_set, selected_functions, false, true, true);
     newtrainset-&gt;defineSizes(nf,1,weighted?1:0);
-    // perr.clearOutMap();
-    // perr &lt;&lt; &quot;new train set:\n&quot; &lt;&lt; newtrainset &lt;&lt; endl;
     learner-&gt;setTrainingSet(newtrainset);
     learner-&gt;forget();
     learner-&gt;train();
-    // perr &lt;&lt; &quot;retrained learner:\n&quot; &lt;&lt; learner &lt;&lt; endl;
     // resize features matrix so it contains only the features
     if(precompute_features)
         features.resize(l,nf);
@@ -1186,7 +1186,6 @@
     residue_sum = 0.;
     residue_sum_sq = 0.;
     weights.resize(l);
-    weights_sum = 0.;
 
     real w;
     for(int i=0; i&lt;l; i++)
@@ -1195,10 +1194,9 @@
         real t = targ[0];
         targets[i] = t;
         residue[i] = t;
+        weights[i] = w;
         residue_sum += w*t;
         residue_sum_sq += w*square(t);
-        weights[i] = w;
-        weights_sum += w;
     }
 }
 
@@ -1293,13 +1291,13 @@
 void BasisSelectionRegressor::setTrainStatsCollector(PP&lt;VecStatsCollector&gt; statscol)
 { 
     train_stats = statscol;
-    learner-&gt;setTrainStatsCollector(statscol);
+    template_learner-&gt;setTrainStatsCollector(statscol);
 }
 
 
 TVec&lt;string&gt; BasisSelectionRegressor::getTrainCostNames() const
 {
-    return learner-&gt;getTrainCostNames();
+    return template_learner-&gt;getTrainCostNames();
 }
 
 

Modified: trunk/plearn_learners/regressors/BasisSelectionRegressor.h
===================================================================
--- trunk/plearn_learners/regressors/BasisSelectionRegressor.h	2008-08-14 13:52:38 UTC (rev 9370)
+++ trunk/plearn_learners/regressors/BasisSelectionRegressor.h	2008-08-14 20:41:39 UTC (rev 9371)
@@ -233,6 +233,12 @@
     void recomputeResidue();
     void computeOutputFromFeaturevec(const Vec&amp; featurevec, Vec&amp; output) const;
 
+protected:
+    //#####  Protected Data Members  ##########################################
+
+    // Template learner.  Each train step is done with a copy of this one.
+    PP&lt;PLearner&gt; template_learner;
+
 private:
     //#####  Private Data Members  ############################################
 
@@ -244,7 +250,6 @@
     Vec weights;
     double residue_sum;
     double residue_sum_sq;
-    double weights_sum;
 
     mutable Vec input;
     mutable Vec targ;


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002810.html">[Plearn-commits] r9370 - trunk/plearn/math
</A></li>
	<LI>Next message: <A HREF="002811.html">[Plearn-commits] r9372 - trunk/plearn_learners_experimental
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2816">[ date ]</a>
              <a href="thread.html#2816">[ thread ]</a>
              <a href="subject.html#2816">[ subject ]</a>
              <a href="author.html#2816">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
