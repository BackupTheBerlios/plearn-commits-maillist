<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r10060 - in trunk/plearn_learners: meta/test/AdaBoost meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0 meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0 meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0 meta/test/MultiClassAdaBoost meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0 regressors regressors/test/RegressionTree regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir regressors/test/Re! gressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2009-March/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10060%20-%20in%20trunk/plearn_learners%3A%0A%20meta/test/AdaBoost%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0%0A%20meta/test/MultiClassAdaBoost%0A%20meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir%0A%20meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0%0A%20regressors%20regressors/test/RegressionTree%0A%20regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir%0A%20regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir%0A%20regressors/test/Re%21%0A%20gressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir%0A%20regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir&In-Reply-To=%3C200903261509.n2QF9dqx018529%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003499.html">
   <LINK REL="Next"  HREF="003501.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r10060 - in trunk/plearn_learners: meta/test/AdaBoost meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0 meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0 meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0 meta/test/MultiClassAdaBoost meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0 regressors regressors/test/RegressionTree regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir regressors/test/Re! gressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r10060%20-%20in%20trunk/plearn_learners%3A%0A%20meta/test/AdaBoost%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir%0A%20meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0%0A%20meta/test/MultiClassAdaBoost%0A%20meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir%0A%20meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0%0A%20regressors%20regressors/test/RegressionTree%0A%20regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir%0A%20regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir%0A%20regressors/test/Re%21%0A%20gressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir%0A%20regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir&In-Reply-To=%3C200903261509.n2QF9dqx018529%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r10060 - in trunk/plearn_learners: meta/test/AdaBoost meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0 meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0 meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0 meta/test/MultiClassAdaBoost meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0 regressors regressors/test/RegressionTree regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir regressors/test/Re! gressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir">nouiz at mail.berlios.de
       </A><BR>
    <I>Thu Mar 26 16:09:39 CET 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="003499.html">[Plearn-commits] r10059 - trunk/plearn/vmat
</A></li>
        <LI>Next message: <A HREF="003501.html">[Plearn-commits] r10061 - trunk/plearn_learners/cgi
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3500">[ date ]</a>
              <a href="thread.html#3500">[ thread ]</a>
              <a href="subject.html#3500">[ subject ]</a>
              <a href="author.html#3500">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2009-03-26 16:09:37 +0100 (Thu, 26 Mar 2009)
New Revision: 10060

Modified:
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0/final_learner.psave
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/tester.psave
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0/final_learner.psave
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/tester.psave
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0/final_learner.psave
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/tester.psave
   trunk/plearn_learners/meta/test/AdaBoost/PL_AdaBoost_template.pyplearn
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave
   trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn
   trunk/plearn_learners/regressors/RegressionTree.cc
   trunk/plearn_learners/regressors/RegressionTree.h
   trunk/plearn_learners/regressors/RegressionTreeLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeLeave.h
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
   trunk/plearn_learners/regressors/RegressionTreeMulticlassLeaveFast.cc
   trunk/plearn_learners/regressors/RegressionTreeNode.cc
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/tester.psave
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/tester.psave
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/tester.psave
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/experiment.plearn
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/metainfos.txt
   trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/tester.psave
   trunk/plearn_learners/regressors/test/RegressionTree/regression_tree.pyplearn
   trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass.pyplearn
   trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_fast.pyplearn
   trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_outputs.pyplearn
Log:
-Modified RegressionTree so that the output is completly determined by the leave.
  -The Tree just pass it around. 
  -This will allow other type of leave in the futur.
  -Updated the tests


Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0/final_learner.psave
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0/final_learner.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/Split0/final_learner.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -260,7 +260,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *9 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -282,7 +283,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *11 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -304,7 +306,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -332,7 +335,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *15 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -354,7 +358,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -382,7 +387,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -414,7 +420,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *21 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -436,7 +443,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -464,7 +472,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -526,7 +535,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *28 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -548,7 +558,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *30 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -570,7 +581,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -598,7 +610,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -628,7 +641,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *36 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -650,7 +664,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *38 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -672,7 +687,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -700,7 +716,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -730,7 +747,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -792,7 +810,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *47 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -814,7 +833,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *49 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -836,7 +856,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *51 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -858,7 +879,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -886,7 +908,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *55 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -908,7 +931,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -936,7 +960,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -968,7 +993,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -998,7 +1024,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1058,7 +1085,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *66 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1080,7 +1108,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *68 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1102,7 +1131,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *70 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1124,7 +1154,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1152,7 +1183,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1182,7 +1214,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1212,7 +1245,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *78 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1234,7 +1268,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1262,7 +1297,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1324,7 +1360,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *85 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1346,7 +1383,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1374,7 +1412,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *89 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1396,7 +1435,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1424,7 +1464,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *93 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1446,7 +1487,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1474,7 +1516,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *97 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1496,7 +1539,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1524,7 +1568,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1585,7 +1630,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -1709,6 +1755,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *5  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -23,7 +23,7 @@
             weak_learner_template = *3 -&gt; RegressionTree(
                 complexity_penalty_factor = 0.0,
                 compute_train_stats = 0,
-                leave_template = *2 -&gt; RegressionTreeLeave( ),
+                leave_template = *2 -&gt; RegressionTreeLeave( output_confidence_target = 1 ),
                 loss_function_weight = 1,
                 maximum_number_of_nodes = 5,
                 missing_is_valid = 0,

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,3 +1,3 @@
-__REVISION__ = &quot;PL9866&quot;
+__REVISION__ = &quot;PL10047&quot;
 conf                                          = False
 pseudo                                        = False

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_base/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -68,7 +68,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -193,6 +194,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *6  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0/final_learner.psave
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0/final_learner.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/Split0/final_learner.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -260,7 +260,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *9 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -282,7 +283,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *11 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -304,7 +306,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -332,7 +335,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *15 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -354,7 +358,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -382,7 +387,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -414,7 +420,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *21 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -436,7 +443,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -464,7 +472,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -526,7 +535,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *28 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -548,7 +558,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *30 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -570,7 +581,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -598,7 +610,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -628,7 +641,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *36 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -650,7 +664,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *38 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -672,7 +687,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -700,7 +716,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -730,7 +747,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -792,7 +810,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *47 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -814,7 +833,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *49 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -836,7 +856,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *51 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -858,7 +879,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -886,7 +908,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *55 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -908,7 +931,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -936,7 +960,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -968,7 +993,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -998,7 +1024,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1058,7 +1085,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *66 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1080,7 +1108,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *68 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1102,7 +1131,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *70 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1124,7 +1154,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1152,7 +1183,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1182,7 +1214,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1212,7 +1245,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *78 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1234,7 +1268,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1262,7 +1297,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1324,7 +1360,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *85 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1346,7 +1383,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1374,7 +1412,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *89 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1396,7 +1435,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1424,7 +1464,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *93 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1446,7 +1487,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1474,7 +1516,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *97 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1496,7 +1539,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1524,7 +1568,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1585,7 +1630,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -1709,6 +1755,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *5  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -23,7 +23,7 @@
             weak_learner_template = *3 -&gt; RegressionTree(
                 complexity_penalty_factor = 0.0,
                 compute_train_stats = 0,
-                leave_template = *2 -&gt; RegressionTreeLeave( ),
+                leave_template = *2 -&gt; RegressionTreeLeave( output_confidence_target = 1 ),
                 loss_function_weight = 1,
                 maximum_number_of_nodes = 5,
                 missing_is_valid = 0,

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,3 +1,3 @@
-__REVISION__ = &quot;PL9866&quot;
+__REVISION__ = &quot;PL10047&quot;
 conf                                          = True
 pseudo                                        = False

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_conf_rated_adaboost/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -68,7 +68,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -193,6 +194,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *6  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0/final_learner.psave
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0/final_learner.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/Split0/final_learner.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -260,7 +260,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *9 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -282,7 +283,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *11 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -304,7 +306,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -332,7 +335,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *15 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -354,7 +358,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -382,7 +387,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -414,7 +420,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *21 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -436,7 +443,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -464,7 +472,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -526,7 +535,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *28 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -548,7 +558,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *30 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -570,7 +581,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -598,7 +610,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -628,7 +641,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *36 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -650,7 +664,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *38 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -672,7 +687,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -700,7 +716,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -730,7 +747,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -792,7 +810,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *47 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -814,7 +833,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *49 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -836,7 +856,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *51 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -858,7 +879,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -886,7 +908,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *55 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -908,7 +931,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -936,7 +960,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -968,7 +993,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -998,7 +1024,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1058,7 +1085,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *66 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1080,7 +1108,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *68 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1102,7 +1131,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *70 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1124,7 +1154,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1152,7 +1183,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1182,7 +1214,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1212,7 +1245,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *78 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1234,7 +1268,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1262,7 +1297,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1324,7 +1360,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *85 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1346,7 +1383,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1374,7 +1412,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *89 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1396,7 +1435,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1424,7 +1464,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *93 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1446,7 +1487,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1474,7 +1516,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *97 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -1496,7 +1539,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1524,7 +1568,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -1585,7 +1630,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -1709,6 +1755,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *5  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -23,7 +23,7 @@
             weak_learner_template = *3 -&gt; RegressionTree(
                 complexity_penalty_factor = 0.0,
                 compute_train_stats = 0,
-                leave_template = *2 -&gt; RegressionTreeLeave( ),
+                leave_template = *2 -&gt; RegressionTreeLeave( output_confidence_target = 1 ),
                 loss_function_weight = 1,
                 maximum_number_of_nodes = 5,
                 missing_is_valid = 0,

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,3 +1,3 @@
-__REVISION__ = &quot;PL9866&quot;
+__REVISION__ = &quot;PL10047&quot;
 conf                                          = False
 pseudo                                        = True

Modified: trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/.pytest/PL_AdaBoost_pseudo_loss_adaboost/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -68,7 +68,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -193,6 +194,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *6  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;

Modified: trunk/plearn_learners/meta/test/AdaBoost/PL_AdaBoost_template.pyplearn
===================================================================
--- trunk/plearn_learners/meta/test/AdaBoost/PL_AdaBoost_template.pyplearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/AdaBoost/PL_AdaBoost_template.pyplearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -66,7 +66,7 @@
         complexity_penalty_factor = 0.0,
         verbosity = 2,
         report_progress = 0,
-        leave_template = pl.RegressionTreeLeave( )
+        leave_template = pl.RegressionTreeLeave(output_confidence_target = 1)
         )
 )
 

Modified: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/Split0/final_learner.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -277,7 +277,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *10 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -299,7 +300,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *12 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -321,7 +323,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -349,7 +352,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *16 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -371,7 +375,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -399,7 +404,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -431,7 +437,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -486,7 +493,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -572,7 +580,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *28 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -594,7 +603,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *30 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -616,7 +626,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -644,7 +655,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *34 -&gt;RegressionTreeNode(
 missing_is_valid = 0 ;
@@ -666,7 +678,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -694,7 +707,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -726,7 +740,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 2  )
+loss_function_factor = 2 ;
+output_confidence_target = 1  )
 ;
 left_node = *0 ;
 left_leave = *0 ;
@@ -781,7 +796,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -867,7 +883,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;

Modified: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -18,7 +18,7 @@
                     complexity_penalty_factor = 0.0,
                     compute_train_stats = 0,
                     forget_when_training_set_changes = 1,
-                    leave_template = *2 -&gt; RegressionTreeLeave( ),
+                    leave_template = *2 -&gt; RegressionTreeLeave( output_confidence_target = 1 ),
                     loss_function_weight = 1,
                     maximum_number_of_nodes = 3,
                     missing_is_valid = 0,

Modified: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,4 +1,4 @@
-__REVISION__ = &quot;PL10045&quot;
+__REVISION__ = &quot;PL10047&quot;
 conf                                          = False
 pseudo                                        = False
 tms                                           = 1

Modified: trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/.pytest/PL_MultiClassAdaBoost/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -85,7 +85,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -170,7 +171,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -256,7 +258,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;

Modified: trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn
===================================================================
--- trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/meta/test/MultiClassAdaBoost/PL_MutiClassAdaBoost.pyplearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -20,7 +20,7 @@
             verbosity = 2,
             report_progress = 1,
             forget_when_training_set_changes = 1,
-            leave_template = pl.RegressionTreeLeave( )
+            leave_template = pl.RegressionTreeLeave(output_confidence_target = 1)
             ),
         test_minibatch_size=plargs.tms,
         weight_by_resampling=0,

Modified: trunk/plearn_learners/regressors/RegressionTree.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTree.cc	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/RegressionTree.cc	2009-03-26 15:09:37 UTC (rev 10060)
@@ -61,14 +61,14 @@
                         &quot;and one for the others.\n&quot;
     );
 
+bool RegressionTree::output_confidence_target = false;
+
 RegressionTree::RegressionTree()     
     : missing_is_valid(false),
       loss_function_weight(1.0),
       maximum_number_of_nodes(400),
       compute_train_stats(1),
-      complexity_penalty_factor(0.0),
-      output_confidence_target(false)
-
+      complexity_penalty_factor(0.0)
 {
 }
 
@@ -93,14 +93,11 @@
                   &quot;If the error inprovement for the next split is less than the result, the algorithm proceed to an early stop.&quot;
                   &quot;(When set to 0.0, the default value, it has no impact).&quot;);
 
-    declareOption(ol, &quot;output_confidence_target&quot;,
+    declareStaticOption(ol, &quot;output_confidence_target&quot;,
                   &amp;RegressionTree::output_confidence_target,
                   OptionBase::buildoption,
-                  &quot;If false the output size is 1 and contain only the predicted&quot;
-                  &quot; target. Else output size is 2 and contain also the&quot;
-                  &quot; confidence\n&quot;);
+                  &quot;to reload old learner.&quot;);
 
-
     declareOption(ol, &quot;multiclass_outputs&quot;, &amp;RegressionTree::multiclass_outputs, OptionBase::buildoption,
                   &quot;A vector of possible output values when solving a multiclass problem.\n&quot;
                   &quot;When making a prediction, the tree will adjust the output value of each leave to the closest value provided in this vector.&quot;);
@@ -152,7 +149,7 @@
     deepCopyField(first_leave, copies);
     deepCopyField(split_cols, copies);
     deepCopyField(split_values, copies);
-    deepCopyField(tmp_vec, copies);
+    //deepCopyField(tmp_vec, copies); not needed as we don't use it.
     
 }
 
@@ -196,7 +193,6 @@
                     weightsize);
     }
 
-    tmp_vec.resize(2);
     nodes = new TVec&lt;PP&lt;RegressionTreeNode&gt; &gt;();
     tmp_computeCostsFromOutput.resize(outputsize());
     
@@ -367,14 +363,6 @@
     return node; 
 }
 
-int RegressionTree::outputsize() const
-{
-    if(output_confidence_target)
-        return 2;
-    else
-        return 1;
-}
-
 TVec&lt;string&gt; RegressionTree::getTrainCostNames() const
 {
     TVec&lt;string&gt; return_msg(5);
@@ -407,24 +395,13 @@
 }
 void RegressionTree::computeOutput(const Vec&amp; inputv, Vec&amp; outputv) const
 {
-    if(!output_confidence_target){
-        computeOutputAndNodes(inputv, tmp_vec);
-        outputv[0]=tmp_vec[0];
-    }
-    else
-        computeOutputAndNodes(inputv, outputv);
-        
+    computeOutputAndNodes(inputv, outputv);
 }
 
 void RegressionTree::computeOutputAndNodes(const Vec&amp; inputv, Vec&amp; outputv,
                                            TVec&lt;PP&lt;RegressionTreeNode&gt; &gt;* nodes) const
 {
-    if(!output_confidence_target){
-        root-&gt;computeOutputAndNodes(inputv, tmp_vec, nodes);
-        outputv[0]=tmp_vec[0];
-    }
-    else
-        root-&gt;computeOutputAndNodes(inputv, outputv, nodes);
+    root-&gt;computeOutputAndNodes(inputv, outputv, nodes);
     return;
 }
 
@@ -436,13 +413,9 @@
     PLASSERT(nodes);
     nodes-&gt;resize(0);
 
-    computeOutputAndNodes(input, tmp_vec, nodes);
-    if(!output_confidence_target)
-        output[0]=tmp_vec[0];
-    else
-        output&lt;&lt;tmp_vec;
+    computeOutputAndNodes(input, output, nodes);
 
-    computeCostsFromOutputsAndNodes(input, tmp_vec, target, *nodes, costs);
+    computeCostsFromOutputsAndNodes(input, output, target, *nodes, costs);
 }
 
 void RegressionTree::computeCostsFromOutputsAndNodes(const Vec&amp; input,

Modified: trunk/plearn_learners/regressors/RegressionTree.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTree.h	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/RegressionTree.h	2009-03-26 15:09:37 UTC (rev 10060)
@@ -46,10 +46,10 @@
 
 #include &lt;plearn_learners/generic/PLearner.h&gt;
 #include &quot;RegressionTreeRegisters.h&quot;
+#include &quot;RegressionTreeLeave.h&quot;
 namespace PLearn {
 using namespace std;
 class RegressionTreeQueue;
-class RegressionTreeLeave;
 class RegressionTreeNode;
 
 class RegressionTree: public PLearner
@@ -63,16 +63,15 @@
   Build options: they have to be set before training
 */
 
-    bool  missing_is_valid;
+    bool missing_is_valid;
     real loss_function_weight;
     int maximum_number_of_nodes;
     int compute_train_stats;   
     real complexity_penalty_factor;
-    bool output_confidence_target;
     Vec multiclass_outputs;
     PP&lt;RegressionTreeLeave&gt; leave_template;    
     PP&lt;RegressionTreeRegisters&gt; sorted_train_set;
-  
+    static bool output_confidence_target; //to reload old computer
 /*
   Learnt options: they are sized and initialized if need be, at stage 0
 */
@@ -107,7 +106,7 @@
     virtual void         train();
     virtual void         finalize();
     virtual void         forget();
-    virtual int          outputsize() const;
+    virtual int          outputsize() const {return leave_template-&gt;outputsize();}
     virtual TVec&lt;string&gt; getTrainCostNames() const;
     virtual TVec&lt;string&gt; getTestCostNames() const;
     PP&lt;RegressionTreeRegisters&gt; getSortedTrainingSet() const;

Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.cc	2009-03-26 15:09:37 UTC (rev 10060)
@@ -53,6 +53,7 @@
 
 int RegressionTreeLeave::verbosity = 0;
 Vec RegressionTreeLeave::dummy_vec;
+bool RegressionTreeLeave::output_confidence_target = false;
 
 RegressionTreeLeave::RegressionTreeLeave():
     missing_leave(false),
@@ -98,6 +99,13 @@
     declareOption(ol, &quot;loss_function_factor&quot;, &amp;RegressionTreeLeave::loss_function_factor, OptionBase::learntoption,
                   &quot;2 / pow(loss_function_weight, 2.0).\n&quot;);
 
+    declareStaticOption(ol, &quot;output_confidence_target&quot;,
+                  &amp;RegressionTreeLeave::output_confidence_target,
+                  OptionBase::buildoption,
+                  &quot;If false the output size is 1 and contain only the predicted&quot;
+                  &quot; target. Else output size is 2 and contain also the&quot;
+                  &quot; confidence\n&quot;);
+
     declareStaticOption(ol, &quot;output&quot;, &amp;RegressionTreeLeave::dummy_vec, OptionBase::nosave,
                   &quot;DEPRECATED&quot;);
     declareStaticOption(ol, &quot;error&quot;, &amp;RegressionTreeLeave::dummy_vec, OptionBase::nosave,
@@ -194,12 +202,13 @@
 
 void RegressionTreeLeave::getOutputAndError(Vec&amp; output, Vec&amp; error)const
 {
+    real conf = 0;
     if(length_&gt;0){
         output[0] = weighted_targets_sum / weights_sum;
         if (missing_leave != true)
         {
             //we put the most frequent case first as an optimisation
-            output[1] = 1.0;
+            conf = 1.0;
             error[0] = ((weights_sum * output[0] * output[0]) - 
                         (2.0 * weighted_targets_sum * output[0]) + weighted_squared_targets_sum)
                 * loss_function_factor;
@@ -211,17 +220,15 @@
         }
         else
         {
-            output[1] = 0.0;
             error[0] = 0.0;
             error[1] = weights_sum;
             error[2] = 0.0;
         }
     }else{
-        output[0]=MISSING_VALUE;
-        output[1] = 0.0;
+        output[0] = MISSING_VALUE;
         error.clear();
-        return;
     }
+    if(output_confidence_target) output[1] = conf;
 }
 
 void RegressionTreeLeave::printStats()
@@ -231,7 +238,8 @@
     Vec error(3);
     getOutputAndError(output,error);
     cout &lt;&lt; &quot; o0 &quot; &lt;&lt; output[0];
-    cout &lt;&lt; &quot; o1 &quot; &lt;&lt; output[1];
+    if(output_confidence_target)
+        cout &lt;&lt; &quot; o1 &quot; &lt;&lt; output[1];
     cout &lt;&lt; &quot; e0 &quot; &lt;&lt; error[0];
     cout &lt;&lt; &quot; e1 &quot; &lt;&lt; error[1];
     cout &lt;&lt; &quot; ws &quot; &lt;&lt; weights_sum;

Modified: trunk/plearn_learners/regressors/RegressionTreeLeave.h
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeLeave.h	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/RegressionTreeLeave.h	2009-03-26 15:09:37 UTC (rev 10060)
@@ -77,7 +77,7 @@
     real weighted_targets_sum;
     real weighted_squared_targets_sum;
     real loss_function_factor;
- 
+    static bool output_confidence_target;
 public:
     RegressionTreeLeave();
     virtual              ~RegressionTreeLeave();
@@ -86,6 +86,8 @@
     static  void         declareOptions(OptionList&amp; ol);
     virtual void         makeDeepCopyFromShallowCopy(CopiesMap &amp;copies);
     virtual void         build();
+    virtual int          outputsize() const
+    {return output_confidence_target?2:1;}
     void         initLeave(PP&lt;RegressionTreeRegisters&gt; the_train_set, RTR_type_id the_id, bool the_missing_leave = false);
     virtual void         initStats();
     virtual void         addRow(int row);

Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeave.cc	2009-03-26 15:09:37 UTC (rev 10060)
@@ -216,6 +216,7 @@
         error.clear();
         return;
     }
+    real conf = 0;
     int mc_winer = 0;
     //index of the max. Is their an optimized version?
     for (int mc_ind = 1; mc_ind &lt; multiclass_outputs.length(); mc_ind++)
@@ -226,14 +227,13 @@
     output[0] = multiclass_outputs[mc_winer];
     if (missing_leave)
     {
-        output[1] = 0.0;
         error[0] = 0.0;
         error[1] = weights_sum;
         error[2] = 0.0;
     }
     else
     {
-        output[1] = multiclass_weights_sum[mc_winer] / weights_sum;;
+        conf = multiclass_weights_sum[mc_winer] / weights_sum;;
         error[0] = 0.0;
         if (objective_function == &quot;l1&quot;)
         {
@@ -261,8 +261,9 @@
                 error[2] = weights_sum * l2_loss_function_factor; 
             else error[2] = error[0];
         }
-        error[1] = (1.0 - output[1]) * length_;
+        error[1] = (1.0 - conf) * length_;
     }
+    if(output_confidence_target) output[1] = conf;
 }
 
 void RegressionTreeMulticlassLeave::printStats()

Modified: trunk/plearn_learners/regressors/RegressionTreeMulticlassLeaveFast.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeMulticlassLeaveFast.cc	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/RegressionTreeMulticlassLeaveFast.cc	2009-03-26 15:09:37 UTC (rev 10060)
@@ -188,6 +188,7 @@
         return;
     }
     int mc_winer = 0;
+    real conf = 0;
     //index of the max. Is their an optimized version?
     for (int mc_ind = 1; mc_ind &lt; nb_class; mc_ind++)
     {
@@ -197,14 +198,13 @@
     output[0] = mc_winer;
     if (missing_leave)
     {
-        output[1] = 0.0;
         error[0] = 0.0;
         error[1] = weights_sum;
         error[2] = 0.0;
     }
     else
     {
-        output[1] = multiclass_weights_sum[mc_winer] / weights_sum;
+        conf = multiclass_weights_sum[mc_winer] / weights_sum;
         error[0] = 0.0;
         if (objective_function == &quot;l1&quot;)
         {
@@ -227,8 +227,9 @@
         if (error[0] &gt; weights_sum * loss_function_factor)
             error[2] = weights_sum * loss_function_factor;
         else error[2] = error[0];
-        error[1] = (1.0 - output[1]) * length_;
+        error[1] = (1.0 - conf) * length_;
     }
+    if(output_confidence_target) output[1] = conf;
 }
 
 void RegressionTreeMulticlassLeaveFast::printStats()

Modified: trunk/plearn_learners/regressors/RegressionTreeNode.cc
===================================================================
--- trunk/plearn_learners/regressors/RegressionTreeNode.cc	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/RegressionTreeNode.cc	2009-03-26 15:09:37 UTC (rev 10060)
@@ -214,7 +214,7 @@
     right_leave = ::PLearn::deepCopy(leave_template);
     right_leave-&gt;initLeave(the_train_set, right_leave_id);
 
-    leave_output.resize(2);
+    leave_output.resize(leave_template-&gt;outputsize());
     leave_error.resize(3);
 
     leave-&gt;getOutputAndError(leave_output,leave_error);
@@ -496,8 +496,7 @@
         nodes-&gt;append(this);
     if (!left_node)
     {
-        outputv[0] = leave_output[0];
-        outputv[1] = leave_output[1];
+        outputv &lt;&lt; leave_output;
         return;
     }
     if (is_missing(inputv[split_col]))

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -19,7 +19,7 @@
             complexity_penalty_factor = 0.0,
             compute_train_stats = 1,
             forget_when_training_set_changes = 1,
-            leave_template = *3 -&gt; RegressionTreeLeave( ),
+            leave_template = *3 -&gt; RegressionTreeLeave( output_confidence_target = 1 ),
             loss_function_weight = 1,
             maximum_number_of_nodes = 50,
             nstages = 10,

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,2 +1,2 @@
-__REVISION__ = &quot;PL9855&quot;
+__REVISION__ = &quot;PL10047&quot;
 data                                          = PLEARNDIR:examples/data/test_suite/linear_4x_2y.pmat

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -27,7 +27,7 @@
 targetsize = 1 ;
 weightsize = 0 ;
 extrasize = 0 ;
-metadatadir = &quot;&quot; ;
+metadatadir = &quot;PLEARNDIR:examples/data/test_suite/linear_4x_2y.pmat.metadata/SubVMatrix_istart=0_jstart=0_length=200_width=5.metadata/&quot; ;
 source = *2   )
 ;
 splitter = *3 -&gt;FractionSplitter(
@@ -75,7 +75,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -98,7 +99,8 @@
 nservers = 0 ;
 save_trainingset_prefix = &quot;&quot; ;
 test_minibatch_size = 1 ;
-use_a_separate_random_generator_for_testing = 1827  )
+use_a_separate_random_generator_for_testing = 1827 ;
+finalized = 0  )
 ;
 perf_evaluators = {};
 report_stats = 1 ;
@@ -115,6 +117,7 @@
 provide_learner_expdir = 1 ;
 should_train = 1 ;
 should_test = 1 ;
+finalize_learner = 0 ;
 template_stats_collector = *0 ;
 global_template_stats_collector = *0 ;
 final_commands = []
@@ -168,6 +171,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *7  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;
@@ -185,7 +189,8 @@
 nservers = 0 ;
 save_trainingset_prefix = &quot;&quot; ;
 test_minibatch_size = 1 ;
-use_a_separate_random_generator_for_testing = 1827  )
+use_a_separate_random_generator_for_testing = 1827 ;
+finalized = 0  )
 ;
 perf_evaluators = {};
 report_stats = 1 ;
@@ -202,6 +207,7 @@
 provide_learner_expdir = 1 ;
 should_train = 1 ;
 should_test = 1 ;
+finalize_learner = 0 ;
 template_stats_collector = *0 ;
 global_template_stats_collector = *0 ;
 final_commands = []

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -28,7 +28,8 @@
                 multiclass_outputs = [
                     0,
                     1
-                    ]
+                    ],
+                output_confidence_target = 1
                 ),
             loss_function_weight = 1,
             maximum_number_of_nodes = 50,

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,3 +1,3 @@
-__REVISION__ = &quot;PL9855&quot;
+__REVISION__ = &quot;PL10047&quot;
 datatest                                      = PLEARNDIR:examples/data/test_suite/eslt_mixture/data_test.amat
 datatrain                                     = PLEARNDIR:examples/data/test_suite/eslt_mixture/data_train.amat

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClass/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -90,7 +90,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -113,7 +114,8 @@
 nservers = 0 ;
 save_trainingset_prefix = &quot;&quot; ;
 test_minibatch_size = 1 ;
-use_a_separate_random_generator_for_testing = 1827  )
+use_a_separate_random_generator_for_testing = 1827 ;
+finalized = 0  )
 ;
 perf_evaluators = {};
 report_stats = 1 ;
@@ -130,6 +132,7 @@
 provide_learner_expdir = 1 ;
 should_train = 1 ;
 should_test = 1 ;
+finalize_learner = 0 ;
 template_stats_collector = *0 ;
 global_template_stats_collector = *0 ;
 final_commands = []
@@ -183,6 +186,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *8  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;
@@ -200,7 +204,8 @@
 nservers = 0 ;
 save_trainingset_prefix = &quot;&quot; ;
 test_minibatch_size = 1 ;
-use_a_separate_random_generator_for_testing = 1827  )
+use_a_separate_random_generator_for_testing = 1827 ;
+finalized = 0  )
 ;
 perf_evaluators = {};
 report_stats = 1 ;
@@ -217,6 +222,7 @@
 provide_learner_expdir = 1 ;
 should_train = 1 ;
 should_test = 1 ;
+finalize_learner = 0 ;
 template_stats_collector = *0 ;
 global_template_stats_collector = *0 ;
 final_commands = []

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -24,7 +24,10 @@
             complexity_penalty_factor = 0.0,
             compute_train_stats = 1,
             forget_when_training_set_changes = 1,
-            leave_template = *4 -&gt; RegressionTreeMulticlassLeaveFast( nb_class = 2 ),
+            leave_template = *4 -&gt; RegressionTreeMulticlassLeaveFast(
+                nb_class = 2,
+                output_confidence_target = 1
+                ),
             loss_function_weight = 1,
             maximum_number_of_nodes = 50,
             nstages = 10,

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,3 +1,3 @@
-__REVISION__ = &quot;PL9955&quot;
+__REVISION__ = &quot;PL10047&quot;
 datatest                                      = PLEARNDIR:examples/data/test_suite/eslt_mixture/data_test.amat
 datatrain                                     = PLEARNDIR:examples/data/test_suite/eslt_mixture/data_train.amat

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassFast/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -85,6 +85,7 @@
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
 loss_function_factor = 1 ;
+output_confidence_target = 1 ;
 nb_class = 2 ;
 objective_function = &quot;l1&quot; ;
 multiclass_weights_sum = []

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/experiment.plearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/experiment.plearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/experiment.plearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -8,7 +8,7 @@
             complexity_penalty_factor = 0.0,
             compute_train_stats = 1,
             forget_when_training_set_changes = 1,
-            leave_template = *2 -&gt; RegressionTreeLeave( ),
+            leave_template = *2 -&gt; RegressionTreeLeave( output_confidence_target = 1 ),
             loss_function_weight = 1,
             maximum_number_of_nodes = 50,
             multiclass_outputs = [

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/metainfos.txt
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/metainfos.txt	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/metainfos.txt	2009-03-26 15:09:37 UTC (rev 10060)
@@ -1,2 +1,2 @@
-__REVISION__ = &quot;PL9855&quot;
+__REVISION__ = &quot;PL10047&quot;
 data                                          = PLEARNDIR:examples/data/test_suite/linear_4x_2y_multi_class.vmat

Modified: trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/tester.psave
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/tester.psave	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/.pytest/PL_RegressionTree_MultiClassOutput/expected_results/expdir/tester.psave	2009-03-26 15:09:37 UTC (rev 10060)
@@ -57,7 +57,8 @@
 targets_sum = 0 ;
 weighted_targets_sum = 0 ;
 weighted_squared_targets_sum = 0 ;
-loss_function_factor = 1  )
+loss_function_factor = 1 ;
+output_confidence_target = 1  )
 ;
 root = *0 ;
 priority_queue = *0 ;
@@ -80,7 +81,8 @@
 nservers = 0 ;
 save_trainingset_prefix = &quot;&quot; ;
 test_minibatch_size = 1 ;
-use_a_separate_random_generator_for_testing = 1827  )
+use_a_separate_random_generator_for_testing = 1827 ;
+finalized = 0  )
 ;
 perf_evaluators = {};
 report_stats = 1 ;
@@ -97,6 +99,7 @@
 provide_learner_expdir = 1 ;
 should_train = 1 ;
 should_test = 1 ;
+finalize_learner = 0 ;
 template_stats_collector = *0 ;
 global_template_stats_collector = *0 ;
 final_commands = []
@@ -150,6 +153,7 @@
 ] ;
 provide_strategy_expdir = 1 ;
 save_final_learner = 0 ;
+finalize_learner = 0 ;
 learner = *6  ;
 provide_learner_expdir = 1 ;
 expdir_append = &quot;&quot; ;
@@ -167,7 +171,8 @@
 nservers = 0 ;
 save_trainingset_prefix = &quot;&quot; ;
 test_minibatch_size = 1 ;
-use_a_separate_random_generator_for_testing = 1827  )
+use_a_separate_random_generator_for_testing = 1827 ;
+finalized = 0  )
 ;
 perf_evaluators = {};
 report_stats = 1 ;
@@ -184,6 +189,7 @@
 provide_learner_expdir = 1 ;
 should_train = 1 ;
 should_test = 1 ;
+finalize_learner = 0 ;
 template_stats_collector = *0 ;
 global_template_stats_collector = *0 ;
 final_commands = []

Modified: trunk/plearn_learners/regressors/test/RegressionTree/regression_tree.pyplearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/regression_tree.pyplearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/regression_tree.pyplearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -39,7 +39,7 @@
         ,report_progress = 1
         ,forget_when_training_set_changes = 1
 #        ,conf_rated_adaboost = 0
-        ,leave_template = pl.RegressionTreeLeave( )
+        ,leave_template = pl.RegressionTreeLeave(output_confidence_target = 1)
         ),
     tester = pl.PTester(
     splitter = pl.FractionSplitter(splits = TMat(1,3,[ (0,0.75), (0,.75), (0.75,1) ])),

Modified: trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass.pyplearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass.pyplearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass.pyplearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -35,7 +35,7 @@
         ,report_progress = 1
         ,forget_when_training_set_changes = 1
 #        ,conf_rated_adaboost = 0
-        ,leave_template = pl.RegressionTreeMulticlassLeave(multiclass_outputs=[ 0, 1 ] )
+        ,leave_template = pl.RegressionTreeMulticlassLeave(multiclass_outputs=[ 0, 1 ],output_confidence_target = 1 )
         ),
     tester = pl.PTester(
     splitter = pl.FractionSplitter(splits = TMat(1,3,[ (0,200), (0,200), (200,1) ])),

Modified: trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_fast.pyplearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_fast.pyplearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_fast.pyplearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -35,7 +35,7 @@
         ,report_progress = 1
         ,forget_when_training_set_changes = 1
 #        ,conf_rated_adaboost = 0
-        ,leave_template = pl.RegressionTreeMulticlassLeaveFast(nb_class=2 )
+        ,leave_template = pl.RegressionTreeMulticlassLeaveFast(nb_class=2, output_confidence_target = 1)
         ),
     tester = pl.PTester(
     splitter = pl.FractionSplitter(splits = TMat(1,3,[ (0,200), (0,200), (200,1) ])),

Modified: trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_outputs.pyplearn
===================================================================
--- trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_outputs.pyplearn	2009-03-25 20:30:28 UTC (rev 10059)
+++ trunk/plearn_learners/regressors/test/RegressionTree/regression_tree_multiclass_outputs.pyplearn	2009-03-26 15:09:37 UTC (rev 10060)
@@ -30,7 +30,7 @@
         ,report_progress = 1
         ,forget_when_training_set_changes = 1
 #        ,conf_rated_adaboost = 0
-        ,leave_template = pl.RegressionTreeLeave( )
+        ,leave_template = pl.RegressionTreeLeave(output_confidence_target = 1)
         ),
     tester = pl.PTester(
     splitter = pl.FractionSplitter(splits = TMat(1,3,[ (0,0.75), (0,.75), (0.75,1) ])),


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="003499.html">[Plearn-commits] r10059 - trunk/plearn/vmat
</A></li>
	<LI>Next message: <A HREF="003501.html">[Plearn-commits] r10061 - trunk/plearn_learners/cgi
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3500">[ date ]</a>
              <a href="thread.html#3500">[ thread ]</a>
              <a href="subject.html#3500">[ subject ]</a>
              <a href="author.html#3500">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
