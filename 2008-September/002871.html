<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Plearn-commits] r9431 - in trunk: python_modules/plearn/parallel	scripts
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/plearn-commits/2008-September/index.html" >
   <LINK REL="made" HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9431%20-%20in%20trunk%3A%20python_modules/plearn/parallel%0A%09scripts&In-Reply-To=%3C200809032015.m83KF7XH020805%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002870.html">
   <LINK REL="Next"  HREF="002872.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Plearn-commits] r9431 - in trunk: python_modules/plearn/parallel	scripts</H1>
    <B>nouiz at BerliOS</B> 
    <A HREF="mailto:plearn-commits%40lists.berlios.de?Subject=Re%3A%20%5BPlearn-commits%5D%20r9431%20-%20in%20trunk%3A%20python_modules/plearn/parallel%0A%09scripts&In-Reply-To=%3C200809032015.m83KF7XH020805%40sheep.berlios.de%3E"
       TITLE="[Plearn-commits] r9431 - in trunk: python_modules/plearn/parallel	scripts">nouiz at mail.berlios.de
       </A><BR>
    <I>Wed Sep  3 22:15:07 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="002870.html">[Plearn-commits] r9430 - trunk/scripts
</A></li>
        <LI>Next message: <A HREF="002872.html">[Plearn-commits] r9432 - trunk/plearn/vmat
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2871">[ date ]</a>
              <a href="thread.html#2871">[ thread ]</a>
              <a href="subject.html#2871">[ subject ]</a>
              <a href="author.html#2871">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: nouiz
Date: 2008-09-03 22:15:06 +0200 (Wed, 03 Sep 2008)
New Revision: 9431

Modified:
   trunk/python_modules/plearn/parallel/dbi.py
   trunk/scripts/dbidispatch
Log:
better doc, bugfix for dag


Modified: trunk/python_modules/plearn/parallel/dbi.py
===================================================================
--- trunk/python_modules/plearn/parallel/dbi.py	2008-09-03 17:23:38 UTC (rev 9430)
+++ trunk/python_modules/plearn/parallel/dbi.py	2008-09-03 20:15:06 UTC (rev 9431)
@@ -883,15 +883,36 @@
 
         condor_file_dag = condor_file+&quot;.dag&quot;
         condor_dag = open( condor_file_dag, 'w' )
-        for i in range(len(self.tasks)):
-            task=self.tasks[i]
-            argstring =condor_escape_argument(' ; '.join(task.commands))
-            argstring =' ; '.join(task.commands)
-            condor_dag.write(&quot;JOB %d %s\n&quot;%(i,condor_file))
-            condor_dag.write('VARS %d args=&quot;%s&quot;\n'%(i,argstring))
-            s=os.path.join(self.log_dir,&quot;condor&quot;+self.base_tasks_log_file[i])
-            condor_dag.write('VARS %d stdout=&quot;%s&quot;\n'%(i,s+&quot;.out&quot;))
-            condor_dag.write('VARS %d stderr=&quot;%s&quot;\n\n'%(i,s+&quot;.err&quot;))
+        if self.base_tasks_log_file:
+            for i in range(len(self.tasks)):
+                task=self.tasks[i]
+                argstring =' ; '.join(task.commands)
+                condor_dag.write(&quot;JOB %d %s\n&quot;%(i,condor_file))
+                condor_dag.write('VARS %d args=&quot;%s&quot;\n'%(i,argstring))
+                s=os.path.join(self.log_dir,&quot;condor&quot;+self.base_tasks_log_file[i])
+                condor_dag.write('VARS %d stdout=&quot;%s&quot;\n'%(i,s+&quot;.out&quot;))
+                condor_dag.write('VARS %d stderr=&quot;%s&quot;\n\n'%(i,s+&quot;.err&quot;))
+        elif self.stdouts and self.stderrs:
+            assert len(self.stdouts)==len(self.stderrs)==len(self.tasks)
+            for (task,stdout_file,stderr_file) in zip(self.tasks,self.stdouts,self.stderrs):
+                if stdout_file==stderr_file:
+                    print &quot;Condor can't redirect the stdout and stderr to the same file!&quot;
+                    sys.exit(1)
+                argstring =' ; '.join(task.commands)
+                condor_dag.write(&quot;JOB %d %s\n&quot;%(i,condor_file))
+                condor_dag.write('VARS %d args=&quot;%s&quot;\n'%(i,argstring))
+                s=os.path.join(self.log_dir,&quot;condor&quot;+self.base_tasks_log_file[i])
+                condor_dag.write('VARS %d stdout=&quot;%s&quot;\n'%(i,stdout_file))
+                condor_dag.write('VARS %d stderr=&quot;%s&quot;\n\n'%(i,stderr_file))
+
+
+        elif self.stdouts or self.stderrs:
+            print &quot;DBICondor should have stdouts and stderrs or none of them&quot;
+            sys.exit(1)
+        else:
+            #should not happen
+            raise NotImplementedError()
+                
         condor_dag.close()
 
         dbi_file=get_plearndir()+'/python_modules/plearn/parallel/dbi.py'

Modified: trunk/scripts/dbidispatch
===================================================================
--- trunk/scripts/dbidispatch	2008-09-03 17:23:38 UTC (rev 9430)
+++ trunk/scripts/dbidispatch	2008-09-03 20:15:06 UTC (rev 9431)
@@ -21,86 +21,111 @@
 An * after '[', '{' or ',' signals the default value.
 An + after } tell that we can put one or more of the choise separeted by a comma
 '''
-LongHelp=&quot;&quot;&quot;Dispatches jobs with dbi.py. dbi can dispatch jobs on condor, bqtools, cluster, local and ssh. If no system is selected on the command line, we try them in the previous order. ssh is never automaticaly selected.
+LongHelp=&quot;&quot;&quot;Dispatches jobs with dbi.py. dbi can dispatch jobs on condor, bqtools, cluster,
+local and ssh. If no system is selected on the command line, we try them in the
+previous order. ssh is never automaticaly selected.
 
 %(ShortHelp)s
 
 common options:
   The -h, --help print the long help(this)
-  The --condor, --bqtools, --cluster, --local or --ssh option specify on which system the jobs will be sent. If not present, we will use the first available in the previously given order. ssh is never automaticaly selected.
+  The --condor, --bqtools, --cluster, --local or --ssh option specify on which 
+    system the jobs will be sent. If not present, we will use the first 
+    available in the previously given order. ssh is never automaticaly selected.
   The '--[no_]dbilog' tells dbi to generate (or not) an additional log
-  The '--[no_]test' option makes dbidispatch generate the file %(ScriptName)s, without executing it. That way you can see what dbidispatch generates. Also, this file calls dbi in test mode, so dbi executes everything in the script except the experiment in %(ScriptName)s (so you can check the script).
+  The '--[no_]test' option makes dbidispatch generate the file %(ScriptName)s,
+    without executing it. That way you can see what dbidispatch generates. Also,
+    this file calls dbi in test mode, so dbi do everything but don't execute the
+    jobs. (so you can check the script).
   The '--testdbi' set only dbi in test mode. Not dbidispatch
-  The '--file=FILEPATH' specifies a file containing the jobs to execute, one per line. This is instead of specifying one job[s] on the command line.
-  The '--nb_proc=nb_proc', specifies the maximum number of concurrent jobs running. The value -1 will try to execute all jobs concurently. Use with care as some back-end or configuration do not handle this correctly. (work for condor, bqtools, cluster with --cwait)
+  The '--file=FILEPATH' specifies a file containing the jobs to execute, one 
+    per line. This is instead of specifying job(s) on the command line.
+  The '--nb_proc=nb_proc', specifies the maximum number of concurrent jobs. 
+    The value -1 will try to execute all jobs concurently. This work for condor,
+    bqtools, but for cluster you SHOULD add  the --cwait option.
     --local=N is the same as --local --nb_proc=N
     --cluster=N is the same as --cluster --nb_proc=N
     --bqtools=N is the same as --bqtools --nb_proc=N
     --ssh=N is the same as --ssh --nb_proc=N
     --condor=N  is the same as --condor --nb_proc=N
-  The '--[*no_]clean_up' set the DBI option clean_up to true(false)
+  The '--[*no_]clean_up' set the DBI option clean_up to true or false
 
-
 bqtools and cluster option:
-  The '--duree' option specifies the maximum duration of the jobs. The syntax depends on where the job is dispatched. For the cluster syntax, see 'cluster --help'. For bqtools, the syntax is '--duree=12:13:15', giving 12 hours, 13 minutes and 15 seconds.
+  The '--duree' option specifies the maximum duration of the jobs. The syntax 
+    depends on the back-end. For the cluster syntax, see 'cluster --help'. 
+    For bqtools, the syntax is '--duree=12:13:15', giving 12 hours, 
+    13 minutes and 15 seconds.
 
 bqtools only options:
-  The '--micro[=nb_batch]' option can be used with BqTools when launching many jobs that
-  have a very short duration. This may prevent some queue crashes. The nb_batch value
-  is the number of experience to group together in a batch.(default 20)
-
+  If the --long option is not set, the maximum duration of each job will be 
+    120 hours (5 days).
+  The '--micro[=nb_batch]' option can be used with BqTools when launching many 
+    jobs that have a very short duration. This may prevent some queue crashes. 
+    The nb_batch value is the number of experience to group together in a batch.
+    (by default not used, --micro is equivalent to --micro=20)
   The '--long' option must be used with BqTools to launch jobs whose duration
-  is more than 5 days. The maximum duration of a job will be either the
-  BQ_MAX_JOB_DURATION environment variable (in the form hour:min:sec) if it is
-  set, and 1200:00:00 (50 days) otherwise.
-  Since long jobs are launched on a different queue with few nodes, please make
-  sure you are not using too many nodes at once.
-  If this option is not set, the maximum duration of each job will be 120 hours
-  (5 days).
+    is more than 5 days. The maximum duration of a job will be either the
+    BQ_MAX_JOB_DURATION environment variable (in the form hour:min:sec) if it is
+    set, and 1200:00:00 (50 days) otherwise. Since long jobs are launched on a
+    different queue with few nodes, please make sure you are not using too many
+    nodes at once with the --nb_proc option.
 
 cluster and condor options:
-  The '--3264', '--32' or '--64' specify which type of cpu the node must have to execute the commands.
-  The '--mem=X' speficify the number of meg the program need to execute.
-  The '--os=X' speficify the os of the server. Cluster default: fc4. Condor default to the same as the submit host. On condor, --os=FC7,FC9 tell to use FC7 or FC9 hosts.
+  The '--3264', '--32' or '--64' specify the type of cpu for the execution node.
+  The '--mem=X' speficify the number of ram in meg the program need to execute.
+  The '--os=X' speficify the os of the server. 
+    Cluster default: fc7. Cluster accepted value fc4, fc7 and fc9.
+    Condor default to the same as the submit host and --os=FC7,FC9 
+    tell to use FC7 or FC9 hosts.
 
 cluster only options:
-  The '--[no_]cwait' is transfered to cluster. This must be enabled if there is not nb_proc available nodes. Otherwise when there are no nodes available, the launch of that command fails.
+  The '--[no_]cwait' is transfered to cluster. 
+    This must be enabled if there is not nb_proc available nodes. Otherwise 
+    when there are no nodes available, the launch of that command fails.
   The '--force' option is passed to cluster
   The '--interruptible' option is passed to cluster
   The '--cpu=nb_cpu_per_node' option is passed to cluster
 
 condor only options:
-  The '--[no_]getenv' option is forwarded to condor. If True, the current environnement variable will be forwarded to the execution node.
-  The '--req=\&quot;CONDOR_REQUIREMENT\&quot;' option makes dbidispatch send additional option to DBI that will be used to generate additional requirement for condor. CONDOR_REQUIREMENT must follow the syntax of requirement for condor with one exception. The symbol '\&quot;' must be escaped 3 times! So the requirement (Machine == \&quot;computer.example.com\&quot;) must be writen in the following way:
+  If the CONDOR_HOME environment variable is set, then the HOME variable will
+     be set to this value for jobs submitted to condor.
+  The '--[no_]getenv' option is forwarded to condor. If True, the current 
+    environnement variable will be forwarded to the execution node.
+  The '--req=\&quot;CONDOR_REQUIREMENT\&quot;' add requirement for condor. 
+    CONDOR_REQUIREMENT must follow the syntax of requirement for condor with 
+    one exception. The symbol '\&quot;' must be escaped 3 times! So the requirement 
+    (Machine == \&quot;computer.example.com\&quot;) must be writen in the following way:
 
-  dbidispatch \&quot;--req=Machine==\\\&quot;computer.example.com\\\&quot;\&quot;
-     or
-  dbidispatch '--req=Machine==&quot;computer.example.com&quot;'
+    dbidispatch \&quot;--req=Machine==\\\&quot;computer.example.com\\\&quot;\&quot;
+       or
+    dbidispatch '--req=Machine==&quot;computer.example.com&quot;'
 
-  The '--[no_]server' option add the requirement that the executing host must be a server dedicated to computing. This is equivalent to: dbidispatch '--req=SERVER==True'(SERVER==False)
-  The '--[no_]prefserver' option will tell that you prefer to execute on server first. This is equivalent to 'rank=SERVER=?=True' in the submit file.
+  The '--[no_]server' option add the requirement that the executing host must
+    be a server dedicated to computing. This is equivalent to: 
+    dbidispatch '--req=SERVER==True'(SERVER==False)
+  The '--[no_]prefserver' option will tell that you prefer to execute on server
+    first. This is equivalent to dbidispatch '--rank=SERVER=?=True'.
   The '--rank=STRING' option add rank=STRING in the submit file.
-  The '--machine=full_host_name' option add the requirement that the executing host is full_host_name
-     dbidispatch --machine=computer.example.com
-        witch is equivalent to
-     dbidispatch '--req=Machine==&quot;computer.example.com&quot;'
-  The '--machines=regexp' option add the requirement that the executing host name must be match the regexp
+  The '--machine=full_host_name' option add the requirement that the executing
+     host is full_host_name. Is equivalent to
+     dbidispatch '--req=Machine==&quot;full_host_name&quot;'
+  The '--machines=regexp' option add the requirement that the executing host 
+    name must be match the regexp
      dbidispatch '--machines=computer00*'
         witch is equivalent to
      dbidispatch '--req=regexp(&quot;computer0*&quot;, target.Machine)'
-  The '--[no_]nice' option set the nice_user option to condor. If nice, the job(s) will have the lowest possible priority.
+  The '--[no_]nice' option set the nice_user option to condor. 
+    If nice, the job(s) will have the lowest possible priority.
   The '--env=VAR=VALUE' option will set in the environment of the executing jobs the variable VAR with value VALUE. To pass many variable you can 1) use one --env option and separ the value by ';'(don't forget to quote) or 2) you can pass many time the --env parameter.
   The '--raw=STRING1[\nSTRING2...]' option add all the STRINGX parameter to the submit file of condor.
-  If the CONDOR_HOME environment variable is set, then the HOME variable will
-     be set to this value for jobs submitted to condor.
+  The '--[no_]set_special_env' option will set the varialbe OMP_NUM_THREADS, MKL_NUM_THREADS and GOTO_NUM_THREADS to the number of cpus allocated to job.
   The '--tasks_filename={compact,explicit,nb0,nb1,sh}+' option will change the filename where the stdout, stderr are redirected. We can put many option separated by comma. They will be appended in the filename with a dot. For all format except sh, they have this pattern condor.X.{out,error} where X=:
       - default : same as nb0
-      - compact : will be a unic string with parameter that change of value between jobs
-      - explicit: will be a unic string that represent the full command to execute
+      - compact : a unic string with parameter that change of value between jobs
+      - explicit: a unic string that represent the full command to execute
       - nb0     : a number from 0 to nb job -1.
       - nb1     : a number from 1 to nb job.
       - sh      : parse the command for &gt; and 2&gt; redirection command. If one or both of them are missing, they are redirected to /dev/null
-  The '--[no_]set_special_env' option will set the varialbe OMP_NUM_THREADS, MKL_NUM_THREADS and GOTO_NUM_THREADS to the number of cpus allocated to job.
 
 where &lt;command-template&gt; is interpreted as follows: the first argument
 is the &lt;command&gt; above, and the rest are interpreted as &lt;arguments&gt;.
@@ -142,7 +167,7 @@
 FILE = &quot;&quot;
 dbi_param={}
 testmode=False
-tasks_filename=&quot;&quot;
+tasks_filename = [&quot;nb0&quot;]
 
 PATH=os.getenv('PATH')
 if search_file('condor_submit',PATH):
@@ -405,7 +430,7 @@
             stdouts.append(output)
             stderrs.append(error)
             commands[x]=' '.join(sp)
-            
+            dbi_param[n]=[]
         dbi_param[&quot;stdouts&quot;]=stdouts
         dbi_param[&quot;stderrs&quot;]=stderrs
     else:


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="002870.html">[Plearn-commits] r9430 - trunk/scripts
</A></li>
	<LI>Next message: <A HREF="002872.html">[Plearn-commits] r9432 - trunk/plearn/vmat
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2871">[ date ]</a>
              <a href="thread.html#2871">[ thread ]</a>
              <a href="subject.html#2871">[ subject ]</a>
              <a href="author.html#2871">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/plearn-commits">More information about the Plearn-commits
mailing list</a><br>
</body></html>
